{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f047490f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Import Dataset CIFAR-10 Melalui Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1b3b8",
   "metadata": {},
   "source": [
    "Lakukan clone repository github berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7e9eb7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/YoongiKim/CIFAR-10-images.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d189bd3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Tambahkan kode berikut untuk load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddbd9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_data(image_root='CIFAR-10-images', img_size=(32, 32), batch_size=32, as_numpy=True):\n",
    "    train_dir = os.path.join(image_root, 'train')\n",
    "    test_dir = os.path.join(image_root, 'test')\n",
    "\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        train_dir,\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    if as_numpy:\n",
    "        x_train, y_train = [], []\n",
    "        for imgs, labels in train_ds:\n",
    "            x_train.append(imgs.numpy())\n",
    "            y_train.append(labels.numpy())\n",
    "        x_train = np.concatenate(x_train, axis=0)\n",
    "        if batch_size == None:\n",
    "          y_train = np.stack(y_train, axis=0).reshape(-1, 1)\n",
    "        else:\n",
    "          y_train = np.concatenate(y_train, axis=0).reshape(-1, 1)\n",
    "\n",
    "        x_test, y_test = [], []\n",
    "        for imgs, labels in test_ds:\n",
    "            x_test.append(imgs.numpy())\n",
    "            y_test.append(labels.numpy())\n",
    "        x_test = np.concatenate(x_test, axis=0)\n",
    "        if batch_size == None:\n",
    "          y_test = np.stack(y_test, axis=0).reshape(-1, 1)\n",
    "        else:\n",
    "          y_test = np.concatenate(y_test, axis=0).reshape(-1, 1)\n",
    "\n",
    "        return (x_train.astype(np.uint8), y_train.astype(np.uint8)), (x_test.astype(np.uint8), y_test.astype(np.uint8))\n",
    "\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3b750f",
   "metadata": {},
   "source": [
    "Train dan Test Dataset bisa langsung di load dengan kode berikut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec3920",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_data()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
