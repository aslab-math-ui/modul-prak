{
  "hash": "5f636197f3a8be81b81d58c9f3592c33",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Model Building\"\nsubtitle: \"Model Building & Model Validation\"\nimage: static\\Plot regresi.png\ndescription: \"Offline di Departemen Matematika\"\ndate: 11/4/2024\npage-navigation: true\nformat:\n  html:\n    code-overflow: wrap\nknitr:\n  opts_chunk:\n    comment: ''\nformat-links: false\ninclude-in-header:\n  - text: |\n      <style>\n      .cell-output-stdout code {\n        word-break: break-wor !important;\n        white-space: pre-wrap !important;\n      }\n      </style>\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n# Model Building\n\nApa Itu Model Building? Model building adalah proses\nmembuat model yang bisa cocok dengan data yang kita miliki dan bisa\nmemberikan prediksi yang baik untuk masa depan. Dalam konteks analisis\nregresi, ini berarti memilih bentuk model yang bisa menunjukkan hubungan\nantara hasil yang kita prediksi $(y)$ dan variabel-variabel **yang**\nmemengaruhi hasil tersebut $(x_1,x_2,...,x_k).$\n\nKenapa Proses Ini Penting? Proses model building sangat penting karena\nmenentukan seberapa baik model kita bisa bekerja. Jika model yang kita\nbuat tidak mencerminkan hubungan yang sebenarnya antara\nvariabel-variabel, maka model tersebut tidak akan memberikan hasil yang\nakurat dan bisa menyebabkan kesalahan dalam analisis atau prediksi.\n\nLangkah-langkah dalam Model Building:\n\n1.  Identifikasi Variabel Respons (Y): Tentukan variabel dependen yang\n    ingin diprediksi atau dianalisis.\n\n2.  Klasifikasi Variabel Prediktor: Kelompokkan variabel independen\n    sebagai variabel kuantitatif (yang diukur dengan angka) atau\n    kualitatif (yang berupa kategori).\n\n3.  Gunakan Dummy Variables: Jika ada variabel kualitatif, ubah variabel\n    tersebut menjadi dummy variables agar bisa dimasukkan ke dalam\n    model.\n\n4.  Pertimbangkan Derajat Lebih Tinggi: Untuk variabel kuantitatif,\n    pertimbangkan untuk menambahkan komponen seperti $X^2$ atau $X^3$\n    untuk menangkap hubungan non-linier yang mungkin ada.\n\n5.  Gunakan Polinomial Derajat Tinggi: Jika relevan, kodekan variabel\n    kuantitatif dalam bentuk polinomial agar model bisa lebih fleksibel\n    dalam menangkap pola data.\n\n6.  Tambahkan Interaksi Antar Variabel: Pertimbangkan untuk menambahkan\n    interaksi antara variabel kuantitatif dan kualitatif untuk melihat\n    efek gabungan mereka terhadap variabel respons.\n\n7.  Bandingkan Model Bertingkat (Nested Models): Gunakan uji partial\n    F-test untuk membandingkan model sederhana dengan model yang lebih\n    kompleks dan pilih model yang terbaik.\n\n8.  Validasi Model: Pastikan model akhir diuji dengan data yang berbeda\n    (misalnya, menggunakan metode cross-validation atau jackknife) untuk\n    memastikan bahwa model tersebut dapat diandalkan untuk prediksi di\n    luar data pelatihan (data training).\n\n## Penerapan Model Building\n\n1.  Identifikasi Variabel Respons (Y)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(AER)\ndata('mtcars')\nhead(mtcars)\nstr(mtcars)\n```\n:::\n\n\n\n2.  Klasifikasi Variabel Prediktor\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncategorical = c(\"cyl\", \"vs\", \"am\", \"gear\", \"carb\")\nmtcars[categorical] <- lapply(mtcars[categorical], as.factor)\nstr(mtcars)\n```\n:::\n\n\n\n3.  Gunakan Dummy Variables untuk Variabel Kualitatif\n\n    Variabel kualitatif yang sudah diubah menjadi faktor di step\n    sebelumnya di-dummy-kan secara otomatis oleh R saat digunakan dalam\n    fungsi lm().\n\n4.  Pertimbangkan Derajat Lebih Tinggi\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 = lm(mpg ~ disp, data = mtcars)\nmodel2 = lm(mpg ~ disp + I(disp^2), data = mtcars)\n```\n:::\n\n\n\nVisualisasi\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mtcars$disp, mtcars$mpg, main = 'Perbandingan Regresi Linier Sederhana dan Derajat 2', xlab = 'disp', ylab = 'mpg')\nlines(mtcars$disp, predict(model1), col = 'blue', lwd = 3)\nlines(sort(mtcars$disp), predict(model2)[order(mtcars$disp)], col = 'darkgreen', lwd = 3)\nlegend('topright', legend = c('Derajat 1', 'Derajat 2'), col = c('blue', 'darkgreen'), lty = 1, cex = 1, lwd = 3)\n```\n:::\n\n\n\n5.  Tambahkan Interaksi Antar Variabel\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_interaction = lm(mpg ~ disp * hp, data = mtcars)\nsummary(model_interaction)\n```\n:::\n\n\n\n6.  Bandingkan Nested Model\n\n    Menggunakan metode seleksi forward, backward, dan both direction.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_intercept = lm(mpg ~ 1, data = mtcars)\nmodel_full = lm(mpg ~ ., data = mtcars)\n\n# Forward selection\nforward = step(model_intercept, direction = 'forward', scope = formula(model_full), trace = 0)\nsummary(forward)\n\n# Backward selection\nbackward = step(model_full, direction = 'backward', trace = 0)\nsummary(backward)\n\n# Both direction selection\nboth = step(model_intercept, direction = 'both', scope = formula(model_full), trace = 0)\nsummary(both)\n```\n:::\n\n\n\n7.  Validasi Model\n\n    Evaluasi model dengan menggunakan metode cross-validation atau\n    melihat pengaruh outliers.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nn <- nrow(mtcars)\nk <- 5  # Jumlah fold\nfolds <- sample(rep(1:k, length.out = n))\n\nerrors <- numeric(k)\n\nfor (i in 1:k) {\n  train_data <- mtcars[folds != i, ]\n  test_data <- mtcars[folds == i, ]\n  \n  model <- lm(mpg ~ disp + hp + wt, data = train_data)\n  predictions <- predict(model, newdata = test_data)\n  \n  errors[i] <- mean((test_data$mpg - predictions)^2)\n}\n\nmean_cv_error <- mean(errors)\nprint(mean_cv_error)\n```\n:::\n\n\n\nNilai mean_cv_error adalah rata-rata dari Mean Squared Error (MSE) pada\ntiap fold selama cross-validation. Semakin kecil nilainya akan semakin\nbaik, yang berarti model membuat prediksi yang lebih akurat pada data\nbaru. Respectively, nilai yang besar mengindikasikan bahwa model mungkin\nmemiliki masalah, seperti underfitting (model tidak cukup kompleks) atau\noverfitting (model terlalu kompleks dan tidak mampu melakukan\ngeneralisasi dengan baik).\n\n-   Nilai mean_cv_error sebesar 9 cukup baik atau tidak tergantung pada\n    konteks dan skala data. Jika variabel targte (mpg) dalam dataset\n    mtcars memiliki kisaran nilai yang relatif besar, maka MSE sebesar 9\n    mungkin dapat diterima. Namun, jika kisaran nilai mpg kecil, maka\n    MSE sebesar 9 bisa dianggap tinggi dan kurang baik yang\n    mengindikasikan model tidak cukup akurat.\n\n# Model Validation\n\nApa Itu Model Validation? Model validation adalah proses mengevaluasi\nmodel yang telah dibangun untuk memastikan bahwa model yang dibangun\ntidak hanya akurat untuk data pelatihan, tetapi juga andal dan stabil\nsaat digunakan pada data lain.\n\nKenapa Proses Ini Penting? Proses validasi model sangat penting karena\nmemungkinkan kita untuk mengevaluasi ketahanan model saat digunakan pada\ndata baru. Model yang bekerja dengan baik pada data pelatihan mungkin\ntidak berkinerja sama baiknya pada data yang berbeda, terutama jika\nmodel tersebut terlalu \"cocok\" atau overfit dengan data pelatihan.\nValidasi ini penting agar model dapat digunakan untuk prediksi atau\npengambilan keputusan di dunia nyata tanpa menghasilkan hasil yang bias\natau tidak akurat.\n\nLangkah-langkah dalam Model Validation:\n\n-   Evaluasi Nilai Prediksi: Memeriksa hasil prediksi untuk memastikan\n    bahwa nilainya masuk akal dan tidak menunjukkan pola atau prediksi\n    yang aneh. Ini membantu mendeteksi apakah model menghasilkan\n    prediksi yang valid dan logis.\n\n-   Pemeriksaan Parameter Model: Mengevaluasi koefisien yang dihasilkan\n    oleh model untuk memastikan bahwa tanda (positif atau negatif) dan\n    besaran koefisien sesuai dengan harapan. Koefisien yang tidak stabil\n    dapat menjadi tanda bahwa model mungkin tidak bekerja baik pada data\n    baru.\n\n-   Cross-Validation (Data-Splitting): Memisahkan data menjadi data\n    training dan data testing untuk menilai performa model pada data\n    yang tidak dilihat selama pelatihan. Cross-validation mengukur\n    ketahanan model dengan mengevaluasi rata-rata kesalahan prediksi\n    pada data testing.\n\n-   Jackknifing: Teknik yang digunakan ketika ukuran data terlalu kecil\n    untuk dipecah menjadi data training dan data testing. Metode ini\n    melibatkan penghilangan satu observasi secara bergantian dan\n    menghitung prediksi untuk masing-masing kasus, lalu menganalisis\n    performanya.\n\n-   Pengumpulan Data Baru untuk Prediksi: Menguji model dengan data baru\n    yang berbeda dari data training Dengan membandingkan prediksi model\n    dengan data nyata yang baru, kita dapat mengukur seberapa baik model\n    bekerja dalam praktik nyata.\n\n## Penerapan Model Validation\n\n1.  Membuat Model Regresi\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata('CigarettesB')\nmodel = lm(packs ~ price + income, data = CigarettesB)\nsummary(model)\n```\n:::\n\n\n\n2.  Evaluasi Plot Diagnostik\n    -   Pada gambar ketiga yang menganalisis pola heteroskedastisitas\n        pada model menunjukkan bahwa meskipun titik-titik tidak\n        sepenuhnya mengikuti garis horizontal dengan distribusi yang\n        merata, plot ini menunjukkan adanya potensi heteroskedastisitas\n        dalam model.\n\n    -   Plot keempat yang merupakan plot Cook's distance digunakan untuk\n        mengidentifikasi pengamatan (observasi) yang memiliki pengaruh\n        besar terhadap model regresi. Pengamatan dengan nilai Cook's\n        Distance yang tinggi menunjukkan bahwa mereka memiliki dampak\n        signifikan terhadap koefisien regresi dan mungkin menjadi\n        outlier atau pengamatan berpengaruh. Pengamatan UT memiliki\n        Cook's Distance tertinggi, menunjukkan bahwa ini adalah\n        pengamatan paling berpengaruh dalam model. AR dan KY juga\n        menunjukkan nilai yang cukup tinggi, yang berarti mereka juga\n        mempengaruhi hasil regresi.\n\n    -   Plot Residuals vs Leverage digunakan untuk mengidentifikasi\n        pengamatan yang memiliki leverage tinggi (pengaruh besar pada\n        model) dan residual yang besar (outliers). Garis melengkung\n        (Cook's Distance) membantu menilai seberapa besar pengaruh\n        pengamatan terhadap model. Pengamatan KY perlu diperiksa lebih\n        lanjut untuk menentukan apakah ada alasan sah untuk pengaruhnya\n        yang besar. Jika pengaruh ini tidak dapat dijustifikasi, dapat\n        dipertimbangkan untuk memodifikasi model atau menghapus\n        pengamatan tersebut. Pengamatan lainnya seperti AR dan UT perlu\n        dipertimbangkan, tetapi perhatian utama harus diberikan pada\n        pengamatan dengan leverage tinggi seperti KY.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(model, which = 1:6)\n```\n:::\n\n\n\n3.  Deteksi Observasi Berpengaruh (Leverage dan Cook's Distance)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_hat = hatvalues(model)\nplot(model_hat)\nabline(h = c(1, 2, 3) * mean(model_hat), col = 2)\nid = which(model_hat > (2 * mean(model_hat)))\ntext(id, model_hat[id], rownames(CigarettesB)[id], pos = 1, xpd = TRUE)\n```\n:::\n\n\n\n4.  Analisis Influence Measures\n    -   dfb.1\\_, dfb.pric, dfb.incm disebut dengan DFBETAS, yang\n        mengukur pengaruh pengamatan individu pada koefisien regresi.\n        Menunjukkan seberapa besar koefisien regresi akan berubah jika\n        pengamatan tersebut dihapus.\n\n    -   dffit disebut DFITS, yaitu ukuran seberapa besar pengaruh\n        pengamatan terhadap prediksi model. Nilai dffit yang besar\n        (lebih dari +-2\\*sqrt(p/n). =\\> Pengamatan KY dan UT memiliki\n        nilai dffit yang signifikan (ditandai dengan \\*\\_)\n        mengindikasikan bahwa mereka mempengaruhi prediksi model secara\n        substansial.\n\n    -   cov.r merupakan rasio covariance yang mengukur stabilitas\n        covariance dari parameter model ketika pengamatan dihapus. Nilai\n        cov.r yang jauh dari 1 menunjukkan adanya pengaruh besar dari\n        pengamatan tersebut =\\> UT memiliki nilai cov.r yang lebih\n        rendah dari 1 (0.68\\_\\*) yang mengindikasikan bahwa pengamatan\n        ini mempengaruhi stabilitas model secara signifikan.\n\n    -   cook.d merupakan Cook's Distance yang merupakan ukuran\n        keseluruhan pengaruh pengamatan pada model regresi. KY dan UT\n        memiliki nilai cook.d cukup tinggi (0.21 dan 0.22) menunjukkan\n        bahwa mereka memiliki pengaruh signifikan terhadap hasil model.\n\n    -   hat (leverage) mengukur seberapa jauh pengamatan tertentu dari\n        nilai rata-rata variabel prediktor. KY memiliki leverage tinggi\n        (0.20\\_\\*) yang berarti pengamatan ini jauh dari nilai rata-rata\n        variabel independen dan dapat mempengaruhi hasil model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(influence.measures(model))\n```\n:::\n\n\n\n5.  Mengidentifikasi dan Menghapus Observasi Berpengaruh\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidx = which(apply(influence.measures(model)$is.inf, 1, any))\nCigarettesB[idx, ]  # Menampilkan observasi berpengaruh\nCigarettesB_noinf = CigarettesB[-idx, ]  # Dataset tanpa observasi berpengaruh\n```\n:::\n\n\n\n6.  Membuat Model Baru Tanpa Observasi Berpengaruh\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_noinf = lm(packs ~ price + income, data = CigarettesB_noinf)\nsummary(model_noinf)\nplot(model_noinf, which = 1:6)\nsummary(influence.measures(model_noinf))\n```\n:::\n\n\n\n7.  Cross-Validation\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nn <- nrow(CigarettesB)\nk <- 5  # Jumlah fold\nfolds <- sample(rep(1:k, length.out = n))\n\nerrors <- numeric(k)\n\nfor (i in 1:k) {\n  train_data <- CigarettesB[folds != i, ]\n  test_data <- CigarettesB[folds == i, ]\n  \n  model_cv <- lm(packs ~ price + income, data = train_data)\n  predictions <- predict(model_cv, newdata = test_data)\n  \n  # Hitung Mean Squared Error (MSE) pada data uji\n  errors[i] <- mean((test_data$packs - predictions)^2)\n}\n\nmean_cv_error <- mean(errors)\nprint(mean_cv_error)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}