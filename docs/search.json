[
  {
    "objectID": "semuahalaman/praktikum.html",
    "href": "semuahalaman/praktikum.html",
    "title": "Praktikum",
    "section": "",
    "text": "Eksplorasi/EDA dan Visualisasi Data (Kurikulum 2020)\nKalkulus 2 & Aljabar Linier 1 (Kurikulum 2020)\nMetode Numerik (Kurikulum 2020)\nPersamaan Diferensial Numerik (Kurikulum 2020)\nSains Data (Kurikulum 2020)"
  },
  {
    "objectID": "semuahalaman/praktikum.html#semester-genap-februari-juni",
    "href": "semuahalaman/praktikum.html#semester-genap-februari-juni",
    "title": "Praktikum",
    "section": "",
    "text": "Eksplorasi/EDA dan Visualisasi Data (Kurikulum 2020)\nKalkulus 2 & Aljabar Linier 1 (Kurikulum 2020)\nMetode Numerik (Kurikulum 2020)\nPersamaan Diferensial Numerik (Kurikulum 2020)\nSains Data (Kurikulum 2020)"
  },
  {
    "objectID": "semuahalaman/praktikum.html#semester-ganjil-september-desember",
    "href": "semuahalaman/praktikum.html#semester-ganjil-september-desember",
    "title": "Praktikum",
    "section": "Semester Ganjil (September-Desember)",
    "text": "Semester Ganjil (September-Desember)\n\nStruktur Data, dengan Python (Kurikulum 2020)"
  },
  {
    "objectID": "semuahalaman/praktikum.html#semester-genap-februari-juni-1",
    "href": "semuahalaman/praktikum.html#semester-genap-februari-juni-1",
    "title": "Praktikum",
    "section": "Semester Genap (Februari-Juni)",
    "text": "Semester Genap (Februari-Juni)\n\nEksplorasi/EDA dan Visualisasi Data (Kurikulum 2020)\nMetode Numerik (Kurikulum 2020)\nPersamaan Diferensial Numerik (Kurikulum 2020)\nSains Data (Kurikulum 2020)"
  },
  {
    "objectID": "semuahalaman/praktikum.html#semester-ganjil-september-desember-1",
    "href": "semuahalaman/praktikum.html#semester-ganjil-september-desember-1",
    "title": "Praktikum",
    "section": "Semester Ganjil (September-Desember)",
    "text": "Semester Ganjil (September-Desember)\n\nStruktur Data (Kurikulum 2020) (modul belum tersedia)"
  },
  {
    "objectID": "semuahalaman/praktikum.html#semester-genap-februari-juni-2",
    "href": "semuahalaman/praktikum.html#semester-genap-februari-juni-2",
    "title": "Praktikum",
    "section": "Semester Genap (Februari-Juni)",
    "text": "Semester Genap (Februari-Juni)\n\nSains Data (Kurikulum 2020)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul8.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul8.html",
    "title": "Modul 8 Praktikum Sains Data: Deep Learning dengan Keras, Regresi dan Klasifikasi Gambar",
    "section": "",
    "text": "Kembali ke Sains Data\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\n\n\n\nDi pertemuan sebelumnya, kita telah menyusun perceptron menggunakan Sequential API seperti berikut (ada dua cara yang ekuivalen):\n\n# langsung menentukan semua layer di awal, dengan memasukkan list\nmodel0 = keras.Sequential(\n    [\n        keras.layers.InputLayer(input_shape = (2,)),\n        keras.layers.Dense(units = 1, activation = keras.activations.sigmoid)\n    ]\n)\n\n\n# menambahkan layer secara berangsur-angsur\nmodel0 = keras.Sequential()\nmodel0.add(keras.layers.InputLayer(input_shape = (2,)))\nmodel0.add(keras.layers.Dense(units = 1, activation = keras.activations.sigmoid))\n\nSequential API sebenarnya cukup terbatas: tiap layer harus berurutan satu sama lain, dan hubungan yang ada hanyalah antar pasangan dua layer yang bersebelahan.\nUntuk model-model yang kita pelajari di mata kuliah Sains Data, sebenarnya Sequential API sudah cukup. Namun, kalau kalian pelajari lebih lanjut tentang neural network / deep learning, kalian akan bertemu dengan arsitektur aneh yang tidak bisa langsung disusun dengan Sequential API.\nContohnya, ada yang namanya skip connection, yaitu suatu layer terhubung dengan layer lain yang agak jauh darinya:\n\nSumber gambar: Aggarwal (2018) hal. 348\n(Skip connection akan kalian temui kalau mempelajari residual network, yaitu arsitektur ResNet dan variasinya, yang sudah sangat di luar cakupan materi mata kuliah Sains Data.)\nUntuk itu, diperlukan API selain Sequential, yaitu bisa dengan Functional API atau dengan Subclassing API. Agar kalian lebih mengenal Keras, kita akan mencoba membuat perceptron menggunakan dua API lainnya tersebut.\nKita bisa uji coba dengan dataset yang sama seperti di pertemuan sebelumnya: titik_negatif_positif.csv\n\ndf = pd.read_csv(\"./titik_negatif_positif.csv\", dtype=\"float32\")\n\n\ninputs_df = df.drop(columns=[\"kelas\"])\ntargets_df = df[[\"kelas\"]]\n\n\ninputs_arr = inputs_df.to_numpy()\ntargets_arr = targets_df.to_numpy()\n\n\n\nIde dari Functional API adalah menyusun tiap layer dan hubungan antar layer sebagai komposisi fungsi.\nUntuk Functional API, daripada keras.layers.InputLayer, gunakan keras.layers.Input\n\nm1_input = keras.layers.Input(shape = (2,))\n\nm1_layer1_func = keras.layers.Dense(units = 1, activation = keras.activations.sigmoid)\nm1_layer1_out = m1_layer1_func(m1_input) # seperti komposisi fungsi\n\nmodel1 = keras.Model(inputs=m1_input, outputs=m1_layer1_out, name=\"model1\")\n\n\nmodel1.summary()\n\nModel: \"model1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_3 (InputLayer)        [(None, 2)]               0         \n                                                                 \n dense_2 (Dense)             (None, 1)                 3         \n                                                                 \n=================================================================\nTotal params: 3\nTrainable params: 3\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nkeras.utils.plot_model(\n    model1,\n    show_shapes = True,\n    show_layer_activations = True,\n    to_file = \"keras_functional_model1.png\"\n)\n\n\nSisanya (compile lalu fit) sama dengan Sequential API\n\nmodel1.compile(\n    optimizer = keras.optimizers.SGD(learning_rate = 0.01),\n    loss = keras.losses.BinaryCrossentropy(),\n    metrics = [keras.metrics.BinaryAccuracy()]\n)\n\n\nhistory1 = model1.fit(inputs_arr, targets_arr, epochs=100, validation_split=0.2)\n\nEpoch 1/100\n50/50 [==============================] - 4s 31ms/step - loss: 1.2000 - binary_accuracy: 0.6144 - val_loss: 2.1506 - val_binary_accuracy: 0.0775\nEpoch 2/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.6425 - binary_accuracy: 0.6837 - val_loss: 1.0554 - val_binary_accuracy: 0.3575\nEpoch 3/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.3413 - binary_accuracy: 0.8344 - val_loss: 0.5549 - val_binary_accuracy: 0.7150\nEpoch 4/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.2141 - binary_accuracy: 0.9406 - val_loss: 0.3460 - val_binary_accuracy: 0.8975\nEpoch 5/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.1576 - binary_accuracy: 0.9800 - val_loss: 0.2475 - val_binary_accuracy: 0.9550\nEpoch 6/100\n50/50 [==============================] - 1s 10ms/step - loss: 0.1277 - binary_accuracy: 0.9900 - val_loss: 0.1938 - val_binary_accuracy: 0.9675\nEpoch 7/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.1092 - binary_accuracy: 0.9912 - val_loss: 0.1604 - val_binary_accuracy: 0.9775\nEpoch 8/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0964 - binary_accuracy: 0.9931 - val_loss: 0.1381 - val_binary_accuracy: 0.9850\nEpoch 9/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0870 - binary_accuracy: 0.9944 - val_loss: 0.1221 - val_binary_accuracy: 0.9850\nEpoch 10/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0796 - binary_accuracy: 0.9950 - val_loss: 0.1101 - val_binary_accuracy: 0.9900\nEpoch 11/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0737 - binary_accuracy: 0.9950 - val_loss: 0.1007 - val_binary_accuracy: 0.9900\nEpoch 12/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0688 - binary_accuracy: 0.9969 - val_loss: 0.0932 - val_binary_accuracy: 0.9900\nEpoch 13/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0647 - binary_accuracy: 0.9969 - val_loss: 0.0870 - val_binary_accuracy: 0.9900\nEpoch 14/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0611 - binary_accuracy: 0.9975 - val_loss: 0.0818 - val_binary_accuracy: 0.9900\nEpoch 15/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0581 - binary_accuracy: 0.9975 - val_loss: 0.0774 - val_binary_accuracy: 0.9900\nEpoch 16/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0554 - binary_accuracy: 0.9975 - val_loss: 0.0736 - val_binary_accuracy: 0.9900\nEpoch 17/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0530 - binary_accuracy: 0.9975 - val_loss: 0.0703 - val_binary_accuracy: 0.9925\nEpoch 18/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0508 - binary_accuracy: 0.9975 - val_loss: 0.0674 - val_binary_accuracy: 0.9925\nEpoch 19/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0489 - binary_accuracy: 0.9969 - val_loss: 0.0649 - val_binary_accuracy: 0.9925\nEpoch 20/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0472 - binary_accuracy: 0.9969 - val_loss: 0.0626 - val_binary_accuracy: 0.9925\nEpoch 21/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0456 - binary_accuracy: 0.9969 - val_loss: 0.0605 - val_binary_accuracy: 0.9925\nEpoch 22/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0441 - binary_accuracy: 0.9969 - val_loss: 0.0586 - val_binary_accuracy: 0.9950\nEpoch 23/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0428 - binary_accuracy: 0.9969 - val_loss: 0.0569 - val_binary_accuracy: 0.9950\nEpoch 24/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0416 - binary_accuracy: 0.9969 - val_loss: 0.0553 - val_binary_accuracy: 0.9950\nEpoch 25/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0404 - binary_accuracy: 0.9969 - val_loss: 0.0538 - val_binary_accuracy: 0.9950\nEpoch 26/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0394 - binary_accuracy: 0.9969 - val_loss: 0.0525 - val_binary_accuracy: 0.9950\nEpoch 27/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0384 - binary_accuracy: 0.9969 - val_loss: 0.0512 - val_binary_accuracy: 0.9950\nEpoch 28/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0375 - binary_accuracy: 0.9969 - val_loss: 0.0501 - val_binary_accuracy: 0.9950\nEpoch 29/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0366 - binary_accuracy: 0.9969 - val_loss: 0.0490 - val_binary_accuracy: 0.9950\nEpoch 30/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0358 - binary_accuracy: 0.9969 - val_loss: 0.0480 - val_binary_accuracy: 0.9950\nEpoch 31/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0351 - binary_accuracy: 0.9969 - val_loss: 0.0470 - val_binary_accuracy: 0.9950\nEpoch 32/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0344 - binary_accuracy: 0.9975 - val_loss: 0.0461 - val_binary_accuracy: 0.9950\nEpoch 33/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0337 - binary_accuracy: 0.9975 - val_loss: 0.0453 - val_binary_accuracy: 0.9950\nEpoch 34/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0331 - binary_accuracy: 0.9975 - val_loss: 0.0445 - val_binary_accuracy: 0.9950\nEpoch 35/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0325 - binary_accuracy: 0.9975 - val_loss: 0.0437 - val_binary_accuracy: 0.9950\nEpoch 36/100\n50/50 [==============================] - 0s 10ms/step - loss: 0.0319 - binary_accuracy: 0.9975 - val_loss: 0.0430 - val_binary_accuracy: 0.9950\nEpoch 37/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0314 - binary_accuracy: 0.9975 - val_loss: 0.0424 - val_binary_accuracy: 0.9950\nEpoch 38/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0308 - binary_accuracy: 0.9975 - val_loss: 0.0417 - val_binary_accuracy: 0.9950\nEpoch 39/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0303 - binary_accuracy: 0.9975 - val_loss: 0.0411 - val_binary_accuracy: 0.9950\nEpoch 40/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0299 - binary_accuracy: 0.9975 - val_loss: 0.0405 - val_binary_accuracy: 0.9975\nEpoch 41/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0294 - binary_accuracy: 0.9975 - val_loss: 0.0400 - val_binary_accuracy: 0.9975\nEpoch 42/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0290 - binary_accuracy: 0.9975 - val_loss: 0.0394 - val_binary_accuracy: 0.9975\nEpoch 43/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0286 - binary_accuracy: 0.9975 - val_loss: 0.0389 - val_binary_accuracy: 0.9975\nEpoch 44/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0282 - binary_accuracy: 0.9975 - val_loss: 0.0384 - val_binary_accuracy: 0.9975\nEpoch 45/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0278 - binary_accuracy: 0.9975 - val_loss: 0.0380 - val_binary_accuracy: 0.9975\nEpoch 46/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0275 - binary_accuracy: 0.9975 - val_loss: 0.0375 - val_binary_accuracy: 0.9975\nEpoch 47/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0271 - binary_accuracy: 0.9975 - val_loss: 0.0371 - val_binary_accuracy: 0.9975\nEpoch 48/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0268 - binary_accuracy: 0.9975 - val_loss: 0.0367 - val_binary_accuracy: 0.9975\nEpoch 49/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0265 - binary_accuracy: 0.9975 - val_loss: 0.0363 - val_binary_accuracy: 0.9975\nEpoch 50/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0262 - binary_accuracy: 0.9975 - val_loss: 0.0359 - val_binary_accuracy: 0.9975\nEpoch 51/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0259 - binary_accuracy: 0.9975 - val_loss: 0.0355 - val_binary_accuracy: 0.9975\nEpoch 52/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0256 - binary_accuracy: 0.9975 - val_loss: 0.0351 - val_binary_accuracy: 0.9975\nEpoch 53/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0253 - binary_accuracy: 0.9975 - val_loss: 0.0348 - val_binary_accuracy: 0.9975\nEpoch 54/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0250 - binary_accuracy: 0.9975 - val_loss: 0.0345 - val_binary_accuracy: 0.9975\nEpoch 55/100\n50/50 [==============================] - 1s 12ms/step - loss: 0.0248 - binary_accuracy: 0.9975 - val_loss: 0.0341 - val_binary_accuracy: 0.9975\nEpoch 56/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0245 - binary_accuracy: 0.9975 - val_loss: 0.0338 - val_binary_accuracy: 0.9975\nEpoch 57/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0243 - binary_accuracy: 0.9975 - val_loss: 0.0335 - val_binary_accuracy: 0.9975\nEpoch 58/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0240 - binary_accuracy: 0.9975 - val_loss: 0.0332 - val_binary_accuracy: 0.9975\nEpoch 59/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0238 - binary_accuracy: 0.9975 - val_loss: 0.0329 - val_binary_accuracy: 0.9975\nEpoch 60/100\n50/50 [==============================] - 1s 12ms/step - loss: 0.0236 - binary_accuracy: 0.9975 - val_loss: 0.0327 - val_binary_accuracy: 0.9975\nEpoch 61/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0234 - binary_accuracy: 0.9975 - val_loss: 0.0324 - val_binary_accuracy: 0.9975\nEpoch 62/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0232 - binary_accuracy: 0.9975 - val_loss: 0.0321 - val_binary_accuracy: 0.9975\nEpoch 63/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0230 - binary_accuracy: 0.9975 - val_loss: 0.0319 - val_binary_accuracy: 0.9975\nEpoch 64/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0228 - binary_accuracy: 0.9975 - val_loss: 0.0316 - val_binary_accuracy: 0.9975\nEpoch 65/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0226 - binary_accuracy: 0.9975 - val_loss: 0.0314 - val_binary_accuracy: 0.9975\nEpoch 66/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0224 - binary_accuracy: 0.9975 - val_loss: 0.0312 - val_binary_accuracy: 0.9975\nEpoch 67/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0222 - binary_accuracy: 0.9975 - val_loss: 0.0309 - val_binary_accuracy: 0.9975\nEpoch 68/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0220 - binary_accuracy: 0.9975 - val_loss: 0.0307 - val_binary_accuracy: 0.9975\nEpoch 69/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0219 - binary_accuracy: 0.9975 - val_loss: 0.0305 - val_binary_accuracy: 0.9975\nEpoch 70/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0217 - binary_accuracy: 0.9975 - val_loss: 0.0303 - val_binary_accuracy: 0.9975\nEpoch 71/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0215 - binary_accuracy: 0.9975 - val_loss: 0.0301 - val_binary_accuracy: 0.9975\nEpoch 72/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0214 - binary_accuracy: 0.9975 - val_loss: 0.0299 - val_binary_accuracy: 0.9975\nEpoch 73/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0212 - binary_accuracy: 0.9975 - val_loss: 0.0297 - val_binary_accuracy: 0.9975\nEpoch 74/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0211 - binary_accuracy: 0.9975 - val_loss: 0.0295 - val_binary_accuracy: 0.9975\nEpoch 75/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0209 - binary_accuracy: 0.9975 - val_loss: 0.0293 - val_binary_accuracy: 0.9975\nEpoch 76/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0208 - binary_accuracy: 0.9975 - val_loss: 0.0291 - val_binary_accuracy: 0.9975\nEpoch 77/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0206 - binary_accuracy: 0.9975 - val_loss: 0.0289 - val_binary_accuracy: 0.9975\nEpoch 78/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0205 - binary_accuracy: 0.9975 - val_loss: 0.0287 - val_binary_accuracy: 0.9975\nEpoch 79/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0204 - binary_accuracy: 0.9975 - val_loss: 0.0286 - val_binary_accuracy: 0.9975\nEpoch 80/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0202 - binary_accuracy: 0.9975 - val_loss: 0.0284 - val_binary_accuracy: 0.9975\nEpoch 81/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0201 - binary_accuracy: 0.9975 - val_loss: 0.0282 - val_binary_accuracy: 0.9975\nEpoch 82/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0200 - binary_accuracy: 0.9975 - val_loss: 0.0281 - val_binary_accuracy: 0.9975\nEpoch 83/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0199 - binary_accuracy: 0.9975 - val_loss: 0.0279 - val_binary_accuracy: 0.9975\nEpoch 84/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0197 - binary_accuracy: 0.9975 - val_loss: 0.0278 - val_binary_accuracy: 0.9975\nEpoch 85/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0196 - binary_accuracy: 0.9975 - val_loss: 0.0276 - val_binary_accuracy: 0.9975\nEpoch 86/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0195 - binary_accuracy: 0.9975 - val_loss: 0.0275 - val_binary_accuracy: 0.9975\nEpoch 87/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0194 - binary_accuracy: 0.9975 - val_loss: 0.0273 - val_binary_accuracy: 0.9975\nEpoch 88/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0193 - binary_accuracy: 0.9975 - val_loss: 0.0272 - val_binary_accuracy: 0.9975\nEpoch 89/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0192 - binary_accuracy: 0.9975 - val_loss: 0.0270 - val_binary_accuracy: 0.9975\nEpoch 90/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0191 - binary_accuracy: 0.9975 - val_loss: 0.0269 - val_binary_accuracy: 0.9975\nEpoch 91/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0190 - binary_accuracy: 0.9975 - val_loss: 0.0268 - val_binary_accuracy: 0.9975\nEpoch 92/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0189 - binary_accuracy: 0.9975 - val_loss: 0.0267 - val_binary_accuracy: 0.9975\nEpoch 93/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0188 - binary_accuracy: 0.9975 - val_loss: 0.0265 - val_binary_accuracy: 0.9975\nEpoch 94/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0187 - binary_accuracy: 0.9975 - val_loss: 0.0264 - val_binary_accuracy: 0.9975\nEpoch 95/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0186 - binary_accuracy: 0.9975 - val_loss: 0.0263 - val_binary_accuracy: 0.9975\nEpoch 96/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0185 - binary_accuracy: 0.9975 - val_loss: 0.0262 - val_binary_accuracy: 0.9975\nEpoch 97/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0184 - binary_accuracy: 0.9975 - val_loss: 0.0260 - val_binary_accuracy: 0.9975\nEpoch 98/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0183 - binary_accuracy: 0.9975 - val_loss: 0.0259 - val_binary_accuracy: 0.9975\nEpoch 99/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0182 - binary_accuracy: 0.9975 - val_loss: 0.0258 - val_binary_accuracy: 0.9975\nEpoch 100/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0181 - binary_accuracy: 0.9975 - val_loss: 0.0257 - val_binary_accuracy: 0.9975\n\n\nKita bisa ubah dictionary .history menjadi CSV:\n\npd.DataFrame(history1.history).to_csv(\"./keras_functional_history1.csv\", index=False)\n\nSilakan download kalau mau menyocokkan/membandingkan dengan modul: keras_functional_history1.csv\nImport kembali:\n\nhistory1_df = pd.read_csv(\"./keras_functional_history1.csv\")\n\nLalu plot loss:\n\nplt.plot(history1_df[\"loss\"], label = \"training loss\")\nplt.plot(history1_df[\"val_loss\"], label = \"validation loss\")\nplt.xlabel(\"epoch\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nUntuk model yang lebih kompleks, mungkin komposisi fungsi akan membuat pusing, karena banyak fungsi bertebaran di mana-mana. Agar lebih rapi dan terstruktur, kita bisa gunakan Subclassing API, yaitu dengan OOP / object oriented programming.\nSilakan review Modul 2 Praktikum Struktur Data tentang Pengantar OOP kalau perlu ;)\nDalam Subclassing API, model yang kita buat berupa class yang meng-inherit (atau disebut subclassing) dari keras.Model yang sudah mengimplementasikan sebagian besar method yang kita butuhkan.\n(Bahkan, kita juga bisa buat class yang hanya berupa kumpulan layer, yang nantinya akan masuk lagi ke class lain. Kalian bisa pelajari lebih lanjut: https://keras.io/guides/making_new_layers_and_models_via_subclassing/)\nDalam model yang kita susun, hanya diperlukan:\n\nconstructor __init__ berisi minimal satu baris, yaitu super().__init__() dan boleh berisi baris lainnya untuk menyiapkan atribut (variabel) yang langsung bisa dibuat ketika model dibuat (sebelum mulai training)\nmethod call yang mendefinisikan bagaimana forward pass\n(opsional) method build yang menyiapkan atribut yang bisa dibuat di awal training setelah ukuran input diketahui\n\n\nclass MyPerceptron(keras.Model):\n    def __init__(self, units=1):\n        super().__init__()\n\n        # banyaknya neuron di output layer\n        self.units = units\n\n    # menyiapkan parameter (weights and biases) tergantung ukuran input\n    def build(self, input_shape):\n        input_dim = input_shape[-1]\n\n        # matriks W terkadang disebut kernel\n        self.kernel = self.add_weight(\n            shape = (input_dim, self.units),\n            initializer = keras.initializers.RandomNormal(mean=0, stddev=0.05),\n            trainable = True,\n        )\n        self.bias = self.add_weight(\n            shape = (self.units,),\n            initializer = keras.initializers.RandomNormal(),\n            trainable = True\n        )\n\n    # forward pass\n    def call(self, inputs):\n        return tf.sigmoid(\n            tf.matmul(inputs, self.kernel) + self.bias\n        )\n\nKita harus membuat instance atau objek dari class ini terlebih dahulu, lalu memanggil .build() dulu, agar kemudian bisa melakukan misalnya .fit()\n\nmodel2 = MyPerceptron()\n\n\nmodel2.build(input_shape = (2,))\n\nSekarang kita bisa compile, fit, simpan history, dan plot loss seperti biasa…\n\nmodel2.compile(\n    optimizer = keras.optimizers.SGD(learning_rate = 0.01),\n    loss = keras.losses.BinaryCrossentropy(),\n    metrics = [keras.metrics.BinaryAccuracy()]\n)\n\n\nhistory2 = model2.fit(inputs_arr, targets_arr, epochs=100, validation_split=0.2)\n\nEpoch 1/100\n50/50 [==============================] - 2s 8ms/step - loss: 0.5171 - binary_accuracy: 0.9000 - val_loss: 0.4495 - val_binary_accuracy: 0.9725\nEpoch 2/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.2978 - binary_accuracy: 0.9944 - val_loss: 0.3160 - val_binary_accuracy: 0.9800\nEpoch 3/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.2108 - binary_accuracy: 0.9950 - val_loss: 0.2446 - val_binary_accuracy: 0.9850\nEpoch 4/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.1650 - binary_accuracy: 0.9950 - val_loss: 0.2012 - val_binary_accuracy: 0.9900\nEpoch 5/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.1368 - binary_accuracy: 0.9956 - val_loss: 0.1720 - val_binary_accuracy: 0.9900\nEpoch 6/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.1176 - binary_accuracy: 0.9962 - val_loss: 0.1510 - val_binary_accuracy: 0.9900\nEpoch 7/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.1037 - binary_accuracy: 0.9962 - val_loss: 0.1352 - val_binary_accuracy: 0.9900\nEpoch 8/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0932 - binary_accuracy: 0.9969 - val_loss: 0.1230 - val_binary_accuracy: 0.9900\nEpoch 9/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0849 - binary_accuracy: 0.9969 - val_loss: 0.1131 - val_binary_accuracy: 0.9900\nEpoch 10/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0782 - binary_accuracy: 0.9969 - val_loss: 0.1050 - val_binary_accuracy: 0.9925\nEpoch 11/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0726 - binary_accuracy: 0.9962 - val_loss: 0.0983 - val_binary_accuracy: 0.9925\nEpoch 12/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0680 - binary_accuracy: 0.9962 - val_loss: 0.0926 - val_binary_accuracy: 0.9925\nEpoch 13/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0640 - binary_accuracy: 0.9962 - val_loss: 0.0876 - val_binary_accuracy: 0.9925\nEpoch 14/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0605 - binary_accuracy: 0.9962 - val_loss: 0.0833 - val_binary_accuracy: 0.9925\nEpoch 15/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0575 - binary_accuracy: 0.9962 - val_loss: 0.0796 - val_binary_accuracy: 0.9925\nEpoch 16/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0549 - binary_accuracy: 0.9962 - val_loss: 0.0762 - val_binary_accuracy: 0.9925\nEpoch 17/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0525 - binary_accuracy: 0.9962 - val_loss: 0.0732 - val_binary_accuracy: 0.9925\nEpoch 18/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0504 - binary_accuracy: 0.9969 - val_loss: 0.0705 - val_binary_accuracy: 0.9925\nEpoch 19/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0485 - binary_accuracy: 0.9969 - val_loss: 0.0681 - val_binary_accuracy: 0.9925\nEpoch 20/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0468 - binary_accuracy: 0.9969 - val_loss: 0.0658 - val_binary_accuracy: 0.9925\nEpoch 21/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0452 - binary_accuracy: 0.9969 - val_loss: 0.0638 - val_binary_accuracy: 0.9925\nEpoch 22/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0438 - binary_accuracy: 0.9969 - val_loss: 0.0620 - val_binary_accuracy: 0.9925\nEpoch 23/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0425 - binary_accuracy: 0.9969 - val_loss: 0.0603 - val_binary_accuracy: 0.9925\nEpoch 24/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0413 - binary_accuracy: 0.9969 - val_loss: 0.0587 - val_binary_accuracy: 0.9925\nEpoch 25/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0401 - binary_accuracy: 0.9969 - val_loss: 0.0572 - val_binary_accuracy: 0.9925\nEpoch 26/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0391 - binary_accuracy: 0.9969 - val_loss: 0.0559 - val_binary_accuracy: 0.9925\nEpoch 27/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0381 - binary_accuracy: 0.9969 - val_loss: 0.0546 - val_binary_accuracy: 0.9925\nEpoch 28/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0372 - binary_accuracy: 0.9969 - val_loss: 0.0534 - val_binary_accuracy: 0.9925\nEpoch 29/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0364 - binary_accuracy: 0.9969 - val_loss: 0.0523 - val_binary_accuracy: 0.9925\nEpoch 30/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0356 - binary_accuracy: 0.9969 - val_loss: 0.0512 - val_binary_accuracy: 0.9925\nEpoch 31/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0348 - binary_accuracy: 0.9969 - val_loss: 0.0503 - val_binary_accuracy: 0.9925\nEpoch 32/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0341 - binary_accuracy: 0.9969 - val_loss: 0.0493 - val_binary_accuracy: 0.9925\nEpoch 33/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0334 - binary_accuracy: 0.9969 - val_loss: 0.0484 - val_binary_accuracy: 0.9925\nEpoch 34/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0328 - binary_accuracy: 0.9969 - val_loss: 0.0476 - val_binary_accuracy: 0.9925\nEpoch 35/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0322 - binary_accuracy: 0.9969 - val_loss: 0.0468 - val_binary_accuracy: 0.9925\nEpoch 36/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0317 - binary_accuracy: 0.9975 - val_loss: 0.0460 - val_binary_accuracy: 0.9925\nEpoch 37/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0311 - binary_accuracy: 0.9975 - val_loss: 0.0453 - val_binary_accuracy: 0.9925\nEpoch 38/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0306 - binary_accuracy: 0.9975 - val_loss: 0.0446 - val_binary_accuracy: 0.9925\nEpoch 39/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0301 - binary_accuracy: 0.9975 - val_loss: 0.0440 - val_binary_accuracy: 0.9925\nEpoch 40/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0296 - binary_accuracy: 0.9975 - val_loss: 0.0433 - val_binary_accuracy: 0.9925\nEpoch 41/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0292 - binary_accuracy: 0.9975 - val_loss: 0.0427 - val_binary_accuracy: 0.9925\nEpoch 42/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0288 - binary_accuracy: 0.9975 - val_loss: 0.0422 - val_binary_accuracy: 0.9925\nEpoch 43/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0284 - binary_accuracy: 0.9975 - val_loss: 0.0416 - val_binary_accuracy: 0.9925\nEpoch 44/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0280 - binary_accuracy: 0.9975 - val_loss: 0.0411 - val_binary_accuracy: 0.9925\nEpoch 45/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0276 - binary_accuracy: 0.9975 - val_loss: 0.0406 - val_binary_accuracy: 0.9925\nEpoch 46/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0272 - binary_accuracy: 0.9975 - val_loss: 0.0401 - val_binary_accuracy: 0.9925\nEpoch 47/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0269 - binary_accuracy: 0.9975 - val_loss: 0.0396 - val_binary_accuracy: 0.9925\nEpoch 48/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0266 - binary_accuracy: 0.9975 - val_loss: 0.0392 - val_binary_accuracy: 0.9925\nEpoch 49/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0262 - binary_accuracy: 0.9975 - val_loss: 0.0388 - val_binary_accuracy: 0.9925\nEpoch 50/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0259 - binary_accuracy: 0.9975 - val_loss: 0.0383 - val_binary_accuracy: 0.9925\nEpoch 51/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0256 - binary_accuracy: 0.9975 - val_loss: 0.0379 - val_binary_accuracy: 0.9925\nEpoch 52/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0254 - binary_accuracy: 0.9975 - val_loss: 0.0375 - val_binary_accuracy: 0.9925\nEpoch 53/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0251 - binary_accuracy: 0.9975 - val_loss: 0.0372 - val_binary_accuracy: 0.9925\nEpoch 54/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0248 - binary_accuracy: 0.9975 - val_loss: 0.0368 - val_binary_accuracy: 0.9925\nEpoch 55/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0245 - binary_accuracy: 0.9975 - val_loss: 0.0364 - val_binary_accuracy: 0.9925\nEpoch 56/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0243 - binary_accuracy: 0.9975 - val_loss: 0.0361 - val_binary_accuracy: 0.9925\nEpoch 57/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0241 - binary_accuracy: 0.9975 - val_loss: 0.0358 - val_binary_accuracy: 0.9925\nEpoch 58/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0238 - binary_accuracy: 0.9975 - val_loss: 0.0354 - val_binary_accuracy: 0.9925\nEpoch 59/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0236 - binary_accuracy: 0.9975 - val_loss: 0.0351 - val_binary_accuracy: 0.9925\nEpoch 60/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0234 - binary_accuracy: 0.9975 - val_loss: 0.0348 - val_binary_accuracy: 0.9925\nEpoch 61/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0232 - binary_accuracy: 0.9975 - val_loss: 0.0345 - val_binary_accuracy: 0.9925\nEpoch 62/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0230 - binary_accuracy: 0.9975 - val_loss: 0.0342 - val_binary_accuracy: 0.9925\nEpoch 63/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0228 - binary_accuracy: 0.9975 - val_loss: 0.0340 - val_binary_accuracy: 0.9925\nEpoch 64/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0226 - binary_accuracy: 0.9975 - val_loss: 0.0337 - val_binary_accuracy: 0.9925\nEpoch 65/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0224 - binary_accuracy: 0.9975 - val_loss: 0.0334 - val_binary_accuracy: 0.9925\nEpoch 66/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0222 - binary_accuracy: 0.9975 - val_loss: 0.0332 - val_binary_accuracy: 0.9925\nEpoch 67/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0220 - binary_accuracy: 0.9975 - val_loss: 0.0329 - val_binary_accuracy: 0.9925\nEpoch 68/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0218 - binary_accuracy: 0.9975 - val_loss: 0.0327 - val_binary_accuracy: 0.9925\nEpoch 69/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0217 - binary_accuracy: 0.9975 - val_loss: 0.0325 - val_binary_accuracy: 0.9925\nEpoch 70/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0215 - binary_accuracy: 0.9975 - val_loss: 0.0322 - val_binary_accuracy: 0.9925\nEpoch 71/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0213 - binary_accuracy: 0.9975 - val_loss: 0.0320 - val_binary_accuracy: 0.9925\nEpoch 72/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0212 - binary_accuracy: 0.9975 - val_loss: 0.0318 - val_binary_accuracy: 0.9925\nEpoch 73/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0210 - binary_accuracy: 0.9975 - val_loss: 0.0316 - val_binary_accuracy: 0.9925\nEpoch 74/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0209 - binary_accuracy: 0.9975 - val_loss: 0.0314 - val_binary_accuracy: 0.9925\nEpoch 75/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0207 - binary_accuracy: 0.9975 - val_loss: 0.0312 - val_binary_accuracy: 0.9925\nEpoch 76/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0206 - binary_accuracy: 0.9975 - val_loss: 0.0310 - val_binary_accuracy: 0.9925\nEpoch 77/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0204 - binary_accuracy: 0.9975 - val_loss: 0.0308 - val_binary_accuracy: 0.9925\nEpoch 78/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0203 - binary_accuracy: 0.9975 - val_loss: 0.0306 - val_binary_accuracy: 0.9925\nEpoch 79/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0202 - binary_accuracy: 0.9975 - val_loss: 0.0304 - val_binary_accuracy: 0.9925\nEpoch 80/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0200 - binary_accuracy: 0.9975 - val_loss: 0.0302 - val_binary_accuracy: 0.9925\nEpoch 81/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0199 - binary_accuracy: 0.9975 - val_loss: 0.0300 - val_binary_accuracy: 0.9925\nEpoch 82/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0198 - binary_accuracy: 0.9975 - val_loss: 0.0298 - val_binary_accuracy: 0.9925\nEpoch 83/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0197 - binary_accuracy: 0.9975 - val_loss: 0.0297 - val_binary_accuracy: 0.9925\nEpoch 84/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0195 - binary_accuracy: 0.9975 - val_loss: 0.0295 - val_binary_accuracy: 0.9925\nEpoch 85/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0194 - binary_accuracy: 0.9975 - val_loss: 0.0293 - val_binary_accuracy: 0.9925\nEpoch 86/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0193 - binary_accuracy: 0.9975 - val_loss: 0.0292 - val_binary_accuracy: 0.9925\nEpoch 87/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0192 - binary_accuracy: 0.9975 - val_loss: 0.0290 - val_binary_accuracy: 0.9925\nEpoch 88/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0191 - binary_accuracy: 0.9975 - val_loss: 0.0289 - val_binary_accuracy: 0.9925\nEpoch 89/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0190 - binary_accuracy: 0.9975 - val_loss: 0.0287 - val_binary_accuracy: 0.9925\nEpoch 90/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0189 - binary_accuracy: 0.9975 - val_loss: 0.0286 - val_binary_accuracy: 0.9925\nEpoch 91/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0188 - binary_accuracy: 0.9975 - val_loss: 0.0284 - val_binary_accuracy: 0.9925\nEpoch 92/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0187 - binary_accuracy: 0.9975 - val_loss: 0.0283 - val_binary_accuracy: 0.9925\nEpoch 93/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0186 - binary_accuracy: 0.9975 - val_loss: 0.0281 - val_binary_accuracy: 0.9925\nEpoch 94/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0185 - binary_accuracy: 0.9975 - val_loss: 0.0280 - val_binary_accuracy: 0.9925\nEpoch 95/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0184 - binary_accuracy: 0.9975 - val_loss: 0.0279 - val_binary_accuracy: 0.9925\nEpoch 96/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0183 - binary_accuracy: 0.9975 - val_loss: 0.0277 - val_binary_accuracy: 0.9925\nEpoch 97/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0182 - binary_accuracy: 0.9975 - val_loss: 0.0276 - val_binary_accuracy: 0.9925\nEpoch 98/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0181 - binary_accuracy: 0.9975 - val_loss: 0.0275 - val_binary_accuracy: 0.9925\nEpoch 99/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0180 - binary_accuracy: 0.9975 - val_loss: 0.0273 - val_binary_accuracy: 0.9925\nEpoch 100/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0179 - binary_accuracy: 0.9975 - val_loss: 0.0272 - val_binary_accuracy: 0.9925\n\n\n\npd.DataFrame(history2.history).to_csv(\"./keras_subclassing_history2.csv\", index=False)\n\nSilakan download kalau mau menyocokkan/membandingkan dengan modul: keras_subclassing_history2.csv\n\nhistory2_df = pd.read_csv(\"./keras_subclassing_history2.csv\")\n\n\nplt.plot(history2_df[\"loss\"], label = \"training loss\")\nplt.plot(history2_df[\"val_loss\"], label = \"validation loss\")\nplt.xlabel(\"epoch\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nSebenarnya, kalian bisa saja menggunakan Functional API di dalam class: siapkan fungsi-fungsinya di dalam constructor __init__ dan gunakan di dalam call\n\nclass MyPerceptron_v2(keras.Model):\n    def __init__(self, units=1):\n        super().__init__()\n\n        # banyaknya neuron di output layer\n        self.units = units\n        \n        # siapkan fungsi\n        self.layer1_func = keras.layers.Dense(\n            units = self.units,\n            activation = keras.activations.sigmoid\n        )\n\n    # forward pass\n    def call(self, inputs):\n        x = self.layer1_func(inputs)\n        return x\n\n\n\n\n\nKita lihat lagi gambar skip connection:\n\nSumber gambar: Aggarwal (2018) hal. 348\nDari gambarnya, kita bisa coba susun neural network nya:\n\n# x\nf3_input = keras.layers.Input(shape = (5,))\n\n# weight layers\nf3_layer1_func = keras.layers.Dense(units = 10, activation = keras.activations.linear)\nf3_layer2_func = keras.layers.Dense(units = 5, activation = keras.activations.relu)\n\n# F(x)\nF_out = f3_layer2_func(f3_layer1_func(f3_input))\n\n# F(x) + x\nf3_layer3_out = F_out + f3_input\n\n# membuat model akhir\nmodel3 = keras.Model(inputs=f3_input, outputs=f3_layer3_out, name=\"model3\")\n\n\nmodel3.summary()\n\nModel: \"model3\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_7 (InputLayer)           [(None, 5)]          0           []                               \n                                                                                                  \n dense_9 (Dense)                (None, 10)           60          ['input_7[0][0]']                \n                                                                                                  \n dense_10 (Dense)               (None, 5)            55          ['dense_9[0][0]']                \n                                                                                                  \n tf.__operators__.add_3 (TFOpLa  (None, 5)           0           ['dense_10[0][0]',               \n mbda)                                                            'input_7[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 115\nTrainable params: 115\nNon-trainable params: 0\n__________________________________________________________________________________________________\n\n\n\nkeras.utils.plot_model(\n    model3,\n    show_shapes = True,\n    show_layer_activations = True,\n    to_file = \"keras_functional_model3.png\"\n)\n\n\nApabila kode Functional API itu disusun ke dalam class, kodenya bisa menjadi seperti berikut:\n\nclass MySkipConnection(keras.Model):\n    def __init__(self, units=5):\n        super().__init__()\n\n        # banyaknya neuron di output layer\n        self.units = units\n        \n        # siapkan fungsi-fungsi\n        self.weight1_func = keras.layers.Dense(\n            units = 10,\n            activation = keras.activations.linear\n        )\n        self.weight2_func = keras.layers.Dense(\n            units = self.units,\n            activation = keras.activations.relu\n        )\n\n    # forward pass\n    def call(self, inputs):\n        F_x = self.weight2_func(self.weight1_func(inputs))\n        x = inputs\n        hasil = F_x + x\n        return hasil\n\n\n\n\nIngat kembali, untuk regresi,\n\nbanyaknya neuron di input layer sesuai banyaknya fitur/variabel prediktor\nbanyaknya neuron di output layer sesuai banyaknya fitur/variabel target (biasanya hanya satu), dan fungsi aktivasi yang digunakan adalah fungsi aktivasi linier/identitas\nfungsi aktivasi untuk semua hidden layer biasanya ReLU\n\nKita akan coba lagi dataset “California Housing Prices” (housing.csv) yang sudah kita gunakan di Modul 4 tentang regresi, yang bisa didownload dari salah satu sumber berikut:\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle: https://www.kaggle.com/datasets/camnugent/california-housing-prices\n\nMari kita lihat isinya\n\nhousing_df = pd.read_csv(\"./housing.csv\")\n\n\nhousing_df\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\nocean_proximity\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\nNEAR BAY\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\nNEAR BAY\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\nNEAR BAY\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\nNEAR BAY\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\nNEAR BAY\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\nINLAND\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\nINLAND\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\nINLAND\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\nINLAND\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\nINLAND\n\n\n\n\n20640 rows × 10 columns\n\n\n\nKalau mau, kalian bisa melakukan encoding data kategorik ocean_proximity seperti di Modul 3. Tapi kali ini kita hapus/drop saja\n\nhousing_df = housing_df.drop(columns=[\"ocean_proximity\"])\n\n\nhousing_df\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n\n\n\n\n20640 rows × 9 columns\n\n\n\nIngat bahwa variabel target (variabel yang ingin kita prediksi) adalah median_house_value. Kita pisah dulu antara variabel prediktor (X atau inputs) dan variabel target (y atau target)\n\nhousing_X_df = housing_df.drop(columns=[\"median_house_value\"])\nhousing_y_df = housing_df[[\"median_house_value\"]]\n\nLalu kita ubah jadi numpy array agar bisa diolah Keras\n\nhousing_X_arr = housing_X_df.to_numpy()\nhousing_y_arr = housing_y_df.to_numpy()\n\n\nprint(housing_X_arr.shape)\nprint(housing_y_arr.shape)\n\n(20640, 8)\n(20640, 1)\n\n\nTrain test split, standarisasi:\n\nfrom sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n    housing_X_arr, housing_y_arr, test_size=0.1, random_state=42\n)\n\n\nfrom sklearn.preprocessing import StandardScaler\n\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nData target juga relatif sangat besar, sehingga sebaiknya kita scaling juga:\n\nprint(f'y min: {y_train.min()}')\nprint(f'y max: {y_train.max()}')\n\ny min: 14999.0\ny max: 500001.0\n\n\n\ny_train /= 100000\ny_test /= 100000\n\n\nprint(f'y min: {y_train.min()}')\nprint(f'y max: {y_train.max()}')\n\ny min: 0.14999\ny max: 5.00001\n\n\nSekarang kita bisa susun modelnya\n\nkeras.backend.clear_session()\n\n\nmodel4 = keras.Sequential(\n    [\n        keras.layers.InputLayer(input_shape = (housing_X_arr.shape[1:])),\n        keras.layers.Dense(units = 15, activation = keras.activations.relu),\n        keras.layers.Dense(units = 30, activation = keras.activations.relu),\n        keras.layers.Dense(units = 1, activation = keras.activations.linear)\n    ]\n)\n\n\nmodel4.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 15)                135       \n                                                                 \n dense_1 (Dense)             (None, 30)                480       \n                                                                 \n dense_2 (Dense)             (None, 1)                 31        \n                                                                 \n=================================================================\nTotal params: 646\nTrainable params: 646\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nkeras.utils.plot_model(\n    model4,\n    show_shapes = True,\n    show_layer_activations = True,\n    to_file = \"keras_sequential_model4.png\"\n)\n\n\nSelanjutnya, kita tentukan hyperparameter: optimizer, loss function, dan accuracy.\nIngat kembali, untuk regresi, loss function yang biasa digunakan adalah MSE (Mean Squared Error)\n\nearly_stop = keras.callbacks.EarlyStopping(\n    patience=5, monitor='val_loss', restore_best_weights=True, verbose=1\n)\n\n\nmodel4.compile(\n    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n    loss = keras.losses.MeanSquaredError(),\n    metrics = [keras.metrics.Accuracy()]\n)\n\n\nhistory4 = model4.fit(X_train, y_train, epochs=100, validation_split=1/9)\n\nEpoch 1/100\n516/516 [==============================] - 6s 4ms/step - loss: 0.8861 - accuracy: 0.0000e+00 - val_loss: 0.4775 - val_accuracy: 0.0000e+00\nEpoch 2/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.4211 - accuracy: 0.0000e+00 - val_loss: 0.4415 - val_accuracy: 0.0000e+00\nEpoch 3/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.3904 - accuracy: 0.0000e+00 - val_loss: 0.4295 - val_accuracy: 0.0000e+00\nEpoch 4/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.3753 - accuracy: 0.0000e+00 - val_loss: 0.4221 - val_accuracy: 0.0000e+00\nEpoch 5/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3670 - accuracy: 0.0000e+00 - val_loss: 0.4116 - val_accuracy: 0.0000e+00\nEpoch 6/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3581 - accuracy: 0.0000e+00 - val_loss: 0.3995 - val_accuracy: 0.0000e+00\nEpoch 7/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.3498 - accuracy: 0.0000e+00 - val_loss: 0.4065 - val_accuracy: 0.0000e+00\nEpoch 8/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3453 - accuracy: 0.0000e+00 - val_loss: 0.3874 - val_accuracy: 0.0000e+00\nEpoch 9/100\n516/516 [==============================] - 3s 5ms/step - loss: 0.3418 - accuracy: 0.0000e+00 - val_loss: 0.3839 - val_accuracy: 0.0000e+00\nEpoch 10/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3361 - accuracy: 0.0000e+00 - val_loss: 0.3779 - val_accuracy: 0.0000e+00\nEpoch 11/100\n516/516 [==============================] - 2s 5ms/step - loss: 0.3321 - accuracy: 0.0000e+00 - val_loss: 0.3782 - val_accuracy: 0.0000e+00\nEpoch 12/100\n516/516 [==============================] - 3s 5ms/step - loss: 0.3294 - accuracy: 0.0000e+00 - val_loss: 0.3718 - val_accuracy: 0.0000e+00\nEpoch 13/100\n516/516 [==============================] - 3s 6ms/step - loss: 0.3266 - accuracy: 0.0000e+00 - val_loss: 0.3698 - val_accuracy: 0.0000e+00\nEpoch 14/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3236 - accuracy: 0.0000e+00 - val_loss: 0.3614 - val_accuracy: 0.0000e+00\nEpoch 15/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.3205 - accuracy: 0.0000e+00 - val_loss: 0.3583 - val_accuracy: 0.0000e+00\nEpoch 16/100\n516/516 [==============================] - 1s 2ms/step - loss: 0.3189 - accuracy: 0.0000e+00 - val_loss: 0.3548 - val_accuracy: 0.0000e+00\nEpoch 17/100\n516/516 [==============================] - 1s 2ms/step - loss: 0.3173 - accuracy: 0.0000e+00 - val_loss: 0.3593 - val_accuracy: 0.0000e+00\nEpoch 18/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3150 - accuracy: 0.0000e+00 - val_loss: 0.3563 - val_accuracy: 0.0000e+00\nEpoch 19/100\n516/516 [==============================] - 4s 7ms/step - loss: 0.3137 - accuracy: 0.0000e+00 - val_loss: 0.3513 - val_accuracy: 0.0000e+00\nEpoch 20/100\n516/516 [==============================] - 3s 5ms/step - loss: 0.3141 - accuracy: 0.0000e+00 - val_loss: 0.3485 - val_accuracy: 0.0000e+00\nEpoch 21/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3105 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\nEpoch 22/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3098 - accuracy: 0.0000e+00 - val_loss: 0.3474 - val_accuracy: 0.0000e+00\nEpoch 23/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3082 - accuracy: 0.0000e+00 - val_loss: 0.3494 - val_accuracy: 0.0000e+00\nEpoch 24/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3068 - accuracy: 0.0000e+00 - val_loss: 0.3416 - val_accuracy: 0.0000e+00\nEpoch 25/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3055 - accuracy: 0.0000e+00 - val_loss: 0.3426 - val_accuracy: 0.0000e+00\nEpoch 26/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3041 - accuracy: 0.0000e+00 - val_loss: 0.3432 - val_accuracy: 0.0000e+00\nEpoch 27/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3003 - accuracy: 0.0000e+00 - val_loss: 0.3551 - val_accuracy: 0.0000e+00\nEpoch 28/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2998 - accuracy: 0.0000e+00 - val_loss: 0.3423 - val_accuracy: 0.0000e+00\nEpoch 29/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2984 - accuracy: 0.0000e+00 - val_loss: 0.3338 - val_accuracy: 0.0000e+00\nEpoch 30/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2968 - accuracy: 0.0000e+00 - val_loss: 0.3331 - val_accuracy: 0.0000e+00\nEpoch 31/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2948 - accuracy: 0.0000e+00 - val_loss: 0.3368 - val_accuracy: 0.0000e+00\nEpoch 32/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2939 - accuracy: 0.0000e+00 - val_loss: 0.3339 - val_accuracy: 0.0000e+00\nEpoch 33/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2924 - accuracy: 0.0000e+00 - val_loss: 0.3331 - val_accuracy: 0.0000e+00\nEpoch 34/100\n516/516 [==============================] - 3s 5ms/step - loss: 0.2933 - accuracy: 0.0000e+00 - val_loss: 0.3285 - val_accuracy: 0.0000e+00\nEpoch 35/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2917 - accuracy: 0.0000e+00 - val_loss: 0.3297 - val_accuracy: 0.0000e+00\nEpoch 36/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2919 - accuracy: 0.0000e+00 - val_loss: 0.3286 - val_accuracy: 0.0000e+00\nEpoch 37/100\n516/516 [==============================] - 1s 3ms/step - loss: 0.2910 - accuracy: 0.0000e+00 - val_loss: 0.3300 - val_accuracy: 0.0000e+00\nEpoch 38/100\n516/516 [==============================] - 3s 5ms/step - loss: 0.2895 - accuracy: 0.0000e+00 - val_loss: 0.3233 - val_accuracy: 0.0000e+00\nEpoch 39/100\n516/516 [==============================] - 2s 5ms/step - loss: 0.2892 - accuracy: 0.0000e+00 - val_loss: 0.3315 - val_accuracy: 0.0000e+00\nEpoch 40/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2885 - accuracy: 0.0000e+00 - val_loss: 0.3253 - val_accuracy: 0.0000e+00\nEpoch 41/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2880 - accuracy: 0.0000e+00 - val_loss: 0.3366 - val_accuracy: 0.0000e+00\nEpoch 42/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2871 - accuracy: 0.0000e+00 - val_loss: 0.3257 - val_accuracy: 0.0000e+00\nEpoch 43/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2851 - accuracy: 0.0000e+00 - val_loss: 0.3200 - val_accuracy: 0.0000e+00\nEpoch 44/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2855 - accuracy: 0.0000e+00 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\nEpoch 45/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2856 - accuracy: 0.0000e+00 - val_loss: 0.3165 - val_accuracy: 0.0000e+00\nEpoch 46/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2838 - accuracy: 0.0000e+00 - val_loss: 0.3145 - val_accuracy: 0.0000e+00\nEpoch 47/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2839 - accuracy: 0.0000e+00 - val_loss: 0.3287 - val_accuracy: 0.0000e+00\nEpoch 48/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2827 - accuracy: 0.0000e+00 - val_loss: 0.3291 - val_accuracy: 0.0000e+00\nEpoch 49/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2835 - accuracy: 0.0000e+00 - val_loss: 0.3196 - val_accuracy: 0.0000e+00\nEpoch 50/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2807 - accuracy: 0.0000e+00 - val_loss: 0.3111 - val_accuracy: 0.0000e+00\nEpoch 51/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2819 - accuracy: 0.0000e+00 - val_loss: 0.3354 - val_accuracy: 0.0000e+00\nEpoch 52/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2811 - accuracy: 0.0000e+00 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\nEpoch 53/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2800 - accuracy: 0.0000e+00 - val_loss: 0.3158 - val_accuracy: 0.0000e+00\nEpoch 54/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2791 - accuracy: 0.0000e+00 - val_loss: 0.3152 - val_accuracy: 0.0000e+00\nEpoch 55/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2796 - accuracy: 0.0000e+00 - val_loss: 0.3158 - val_accuracy: 0.0000e+00\nEpoch 56/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2796 - accuracy: 0.0000e+00 - val_loss: 0.3164 - val_accuracy: 0.0000e+00\nEpoch 57/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2802 - accuracy: 0.0000e+00 - val_loss: 0.3070 - val_accuracy: 0.0000e+00\nEpoch 58/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2775 - accuracy: 0.0000e+00 - val_loss: 0.3103 - val_accuracy: 0.0000e+00\nEpoch 59/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2780 - accuracy: 0.0000e+00 - val_loss: 0.3108 - val_accuracy: 0.0000e+00\nEpoch 60/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2779 - accuracy: 0.0000e+00 - val_loss: 0.3056 - val_accuracy: 0.0000e+00\nEpoch 61/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2766 - accuracy: 0.0000e+00 - val_loss: 0.3087 - val_accuracy: 0.0000e+00\nEpoch 62/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2762 - accuracy: 0.0000e+00 - val_loss: 0.3094 - val_accuracy: 0.0000e+00\nEpoch 63/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2759 - accuracy: 0.0000e+00 - val_loss: 0.3117 - val_accuracy: 0.0000e+00\nEpoch 64/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2761 - accuracy: 0.0000e+00 - val_loss: 0.3026 - val_accuracy: 0.0000e+00\nEpoch 65/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2738 - accuracy: 0.0000e+00 - val_loss: 0.3146 - val_accuracy: 0.0000e+00\nEpoch 66/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2745 - accuracy: 0.0000e+00 - val_loss: 0.3051 - val_accuracy: 0.0000e+00\nEpoch 67/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2747 - accuracy: 0.0000e+00 - val_loss: 0.3139 - val_accuracy: 0.0000e+00\nEpoch 68/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2746 - accuracy: 0.0000e+00 - val_loss: 0.3098 - val_accuracy: 0.0000e+00\nEpoch 69/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2744 - accuracy: 0.0000e+00 - val_loss: 0.3069 - val_accuracy: 0.0000e+00\nEpoch 70/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2737 - accuracy: 0.0000e+00 - val_loss: 0.3083 - val_accuracy: 0.0000e+00\nEpoch 71/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2727 - accuracy: 0.0000e+00 - val_loss: 0.3110 - val_accuracy: 0.0000e+00\nEpoch 72/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2734 - accuracy: 0.0000e+00 - val_loss: 0.3095 - val_accuracy: 0.0000e+00\nEpoch 73/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2715 - accuracy: 6.0562e-05 - val_loss: 0.3102 - val_accuracy: 0.0000e+00\nEpoch 74/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2709 - accuracy: 0.0000e+00 - val_loss: 0.3093 - val_accuracy: 0.0000e+00\nEpoch 75/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2713 - accuracy: 0.0000e+00 - val_loss: 0.3006 - val_accuracy: 0.0000e+00\nEpoch 76/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2704 - accuracy: 0.0000e+00 - val_loss: 0.2985 - val_accuracy: 0.0000e+00\nEpoch 77/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2704 - accuracy: 0.0000e+00 - val_loss: 0.2987 - val_accuracy: 0.0000e+00\nEpoch 78/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2682 - accuracy: 0.0000e+00 - val_loss: 0.2959 - val_accuracy: 0.0000e+00\nEpoch 79/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2692 - accuracy: 0.0000e+00 - val_loss: 0.3003 - val_accuracy: 0.0000e+00\nEpoch 80/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2693 - accuracy: 0.0000e+00 - val_loss: 0.2978 - val_accuracy: 0.0000e+00\nEpoch 81/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2689 - accuracy: 0.0000e+00 - val_loss: 0.2991 - val_accuracy: 0.0000e+00\nEpoch 82/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2667 - accuracy: 0.0000e+00 - val_loss: 0.2978 - val_accuracy: 0.0000e+00\nEpoch 83/100\n516/516 [==============================] - 2s 5ms/step - loss: 0.2688 - accuracy: 0.0000e+00 - val_loss: 0.3050 - val_accuracy: 0.0000e+00\nEpoch 84/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2678 - accuracy: 0.0000e+00 - val_loss: 0.2974 - val_accuracy: 0.0000e+00\nEpoch 85/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2669 - accuracy: 0.0000e+00 - val_loss: 0.2992 - val_accuracy: 0.0000e+00\nEpoch 86/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2675 - accuracy: 0.0000e+00 - val_loss: 0.2976 - val_accuracy: 0.0000e+00\nEpoch 87/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2664 - accuracy: 0.0000e+00 - val_loss: 0.2989 - val_accuracy: 0.0000e+00\nEpoch 88/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2659 - accuracy: 0.0000e+00 - val_loss: 0.3006 - val_accuracy: 0.0000e+00\nEpoch 89/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2664 - accuracy: 0.0000e+00 - val_loss: 0.3128 - val_accuracy: 0.0000e+00\nEpoch 90/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2664 - accuracy: 0.0000e+00 - val_loss: 0.2985 - val_accuracy: 0.0000e+00\nEpoch 91/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2657 - accuracy: 0.0000e+00 - val_loss: 0.2959 - val_accuracy: 0.0000e+00\nEpoch 92/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2651 - accuracy: 0.0000e+00 - val_loss: 0.2977 - val_accuracy: 0.0000e+00\nEpoch 93/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2650 - accuracy: 0.0000e+00 - val_loss: 0.2915 - val_accuracy: 0.0000e+00\nEpoch 94/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2656 - accuracy: 0.0000e+00 - val_loss: 0.2995 - val_accuracy: 0.0000e+00\nEpoch 95/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2648 - accuracy: 0.0000e+00 - val_loss: 0.2937 - val_accuracy: 0.0000e+00\nEpoch 96/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2646 - accuracy: 0.0000e+00 - val_loss: 0.3010 - val_accuracy: 0.0000e+00\nEpoch 97/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2638 - accuracy: 0.0000e+00 - val_loss: 0.2958 - val_accuracy: 0.0000e+00\nEpoch 98/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2651 - accuracy: 0.0000e+00 - val_loss: 0.2996 - val_accuracy: 0.0000e+00\nEpoch 99/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2640 - accuracy: 0.0000e+00 - val_loss: 0.3002 - val_accuracy: 0.0000e+00\nEpoch 100/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2636 - accuracy: 0.0000e+00 - val_loss: 0.2936 - val_accuracy: 0.0000e+00\n\n\n\npd.DataFrame(history4.history).to_csv(\"./keras_sequential_history4.csv\", index=False)\n\nSilakan download kalau mau menyocokkan/membandingkan dengan modul: keras_sequential_history4.csv\n\nhistory4_df = pd.read_csv(\"./keras_sequential_history4.csv\")\n\n\nplt.plot(history4_df[\"loss\"], label = \"training loss\")\nplt.plot(history4_df[\"val_loss\"], label = \"validation loss\")\nplt.xlabel(\"epoch\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\ny_pred = model4.predict(X_test)\n\nplt.hist(y_pred, color='green', alpha=.6)\nplt.hist(y_test, color='blue', alpha=.6)\nplt.legend(['prediction', 'truth'], loc='upper right')\nplt.show()\n\n65/65 [==============================] - 1s 5ms/step\n\n\n\n\n\n\n\n\n\n\n\n\nGambar atau citra (image) adalah sekumpulan pixel yang disusun secara dua dimensi. Sejauh ini, neural network yang kita pelajari memiliki satu input layer yang “flat” atau datar. Sehingga, apabila kita ingin meng-input data citra ke dalam neural network, caranya adalah dengan flatten, yaitu data citra yang mula-mula dua dimensi itu disusun ulang menjadi satu dimensi.\nDi Keras, ada layer istimewa untuk melakukan flatten untuk gambar berukuran a kali b pixel:\nkeras.layers.Flatten(input_shape = (a, b))\nKetika berurusan dengan data citra, layer ini menggantikan InputLayer yang biasa kita gunakan.\n\n\nMari kita coba menggunakan dataset Fashion MNIST yang sudah tersedia dari Keras:\n\nfashion_mnist = keras.datasets.fashion_mnist\n(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n\n\nprint(f'X_train_full shape: {X_train_full.shape}')\nprint(f'y_train_full shape: {y_train_full.shape}')\nprint(f'X_test shape: {X_test.shape}')\nprint(f'y_test shape: {y_test.shape}')\n\nX_train_full shape: (60000, 28, 28)\ny_train_full shape: (60000,)\nX_test shape: (10000, 28, 28)\ny_test shape: (10000,)\n\n\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train_full, y_train_full, test_size=1/6, random_state=42\n)\n\nprint(f'X_train shape: {X_train.shape}')\nprint(f'y_train shape: {y_train.shape}')\nprint(f'X_val shape: {X_val.shape}')\nprint(f'y_val shape: {y_val.shape}')\nprint(f'X_test shape: {X_test.shape}')\nprint(f'y_test shape: {y_test.shape}')\n\nX_train shape: (50000, 28, 28)\ny_train shape: (50000,)\nX_val shape: (10000, 28, 28)\ny_val shape: (10000,)\nX_test shape: (10000, 28, 28)\ny_test shape: (10000,)\n\n\n\nX_train = X_train / 255\nX_val = X_val / 255\nX_test = X_test / 255\n\nAda 10 kelas:\n\nprint(set(y_train))\n\n{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n\n\n\nclass_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n\n\nprint(len(class_names))\n\n10\n\n\nKita lihat salah satu gambarnya:\n\n#@title Slider to look for some image examples {run: \"auto\"}\nidx = 21402 #@param {type:\"slider\", min:0, max:49999, step:1}\n\nplt.imshow(X_train[idx], cmap='gray')\nplt.title(class_names[y_train[idx]])\nplt.axis('OFF')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nmodel5 = keras.Sequential(\n    [\n        keras.layers.Flatten(input_shape=(28,28)),\n        keras.layers.Dense(units=100, activation=keras.activations.relu),\n        keras.layers.Dense(units=50, activation=keras.activations.relu),\n        keras.layers.Dense(units=10, activation=keras.activations.softmax)\n    ]\n)\n\n\nmodel5.compile(\n    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n    loss = keras.losses.SparseCategoricalCrossentropy(),\n    metrics = [keras.metrics.CategoricalAccuracy()]\n)\n\n\nmodel5.summary()\n\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten (Flatten)           (None, 784)               0         \n                                                                 \n dense_3 (Dense)             (None, 100)               78500     \n                                                                 \n dense_4 (Dense)             (None, 50)                5050      \n                                                                 \n dense_5 (Dense)             (None, 10)                510       \n                                                                 \n=================================================================\nTotal params: 84,060\nTrainable params: 84,060\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nhistory5 = model5.fit(\n    X_train, y_train, validation_data=(X_val, y_val),\n    epochs=50, batch_size=256\n)\n\nEpoch 1/50\n196/196 [==============================] - 5s 13ms/step - loss: 0.6641 - categorical_accuracy: 0.1050 - val_loss: 0.4997 - val_categorical_accuracy: 0.0831\nEpoch 2/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.4335 - categorical_accuracy: 0.1032 - val_loss: 0.4217 - val_categorical_accuracy: 0.1034\nEpoch 3/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.3868 - categorical_accuracy: 0.1032 - val_loss: 0.3928 - val_categorical_accuracy: 0.0899\nEpoch 4/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.3631 - categorical_accuracy: 0.1022 - val_loss: 0.3738 - val_categorical_accuracy: 0.0970\nEpoch 5/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.3410 - categorical_accuracy: 0.1022 - val_loss: 0.3662 - val_categorical_accuracy: 0.1274\nEpoch 6/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.3260 - categorical_accuracy: 0.1030 - val_loss: 0.3563 - val_categorical_accuracy: 0.1213\nEpoch 7/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.3113 - categorical_accuracy: 0.1023 - val_loss: 0.3779 - val_categorical_accuracy: 0.1185\nEpoch 8/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.2981 - categorical_accuracy: 0.1022 - val_loss: 0.3430 - val_categorical_accuracy: 0.1037\nEpoch 9/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2869 - categorical_accuracy: 0.1025 - val_loss: 0.3368 - val_categorical_accuracy: 0.1135\nEpoch 10/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.2813 - categorical_accuracy: 0.1025 - val_loss: 0.3477 - val_categorical_accuracy: 0.0992\nEpoch 11/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2738 - categorical_accuracy: 0.1021 - val_loss: 0.3513 - val_categorical_accuracy: 0.1056\nEpoch 12/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2614 - categorical_accuracy: 0.1021 - val_loss: 0.3279 - val_categorical_accuracy: 0.1111\nEpoch 13/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2564 - categorical_accuracy: 0.1021 - val_loss: 0.3229 - val_categorical_accuracy: 0.0928\nEpoch 14/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2518 - categorical_accuracy: 0.1019 - val_loss: 0.3353 - val_categorical_accuracy: 0.1203\nEpoch 15/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.2468 - categorical_accuracy: 0.1025 - val_loss: 0.3330 - val_categorical_accuracy: 0.1141\nEpoch 16/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2370 - categorical_accuracy: 0.1027 - val_loss: 0.3178 - val_categorical_accuracy: 0.0977\nEpoch 17/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.2313 - categorical_accuracy: 0.1012 - val_loss: 0.3160 - val_categorical_accuracy: 0.0982\nEpoch 18/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2243 - categorical_accuracy: 0.1024 - val_loss: 0.3269 - val_categorical_accuracy: 0.1197\nEpoch 19/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2198 - categorical_accuracy: 0.1020 - val_loss: 0.3248 - val_categorical_accuracy: 0.1101\nEpoch 20/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2151 - categorical_accuracy: 0.1022 - val_loss: 0.3217 - val_categorical_accuracy: 0.1045\nEpoch 21/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2112 - categorical_accuracy: 0.1010 - val_loss: 0.3300 - val_categorical_accuracy: 0.1171\nEpoch 22/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.2053 - categorical_accuracy: 0.1022 - val_loss: 0.3182 - val_categorical_accuracy: 0.1110\nEpoch 23/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.2010 - categorical_accuracy: 0.1018 - val_loss: 0.3216 - val_categorical_accuracy: 0.1026\nEpoch 24/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1988 - categorical_accuracy: 0.1014 - val_loss: 0.3371 - val_categorical_accuracy: 0.1178\nEpoch 25/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1914 - categorical_accuracy: 0.1020 - val_loss: 0.3260 - val_categorical_accuracy: 0.0944\nEpoch 26/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1910 - categorical_accuracy: 0.1021 - val_loss: 0.3283 - val_categorical_accuracy: 0.1058\nEpoch 27/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.1879 - categorical_accuracy: 0.1019 - val_loss: 0.3209 - val_categorical_accuracy: 0.1010\nEpoch 28/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1823 - categorical_accuracy: 0.1021 - val_loss: 0.3310 - val_categorical_accuracy: 0.1250\nEpoch 29/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1741 - categorical_accuracy: 0.1022 - val_loss: 0.3270 - val_categorical_accuracy: 0.1083\nEpoch 30/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1752 - categorical_accuracy: 0.1013 - val_loss: 0.3395 - val_categorical_accuracy: 0.1095\nEpoch 31/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1708 - categorical_accuracy: 0.1017 - val_loss: 0.3311 - val_categorical_accuracy: 0.1045\nEpoch 32/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1676 - categorical_accuracy: 0.1017 - val_loss: 0.3417 - val_categorical_accuracy: 0.0927\nEpoch 33/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1661 - categorical_accuracy: 0.1011 - val_loss: 0.3631 - val_categorical_accuracy: 0.1184\nEpoch 34/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1605 - categorical_accuracy: 0.1017 - val_loss: 0.3440 - val_categorical_accuracy: 0.1029\nEpoch 35/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1594 - categorical_accuracy: 0.1012 - val_loss: 0.3512 - val_categorical_accuracy: 0.1084\nEpoch 36/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1556 - categorical_accuracy: 0.1009 - val_loss: 0.3603 - val_categorical_accuracy: 0.1116\nEpoch 37/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1516 - categorical_accuracy: 0.1016 - val_loss: 0.3495 - val_categorical_accuracy: 0.1175\nEpoch 38/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1454 - categorical_accuracy: 0.1013 - val_loss: 0.3996 - val_categorical_accuracy: 0.1034\nEpoch 39/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1469 - categorical_accuracy: 0.1012 - val_loss: 0.3549 - val_categorical_accuracy: 0.1058\nEpoch 40/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1425 - categorical_accuracy: 0.1016 - val_loss: 0.3671 - val_categorical_accuracy: 0.1063\nEpoch 41/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.1396 - categorical_accuracy: 0.1013 - val_loss: 0.3639 - val_categorical_accuracy: 0.1009\nEpoch 42/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1383 - categorical_accuracy: 0.1012 - val_loss: 0.3912 - val_categorical_accuracy: 0.1223\nEpoch 43/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1350 - categorical_accuracy: 0.1011 - val_loss: 0.3731 - val_categorical_accuracy: 0.1065\nEpoch 44/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.1343 - categorical_accuracy: 0.1013 - val_loss: 0.3782 - val_categorical_accuracy: 0.1079\nEpoch 45/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.1311 - categorical_accuracy: 0.1005 - val_loss: 0.3870 - val_categorical_accuracy: 0.1125\nEpoch 46/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1257 - categorical_accuracy: 0.1013 - val_loss: 0.3707 - val_categorical_accuracy: 0.1047\nEpoch 47/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1232 - categorical_accuracy: 0.1011 - val_loss: 0.3853 - val_categorical_accuracy: 0.1067\nEpoch 48/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1203 - categorical_accuracy: 0.1009 - val_loss: 0.3793 - val_categorical_accuracy: 0.1061\nEpoch 49/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1149 - categorical_accuracy: 0.1009 - val_loss: 0.3932 - val_categorical_accuracy: 0.1101\nEpoch 50/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1207 - categorical_accuracy: 0.1011 - val_loss: 0.3985 - val_categorical_accuracy: 0.1003\n\n\n\npd.DataFrame(history5.history).to_csv(\"./keras_sequential_history5.csv\", index=False)\n\nSilakan download kalau mau menyocokkan/membandingkan dengan modul: keras_sequential_history5.csv\n\nhistory5_df = pd.read_csv(\"./keras_sequential_history5.csv\")\n\n\nplt.plot(history5_df[\"loss\"], label = \"training loss\")\nplt.plot(history5_df[\"val_loss\"], label = \"validation loss\")\nplt.xlabel(\"epoch\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\ny_pred = model5.predict(X_test)\n\n313/313 [==============================] - 2s 7ms/step\n\n\n\ny_pred\n\narray([[7.3191592e-10, 4.9755400e-10, 2.0336069e-08, ..., 2.6508974e-04,\n        6.6600020e-10, 9.9970919e-01],\n       [1.0685701e-06, 1.3641132e-16, 9.9973696e-01, ..., 6.6150912e-25,\n        1.0635574e-14, 2.7912504e-22],\n       [3.8944440e-14, 1.0000000e+00, 7.2451013e-19, ..., 1.9461965e-25,\n        9.4534440e-24, 5.5635325e-28],\n       ...,\n       [6.9977574e-10, 8.2804253e-17, 9.0566991e-11, ..., 4.9004850e-12,\n        1.0000000e+00, 8.5710581e-16],\n       [8.6001712e-09, 9.9999988e-01, 2.2160624e-12, ..., 9.4472928e-21,\n        9.9464089e-13, 7.2510805e-17],\n       [2.2053911e-10, 1.0453890e-11, 9.8423698e-06, ..., 2.5791397e-07,\n        3.4278116e-10, 9.7139477e-11]], dtype=float32)\n\n\n\ny_pred[123]\n\narray([1.04234315e-19, 2.76166473e-17, 7.08109165e-22, 1.09880367e-13,\n       1.19973995e-17, 3.41231225e-15, 5.77217902e-19, 1.47765789e-07,\n       6.00817884e-14, 9.99999881e-01], dtype=float32)\n\n\n\nnp.argmax(y_pred[123])\n\n9\n\n\nKita bisa melihat hasil prediksi:\n\n#@title Slider to look for some prediction examples {run: \"auto\"}\nidx = 123 #@param {type:\"slider\", min:0, max:9999, step:1}\n\nplt.imshow(X_test[idx], cmap='gray')\nplt.title(\n    f\"Predicted class: {class_names[int(np.argmax(y_pred[idx]))]}\\n\" +\n    f\"True class: {class_names[y_test[idx]]}\"\n)\nplt.axis('OFF')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nSebenarnya, menerima input gambar dengan teknik flatten itu kurang efektif.\n\nDengan dense layer, bahkan dua pixel yang sangat jauh itu juga terhubungkan, padahal seharusnya tidak berhubungan.\nKarena itu juga, tidak ada penekanan hubungan antara dua pixel yang saling berdekatan.\n\nAlangkah baiknya, ada teknik input gambar yang bisa mempertimbangkan bagaimana hubungan suatu pixel dengan pixel-pixel di sekitarnya saja, daripada dengan semua pixel.\nConvolutional Neural Network (CNN) mencoba mengatasi hal ini. Ciri khasnya adalah adanya dua jenis layer baru:\n\nconvolution layer\npooling layer, biasanya max pooling\n\nKedua layer baru ini bersifat sparse, yaitu beberapa neuron terhubung dengan beberapa neuron saja, tidak dengan semuanya.\nGambar berikut ini membandingkan antara sparse layer dengan dense layer:\n\nSumber gambar: Goodfellow, et. al. (2016) hal. 337\n\n\nSuatu convolution layer menghitung “konvolusi” (convolution).\n\nSumber gambar: Kotu, hal. 325\nPerhitungan konvolusi selalu melibatkan suatu “filter”, yang nilai-nilainya menjadi parameter (seperti weights and biases) yang terus di-update selama proses training.\n\nSumber gambar: Aggarwal (2018) hal. 321\nContoh perhitungan menggunakan filter bisa dilihat di gambar berikut.\n\nSumber gambar: Aggarwal (2018) hal. 336\nKetika menghitung konvolusi, filter selalu digeser. Pergeseran filter ini sebenarnya tidak harus satu langkah. Bisa saja, misalnya, dua langkah. Banyaknya langkah ini disebut stride.\n\nSumber gambar: Kotu, hal. 328\n\n\n\nDaripada menghitung konvolusi, pooling hanya menghitung statistik sederhana saja. Biasanya menghitung maksimum, yang disebut max pooling.\n\nSumber gambar: Kotu, hal. 328\n\n\n\nNote: aslinya, LeNet-5 menggunakan average pooling, yaitu menghitung rata-rata, tidak seperti max pooling yang memilih maksimum.\n\nSumber gambar: Aggarwal (2018) hal. 41\nArsitektur LeNet-5 menggunakan Keras bisa disusun sebagai berikut:\n\nlenet5 = keras.Sequential()\n\nlenet5.add(keras.layers.Conv2D(\n    input_shape = (32, 32, 1),\n    kernel_size = (5, 5),\n    filters = 6,\n    activation = keras.activations.sigmoid\n)) # menghasilkan C1 di gambar: ukuran 28 x 28 x 6\n\nlenet5.add(keras.layers.AveragePooling2D(\n    pool_size = (2, 2),\n    strides = 2\n)) # menghasilkan S2 di gambar: ukuran 14 x 14 x 6\n\nlenet5.add(keras.layers.Conv2D(\n    kernel_size = (5, 5),\n    filters = 16,\n    activation = keras.activations.sigmoid\n)) # menghasilkan C3 di gambar: ukuran 10 x 10 x 16\n\nlenet5.add(keras.layers.AveragePooling2D(\n    pool_size = (2, 2),\n    strides = 2\n)) # menghasilkan S4 di gambar: ukuran 5 x 5 x 16\n\nlenet5.add(keras.layers.Flatten())\n# menjadi C5 di gambar, dengan 400 neuron\n\nlenet5.add(keras.layers.Dense(\n    units = 120, activation = keras.activations.sigmoid\n))\n\nlenet5.add(keras.layers.Dense(\n    units = 84, activation = keras.activations.sigmoid\n))\n\nlenet5.add(keras.layers.Dense(\n    units = 10, activation = keras.activations.softmax\n))\n\n\nkeras.utils.plot_model(\n    lenet5,\n    show_shapes = True,\n    show_layer_activations = True,\n    to_file = \"keras_sequential_lenet5.png\"\n)\n\n\n\n\n\n\nSumber gambar\n\nAggarwal, C. Charu. 2018. Neural Networks and Deep Learning: A Textbook. Edisi Pertama. Springer.\nGoodfellow, Ian; Bengio, Yoshua; & Courville, Aaron. 2016. Deep Learning. MIT Press.\nKotu, Data Science Concepts and Practice"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul8.html#perceptron-revisited-selain-sequential-api",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul8.html#perceptron-revisited-selain-sequential-api",
    "title": "Modul 8 Praktikum Sains Data: Deep Learning dengan Keras, Regresi dan Klasifikasi Gambar",
    "section": "",
    "text": "Di pertemuan sebelumnya, kita telah menyusun perceptron menggunakan Sequential API seperti berikut (ada dua cara yang ekuivalen):\n\n# langsung menentukan semua layer di awal, dengan memasukkan list\nmodel0 = keras.Sequential(\n    [\n        keras.layers.InputLayer(input_shape = (2,)),\n        keras.layers.Dense(units = 1, activation = keras.activations.sigmoid)\n    ]\n)\n\n\n# menambahkan layer secara berangsur-angsur\nmodel0 = keras.Sequential()\nmodel0.add(keras.layers.InputLayer(input_shape = (2,)))\nmodel0.add(keras.layers.Dense(units = 1, activation = keras.activations.sigmoid))\n\nSequential API sebenarnya cukup terbatas: tiap layer harus berurutan satu sama lain, dan hubungan yang ada hanyalah antar pasangan dua layer yang bersebelahan.\nUntuk model-model yang kita pelajari di mata kuliah Sains Data, sebenarnya Sequential API sudah cukup. Namun, kalau kalian pelajari lebih lanjut tentang neural network / deep learning, kalian akan bertemu dengan arsitektur aneh yang tidak bisa langsung disusun dengan Sequential API.\nContohnya, ada yang namanya skip connection, yaitu suatu layer terhubung dengan layer lain yang agak jauh darinya:\n\nSumber gambar: Aggarwal (2018) hal. 348\n(Skip connection akan kalian temui kalau mempelajari residual network, yaitu arsitektur ResNet dan variasinya, yang sudah sangat di luar cakupan materi mata kuliah Sains Data.)\nUntuk itu, diperlukan API selain Sequential, yaitu bisa dengan Functional API atau dengan Subclassing API. Agar kalian lebih mengenal Keras, kita akan mencoba membuat perceptron menggunakan dua API lainnya tersebut.\nKita bisa uji coba dengan dataset yang sama seperti di pertemuan sebelumnya: titik_negatif_positif.csv\n\ndf = pd.read_csv(\"./titik_negatif_positif.csv\", dtype=\"float32\")\n\n\ninputs_df = df.drop(columns=[\"kelas\"])\ntargets_df = df[[\"kelas\"]]\n\n\ninputs_arr = inputs_df.to_numpy()\ntargets_arr = targets_df.to_numpy()\n\n\n\nIde dari Functional API adalah menyusun tiap layer dan hubungan antar layer sebagai komposisi fungsi.\nUntuk Functional API, daripada keras.layers.InputLayer, gunakan keras.layers.Input\n\nm1_input = keras.layers.Input(shape = (2,))\n\nm1_layer1_func = keras.layers.Dense(units = 1, activation = keras.activations.sigmoid)\nm1_layer1_out = m1_layer1_func(m1_input) # seperti komposisi fungsi\n\nmodel1 = keras.Model(inputs=m1_input, outputs=m1_layer1_out, name=\"model1\")\n\n\nmodel1.summary()\n\nModel: \"model1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_3 (InputLayer)        [(None, 2)]               0         \n                                                                 \n dense_2 (Dense)             (None, 1)                 3         \n                                                                 \n=================================================================\nTotal params: 3\nTrainable params: 3\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nkeras.utils.plot_model(\n    model1,\n    show_shapes = True,\n    show_layer_activations = True,\n    to_file = \"keras_functional_model1.png\"\n)\n\n\nSisanya (compile lalu fit) sama dengan Sequential API\n\nmodel1.compile(\n    optimizer = keras.optimizers.SGD(learning_rate = 0.01),\n    loss = keras.losses.BinaryCrossentropy(),\n    metrics = [keras.metrics.BinaryAccuracy()]\n)\n\n\nhistory1 = model1.fit(inputs_arr, targets_arr, epochs=100, validation_split=0.2)\n\nEpoch 1/100\n50/50 [==============================] - 4s 31ms/step - loss: 1.2000 - binary_accuracy: 0.6144 - val_loss: 2.1506 - val_binary_accuracy: 0.0775\nEpoch 2/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.6425 - binary_accuracy: 0.6837 - val_loss: 1.0554 - val_binary_accuracy: 0.3575\nEpoch 3/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.3413 - binary_accuracy: 0.8344 - val_loss: 0.5549 - val_binary_accuracy: 0.7150\nEpoch 4/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.2141 - binary_accuracy: 0.9406 - val_loss: 0.3460 - val_binary_accuracy: 0.8975\nEpoch 5/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.1576 - binary_accuracy: 0.9800 - val_loss: 0.2475 - val_binary_accuracy: 0.9550\nEpoch 6/100\n50/50 [==============================] - 1s 10ms/step - loss: 0.1277 - binary_accuracy: 0.9900 - val_loss: 0.1938 - val_binary_accuracy: 0.9675\nEpoch 7/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.1092 - binary_accuracy: 0.9912 - val_loss: 0.1604 - val_binary_accuracy: 0.9775\nEpoch 8/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0964 - binary_accuracy: 0.9931 - val_loss: 0.1381 - val_binary_accuracy: 0.9850\nEpoch 9/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0870 - binary_accuracy: 0.9944 - val_loss: 0.1221 - val_binary_accuracy: 0.9850\nEpoch 10/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0796 - binary_accuracy: 0.9950 - val_loss: 0.1101 - val_binary_accuracy: 0.9900\nEpoch 11/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0737 - binary_accuracy: 0.9950 - val_loss: 0.1007 - val_binary_accuracy: 0.9900\nEpoch 12/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0688 - binary_accuracy: 0.9969 - val_loss: 0.0932 - val_binary_accuracy: 0.9900\nEpoch 13/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0647 - binary_accuracy: 0.9969 - val_loss: 0.0870 - val_binary_accuracy: 0.9900\nEpoch 14/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0611 - binary_accuracy: 0.9975 - val_loss: 0.0818 - val_binary_accuracy: 0.9900\nEpoch 15/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0581 - binary_accuracy: 0.9975 - val_loss: 0.0774 - val_binary_accuracy: 0.9900\nEpoch 16/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0554 - binary_accuracy: 0.9975 - val_loss: 0.0736 - val_binary_accuracy: 0.9900\nEpoch 17/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0530 - binary_accuracy: 0.9975 - val_loss: 0.0703 - val_binary_accuracy: 0.9925\nEpoch 18/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0508 - binary_accuracy: 0.9975 - val_loss: 0.0674 - val_binary_accuracy: 0.9925\nEpoch 19/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0489 - binary_accuracy: 0.9969 - val_loss: 0.0649 - val_binary_accuracy: 0.9925\nEpoch 20/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0472 - binary_accuracy: 0.9969 - val_loss: 0.0626 - val_binary_accuracy: 0.9925\nEpoch 21/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0456 - binary_accuracy: 0.9969 - val_loss: 0.0605 - val_binary_accuracy: 0.9925\nEpoch 22/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0441 - binary_accuracy: 0.9969 - val_loss: 0.0586 - val_binary_accuracy: 0.9950\nEpoch 23/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0428 - binary_accuracy: 0.9969 - val_loss: 0.0569 - val_binary_accuracy: 0.9950\nEpoch 24/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0416 - binary_accuracy: 0.9969 - val_loss: 0.0553 - val_binary_accuracy: 0.9950\nEpoch 25/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0404 - binary_accuracy: 0.9969 - val_loss: 0.0538 - val_binary_accuracy: 0.9950\nEpoch 26/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0394 - binary_accuracy: 0.9969 - val_loss: 0.0525 - val_binary_accuracy: 0.9950\nEpoch 27/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0384 - binary_accuracy: 0.9969 - val_loss: 0.0512 - val_binary_accuracy: 0.9950\nEpoch 28/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0375 - binary_accuracy: 0.9969 - val_loss: 0.0501 - val_binary_accuracy: 0.9950\nEpoch 29/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0366 - binary_accuracy: 0.9969 - val_loss: 0.0490 - val_binary_accuracy: 0.9950\nEpoch 30/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0358 - binary_accuracy: 0.9969 - val_loss: 0.0480 - val_binary_accuracy: 0.9950\nEpoch 31/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0351 - binary_accuracy: 0.9969 - val_loss: 0.0470 - val_binary_accuracy: 0.9950\nEpoch 32/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0344 - binary_accuracy: 0.9975 - val_loss: 0.0461 - val_binary_accuracy: 0.9950\nEpoch 33/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0337 - binary_accuracy: 0.9975 - val_loss: 0.0453 - val_binary_accuracy: 0.9950\nEpoch 34/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0331 - binary_accuracy: 0.9975 - val_loss: 0.0445 - val_binary_accuracy: 0.9950\nEpoch 35/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0325 - binary_accuracy: 0.9975 - val_loss: 0.0437 - val_binary_accuracy: 0.9950\nEpoch 36/100\n50/50 [==============================] - 0s 10ms/step - loss: 0.0319 - binary_accuracy: 0.9975 - val_loss: 0.0430 - val_binary_accuracy: 0.9950\nEpoch 37/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0314 - binary_accuracy: 0.9975 - val_loss: 0.0424 - val_binary_accuracy: 0.9950\nEpoch 38/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0308 - binary_accuracy: 0.9975 - val_loss: 0.0417 - val_binary_accuracy: 0.9950\nEpoch 39/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0303 - binary_accuracy: 0.9975 - val_loss: 0.0411 - val_binary_accuracy: 0.9950\nEpoch 40/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0299 - binary_accuracy: 0.9975 - val_loss: 0.0405 - val_binary_accuracy: 0.9975\nEpoch 41/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0294 - binary_accuracy: 0.9975 - val_loss: 0.0400 - val_binary_accuracy: 0.9975\nEpoch 42/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0290 - binary_accuracy: 0.9975 - val_loss: 0.0394 - val_binary_accuracy: 0.9975\nEpoch 43/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0286 - binary_accuracy: 0.9975 - val_loss: 0.0389 - val_binary_accuracy: 0.9975\nEpoch 44/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0282 - binary_accuracy: 0.9975 - val_loss: 0.0384 - val_binary_accuracy: 0.9975\nEpoch 45/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0278 - binary_accuracy: 0.9975 - val_loss: 0.0380 - val_binary_accuracy: 0.9975\nEpoch 46/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0275 - binary_accuracy: 0.9975 - val_loss: 0.0375 - val_binary_accuracy: 0.9975\nEpoch 47/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0271 - binary_accuracy: 0.9975 - val_loss: 0.0371 - val_binary_accuracy: 0.9975\nEpoch 48/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0268 - binary_accuracy: 0.9975 - val_loss: 0.0367 - val_binary_accuracy: 0.9975\nEpoch 49/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0265 - binary_accuracy: 0.9975 - val_loss: 0.0363 - val_binary_accuracy: 0.9975\nEpoch 50/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0262 - binary_accuracy: 0.9975 - val_loss: 0.0359 - val_binary_accuracy: 0.9975\nEpoch 51/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0259 - binary_accuracy: 0.9975 - val_loss: 0.0355 - val_binary_accuracy: 0.9975\nEpoch 52/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0256 - binary_accuracy: 0.9975 - val_loss: 0.0351 - val_binary_accuracy: 0.9975\nEpoch 53/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0253 - binary_accuracy: 0.9975 - val_loss: 0.0348 - val_binary_accuracy: 0.9975\nEpoch 54/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0250 - binary_accuracy: 0.9975 - val_loss: 0.0345 - val_binary_accuracy: 0.9975\nEpoch 55/100\n50/50 [==============================] - 1s 12ms/step - loss: 0.0248 - binary_accuracy: 0.9975 - val_loss: 0.0341 - val_binary_accuracy: 0.9975\nEpoch 56/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0245 - binary_accuracy: 0.9975 - val_loss: 0.0338 - val_binary_accuracy: 0.9975\nEpoch 57/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0243 - binary_accuracy: 0.9975 - val_loss: 0.0335 - val_binary_accuracy: 0.9975\nEpoch 58/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0240 - binary_accuracy: 0.9975 - val_loss: 0.0332 - val_binary_accuracy: 0.9975\nEpoch 59/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0238 - binary_accuracy: 0.9975 - val_loss: 0.0329 - val_binary_accuracy: 0.9975\nEpoch 60/100\n50/50 [==============================] - 1s 12ms/step - loss: 0.0236 - binary_accuracy: 0.9975 - val_loss: 0.0327 - val_binary_accuracy: 0.9975\nEpoch 61/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0234 - binary_accuracy: 0.9975 - val_loss: 0.0324 - val_binary_accuracy: 0.9975\nEpoch 62/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0232 - binary_accuracy: 0.9975 - val_loss: 0.0321 - val_binary_accuracy: 0.9975\nEpoch 63/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0230 - binary_accuracy: 0.9975 - val_loss: 0.0319 - val_binary_accuracy: 0.9975\nEpoch 64/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0228 - binary_accuracy: 0.9975 - val_loss: 0.0316 - val_binary_accuracy: 0.9975\nEpoch 65/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0226 - binary_accuracy: 0.9975 - val_loss: 0.0314 - val_binary_accuracy: 0.9975\nEpoch 66/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0224 - binary_accuracy: 0.9975 - val_loss: 0.0312 - val_binary_accuracy: 0.9975\nEpoch 67/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0222 - binary_accuracy: 0.9975 - val_loss: 0.0309 - val_binary_accuracy: 0.9975\nEpoch 68/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0220 - binary_accuracy: 0.9975 - val_loss: 0.0307 - val_binary_accuracy: 0.9975\nEpoch 69/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0219 - binary_accuracy: 0.9975 - val_loss: 0.0305 - val_binary_accuracy: 0.9975\nEpoch 70/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0217 - binary_accuracy: 0.9975 - val_loss: 0.0303 - val_binary_accuracy: 0.9975\nEpoch 71/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0215 - binary_accuracy: 0.9975 - val_loss: 0.0301 - val_binary_accuracy: 0.9975\nEpoch 72/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0214 - binary_accuracy: 0.9975 - val_loss: 0.0299 - val_binary_accuracy: 0.9975\nEpoch 73/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0212 - binary_accuracy: 0.9975 - val_loss: 0.0297 - val_binary_accuracy: 0.9975\nEpoch 74/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0211 - binary_accuracy: 0.9975 - val_loss: 0.0295 - val_binary_accuracy: 0.9975\nEpoch 75/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0209 - binary_accuracy: 0.9975 - val_loss: 0.0293 - val_binary_accuracy: 0.9975\nEpoch 76/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0208 - binary_accuracy: 0.9975 - val_loss: 0.0291 - val_binary_accuracy: 0.9975\nEpoch 77/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0206 - binary_accuracy: 0.9975 - val_loss: 0.0289 - val_binary_accuracy: 0.9975\nEpoch 78/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0205 - binary_accuracy: 0.9975 - val_loss: 0.0287 - val_binary_accuracy: 0.9975\nEpoch 79/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0204 - binary_accuracy: 0.9975 - val_loss: 0.0286 - val_binary_accuracy: 0.9975\nEpoch 80/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0202 - binary_accuracy: 0.9975 - val_loss: 0.0284 - val_binary_accuracy: 0.9975\nEpoch 81/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0201 - binary_accuracy: 0.9975 - val_loss: 0.0282 - val_binary_accuracy: 0.9975\nEpoch 82/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0200 - binary_accuracy: 0.9975 - val_loss: 0.0281 - val_binary_accuracy: 0.9975\nEpoch 83/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0199 - binary_accuracy: 0.9975 - val_loss: 0.0279 - val_binary_accuracy: 0.9975\nEpoch 84/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0197 - binary_accuracy: 0.9975 - val_loss: 0.0278 - val_binary_accuracy: 0.9975\nEpoch 85/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0196 - binary_accuracy: 0.9975 - val_loss: 0.0276 - val_binary_accuracy: 0.9975\nEpoch 86/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0195 - binary_accuracy: 0.9975 - val_loss: 0.0275 - val_binary_accuracy: 0.9975\nEpoch 87/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0194 - binary_accuracy: 0.9975 - val_loss: 0.0273 - val_binary_accuracy: 0.9975\nEpoch 88/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0193 - binary_accuracy: 0.9975 - val_loss: 0.0272 - val_binary_accuracy: 0.9975\nEpoch 89/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0192 - binary_accuracy: 0.9975 - val_loss: 0.0270 - val_binary_accuracy: 0.9975\nEpoch 90/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0191 - binary_accuracy: 0.9975 - val_loss: 0.0269 - val_binary_accuracy: 0.9975\nEpoch 91/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0190 - binary_accuracy: 0.9975 - val_loss: 0.0268 - val_binary_accuracy: 0.9975\nEpoch 92/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0189 - binary_accuracy: 0.9975 - val_loss: 0.0267 - val_binary_accuracy: 0.9975\nEpoch 93/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0188 - binary_accuracy: 0.9975 - val_loss: 0.0265 - val_binary_accuracy: 0.9975\nEpoch 94/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0187 - binary_accuracy: 0.9975 - val_loss: 0.0264 - val_binary_accuracy: 0.9975\nEpoch 95/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0186 - binary_accuracy: 0.9975 - val_loss: 0.0263 - val_binary_accuracy: 0.9975\nEpoch 96/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0185 - binary_accuracy: 0.9975 - val_loss: 0.0262 - val_binary_accuracy: 0.9975\nEpoch 97/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0184 - binary_accuracy: 0.9975 - val_loss: 0.0260 - val_binary_accuracy: 0.9975\nEpoch 98/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0183 - binary_accuracy: 0.9975 - val_loss: 0.0259 - val_binary_accuracy: 0.9975\nEpoch 99/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0182 - binary_accuracy: 0.9975 - val_loss: 0.0258 - val_binary_accuracy: 0.9975\nEpoch 100/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0181 - binary_accuracy: 0.9975 - val_loss: 0.0257 - val_binary_accuracy: 0.9975\n\n\nKita bisa ubah dictionary .history menjadi CSV:\n\npd.DataFrame(history1.history).to_csv(\"./keras_functional_history1.csv\", index=False)\n\nSilakan download kalau mau menyocokkan/membandingkan dengan modul: keras_functional_history1.csv\nImport kembali:\n\nhistory1_df = pd.read_csv(\"./keras_functional_history1.csv\")\n\nLalu plot loss:\n\nplt.plot(history1_df[\"loss\"], label = \"training loss\")\nplt.plot(history1_df[\"val_loss\"], label = \"validation loss\")\nplt.xlabel(\"epoch\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nUntuk model yang lebih kompleks, mungkin komposisi fungsi akan membuat pusing, karena banyak fungsi bertebaran di mana-mana. Agar lebih rapi dan terstruktur, kita bisa gunakan Subclassing API, yaitu dengan OOP / object oriented programming.\nSilakan review Modul 2 Praktikum Struktur Data tentang Pengantar OOP kalau perlu ;)\nDalam Subclassing API, model yang kita buat berupa class yang meng-inherit (atau disebut subclassing) dari keras.Model yang sudah mengimplementasikan sebagian besar method yang kita butuhkan.\n(Bahkan, kita juga bisa buat class yang hanya berupa kumpulan layer, yang nantinya akan masuk lagi ke class lain. Kalian bisa pelajari lebih lanjut: https://keras.io/guides/making_new_layers_and_models_via_subclassing/)\nDalam model yang kita susun, hanya diperlukan:\n\nconstructor __init__ berisi minimal satu baris, yaitu super().__init__() dan boleh berisi baris lainnya untuk menyiapkan atribut (variabel) yang langsung bisa dibuat ketika model dibuat (sebelum mulai training)\nmethod call yang mendefinisikan bagaimana forward pass\n(opsional) method build yang menyiapkan atribut yang bisa dibuat di awal training setelah ukuran input diketahui\n\n\nclass MyPerceptron(keras.Model):\n    def __init__(self, units=1):\n        super().__init__()\n\n        # banyaknya neuron di output layer\n        self.units = units\n\n    # menyiapkan parameter (weights and biases) tergantung ukuran input\n    def build(self, input_shape):\n        input_dim = input_shape[-1]\n\n        # matriks W terkadang disebut kernel\n        self.kernel = self.add_weight(\n            shape = (input_dim, self.units),\n            initializer = keras.initializers.RandomNormal(mean=0, stddev=0.05),\n            trainable = True,\n        )\n        self.bias = self.add_weight(\n            shape = (self.units,),\n            initializer = keras.initializers.RandomNormal(),\n            trainable = True\n        )\n\n    # forward pass\n    def call(self, inputs):\n        return tf.sigmoid(\n            tf.matmul(inputs, self.kernel) + self.bias\n        )\n\nKita harus membuat instance atau objek dari class ini terlebih dahulu, lalu memanggil .build() dulu, agar kemudian bisa melakukan misalnya .fit()\n\nmodel2 = MyPerceptron()\n\n\nmodel2.build(input_shape = (2,))\n\nSekarang kita bisa compile, fit, simpan history, dan plot loss seperti biasa…\n\nmodel2.compile(\n    optimizer = keras.optimizers.SGD(learning_rate = 0.01),\n    loss = keras.losses.BinaryCrossentropy(),\n    metrics = [keras.metrics.BinaryAccuracy()]\n)\n\n\nhistory2 = model2.fit(inputs_arr, targets_arr, epochs=100, validation_split=0.2)\n\nEpoch 1/100\n50/50 [==============================] - 2s 8ms/step - loss: 0.5171 - binary_accuracy: 0.9000 - val_loss: 0.4495 - val_binary_accuracy: 0.9725\nEpoch 2/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.2978 - binary_accuracy: 0.9944 - val_loss: 0.3160 - val_binary_accuracy: 0.9800\nEpoch 3/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.2108 - binary_accuracy: 0.9950 - val_loss: 0.2446 - val_binary_accuracy: 0.9850\nEpoch 4/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.1650 - binary_accuracy: 0.9950 - val_loss: 0.2012 - val_binary_accuracy: 0.9900\nEpoch 5/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.1368 - binary_accuracy: 0.9956 - val_loss: 0.1720 - val_binary_accuracy: 0.9900\nEpoch 6/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.1176 - binary_accuracy: 0.9962 - val_loss: 0.1510 - val_binary_accuracy: 0.9900\nEpoch 7/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.1037 - binary_accuracy: 0.9962 - val_loss: 0.1352 - val_binary_accuracy: 0.9900\nEpoch 8/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0932 - binary_accuracy: 0.9969 - val_loss: 0.1230 - val_binary_accuracy: 0.9900\nEpoch 9/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0849 - binary_accuracy: 0.9969 - val_loss: 0.1131 - val_binary_accuracy: 0.9900\nEpoch 10/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0782 - binary_accuracy: 0.9969 - val_loss: 0.1050 - val_binary_accuracy: 0.9925\nEpoch 11/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0726 - binary_accuracy: 0.9962 - val_loss: 0.0983 - val_binary_accuracy: 0.9925\nEpoch 12/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0680 - binary_accuracy: 0.9962 - val_loss: 0.0926 - val_binary_accuracy: 0.9925\nEpoch 13/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0640 - binary_accuracy: 0.9962 - val_loss: 0.0876 - val_binary_accuracy: 0.9925\nEpoch 14/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0605 - binary_accuracy: 0.9962 - val_loss: 0.0833 - val_binary_accuracy: 0.9925\nEpoch 15/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0575 - binary_accuracy: 0.9962 - val_loss: 0.0796 - val_binary_accuracy: 0.9925\nEpoch 16/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0549 - binary_accuracy: 0.9962 - val_loss: 0.0762 - val_binary_accuracy: 0.9925\nEpoch 17/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0525 - binary_accuracy: 0.9962 - val_loss: 0.0732 - val_binary_accuracy: 0.9925\nEpoch 18/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0504 - binary_accuracy: 0.9969 - val_loss: 0.0705 - val_binary_accuracy: 0.9925\nEpoch 19/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0485 - binary_accuracy: 0.9969 - val_loss: 0.0681 - val_binary_accuracy: 0.9925\nEpoch 20/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0468 - binary_accuracy: 0.9969 - val_loss: 0.0658 - val_binary_accuracy: 0.9925\nEpoch 21/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0452 - binary_accuracy: 0.9969 - val_loss: 0.0638 - val_binary_accuracy: 0.9925\nEpoch 22/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0438 - binary_accuracy: 0.9969 - val_loss: 0.0620 - val_binary_accuracy: 0.9925\nEpoch 23/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0425 - binary_accuracy: 0.9969 - val_loss: 0.0603 - val_binary_accuracy: 0.9925\nEpoch 24/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0413 - binary_accuracy: 0.9969 - val_loss: 0.0587 - val_binary_accuracy: 0.9925\nEpoch 25/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0401 - binary_accuracy: 0.9969 - val_loss: 0.0572 - val_binary_accuracy: 0.9925\nEpoch 26/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0391 - binary_accuracy: 0.9969 - val_loss: 0.0559 - val_binary_accuracy: 0.9925\nEpoch 27/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0381 - binary_accuracy: 0.9969 - val_loss: 0.0546 - val_binary_accuracy: 0.9925\nEpoch 28/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0372 - binary_accuracy: 0.9969 - val_loss: 0.0534 - val_binary_accuracy: 0.9925\nEpoch 29/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0364 - binary_accuracy: 0.9969 - val_loss: 0.0523 - val_binary_accuracy: 0.9925\nEpoch 30/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0356 - binary_accuracy: 0.9969 - val_loss: 0.0512 - val_binary_accuracy: 0.9925\nEpoch 31/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0348 - binary_accuracy: 0.9969 - val_loss: 0.0503 - val_binary_accuracy: 0.9925\nEpoch 32/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0341 - binary_accuracy: 0.9969 - val_loss: 0.0493 - val_binary_accuracy: 0.9925\nEpoch 33/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0334 - binary_accuracy: 0.9969 - val_loss: 0.0484 - val_binary_accuracy: 0.9925\nEpoch 34/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0328 - binary_accuracy: 0.9969 - val_loss: 0.0476 - val_binary_accuracy: 0.9925\nEpoch 35/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0322 - binary_accuracy: 0.9969 - val_loss: 0.0468 - val_binary_accuracy: 0.9925\nEpoch 36/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0317 - binary_accuracy: 0.9975 - val_loss: 0.0460 - val_binary_accuracy: 0.9925\nEpoch 37/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0311 - binary_accuracy: 0.9975 - val_loss: 0.0453 - val_binary_accuracy: 0.9925\nEpoch 38/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0306 - binary_accuracy: 0.9975 - val_loss: 0.0446 - val_binary_accuracy: 0.9925\nEpoch 39/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0301 - binary_accuracy: 0.9975 - val_loss: 0.0440 - val_binary_accuracy: 0.9925\nEpoch 40/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0296 - binary_accuracy: 0.9975 - val_loss: 0.0433 - val_binary_accuracy: 0.9925\nEpoch 41/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0292 - binary_accuracy: 0.9975 - val_loss: 0.0427 - val_binary_accuracy: 0.9925\nEpoch 42/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0288 - binary_accuracy: 0.9975 - val_loss: 0.0422 - val_binary_accuracy: 0.9925\nEpoch 43/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0284 - binary_accuracy: 0.9975 - val_loss: 0.0416 - val_binary_accuracy: 0.9925\nEpoch 44/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0280 - binary_accuracy: 0.9975 - val_loss: 0.0411 - val_binary_accuracy: 0.9925\nEpoch 45/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0276 - binary_accuracy: 0.9975 - val_loss: 0.0406 - val_binary_accuracy: 0.9925\nEpoch 46/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0272 - binary_accuracy: 0.9975 - val_loss: 0.0401 - val_binary_accuracy: 0.9925\nEpoch 47/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0269 - binary_accuracy: 0.9975 - val_loss: 0.0396 - val_binary_accuracy: 0.9925\nEpoch 48/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0266 - binary_accuracy: 0.9975 - val_loss: 0.0392 - val_binary_accuracy: 0.9925\nEpoch 49/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0262 - binary_accuracy: 0.9975 - val_loss: 0.0388 - val_binary_accuracy: 0.9925\nEpoch 50/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0259 - binary_accuracy: 0.9975 - val_loss: 0.0383 - val_binary_accuracy: 0.9925\nEpoch 51/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0256 - binary_accuracy: 0.9975 - val_loss: 0.0379 - val_binary_accuracy: 0.9925\nEpoch 52/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0254 - binary_accuracy: 0.9975 - val_loss: 0.0375 - val_binary_accuracy: 0.9925\nEpoch 53/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0251 - binary_accuracy: 0.9975 - val_loss: 0.0372 - val_binary_accuracy: 0.9925\nEpoch 54/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0248 - binary_accuracy: 0.9975 - val_loss: 0.0368 - val_binary_accuracy: 0.9925\nEpoch 55/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0245 - binary_accuracy: 0.9975 - val_loss: 0.0364 - val_binary_accuracy: 0.9925\nEpoch 56/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0243 - binary_accuracy: 0.9975 - val_loss: 0.0361 - val_binary_accuracy: 0.9925\nEpoch 57/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0241 - binary_accuracy: 0.9975 - val_loss: 0.0358 - val_binary_accuracy: 0.9925\nEpoch 58/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0238 - binary_accuracy: 0.9975 - val_loss: 0.0354 - val_binary_accuracy: 0.9925\nEpoch 59/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0236 - binary_accuracy: 0.9975 - val_loss: 0.0351 - val_binary_accuracy: 0.9925\nEpoch 60/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0234 - binary_accuracy: 0.9975 - val_loss: 0.0348 - val_binary_accuracy: 0.9925\nEpoch 61/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0232 - binary_accuracy: 0.9975 - val_loss: 0.0345 - val_binary_accuracy: 0.9925\nEpoch 62/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0230 - binary_accuracy: 0.9975 - val_loss: 0.0342 - val_binary_accuracy: 0.9925\nEpoch 63/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0228 - binary_accuracy: 0.9975 - val_loss: 0.0340 - val_binary_accuracy: 0.9925\nEpoch 64/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0226 - binary_accuracy: 0.9975 - val_loss: 0.0337 - val_binary_accuracy: 0.9925\nEpoch 65/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0224 - binary_accuracy: 0.9975 - val_loss: 0.0334 - val_binary_accuracy: 0.9925\nEpoch 66/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0222 - binary_accuracy: 0.9975 - val_loss: 0.0332 - val_binary_accuracy: 0.9925\nEpoch 67/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0220 - binary_accuracy: 0.9975 - val_loss: 0.0329 - val_binary_accuracy: 0.9925\nEpoch 68/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0218 - binary_accuracy: 0.9975 - val_loss: 0.0327 - val_binary_accuracy: 0.9925\nEpoch 69/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0217 - binary_accuracy: 0.9975 - val_loss: 0.0325 - val_binary_accuracy: 0.9925\nEpoch 70/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0215 - binary_accuracy: 0.9975 - val_loss: 0.0322 - val_binary_accuracy: 0.9925\nEpoch 71/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0213 - binary_accuracy: 0.9975 - val_loss: 0.0320 - val_binary_accuracy: 0.9925\nEpoch 72/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0212 - binary_accuracy: 0.9975 - val_loss: 0.0318 - val_binary_accuracy: 0.9925\nEpoch 73/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0210 - binary_accuracy: 0.9975 - val_loss: 0.0316 - val_binary_accuracy: 0.9925\nEpoch 74/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0209 - binary_accuracy: 0.9975 - val_loss: 0.0314 - val_binary_accuracy: 0.9925\nEpoch 75/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0207 - binary_accuracy: 0.9975 - val_loss: 0.0312 - val_binary_accuracy: 0.9925\nEpoch 76/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0206 - binary_accuracy: 0.9975 - val_loss: 0.0310 - val_binary_accuracy: 0.9925\nEpoch 77/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0204 - binary_accuracy: 0.9975 - val_loss: 0.0308 - val_binary_accuracy: 0.9925\nEpoch 78/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0203 - binary_accuracy: 0.9975 - val_loss: 0.0306 - val_binary_accuracy: 0.9925\nEpoch 79/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0202 - binary_accuracy: 0.9975 - val_loss: 0.0304 - val_binary_accuracy: 0.9925\nEpoch 80/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0200 - binary_accuracy: 0.9975 - val_loss: 0.0302 - val_binary_accuracy: 0.9925\nEpoch 81/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0199 - binary_accuracy: 0.9975 - val_loss: 0.0300 - val_binary_accuracy: 0.9925\nEpoch 82/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0198 - binary_accuracy: 0.9975 - val_loss: 0.0298 - val_binary_accuracy: 0.9925\nEpoch 83/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0197 - binary_accuracy: 0.9975 - val_loss: 0.0297 - val_binary_accuracy: 0.9925\nEpoch 84/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0195 - binary_accuracy: 0.9975 - val_loss: 0.0295 - val_binary_accuracy: 0.9925\nEpoch 85/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0194 - binary_accuracy: 0.9975 - val_loss: 0.0293 - val_binary_accuracy: 0.9925\nEpoch 86/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0193 - binary_accuracy: 0.9975 - val_loss: 0.0292 - val_binary_accuracy: 0.9925\nEpoch 87/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0192 - binary_accuracy: 0.9975 - val_loss: 0.0290 - val_binary_accuracy: 0.9925\nEpoch 88/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0191 - binary_accuracy: 0.9975 - val_loss: 0.0289 - val_binary_accuracy: 0.9925\nEpoch 89/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0190 - binary_accuracy: 0.9975 - val_loss: 0.0287 - val_binary_accuracy: 0.9925\nEpoch 90/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0189 - binary_accuracy: 0.9975 - val_loss: 0.0286 - val_binary_accuracy: 0.9925\nEpoch 91/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0188 - binary_accuracy: 0.9975 - val_loss: 0.0284 - val_binary_accuracy: 0.9925\nEpoch 92/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0187 - binary_accuracy: 0.9975 - val_loss: 0.0283 - val_binary_accuracy: 0.9925\nEpoch 93/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0186 - binary_accuracy: 0.9975 - val_loss: 0.0281 - val_binary_accuracy: 0.9925\nEpoch 94/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0185 - binary_accuracy: 0.9975 - val_loss: 0.0280 - val_binary_accuracy: 0.9925\nEpoch 95/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0184 - binary_accuracy: 0.9975 - val_loss: 0.0279 - val_binary_accuracy: 0.9925\nEpoch 96/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0183 - binary_accuracy: 0.9975 - val_loss: 0.0277 - val_binary_accuracy: 0.9925\nEpoch 97/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0182 - binary_accuracy: 0.9975 - val_loss: 0.0276 - val_binary_accuracy: 0.9925\nEpoch 98/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0181 - binary_accuracy: 0.9975 - val_loss: 0.0275 - val_binary_accuracy: 0.9925\nEpoch 99/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0180 - binary_accuracy: 0.9975 - val_loss: 0.0273 - val_binary_accuracy: 0.9925\nEpoch 100/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0179 - binary_accuracy: 0.9975 - val_loss: 0.0272 - val_binary_accuracy: 0.9925\n\n\n\npd.DataFrame(history2.history).to_csv(\"./keras_subclassing_history2.csv\", index=False)\n\nSilakan download kalau mau menyocokkan/membandingkan dengan modul: keras_subclassing_history2.csv\n\nhistory2_df = pd.read_csv(\"./keras_subclassing_history2.csv\")\n\n\nplt.plot(history2_df[\"loss\"], label = \"training loss\")\nplt.plot(history2_df[\"val_loss\"], label = \"validation loss\")\nplt.xlabel(\"epoch\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nSebenarnya, kalian bisa saja menggunakan Functional API di dalam class: siapkan fungsi-fungsinya di dalam constructor __init__ dan gunakan di dalam call\n\nclass MyPerceptron_v2(keras.Model):\n    def __init__(self, units=1):\n        super().__init__()\n\n        # banyaknya neuron di output layer\n        self.units = units\n        \n        # siapkan fungsi\n        self.layer1_func = keras.layers.Dense(\n            units = self.units,\n            activation = keras.activations.sigmoid\n        )\n\n    # forward pass\n    def call(self, inputs):\n        x = self.layer1_func(inputs)\n        return x"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul8.html#contoh-skip-connection-dengan-functional-api",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul8.html#contoh-skip-connection-dengan-functional-api",
    "title": "Modul 8 Praktikum Sains Data: Deep Learning dengan Keras, Regresi dan Klasifikasi Gambar",
    "section": "",
    "text": "Kita lihat lagi gambar skip connection:\n\nSumber gambar: Aggarwal (2018) hal. 348\nDari gambarnya, kita bisa coba susun neural network nya:\n\n# x\nf3_input = keras.layers.Input(shape = (5,))\n\n# weight layers\nf3_layer1_func = keras.layers.Dense(units = 10, activation = keras.activations.linear)\nf3_layer2_func = keras.layers.Dense(units = 5, activation = keras.activations.relu)\n\n# F(x)\nF_out = f3_layer2_func(f3_layer1_func(f3_input))\n\n# F(x) + x\nf3_layer3_out = F_out + f3_input\n\n# membuat model akhir\nmodel3 = keras.Model(inputs=f3_input, outputs=f3_layer3_out, name=\"model3\")\n\n\nmodel3.summary()\n\nModel: \"model3\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_7 (InputLayer)           [(None, 5)]          0           []                               \n                                                                                                  \n dense_9 (Dense)                (None, 10)           60          ['input_7[0][0]']                \n                                                                                                  \n dense_10 (Dense)               (None, 5)            55          ['dense_9[0][0]']                \n                                                                                                  \n tf.__operators__.add_3 (TFOpLa  (None, 5)           0           ['dense_10[0][0]',               \n mbda)                                                            'input_7[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 115\nTrainable params: 115\nNon-trainable params: 0\n__________________________________________________________________________________________________\n\n\n\nkeras.utils.plot_model(\n    model3,\n    show_shapes = True,\n    show_layer_activations = True,\n    to_file = \"keras_functional_model3.png\"\n)\n\n\nApabila kode Functional API itu disusun ke dalam class, kodenya bisa menjadi seperti berikut:\n\nclass MySkipConnection(keras.Model):\n    def __init__(self, units=5):\n        super().__init__()\n\n        # banyaknya neuron di output layer\n        self.units = units\n        \n        # siapkan fungsi-fungsi\n        self.weight1_func = keras.layers.Dense(\n            units = 10,\n            activation = keras.activations.linear\n        )\n        self.weight2_func = keras.layers.Dense(\n            units = self.units,\n            activation = keras.activations.relu\n        )\n\n    # forward pass\n    def call(self, inputs):\n        F_x = self.weight2_func(self.weight1_func(inputs))\n        x = inputs\n        hasil = F_x + x\n        return hasil"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul8.html#neural-network-untuk-regresi",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul8.html#neural-network-untuk-regresi",
    "title": "Modul 8 Praktikum Sains Data: Deep Learning dengan Keras, Regresi dan Klasifikasi Gambar",
    "section": "",
    "text": "Ingat kembali, untuk regresi,\n\nbanyaknya neuron di input layer sesuai banyaknya fitur/variabel prediktor\nbanyaknya neuron di output layer sesuai banyaknya fitur/variabel target (biasanya hanya satu), dan fungsi aktivasi yang digunakan adalah fungsi aktivasi linier/identitas\nfungsi aktivasi untuk semua hidden layer biasanya ReLU\n\nKita akan coba lagi dataset “California Housing Prices” (housing.csv) yang sudah kita gunakan di Modul 4 tentang regresi, yang bisa didownload dari salah satu sumber berikut:\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle: https://www.kaggle.com/datasets/camnugent/california-housing-prices\n\nMari kita lihat isinya\n\nhousing_df = pd.read_csv(\"./housing.csv\")\n\n\nhousing_df\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\nocean_proximity\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\nNEAR BAY\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\nNEAR BAY\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\nNEAR BAY\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\nNEAR BAY\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\nNEAR BAY\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\nINLAND\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\nINLAND\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\nINLAND\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\nINLAND\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\nINLAND\n\n\n\n\n20640 rows × 10 columns\n\n\n\nKalau mau, kalian bisa melakukan encoding data kategorik ocean_proximity seperti di Modul 3. Tapi kali ini kita hapus/drop saja\n\nhousing_df = housing_df.drop(columns=[\"ocean_proximity\"])\n\n\nhousing_df\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n\n\n\n\n20640 rows × 9 columns\n\n\n\nIngat bahwa variabel target (variabel yang ingin kita prediksi) adalah median_house_value. Kita pisah dulu antara variabel prediktor (X atau inputs) dan variabel target (y atau target)\n\nhousing_X_df = housing_df.drop(columns=[\"median_house_value\"])\nhousing_y_df = housing_df[[\"median_house_value\"]]\n\nLalu kita ubah jadi numpy array agar bisa diolah Keras\n\nhousing_X_arr = housing_X_df.to_numpy()\nhousing_y_arr = housing_y_df.to_numpy()\n\n\nprint(housing_X_arr.shape)\nprint(housing_y_arr.shape)\n\n(20640, 8)\n(20640, 1)\n\n\nTrain test split, standarisasi:\n\nfrom sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n    housing_X_arr, housing_y_arr, test_size=0.1, random_state=42\n)\n\n\nfrom sklearn.preprocessing import StandardScaler\n\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nData target juga relatif sangat besar, sehingga sebaiknya kita scaling juga:\n\nprint(f'y min: {y_train.min()}')\nprint(f'y max: {y_train.max()}')\n\ny min: 14999.0\ny max: 500001.0\n\n\n\ny_train /= 100000\ny_test /= 100000\n\n\nprint(f'y min: {y_train.min()}')\nprint(f'y max: {y_train.max()}')\n\ny min: 0.14999\ny max: 5.00001\n\n\nSekarang kita bisa susun modelnya\n\nkeras.backend.clear_session()\n\n\nmodel4 = keras.Sequential(\n    [\n        keras.layers.InputLayer(input_shape = (housing_X_arr.shape[1:])),\n        keras.layers.Dense(units = 15, activation = keras.activations.relu),\n        keras.layers.Dense(units = 30, activation = keras.activations.relu),\n        keras.layers.Dense(units = 1, activation = keras.activations.linear)\n    ]\n)\n\n\nmodel4.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 15)                135       \n                                                                 \n dense_1 (Dense)             (None, 30)                480       \n                                                                 \n dense_2 (Dense)             (None, 1)                 31        \n                                                                 \n=================================================================\nTotal params: 646\nTrainable params: 646\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nkeras.utils.plot_model(\n    model4,\n    show_shapes = True,\n    show_layer_activations = True,\n    to_file = \"keras_sequential_model4.png\"\n)\n\n\nSelanjutnya, kita tentukan hyperparameter: optimizer, loss function, dan accuracy.\nIngat kembali, untuk regresi, loss function yang biasa digunakan adalah MSE (Mean Squared Error)\n\nearly_stop = keras.callbacks.EarlyStopping(\n    patience=5, monitor='val_loss', restore_best_weights=True, verbose=1\n)\n\n\nmodel4.compile(\n    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n    loss = keras.losses.MeanSquaredError(),\n    metrics = [keras.metrics.Accuracy()]\n)\n\n\nhistory4 = model4.fit(X_train, y_train, epochs=100, validation_split=1/9)\n\nEpoch 1/100\n516/516 [==============================] - 6s 4ms/step - loss: 0.8861 - accuracy: 0.0000e+00 - val_loss: 0.4775 - val_accuracy: 0.0000e+00\nEpoch 2/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.4211 - accuracy: 0.0000e+00 - val_loss: 0.4415 - val_accuracy: 0.0000e+00\nEpoch 3/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.3904 - accuracy: 0.0000e+00 - val_loss: 0.4295 - val_accuracy: 0.0000e+00\nEpoch 4/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.3753 - accuracy: 0.0000e+00 - val_loss: 0.4221 - val_accuracy: 0.0000e+00\nEpoch 5/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3670 - accuracy: 0.0000e+00 - val_loss: 0.4116 - val_accuracy: 0.0000e+00\nEpoch 6/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3581 - accuracy: 0.0000e+00 - val_loss: 0.3995 - val_accuracy: 0.0000e+00\nEpoch 7/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.3498 - accuracy: 0.0000e+00 - val_loss: 0.4065 - val_accuracy: 0.0000e+00\nEpoch 8/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3453 - accuracy: 0.0000e+00 - val_loss: 0.3874 - val_accuracy: 0.0000e+00\nEpoch 9/100\n516/516 [==============================] - 3s 5ms/step - loss: 0.3418 - accuracy: 0.0000e+00 - val_loss: 0.3839 - val_accuracy: 0.0000e+00\nEpoch 10/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3361 - accuracy: 0.0000e+00 - val_loss: 0.3779 - val_accuracy: 0.0000e+00\nEpoch 11/100\n516/516 [==============================] - 2s 5ms/step - loss: 0.3321 - accuracy: 0.0000e+00 - val_loss: 0.3782 - val_accuracy: 0.0000e+00\nEpoch 12/100\n516/516 [==============================] - 3s 5ms/step - loss: 0.3294 - accuracy: 0.0000e+00 - val_loss: 0.3718 - val_accuracy: 0.0000e+00\nEpoch 13/100\n516/516 [==============================] - 3s 6ms/step - loss: 0.3266 - accuracy: 0.0000e+00 - val_loss: 0.3698 - val_accuracy: 0.0000e+00\nEpoch 14/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3236 - accuracy: 0.0000e+00 - val_loss: 0.3614 - val_accuracy: 0.0000e+00\nEpoch 15/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.3205 - accuracy: 0.0000e+00 - val_loss: 0.3583 - val_accuracy: 0.0000e+00\nEpoch 16/100\n516/516 [==============================] - 1s 2ms/step - loss: 0.3189 - accuracy: 0.0000e+00 - val_loss: 0.3548 - val_accuracy: 0.0000e+00\nEpoch 17/100\n516/516 [==============================] - 1s 2ms/step - loss: 0.3173 - accuracy: 0.0000e+00 - val_loss: 0.3593 - val_accuracy: 0.0000e+00\nEpoch 18/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3150 - accuracy: 0.0000e+00 - val_loss: 0.3563 - val_accuracy: 0.0000e+00\nEpoch 19/100\n516/516 [==============================] - 4s 7ms/step - loss: 0.3137 - accuracy: 0.0000e+00 - val_loss: 0.3513 - val_accuracy: 0.0000e+00\nEpoch 20/100\n516/516 [==============================] - 3s 5ms/step - loss: 0.3141 - accuracy: 0.0000e+00 - val_loss: 0.3485 - val_accuracy: 0.0000e+00\nEpoch 21/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3105 - accuracy: 0.0000e+00 - val_loss: 0.3484 - val_accuracy: 0.0000e+00\nEpoch 22/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3098 - accuracy: 0.0000e+00 - val_loss: 0.3474 - val_accuracy: 0.0000e+00\nEpoch 23/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3082 - accuracy: 0.0000e+00 - val_loss: 0.3494 - val_accuracy: 0.0000e+00\nEpoch 24/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3068 - accuracy: 0.0000e+00 - val_loss: 0.3416 - val_accuracy: 0.0000e+00\nEpoch 25/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3055 - accuracy: 0.0000e+00 - val_loss: 0.3426 - val_accuracy: 0.0000e+00\nEpoch 26/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3041 - accuracy: 0.0000e+00 - val_loss: 0.3432 - val_accuracy: 0.0000e+00\nEpoch 27/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.3003 - accuracy: 0.0000e+00 - val_loss: 0.3551 - val_accuracy: 0.0000e+00\nEpoch 28/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2998 - accuracy: 0.0000e+00 - val_loss: 0.3423 - val_accuracy: 0.0000e+00\nEpoch 29/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2984 - accuracy: 0.0000e+00 - val_loss: 0.3338 - val_accuracy: 0.0000e+00\nEpoch 30/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2968 - accuracy: 0.0000e+00 - val_loss: 0.3331 - val_accuracy: 0.0000e+00\nEpoch 31/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2948 - accuracy: 0.0000e+00 - val_loss: 0.3368 - val_accuracy: 0.0000e+00\nEpoch 32/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2939 - accuracy: 0.0000e+00 - val_loss: 0.3339 - val_accuracy: 0.0000e+00\nEpoch 33/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2924 - accuracy: 0.0000e+00 - val_loss: 0.3331 - val_accuracy: 0.0000e+00\nEpoch 34/100\n516/516 [==============================] - 3s 5ms/step - loss: 0.2933 - accuracy: 0.0000e+00 - val_loss: 0.3285 - val_accuracy: 0.0000e+00\nEpoch 35/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2917 - accuracy: 0.0000e+00 - val_loss: 0.3297 - val_accuracy: 0.0000e+00\nEpoch 36/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2919 - accuracy: 0.0000e+00 - val_loss: 0.3286 - val_accuracy: 0.0000e+00\nEpoch 37/100\n516/516 [==============================] - 1s 3ms/step - loss: 0.2910 - accuracy: 0.0000e+00 - val_loss: 0.3300 - val_accuracy: 0.0000e+00\nEpoch 38/100\n516/516 [==============================] - 3s 5ms/step - loss: 0.2895 - accuracy: 0.0000e+00 - val_loss: 0.3233 - val_accuracy: 0.0000e+00\nEpoch 39/100\n516/516 [==============================] - 2s 5ms/step - loss: 0.2892 - accuracy: 0.0000e+00 - val_loss: 0.3315 - val_accuracy: 0.0000e+00\nEpoch 40/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2885 - accuracy: 0.0000e+00 - val_loss: 0.3253 - val_accuracy: 0.0000e+00\nEpoch 41/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2880 - accuracy: 0.0000e+00 - val_loss: 0.3366 - val_accuracy: 0.0000e+00\nEpoch 42/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2871 - accuracy: 0.0000e+00 - val_loss: 0.3257 - val_accuracy: 0.0000e+00\nEpoch 43/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2851 - accuracy: 0.0000e+00 - val_loss: 0.3200 - val_accuracy: 0.0000e+00\nEpoch 44/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2855 - accuracy: 0.0000e+00 - val_loss: 0.3179 - val_accuracy: 0.0000e+00\nEpoch 45/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2856 - accuracy: 0.0000e+00 - val_loss: 0.3165 - val_accuracy: 0.0000e+00\nEpoch 46/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2838 - accuracy: 0.0000e+00 - val_loss: 0.3145 - val_accuracy: 0.0000e+00\nEpoch 47/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2839 - accuracy: 0.0000e+00 - val_loss: 0.3287 - val_accuracy: 0.0000e+00\nEpoch 48/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2827 - accuracy: 0.0000e+00 - val_loss: 0.3291 - val_accuracy: 0.0000e+00\nEpoch 49/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2835 - accuracy: 0.0000e+00 - val_loss: 0.3196 - val_accuracy: 0.0000e+00\nEpoch 50/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2807 - accuracy: 0.0000e+00 - val_loss: 0.3111 - val_accuracy: 0.0000e+00\nEpoch 51/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2819 - accuracy: 0.0000e+00 - val_loss: 0.3354 - val_accuracy: 0.0000e+00\nEpoch 52/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2811 - accuracy: 0.0000e+00 - val_loss: 0.3170 - val_accuracy: 0.0000e+00\nEpoch 53/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2800 - accuracy: 0.0000e+00 - val_loss: 0.3158 - val_accuracy: 0.0000e+00\nEpoch 54/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2791 - accuracy: 0.0000e+00 - val_loss: 0.3152 - val_accuracy: 0.0000e+00\nEpoch 55/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2796 - accuracy: 0.0000e+00 - val_loss: 0.3158 - val_accuracy: 0.0000e+00\nEpoch 56/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2796 - accuracy: 0.0000e+00 - val_loss: 0.3164 - val_accuracy: 0.0000e+00\nEpoch 57/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2802 - accuracy: 0.0000e+00 - val_loss: 0.3070 - val_accuracy: 0.0000e+00\nEpoch 58/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2775 - accuracy: 0.0000e+00 - val_loss: 0.3103 - val_accuracy: 0.0000e+00\nEpoch 59/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2780 - accuracy: 0.0000e+00 - val_loss: 0.3108 - val_accuracy: 0.0000e+00\nEpoch 60/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2779 - accuracy: 0.0000e+00 - val_loss: 0.3056 - val_accuracy: 0.0000e+00\nEpoch 61/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2766 - accuracy: 0.0000e+00 - val_loss: 0.3087 - val_accuracy: 0.0000e+00\nEpoch 62/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2762 - accuracy: 0.0000e+00 - val_loss: 0.3094 - val_accuracy: 0.0000e+00\nEpoch 63/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2759 - accuracy: 0.0000e+00 - val_loss: 0.3117 - val_accuracy: 0.0000e+00\nEpoch 64/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2761 - accuracy: 0.0000e+00 - val_loss: 0.3026 - val_accuracy: 0.0000e+00\nEpoch 65/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2738 - accuracy: 0.0000e+00 - val_loss: 0.3146 - val_accuracy: 0.0000e+00\nEpoch 66/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2745 - accuracy: 0.0000e+00 - val_loss: 0.3051 - val_accuracy: 0.0000e+00\nEpoch 67/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2747 - accuracy: 0.0000e+00 - val_loss: 0.3139 - val_accuracy: 0.0000e+00\nEpoch 68/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2746 - accuracy: 0.0000e+00 - val_loss: 0.3098 - val_accuracy: 0.0000e+00\nEpoch 69/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2744 - accuracy: 0.0000e+00 - val_loss: 0.3069 - val_accuracy: 0.0000e+00\nEpoch 70/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2737 - accuracy: 0.0000e+00 - val_loss: 0.3083 - val_accuracy: 0.0000e+00\nEpoch 71/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2727 - accuracy: 0.0000e+00 - val_loss: 0.3110 - val_accuracy: 0.0000e+00\nEpoch 72/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2734 - accuracy: 0.0000e+00 - val_loss: 0.3095 - val_accuracy: 0.0000e+00\nEpoch 73/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2715 - accuracy: 6.0562e-05 - val_loss: 0.3102 - val_accuracy: 0.0000e+00\nEpoch 74/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2709 - accuracy: 0.0000e+00 - val_loss: 0.3093 - val_accuracy: 0.0000e+00\nEpoch 75/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2713 - accuracy: 0.0000e+00 - val_loss: 0.3006 - val_accuracy: 0.0000e+00\nEpoch 76/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2704 - accuracy: 0.0000e+00 - val_loss: 0.2985 - val_accuracy: 0.0000e+00\nEpoch 77/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2704 - accuracy: 0.0000e+00 - val_loss: 0.2987 - val_accuracy: 0.0000e+00\nEpoch 78/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2682 - accuracy: 0.0000e+00 - val_loss: 0.2959 - val_accuracy: 0.0000e+00\nEpoch 79/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2692 - accuracy: 0.0000e+00 - val_loss: 0.3003 - val_accuracy: 0.0000e+00\nEpoch 80/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2693 - accuracy: 0.0000e+00 - val_loss: 0.2978 - val_accuracy: 0.0000e+00\nEpoch 81/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2689 - accuracy: 0.0000e+00 - val_loss: 0.2991 - val_accuracy: 0.0000e+00\nEpoch 82/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2667 - accuracy: 0.0000e+00 - val_loss: 0.2978 - val_accuracy: 0.0000e+00\nEpoch 83/100\n516/516 [==============================] - 2s 5ms/step - loss: 0.2688 - accuracy: 0.0000e+00 - val_loss: 0.3050 - val_accuracy: 0.0000e+00\nEpoch 84/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2678 - accuracy: 0.0000e+00 - val_loss: 0.2974 - val_accuracy: 0.0000e+00\nEpoch 85/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2669 - accuracy: 0.0000e+00 - val_loss: 0.2992 - val_accuracy: 0.0000e+00\nEpoch 86/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2675 - accuracy: 0.0000e+00 - val_loss: 0.2976 - val_accuracy: 0.0000e+00\nEpoch 87/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2664 - accuracy: 0.0000e+00 - val_loss: 0.2989 - val_accuracy: 0.0000e+00\nEpoch 88/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2659 - accuracy: 0.0000e+00 - val_loss: 0.3006 - val_accuracy: 0.0000e+00\nEpoch 89/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2664 - accuracy: 0.0000e+00 - val_loss: 0.3128 - val_accuracy: 0.0000e+00\nEpoch 90/100\n516/516 [==============================] - 2s 3ms/step - loss: 0.2664 - accuracy: 0.0000e+00 - val_loss: 0.2985 - val_accuracy: 0.0000e+00\nEpoch 91/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2657 - accuracy: 0.0000e+00 - val_loss: 0.2959 - val_accuracy: 0.0000e+00\nEpoch 92/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2651 - accuracy: 0.0000e+00 - val_loss: 0.2977 - val_accuracy: 0.0000e+00\nEpoch 93/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2650 - accuracy: 0.0000e+00 - val_loss: 0.2915 - val_accuracy: 0.0000e+00\nEpoch 94/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2656 - accuracy: 0.0000e+00 - val_loss: 0.2995 - val_accuracy: 0.0000e+00\nEpoch 95/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2648 - accuracy: 0.0000e+00 - val_loss: 0.2937 - val_accuracy: 0.0000e+00\nEpoch 96/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2646 - accuracy: 0.0000e+00 - val_loss: 0.3010 - val_accuracy: 0.0000e+00\nEpoch 97/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2638 - accuracy: 0.0000e+00 - val_loss: 0.2958 - val_accuracy: 0.0000e+00\nEpoch 98/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2651 - accuracy: 0.0000e+00 - val_loss: 0.2996 - val_accuracy: 0.0000e+00\nEpoch 99/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2640 - accuracy: 0.0000e+00 - val_loss: 0.3002 - val_accuracy: 0.0000e+00\nEpoch 100/100\n516/516 [==============================] - 2s 4ms/step - loss: 0.2636 - accuracy: 0.0000e+00 - val_loss: 0.2936 - val_accuracy: 0.0000e+00\n\n\n\npd.DataFrame(history4.history).to_csv(\"./keras_sequential_history4.csv\", index=False)\n\nSilakan download kalau mau menyocokkan/membandingkan dengan modul: keras_sequential_history4.csv\n\nhistory4_df = pd.read_csv(\"./keras_sequential_history4.csv\")\n\n\nplt.plot(history4_df[\"loss\"], label = \"training loss\")\nplt.plot(history4_df[\"val_loss\"], label = \"validation loss\")\nplt.xlabel(\"epoch\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\ny_pred = model4.predict(X_test)\n\nplt.hist(y_pred, color='green', alpha=.6)\nplt.hist(y_test, color='blue', alpha=.6)\nplt.legend(['prediction', 'truth'], loc='upper right')\nplt.show()\n\n65/65 [==============================] - 1s 5ms/step"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul8.html#klasifikasi-gambar-dengan-flatten",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul8.html#klasifikasi-gambar-dengan-flatten",
    "title": "Modul 8 Praktikum Sains Data: Deep Learning dengan Keras, Regresi dan Klasifikasi Gambar",
    "section": "",
    "text": "Gambar atau citra (image) adalah sekumpulan pixel yang disusun secara dua dimensi. Sejauh ini, neural network yang kita pelajari memiliki satu input layer yang “flat” atau datar. Sehingga, apabila kita ingin meng-input data citra ke dalam neural network, caranya adalah dengan flatten, yaitu data citra yang mula-mula dua dimensi itu disusun ulang menjadi satu dimensi.\nDi Keras, ada layer istimewa untuk melakukan flatten untuk gambar berukuran a kali b pixel:\nkeras.layers.Flatten(input_shape = (a, b))\nKetika berurusan dengan data citra, layer ini menggantikan InputLayer yang biasa kita gunakan.\n\n\nMari kita coba menggunakan dataset Fashion MNIST yang sudah tersedia dari Keras:\n\nfashion_mnist = keras.datasets.fashion_mnist\n(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n\n\nprint(f'X_train_full shape: {X_train_full.shape}')\nprint(f'y_train_full shape: {y_train_full.shape}')\nprint(f'X_test shape: {X_test.shape}')\nprint(f'y_test shape: {y_test.shape}')\n\nX_train_full shape: (60000, 28, 28)\ny_train_full shape: (60000,)\nX_test shape: (10000, 28, 28)\ny_test shape: (10000,)\n\n\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train_full, y_train_full, test_size=1/6, random_state=42\n)\n\nprint(f'X_train shape: {X_train.shape}')\nprint(f'y_train shape: {y_train.shape}')\nprint(f'X_val shape: {X_val.shape}')\nprint(f'y_val shape: {y_val.shape}')\nprint(f'X_test shape: {X_test.shape}')\nprint(f'y_test shape: {y_test.shape}')\n\nX_train shape: (50000, 28, 28)\ny_train shape: (50000,)\nX_val shape: (10000, 28, 28)\ny_val shape: (10000,)\nX_test shape: (10000, 28, 28)\ny_test shape: (10000,)\n\n\n\nX_train = X_train / 255\nX_val = X_val / 255\nX_test = X_test / 255\n\nAda 10 kelas:\n\nprint(set(y_train))\n\n{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n\n\n\nclass_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n\n\nprint(len(class_names))\n\n10\n\n\nKita lihat salah satu gambarnya:\n\n#@title Slider to look for some image examples {run: \"auto\"}\nidx = 21402 #@param {type:\"slider\", min:0, max:49999, step:1}\n\nplt.imshow(X_train[idx], cmap='gray')\nplt.title(class_names[y_train[idx]])\nplt.axis('OFF')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nmodel5 = keras.Sequential(\n    [\n        keras.layers.Flatten(input_shape=(28,28)),\n        keras.layers.Dense(units=100, activation=keras.activations.relu),\n        keras.layers.Dense(units=50, activation=keras.activations.relu),\n        keras.layers.Dense(units=10, activation=keras.activations.softmax)\n    ]\n)\n\n\nmodel5.compile(\n    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n    loss = keras.losses.SparseCategoricalCrossentropy(),\n    metrics = [keras.metrics.CategoricalAccuracy()]\n)\n\n\nmodel5.summary()\n\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten (Flatten)           (None, 784)               0         \n                                                                 \n dense_3 (Dense)             (None, 100)               78500     \n                                                                 \n dense_4 (Dense)             (None, 50)                5050      \n                                                                 \n dense_5 (Dense)             (None, 10)                510       \n                                                                 \n=================================================================\nTotal params: 84,060\nTrainable params: 84,060\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nhistory5 = model5.fit(\n    X_train, y_train, validation_data=(X_val, y_val),\n    epochs=50, batch_size=256\n)\n\nEpoch 1/50\n196/196 [==============================] - 5s 13ms/step - loss: 0.6641 - categorical_accuracy: 0.1050 - val_loss: 0.4997 - val_categorical_accuracy: 0.0831\nEpoch 2/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.4335 - categorical_accuracy: 0.1032 - val_loss: 0.4217 - val_categorical_accuracy: 0.1034\nEpoch 3/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.3868 - categorical_accuracy: 0.1032 - val_loss: 0.3928 - val_categorical_accuracy: 0.0899\nEpoch 4/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.3631 - categorical_accuracy: 0.1022 - val_loss: 0.3738 - val_categorical_accuracy: 0.0970\nEpoch 5/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.3410 - categorical_accuracy: 0.1022 - val_loss: 0.3662 - val_categorical_accuracy: 0.1274\nEpoch 6/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.3260 - categorical_accuracy: 0.1030 - val_loss: 0.3563 - val_categorical_accuracy: 0.1213\nEpoch 7/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.3113 - categorical_accuracy: 0.1023 - val_loss: 0.3779 - val_categorical_accuracy: 0.1185\nEpoch 8/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.2981 - categorical_accuracy: 0.1022 - val_loss: 0.3430 - val_categorical_accuracy: 0.1037\nEpoch 9/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2869 - categorical_accuracy: 0.1025 - val_loss: 0.3368 - val_categorical_accuracy: 0.1135\nEpoch 10/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.2813 - categorical_accuracy: 0.1025 - val_loss: 0.3477 - val_categorical_accuracy: 0.0992\nEpoch 11/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2738 - categorical_accuracy: 0.1021 - val_loss: 0.3513 - val_categorical_accuracy: 0.1056\nEpoch 12/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2614 - categorical_accuracy: 0.1021 - val_loss: 0.3279 - val_categorical_accuracy: 0.1111\nEpoch 13/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2564 - categorical_accuracy: 0.1021 - val_loss: 0.3229 - val_categorical_accuracy: 0.0928\nEpoch 14/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2518 - categorical_accuracy: 0.1019 - val_loss: 0.3353 - val_categorical_accuracy: 0.1203\nEpoch 15/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.2468 - categorical_accuracy: 0.1025 - val_loss: 0.3330 - val_categorical_accuracy: 0.1141\nEpoch 16/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2370 - categorical_accuracy: 0.1027 - val_loss: 0.3178 - val_categorical_accuracy: 0.0977\nEpoch 17/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.2313 - categorical_accuracy: 0.1012 - val_loss: 0.3160 - val_categorical_accuracy: 0.0982\nEpoch 18/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2243 - categorical_accuracy: 0.1024 - val_loss: 0.3269 - val_categorical_accuracy: 0.1197\nEpoch 19/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2198 - categorical_accuracy: 0.1020 - val_loss: 0.3248 - val_categorical_accuracy: 0.1101\nEpoch 20/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2151 - categorical_accuracy: 0.1022 - val_loss: 0.3217 - val_categorical_accuracy: 0.1045\nEpoch 21/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2112 - categorical_accuracy: 0.1010 - val_loss: 0.3300 - val_categorical_accuracy: 0.1171\nEpoch 22/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.2053 - categorical_accuracy: 0.1022 - val_loss: 0.3182 - val_categorical_accuracy: 0.1110\nEpoch 23/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.2010 - categorical_accuracy: 0.1018 - val_loss: 0.3216 - val_categorical_accuracy: 0.1026\nEpoch 24/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1988 - categorical_accuracy: 0.1014 - val_loss: 0.3371 - val_categorical_accuracy: 0.1178\nEpoch 25/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1914 - categorical_accuracy: 0.1020 - val_loss: 0.3260 - val_categorical_accuracy: 0.0944\nEpoch 26/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1910 - categorical_accuracy: 0.1021 - val_loss: 0.3283 - val_categorical_accuracy: 0.1058\nEpoch 27/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.1879 - categorical_accuracy: 0.1019 - val_loss: 0.3209 - val_categorical_accuracy: 0.1010\nEpoch 28/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1823 - categorical_accuracy: 0.1021 - val_loss: 0.3310 - val_categorical_accuracy: 0.1250\nEpoch 29/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1741 - categorical_accuracy: 0.1022 - val_loss: 0.3270 - val_categorical_accuracy: 0.1083\nEpoch 30/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1752 - categorical_accuracy: 0.1013 - val_loss: 0.3395 - val_categorical_accuracy: 0.1095\nEpoch 31/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1708 - categorical_accuracy: 0.1017 - val_loss: 0.3311 - val_categorical_accuracy: 0.1045\nEpoch 32/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1676 - categorical_accuracy: 0.1017 - val_loss: 0.3417 - val_categorical_accuracy: 0.0927\nEpoch 33/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1661 - categorical_accuracy: 0.1011 - val_loss: 0.3631 - val_categorical_accuracy: 0.1184\nEpoch 34/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1605 - categorical_accuracy: 0.1017 - val_loss: 0.3440 - val_categorical_accuracy: 0.1029\nEpoch 35/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1594 - categorical_accuracy: 0.1012 - val_loss: 0.3512 - val_categorical_accuracy: 0.1084\nEpoch 36/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1556 - categorical_accuracy: 0.1009 - val_loss: 0.3603 - val_categorical_accuracy: 0.1116\nEpoch 37/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1516 - categorical_accuracy: 0.1016 - val_loss: 0.3495 - val_categorical_accuracy: 0.1175\nEpoch 38/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1454 - categorical_accuracy: 0.1013 - val_loss: 0.3996 - val_categorical_accuracy: 0.1034\nEpoch 39/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1469 - categorical_accuracy: 0.1012 - val_loss: 0.3549 - val_categorical_accuracy: 0.1058\nEpoch 40/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1425 - categorical_accuracy: 0.1016 - val_loss: 0.3671 - val_categorical_accuracy: 0.1063\nEpoch 41/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.1396 - categorical_accuracy: 0.1013 - val_loss: 0.3639 - val_categorical_accuracy: 0.1009\nEpoch 42/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1383 - categorical_accuracy: 0.1012 - val_loss: 0.3912 - val_categorical_accuracy: 0.1223\nEpoch 43/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1350 - categorical_accuracy: 0.1011 - val_loss: 0.3731 - val_categorical_accuracy: 0.1065\nEpoch 44/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.1343 - categorical_accuracy: 0.1013 - val_loss: 0.3782 - val_categorical_accuracy: 0.1079\nEpoch 45/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.1311 - categorical_accuracy: 0.1005 - val_loss: 0.3870 - val_categorical_accuracy: 0.1125\nEpoch 46/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1257 - categorical_accuracy: 0.1013 - val_loss: 0.3707 - val_categorical_accuracy: 0.1047\nEpoch 47/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1232 - categorical_accuracy: 0.1011 - val_loss: 0.3853 - val_categorical_accuracy: 0.1067\nEpoch 48/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1203 - categorical_accuracy: 0.1009 - val_loss: 0.3793 - val_categorical_accuracy: 0.1061\nEpoch 49/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.1149 - categorical_accuracy: 0.1009 - val_loss: 0.3932 - val_categorical_accuracy: 0.1101\nEpoch 50/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1207 - categorical_accuracy: 0.1011 - val_loss: 0.3985 - val_categorical_accuracy: 0.1003\n\n\n\npd.DataFrame(history5.history).to_csv(\"./keras_sequential_history5.csv\", index=False)\n\nSilakan download kalau mau menyocokkan/membandingkan dengan modul: keras_sequential_history5.csv\n\nhistory5_df = pd.read_csv(\"./keras_sequential_history5.csv\")\n\n\nplt.plot(history5_df[\"loss\"], label = \"training loss\")\nplt.plot(history5_df[\"val_loss\"], label = \"validation loss\")\nplt.xlabel(\"epoch\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\ny_pred = model5.predict(X_test)\n\n313/313 [==============================] - 2s 7ms/step\n\n\n\ny_pred\n\narray([[7.3191592e-10, 4.9755400e-10, 2.0336069e-08, ..., 2.6508974e-04,\n        6.6600020e-10, 9.9970919e-01],\n       [1.0685701e-06, 1.3641132e-16, 9.9973696e-01, ..., 6.6150912e-25,\n        1.0635574e-14, 2.7912504e-22],\n       [3.8944440e-14, 1.0000000e+00, 7.2451013e-19, ..., 1.9461965e-25,\n        9.4534440e-24, 5.5635325e-28],\n       ...,\n       [6.9977574e-10, 8.2804253e-17, 9.0566991e-11, ..., 4.9004850e-12,\n        1.0000000e+00, 8.5710581e-16],\n       [8.6001712e-09, 9.9999988e-01, 2.2160624e-12, ..., 9.4472928e-21,\n        9.9464089e-13, 7.2510805e-17],\n       [2.2053911e-10, 1.0453890e-11, 9.8423698e-06, ..., 2.5791397e-07,\n        3.4278116e-10, 9.7139477e-11]], dtype=float32)\n\n\n\ny_pred[123]\n\narray([1.04234315e-19, 2.76166473e-17, 7.08109165e-22, 1.09880367e-13,\n       1.19973995e-17, 3.41231225e-15, 5.77217902e-19, 1.47765789e-07,\n       6.00817884e-14, 9.99999881e-01], dtype=float32)\n\n\n\nnp.argmax(y_pred[123])\n\n9\n\n\nKita bisa melihat hasil prediksi:\n\n#@title Slider to look for some prediction examples {run: \"auto\"}\nidx = 123 #@param {type:\"slider\", min:0, max:9999, step:1}\n\nplt.imshow(X_test[idx], cmap='gray')\nplt.title(\n    f\"Predicted class: {class_names[int(np.argmax(y_pred[idx]))]}\\n\" +\n    f\"True class: {class_names[y_test[idx]]}\"\n)\nplt.axis('OFF')\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul8.html#pengantar-cnn-convolutional-neural-network",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul8.html#pengantar-cnn-convolutional-neural-network",
    "title": "Modul 8 Praktikum Sains Data: Deep Learning dengan Keras, Regresi dan Klasifikasi Gambar",
    "section": "",
    "text": "Sebenarnya, menerima input gambar dengan teknik flatten itu kurang efektif.\n\nDengan dense layer, bahkan dua pixel yang sangat jauh itu juga terhubungkan, padahal seharusnya tidak berhubungan.\nKarena itu juga, tidak ada penekanan hubungan antara dua pixel yang saling berdekatan.\n\nAlangkah baiknya, ada teknik input gambar yang bisa mempertimbangkan bagaimana hubungan suatu pixel dengan pixel-pixel di sekitarnya saja, daripada dengan semua pixel.\nConvolutional Neural Network (CNN) mencoba mengatasi hal ini. Ciri khasnya adalah adanya dua jenis layer baru:\n\nconvolution layer\npooling layer, biasanya max pooling\n\nKedua layer baru ini bersifat sparse, yaitu beberapa neuron terhubung dengan beberapa neuron saja, tidak dengan semuanya.\nGambar berikut ini membandingkan antara sparse layer dengan dense layer:\n\nSumber gambar: Goodfellow, et. al. (2016) hal. 337\n\n\nSuatu convolution layer menghitung “konvolusi” (convolution).\n\nSumber gambar: Kotu, hal. 325\nPerhitungan konvolusi selalu melibatkan suatu “filter”, yang nilai-nilainya menjadi parameter (seperti weights and biases) yang terus di-update selama proses training.\n\nSumber gambar: Aggarwal (2018) hal. 321\nContoh perhitungan menggunakan filter bisa dilihat di gambar berikut.\n\nSumber gambar: Aggarwal (2018) hal. 336\nKetika menghitung konvolusi, filter selalu digeser. Pergeseran filter ini sebenarnya tidak harus satu langkah. Bisa saja, misalnya, dua langkah. Banyaknya langkah ini disebut stride.\n\nSumber gambar: Kotu, hal. 328\n\n\n\nDaripada menghitung konvolusi, pooling hanya menghitung statistik sederhana saja. Biasanya menghitung maksimum, yang disebut max pooling.\n\nSumber gambar: Kotu, hal. 328\n\n\n\nNote: aslinya, LeNet-5 menggunakan average pooling, yaitu menghitung rata-rata, tidak seperti max pooling yang memilih maksimum.\n\nSumber gambar: Aggarwal (2018) hal. 41\nArsitektur LeNet-5 menggunakan Keras bisa disusun sebagai berikut:\n\nlenet5 = keras.Sequential()\n\nlenet5.add(keras.layers.Conv2D(\n    input_shape = (32, 32, 1),\n    kernel_size = (5, 5),\n    filters = 6,\n    activation = keras.activations.sigmoid\n)) # menghasilkan C1 di gambar: ukuran 28 x 28 x 6\n\nlenet5.add(keras.layers.AveragePooling2D(\n    pool_size = (2, 2),\n    strides = 2\n)) # menghasilkan S2 di gambar: ukuran 14 x 14 x 6\n\nlenet5.add(keras.layers.Conv2D(\n    kernel_size = (5, 5),\n    filters = 16,\n    activation = keras.activations.sigmoid\n)) # menghasilkan C3 di gambar: ukuran 10 x 10 x 16\n\nlenet5.add(keras.layers.AveragePooling2D(\n    pool_size = (2, 2),\n    strides = 2\n)) # menghasilkan S4 di gambar: ukuran 5 x 5 x 16\n\nlenet5.add(keras.layers.Flatten())\n# menjadi C5 di gambar, dengan 400 neuron\n\nlenet5.add(keras.layers.Dense(\n    units = 120, activation = keras.activations.sigmoid\n))\n\nlenet5.add(keras.layers.Dense(\n    units = 84, activation = keras.activations.sigmoid\n))\n\nlenet5.add(keras.layers.Dense(\n    units = 10, activation = keras.activations.softmax\n))\n\n\nkeras.utils.plot_model(\n    lenet5,\n    show_shapes = True,\n    show_layer_activations = True,\n    to_file = \"keras_sequential_lenet5.png\"\n)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul8.html#referensi",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul8.html#referensi",
    "title": "Modul 8 Praktikum Sains Data: Deep Learning dengan Keras, Regresi dan Klasifikasi Gambar",
    "section": "",
    "text": "Sumber gambar\n\nAggarwal, C. Charu. 2018. Neural Networks and Deep Learning: A Textbook. Edisi Pertama. Springer.\nGoodfellow, Ian; Bengio, Yoshua; & Courville, Aaron. 2016. Deep Learning. MIT Press.\nKotu, Data Science Concepts and Practice"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul6.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul6.html",
    "title": "Modul 6 Praktikum Sains Data: K-Nearest Neighbor, K-Means Clustering",
    "section": "",
    "text": "Kembali ke Sains Data\n\n\n\nK-Nearest neighbor adalah salah satu jenis algoritma supervised learning. Biasanya, algoritma ini digunakan untuk masalah klasifikasi. Kelas dari data tersebut ditentukan dari sejumlah k titik yang berperan “tetangga”. Pada gambar di atas, ketika k = 3, bintang akan diklasifikasikan sebagai kelas ungu, sebab mayoritas dari tetangganya adalah ungu. Sedangkan, ketika k = 6, bintang akan diklasifikasikan sebagai kelas kuning.\n\n#import modul\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n%matplotlib inline\n\n\n\nPada module kali ini, akan digunakan data csv teleCust1000t (teleCust1000t.csv) yang bisa didownload dari:\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle: https://www.kaggle.com/code/zohaib123/telecusts-prediction-k-nearest-neighbors\n\n\n #membaca dataset\ndf = pd.read_csv('./teleCust1000t.csv')\ndf.head()\n\n\n\n\n\n\n\n\nregion\ntenure\nage\nmarital\naddress\nincome\ned\nemploy\nretire\ngender\nreside\ncustcat\n\n\n\n\n0\n2\n13\n44\n1\n9\n64.0\n4\n5\n0.0\n0\n2\n1\n\n\n1\n3\n11\n33\n1\n7\n136.0\n5\n5\n0.0\n0\n6\n4\n\n\n2\n3\n68\n52\n1\n24\n116.0\n1\n29\n0.0\n1\n2\n3\n\n\n3\n2\n33\n33\n0\n12\n33.0\n2\n0\n0.0\n1\n1\n1\n\n\n4\n2\n23\n30\n1\n9\n30.0\n1\n2\n0.0\n0\n4\n3\n\n\n\n\n\n\n\n\n#menghitung jumlah anggota tiap kelas\ndf['custcat'].value_counts()\n\ncustcat\n3    281\n1    266\n4    236\n2    217\nName: count, dtype: int64\n\n\n\n #melihat sebaran income dengan histogram\ndf.hist(column='income')\n\narray([[&lt;Axes: title={'center': 'income'}&gt;]], dtype=object)\n\n\n\n\n\n\n\n\n\n\n#melihat 4 row pertama\nX = df.drop(columns=\"custcat\")\nX.head(4)\n\n\n\n\n\n\n\n\nregion\ntenure\nage\nmarital\naddress\nincome\ned\nemploy\nretire\ngender\nreside\n\n\n\n\n0\n2\n13\n44\n1\n9\n64.0\n4\n5\n0.0\n0\n2\n\n\n1\n3\n11\n33\n1\n7\n136.0\n5\n5\n0.0\n0\n6\n\n\n2\n3\n68\n52\n1\n24\n116.0\n1\n29\n0.0\n1\n2\n\n\n3\n2\n33\n33\n0\n12\n33.0\n2\n0\n0.0\n1\n1\n\n\n\n\n\n\n\n\n#melihat kelas dari 4 row pertama\ny = df['custcat']\ny.head(4)\n\n0    1\n1    4\n2    3\n3    1\nName: custcat, dtype: int64\n\n\n\n\n\nNormalisasi adalah melakukan scaling pada keseluruhan data sehingga berada dalam rentang interval \\([0, 1]\\). Normalisasi bisa meningkatkan akurasi KNN karena\n\ndata semua fitur berada di rentang yang sama, sehingga tidak ada bias (bias dalam artian lebih memperhatikan fitur lain karena rentangnya lebih besar sehingga perhitungan jarak menjadi lebih dipengaruhi oleh fitur lain itu)\nbilangan floating-point paling presisi di interval \\([0, 1]\\)\n\nsklearn menyediakan class untuk normalisasi bernama MinMaxScaler. Sebenarnya min-max scaler ini bisa diubah intervalnya selain \\([0,1]\\), dengan mengubah parameter feature_range=(0, 1) tetapi tidak kita lakukan\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n#normalize data\nX_minmax = MinMaxScaler(feature_range=(0, 1))\nX_minmax.fit(X)\nX_sc = X_minmax.transform(X.astype(float))\n\n\nX_sc[0:4]\n\narray([[0.5       , 0.16901408, 0.44067797, 1.        , 0.16363636,\n        0.0331525 , 0.75      , 0.10638298, 0.        , 0.        ,\n        0.14285714],\n       [1.        , 0.14084507, 0.25423729, 1.        , 0.12727273,\n        0.07655214, 1.        , 0.10638298, 0.        , 0.        ,\n        0.71428571],\n       [1.        , 0.94366197, 0.57627119, 1.        , 0.43636364,\n        0.06449668, 0.        , 0.61702128, 0.        , 1.        ,\n        0.14285714],\n       [0.5       , 0.45070423, 0.25423729, 0.        , 0.21818182,\n        0.01446655, 0.25      , 0.        , 0.        , 1.        ,\n        0.        ]])\n\n\n\n\n\n\nfrom sklearn.model_selection import train_test_split\n\n\n#train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)\n\n(800, 11)\n(800,)\n(200, 11)\n(200,)\n\n\n\n\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\n#membuat model dengan k = 4\nk = 4\ntele_KNN = KNeighborsClassifier(n_neighbors = k)\ntele_KNN.fit(X_train, y_train)\n\nKNeighborsClassifier(n_neighbors=4)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KNeighborsClassifierKNeighborsClassifier(n_neighbors=4)\n\n\n\n\n\n\n#hasil prediksi\ny_pred = tele_KNN.predict(X_test)\ny_pred[0:5]\n\narray([3, 2, 1, 3, 1])\n\n\n\n#kelas sebenarnya\ny_test[0:5]\n\n521    2\n737    1\n740    2\n660    3\n411    1\nName: custcat, dtype: int64\n\n\n\n\n\n\nfrom sklearn import metrics\n\n\n#menghitung akurasi\nmetrics.accuracy_score(y_test, y_pred)\n\n0.3\n\n\n\n\n\n\n#membuat model dengan k = 6\nk = 6\ntele_KNN_6 = KNeighborsClassifier(n_neighbors = k).fit(X_train, y_train)\n\n\n#hasil prediksi\ny_pred_6 = tele_KNN_6.predict(X_test)\ny_pred_6[0:5]\n\narray([3, 2, 1, 3, 1])\n\n\n\n#kelas sebenarnya\ny_test[0:5]\n\n521    2\n737    1\n740    2\n660    3\n411    1\nName: custcat, dtype: int64\n\n\n\n#akurasi\nmetrics.accuracy_score(y_test, y_pred_6)\n\n0.33\n\n\n\n\n\nKinerja model K-NN sangat bergantung pada jumlah k yang dipilih. Kita bisa saja menentukan k terbaik secara manual menggunakan loop.\n\n#mencari k terbaik diantara 1&lt;=k&lt;=10\nnk = 10\n\nmean_acc= np.zeros((nk))\nstd_acc = np.zeros((nk))\n\nfor n in range(1,nk+1):\n neighbor_k = KNeighborsClassifier(n_neighbors= n).fit(X_train,Y_train)\n ypredict = neighbor_k.predict(X_test)\n mean_acc[n-1] = metrics.accuracy_score(Y_test, ypredict)\n std_acc[n-1]= np.std(ypredict==Y_test)/np.sqrt(ypredict.shape[0])\n\nmean_acc\n\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\n\n\narray([0.3  , 0.29 , 0.315, 0.32 , 0.315, 0.31 , 0.335, 0.325, 0.34 ,\n       0.33 ])\n\n\n\n#plot akurasi dari beberapa k\nplt.plot(range(1,nk+1),mean_acc,'g')\nplt.fill_between(range(1,nk+1),mean_acc-1*std_acc,mean_acc+1*std_acc,alpha = 0.10)\nplt.fill_between(range(1,nk+1),mean_acc-3*std_acc,mean_acc+3*std_acc,alpha = 0.10, color = \"red\")\nplt.legend(('Accuracy', '+-1xstd', '+-3xstd'))\nplt.ylabel('Accuracy')\nplt.xlabel('Jumlah neighbor')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#plot akurasi dari beberapa k\nplt.plot(range(1,nk+1),mean_acc,'g')\nplt.fill_between(range(1,nk+1),mean_acc-1*std_acc,mean_acc+1*std_acc,alpha = 0.10)\nplt.fill_between(range(1,nk+1),mean_acc-3*std_acc,mean_acc+3*std_acc,alpha = 0.10, color = \"red\")\nplt.legend(('Accuracy', '+-1xstd', '+-3xstd'))\nplt.ylabel('Accuracy')\nplt.xlabel('Jumlah neighbor')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#k terbaik beserta hasilnya\nprint(\"akurasi terbaik model adalah\", mean_acc.max(), \"dengan jumlah k=\", mean_acc.argmax()+1)\n\nakurasi terbaik model adalah 0.34 dengan jumlah k= 9\n\n\nDaripada cara manual, kita bisa menggunakan fitur grid search dari scikit-learn.\n\nfrom sklearn.model_selection import GridSearchCV\n\nBuatlah dictionary berisi semua nilai yang ingin dicoba untuk tiap parameter:\n\nKNN_param_grid = {\n    'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n}\n\n\nKNN_auto = KNeighborsClassifier()\n\nKNN_grid_search = GridSearchCV(KNN_auto, KNN_param_grid, scoring=\"accuracy\")\n\n\n# Lakukan grid search\nKNN_grid_search.fit(X_train, y_train)\n\nGridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n             scoring='accuracy')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n             scoring='accuracy')estimator: KNeighborsClassifierKNeighborsClassifier()KNeighborsClassifierKNeighborsClassifier()\n\n\nLihat hasilnya:\n\nprint(KNN_grid_search.best_params_)\n\n{'n_neighbors': 9}\n\n\n\nprint(KNN_grid_search.best_score_)\n\n0.34500000000000003\n\n\nSehingga nilai k terbaik (dari 1 sampai 10) adalah 9 dengan akurasi 0.345\n\n\n\n\n\nTermasuk dalam kategori unsupervised learning (data tidak memiliki label)\nMengelompokkan data data dengan sifat/karakteristik yg sama sebagai satu cluster\nCluster : sekelompok objek yang memiliki kesamaan dengan objek yang ada di cluster tersebut dan berbeda dengan objek di cluster lainnya\nAplikasi : rekomendasi film/musik pada aplikasi, iklan pada sosmed, dll.\n\n\n\n\nK-Means bertujuan memperkecil jarak antar data (SSE) dalam cluster dan memperbesar jarak antar cluster\n\n\\[SSE = \\sum (x_i -c_j)^2\\]\n\nLangkah-Langkah: 1. Tentukan centroid untuk k cluster 2. Hitung jarak tiap data dengan centroid 3. Assign data ke centroid terdeka 4. Tentukan centroid baru 5. Ulangi langkah 1 - 4\n\n\n\n\nContoh K-Means clustering menggunakan data random.\n\n#import modul yang diperlukan\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\n%matplotlib inline\n\n\n\n\n#data\nnp.random.seed(0)\n\n\n#membuat sample, dengan centroid sebagai berikut\nX, y = make_blobs(n_samples= 5000, centers = [[4,4],[-2,-1],[2,-3],[1,1]], cluster_std=0.9)\n\n\n#menggambar plot dari sample\nplt.scatter(X[:,0], X[:,1],marker='.')\n\n\n\n\n\n\n\n\n\n\n\n\n#buat model k-means, jumlah cluster 4, algoritma akan diulang sebanyak 12 kali\nk_means = KMeans(init=\"k-means++\", n_clusters = 4, n_init = 12)\n\n\n#fitting x ke model\nk_means.fit(X)\n\nKMeans(n_clusters=4, n_init=12)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KMeansKMeans(n_clusters=4, n_init=12)\n\n\n\n\n\n\n#hasil clustering pada data\nk_means_labels = k_means.labels_\nk_means_labels\n\narray([0, 3, 3, ..., 1, 0, 0], dtype=int32)\n\n\n\n#centroid dari 4 cluster setelah menggunakan model k-means\nk_means_cluster_centers = k_means.cluster_centers_\nk_means_cluster_centers\n\narray([[-2.03743147, -0.99782524],\n       [ 3.97334234,  3.98758687],\n       [ 0.96900523,  0.98370298],\n       [ 1.99741008, -3.01666822]])\n\n\n\n#plot hasil clustering\nfig = plt.figure(figsize=(6,4))\ncolors = plt.cm.Spectral(np.linspace(0,1, len(set(k_means_labels))))\nax= fig.add_subplot(1,1,1)\nfor k, col in zip(range(len([[4,4],[-2,-1],[2,-3],[1,1]])), colors) :\n my_members = (k_means_labels==k)\n cluster_center = k_means_cluster_centers[k]\n ax.plot(X[my_members,0], X[my_members,1], 'w', markerfacecolor=col,marker='.')\n ax.plot(cluster_center[0],cluster_center[1],'o',markerfacecolor=col,markeredgecolor='k',markersize=\n6)\nax.set_title('KMeans Clustering')\n#hilangkan sumbu\nax.set_xticks(())\nax.set_yticks(())\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nPada contoh ini, akan dilakukan clustering menggunakan dataset nasabah bank (Cust_Segmentation.csv).\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle: https://www.kaggle.com/datasets/sam1o1/cust-segmentation\n\nNasabah tersebut akan dikelompokkan menjadi 3 cluster.\n\n#import modul dan membaca dataset\nimport pandas as pd\ncust_df = pd.read_csv('./Cust_Segmentation.csv')\n\n\n\n\n#cuplikan dataset\ncust_df.head()\n\n\n\n\n\n\n\n\nCustomer Id\nAge\nEdu\nYears Employed\nIncome\nCard Debt\nOther Debt\nDefaulted\nAddress\nDebtIncomeRatio\n\n\n\n\n0\n1\n41\n2\n6\n19\n0.124\n1.073\n0.0\nNBA001\n6.3\n\n\n1\n2\n47\n1\n26\n100\n4.582\n8.218\n0.0\nNBA021\n12.8\n\n\n2\n3\n33\n2\n10\n57\n6.111\n5.802\n1.0\nNBA013\n20.9\n\n\n3\n4\n29\n2\n4\n19\n0.681\n0.516\n0.0\nNBA009\n6.3\n\n\n4\n5\n47\n1\n31\n253\n9.308\n8.908\n0.0\nNBA008\n7.2\n\n\n\n\n\n\n\n\n#periksa tipe data dari masing masing kolom pada dataset\ncust_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 850 entries, 0 to 849\nData columns (total 10 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   Customer Id      850 non-null    int64  \n 1   Age              850 non-null    int64  \n 2   Edu              850 non-null    int64  \n 3   Years Employed   850 non-null    int64  \n 4   Income           850 non-null    int64  \n 5   Card Debt        850 non-null    float64\n 6   Other Debt       850 non-null    float64\n 7   Defaulted        700 non-null    float64\n 8   Address          850 non-null    object \n 9   DebtIncomeRatio  850 non-null    float64\ndtypes: float64(4), int64(5), object(1)\nmemory usage: 66.5+ KB\n\n\n\n\n\n\n#buat semua data menjadi numerik\ncust_df2 = cust_df.drop('Address',axis=1)\ncust_df2.head()\n\n\n\n\n\n\n\n\nCustomer Id\nAge\nEdu\nYears Employed\nIncome\nCard Debt\nOther Debt\nDefaulted\nDebtIncomeRatio\n\n\n\n\n0\n1\n41\n2\n6\n19\n0.124\n1.073\n0.0\n6.3\n\n\n1\n2\n47\n1\n26\n100\n4.582\n8.218\n0.0\n12.8\n\n\n2\n3\n33\n2\n10\n57\n6.111\n5.802\n1.0\n20.9\n\n\n3\n4\n29\n2\n4\n19\n0.681\n0.516\n0.0\n6.3\n\n\n4\n5\n47\n1\n31\n253\n9.308\n8.908\n0.0\n7.2\n\n\n\n\n\n\n\n\ncust_df2.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 850 entries, 0 to 849\nData columns (total 9 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   Customer Id      850 non-null    int64  \n 1   Age              850 non-null    int64  \n 2   Edu              850 non-null    int64  \n 3   Years Employed   850 non-null    int64  \n 4   Income           850 non-null    int64  \n 5   Card Debt        850 non-null    float64\n 6   Other Debt       850 non-null    float64\n 7   Defaulted        700 non-null    float64\n 8   DebtIncomeRatio  850 non-null    float64\ndtypes: float64(4), int64(5)\nmemory usage: 59.9 KB\n\n\nSelain normalisasi, ada yang namanya standarisasi, yang mengubah data supaya rata-ratanya adalah nol dan simpangan baku / standard deviation bernilai satu.\n\nfrom sklearn.preprocessing import StandardScaler\n\n\nX = cust_df2.values[:,1:]\nX = np.nan_to_num(X)\nClus_dataSet= StandardScaler().fit_transform(X)\nClus_dataSet\n\narray([[ 0.74291541,  0.31212243, -0.37878978, ..., -0.59048916,\n        -0.52379654, -0.57652509],\n       [ 1.48949049, -0.76634938,  2.5737211 , ...,  1.51296181,\n        -0.52379654,  0.39138677],\n       [-0.25251804,  0.31212243,  0.2117124 , ...,  0.80170393,\n         1.90913822,  1.59755385],\n       ...,\n       [-1.24795149,  2.46906604, -1.26454304, ...,  0.03863257,\n         1.90913822,  3.45892281],\n       [-0.37694723, -0.76634938,  0.50696349, ..., -0.70147601,\n        -0.52379654, -1.08281745],\n       [ 2.1116364 , -0.76634938,  1.09746566, ...,  0.16463355,\n        -0.52379654, -0.2340332 ]])\n\n\n\n\n\n\n#modelling\nclusterNum = 3\nk_means_cust = KMeans(init = 'k-means++', n_clusters= clusterNum, n_init = 12) \n#3 cluster, dengan running algoritma sebanyak 12 kali\n\nk_means_cust.fit(X)\n\n#hasil clustering\nlabels_cust = k_means_cust.labels_\nprint(labels_cust)\n\n[2 0 2 2 1 0 2 0 2 0 0 2 2 2 2 2 2 2 0 2 2 2 2 0 0 0 2 2 0 2 0 2 2 2 2 2 2\n 2 2 0 2 0 2 1 2 0 2 2 2 0 0 2 2 0 0 2 2 2 0 2 0 2 0 0 2 2 0 2 2 2 0 0 0 2\n 2 2 2 2 0 2 0 0 1 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 0 2\n 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2 2 2 0 2 2 2 2 2 2 2 0 2 0 2\n 2 2 2 2 2 2 0 2 0 0 2 0 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 2 2 2 0 2\n 2 2 2 2 0 2 2 0 2 0 2 2 0 1 2 0 2 2 2 2 2 2 1 0 2 2 2 2 0 2 2 0 0 2 0 2 0\n 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 1 0 2 2 2 2 2 2 2 0 2 2 2 2\n 2 2 0 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 0 2 0 2 0 0 2 2 2 2 2 2\n 2 2 2 0 0 0 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 0 2 0 0 2\n 2 2 2 2 0 2 2 2 2 2 2 0 2 2 0 2 2 0 2 2 2 2 2 0 2 2 2 1 2 2 2 0 2 0 0 0 2\n 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2\n 2 0 2 2 0 2 2 2 2 0 2 2 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 1\n 2 2 2 2 2 2 0 2 2 2 1 2 2 2 2 0 2 1 2 2 2 2 0 2 0 0 0 2 2 0 0 2 2 2 2 2 2\n 2 0 2 2 2 2 0 2 2 2 0 2 0 2 2 2 0 2 2 2 2 0 0 2 2 2 2 0 2 2 2 2 0 2 2 2 2\n 2 0 0 2 2 2 2 2 2 2 2 2 2 2 1 0 2 2 2 2 2 2 0 2 2 2 2 0 2 2 0 2 2 1 2 1 2\n 2 1 2 2 2 2 2 2 2 2 2 0 2 0 2 2 1 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 2 0\n 2 2 2 2 2 2 0 2 2 2 2 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0\n 0 2 2 0 2 0 2 2 0 2 0 2 2 1 2 0 2 0 2 2 2 2 2 0 0 2 2 2 2 0 2 2 2 0 0 2 2\n 0 2 2 2 0 2 1 2 2 0 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2 0 2 2 0 2 2 2 2 2 2\n 2 2 0 2 2 0 2 0 2 0 0 2 2 2 0 2 0 2 2 2 2 2 0 2 2 2 2 0 0 2 2 0 0 2 2 2 2\n 2 0 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 2 0 2 0 0 2 2 0 2 2 2 2 2 0 0\n 2 2 2 2 2 2 2 0 2 2 2 2 2 2 1 0 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0]\n\n\nMetrik evaluasi untuk clustering, salah satunya bisa berupa hasil SSE (makin kecil makin baik), yang bisa dilihat dengan .inertia_\n\nprint(k_means_cust.inertia_)\n\n381849.3821502842\n\n\nMenyimpan hasil clustering ke dalam CSV:\n\n#menambahkan kolom hasil clustering pada dataset\ncust_df2['Clus_km'] = labels_cust\ncust_df2.head(5)\n\n\n\n\n\n\n\n\nCustomer Id\nAge\nEdu\nYears Employed\nIncome\nCard Debt\nOther Debt\nDefaulted\nDebtIncomeRatio\nClus_km\n\n\n\n\n0\n1\n41\n2\n6\n19\n0.124\n1.073\n0.0\n6.3\n2\n\n\n1\n2\n47\n1\n26\n100\n4.582\n8.218\n0.0\n12.8\n0\n\n\n2\n3\n33\n2\n10\n57\n6.111\n5.802\n1.0\n20.9\n2\n\n\n3\n4\n29\n2\n4\n19\n0.681\n0.516\n0.0\n6.3\n2\n\n\n4\n5\n47\n1\n31\n253\n9.308\n8.908\n0.0\n7.2\n1\n\n\n\n\n\n\n\n\ncust_df2.to_csv(\"./Cust_Segmentation_clusters.csv\")\n\nEksplorasi hasil clustering:\n\n#melihat rata rata per cluster\ncust_df2.groupby('Clus_km').mean()\n\n\n\n\n\n\n\n\nCustomer Id\nAge\nEdu\nYears Employed\nIncome\nCard Debt\nOther Debt\nDefaulted\nDebtIncomeRatio\n\n\nClus_km\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n402.295082\n41.333333\n1.956284\n15.256831\n83.928962\n3.103639\n5.765279\n0.171233\n10.724590\n\n\n1\n410.166667\n45.388889\n2.666667\n19.555556\n227.166667\n5.678444\n10.907167\n0.285714\n7.322222\n\n\n2\n432.468413\n32.964561\n1.614792\n6.374422\n31.164869\n1.032541\n2.104133\n0.285185\n10.094761\n\n\n\n\n\n\n\n\n#plot hasil clustering berdasarkan age dan income\narea = np.pi * (X[:, 1])**2\nplt.scatter(X[:,0],X[:,3],s = area, c = labels_cust.astype(float), alpha=0.5)\nplt.xlabel('Age',fontsize=18)\nplt.ylabel('Income',fontsize = 16)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nDari datset diatas, kita dapat membuat 3 cluster, dengan segmentasi sebagai berikut:\n\nKuning : dewasa muda, pendapatan rendah\nUngu: dewasa menengah, pendapatan kelas menengah\nHijau: dewasa tua, pendapatan tinggi"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul6.html#k-nearest-neighbor",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul6.html#k-nearest-neighbor",
    "title": "Modul 6 Praktikum Sains Data: K-Nearest Neighbor, K-Means Clustering",
    "section": "",
    "text": "K-Nearest neighbor adalah salah satu jenis algoritma supervised learning. Biasanya, algoritma ini digunakan untuk masalah klasifikasi. Kelas dari data tersebut ditentukan dari sejumlah k titik yang berperan “tetangga”. Pada gambar di atas, ketika k = 3, bintang akan diklasifikasikan sebagai kelas ungu, sebab mayoritas dari tetangganya adalah ungu. Sedangkan, ketika k = 6, bintang akan diklasifikasikan sebagai kelas kuning.\n\n#import modul\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n%matplotlib inline\n\n\n\nPada module kali ini, akan digunakan data csv teleCust1000t (teleCust1000t.csv) yang bisa didownload dari:\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle: https://www.kaggle.com/code/zohaib123/telecusts-prediction-k-nearest-neighbors\n\n\n #membaca dataset\ndf = pd.read_csv('./teleCust1000t.csv')\ndf.head()\n\n\n\n\n\n\n\n\nregion\ntenure\nage\nmarital\naddress\nincome\ned\nemploy\nretire\ngender\nreside\ncustcat\n\n\n\n\n0\n2\n13\n44\n1\n9\n64.0\n4\n5\n0.0\n0\n2\n1\n\n\n1\n3\n11\n33\n1\n7\n136.0\n5\n5\n0.0\n0\n6\n4\n\n\n2\n3\n68\n52\n1\n24\n116.0\n1\n29\n0.0\n1\n2\n3\n\n\n3\n2\n33\n33\n0\n12\n33.0\n2\n0\n0.0\n1\n1\n1\n\n\n4\n2\n23\n30\n1\n9\n30.0\n1\n2\n0.0\n0\n4\n3\n\n\n\n\n\n\n\n\n#menghitung jumlah anggota tiap kelas\ndf['custcat'].value_counts()\n\ncustcat\n3    281\n1    266\n4    236\n2    217\nName: count, dtype: int64\n\n\n\n #melihat sebaran income dengan histogram\ndf.hist(column='income')\n\narray([[&lt;Axes: title={'center': 'income'}&gt;]], dtype=object)\n\n\n\n\n\n\n\n\n\n\n#melihat 4 row pertama\nX = df.drop(columns=\"custcat\")\nX.head(4)\n\n\n\n\n\n\n\n\nregion\ntenure\nage\nmarital\naddress\nincome\ned\nemploy\nretire\ngender\nreside\n\n\n\n\n0\n2\n13\n44\n1\n9\n64.0\n4\n5\n0.0\n0\n2\n\n\n1\n3\n11\n33\n1\n7\n136.0\n5\n5\n0.0\n0\n6\n\n\n2\n3\n68\n52\n1\n24\n116.0\n1\n29\n0.0\n1\n2\n\n\n3\n2\n33\n33\n0\n12\n33.0\n2\n0\n0.0\n1\n1\n\n\n\n\n\n\n\n\n#melihat kelas dari 4 row pertama\ny = df['custcat']\ny.head(4)\n\n0    1\n1    4\n2    3\n3    1\nName: custcat, dtype: int64\n\n\n\n\n\nNormalisasi adalah melakukan scaling pada keseluruhan data sehingga berada dalam rentang interval \\([0, 1]\\). Normalisasi bisa meningkatkan akurasi KNN karena\n\ndata semua fitur berada di rentang yang sama, sehingga tidak ada bias (bias dalam artian lebih memperhatikan fitur lain karena rentangnya lebih besar sehingga perhitungan jarak menjadi lebih dipengaruhi oleh fitur lain itu)\nbilangan floating-point paling presisi di interval \\([0, 1]\\)\n\nsklearn menyediakan class untuk normalisasi bernama MinMaxScaler. Sebenarnya min-max scaler ini bisa diubah intervalnya selain \\([0,1]\\), dengan mengubah parameter feature_range=(0, 1) tetapi tidak kita lakukan\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n#normalize data\nX_minmax = MinMaxScaler(feature_range=(0, 1))\nX_minmax.fit(X)\nX_sc = X_minmax.transform(X.astype(float))\n\n\nX_sc[0:4]\n\narray([[0.5       , 0.16901408, 0.44067797, 1.        , 0.16363636,\n        0.0331525 , 0.75      , 0.10638298, 0.        , 0.        ,\n        0.14285714],\n       [1.        , 0.14084507, 0.25423729, 1.        , 0.12727273,\n        0.07655214, 1.        , 0.10638298, 0.        , 0.        ,\n        0.71428571],\n       [1.        , 0.94366197, 0.57627119, 1.        , 0.43636364,\n        0.06449668, 0.        , 0.61702128, 0.        , 1.        ,\n        0.14285714],\n       [0.5       , 0.45070423, 0.25423729, 0.        , 0.21818182,\n        0.01446655, 0.25      , 0.        , 0.        , 1.        ,\n        0.        ]])\n\n\n\n\n\n\nfrom sklearn.model_selection import train_test_split\n\n\n#train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)\n\n(800, 11)\n(800,)\n(200, 11)\n(200,)\n\n\n\n\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\n#membuat model dengan k = 4\nk = 4\ntele_KNN = KNeighborsClassifier(n_neighbors = k)\ntele_KNN.fit(X_train, y_train)\n\nKNeighborsClassifier(n_neighbors=4)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KNeighborsClassifierKNeighborsClassifier(n_neighbors=4)\n\n\n\n\n\n\n#hasil prediksi\ny_pred = tele_KNN.predict(X_test)\ny_pred[0:5]\n\narray([3, 2, 1, 3, 1])\n\n\n\n#kelas sebenarnya\ny_test[0:5]\n\n521    2\n737    1\n740    2\n660    3\n411    1\nName: custcat, dtype: int64\n\n\n\n\n\n\nfrom sklearn import metrics\n\n\n#menghitung akurasi\nmetrics.accuracy_score(y_test, y_pred)\n\n0.3\n\n\n\n\n\n\n#membuat model dengan k = 6\nk = 6\ntele_KNN_6 = KNeighborsClassifier(n_neighbors = k).fit(X_train, y_train)\n\n\n#hasil prediksi\ny_pred_6 = tele_KNN_6.predict(X_test)\ny_pred_6[0:5]\n\narray([3, 2, 1, 3, 1])\n\n\n\n#kelas sebenarnya\ny_test[0:5]\n\n521    2\n737    1\n740    2\n660    3\n411    1\nName: custcat, dtype: int64\n\n\n\n#akurasi\nmetrics.accuracy_score(y_test, y_pred_6)\n\n0.33\n\n\n\n\n\nKinerja model K-NN sangat bergantung pada jumlah k yang dipilih. Kita bisa saja menentukan k terbaik secara manual menggunakan loop.\n\n#mencari k terbaik diantara 1&lt;=k&lt;=10\nnk = 10\n\nmean_acc= np.zeros((nk))\nstd_acc = np.zeros((nk))\n\nfor n in range(1,nk+1):\n neighbor_k = KNeighborsClassifier(n_neighbors= n).fit(X_train,Y_train)\n ypredict = neighbor_k.predict(X_test)\n mean_acc[n-1] = metrics.accuracy_score(Y_test, ypredict)\n std_acc[n-1]= np.std(ypredict==Y_test)/np.sqrt(ypredict.shape[0])\n\nmean_acc\n\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\n\n\narray([0.3  , 0.29 , 0.315, 0.32 , 0.315, 0.31 , 0.335, 0.325, 0.34 ,\n       0.33 ])\n\n\n\n#plot akurasi dari beberapa k\nplt.plot(range(1,nk+1),mean_acc,'g')\nplt.fill_between(range(1,nk+1),mean_acc-1*std_acc,mean_acc+1*std_acc,alpha = 0.10)\nplt.fill_between(range(1,nk+1),mean_acc-3*std_acc,mean_acc+3*std_acc,alpha = 0.10, color = \"red\")\nplt.legend(('Accuracy', '+-1xstd', '+-3xstd'))\nplt.ylabel('Accuracy')\nplt.xlabel('Jumlah neighbor')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#plot akurasi dari beberapa k\nplt.plot(range(1,nk+1),mean_acc,'g')\nplt.fill_between(range(1,nk+1),mean_acc-1*std_acc,mean_acc+1*std_acc,alpha = 0.10)\nplt.fill_between(range(1,nk+1),mean_acc-3*std_acc,mean_acc+3*std_acc,alpha = 0.10, color = \"red\")\nplt.legend(('Accuracy', '+-1xstd', '+-3xstd'))\nplt.ylabel('Accuracy')\nplt.xlabel('Jumlah neighbor')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#k terbaik beserta hasilnya\nprint(\"akurasi terbaik model adalah\", mean_acc.max(), \"dengan jumlah k=\", mean_acc.argmax()+1)\n\nakurasi terbaik model adalah 0.34 dengan jumlah k= 9\n\n\nDaripada cara manual, kita bisa menggunakan fitur grid search dari scikit-learn.\n\nfrom sklearn.model_selection import GridSearchCV\n\nBuatlah dictionary berisi semua nilai yang ingin dicoba untuk tiap parameter:\n\nKNN_param_grid = {\n    'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n}\n\n\nKNN_auto = KNeighborsClassifier()\n\nKNN_grid_search = GridSearchCV(KNN_auto, KNN_param_grid, scoring=\"accuracy\")\n\n\n# Lakukan grid search\nKNN_grid_search.fit(X_train, y_train)\n\nGridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n             scoring='accuracy')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n             scoring='accuracy')estimator: KNeighborsClassifierKNeighborsClassifier()KNeighborsClassifierKNeighborsClassifier()\n\n\nLihat hasilnya:\n\nprint(KNN_grid_search.best_params_)\n\n{'n_neighbors': 9}\n\n\n\nprint(KNN_grid_search.best_score_)\n\n0.34500000000000003\n\n\nSehingga nilai k terbaik (dari 1 sampai 10) adalah 9 dengan akurasi 0.345"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul6.html#clustering",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul6.html#clustering",
    "title": "Modul 6 Praktikum Sains Data: K-Nearest Neighbor, K-Means Clustering",
    "section": "",
    "text": "Termasuk dalam kategori unsupervised learning (data tidak memiliki label)\nMengelompokkan data data dengan sifat/karakteristik yg sama sebagai satu cluster\nCluster : sekelompok objek yang memiliki kesamaan dengan objek yang ada di cluster tersebut dan berbeda dengan objek di cluster lainnya\nAplikasi : rekomendasi film/musik pada aplikasi, iklan pada sosmed, dll.\n\n\n\n\nK-Means bertujuan memperkecil jarak antar data (SSE) dalam cluster dan memperbesar jarak antar cluster\n\n\\[SSE = \\sum (x_i -c_j)^2\\]\n\nLangkah-Langkah: 1. Tentukan centroid untuk k cluster 2. Hitung jarak tiap data dengan centroid 3. Assign data ke centroid terdeka 4. Tentukan centroid baru 5. Ulangi langkah 1 - 4"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul6.html#k-means-clustering-menggunakan-dataset-random",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul6.html#k-means-clustering-menggunakan-dataset-random",
    "title": "Modul 6 Praktikum Sains Data: K-Nearest Neighbor, K-Means Clustering",
    "section": "",
    "text": "Contoh K-Means clustering menggunakan data random.\n\n#import modul yang diperlukan\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\n%matplotlib inline\n\n\n\n\n#data\nnp.random.seed(0)\n\n\n#membuat sample, dengan centroid sebagai berikut\nX, y = make_blobs(n_samples= 5000, centers = [[4,4],[-2,-1],[2,-3],[1,1]], cluster_std=0.9)\n\n\n#menggambar plot dari sample\nplt.scatter(X[:,0], X[:,1],marker='.')\n\n\n\n\n\n\n\n\n\n\n\n\n#buat model k-means, jumlah cluster 4, algoritma akan diulang sebanyak 12 kali\nk_means = KMeans(init=\"k-means++\", n_clusters = 4, n_init = 12)\n\n\n#fitting x ke model\nk_means.fit(X)\n\nKMeans(n_clusters=4, n_init=12)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KMeansKMeans(n_clusters=4, n_init=12)\n\n\n\n\n\n\n#hasil clustering pada data\nk_means_labels = k_means.labels_\nk_means_labels\n\narray([0, 3, 3, ..., 1, 0, 0], dtype=int32)\n\n\n\n#centroid dari 4 cluster setelah menggunakan model k-means\nk_means_cluster_centers = k_means.cluster_centers_\nk_means_cluster_centers\n\narray([[-2.03743147, -0.99782524],\n       [ 3.97334234,  3.98758687],\n       [ 0.96900523,  0.98370298],\n       [ 1.99741008, -3.01666822]])\n\n\n\n#plot hasil clustering\nfig = plt.figure(figsize=(6,4))\ncolors = plt.cm.Spectral(np.linspace(0,1, len(set(k_means_labels))))\nax= fig.add_subplot(1,1,1)\nfor k, col in zip(range(len([[4,4],[-2,-1],[2,-3],[1,1]])), colors) :\n my_members = (k_means_labels==k)\n cluster_center = k_means_cluster_centers[k]\n ax.plot(X[my_members,0], X[my_members,1], 'w', markerfacecolor=col,marker='.')\n ax.plot(cluster_center[0],cluster_center[1],'o',markerfacecolor=col,markeredgecolor='k',markersize=\n6)\nax.set_title('KMeans Clustering')\n#hilangkan sumbu\nax.set_xticks(())\nax.set_yticks(())\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul6.html#k-means-clustering-menggunakan-dataset-csv",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul6.html#k-means-clustering-menggunakan-dataset-csv",
    "title": "Modul 6 Praktikum Sains Data: K-Nearest Neighbor, K-Means Clustering",
    "section": "",
    "text": "Pada contoh ini, akan dilakukan clustering menggunakan dataset nasabah bank (Cust_Segmentation.csv).\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle: https://www.kaggle.com/datasets/sam1o1/cust-segmentation\n\nNasabah tersebut akan dikelompokkan menjadi 3 cluster.\n\n#import modul dan membaca dataset\nimport pandas as pd\ncust_df = pd.read_csv('./Cust_Segmentation.csv')\n\n\n\n\n#cuplikan dataset\ncust_df.head()\n\n\n\n\n\n\n\n\nCustomer Id\nAge\nEdu\nYears Employed\nIncome\nCard Debt\nOther Debt\nDefaulted\nAddress\nDebtIncomeRatio\n\n\n\n\n0\n1\n41\n2\n6\n19\n0.124\n1.073\n0.0\nNBA001\n6.3\n\n\n1\n2\n47\n1\n26\n100\n4.582\n8.218\n0.0\nNBA021\n12.8\n\n\n2\n3\n33\n2\n10\n57\n6.111\n5.802\n1.0\nNBA013\n20.9\n\n\n3\n4\n29\n2\n4\n19\n0.681\n0.516\n0.0\nNBA009\n6.3\n\n\n4\n5\n47\n1\n31\n253\n9.308\n8.908\n0.0\nNBA008\n7.2\n\n\n\n\n\n\n\n\n#periksa tipe data dari masing masing kolom pada dataset\ncust_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 850 entries, 0 to 849\nData columns (total 10 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   Customer Id      850 non-null    int64  \n 1   Age              850 non-null    int64  \n 2   Edu              850 non-null    int64  \n 3   Years Employed   850 non-null    int64  \n 4   Income           850 non-null    int64  \n 5   Card Debt        850 non-null    float64\n 6   Other Debt       850 non-null    float64\n 7   Defaulted        700 non-null    float64\n 8   Address          850 non-null    object \n 9   DebtIncomeRatio  850 non-null    float64\ndtypes: float64(4), int64(5), object(1)\nmemory usage: 66.5+ KB\n\n\n\n\n\n\n#buat semua data menjadi numerik\ncust_df2 = cust_df.drop('Address',axis=1)\ncust_df2.head()\n\n\n\n\n\n\n\n\nCustomer Id\nAge\nEdu\nYears Employed\nIncome\nCard Debt\nOther Debt\nDefaulted\nDebtIncomeRatio\n\n\n\n\n0\n1\n41\n2\n6\n19\n0.124\n1.073\n0.0\n6.3\n\n\n1\n2\n47\n1\n26\n100\n4.582\n8.218\n0.0\n12.8\n\n\n2\n3\n33\n2\n10\n57\n6.111\n5.802\n1.0\n20.9\n\n\n3\n4\n29\n2\n4\n19\n0.681\n0.516\n0.0\n6.3\n\n\n4\n5\n47\n1\n31\n253\n9.308\n8.908\n0.0\n7.2\n\n\n\n\n\n\n\n\ncust_df2.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 850 entries, 0 to 849\nData columns (total 9 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   Customer Id      850 non-null    int64  \n 1   Age              850 non-null    int64  \n 2   Edu              850 non-null    int64  \n 3   Years Employed   850 non-null    int64  \n 4   Income           850 non-null    int64  \n 5   Card Debt        850 non-null    float64\n 6   Other Debt       850 non-null    float64\n 7   Defaulted        700 non-null    float64\n 8   DebtIncomeRatio  850 non-null    float64\ndtypes: float64(4), int64(5)\nmemory usage: 59.9 KB\n\n\nSelain normalisasi, ada yang namanya standarisasi, yang mengubah data supaya rata-ratanya adalah nol dan simpangan baku / standard deviation bernilai satu.\n\nfrom sklearn.preprocessing import StandardScaler\n\n\nX = cust_df2.values[:,1:]\nX = np.nan_to_num(X)\nClus_dataSet= StandardScaler().fit_transform(X)\nClus_dataSet\n\narray([[ 0.74291541,  0.31212243, -0.37878978, ..., -0.59048916,\n        -0.52379654, -0.57652509],\n       [ 1.48949049, -0.76634938,  2.5737211 , ...,  1.51296181,\n        -0.52379654,  0.39138677],\n       [-0.25251804,  0.31212243,  0.2117124 , ...,  0.80170393,\n         1.90913822,  1.59755385],\n       ...,\n       [-1.24795149,  2.46906604, -1.26454304, ...,  0.03863257,\n         1.90913822,  3.45892281],\n       [-0.37694723, -0.76634938,  0.50696349, ..., -0.70147601,\n        -0.52379654, -1.08281745],\n       [ 2.1116364 , -0.76634938,  1.09746566, ...,  0.16463355,\n        -0.52379654, -0.2340332 ]])\n\n\n\n\n\n\n#modelling\nclusterNum = 3\nk_means_cust = KMeans(init = 'k-means++', n_clusters= clusterNum, n_init = 12) \n#3 cluster, dengan running algoritma sebanyak 12 kali\n\nk_means_cust.fit(X)\n\n#hasil clustering\nlabels_cust = k_means_cust.labels_\nprint(labels_cust)\n\n[2 0 2 2 1 0 2 0 2 0 0 2 2 2 2 2 2 2 0 2 2 2 2 0 0 0 2 2 0 2 0 2 2 2 2 2 2\n 2 2 0 2 0 2 1 2 0 2 2 2 0 0 2 2 0 0 2 2 2 0 2 0 2 0 0 2 2 0 2 2 2 0 0 0 2\n 2 2 2 2 0 2 0 0 1 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 0 2\n 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2 2 2 0 2 2 2 2 2 2 2 0 2 0 2\n 2 2 2 2 2 2 0 2 0 0 2 0 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 2 2 2 0 2\n 2 2 2 2 0 2 2 0 2 0 2 2 0 1 2 0 2 2 2 2 2 2 1 0 2 2 2 2 0 2 2 0 0 2 0 2 0\n 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 1 0 2 2 2 2 2 2 2 0 2 2 2 2\n 2 2 0 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 0 2 0 2 0 0 2 2 2 2 2 2\n 2 2 2 0 0 0 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 0 2 0 0 2\n 2 2 2 2 0 2 2 2 2 2 2 0 2 2 0 2 2 0 2 2 2 2 2 0 2 2 2 1 2 2 2 0 2 0 0 0 2\n 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2\n 2 0 2 2 0 2 2 2 2 0 2 2 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 1\n 2 2 2 2 2 2 0 2 2 2 1 2 2 2 2 0 2 1 2 2 2 2 0 2 0 0 0 2 2 0 0 2 2 2 2 2 2\n 2 0 2 2 2 2 0 2 2 2 0 2 0 2 2 2 0 2 2 2 2 0 0 2 2 2 2 0 2 2 2 2 0 2 2 2 2\n 2 0 0 2 2 2 2 2 2 2 2 2 2 2 1 0 2 2 2 2 2 2 0 2 2 2 2 0 2 2 0 2 2 1 2 1 2\n 2 1 2 2 2 2 2 2 2 2 2 0 2 0 2 2 1 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 2 0\n 2 2 2 2 2 2 0 2 2 2 2 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0\n 0 2 2 0 2 0 2 2 0 2 0 2 2 1 2 0 2 0 2 2 2 2 2 0 0 2 2 2 2 0 2 2 2 0 0 2 2\n 0 2 2 2 0 2 1 2 2 0 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2 0 2 2 0 2 2 2 2 2 2\n 2 2 0 2 2 0 2 0 2 0 0 2 2 2 0 2 0 2 2 2 2 2 0 2 2 2 2 0 0 2 2 0 0 2 2 2 2\n 2 0 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 2 0 2 0 0 2 2 0 2 2 2 2 2 0 0\n 2 2 2 2 2 2 2 0 2 2 2 2 2 2 1 0 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0]\n\n\nMetrik evaluasi untuk clustering, salah satunya bisa berupa hasil SSE (makin kecil makin baik), yang bisa dilihat dengan .inertia_\n\nprint(k_means_cust.inertia_)\n\n381849.3821502842\n\n\nMenyimpan hasil clustering ke dalam CSV:\n\n#menambahkan kolom hasil clustering pada dataset\ncust_df2['Clus_km'] = labels_cust\ncust_df2.head(5)\n\n\n\n\n\n\n\n\nCustomer Id\nAge\nEdu\nYears Employed\nIncome\nCard Debt\nOther Debt\nDefaulted\nDebtIncomeRatio\nClus_km\n\n\n\n\n0\n1\n41\n2\n6\n19\n0.124\n1.073\n0.0\n6.3\n2\n\n\n1\n2\n47\n1\n26\n100\n4.582\n8.218\n0.0\n12.8\n0\n\n\n2\n3\n33\n2\n10\n57\n6.111\n5.802\n1.0\n20.9\n2\n\n\n3\n4\n29\n2\n4\n19\n0.681\n0.516\n0.0\n6.3\n2\n\n\n4\n5\n47\n1\n31\n253\n9.308\n8.908\n0.0\n7.2\n1\n\n\n\n\n\n\n\n\ncust_df2.to_csv(\"./Cust_Segmentation_clusters.csv\")\n\nEksplorasi hasil clustering:\n\n#melihat rata rata per cluster\ncust_df2.groupby('Clus_km').mean()\n\n\n\n\n\n\n\n\nCustomer Id\nAge\nEdu\nYears Employed\nIncome\nCard Debt\nOther Debt\nDefaulted\nDebtIncomeRatio\n\n\nClus_km\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n402.295082\n41.333333\n1.956284\n15.256831\n83.928962\n3.103639\n5.765279\n0.171233\n10.724590\n\n\n1\n410.166667\n45.388889\n2.666667\n19.555556\n227.166667\n5.678444\n10.907167\n0.285714\n7.322222\n\n\n2\n432.468413\n32.964561\n1.614792\n6.374422\n31.164869\n1.032541\n2.104133\n0.285185\n10.094761\n\n\n\n\n\n\n\n\n#plot hasil clustering berdasarkan age dan income\narea = np.pi * (X[:, 1])**2\nplt.scatter(X[:,0],X[:,3],s = area, c = labels_cust.astype(float), alpha=0.5)\nplt.xlabel('Age',fontsize=18)\nplt.ylabel('Income',fontsize = 16)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nDari datset diatas, kita dapat membuat 3 cluster, dengan segmentasi sebagai berikut:\n\nKuning : dewasa muda, pendapatan rendah\nUngu: dewasa menengah, pendapatan kelas menengah\nHijau: dewasa tua, pendapatan tinggi"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul4.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul4.html",
    "title": "Modul 4 Sains Data: Regresi",
    "section": "",
    "text": "Kembali ke Sains Data\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nPada pertemuan kali ini, kita akan membahas tentang salah satu metode machine learning, yaitu regresi.\nMetode regresi yang paling sering digunakan adalah regresi linier (linear regression).\nInti sari dari regresi linier adalah, diberikan sekumpulan data (meliputi satu fitur target yang ingin diprediksi, biasa disebut \\(y\\), serta minimal satu variabel bebas), ingin ditemukan garis yang paling mendekati semua titik.\n“Paling mendekati” bisa diukur dengan menjumlahkan (kuadrat dari) semua selisih antara nilai \\(y\\) pada tiap titik dengan nilai \\(y\\) pada garis. (Misalkan fungsi garis ditulis \\(y = P\\left(x\\right)\\). Maka, nilai \\(y\\) pada garis ditulis \\(P\\left(x_i\\right)\\) untuk titik ke-\\(i\\).)\nJika hasil jumlah ini makin kecil, maka garis makin mendekati titik-titiknya. Hasil jumlah ini disebut error, atau di sini lebih tepatnya SSE (sum of squared errors):\n\\[\\text{SSE = } \\sum_{i=1}^{n} \\left( y_i - P\\left(x_i\\right) \\right)^2\\]\nMaka, tujuan dari regresi linier adalah menemukan garis yang meminimalkan error, yaitu meminimalkan SSE. Fungsi yang ingin diminimalkan (di sini SSE) biasa disebut fungsi objektif (objective function) di dunia optimasi, atau seringkali disebut loss function di dunia sains data / pembelajaran mesin (machine learning).\nRegresi linier umumnya terbagi lagi menjadi dua jenis, yaitu\nBanyak metode regresi lainnya yang sebenarnya dibangun di atas regresi linier, contohnya regresi polinomial (polynomial regression). Intinya sama: mencoba mencari bentuk fungsi tertentu yang paling cocok dengan sekumpulan data yang diberikan, baik untuk urusan deskripsi maupun prediksi."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#import-dataset",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#import-dataset",
    "title": "Modul 4 Sains Data: Regresi",
    "section": "Import Dataset",
    "text": "Import Dataset\nSebelum mulai, seperti biasa, kita perlu meng-import dataset terlebih dahulu.\nUntuk praktikum kali ini, kita akan melanjutkan dataset minggu lalu, California Housing Prices, yang sudah kita imputasi. Apabila kalian tidak sempat menyimpan dataset hasil imputasi tersebut sebagai file CSV, silakan download housing_modified.csv berikut:\n\nDirect link: housing_modified.csv\n\nKemudian read dengan pandas seperti biasa:\n\ndf = pd.read_csv(\"./housing_modified.csv\")\n\n\ndf\n\n\n\n\n\n\n\n\n\nUnnamed: 0\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 15 columns\n\n\n\n\n\ndf = df.drop(df.columns[0], axis=1)\n\n\ndf\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 14 columns\n\n\n\n\nPastikan sudah tidak ada missing value:\n\ndf.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\nUntuk dataset ini, fitur target utama yang ingin diprediksi adalah harga rumah, yaitu median_house_value. Kita bisa memisahkan antara fitur target tersebut, misal \\(y\\), dengan fitur-fitur lainnya, misal \\(X\\) besar.\n\nX = df.drop(columns=[\"median_house_value\"])\ny = df[[\"median_house_value\"]]\n\n\nX\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 13 columns\n\n\n\n\n\ny\n\n\n\n\n\n\n\n\n\nmedian_house_value\n\n\n\n\n0\n452600.0\n\n\n1\n358500.0\n\n\n2\n352100.0\n\n\n3\n341300.0\n\n\n4\n342200.0\n\n\n...\n...\n\n\n20635\n78100.0\n\n\n20636\n77100.0\n\n\n20637\n92300.0\n\n\n20638\n84700.0\n\n\n20639\n89400.0\n\n\n\n\n20640 rows × 1 columns"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#train-test-split",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#train-test-split",
    "title": "Modul 4 Sains Data: Regresi",
    "section": "Train-Test Split",
    "text": "Train-Test Split\nInti sari dari machine learning adalah membuat “model” yang bisa belajar dari pola, dan kemudian bisa menghasilkan prediksi yang akurat berdasarkan pola tersebut.\nSehingga, untuk menguji apakah model kita sudah bagus, fokus kita adalah menguji seberapa baik model bisa memprediksi.\n\nDi satu sisi, model machine learning memerlukan data, yang dengan data tersebut, model akan terbentuk dengan “latihan”, mencoba memahami pola yang ada di data tersebut.\nDi sisi lain, untuk menguji kemampuan model memprediksi, perlu ada juga data acuan sehingga hasil prediksi model bisa dibandingkan dengan data aslinya (yaitu data acuan tersebut).\n\nData untuk “latihan” disebut data training (training data), dan data acuan untuk menguji kemampuan prediksi disebut data testing (test data).\nTentunya, kedua data ini harus saling lepas (tidak memiliki irisan), agar tidak terjadi yang namanya data leakage. Semisal ada data training yang sama persis muncul di data testing, kan prediksinya jadi hafalan doang, kegampangan :D\nSebenarnya, regresi tidak terbatas machine learning. Kebetulan, regresi juga menjadi pembahasan yang mendalam di kalangan statistika, hingga ada mata kuliah tersendiri yang membahas regresi (Model Linier / Model Linear).\nDalam konteks machine learning, regresi linier (sebagai model) mencoba mencari garis yang meminimalkan SSE menggunakan data training saja, yaitu data yang dimaksudkan untuk membentuk model. Kemudian, garis yang ditemukan (model yang terbentuk) akan diuji kemampuan prediksinya menggunakan data testing.\nDi dunia nyata, data yang kita peroleh biasanya utuh, satu kesatuan. Padahal, untuk menggunakan machine learning, kita memerlukan data training dan data testing.\nSehingga, dataset yang utuh tersebut bisa kita pecah sendiri menjadi data training dan data testing, namanya train-test split.\nKebetulan, scikit-learn menyediakan fungsi untuk melakukan train-test split. Mari kita coba. Import dulu:\n\nfrom sklearn.model_selection import train_test_split\n\nBiasanya, dataset dipisah menjadi data training sebanyak 80% dan data testing sebanyak 20%. Dalam penggunaan fungsi train_test_split, ditulis test_size=0.2.\nRasio 80-20 ini sebenarnya hanya kebiasaan saja; paling sering begitu, tapi boleh saja misalnya 70-30 atau bahkan 90-10.\nMengapa jauh lebih banyak data training? Tujuannya agar model bisa memahami pola pada data dengan lebih mendalam. Namun, perlu hati-hati juga: kalau data testing terlalu sedikit, kita kurang bisa menguji kemampuan prediksi model.\nKalau ragu, langsung gunakan saja rasio 80-20. Sepertinya memang sudah standar, digunakan di mana-mana.\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nApa itu random state?\nTentunya, kita berharap bahwa train-test split dilakukan secara random atau sembarang, yaitu tidak berdasarkan pola tertentu, agar apapun pola yang terkandung dalam data training itu kurang lebih juga terkandung dalam data testing.\nDi sisi lain, apabila orang lain ingin mencoba model yang kita buat, tentunya kita juga berharap bahwa dia mendapatkan hasil yang sama.\nApabila train-test split benar-benar selalu random tiap kali dijalankan, kemungkinan hasil yang diperoleh orang lain akan cukup berbeda dengan hasil yang kita peroleh, padahal modelnya sama.\nOleh karena itu, meskipun kita menginginkan train-test split dilakukan secara random, kita juga menginginkan cara random tersebut adalah selalu cara yang sama. Hal ini bisa kita atur dengan memasang nilai random_state yang selalu sama.\nBiasanya, random_state dipasang nilai 42. Namun, itu hanya kebiasaan saja. Apapun boleh, asalkan konsisten.\nMari kita lihat hasilnya:\n\nX_train\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n14196\n-117.03\n32.71\n33.0\n3126.0\n627.0\n2300.0\n623.0\n3.2596\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n8267\n-118.16\n33.77\n49.0\n3382.0\n787.0\n1314.0\n756.0\n3.8125\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n17445\n-120.48\n34.66\n4.0\n1897.0\n331.0\n915.0\n336.0\n4.1563\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n14265\n-117.11\n32.69\n36.0\n1421.0\n367.0\n1418.0\n355.0\n1.9425\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n2271\n-119.80\n36.78\n43.0\n2382.0\n431.0\n874.0\n380.0\n3.5542\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n11284\n-117.96\n33.78\n35.0\n1330.0\n201.0\n658.0\n217.0\n6.3700\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n11964\n-117.43\n34.02\n33.0\n3084.0\n570.0\n1753.0\n449.0\n3.0500\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n5390\n-118.38\n34.03\n36.0\n2101.0\n569.0\n1756.0\n527.0\n2.9344\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n860\n-121.96\n37.58\n15.0\n3575.0\n597.0\n1777.0\n559.0\n5.7192\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n15795\n-122.42\n37.77\n52.0\n4226.0\n1315.0\n2619.0\n1242.0\n2.5755\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n\n\n16512 rows × 13 columns\n\n\n\n\n\nX_test\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n20046\n-119.01\n36.06\n25.0\n1505.0\n537.870553\n1392.0\n359.0\n1.6812\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n3024\n-119.46\n35.14\n30.0\n2943.0\n537.870553\n1565.0\n584.0\n2.5313\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n15663\n-122.44\n37.80\n52.0\n3830.0\n537.870553\n1310.0\n963.0\n3.4801\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n20484\n-118.72\n34.28\n17.0\n3051.0\n537.870553\n1705.0\n495.0\n5.7376\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n9814\n-121.93\n36.62\n34.0\n2351.0\n537.870553\n1063.0\n428.0\n3.7250\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n15362\n-117.22\n33.36\n16.0\n3165.0\n482.000000\n1351.0\n452.0\n4.6050\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n16623\n-120.83\n35.36\n28.0\n4323.0\n886.000000\n1650.0\n705.0\n2.7266\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n18086\n-122.05\n37.31\n25.0\n4111.0\n538.000000\n1585.0\n568.0\n9.2298\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n2144\n-119.76\n36.77\n36.0\n2507.0\n466.000000\n1227.0\n474.0\n2.7850\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n3665\n-118.37\n34.22\n17.0\n1787.0\n463.000000\n1671.0\n448.0\n3.5521\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n4128 rows × 13 columns\n\n\n\n\n\ny_train\n\n\n\n\n\n\n\n\n\nmedian_house_value\n\n\n\n\n14196\n103000.0\n\n\n8267\n382100.0\n\n\n17445\n172600.0\n\n\n14265\n93400.0\n\n\n2271\n96500.0\n\n\n...\n...\n\n\n11284\n229200.0\n\n\n11964\n97800.0\n\n\n5390\n222100.0\n\n\n860\n283500.0\n\n\n15795\n325000.0\n\n\n\n\n16512 rows × 1 columns\n\n\n\n\n\ny_test\n\n\n\n\n\n\n\n\n\nmedian_house_value\n\n\n\n\n20046\n47700.0\n\n\n3024\n45800.0\n\n\n15663\n500001.0\n\n\n20484\n218600.0\n\n\n9814\n278000.0\n\n\n...\n...\n\n\n15362\n263300.0\n\n\n16623\n266800.0\n\n\n18086\n500001.0\n\n\n2144\n72300.0\n\n\n3665\n151500.0\n\n\n\n\n4128 rows × 1 columns"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#regresi-linier-sederhana",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#regresi-linier-sederhana",
    "title": "Modul 4 Sains Data: Regresi",
    "section": "Regresi Linier Sederhana",
    "text": "Regresi Linier Sederhana\nUntuk satu variabel bebas \\(x\\), rumus garis untuk regresi linier sederhana adalah sebagai berikut:\n\\[y = \\beta_0 + \\beta_1 x\\]\nIngin ditemukan nilai \\(\\beta_0\\) dan \\(\\beta_1\\) yang meminimalkan SSE.\n(Ada juga yang menulis \\(y = \\theta_0 + \\theta_1 x\\), sama saja)\nMari kita pilih terlebih dahulu, variabel bebas apa yang ingin kita gunakan.\n\ndf\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 14 columns\n\n\n\n\nMisalkan kita ingin menggunakan fitur median_income sebagai prediktor untuk mencoba memprediksi variabel target median_house_value. (Asumsinya, mungkin harga rumah kurang lebih berbanding lurus dengan penghasilan.)\n\nx1_train = X_train[[\"median_income\"]]\nx1_test = X_test[[\"median_income\"]]\n\n\nx1_train\n\n\n\n\n\n\n\n\n\nmedian_income\n\n\n\n\n14196\n3.2596\n\n\n8267\n3.8125\n\n\n17445\n4.1563\n\n\n14265\n1.9425\n\n\n2271\n3.5542\n\n\n...\n...\n\n\n11284\n6.3700\n\n\n11964\n3.0500\n\n\n5390\n2.9344\n\n\n860\n5.7192\n\n\n15795\n2.5755\n\n\n\n\n16512 rows × 1 columns\n\n\n\n\n\nx1_test\n\n\n\n\n\n\n\n\n\nmedian_income\n\n\n\n\n20046\n1.6812\n\n\n3024\n2.5313\n\n\n15663\n3.4801\n\n\n20484\n5.7376\n\n\n9814\n3.7250\n\n\n...\n...\n\n\n15362\n4.6050\n\n\n16623\n2.7266\n\n\n18086\n9.2298\n\n\n2144\n2.7850\n\n\n3665\n3.5521\n\n\n\n\n4128 rows × 1 columns\n\n\n\n\nAda beberapa cara untuk melakukan regresi linier sederhana di Python.\n\nscikit-learn\n\nfrom sklearn.linear_model import LinearRegression\n\nLinearRegression adalah class yang dapat menghasilkan objek (inget-inget lagi materi OOP di praktikum Struktur Data :D), dengan tiap objek itu adalah model regresi linier tersendiri.\nSehingga, untuk membuat model regresi linier, kita buat objeknya terlebih dahulu:\n\nlinreg1 = LinearRegression()\n\nTraining dilakukan dengan method .fit()\n\nlinreg1.fit(x1_train, y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\nSetelah dilakukan .fit(), model linreg1 sudah selesai training.\nKita bisa memperoleh nilai parameter \\(\\beta_0\\) dan \\(\\beta_1\\) melalui atribut .intercept_ dan .coef_\n\nlinreg1.intercept_\n\narray([44459.72916908])\n\n\n\nlinreg1.coef_\n\narray([[41933.84939381]])\n\n\n\nlinreg1_b0 = linreg1.intercept_[0]\nlinreg1_b1 = linreg1.coef_[0][0]\n\n\nprint(\"y =\", linreg1_b0, \"+\", linreg1_b1, \"x\")\n\ny = 44459.72916907875 + 41933.84939381272 x\n\n\nPrediksi dilakukan dengan method .predict()\n\ny_pred1 = linreg1.predict(x1_test)\n\n\ny_pred1\n\narray([[114958.91676996],\n       [150606.88213964],\n       [190393.71844449],\n       ...,\n       [431500.77230409],\n       [161245.49973085],\n       [193412.95560084]])\n\n\n\n\nSolusi eksak: metode least squares\nMetode least squares menyediakan “solusi eksak” (dijamin meminimalkan loss function) untuk regresi linier sederhana, sebagai berikut:\n\\[\\beta_1 = \\frac{n \\left( \\sum_{i=1}^{n} x_i y_i \\right) - \\left( \\sum_{i=1}^{n} x_i \\right) \\left( \\sum_{i=1}^{n} y_i \\right)}{n \\left( \\sum_{i=1}^{n} \\left(x_i\\right)^2 \\right) - \\left( \\sum_{i=1}^{n} x_i \\right)^2}\\]\n\\[\\beta_0 = \\bar{y} - \\beta_1 \\bar{x}\\]\ndengan\n\\[\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\\]\n\\[\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i\\]\n\ndef least_squares_sederhana(x, y):\n    n = len(y)\n    x = np.array(x)\n    y = np.array(y)\n    \n    sum_x = sum(x)\n    sum_y = sum(y)\n    sum_x2 = sum(x**2)\n    sum_xy = sum(x*y)\n    \n    atas = n*(sum_xy) - (sum_x)*(sum_y)\n    bawah = n * sum_x2 - (sum_x)**2\n    beta1 = atas/bawah\n\n    mean_x = sum_x / n\n    mean_y = sum_y / n\n\n    beta0 = mean_y - beta1 * mean_x\n\n    return (beta0[0], beta1[0])\n\n\nlinreg2_betas = least_squares_sederhana(x1_train, y_train)\n\n\nlinreg2_betas\n\n(44459.72916908396, 41933.849393811244)\n\n\n\nlinreg2_beta0, linreg2_beta1 = linreg2_betas\n\nUntuk melakukan prediksi, ikuti rumus model (bentuk umum) \\(y = \\beta_0 + \\beta_1 x\\):\n\ny_pred2 = np.array(linreg2_beta0 + linreg2_beta1 * x1_test)\n\n\ny_pred2\n\narray([[114958.91676996],\n       [150606.88213964],\n       [190393.71844449],\n       ...,\n       [431500.77230408],\n       [161245.49973085],\n       [193412.95560084]])\n\n\n\n\nTambahan: statsmodels\nscikit-learn adalah package di Python untuk kebutuhan sains data dan/atau machine learning dasar.\nKarena regresi linier juga dibahas di dunia statistika, ada package statistika bernama “statsmodels” yang juga menyediakan model regresi linier, yang disebut OLS (ordinary least squares). Bedanya, model regresi linier dari statsmodels menyediakan lebih banyak statistik seputar model. Mari kita coba.\nKalau belum punya, install terlebih dahulu:\n\n!pip install statsmodels\n\nKemudian import:\n\nimport statsmodels.api as sm\n\nSebelum membuat model, statsmodels memerlukan adanya kolom intercept di variabel prediktor, yaitu kolom yang berisi konstanta yaitu 1 semua.\n\nx1_train_sm = sm.add_constant(x1_train)\n\nModel OLS bisa diakses melalui sm.OLS, yang lagi-lagi merupakan class\n\nlinreg3_OLS = sm.OLS(y_train, x1_train_sm)\n\nAgak berbeda dengan scikit-learn, statsmodels menghasilkan objek baru lagi (yang menyimpan hasilnya) ketika dilakukan training dengan .fit()\n\nlinreg3 = linreg3_OLS.fit()\n\nKita bisa lihat hasilnya:\n\nprint(linreg3.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:     median_house_value   R-squared:                       0.477\nModel:                            OLS   Adj. R-squared:                  0.477\nMethod:                 Least Squares   F-statistic:                 1.506e+04\nDate:                Mon, 01 Apr 2024   Prob (F-statistic):               0.00\nTime:                        14:33:59   Log-Likelihood:            -2.1058e+05\nNo. Observations:               16512   AIC:                         4.212e+05\nDf Residuals:                   16510   BIC:                         4.212e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nconst          4.446e+04   1477.242     30.096      0.000    4.16e+04    4.74e+04\nmedian_income  4.193e+04    341.735    122.709      0.000    4.13e+04    4.26e+04\n==============================================================================\nOmnibus:                     3353.131   Durbin-Watson:                   1.982\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             7339.541\nSkew:                           1.175   Prob(JB):                         0.00\nKurtosis:                       5.268   Cond. No.                         10.2\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nParameter \\(\\beta_0\\) dan \\(\\beta_1\\) bisa diperoleh melalui atribut .params\n\nlinreg3_betas = linreg3.params\n\n\nlinreg3_betas\n\nconst            44459.729169\nmedian_income    41933.849394\ndtype: float64\n\n\n\nlinreg3_beta0 = linreg3_betas[\"const\"]\nlinreg3_beta1 = linreg3_betas[\"median_income\"]\n\n\nprint(\"y =\", linreg3_beta0, \"+\", linreg3_beta1, \"x\")\n\ny = 44459.729169078724 + 41933.8493938127 x\n\n\nPrediksi dengan .predict()\n\nx1_test_sm = sm.add_constant(x1_test)\n\n\ny_pred3 = linreg3.predict(x1_test_sm)\n\n\ny_pred3\n\n20046    114958.916770\n3024     150606.882140\n15663    190393.718444\n20484    285059.383451\n9814     200663.318161\n             ...      \n15362    237565.105628\n16623    158796.562926\n18086    431500.772304\n2144     161245.499731\n3665     193412.955601\nLength: 4128, dtype: float64"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#metrik-evaluasi-untuk-regresi",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#metrik-evaluasi-untuk-regresi",
    "title": "Modul 4 Sains Data: Regresi",
    "section": "Metrik Evaluasi untuk Regresi",
    "text": "Metrik Evaluasi untuk Regresi\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n\nmean_absolute_error(y_test, y_pred1)\n\n62990.86530093761\n\n\n\nmean_squared_error(y_test, y_pred1)\n\n7091157771.76555\n\n\n\nr2_score(y_test, y_pred1)\n\n0.45885918903846656"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#regresi-linier-berganda",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#regresi-linier-berganda",
    "title": "Modul 4 Sains Data: Regresi",
    "section": "Regresi Linier Berganda",
    "text": "Regresi Linier Berganda\n\nlinreg4 = LinearRegression()\n\n\nX_train\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n14196\n-117.03\n32.71\n33.0\n3126.0\n627.0\n2300.0\n623.0\n3.2596\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n8267\n-118.16\n33.77\n49.0\n3382.0\n787.0\n1314.0\n756.0\n3.8125\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n17445\n-120.48\n34.66\n4.0\n1897.0\n331.0\n915.0\n336.0\n4.1563\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n14265\n-117.11\n32.69\n36.0\n1421.0\n367.0\n1418.0\n355.0\n1.9425\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n2271\n-119.80\n36.78\n43.0\n2382.0\n431.0\n874.0\n380.0\n3.5542\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n11284\n-117.96\n33.78\n35.0\n1330.0\n201.0\n658.0\n217.0\n6.3700\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n11964\n-117.43\n34.02\n33.0\n3084.0\n570.0\n1753.0\n449.0\n3.0500\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n5390\n-118.38\n34.03\n36.0\n2101.0\n569.0\n1756.0\n527.0\n2.9344\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n860\n-121.96\n37.58\n15.0\n3575.0\n597.0\n1777.0\n559.0\n5.7192\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n15795\n-122.42\n37.77\n52.0\n4226.0\n1315.0\n2619.0\n1242.0\n2.5755\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n\n\n16512 rows × 13 columns\n\n\n\n\n\ny_train\n\n\n\n\n\n\n\n\n\nmedian_house_value\n\n\n\n\n14196\n103000.0\n\n\n8267\n382100.0\n\n\n17445\n172600.0\n\n\n14265\n93400.0\n\n\n2271\n96500.0\n\n\n...\n...\n\n\n11284\n229200.0\n\n\n11964\n97800.0\n\n\n5390\n222100.0\n\n\n860\n283500.0\n\n\n15795\n325000.0\n\n\n\n\n16512 rows × 1 columns\n\n\n\n\n\nlinreg4.fit(X_train, y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\nlinreg4.intercept_\n\narray([-2256620.79885445])\n\n\n\nlinreg4.coef_\n\narray([[-2.68382734e+04, -2.54683520e+04,  1.10218508e+03,\n        -6.02150567e+00,  1.02789395e+02, -3.81729064e+01,\n         4.82527528e+01,  3.94739752e+04, -1.89265829e+04,\n        -5.87132390e+04,  1.17198490e+05, -2.40632251e+04,\n        -1.54954428e+04]])\n\n\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_{13} x_{13}\\]\n\ny_pred4 = linreg4.predict(X_test)\n\n\ny_pred4\n\narray([[ 64629.45079786],\n       [134799.34083607],\n       [266063.38139054],\n       ...,\n       [439180.98341181],\n       [120797.55240621],\n       [183386.04993584]])\n\n\n\ny_test\n\n\n\n\n\n\n\n\n\nmedian_house_value\n\n\n\n\n20046\n47700.0\n\n\n3024\n45800.0\n\n\n15663\n500001.0\n\n\n20484\n218600.0\n\n\n9814\n278000.0\n\n\n...\n...\n\n\n15362\n263300.0\n\n\n16623\n266800.0\n\n\n18086\n500001.0\n\n\n2144\n72300.0\n\n\n3665\n151500.0\n\n\n\n\n4128 rows × 1 columns\n\n\n\n\n\nmean_absolute_error(y_test, y_pred4)\n\n50701.77903133001\n\n\n\nmean_squared_error(y_test, y_pred4)\n\n4904399775.949288\n\n\n\nr2_score(y_test, y_pred4)\n\n0.6257351821159695\n\n\nBandingkan dengan hasil regresi linier sederhana yang kita coba sebelumnya:\n\nprint(\"Hasil regresi linier sederhana (model linreg1)\")\nprint(\"MAE:\", mean_absolute_error(y_test, y_pred1))\nprint(\"MSE\", mean_squared_error(y_test, y_pred1))\nprint(\"R^2:\", r2_score(y_test, y_pred1))\n\nHasil regresi linier sederhana (model linreg1)\nMAE: 62990.86530093761\nMSE 7091157771.76555\nR^2: 0.45885918903846656"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#regresi-logistik",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#regresi-logistik",
    "title": "Modul 4 Sains Data: Regresi",
    "section": "Regresi Logistik",
    "text": "Regresi Logistik\n\nfrom sklearn.linear_model import LogisticRegression\n\n\nlogreg1 = LogisticRegression()\n\n\ndf.describe()\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\ncount\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n20640.000000\n\n\nmean\n-119.569704\n35.631861\n28.639486\n2635.763081\n537.870553\n1425.476744\n499.539680\n3.870671\n206855.816909\n0.442636\n0.317393\n0.000242\n0.110950\n0.128779\n\n\nstd\n2.003532\n2.135952\n12.585558\n2181.615252\n419.266592\n1132.462122\n382.329753\n1.899822\n115395.615874\n0.496710\n0.465473\n0.015563\n0.314077\n0.334963\n\n\nmin\n-124.350000\n32.540000\n1.000000\n2.000000\n1.000000\n3.000000\n1.000000\n0.499900\n14999.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n-121.800000\n33.930000\n18.000000\n1447.750000\n297.000000\n787.000000\n280.000000\n2.563400\n119600.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n50%\n-118.490000\n34.260000\n29.000000\n2127.000000\n438.000000\n1166.000000\n409.000000\n3.534800\n179700.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n75%\n-118.010000\n37.710000\n37.000000\n3148.000000\n643.250000\n1725.000000\n605.000000\n4.743250\n264725.000000\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n\n\nmax\n-114.310000\n41.950000\n52.000000\n39320.000000\n6445.000000\n35682.000000\n6082.000000\n15.000100\n500001.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n\n\n\n\n\ndf2 = df.copy()\n\n\ndf2[[\"many_rooms\"]] = (df2[[\"total_rooms\"]] &gt;= 2000)\n\n\ndf2\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\nmany_rooms\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\nFalse\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\nTrue\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\nFalse\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\nFalse\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\nFalse\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\nFalse\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\nTrue\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\nFalse\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\nTrue\n\n\n\n\n20640 rows × 15 columns\n\n\n\n\n\ndf2 = df2.drop(columns=[\"total_rooms\"], axis=1)\n\n\ndf2\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\nmany_rooms\n\n\n\n\n0\n-122.23\n37.88\n41.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\nFalse\n\n\n1\n-122.22\n37.86\n21.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\nTrue\n\n\n2\n-122.24\n37.85\n52.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\nFalse\n\n\n3\n-122.25\n37.85\n52.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\nFalse\n\n\n4\n-122.25\n37.85\n52.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\nFalse\n\n\n20636\n-121.21\n39.49\n18.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\nFalse\n\n\n20637\n-121.22\n39.43\n17.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\nTrue\n\n\n20638\n-121.32\n39.43\n18.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\nFalse\n\n\n20639\n-121.24\n39.37\n16.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\nTrue\n\n\n\n\n20640 rows × 14 columns\n\n\n\n\n\nX2 = df2.drop(columns=[\"many_rooms\"], axis=1)\ny2 = df2[[\"many_rooms\"]]\n\n\nX2\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 13 columns\n\n\n\n\n\ny2\n\n\n\n\n\n\n\n\n\nmany_rooms\n\n\n\n\n0\nFalse\n\n\n1\nTrue\n\n\n2\nFalse\n\n\n3\nFalse\n\n\n4\nFalse\n\n\n...\n...\n\n\n20635\nFalse\n\n\n20636\nFalse\n\n\n20637\nTrue\n\n\n20638\nFalse\n\n\n20639\nTrue\n\n\n\n\n20640 rows × 1 columns\n\n\n\n\n\nX2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n\n\nlogreg1.fit(X2_train, y2_train)\n\n/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n\n\nLogisticRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression()\n\n\n\ny2_pred = logreg1.predict(X2_test)\n\n\ny2_pred\n\narray([ True,  True,  True, ...,  True,  True,  True])\n\n\n\ny2_test\n\n\n\n\n\n\n\n\n\nmany_rooms\n\n\n\n\n20046\nFalse\n\n\n3024\nTrue\n\n\n15663\nTrue\n\n\n20484\nTrue\n\n\n9814\nTrue\n\n\n...\n...\n\n\n15362\nTrue\n\n\n16623\nTrue\n\n\n18086\nTrue\n\n\n2144\nTrue\n\n\n3665\nFalse\n\n\n\n\n4128 rows × 1 columns\n\n\n\n\n\nfrom sklearn.metrics import confusion_matrix\n\n\nconfusion_matrix(y2_test, y2_pred)\n\n\nfrom sklearn.metrics import log_loss, jaccard_score\n\n\nlog_loss(y2_test, y2_pred)\n\n4.584040220272894\n\n\n\njaccard_score(y2_test, y2_pred)\n\n0.7894947874899759"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul2.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul2.html",
    "title": "Modul 2 Sains Data: Visualisasi Data",
    "section": "",
    "text": "Kembali ke Sains Data\nPada modul ini kita akan mempelajari beberapa cara untuk membuat visualisasi data menggunakan package Matplotlib dan Seaborn. Seaborn merupakan salah satu package visualisasi data yang sangat sering digunakan karena fleksibilitas dan banyaknya jenis plot yang disediakan."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#prerequisites",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#prerequisites",
    "title": "Modul 2 Sains Data: Visualisasi Data",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nImport Module\nSebelum memulai, mari kita import terlebih dahulu module - module yang diperlukan.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\nImport Data\nPada module kali ini, akan digunakan tiga data csv yang berbeda untuk mempermudah kebutuhan visualisasi, yaitu:\n\nSpotify Dataset (spotify.csv), bisa di-download dari\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle\nGoogle Drive: https://bit.ly/DataWeek2 atau langsung\n\nFlight Delays Dataset (flight_delays.csv), bisa di-download dari\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle\nGoogle Drive: https://bit.ly/DataWeek2 atau langsung\n\nInsurance Dataset (insurance.csv), bisa di-download dari\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle\nGoogle Drive: https://bit.ly/DataWeek2 atau langsung\n\n\natau langsung download ketiganya sekaligus, bisa dari:\n\nGoogle Drive: https://bit.ly/DataWeek2 atau langsung\n\nKemudian, baca tiap CSV sebagai dataframe:\n\nspotify_df = pd.read_csv(\"./spotify.csv\",\n                         index_col='Date',\n                         parse_dates=['Date'])\nflight_df = pd.read_csv(\"./flight_delays.csv\")\ninsurance_df = pd.read_csv(\"./insurance.csv\")"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#review-matplotlib",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#review-matplotlib",
    "title": "Modul 2 Sains Data: Visualisasi Data",
    "section": "Review Matplotlib",
    "text": "Review Matplotlib\nSeperti yang sudah dipelajari pada Algoritma dan Pemrograman, visualisasi data dapat dilakukan dengan module matplotlib, antara lain untuk membuat line plot dan scatter plot.\nPertama, kita akan menggunakan data Spotify, yaitu data total daily streams 5 lagu hits pada masanya.\n\nspotify_df\n\n\n\n\n\n\n\n\n\nShape of You\nDespacito\nSomething Just Like This\nHUMBLE.\nUnforgettable\n\n\nDate\n\n\n\n\n\n\n\n\n\n2017-01-06\n12287078\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-07\n13190270\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-08\n13099919\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-09\n14506351\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-10\n14275628\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n\n\n2018-01-05\n4492978\n3450315.0\n2408365.0\n2685857.0\n2869783.0\n\n\n2018-01-06\n4416476\n3394284.0\n2188035.0\n2559044.0\n2743748.0\n\n\n2018-01-07\n4009104\n3020789.0\n1908129.0\n2350985.0\n2441045.0\n\n\n2018-01-08\n4135505\n2755266.0\n2023251.0\n2523265.0\n2622693.0\n\n\n2018-01-09\n4168506\n2791601.0\n2058016.0\n2727678.0\n2627334.0\n\n\n\n\n366 rows × 5 columns\n\n\n\n\nCatatan:\n\nShape of You dirilis tanggal 6 Januari 2017.\nDespacito dirilis tanggal 13 Januari 2017.\nSomething Just Like This dirilis tanggal 22 Februari 2017.\nHUMBLE. dirilis tanggal 30 Maret 2017.\nUnforgettable dirilis tanggal 7 April 2017.\n\nPerhatikan bahwa ada beberapa data NaN (not a number), artinya tidak ada data (missing data).\n\nspotify_df.isna()\n\n\n\n\n\n\n\n\n\nShape of You\nDespacito\nSomething Just Like This\nHUMBLE.\nUnforgettable\n\n\nDate\n\n\n\n\n\n\n\n\n\n2017-01-06\nFalse\nTrue\nTrue\nTrue\nTrue\n\n\n2017-01-07\nFalse\nTrue\nTrue\nTrue\nTrue\n\n\n2017-01-08\nFalse\nTrue\nTrue\nTrue\nTrue\n\n\n2017-01-09\nFalse\nTrue\nTrue\nTrue\nTrue\n\n\n2017-01-10\nFalse\nTrue\nTrue\nTrue\nTrue\n\n\n...\n...\n...\n...\n...\n...\n\n\n2018-01-05\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2018-01-06\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2018-01-07\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2018-01-08\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2018-01-09\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n366 rows × 5 columns\n\n\n\n\n\nspotify_df.isna().sum()\n\nShape of You                 0\nDespacito                    7\nSomething Just Like This    47\nHUMBLE.                     84\nUnforgettable               91\ndtype: int64\n\n\nCara menangani missing values tergantung konteks. Di sini, lagu-lagu dengan data NaN pada tanggal tertentu memang belum dirilis.\n\nUntuk analisis trend tiap lagu sejak dirilis, sebaiknya data NaN dibiarkan saja.\nUntuk analisis frekuensi streaming, data NaN bisa diganti jadi nol. (Hati-hati, jangan sampai nantinya lupa dan malah terpikir “kok bisa ya lagu ini ga didengerin sama sekali”)\nApabila semua lagu ingin dibandingkan datanya di masa sudah rilis semua, sebaiknya baris-baris dengan data NaN itu dihapus.\n\nKali ini, kita akan memperhatikan trend tiap lagu, sehingga data NaN kita biarkan saja.\nBerikut adalah cara untuk membuat line plot pada satu fitur di dataframe menggunakan matplotlib\n\n\"\"\"\nMembuat line plot untuk lagu Shape of You menggunakan matplotlib\n\"\"\"\n\n# Mengatur besar figur plot\nplt.subplots(figsize=(8,6))\n\n# Membuat line plot\nplt.plot(spotify_df['Shape of You'], 'b')\n# Membuat label sumbu-x dan sumbu-y\nplt.xlabel('Date')\nplt.ylabel('Shape of You Total Daily Streams')\n# Menampilkan plot\nplt.show()\n\n\n\n\n\n\n\n\nApabila kita ingin menampilkan fitur-fitur lain dalam figur yang sama, kita dapat memanfaatkan loop\n\n\"\"\"\nMembuat line plot untuk semua lagu dalam spotify_df menggunakan loop\n\"\"\"\n\nplt.subplots(figsize=(8,6))\n\n# Loop setiap nama kolom pada dataframe, lalu plot\nfor column in spotify_df.columns:\n    plt.plot(spotify_df[column])\n\nplt.legend(spotify_df.columns)\nplt.show()\n\n\n\n\n\n\n\n\nNamun, terdapat cara yang lebih mudah selain menggunakan looping. pandas dataframe memiliki method yang dapat secara langsung memvisualisasikan keseluruhan fiturnya, yaitu .plot().\nPada .plot() kita memiliki beberapa parameter yang dapat diatur, antara lain kind dan figsize. kind berfungsi untuk mengatur jenis plot yang ingin kita buat, sedangkan figsize berfungsi untuk mengatur besar figur yang dihasilkan.\nParameter lainnya dapat dilihat pada:\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n\n\"\"\"\nMembuat line plot untuk semua lagu dalam spotify_df menggunakan pandas .plot()\n\"\"\"\n\nspotify_df.plot(kind='line', figsize=(8,6))\nplt.xlabel('Date')\nplt.ylabel('Total Daily Streams')\nplt.show()\n\n\n\n\n\n\n\n\nSelain line plot, terdapat banyak macam kind yang bisa digunakan. Pada code cell dibawah terlihat bahwa pandas .plot() dapat menghasilkan histogram (perlu diperhatikan bahwa jenis plot perlu menyesuaikan tipe data yang dimiliki, terlihat bahwa menggunakan data spotify, histogram tidak menghasilkan insight yang cukup berguna).\n\nspotify_df.plot(kind='hist', figsize=(8,6), alpha=.7)\n\nplt.show()\n\n\n\n\n\n\n\n\nPada praktikum Algoritma dan Pemrograman kita juga telah mempelajari cara untuk membuat scatter plot. Berikut code untuk membuat scatter plot menggunakan matplotlib, untuk melihat korelasi antara daily streams lagu Shape of You dengan Something Just Like This.\n\n\"\"\"\nMembuat scatter plot untuk melihat korelasi antara lagu\nShape of You dengan Something Just Like This menggunakan\nmatplotlib\n\"\"\"\n\nplt.subplots(figsize=(8,6))\n\nplt.scatter(x=spotify_df['Shape of You'], \n            y=spotify_df['Something Just Like This'],\n            alpha=.5)\nplt.xlabel('\"Shape of You\" Total Daily Streams')\nplt.ylabel('\"Something Just Like This\" Total Daily Streams')\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#pengenalan-seaborn",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#pengenalan-seaborn",
    "title": "Modul 2 Sains Data: Visualisasi Data",
    "section": "Pengenalan Seaborn",
    "text": "Pengenalan Seaborn\nWalaupun matplotlib cukup fleksibel dalam menghasilkan plot, tetapi tipe plot yang disediakan cenderung terbatas. Oleh karena itu, kita dapat menggunakan Seaborn karena tipe plot yang disediakan sangat banyak sesuai kebutuhan kita, antara lain line, bar, heatmap, scatter, box, swarm, histogram, density, dan masih banyak lagi.\n\nLine Plot\nLine plot biasa digunakan untuk melihat trend data dalam jangka waktu tertentu.\nUntuk membuat line plot pada seaborn, kita dapat menggunakan sns.lineplot(). Jika data yang ingin kita visualisasikan adalah dataframe, kita dapat memasukkan variabel dataframe tersebut pada parameter data, seperti code di bawah ini.\n\n\"\"\"\nMembuat line plot dengan module seaborn\n\"\"\"\n\nplt.subplots(figsize=(8,6))\nsns.lineplot(data=spotify_df)\nplt.show()\n\n\n\n\n\n\n\n\nFleksibilitas Seaborn membuat kita dapat memilih color palette yang sesuai dengan keinginan kita. Kita dapat memilih palette yang sudah disediakan oleh seaborn (antara lain: bright, deep, pastel, dan masih banyak lagi) atau kita dapat mengatur sendiri palette yang ingin kita gunakan.\nUntuk memilih palette yang akan digunakan untuk plot selanjutnya pada seaborn, kita dapat menggunakan sns.set_palette().\nJenis palette yang disediakan seaborn serta cara membuat color palette secara mandiri dapat dilihat pada:\nhttps://seaborn.pydata.org/tutorial/color_palettes.html#tools-for-choosing-color-palettes\n\n# Mengganti color palette menjadi \"bright\"\nsns.set_palette('bright')\n\n\n\"\"\"\nMembuat line plot setelah color palette diubah menjadi \"bright\"\n\"\"\"\n\n# Mengatur besar figur yang ingin ditampilkan\nplt.figure(figsize=(14,6))\n\n# Membuat line plot\nsns.lineplot(data=spotify_df)\n# Membuat judul figur\nplt.title(\"Daily Global Streams of Popular Songs in 2017-2018\")\n# Menampilkan plot\nplt.show()\n\n\n\n\n\n\n\n\nApabila tidak semua fitur pada data ingin kita visualisasikan, kita dapat menggunakan sns.lineplot() beberapa kali, sesuai dengan banyaknya fitur yang ingin kita tampilkan, seperti pada code di bawah.\n\nplt.figure(figsize=(14,6))\n\n# Membuat line plot hanya dengan lagu Shape of You\nsns.lineplot(data=spotify_df['Shape of You'], label=\"Shape of You\")\n# Menambahkan line plot pada figur dengan lagu Despacito\nsns.lineplot(data=spotify_df['Despacito'], label=\"Despacito\")\n\nplt.title(\"Daily Global Streams of Popular Songs in 2017-2018\")\nplt.xlabel(\"Date\")\nplt.ylabel('')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBar Plot\nBar plot biasa digunakan untuk membandingkan kuantitas/nilai pada data bertipe kategori.\nSelanjutnya, kita akan menggunakan data flight_delays.csv, yaitu data rata-rata keterlambatan beberapa maskapai pesawat pada setiap bulannya.\n\nflight_df\n\n\n\n\n\n\n\n\n\nMonth\nAA\nAS\nB6\nDL\nEV\nF9\nHA\nMQ\nNK\nOO\nUA\nUS\nVX\nWN\n\n\n\n\n0\n1\n6.955843\n-0.320888\n7.347281\n-2.043847\n8.537497\n18.357238\n3.512640\n18.164974\n11.398054\n10.889894\n6.352729\n3.107457\n1.420702\n3.389466\n\n\n1\n2\n7.530204\n-0.782923\n18.657673\n5.614745\n10.417236\n27.424179\n6.029967\n21.301627\n16.474466\n9.588895\n7.260662\n7.114455\n7.784410\n3.501363\n\n\n2\n3\n6.693587\n-0.544731\n10.741317\n2.077965\n6.730101\n20.074855\n3.468383\n11.018418\n10.039118\n3.181693\n4.892212\n3.330787\n5.348207\n3.263341\n\n\n3\n4\n4.931778\n-3.009003\n2.780105\n0.083343\n4.821253\n12.640440\n0.011022\n5.131228\n8.766224\n3.223796\n4.376092\n2.660290\n0.995507\n2.996399\n\n\n4\n5\n5.173878\n-1.716398\n-0.709019\n0.149333\n7.724290\n13.007554\n0.826426\n5.466790\n22.397347\n4.141162\n6.827695\n0.681605\n7.102021\n5.680777\n\n\n5\n6\n8.191017\n-0.220621\n5.047155\n4.419594\n13.952793\n19.712951\n0.882786\n9.639323\n35.561501\n8.338477\n16.932663\n5.766296\n5.779415\n10.743462\n\n\n6\n7\n3.870440\n0.377408\n5.841454\n1.204862\n6.926421\n14.464543\n2.001586\n3.980289\n14.352382\n6.790333\n10.262551\nNaN\n7.135773\n10.504942\n\n\n7\n8\n3.193907\n2.503899\n9.280950\n0.653114\n5.154422\n9.175737\n7.448029\n1.896565\n20.519018\n5.606689\n5.014041\nNaN\n5.106221\n5.532108\n\n\n8\n9\n-1.432732\n-1.813800\n3.539154\n-3.703377\n0.851062\n0.978460\n3.696915\n-2.167268\n8.000101\n1.530896\n-1.794265\nNaN\n0.070998\n-1.336260\n\n\n9\n10\n-0.580930\n-2.993617\n3.676787\n-5.011516\n2.303760\n0.082127\n0.467074\n-3.735054\n6.810736\n1.750897\n-2.456542\nNaN\n2.254278\n-0.688851\n\n\n10\n11\n0.772630\n-1.916516\n1.418299\n-3.175414\n4.415930\n11.164527\n-2.719894\n0.220061\n7.543881\n4.925548\n0.281064\nNaN\n0.116370\n0.995684\n\n\n11\n12\n4.149684\n-1.846681\n13.839290\n2.504595\n6.685176\n9.346221\n-1.706475\n0.662486\n12.733123\n10.947612\n7.012079\nNaN\n13.498720\n6.720893\n\n\n\n\n\n\n\n\nUntuk membuat bar plot pada seaborn dengan dataframe, kita dapat menggunakan sns.barplot() dengan tiga parameter yang wajib kita set, yaitu:\n\ndata: dataframe yang ingin kita visualisasikan\nx: nama fitur pada dataframe yang ingin kita jadikan sumbu-x\ny: nama fitur pada dataframe yang ingin kita jadikan sumbu-y\n\nPada kode di bawah, juga digunakan satu parameter opsional, yaitu palette yang merupakan cara lain untuk mengatur color palette yang ingin kita gunakan\n\n\"\"\"\nMembuat bar plot keterlambatan maskapai EV setiap \nbulannya menggunakan seaborn\n\"\"\"\n\nplt.figure(figsize=(14,6))\n\nsns.barplot(data=flight_df, x='Month', y='EV',\n            palette=sns.color_palette('deep'))\nplt.ylabel('EV Flight Delays (minute)')\nplt.title('Average EV Flight Delays per Month')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan hasil plot di atas, terlihat bahwa maskapai EV memiliki rata-rata keterlambatan terlama pada bulan Juni, serta tercepat pada bulan September.\nSelanjutnya, mari kita coba lihat urutan rata-rata keterlambatan semua maskapai dalam satu tahun (maskapai mana yang memiliki rata-rata keterlambatan terlama, serta maskapai mana yang tercepat).\nHal pertama yang perlu kita lakukan adalah, jadikan fitur Month sebagai index dataframe.\n\n# Set fitur \"Month\" menjadi index dataframe\nflight_df = flight_df.set_index('Month')\nflight_df.head(2)\n\n\n\n\n\n\n\n\n\nAA\nAS\nB6\nDL\nEV\nF9\nHA\nMQ\nNK\nOO\nUA\nUS\nVX\nWN\n\n\nMonth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n6.955843\n-0.320888\n7.347281\n-2.043847\n8.537497\n18.357238\n3.512640\n18.164974\n11.398054\n10.889894\n6.352729\n3.107457\n1.420702\n3.389466\n\n\n2\n7.530204\n-0.782923\n18.657673\n5.614745\n10.417236\n27.424179\n6.029967\n21.301627\n16.474466\n9.588895\n7.260662\n7.114455\n7.784410\n3.501363\n\n\n\n\n\n\n\n\nSelanjutnya, kita perlu hitung rata-rata keterlambatan tiap maskapai dalam satu tahun, yaitu hitung rata-rata tiap kolom pada dataframe menggunakan .mean() (Tambahan: apabila kita ingin menghitung rata-rata tiap barisnya, kita dapat menggunakan parameter axis=1 pada .mean()). .mean() akan menghasilkan pandas Series.\nLalu, agar mempermudah kita dalam melihat visualisasi bar plotnya, kita dapat menggunakan .sort_values().\n\n# Simpan rata-rata keterlambatan semua maskapai dalam satu tahun pada variabel flight_mean_inyear\nflight_mean_inyear = flight_df.mean()\n# Urutkan flight_mean_inyear secara ascending\nflight_mean_inyear = flight_mean_inyear.sort_values()\n\nflight_mean_inyear\n\nAS    -1.023656\nDL     0.231116\nHA     1.993205\nUS     3.776815\nAA     4.120776\nWN     4.275277\nVX     4.717718\nUA     5.413415\nOO     5.909658\nMQ     5.964953\nEV     6.543328\nB6     6.788370\nF9    13.035736\nNK    14.549663\ndtype: float64\n\n\nTerakhir, visualisasikan bar plot menggunakan cara seperti sebelumnya.\nKita dapat lihat pada code dibawah bahwa tidak digunakan parameter data, karena flight_mean_inyear merupakan pandas Series (bukan dataframe) sehingga lebih mudah jika kita langsung menggunakan parameter x dan y saja.\n\nplt.subplots(figsize=(14,6))\nsns.barplot(x=flight_mean_inyear.index, \n            y=flight_mean_inyear.values,\n            palette=sns.color_palette('deep'))\nplt.title('Average Delay per Flight in a Year')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan plot diatas, NK merupakan maskapai dengan rata-rata keterlambatan terlama dalam satu tahun, sedangkan AS adalah yang tercepat (AS bernilai negatif yang berarti rata-rata kedatangan pesawat lebih cepat dari yang dijadwalkan dalam satu tahun.\n\n\nHeatmap\nHeatmap biasa digunakan untuk mempermudah melihat pola pada data berdasarkan warna yang dihasilkan.\nPada seaborn, kita dapat menggunakan heatmap dengan sns.heatmap() seperti pada kode dibawah. Parameter annot berfungsi untuk menampilkan nilai data (jika True) atau tidak (jika False).\nBar sebelah kanan heatmap menunjukkan bahwa, semakin lama keterlambatan pesawat, maka warna yang dihasilkan semakin terang. Sebaliknya, semakin gelap warna yang dihasilkan berarti semakin cepat pesawat datang tersebut.\n\n\"\"\"\nMembuat heatmap menggunakan Seaborn\n\"\"\"\nplt.figure(figsize=(14,10))\n\nsns.heatmap(data=flight_df, annot=True)\nplt.title(\"Average Arrival Delay for Each Airline, by Month\")\nplt.xlabel(\"Airline\")\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan heatmap di atas, kita dapat melihat dengan mudah pada bulan apa suatu maskapai sangat terlambat (contoh: maskapai NK pada bulan Juni).\nHeatmap sangat sering digunakan untuk melihat korelasi antarfitur pada dataset agar kita dapat mengerti lebih jauh tentang fitur-fitur pada data, atau juga dapat dimanfaatkan untuk melakukan feature selection sebelum membuat sebuat model Machine Learning.\nUntuk melakukan hal tersebut, kita perlu menghitung dahulu korelasi antar fitur menggunakan pandas .corr(), yaitu fungsi yang akan menghitung korelasi antar dua fitur menggunakan korelasi Pearson.\nNotes: Metode korelasi dapat diubah dengan menggunakan parameter method pada .corr(), contoh: .corr(method='spearman'). Metode lainnya dapat dilihat pada:\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\n\n# Hitung korelasi antar dua fitur pada flight_df\nflight_corr = flight_df.corr()\n\nflight_corr\n\n\n\n\n\n\n\n\n\nAA\nAS\nB6\nDL\nEV\nF9\nHA\nMQ\nNK\nOO\nUA\nUS\nVX\nWN\n\n\n\n\nAA\n1.000000\n0.334980\n0.429854\n0.805229\n0.896523\n0.903986\n0.220065\n0.842701\n0.573716\n0.620477\n0.809874\n0.823713\n0.425237\n0.615664\n\n\nAS\n0.334980\n1.000000\n0.340359\n0.394359\n0.356608\n0.336791\n0.684979\n0.283977\n0.480863\n0.350657\n0.457414\n0.489025\n0.229571\n0.519228\n\n\nB6\n0.429854\n0.340359\n1.000000\n0.643313\n0.342627\n0.510718\n0.467905\n0.529724\n0.032038\n0.591115\n0.233021\n0.788345\n0.579750\n0.151750\n\n\nDL\n0.805229\n0.394359\n0.643313\n1.000000\n0.796951\n0.783265\n0.262251\n0.598765\n0.625277\n0.569073\n0.797339\n0.821757\n0.700605\n0.691805\n\n\nEV\n0.896523\n0.356608\n0.342627\n0.796951\n1.000000\n0.828515\n0.099369\n0.721468\n0.784026\n0.692697\n0.911499\n0.669736\n0.462638\n0.730115\n\n\nF9\n0.903986\n0.336791\n0.510718\n0.783265\n0.828515\n1.000000\n0.273878\n0.912984\n0.414064\n0.582509\n0.671986\n0.878874\n0.308397\n0.465765\n\n\nHA\n0.220065\n0.684979\n0.467905\n0.262251\n0.099369\n0.273878\n1.000000\n0.436015\n0.176485\n0.056941\n0.066821\n0.586160\n-0.008439\n-0.007296\n\n\nMQ\n0.842701\n0.283977\n0.529724\n0.598765\n0.721468\n0.912984\n0.436015\n1.000000\n0.281890\n0.586963\n0.503575\n0.660181\n0.150111\n0.239744\n\n\nNK\n0.573716\n0.480863\n0.032038\n0.625277\n0.784026\n0.414064\n0.176485\n0.281890\n1.000000\n0.365273\n0.827455\n0.293515\n0.395419\n0.742869\n\n\nOO\n0.620477\n0.350657\n0.591115\n0.569073\n0.692697\n0.582509\n0.056941\n0.586963\n0.365273\n1.000000\n0.626051\n0.590313\n0.561515\n0.548304\n\n\nUA\n0.809874\n0.457414\n0.233021\n0.797339\n0.911499\n0.671986\n0.066821\n0.503575\n0.827455\n0.626051\n1.000000\n0.477816\n0.536968\n0.926800\n\n\nUS\n0.823713\n0.489025\n0.788345\n0.821757\n0.669736\n0.878874\n0.586160\n0.660181\n0.293515\n0.590313\n0.477816\n1.000000\n0.333396\n0.242344\n\n\nVX\n0.425237\n0.229571\n0.579750\n0.700605\n0.462638\n0.308397\n-0.008439\n0.150111\n0.395419\n0.561515\n0.536968\n0.333396\n1.000000\n0.630278\n\n\nWN\n0.615664\n0.519228\n0.151750\n0.691805\n0.730115\n0.465765\n-0.007296\n0.239744\n0.742869\n0.548304\n0.926800\n0.242344\n0.630278\n1.000000\n\n\n\n\n\n\n\n\nPandas .corr() menghasilkan dataframe dengan nama baris dan kolom yang sama, serta berisi nilai korelasi antara baris dan kolom yang ditinjau (contoh: korelasi antara maskapai AA dan AS adalah 0,334980). Serta, dataframe yang dihasilkan adalah sebuat matriks simetris.\nTentu dengan hanya melihat dataframe di atas, tidak terlihat begitu jelas mana fitur yang memiliki korelasi tinggi dan mana yang yang memiliki korelasi rendah. Oleh karena itu, kita dapat memanfaatkan heatmap.\nPada code di bawah, untuk mempermudah pembacaan heatmap, kita menggunakan parameter vmin, vmax, dan center pada sns.heatmap(). vmin berfungsi untuk mengatur nilai terendah, vmax berfungsi untuk mengatur nilai tertinggi, dan center berfungsi untuk mengatur nilai tengah pada heatmap. Korelasi Pearson menghasilkan nilai antara -1 hingga 1, sehingga kita dapat set ketiga parameter tersebut seperti pada code di bawah.\n\nplt.figure(figsize=(14,10))\n\nsns.heatmap(data=flight_corr, vmin=-1, vmax=1, center=0, annot=True)\nplt.title(\"Pearson Correlation of Each Airline Flight Delays\")\nplt.xlabel(\"Airline\")\nplt.show()\n\n\n\n\n\n\n\n\nDengan menggunakan heatmap, sekarang terlihat bahwa mana maskapai yang keterlambatannya berkorelasi tinggi dan mana yang rendah. Misal, AA dan EV menghasilkan korelasi yang cukup tinggi positif, yaitu 0.9, yang artinya jika keterlambatan maskapai AA tinggi, begitu juga maskapai EV, dan sebaliknya jika keterlambatan maskapai AA rendah, begitu juga maskapai EV.\nUntuk meyakinkan kita dengan hal tersebut, kita dapat lihat pada materi selanjutnya, yaitu Scatter Plot.\n\n\nScatter Plot\nScatter plot biasa digunakan untuk melihat korelasi antara dua fitur bertipe numerik.\nUntuk menggunakan scatter plot pada seaborn, kita dapat menggunakan sns.scatterplot(), dengan parameter yang sama seperti kita membuat bar plot.\n\n\"\"\"\nMembuat scatter plot untuk melihat \nketerkaitan pada keterlambatan pesawat\nmaskapai EV dan AA\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='EV', y='AA')\nplt.show()\n\n\n\n\n\n\n\n\nMelalui scatter plot di atas, kita dapat semakin yakin bahwa kesimpulan yang kita ambil dengan melihat heatmap sebelumnya benar.\n\n\"\"\"\nTambahan scatter plot pada maskapai lain yang\nmemiliki korelasi tinggi\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='EV', y='UA')\nplt.show()\n\n\n\n\n\n\n\n\n\n\"\"\"\nScatter plot pada maskapai yang memiliki\nkorelasi rendah (mendekati 0)\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='UA', y='HA')\nplt.show()\n\n\n\n\n\n\n\n\nPada heatmap, terlihat bahwa maskapai UA dan HA memiliki korelasi yang rendah, yaitu 0.067. Sehingga, jika kita buat scatter plotnya, menghasilkan plot seperti di atas.\nSekarang kita akan menggunakan dataset lainnya, yaitu insurance.csv yang merupakan data berisi biaya asuransi (charges) beberapa orang.\n\ninsurance_df.head()\n\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n\n\n\n\n\n\n\n\nMisal, kita ingin melihat keterkaitan indeks massa tubuh (bmi) seseorang dengan biaya asuransi (charges) orang tersebut. Sama seperti sebelumnya, kita dapat melakukannya seperti pada code di bawah.\n\n# Mengubah palette menjadi default\nsns.set_palette('tab10')\n# Membuat scatter plot antara fitur bmi dan charges\nsns.scatterplot(data=insurance_df, x='bmi', y='charges')\n\nplt.show()\n\n\n\n\n\n\n\n\nScatter plot di atas menunjukkan bahwa korelasi antara bmi dan charges adalah cenderung positif, tetapi tidak terlalu tinggi. Yang artinya, orang dengan BMI tinggi, cenderung akan membayar biaya asuransi lebih tinggi.\nAgar kita semakin yakin dengan kesimpulan tersebut, kita dapat menambahakn garis regresi pada scatter plot tersebut dengan menggunakan sns.regplot().\n\nsns.regplot(data=insurance_df, x='bmi', y='charges')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan scatter plot dan garis regresi dihasilkan, terlihat bahwa kesimpulan yang kita ambil benar. Agar semakin yakin lagi, kita juga dapat menghitung langsung korelasi Pearsonnya menggunakan cara sebelumnya, yaitu pandas .corr().\n\ninsurance_df[['bmi', 'charges']].corr()\n\n\n\n\n\n\n\n\n\nbmi\ncharges\n\n\n\n\nbmi\n1.000000\n0.198341\n\n\ncharges\n0.198341\n1.000000\n\n\n\n\n\n\n\n\nDengan menggunakan seaborn, kita juga dapat memvisualisasikan scatter plot berdasarkan dengan pewarnaan yang berbeda berdasarkan fitur lainnya yang bertipe kategorik.\nMisal, kita ingin membuat scatter plot antara fitur bmi dan charges dengan pewarnaannya berdasarkan nilai dari fitur smoker, yaitu yes atau no. Kita dapat set parameter hue='smoker' pada sns.scatterplot() seperti pada code di bawah.\n\nsns.scatterplot(data=insurance_df, x='bmi', y='charges', hue='smoker')\nplt.show()\n\n\n\n\n\n\n\n\nSehingga dihasilkan pewarnaan yang berbeda untuk seseorang yang merupakan perokok (biru) dan yang tidak (orange). Berdasarkan scatter plot di atas, terlihat bahwa korelasi antara bmi dan charges untuk perokok cendering tinggi positif (semakin besar bmi, semakin besar juga charges). Sedangkan, untuk bukan perokok, korelasinya cenderung rendah (semakin besar bmi, tidak terlalu berpengaruh terhadap charges).\nSeperti cara sebelumnya, kita dapat menambahkan garis regresi. Namun, karena kita disini menggunakan hue, terdapat dua cara untuk menambahkan garis regresi, yaitu yang pertama adalah menggunakan sns.regplot() seperti di bawah ini.\n\nsns.regplot(data=insurance_df.query('smoker == \"yes\"'), x='bmi', y='charges') # axes 1\nsns.regplot(data=insurance_df.query('smoker == \"no\"'), x='bmi', y='charges') # axes 2\nplt.show()\n\n\n\n\n\n\n\n\nPerhatikan bahwa sns.regplot() dipanggil dua kali karena fungsi tersebut tidak memiliki parameter hue.\nUntuk mempermudah, kita dapat menggunakan cara kedua, yaitu menggunakan sns.lmplot(). Cara kerja sns.lmplot() yaitu menggabungkan dua (atau lebih) sns.regplot() dalam satu figur.\n\nsns.lmplot(data=insurance_df, x='bmi', y='charges', hue='smoker')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBox Plot dan Swarm Plot\nBox plot dan swarm plot biasa digunakan untuk melihat keterkaitan antara data kategorik dan data numerik. Swarm plot biasa disebut sebagai “categorical scatter plot”, karena plot yang dihasilkan mirip seperti scatter plot, tetapi untuk data kategorik.\nUntuk menggunakan box plot pada seaborn kita dapat menggunakan sns.boxplot().\nUntuk menggunakan swarm plot pada seaborn kita dapat menggunakan sns.swarmplot().\nMisal, kita ingin melihat keterkaitan antara fitur smoker dan charges menggunakan swarm plot. Maka, kita dapat menggunakan code seperti di bawah ini.\n\nplt.subplots(figsize=(10,6))\n\nsns.swarmplot(data=insurance_df, x='smoker', y='charges', size=3)\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan swarm plot di atas, terlihat bahwa perokok cenderung memiliki biaya asuransi yang lebih tinggi dibandingkan yang bukan perokok. Selain itu, semakin lebar “swarm” pada suatu kategori berarti semakin banyak seseorang dengan nilai charges tersebut.\nApabila kita ingin menggunakan box plot, maka dapat digunakan code seperti di bawah ini.\n\nsns.boxplot(data=insurance_df, x='smoker', y='charges')\nplt.show()\n\n\n\n\n\n\n\n\nPada box plot, terdapat dua istilah yang umum digunakan, yaitu “box” dan “whiskers”. Pada box plot di atas, “box” merupakan persegi panjang berwarna biru dan orange. Garis di tengah box merupakan nilai mediannya, serta garis bawah dan garis atas box merupakan kuartil bawah (Q1) dan kuartil atas (Q3) secara berurutan. “Whiskers” adalah garis yang merupakan perpanjangan dari box. Ujung dari whiskers atas adalah Q3 + (1.5 x IQR) data, sedangkan ujung whiskers bawah adalah Q1 - (1.5 x IQR) data.\nTitik di luar box dan whiskers tersebut adalah titik yang biasa dijadikan sebagai outlier (penentuan outlier diserahkan ke diri masing-masing, apakah hanya dengan melihat box plot atau dengan menggunakan metode lain, tetapi untuk mempermudah dapat menggunakan box plot).\n\n\nHistogram dan Density Plot\nSelain box plot dan swarm plot, kita juga dapat melihat persebaran data menggunakan histogram dan density plot. Histogram biasa digunakan untuk melihat persebaran data secara diskrit, sedangkan density plot untuk melihat persebaran data secara kontinu.\nUntuk membuat histogram pada seaborn, kita dapat menggunakan sns.histplot().\nUntuk membuat density plot pada seaborn, kita dapat menggunakan sns.kdeplot().\nMisal, kita ingin melihat persebaran dari fitur charges pada insurance_df. Maka dapat digunakan code seperti di bawah.\n\nplt.subplots(figsize=(12,6))\n\nsns.histplot(data=insurance_df, x='charges')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan histogram di atas, terlihat bahwa distribusi charges cenderung “skew” atau miring ke kanan. “Skewness” atau tingkat kecondongan merupakan aspek yang penting untuk diperhatikan ketika kita ingin membuat model Machine Learning.\nSeperti scatter plot, kita juga dapat menentukan pewarnaan histogram berdasarkan fitur lainnya dengan menggunakan parameter hue seperti di bawah ini/\n\nplt.subplots(figsize=(12,6))\nsns.histplot(data=insurance_df, x='charges', hue='smoker')\nplt.show()\n\n\n\n\n\n\n\n\nJika ingin membuat density plot dari fitur charges, kita dapat menggunakan kode seperti di bawah ini. Parameter shade berfungsi untuk memberikan warna di bawah kurva.\n\nplt.subplots(figsize=(12,6))\nsns.kdeplot(data=insurance_df, x='charges', shade=True)\nplt.show()\n\n\n\n\n\n\n\n\nsns.kdeplot() juga dapat menggunakan parameter hue.\n\nplt.subplots(figsize=(12,6))\nsns.kdeplot(data=insurance_df, x='charges',\n            hue='smoker', shade=True)\nplt.show()\n\n\n\n\n\n\n\n\nApabila kita ingin menggabungkan histogram dan density plot dalam satu figur, kita dapat menggunakan sns.histplot() dengan parameter kde=True.\n\nplt.subplots(figsize=(12,6))\nsns.histplot(data=insurance_df, x='charges', hue='smoker', kde=True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nJoint Plot\nPada seaborn, kita juga dapat membuat dua plot yang berbeda dari dua fitur dalam satu figur yang sama menggunakan sns.jointplot().\nJenis plot yang dihasilkan dapat diatur pada parameter kind. Pilihan jenis kind yang disediakan dapat dilihat pada:\nhttps://seaborn.pydata.org/generated/seaborn.jointplot.html\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"scatter\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"hist\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"kde\")\n\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#supplementary-panduan-pemilihan-plot",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#supplementary-panduan-pemilihan-plot",
    "title": "Modul 2 Sains Data: Visualisasi Data",
    "section": "Supplementary: Panduan Pemilihan Plot",
    "text": "Supplementary: Panduan Pemilihan Plot\n\n\n\nimage.png\n\n\nsource: https://www.kaggle.com/code/alexisbcook/choosing-plot-types-and-custom-styles"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/pdnum2024genap.html",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/pdnum2024genap.html",
    "title": "Praktikum PDNum (Persamaan Diferensial Numerik) 2024 Genap (Kurikulum 2020)",
    "section": "",
    "text": "Kembali ke Praktikum\n\nTimeline\n\nModul 1: Pengenalan GNU Octave, 21-22 Februari 2024 (offline di Lab Komputer D.311 untuk sesi 1 dan sesi 2, dan di Lab Statistika D.406 untuk sesi 3)\nModul 2: Plotting Fungsi, Metode Euler, Metode Taylor, 28-29 Februari 2024 (offline di Lab Komputer D.311 untuk sesi 1 dan sesi 2, dan di Lab Statistika D.406 untuk sesi 3)\nModul 3: Metode Runge-Kutta dan variasinya, 6-7 Maret 2024 (offline di Lab Komputer D.311 untuk sesi 1 dan sesi 2)\nModul 4: Metode Multistep, 13-14 Maret 2024\nModul 5: Sistem PDB orde 1 dan PDB orde tinggi, 17-18 April 2024 (Sesi 1 online, Sesi 2 offline)\nModul 6: Metode Shooting dan Linear Finite Difference untuk Masalah Nilai Batas PDB, 24-25 April 2024\nModul 7: Nonlinear Finite Difference, PDP Eliptik & Hiperbolik, Kamis, 2 Mei 2024, online melalui Zoom\nModul 8: PDP Parabolik, Rabu, 8 Mei 2024, hybrid: offline di D.311 dan online melalui Zoom\nModul 9: PDP orde 1, persamaan transport/adveksi, 15-16 Mei 2024, offline di D.311\n\nTugas Akhir\n\nTugas 1: Masalah Nilai Awal PDB Numerik\nDiberikan: Senin, 10 Juni 2024\nDeadline: Jumat, 14 Juni 2024, 23.59 WIB\nTugas 2: Masalah Nilai Batas PDB Numerik\nDiberikan: Senin, 10 Juni 2024\nDeadline: Jumat, 14 Juni 2024, 23.59 WIB\nTugas 3: PDP Numerik\nDiberikan: Senin, 10 Juni 2024\nDeadline: Jumat, 14 Juni 2024, 23.59 WIB\n\n\n\nRekaman praktikum\nUntuk pertemuan-pertemuan praktikum PDNum (Persamaan Diferensial Numerik) yang dilaksanakan secara online melalui Zoom, semua rekaman disimpan di link berikut.\nhttps://bit.ly/RekamanPrakPDNum2024Genap"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul6.html",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul6.html",
    "title": "Modul 6 Persamaan Diferensial Numerik: Metode Shooting dan Linear Finite Difference untuk Masalah Nilai Batas PDB",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\nDi modul ini, kita akan membahas beberapa metode untuk masalah nilai batas untuk PDB, yaitu:"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul6.html#review-runge-kutta-orde-4-untuk-sistem",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul6.html#review-runge-kutta-orde-4-untuk-sistem",
    "title": "Modul 6 Persamaan Diferensial Numerik: Metode Shooting dan Linear Finite Difference untuk Masalah Nilai Batas PDB",
    "section": "Review: Runge-Kutta orde 4 untuk sistem",
    "text": "Review: Runge-Kutta orde 4 untuk sistem\nShooting method untuk masalah nilai batas melibatkan sistem persamaan diferensial. Kita akan menggunakan kode metode Runge-Kutta orde 4 untuk sistem dari modul sebelumnya:\n\nFunction file rko4_sysm.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = rko4_sysm(cell_f, a, b, N, alphas)\n  m = length(cell_f);\n\n  h = (b - a) / N;\n  t = zeros(N + 1, 1);\n  w = zeros(m, N + 1);\n  t(1) = a;\n  w(:, 1) = alphas;\n\n  k1 = zeros(m, 1);\n  k2 = zeros(m, 1);\n  k3 = zeros(m, 1);\n  k4 = zeros(m, 1);\n  for i = 1 : N\n    t(i + 1) = t(i) + h;\n\n    for j = 1 : m\n      k1(j) = h * cell_f{j}(t(i), w(:, i));\n    endfor\n\n    for j = 1 : m\n      k2(j) = h * cell_f{j}(t(i) + (h / 2), w(:, i) + (k1 / 2));\n    endfor\n\n    for j = 1 : m\n      k3(j) = h * cell_f{j}(t(i) + (h / 2), w(:, i) + (k2 / 2));\n    endfor\n\n    for j = 1 : m\n      k4(j) = h * cell_f{j}(t(i + 1), w(:, i) + k3);\n    endfor\n\n    for j = 1 : m\n      w(j, i + 1) = w(j, i) + (k1(j) + 2 * k2(j) + 2 * k3(j) + k4(j)) / 6;\n    endfor\n  endfor\nendfunction\n\n\n\n\nSebenarnya tidak harus metode Runge-Kutta orde 4 untuk sistem. Boleh ditukar dengan metode lainnya untuk sistem, misalnya metode Adams predictor-corrector orde 4 untuk sistem."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul6.html#linear-shooting",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul6.html#linear-shooting",
    "title": "Modul 6 Persamaan Diferensial Numerik: Metode Shooting dan Linear Finite Difference untuk Masalah Nilai Batas PDB",
    "section": "Linear Shooting",
    "text": "Linear Shooting\n\nBentuk umum, ide utama, penyederhanaan\nLinear Shooting merupakan metode untuk menyelesaikan sejenis masalah nilai batas untuk PDB, yaitu yang berbentuk:\n\\(y'' = f\\left(x,y,y'\\right) = p(x)y' + q(x)y + r(x), \\;a\\leq x\\leq b\\)\n\\(y(a)=\\alpha, \\;y(b)=\\beta\\)\ndengan\n\n\\(p(x), q(x), r(x)\\) adalah fungsi kontinu dalam \\(x\\)\n\\(q(x) &gt; 0\\) pada \\([a,b]\\) agar dijamin ada solusi unik\n\nCara penyelesaiannya:\n\nSelesaikan MNA PDB orde 2 berikut, solusinya disebut \\(y_1 \\left(x\\right)\\):\n\n\\[y'' = p(x)y' + q(x)y + r(x), \\quad a \\le x \\le b, \\quad y\\left(a\\right) = \\alpha, \\quad y'\\left(a\\right) = 0\\]\n\nSelesaikan MNA PDB orde 2 berikut, solusinya disebut \\(y_2 \\left(x\\right)\\)\n\n\\[y'' = p(x)y' + q(x)y, \\quad a \\le x \\le b, \\quad y\\left(a\\right) = 0, \\quad y'\\left(a\\right) = 1\\]\n\nSolusi akhirnya adalah\n\n\\[y\\left(x\\right) = y_1 \\left(x\\right) + \\frac{\\beta - y_1 \\left(b\\right)}{y_2 \\left(b\\right)} y_2 \\left(x\\right)\\]\nKita bisa menuliskan kedua MNA PDB orde 2 tersebut masing-masing sebagai sistem PDB orde 1, seperti biasa dengan permisalan \\(u_1(x) = y(x)\\) dan \\(u_2(x) = y'(x)\\).\nSehingga, langkahnya menjadi:\n\nSelesaikan sistem PDB orde 1 berikut. Kemudian solusi \\(u_1(x)\\) disebut \\(y_1(x)\\) dan solusi \\(u_2(x)\\) disebut \\(y_1'(x)\\).\n\n\\[\\begin{aligned}\nu_1'(x) &= u_2(x) \\\\\nu_2'(x) &= p(x) u_2(x) + q(x) u_1(x) + r(x) \\\\\nu_1 (a) &= \\alpha, \\quad u_2 (a) = 0\n\\end{aligned}\\]\n\nSelesaikan sistem PDB orde 1 berikut. Kemudian solusi \\(u_1(x)\\) disebut \\(y_2(x)\\) dan solusi \\(u_2(x)\\) disebut \\(y_2'(x)\\).\n\n\\[\\begin{aligned}\nu_1'(x) &= u_2(x) \\\\\nu_2'(x) &= p(x)u_2(x) + q(x)u_1(x) \\\\\nu_1 (a) &= 0, \\quad u_2(a) = 1\n\\end{aligned}\\]\n\nSolusi akhirnya adalah\n\n\\[y(x) = y_1(x) + \\frac{\\beta - y_1(b)}{y_2(b)} y_2(x)\\]\nKalau perlu,\n\\[y'(x) = y_1'(x) + \\frac{\\beta - y_1(b)}{y_2(b)} y_2'(x)\\]\n\n\nFunction file (dari pseudocode di buku)\n\nFunction file linshoot_pseudocode.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x_i, w_1i, w_2i] = linshoot_pseudocode(p, q, r, a, b, n, alpha, beta)\n  h = (b - a)/n;\n  u = [alpha ; 0];\n  v = [0 ; 1];\n  x_i = w_1i = w_2i = [];\n  for i = 1:n\n    x = a + (i-1)*h;\n\n    k_11 = h * u(2,i);\n    k_12 = h * (p(x)*u(2,i) + q(x)*u(1,i) + r(x));\n\n    k_21 = h * (u(2,i)+(k_12/2));\n    k_22 = h * (p(x+(h/2))*(u(2,i)+(k_12/2)) + q(x+(h/2))*(u(1,i)+(k_11/2)) + r(x+(h/2)));\n\n    k_31 = h * (u(2,i)+(k_22/2));\n    k_32 = h * (p(x+(h/2))*(u(2,i)+(k_22/2)) + q(x+(h/2))*(u(1,i)+(k_21/2)) + r(x+(h/2)));\n\n    k_41 = h * (u(2,i)+k_32);\n    k_42 = h * (p(x+h)*(u(2,i)+k_32) + q(x+h)*(u(1,i)+k_31) + r(x+h));\n\n    u(1,i+1) = u(1,i) + ((k_11 + 2*k_21 + 2*k_31 + k_41)/6);\n    u(2,i+1) = u(2,i) + ((k_12 + 2*k_22 + 2*k_32 + k_42)/6);\n\n    kp_11 = h * v(2,i);\n    kp_12 = h * (p(x)*v(2,i) + q(x)*v(1,i));\n\n    kp_21 = h * (v(2,i) + (kp_12/2));\n    kp_22 = h * (p(x+(h/2))*(v(2,i)+(kp_12/2)) + q(x+(h/2))*(v(1,i)+(kp_11/2)));\n\n    kp_31 = h * (v(2,i)+(kp_22/2));\n    kp_32 = h * (p(x+(h/2))*(v(2,i)+(kp_22/2)) + q(x+(h/2))*(v(1,i)+(kp_21/2)));\n\n    kp_41 = h * (v(2,i)+kp_32);\n    kp_42 = h * (p(x+h)*(v(2,i)+kp_32) + q(x+h)*(v(1,i)+kp_31));\n\n    v(1,i+1) = v(1,i) + (kp_11 + 2*kp_21 + 2*kp_31 + kp_41)/6;\n    v(2,i+1) = v(2,i) + (kp_12 + 2*kp_22 + 2*kp_32 + kp_42)/6;\n  endfor\n\n  w = [alpha ; ((beta - u(1,(n+1))) / v(1,(n+1)))];\n  x_i(1) = a;\n  w_1i(1) = w(1,1);\n  w_2i(1) = w(2,1);\n\n  for i = 2:(n+1)\n    W1 = u(1,i) + w(2,1)*v(1,i);\n    W2 = u(2,i) + w(2,1)*v(2,i);\n    x = a + (i-1)*h;\n    x_i(i) = x;\n    w_1i(i) = W1;\n    w_2i(i) = W2;\n  endfor\nendfunction\n\n\n\n\n\n\nFunction file (lebih sederhana)\n\nFunction file linear_shooting.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x, w1, w2] = linear_shooting(p, q, r, a, b, N, alph, bet)\n  % sistem PDB yang pertama\n  u1_aksen = @(x, u) u(2);\n  u2_aksen = @(x, u) p(x)*u(2) + q(x)*u(1) + r(x);\n  [x, w_pers1] = rko4_sysm({u1_aksen, u2_aksen}, a, b, N, [alph, 0]);\n  y1_b = w_pers1(1, N+1);\n  \n  % sistem PDB yang kedua\n  u1_aksen = @(x, u) u(2);\n  u2_aksen = @(x, u) p(x)*u(2) + q(x)*u(1);\n  [x, w_pers2] = rko4_sysm({u1_aksen, u2_aksen}, a, b, N, [0, 1]);\n  y2_b = w_pers2(1, N+1);\n  \n  % solusi akhir (superposisi)\n  w_akhir = w_pers1 + (bet - y1_b)/(y2_b) * w_pers2;\n  % dipisah jadi w1,i (aproksimasi y(x)) dan w2,i (aproksimasi y'(x))\n  w1 = w_akhir(1, :)'; % ditranspos agar menjadi vektor kolom\n  w2 = w_akhir(2, :)';\nendfunction\n\n\n\n\n\n\nContoh Linear Shooting\n\\(y'' = -\\frac{2}{x}y' + \\frac{2}{x^2}y + \\frac{\\sin(\\ln(x))}{x^2}, \\; 1\\leq x\\leq 2\\)\n\\(y(1)=1,\\; y(2)=2\\)\ndengan \\(N=10\\)\ndan solusi eksak:\n\\(y(x)=c_1x+\\frac{c_2}{x^2} - \\frac{3}{10}\\sin(\\ln(x))-\\frac{1}{10}\\cos(\\ln(x))\\)\n\\(y'(x)=c_1 - \\frac{2c_2}{x^3} - \\frac{3\\cos(\\ln(x))}{10x} + \\frac{\\sin(\\ln(x))}{10x}\\)\n\\(c_2 = \\frac{1}{70}(8-12\\sin(\\ln(2)) - 4\\cos(\\ln(2)))\\)\n\\(c_1 = \\frac{11}{10}-c_2\\)\nBerikut code script file untuk permasalahan di atas menggunakan metode linear shooting:\n\nScript file coba_linear_shooting.m - nama file bebas\n\n\n\np = @(x) (-2 ./ x);\nq = @(x) (2 ./ (x .^ 2));\nr = @(x) (sin(log(x)) ./ (x .^ 2));\na = 1;\nb = 2;\nN = 10;\nalph = 1;\nbet = 2;\n\n[xi, w1i, w2i] = linear_shooting(p, q, r, a, b, N, alph, bet);\n\n% solusi eksak y(x)\nc2 = (8-12*sin(log(2)) - 4*cos(log(2)))/70;\nc1 = (11/10) - c2;\nsln = @(x) (c1*x + (c2 ./ x.^2) - (3/10)*sin(log(x)) - (1/10)*cos(log(x)));\ny_eksak = sln(xi);\n\n% menghitung error\nerr_w1i = abs(w1i - y_eksak);\nerr1_total = sum(err_w1i);\n\n% tampilkan\nformat long;\ndisp(\"Tabel aproksimasi w1,i, solusi eksak y(x), dan error:\");\n[xi, w1i, y_eksak, err_w1i]\ndisp(\"Error total (norm L1):\");\ndisp(err1_total);\nformat;\n\n% plot untuk y(x)\nfigure;\nhold on;\nfplot(sln, [a,b], 'k');\nscatter(xi, w1i, 'r');\ntitle(\"Aproksimasi y(x)\");\nlegend(\"Eksak\", \"Aproksimasi (w1,i)\");\nlegend('location', 'northwest');\n\nTabel aproksimasi w1,i, solusi eksak y(x), dan error:\nans =\n\n   1.000000000000000   1.000000000000000   1.000000000000000                   0\n   1.100000000000000   1.092629164133552   1.092629298481288   0.000000134347735\n   1.200000000000000   1.187084706810955   1.187084840483685   0.000000133672730\n   1.300000000000000   1.283382266283346   1.283382364079130   0.000000097795784\n   1.400000000000000   1.381445891533503   1.381445951696987   0.000000060163484\n   1.500000000000000   1.481159386366171   1.481159416999814   0.000000030633643\n   1.600000000000001   1.582392449986370   1.582392460756381   0.000000010770011\n   1.700000000000001   1.685013962277612   1.685013961734097   0.000000000543514\n   1.800000000000001   1.788898539692082   1.788898534641947   0.000000005050134\n   1.900000000000001   1.893929513621671   1.893929509211183   0.000000004410488\n   2.000000000000001   2.000000000000000   2.000000000000000   0.000000000000000\n\nError total (norm L1):\n4.773875239560965e-07\n\n\n\n\n\n\n\n\n\n\n\n\nJika kita run script file tersebut, maka program akan mengeluarkan dua macam output, yaitu tabel serta plot perbandingan solusi eksak dan aproksimasi dengan errornya.\nApabila diperlukan bukan hanya \\(y(x)\\) (yaitu \\(w_{1,i}\\)) tetapi juga \\(y'(x)\\) (yaitu \\(w_{2,i}\\)), kodenya menjadi seperti berikut:\n\nScript file coba2_linear_shooting.m - nama file bebas\n\n\n\np = @(x) (-2 ./ x);\nq = @(x) (2 ./ (x .^ 2));\nr = @(x) (sin(log(x)) ./ (x .^ 2));\na = 1;\nb = 2;\nN = 10;\nalph = 1;\nbet = 2;\n\n[xi, w1i, w2i] = linear_shooting(p, q, r, a, b, N, alph, bet);\n\n% solusi eksak y(x) dan y'(x)\nc2 = (8-12*sin(log(2)) - 4*cos(log(2)))/70;\nc1 = (11/10) - c2;\nsln = @(x) (c1*x + (c2 ./ x.^2) - (3/10)*sin(log(x)) - (1/10)*cos(log(x)));\nsln_p = @(x) (c1 - (2*c2 ./ x.^3) - 3*cos(log(x))./(10*x) + sin(log(x))./(10*x));\ny_eksak = sln(xi);\nyp_eksak = sln_p(xi);\n\n% menghitung error\nerr_w1i = abs(w1i - y_eksak);\nerr_w2i = abs(w2i - yp_eksak);\nerr1_total = sum(err_w1i);\nerr2_total = sum(err_w2i);\n\n% tampilkan\nformat long;\ndisp(\"Tabel aproksimasi w1,i, solusi eksak y(x), dan error:\");\n[xi, w1i, y_eksak, err_w1i]\ndisp(\"Tabel aproksimasi w2,i, solusi eksak y'(x), dan error:\");\n[xi, w2i, yp_eksak, err_w2i]\ndisp(\"Error total (norm L1) untuk w1,i:\");\ndisp(err1_total);\ndisp(\"Error total (norm L1) untuk w2,i:\");\ndisp(err2_total);\nformat;\n\n% plot untuk y(x)\nfigure;\nhold on;\nfplot(sln, [a,b], 'k');\nscatter(xi, w1i, 'r');\ntitle(\"Aproksimasi y(x)\");\nlegend(\"Eksak\", \"Aproksimasi (w1,i)\");\nlegend('location', 'northwest');\n\n% plot untuk y'(x)\nfigure;\nhold on;\nfplot(sln_p, [a,b], 'k');\nscatter(xi, w2i, 'b');\ntitle(\"Aproksimasi y'(x)\");\nlegend(\"Eksak\", \"Aproksimasi (w2,i)\");\nlegend('location', 'northwest');\n\nTabel aproksimasi w1,i, solusi eksak y(x), dan error:\nans =\n\n   1.000000000000000   1.000000000000000   1.000000000000000                   0\n   1.100000000000000   1.092629164133552   1.092629298481288   0.000000134347735\n   1.200000000000000   1.187084706810955   1.187084840483685   0.000000133672730\n   1.300000000000000   1.283382266283346   1.283382364079130   0.000000097795784\n   1.400000000000000   1.381445891533503   1.381445951696987   0.000000060163484\n   1.500000000000000   1.481159386366171   1.481159416999814   0.000000030633643\n   1.600000000000001   1.582392449986370   1.582392460756381   0.000000010770011\n   1.700000000000001   1.685013962277612   1.685013961734097   0.000000000543514\n   1.800000000000001   1.788898539692082   1.788898534641947   0.000000005050134\n   1.900000000000001   1.893929513621671   1.893929509211183   0.000000004410488\n   2.000000000000001   2.000000000000000   2.000000000000000   0.000000000000000\n\nTabel aproksimasi w2,i, solusi eksak y'(x), dan error:\nans =\n\n Columns 1 through 3:\n\n   1.000000000000000e+00   9.176213963846825e-01   9.176210394808360e-01\n   1.100000000000000e+00   9.352828620960821e-01   9.352826025486669e-01\n   1.200000000000000e+00   9.538386694942848e-01   9.538385751339796e-01\n   1.300000000000000e+00   9.719773228811912e-01   9.719773623999391e-01\n   1.400000000000000e+00   9.890965253486431e-01   9.890966553369642e-01\n   1.500000000000000e+00   1.004953219518007e+00   1.004953404763131e+00\n   1.600000000000001e+00   1.019487696052374e+00   1.019487911769632e+00\n   1.700000000000001e+00   1.032732443129011e+00   1.032732672951544e+00\n   1.800000000000001e+00   1.044763943100940e+00   1.044764176648869e+00\n   1.900000000000001e+00   1.055676941937622e+00   1.055677172867598e+00\n   2.000000000000001e+00   1.065570770445955e+00   1.065570995061434e+00\n\n Column 4:\n\n   3.569038465878194e-07\n   2.595474152267130e-07\n   9.436030512510740e-08\n   3.951874794072552e-08\n   1.299883211069996e-07\n   1.852451241290964e-07\n   2.157172589445366e-07\n   2.298225325603198e-07\n   2.335479285520137e-07\n   2.309299755864913e-07\n   2.246154791052390e-07\n\nError total (norm L1) untuk w1,i:\n4.773875239560965e-07\nError total (norm L1) untuk w2,i:\n2.200196934865062e-06"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul6.html#nonlinear-shooting",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul6.html#nonlinear-shooting",
    "title": "Modul 6 Persamaan Diferensial Numerik: Metode Shooting dan Linear Finite Difference untuk Masalah Nilai Batas PDB",
    "section": "Nonlinear Shooting",
    "text": "Nonlinear Shooting\n\nBentuk umum, ide utama\nNonlinear Shooting digunakan untuk menyelesaikan masalah nilai batas berbentuk:\n\\(y'' = f(x, y, y'), \\; a\\leq x \\leq b\\)\n\\(y(a)=\\alpha, \\; y(b)=\\beta\\)\ndengan \\(f\\) boleh berupa fungsi linier maupun nonlinier\nCara penyelesaiannya:\n\nTentukan toleransi \\(\\varepsilon\\), dan pilih tebakan awal \\(t_0\\) (yaitu \\(t_k\\) sebelum iterasi pertama, yaitu dengan \\(k=0\\)). Kalau bingung, disarankan\n\n\\[t_0 = \\frac{\\beta - \\alpha}{b-a}\\]\n\nSelesaikan MNA PDB orde 2 berikut, misalkan solusinya disebut \\(w(x,t_k)\\):\n\n\\[y'' = f(x,y,y'), \\quad a \\le x \\le b, \\quad y(a) = \\alpha, \\quad y'(a) = t_k\\]\n\nPeriksa apakah \\(\\left|w(b,t_k) - \\beta\\right| \\le \\varepsilon\\).\n\nKalau iya, selesai; solusi akhirnya adalah \\(y(x) = w(x,t_k)\\).\nKalau tidak, peroleh tebakan baru untuk \\(t_i\\) (misalnya dengan metode secant atau metode Newton), lalu kembali ke langkah 2.\n\n\nSeperti biasa, kita bisa misalkan \\(u_1(x) = y(x)\\) dan \\(u_2(x) = y'(x)\\) agar MNA PDB orde 2 menjadi sistem PDB orde 1.\nCara penyelesaiannya menjadi:\n\nTentukan toleransi \\(\\varepsilon\\), dan pilih tebakan awal \\(t_0\\) (yaitu \\(t_k\\) sebelum iterasi pertama, yaitu dengan \\(k=0\\)). Kalau bingung, disarankan\n\n\\[t_0 = \\frac{\\beta - \\alpha}{b-a}\\]\n\nSelesaikan sistem PDB orde 1 berikut. Kemudian \\(u_1(x)\\) disebut \\(w(x,t_k)\\) dan \\(u_2(x)\\) disebut \\(w'(x,t_k)\\).\n\n\\[\\begin{aligned}\nu_1'(x) &= u_2(x) \\\\\nu_2'(x) &= f(x,u_1,u_2) \\\\\ny(a) &= \\alpha, \\quad y'(a) = t_k\n\\end{aligned}\\]\n\nPeriksa apakah \\(\\left|w(b,t_k) - \\beta\\right| \\le \\varepsilon\\).\n\nKalau iya, selesai; solusi akhirnya adalah \\(y(x) = w(x,t_k)\\).\nKalau tidak, peroleh tebakan baru untuk \\(t_k\\) (misalnya dengan metode secant atau metode Newton), lalu kembali ke langkah 2.\n\n\n\n\nFunction file (metode secant)\n\nFunction file nonlinear_shooting_secant.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x, w1, w2] = nonlinear_shooting_secant(f, a, b, N, alph, bet, tol, t0, t1)\n  u1_aksen = @(x, u) u(2);\n  u2_aksen = @(x, u) f(x, u(1), u(2));\n  \n  t_k_min_2 = t0;\n  t_k_min_1 = t1;\n  [x, w_k_min_2] = rko4_sysm({u1_aksen, u2_aksen}, a, b, N, [alph, t_k_min_2]);\n  [x, w_k_min_1] = rko4_sysm({u1_aksen, u2_aksen}, a, b, N, [alph, t_k_min_1]);\n  w_k = w_k_min_1;\n  err = abs(w_k(1, N+1) - bet);\n  while !(err &lt;= tol)\n    pembilang = (w_k_min_1(1,N+1) - bet) * (t_k_min_1 - t_k_min_2);\n    penyebut = w_k_min_1(1,N+1) - w_k_min_2(1,N+1);\n    t_k = t_k_min_1 - pembilang/penyebut;\n\n    t_k_min_2 = t_k_min_1\n    t_k_min_1 = t_k\n\n    [x, w_k] = rko4_sysm({u1_aksen, u2_aksen}, a, b, N, [alph, t_k]);\n    err = abs(w_k(1, N+1) - bet);\n  endwhile\n  % keluar loop artinya toleransi sudah terpenuhi\n  \n  % memisahkan w_k menjadi w1i dan w2i\n  w1 = w_k(1, :)'; % transpos juga agar menjadi vektor kolom\n  w2 = w_k(2, :)';\nendfunction\n\n\n\n\n\n\nModifikasi untuk metode Newton\nUntuk menggunakan metode Newton, diperlukan tidak hanya \\(y(b,t)\\) tetapi juga turunannya \\(\\frac{\\partial y(b,t)}{\\partial t}\\) yang sayangnya tidak dimiliki.\nSetelah penjabaran yang panjang di buku, ternyata bisa dimisalkan\n\\[z(x,t) = \\frac{\\partial y(x,t)}{\\partial t}\\]\ndan nilai fungsi \\(z\\) ini ternyata bisa diperoleh dengan menyelesaikan suatu MNA PDB orde 2 (lagi). Sehingga, di tiap iterasi, ada dua MNA PDB orde 2 yang harus diselesaikan.\nLangkah nonlinear shooting dengan metode Newton bisa ditulis:\n\nHitung rumus \\(\\frac{\\partial f}{\\partial y}(x,y,y')\\) dan rumus \\(\\frac{\\partial f}{\\partial y'}(x,y,y')\\) secara analitik.\nTentukan toleransi \\(\\varepsilon\\), dan pilih tebakan awal \\(t_0\\) (yaitu \\(t_k\\) sebelum iterasi pertama, yaitu dengan \\(k=0\\)). Kalau bingung, disarankan\n\n\\[t_0 = \\frac{\\beta - \\alpha}{b-a}\\]\n\nSelesaikan MNA PDB orde 2 berikut, misalkan solusinya disebut \\(w(x,t_k)\\):\n\n\\[y'' = f(x,y,y'), \\quad a \\le x \\le b, \\quad y(a) = \\alpha, \\quad y'(a) = t_k\\]\n\nSelesaikan MNA PDB orde 2 berikut:\n\n\\[z'' = \\frac{\\partial f}{\\partial y}(x,y,y')z(x) + \\frac{\\partial f}{\\partial y'}(x,y,y')z'(x), \\quad z(a) = 0, \\quad z'(a) = 1\\]\n\nPeriksa apakah \\(\\left|w(b,t_k) - \\beta\\right| \\le \\varepsilon\\).\n\nKalau iya, selesai; solusi akhirnya adalah \\(y(x) = w(x,t_k)\\).\nKalau tidak, kembali ke langkah 3 setelah memperoleh tebakan baru untuk \\(t_k\\): \\[t_k = t_{k-1} - \\frac{w(b, t_{k-1}) - \\beta}{z(b, t_{k-1})}\\]\n\n\nDengan permisalan \\(u_1\\) dan \\(u_2\\) agar PDB orde 2 menjadi sistem PDB orde 1, langkah-langkahnya menjadi:\n\nHitung rumus \\(\\frac{\\partial f}{\\partial y}(x,y,y')\\) dan rumus \\(\\frac{\\partial f}{\\partial y'}(x,y,y')\\) secara analitik.\nTentukan toleransi \\(\\varepsilon\\), dan pilih tebakan awal \\(t_0\\) (yaitu \\(t_k\\) sebelum iterasi pertama, yaitu dengan \\(k=0\\)). Kalau bingung, disarankan\n\n\\[t_0 = \\frac{\\beta - \\alpha}{b-a}\\]\n\nSelesaikan sistem PDB orde 1 berikut. Kemudian \\(u_1(x)\\) disebut \\(w(x,t_k)\\) dan \\(u_2(x)\\) disebut \\(w'(x,t_k)\\).\n\n\\[\\begin{aligned}\nu_1'(x) &= u_2(x) \\\\\nu_2'(x) &= f(x,u_1,u_2) \\\\\ny(a) &= \\alpha, \\quad y'(a) = t_k\n\\end{aligned}\\]\n\nSelesaikan sistem PDB orde 1 berikut. Kemudian \\(u_1(x)\\) disebut \\(z(x,t_k)\\) dan \\(u_2(x)\\) disebut \\(z'(x,t_k)\\).\n\\[\\begin{aligned}\nu_1'(x) &= u_2(x) \\\\\nu_2'(x) &= \\frac{\\partial f}{\\partial y}(x,y,y')u_1(x) + \\frac{\\partial f}{\\partial y'}(x,y,y')u_2(x) \\\\\nu_1(a) &= 0, \\quad u_2(a) = 1\n\\end{aligned}\\]\nNote: nilai \\(y\\) dan \\(y'\\) sebenarnya tergantung \\(x\\), sehingga sebaiknya ditulis \\(y(x)\\) dan \\(y'(x)\\):\n\\[\\begin{aligned}\nu_1'(x) &= u_2(x) \\\\\nu_2'(x) &= \\frac{\\partial f}{\\partial y}(x,y(x),y'(x))u_1(x) + \\frac{\\partial f}{\\partial y'}(x,y(x),y'(x))u_2(x) \\\\\nu_1(a) &= 0, \\quad u_2(a) = 1\n\\end{aligned}\\]\nDalam perhitungan, nilai \\(y(x)\\) dan \\(y'(x)\\) bisa kita peroleh dari \\(w(x,t_k)\\) dan \\(w'(x,t_k)\\), yaitu nilai \\(w_{1,i}\\) dan \\(w_{2,i}\\) dari sistem yang sebelumnya.\nPeriksa apakah \\(\\left|w(b,t_k) - \\beta\\right| \\le \\varepsilon\\).\n\nKalau iya, selesai; solusi akhirnya adalah \\(y(x) = w(x,t_k)\\).\nKalau tidak, kembali ke langkah 3 setelah memperoleh tebakan baru untuk \\(t_k\\): \\[t_k = t_{k-1} - \\frac{w(b, t_{k-1}) - \\beta}{z(b, t_{k-1})}\\]\n\n\n\n\nFunction file (dari pseudocode)\n\nFunction file nonlinshoot_pseudocode.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x_i, w_1i, w_2i] = nonlinshoot_pseudocode(f, fy, fyp, a, b, n, alpha, beta, m, tol)\n  % m adalah maksimum iterasi\n\n  h = (b - a)/n;\n  k = 1;\n  tk = (beta - alpha)/(b - a);\n  x_i = w_1i = w_2i = [];\n  while k &lt;= m\n    w = [alpha;tk];\n    u = [0,1];\n    for i = 1:n\n      x = a + (i-1)*h;\n\n      k_11 = h*w(2,i);\n      k_12 = h*f(x, w(1,i), w(2,i));\n\n      k_21 = h*(w(2,i)+(k_12/2));\n      k_22 = h*f((x+(h/2)), (w(1,i)+(k_11/2)), (w(2,i)+(k_12/2)));\n\n      k_31 = h*(w(2,i)+(k_22/2));\n      k_32 = h*f((x+(h/2)), (w(1,i)+(k_21/2)), (w(2,i)+(k_22/2)));\n\n      k_41 = h*(w(2,i)+k_32);\n      k_42 = h*f((x+h), (w(1,i)+k_31), (w(2,i)+k_32));\n\n      w(1,i+1) = w(1,i) + ((k_11 + 2*k_21 + 2*k_31 + k_41)/6);\n      w(2,i+1) = w(2,i) + ((k_12 + 2*k_22 + 2*k_32 + k_42)/6);\n\n      kp_11 = h*u(2);\n      kp_12 = h*(fy(x, w(1,i), w(2,i))*u(1) + fyp(x, w(1,i), w(2,i))*u(2));\n\n      kp_21 = h*(u(2) + (kp_12/2));\n      kp_22 = h*(fy((x+(h/2)), w(1,i), w(2,i))*u(1) + fyp((x+(h/2)), w(1,i), w(2,i))*(u(2) + (kp_12/2)));\n\n      kp_31 = h*(u(2)+(kp_22/2));\n      kp_32 = h*(fy((x+(h/2)), w(1,i), w(2,i))*(u(1) + (kp_21/2)) + fyp((x+(h/2)), w(1,i), w(2,i))*(u(2) + (kp_22/2)));\n\n      kp_41 = h*(u(2)+kp_32);\n      kp_42 = h*(fy((x+h), w(1,i), w(2,i))*(u(1)+kp_31) + fyp((x+h), w(1,i), w(2,i))*(u(2) + kp_32));\n\n      u(1) = u(1) + (kp_11 + 2*kp_21 + 2*kp_31 + kp_41)/6;\n      u(2) = u(2) + (kp_12 + 2*kp_22 + 2*kp_32 + kp_42)/6;\n    endfor\n\n  if abs(w(1,n+1) - beta) &lt;= tol       % jika sudah mencapai batas toleransi maka program berhenti\n    for i = 1:(n+1)\n      x = a+(i-1)*h;\n      x_i(i) = x;\n      w_1i(i) = w(1,i);\n      w_2i(i) = w(2,i);\n    endfor\n    return\n  endif\n  tk = tk-((w(1,n+1) - beta)/u(1));\n  k = k + 1;\n  endwhile\n  disp('max iteration')\nendfunction\n\n\n\n\n\n\nFunction file (metode Newton)\n\nFunction file nonlinear_shooting_newton.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x_arr, w1i, w2i] = nonlinear_shooting_newton(f, fy, fyp, a, b, N, alph, bet, tol, M, t0)\n  % kalau input t0 bukan angka, dianggap tidak memilih tebakan awal\n  if isnumeric(t0)\n    t_k = t0;\n  else\n    t_k = (bet-alph)/(b-a);\n  endif\n\n  % banyaknya iterasi\n  k = 1;\n\n  err = tol + 1;\n  % selama belum memenuhi toleransi ataupun mencapai batas iterasi\n  while (!(err &lt;= tol) && k != M+1)\n    % selesaikan sistem pertama\n    u1_aksen = @(x, u) u(2);\n    u2_aksen = @(x, u) f(x, u(1), u(2));\n    [x_arr, w_sys] = rko4_sysm({u1_aksen, u2_aksen}, a, b, N, [alph, t_k]);\n\n    % y(x) adalah w1,i dengan i adalah indeks dari x (perlu dicari)\n    % carinya bisa dengan memilih nilai terakhir (indeks end) di x_arr yang &lt;= x\n    % (seandainya ada misalnya t_i + h/2, nilai w yang digunakan tetap di t_i)\n    y = @(x) w_sys(1, find(x_arr &lt;= x)(end));\n\n    % y'(x) adalah w2,i dengan i adalah indeks dari x (perlu dicari)\n    yp = @(x) w_sys(2, find(x_arr &lt;= x)(end));\n\n    % selesaikan sistem kedua\n    u1_aksen = @(x, u) u(2);\n    u2_aksen = @(x, u) fy(x, y(x), yp(x))*u(1) + fyp(x, y(x), yp(x))*u(2);\n    [x_arr, z_sys] = rko4_sysm({u1_aksen, u2_aksen}, a, b, N, [0, 1]);\n\n    % periksa toleransi, update t_k\n    err = abs(w_sys(1, N+1) - bet);\n    if !(err &lt;= tol)\n      t_k = t_k - (w_sys(1, N+1) - bet)/(z_sys(1, N+1));\n    endif\n\n    % lanjut iterasi selanjutnya\n    k += 1;\n  endwhile\n  % keluar loop artinya toleransi sudah terpenuhi atau maks iterasi tercapai\n  if (k == M)\n    printf(\"Maks iterasi (%d) tercapai\\n\", M);\n  endif\n\n  % pisahkan w_sys menjadi w1i dan w2i\n  w1i = w_sys(1, :)'; % transpos juga agar menjadi vektor kolom\n  w2i = w_sys(2, :)';\nendfunction\n\n\n\n\n\n\nContoh Nonlinear Shooting\n\\(y'' = \\frac{1}{8}(32+2x^3-yy'), \\; 1\\leq x \\leq 3\\)\n\\(y(1) = 17, \\; y(3)=43/3\\)\ndengan \\(N=20\\) dan toleransi \\(=10^{-5}\\)\ndan solusi eksak:\n\\(y(x)=x^2 + \\frac{16}{x}\\)\n\\(y'(x)=2x - \\frac{16}{x^2}\\)\nHint:\n\\[\\begin{aligned}\nf(x,y,y') &= \\frac{1}{8}(32+2x^3-yy') \\\\\n\\frac{\\partial f}{\\partial y}(x,y,y') &= -\\frac{1}{8}y' \\\\\n\\frac{\\partial f}{\\partial y'}(x,y,y') &= -\\frac{1}{8}y\n\\end{aligned}\\]\nBerikut code script file untuk permasalahan di atas menggunakan metode nonlinear shooting (dengan metode Newton):\n::: {.panel-tabset}\n\n\nScript file coba_nonlinear_shooting_newton.m - nama file bebas\n\nf = @(x, y, yp) ((1/8)*(32 + 2 * x.^3 - y .* yp));\nfy = @(x, y, yp) (-yp/8);\nfyp = @(x, y, yp) (-y/8);\na = 1;\nb = 3;\nN = 20;\nalph = 17;\nbet = 43/3;\ntol = 10^(-5);\nM = -1; % maks iterasi. Nilai negatif artinya tidak ada maks\n\n[xi, w1i, w2i] = nonlinear_shooting_newton(f, fy, fyp, a, b, N, alph, bet, tol, M, \"\");\n\n% solusi eksak y(x)\nsln = @(x) ((x .^ 2) + (16 ./ x));\ny_eksak = sln(xi);\n\n% menghitung error\nerr_w1i = abs(w1i - y_eksak);\nerr1_total = sum(err_w1i);\n\n% tampilkan\nformat long;\ndisp(\"Tabel aproksimasi w1,i, solusi eksak y(x), dan error:\");\n[xi, w1i, y_eksak, err_w1i]\ndisp(\"Error total (norm L1):\");\ndisp(err1_total);\nformat;\n\nfigure;\nhold on;\nfplot(sln, [a,b], 'k');\nscatter(xi, w1i, 'r');\ntitle(\"Aproksimasi y(x)\");\nlegend(\"Eksak\", \"Aproksimasi (w1,i)\");\nlegend('location', 'northeast');\n\nTabel aproksimasi w1,i, solusi eksak y(x), dan error:\nans =\n\n Columns 1 through 3:\n\n   1.000000000000000e+00   1.700000000000000e+01   1.700000000000000e+01\n   1.100000000000000e+00   1.575549578599484e+01   1.575545454545455e+01\n   1.200000000000000e+00   1.477339050038047e+01   1.477333333333333e+01\n   1.300000000000000e+00   1.399775337003275e+01   1.399769230769231e+01\n   1.400000000000000e+00   1.338863063808904e+01   1.338857142857143e+01\n   1.500000000000000e+00   1.291672136654978e+01   1.291666666666667e+01\n   1.600000000000001e+00   1.256004909500447e+01   1.256000000000000e+01\n   1.700000000000001e+00   1.230180789967695e+01   1.230176470588235e+01\n   1.800000000000001e+00   1.212892629211319e+01   1.212888888888889e+01\n   1.900000000000001e+00   1.203108455596395e+01   1.203105263157895e+01\n   2.000000000000001e+00   1.200002684877419e+01   1.200000000000000e+01\n   2.100000000000001e+00   1.202906982837228e+01   1.202904761904762e+01\n   2.200000000000001e+00   1.211274528064585e+01   1.211272727272727e+01\n   2.300000000000001e+00   1.224653596950516e+01   1.224652173913044e+01\n   2.400000000000001e+00   1.242667752129748e+01   1.242666666666667e+01\n   2.500000000000001e+00   1.265000785517754e+01   1.265000000000000e+01\n   2.600000000000001e+00   1.291385135925930e+01   1.291384615384616e+01\n   2.700000000000002e+00   1.321592880477185e+01   1.321592592592593e+01\n   2.800000000000002e+00   1.355428656395277e+01   1.355428571428572e+01\n   2.900000000000002e+00   1.392724047230069e+01   1.392724137931035e+01\n   3.000000000000002e+00   1.433333091826060e+01   1.433333333333334e+01\n\n Column 4:\n\n                       0\n   4.124054029475133e-05\n   5.716704713520926e-05\n   6.106234043912195e-05\n   5.920951761773097e-05\n   5.469988311368468e-05\n   4.909500447425330e-05\n   4.319379459793993e-05\n   3.740322430267895e-05\n   3.192438500754236e-05\n   2.684877418701603e-05\n   2.220932465668568e-05\n   1.800791857675677e-05\n   1.423037472392252e-05\n   1.085463081196281e-05\n   7.855177535986968e-06\n   5.205413140529913e-06\n   2.878845918985462e-06\n   8.496670478308488e-07\n   9.070096620433787e-07\n   2.415072742678603e-06\n\nError total (norm L1):\n5.472579459873117e-04\n\n\n\n\n\n\n\n\n\nJika kita run script file tersebut, maka program akan mengeluarkan dua macam output, yaitu tabel serta plot perbandingan solusi eksak dan aproksimasi dengan errornya.\nApabila diperlukan bukan hanya \\(y(x)\\) (yaitu \\(w_{1,i}\\)) tetapi juga \\(y'(x)\\) (yaitu \\(w_{2,i}\\)), kodenya menjadi seperti berikut:\n\nf = @(x, y, yp) ((1/8)*(32 + 2 * x.^3 - y .* yp));\nfy = @(x, y, yp) (-yp/8);\nfyp = @(x, y, yp) (-y/8);\na = 1;\nb = 3;\nN = 20;\nalph = 17;\nbet = 43/3;\ntol = 10^(-5);\nM = -1; % maks iterasi. Nilai negatif artinya tidak ada maks\n\n[xi, w1i, w2i] = nonlinear_shooting_newton(f, fy, fyp, a, b, N, alph, bet, tol, M, \"\");\n\n% solusi eksak y(x) dan y'(x)\nsln = @(x) ((x .^ 2) + (16 ./ x));\nsln_p = @(x) (2*x - 16 ./ (x.^2));\ny_eksak = sln(xi);\nyp_eksak = sln_p(xi);\n\n% menghitung error\nerr_w1i = abs(w1i - y_eksak);\nerr_w2i = abs(w2i - yp_eksak);\nerr1_total = sum(err_w1i);\nerr2_total = sum(err_w2i);\n\n% tampilkan\nformat long;\ndisp(\"Tabel aproksimasi w1,i, solusi eksak y(x), dan error:\");\n[xi, w1i, y_eksak, err_w1i]\ndisp(\"Tabel aproksimasi w2,i, solusi eksak y'(x), dan error:\");\n[xi, w2i, yp_eksak, err_w2i]\ndisp(\"Error total (norm L1) untuk w1,i:\");\ndisp(err1_total);\ndisp(\"Error total (norm L1) untuk w2,i:\");\ndisp(err2_total);\nformat;\n\nfigure;\nhold on;\nfplot(sln, [a,b], 'k');\nscatter(xi, w1i, 'r');\ntitle(\"Aproksimasi y(x)\");\nlegend(\"Eksak\", \"Aproksimasi (w1,i)\");\nlegend('location', 'northeast');\n\nfigure;\nhold on;\nfplot(sln_p, [a,b], 'k');\nscatter(xi, w2i, 'b');\ntitle(\"Aproksimasi y'(x)\");\nlegend(\"Eksak\", \"Aproksimasi (w2,i)\");\nlegend('location', 'northwest');\n\nTabel aproksimasi w1,i, solusi eksak y(x), dan error:\nans =\n\n Columns 1 through 3:\n\n   1.000000000000000e+00   1.700000000000000e+01   1.700000000000000e+01\n   1.100000000000000e+00   1.575549578599484e+01   1.575545454545455e+01\n   1.200000000000000e+00   1.477339050038047e+01   1.477333333333333e+01\n   1.300000000000000e+00   1.399775337003275e+01   1.399769230769231e+01\n   1.400000000000000e+00   1.338863063808904e+01   1.338857142857143e+01\n   1.500000000000000e+00   1.291672136654978e+01   1.291666666666667e+01\n   1.600000000000001e+00   1.256004909500447e+01   1.256000000000000e+01\n   1.700000000000001e+00   1.230180789967695e+01   1.230176470588235e+01\n   1.800000000000001e+00   1.212892629211319e+01   1.212888888888889e+01\n   1.900000000000001e+00   1.203108455596395e+01   1.203105263157895e+01\n   2.000000000000001e+00   1.200002684877419e+01   1.200000000000000e+01\n   2.100000000000001e+00   1.202906982837228e+01   1.202904761904762e+01\n   2.200000000000001e+00   1.211274528064585e+01   1.211272727272727e+01\n   2.300000000000001e+00   1.224653596950516e+01   1.224652173913044e+01\n   2.400000000000001e+00   1.242667752129748e+01   1.242666666666667e+01\n   2.500000000000001e+00   1.265000785517754e+01   1.265000000000000e+01\n   2.600000000000001e+00   1.291385135925930e+01   1.291384615384616e+01\n   2.700000000000002e+00   1.321592880477185e+01   1.321592592592593e+01\n   2.800000000000002e+00   1.355428656395277e+01   1.355428571428572e+01\n   2.900000000000002e+00   1.392724047230069e+01   1.392724137931035e+01\n   3.000000000000002e+00   1.433333091826060e+01   1.433333333333334e+01\n\n Column 4:\n\n                       0\n   4.124054029475133e-05\n   5.716704713520926e-05\n   6.106234043912195e-05\n   5.920951761773097e-05\n   5.469988311368468e-05\n   4.909500447425330e-05\n   4.319379459793993e-05\n   3.740322430267895e-05\n   3.192438500754236e-05\n   2.684877418701603e-05\n   2.220932465668568e-05\n   1.800791857675677e-05\n   1.423037472392252e-05\n   1.085463081196281e-05\n   7.855177535986968e-06\n   5.205413140529913e-06\n   2.878845918985462e-06\n   8.496670478308488e-07\n   9.070096620433787e-07\n   2.415072742678603e-06\n\nTabel aproksimasi w2,i, solusi eksak y'(x), dan error:\nans =\n\n Columns 1 through 3:\n\n   1.000000000000000e+00  -1.400019602422796e+01  -1.400000000000000e+01\n   1.100000000000000e+00  -1.102334186854095e+01  -1.102314049586777e+01\n   1.200000000000000e+00  -8.711296684185600e+00  -8.711111111111109e+00\n   1.300000000000000e+00  -6.867619909427612e+00  -6.867455621301771e+00\n   1.400000000000000e+00  -5.363408505219970e+00  -5.363265306122443e+00\n   1.500000000000000e+00  -4.111235293408942e+00  -4.111111111111106e+00\n   1.600000000000001e+00  -3.050107650303584e+00  -3.049999999999994e+00\n   1.700000000000001e+00  -2.136425654341337e+00  -2.136332179930791e+00\n   1.800000000000001e+00  -1.338352959256321e+00  -1.338271604938266e+00\n   1.900000000000001e+00  -6.322039283580119e-01  -6.321329639889148e-01\n   2.000000000000001e+00  -6.200755926466517e-05   5.329070518200751e-15\n   2.100000000000001e+00   5.718278547215568e-01   5.718820861678053e-01\n   2.200000000000001e+00   1.094167447234676e+00   1.094214876033063e+00\n   2.300000000000001e+00   1.575383898119827e+00   1.575425330812860e+00\n   2.400000000000001e+00   2.022186112082093e+00   2.022222222222227e+00\n   2.500000000000001e+00   2.439968644139854e+00   2.440000000000006e+00\n   2.600000000000001e+00   2.833109007887408e+00   2.833136094674562e+00\n   2.700000000000002e+00   3.205189382604409e+00   3.205212620027440e+00\n   2.800000000000002e+00   3.559163917474358e+00   3.559183673469393e+00\n   2.900000000000002e+00   3.897486371338108e+00   3.897502972651611e+00\n   3.000000000000002e+00   4.222208482001776e+00   4.222222222222228e+00\n\n Column 4:\n\n   1.960242279608337e-04\n   2.013726731835419e-04\n   1.855730744910744e-04\n   1.642881258403506e-04\n   1.431990975273578e-04\n   1.241822978359508e-04\n   1.076503035899457e-04\n   9.347441054607941e-05\n   8.135431805422755e-05\n   7.096436909703741e-05\n   6.200755926999424e-05\n   5.423144624849829e-05\n   4.742879838692815e-05\n   4.143269303269470e-05\n   3.611014013493730e-05\n   3.135586015190484e-05\n   2.708678715324098e-05\n   2.323742303111942e-05\n   1.975599503500902e-05\n   1.660131350300631e-05\n   1.374022045119716e-05\n\nError total (norm L1) untuk w1,i:\n5.472579459873117e-04\nError total (norm L1) untuk w2,i:\n1.741071134524930e-03"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul6.html#linear-finite-difference",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul6.html#linear-finite-difference",
    "title": "Modul 6 Persamaan Diferensial Numerik: Metode Shooting dan Linear Finite Difference untuk Masalah Nilai Batas PDB",
    "section": "Linear Finite Difference",
    "text": "Linear Finite Difference\nMetode ini digunakan untuk mengaproksimasi masalah linear dalam bentuk:\n\\[\\begin{gathered}\ny^{\\prime \\prime}=p(x) y^{\\prime}+q(x) y+r(x), \\quad a \\leq x \\leq b \\\\\ny(a)=\\alpha, y(b)=\\beta\n\\end{gathered}\\]\nPenyelesaiannya adalah dengan persamaan-persamaan berikut:\n\\[\\begin{gathered}\nw_{0}=\\alpha, \\quad w_{N+1}=\\beta \\\\\n-\\left(1+\\frac{h}{2} p\\left(x_{i}\\right)\\right) w_{i-1}+\\left(2+h^{2} q\\left(x_{i}\\right)\\right) w_{i}-\\left(1-\\frac{h}{2} p\\left(x_{i}\\right)\\right) w_{i+1}=-h^{2} r\\left(x_{i}\\right)\n\\end{gathered}\\]\nBentuk tersebut dapat disusun menjadi suatu SPL:\n\\[\nA \\mathbf{w}=\\mathbf{b}\n\\]\n\n\\(\\mathbf{w}=\\left[\\begin{array}{c}w_{1} \\\\ w_{2} \\\\ \\vdots \\\\ w_{N-1} \\\\ w_{N}\\end{array}\\right], \\quad\\) and \\(\\quad \\mathbf{b}=\\left[\\begin{array}{c}-h^{2} r\\left(x_{1}\\right)+\\left(1+\\frac{h}{2} p\\left(x_{1}\\right)\\right) w_{0} \\\\ -h^{2} r\\left(x_{2}\\right) \\\\ \\vdots \\\\ -h^{2} r\\left(x_{N-1}\\right) \\\\ -h^{2} r\\left(x_{N}\\right)+\\left(1-\\frac{h}{2} p\\left(x_{N}\\right)\\right) w_{N+1}\\end{array}\\right]\\).\nMenurut buku, SPL tersebut sebaiknya diselesaikan dengan metode faktorisasi Crout (algoritma 6.7). (Intinya, mumpung A adalah matriks tridiagonal, algoritma ini nyari inverse A secara linier, makanya runtime dari algortima ini adalah \\(O(n)\\))\nNamun, tentunya kita bebas menyelesaikan SPLnya dengan cara apapun, misalnya dengan invers, OBE, atau bahkan dengan cara iteratif seperti Gauss-Seidel\n\nFunction file (dari pseudocode)\n\nFunction file linfdm_pseudocode.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [xt,w]=linfdm_pseudocode(p,q,r,a_boundary,b_boundary,alpha,beta,n)\n  h=(b_boundary-a_boundary)/(n+1); %stepsize\n  a=zeros(n,1); %diagonal sistem persamaannya\n  b=zeros(n,1); % right diagonal sistem persamaannya\n  c=zeros(n,1); %left diagonal sistem persamaannya\n  d=zeros(n,1); %vektor b (Ay=b) pada sistem persamaannya\n  l=zeros(n,1); % main diagonal of lower triangle matrix\n  u=zeros(n,1); %right diagonal of upper triangle matrix\n  z= zeros(n,1); %solution of Lz=b\n  w=zeros(n+1,1); %solusi aproksimasi dengan linear fdm\n  xt=[a_boundary:h:b_boundary]; %mesh_point\n  x=a_boundary+h;\n\n  %konstruksi matrix tridiagonalnya\n  a(1)=2+(h^2)*q(x);\n  b(1)= -1+(h/2)*p(x);\n  d(1)=-h^2*r(x) +(1+(h/2)*p(x))*alpha;\n\n  for i = 2:n-1\n    x= a_boundary+i*h;\n    a(i)=2+h^2*q(x); %diagonal\n    b(i)=-1+(h/2)*p(x);\n    c(i)=-1-(h/2)*p(x);\n    d(i)=-h^2*r(x);\n  endfor\n\n  x=b_boundary-h;\n  a(n)=2+h^2*q(x);\n  c(n)=-1-(h/2)*p(x);\n  d(n)=-h^2*r(x)+(1-(h/2)*p(x))*beta;\n\n  %matriks tridiagonalnya sudah didapatkan,\n  %akan diselesaikan dengan LU Decomposition (crout factorization)\n\n  l(1)= a(1);\n  u(1)=b(1)/a(1);\n  z(1)=d(1)/l(1);\n\n  for i= 2:n-1\n    l(i)=a(i)-c(i)*u(i-1);\n    u(i)=b(i)/l(i);\n    z(i)=(d(i)-c(i)*z(i-1))/l(i);\n\n  endfor\n\n  l(n)=a(n)-c(n)*u(n-1);\n  z(n)=(d(n)-c(n)*z(n-1))/l(n);\n\n  %konstruksi akhir w-nya\n  w(n+1)=beta;\n  w(n)=z(n);\n  for i = n-1:-1:1\n    w(i)=z(i)-u(i)*w(i+1);\n  endfor\n\n  w=[alpha;w];\n  xt=transpose(xt);\n\nendfunction\n\n\n\n\n\n\nFunction file (dengan solusi SPL secara langsung/invers)\n\nFunction file linear_fd_langsung.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x, w_grid] = linear_fd_langsung(p, q, r, a, b, N, alph, bet)\n  % bikin array x\n  h = (b - a) / (N+1);\n  x = (a : h : b)'; % transpos juga agar menjadi vektor kolom\n\n  % susun matriks A dan vektor b\n  A = zeros(N, N);\n  b = -h^2 * r(x(2:N+1));\n  % kasus khusus untuk baris pertama\n  b(1) += (1 + h/2 * p(x(2))) * alph;\n  A(1, 1) += 2 + h^2 * q(x(2));\n  A(1, 2) += -1 + h/2 * p(x(2));\n  % kasus khusus untuk baris terakhir\n  A(N, N-1) += -1 - h/2 * p(x(N+1));\n  A(N, N) += 2 + h^2 * q(x(N+1));\n  b(N) += (1 - h/2 * p(x(N+1))) * bet;\n  % untuk baris kedua hingga kedua-terakhir\n  for i = 2 : (N-1)\n    A(i, i-1) += -1 - h/2 * p(x(i+1));\n    A(i, i) += 2 + h^2 * q(x(i+1));\n    A(i, i+1) += -1 + h/2 * p(x(i+1));\n  endfor\n\n  % selesaikan SPL\n  w = A \\ b;\n  % w baru mengandung w1, ..., w_N\n\n  % gabungkan dengan w0 (alpha) dan w_{N+1} (beta)\n  w_grid = [alph w' bet]'; % transpos juga agar menjadi vektor kolom\nendfunction\n\n\n\n\n\n\nContoh Linear Finite Difference\nAkan kita uji dengan masalah nilai batas:\n\\[\n\\begin{aligned}\ny^{\\prime \\prime} & =-\\frac{4}{x} y^{\\prime}-\\frac{2}{x^2} y+\\frac{2 \\ln x}{x^2}, \\quad 1 \\leq x \\leq 2 \\\\\ny(1) & =\\frac{1}{2}, \\quad y(2)=\\ln 2\n\\end{aligned}\n\\] Solusi eksak: \\[\ny(x)=\\frac{4}{x}-\\frac{2}{x^2}+\\ln x-\\frac{3}{2}\n\\]\n\nScript file coba_linear_fd_langsung.m - nama file bebas\n\n\n\np= @(x) (-4./x); %fungsi p(x)\nq= @(x) (-2./x.^2); %fungsi q(x)\nr=@(x) 2*log(x)./(x.^2); %fungsi r(x)\na=1; %batas kiri interval\nb=2; %batas kanan interval\nN=20; %banyaknya partisi\nalph=0.5; %y(a)=alpha\nbet=log(2); %y(b)=beta\n[x_grid, w_grid] = linear_fd_langsung(p,q,r,a,b,N,alph,bet); %memangil fungsinya\n\n% solusi eksak y(x) dan error\nsln = @(x) 4./x - 2./(x.^2) + log(x) - 1.5;\ny_eksak = sln(x_grid);\nerr = abs(y_eksak - w_grid);\nerr_total = sum(err); % norm L1 (taxicab/Manhattan)\n\n% bikin tabel dan grafiknya :D\n\nformat long;\ndisp(\"Tabel aproksimasi, solusi eksak y(x), dan error:\");\n[x_grid, w_grid, y_eksak, err]\ndisp(\"Error total (norm L1):\");\ndisp(err_total);\nformat;\n\nhold on;\nfplot(sln, [a,b], 'b');\nscatter(x_grid, w_grid, 'r');\ntitle(\"Aproksimasi y(x)\");\nlegend(\"Eksak\", \"Aproksimasi\");\nlegend('location', 'northwest');\n\nTabel aproksimasi, solusi eksak y(x), dan error:\nans =\n\n   1.000000000000000   0.500000000000000   0.500000000000000                   0\n   1.047619047619048   0.542451840408551   0.542387784229934   0.000064056178617\n   1.095238095238095   0.575949844443050   0.575848904859791   0.000100939583258\n   1.142857142857143   0.602401287601637   0.602281392624522   0.000119894977115\n   1.190476190476190   0.623280489841670   0.623153387144777   0.000127102696893\n   1.238095238095238   0.639736322556670   0.639609603256639   0.000126719300031\n   1.285714285714286   0.652670546690794   0.652548996182141   0.000121550508653\n   1.333333333333333   0.662795564639343   0.662682072451781   0.000113492187563\n   1.380952380952381   0.670677452832402   0.670573630075180   0.000103822757222\n   1.428571428571429   0.676768343081596   0.676674943938732   0.000093399142864\n   1.476190476190476   0.681431010801427   0.681348221496374   0.000082789305052\n   1.523809523809524   0.684957702680262   0.684885340076304   0.000072362603959\n   1.571428571428571   0.687584665665992   0.687522313825702   0.000062351840290\n   1.619047619047619   0.689503439735737   0.689450543640143   0.000052896095593\n   1.666666666666667   0.690869694214655   0.690825623765991   0.000044070448665\n   1.714285714285714   0.691810185166203   0.691774278510465   0.000035906655738\n   1.761904761904762   0.692428265250871   0.692399857681941   0.000028407568931\n   1.809523809523810   0.692808270884264   0.692786713692713   0.000021557191551\n   1.857142857142857   0.693019033126842   0.693003705447643   0.000015327679199\n   1.904761904761905   0.693116700585629   0.693107016390513   0.000009684195115\n   1.952380952380952   0.693147019138584   0.693142430884514   0.000004588254070\n   2.000000000000000   0.693147180559945   0.693147180559945   0.000000000000000\n\nError total (norm L1):\n1.400919170378323e-03\n\n\n\n\n\n\n\n\n\n\n\n\nSayangnya, metode finite difference untuk masalah nilai batas tidak bisa menentukan aproksimasi \\(y'(x)\\).\nPerhatikan errornya. Menurut buku Burden, untuk masalah nilai batas, metode shooting pada umumnya lebih akurat dibandingkan metode finite difference."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul4.html",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul4.html",
    "title": "Modul 4 Persamaan Diferensial Numerik: Metode Multistep",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\nMetode-metode sebelumnya, seperi metode Euler, Runge-Kutta, dan kawan-kawannya adalah metode jenis one-step, karena di tiap iterasinya kita hanya menggunakan informasi dari satu nilai \\(t_{i}\\). Berikut kita akan mulai membahas mengenai metode multistep, di mana kita menggunakan lebih dari satu nilai \\(t_{i}\\) untuk membuat aproksimasi.\nTerdapat dua jenis metode multistep, yaitu:"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul4.html#metode-multistep-eksplisit-metode-n-step-adams-bashforth",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul4.html#metode-multistep-eksplisit-metode-n-step-adams-bashforth",
    "title": "Modul 4 Persamaan Diferensial Numerik: Metode Multistep",
    "section": "Metode Multistep Eksplisit: Metode \\(n\\)-step Adams-Bashforth",
    "text": "Metode Multistep Eksplisit: Metode \\(n\\)-step Adams-Bashforth\nMetode multistep eksplisit yang akan kita bahas adalah metode \\(n\\)-step Adams-Bashforth.\nMetode \\(n\\)-step Adams-Bashforth menggunakan \\(n\\) titik sebelumnya untuk mengaproksimasi nilai. Karena metode ini adalah metode multistep, maka \\(n\\) nilai awalnya pun harus diperoleh terlebih dahulu. Misal kita ingin menggunakan metode three-step Adams-Bashforth, maka \\(w_{1}, w_{2}\\), dan \\(w_{3}\\) harus ada terlebih dahulu sebelum dilanjutkan ke metode Adams-Bashforth. Nilai-nilai awal tersebut dapat diperoleh dari metode-metode one-step sebelumnya, seperti metode Runge-Kutta (biasanya digunakan metode Runge-Kutta orde 4).\nBentuk umum rumus untuk metode \\(n\\)-step Adams-Bashforth bisa ditulis sebagai berikut.\n\\[w_{i+1} = w_i + \\frac{h}{\\text{pembagi}} \\left[ c_0 f\\left(t_i,w_i\\right) + c_{-1} f\\left(t_{i-1},w_{i-1}\\right) + \\dots + c_{-n+1} f\\left(t_{i-n+1},w_{i-n+1}\\right) \\right]\\]\n\\[\\begin{array}{cc|ccccc}\n    \\text{pembagi} & c_1 & c_0 & c_{-1} & c_{-2} & c_{-3} & c_{-4} \\\\\n    1 & \\hspace{0.5cm} & 1 &&&& \\\\\n    2 & \\hspace{0.5cm} & 3 & -1 &&& \\\\\n    12 & \\hspace{0.5cm} & 23 & -16 & 5 && \\\\\n    24 & \\hspace{0.5cm} & 55 & -59 & 37 & -9 & \\\\\n    720 & \\hspace{0.5cm} & 1901 & -2774 & 2616 & -1274 & 251\n\\end{array}\\]\n\nOrde: banyaknya koefisien taknol yang mengkali \\(f\\)\n\\(n\\)-step, \\(n\\): banyaknya koefisien taknol yang mengkali \\(f\\), kecuali koefisien yang mengkali \\(f\\left(t_{i+1},w_{i+1}\\right)\\) kalau ada\n\nUntuk metode Adams-Bashforth, tidak muncul suku \\(f\\left(t_{i+1},w_{i+1}\\right)\\), yaitu tidak ada koefisien yang mengkali \\(f\\left(t_{i+1},w_{i+1}\\right)\\) (atau bisa dibilang ada tapi nilainya nol). Sehingga, ukuran orde menjadi sama persis dengan step.\nCatatan: one-step Adams-Bashforth ialah metode Euler, sehingga tidak dibahas.\n\nTwo-step Adams-Bashforth (orde 2)\n\\[\\begin{array}{cc|ccccc}\n    \\text{pembagi} & c_1 & c_0 & c_{-1} & c_{-2} & c_{-3} & c_{-4} \\\\\n    1 & \\hspace{0.5cm} & 1 &&&& \\\\\n    \\textcolor{red}{2} & \\hspace{0.5cm} & \\textcolor{red}{3} & \\textcolor{red}{-1} &&& \\\\\n    12 & \\hspace{0.5cm} & 23 & -16 & 5 && \\\\\n    24 & \\hspace{0.5cm} & 55 & -59 & 37 & -9 & \\\\\n    720 & \\hspace{0.5cm} & 1901 & -2774 & 2616 & -1274 & 251\n\\end{array}\\]\n\\[\n\\begin{gathered}\nw_{0}=\\alpha, \\quad w_{1}=\\alpha_{1}, \\\\\nw_{i+1}=w_{i}+\\frac{h}{2}\\left[3 f\\left(t_{i}, w_{i}\\right)-f\\left(t_{i-1}, w_{i-1}\\right)\\right]\n\\end{gathered}\n\\]\nBisa ditulis:\n\\[\n\\begin{gathered}\nw_{1}=\\alpha, \\\\\nw_{2}=\\alpha_1 \\hspace{0.2cm} \\text{(hitung dengan metode Runge-Kutta orde 4)}, \\\\\nm_1 = f\\left(t_{i}, w_{i}\\right) \\\\\nm_2 = f\\left(t_{i-1}, w_{i-1}\\right) \\\\\nw_{i+1}=w_{i}+\\frac{h}{2}\\left[3 m_1-m_2\\right]\n\\end{gathered}\n\\]\n\nFunction file adams_bashforth_orde2.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = adams_bashforth_orde2(f, a, b, N, alpha)\n  % Inisiasi variabel awal\n  h = (b - a) / N;\n  t = zeros(N + 1, 1);\n  w = zeros(N + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  \n  % Hitung w(2) menggunakan metode Runge-Kutta orde 4\n  i = 1;\n  t(i + 1) = t(i) + h;\n  k1 = h * f(t(i), w(i));\n  k2 = h * f(t(i) + (h/2), w(i) + (k1/2));\n  k3 = h * f(t(i) + (h/2), w(i) + (k2/2));\n  k4 = h * f(t(i + 1), w(i) + k3);\n  w(i+1) = w(i) + (k1 + 2*k2 + 2*k3 + k4) / 6;\n  \n  % Algoritma utama Adams-Bashforth orde 2\n  for i = 2 : N\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    m2 = f(t(i-1), w(i-1));\n    w(i+1) = w(i) + (h/2) * (3*m1 - m2);\n  endfor\nendfunction\n\n\n\n\nMisalkan diberikan MNA sebagai berikut, yang ingin diselesaikan secara numerik dengan \\(N = 10\\):\n\\[y' = y - t^2 + 1\\] \\[0 \\le t \\le 2\\] \\[y(0) = 0.5\\]\nyang kebetulan memiliki solusi eksak:\n\\[y\\left(t\\right) = \\left( t + 1 \\right)^2 - 0.5 e^t\\]\nContoh penggunaan:\n::: {.panel-tabset}\n\n\nScript file coba_ab2.m - nama file bebas\n\nf = @(t, y) y - t .^ 2 + 1;\na = 0;\nb = 2;\nN = 10;\nalpha = 0.5;\n\n[t, w] = adams_bashforth_orde2(f, a, b, N, alpha);\n\nsln = @(t) (t + 1) .^ 2 - 0.5 * exp(t);\ny_eksak = sln(t);\n\nerr_ab2 = abs(y_eksak - w);\nerr_ab2_total = sum(err_ab2); % norm L1 (taxicab/Manhattan)\n\ndisp(\"Tabel aproksimasi w, solusi eksak y, dan error:\");\n[t, w, y_eksak, err_ab2]\ndisp(\"Error total (norm L1):\");\ndisp(err_ab2_total);\n\nhold on;\nfplot(sln, [a, b], 'b');\nscatter(t, w, 'r');\nlegend(\"Solusi Eksak\", \"Adams-Bashforth orde 2\")\n\nTabel aproksimasi w, solusi eksak y, dan error:\nans =\n\n        0   0.5000   0.5000        0\n   0.2000   0.8293   0.8293   0.0000\n   0.4000   1.2161   1.2141   0.0020\n   0.6000   1.6540   1.6489   0.0050\n   0.8000   2.1366   2.1272   0.0093\n   1.0000   2.6561   2.6409   0.0153\n   1.2000   3.2033   3.1799   0.0234\n   1.4000   3.7667   3.7324   0.0343\n   1.6000   4.3324   4.2835   0.0489\n   1.8000   4.8834   4.8152   0.0682\n   2.0000   5.3992   5.3055   0.0937\n\nError total (norm L1):\n0.3002\n\n\n\n\n\n\n\n\n\n\n\nThree-step Adams-Bashforth (orde 3)\n\\[\\begin{array}{cc|ccccc}\n    \\text{pembagi} & c_1 & c_0 & c_{-1} & c_{-2} & c_{-3} & c_{-4} \\\\\n    1 & \\hspace{0.5cm} & 1 &&&& \\\\\n    2 & \\hspace{0.5cm} & 3 & -1 &&& \\\\\n    \\textcolor{red}{12} & \\hspace{0.5cm} & \\textcolor{red}{23} & \\textcolor{red}{-16} & \\textcolor{red}{5} && \\\\\n    24 & \\hspace{0.5cm} & 55 & -59 & 37 & -9 & \\\\\n    720 & \\hspace{0.5cm} & 1901 & -2774 & 2616 & -1274 & 251\n\\end{array}\\]\n\\[\n\\begin{gathered}\nw_{0}=\\alpha, \\quad w_{1}=\\alpha_{1}, \\quad w_{2}=\\alpha_{2}, \\\\\nw_{i+1}=w_{i}+\\frac{h}{12}\\left[23 f\\left(t_{i}, w_{i}\\right)-16 f\\left(t_{i-1}, w_{i-1}\\right)+5 f\\left(t_{i-2}, w_{i-2}\\right)\\right]\n\\end{gathered}\n\\]\nBisa ditulis:\n\\[\n\\begin{gathered}\nw_{1}=\\alpha, \\\\\nw_{2}=\\alpha_{1}, \\quad w_{3}=\\alpha_{2}, \\\\\nm_1 = f\\left(t_{i}, w_{i}\\right) \\\\\nm_2 = f\\left(t_{i-1}, w_{i-1}\\right) \\\\\nm_3 = f\\left(t_{i-2}, w_{i-2}\\right) \\\\\nw_{i+1}=w_{i}+\\frac{h}{12}\\left[23 m_1-16 m_2+5 m_3\\right]\n\\end{gathered}\n\\]\n\nFunction file adams_bashforth_orde3.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = adams_bashforth_orde3(f, a, b, N, alpha)\n  % Inisiasi variabel awal\n  h = (b - a) / N;\n  t = zeros(N + 1, 1);\n  w = zeros(N + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  \n  % Hitung w(2), w(3) menggunakan metode Runge-Kutta orde 4\n  for i = 1 : 2\n      t(i + 1) = t(i) + h;\n      k1 = h * f(t(i), w(i));\n      k2 = h * f(t(i) + (h/2), w(i) + (k1/2));\n      k3 = h * f(t(i) + (h/2), w(i) + (k2/2));\n      k4 = h * f(t(i + 1), w(i) + k3);\n      w(i+1) = w(i) + (k1 + 2*k2 + 2*k3 + k4) / 6;\n  endfor\n  \n  % Algoritma utama Adams-Bashforth orde 3\n  for i = 3 : N\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    m2 = f(t(i-1), w(i-1));\n    m3 = f(t(i-2), w(i-2));\n    w(i+1) = w(i) + (h/12) * (23*m1 - 16*m2 + 5*m3);\n  endfor\nendfunction\n\n\n\n\n\n\nFour-step Adams-Bashforth (orde 4)\n\\[\\begin{array}{cc|ccccc}\n    \\text{pembagi} & c_1 & c_0 & c_{-1} & c_{-2} & c_{-3} & c_{-4} \\\\\n    1 & \\hspace{0.5cm} & 1 &&&& \\\\\n    2 & \\hspace{0.5cm} & 3 & -1 &&& \\\\\n    12 & \\hspace{0.5cm} & 23 & -16 & 5 && \\\\\n    \\textcolor{red}{24} & \\hspace{0.5cm} & \\textcolor{red}{55} & \\textcolor{red}{-59} & \\textcolor{red}{37} & \\textcolor{red}{-9} & \\\\\n    720 & \\hspace{0.5cm} & 1901 & -2774 & 2616 & -1274 & 251\n\\end{array}\\]\n\\[\n\\begin{gathered}\nw_{0}=\\alpha, \\quad w_{1}=\\alpha_{1}, \\quad w_{2}=\\alpha_{2}, \\quad w_{3}=\\alpha_{3} \\\\\nw_{i+1}=w_{i}+\\frac{h}{24}\\left[55 f\\left(t_{i}, w_{i}\\right)-59 f\\left(t_{i-1}, w_{i-1}\\right)+37 f\\left(t_{i-2}, w_{i-2}\\right)-9 f\\left(t_{i-3}, w_{i-3}\\right)\\right]\n\\end{gathered}\n\\]\nBisa ditulis:\n\\[\n\\begin{gathered}\nw_{1}=\\alpha, \\\\\nw_{2}=\\alpha_{1}, \\quad w_{3}=\\alpha_{2}, \\quad w_{4}=\\alpha_{3} \\\\\nm_1 = f\\left(t_{i}, w_{i}\\right) \\\\\nm_2 = f\\left(t_{i-1}, w_{i-1}\\right) \\\\\nm_3 = f\\left(t_{i-2}, w_{i-2}\\right) \\\\\nm_4 = f\\left(t_{i-3}, w_{i-3}\\right) \\\\\nw_{i+1}=w_{i}+\\frac{h}{24}\\left[55 m_1-59 m_2+37 m_3-9 m_4\\right]\n\\end{gathered}\n\\]\n\nFunction file adams_bashforth_orde4.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = adams_bashforth_orde4(f, a, b, N, alpha)\n  % Inisiasi variabel awal\n  h = (b - a) / N;\n  t = zeros(N + 1, 1);\n  w = zeros(N + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  \n  % Hitung w(2), w(3), w(4) menggunakan metode Runge-Kutta orde 4\n  for i = 1 : 3\n      t(i + 1) = t(i) + h;\n      k1 = h * f(t(i), w(i));\n      k2 = h * f(t(i) + (h/2), w(i) + (k1/2));\n      k3 = h * f(t(i) + (h/2), w(i) + (k2/2));\n      k4 = h * f(t(i + 1), w(i) + k3);\n      w(i+1) = w(i) + (k1 + 2*k2 + 2*k3 + k4) / 6;\n  endfor\n  \n  % Algoritma utama Adams-Bashforth orde 4\n  for i = 4 : N\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    m2 = f(t(i-1), w(i-1));\n    m3 = f(t(i-2), w(i-2));\n    m4 = f(t(i-3), w(i-3));\n    w(i+1) = w(i) + (h/24) * (55*m1 - 59*m2 + 37*m3 - 9*m4);\n  endfor\nendfunction\n\n\n\n\n\n\nFive-step Adams-Bashforth (orde 5)\n\\[\\begin{array}{cc|ccccc}\n    \\text{pembagi} & c_1 & c_0 & c_{-1} & c_{-2} & c_{-3} & c_{-4} \\\\\n    1 & \\hspace{0.5cm} & 1 &&&& \\\\\n    2 & \\hspace{0.5cm} & 3 & -1 &&& \\\\\n    12 & \\hspace{0.5cm} & 23 & -16 & 5 && \\\\\n    24 & \\hspace{0.5cm} & 55 & -59 & 37 & -9 & \\\\\n    \\textcolor{red}{720} & \\hspace{0.5cm} & \\textcolor{red}{1901} & \\textcolor{red}{-2774} & \\textcolor{red}{2616} & \\textcolor{red}{-1274} & \\textcolor{red}{251}\n\\end{array}\\]\n\\[\n\\begin{gathered}\nw_{0}=\\alpha, \\quad w_{1}=\\alpha_{1}, \\quad w_{2}=\\alpha_{2}, \\quad w_{3}=\\alpha_{3}, \\quad w_{4}=\\alpha_{4}, \\\\\nw_{i+1}=w_{i}+\\frac{h}{720}\\left[1901 f\\left(t_{i}, w_{i}\\right)-2774 f\\left(t_{i-1}, w_{i-1}\\right)+2616 f\\left(t_{i-2}, w_{i-2}\\right)\\right. \\\\\n\\left.-1274 f\\left(t_{i-3}, w_{i-3}\\right)+251 f\\left(t_{i-4}, w_{i-4}\\right)\\right]\n\\end{gathered}\n\\]\nBisa ditulis:\n\\[\n\\begin{gathered}\nw_{1}=\\alpha, \\\\\nw_{2}=\\alpha_{1}, \\quad w_{3}=\\alpha_{2}, \\quad w_{4}=\\alpha_{3}, \\quad w_{5}=\\alpha_{4}, \\\\\nm_1 = f\\left(t_{i}, w_{i}\\right) \\\\\nm_2 = f\\left(t_{i-1}, w_{i-1}\\right) \\\\\nm_3 = f\\left(t_{i-2}, w_{i-2}\\right) \\\\\nm_4 = f\\left(t_{i-3}, w_{i-3}\\right) \\\\\nm_5 = f\\left(t_{i-4}, w_{i-4}\\right) \\\\\nw_{i+1}=w_{i}+\\frac{h}{720}\\left[1901 m_1-2774 m_2+2616 m_3\\right. \\\\\n\\left.-1274 m_4+251 m_5\\right]\n\\end{gathered}\n\\]\n\nFunction file adams_bashforth_orde5.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = adams_bashforth_orde5(f, a, b, N, alpha)\n  % Inisiasi variabel awal\n  h = (b - a) / N;\n  t = zeros(N + 1, 1);\n  w = zeros(N + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  \n  % Hitung w(2), ..., w(5) menggunakan metode Runge-Kutta orde 4\n  for i = 1 : 4\n      t(i + 1) = t(i) + h;\n      k1 = h * f(t(i), w(i));\n      k2 = h * f(t(i) + (h/2), w(i) + (k1/2));\n      k3 = h * f(t(i) + (h/2), w(i) + (k2/2));\n      k4 = h * f(t(i + 1), w(i) + k3);\n      w(i+1) = w(i) + (k1 + 2*k2 + 2*k3 + k4) / 6;\n  endfor\n  \n  % Algoritma utama Adams-Bashforth orde 5\n  for i = 5 : N\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    m2 = f(t(i-1), w(i-1));\n    m3 = f(t(i-2), w(i-2));\n    m4 = f(t(i-3), w(i-3));\n    m5 = f(t(i-4), w(i-4));\n    w(i+1) = w(i) + (h/720) * (1901*m1 - 2774*m2 + 2616*m3 -1274*m4 +251*m5);\n  endfor\nendfunction"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul4.html#perbandingan-metode-adams-bashforth",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul4.html#perbandingan-metode-adams-bashforth",
    "title": "Modul 4 Persamaan Diferensial Numerik: Metode Multistep",
    "section": "Perbandingan Metode Adams-Bashforth",
    "text": "Perbandingan Metode Adams-Bashforth\nMisalkan diberikan MNA sebagai berikut, yang ingin diselesaikan secara numerik dengan \\(N = 10\\):\n\\[y' = y - t^2 + 1\\] \\[0 \\le t \\le 2\\] \\[y(0) = 0.5\\]\nyang kebetulan memiliki solusi eksak:\n\\[y\\left(t\\right) = \\left( t + 1 \\right)^2 - 0.5 e^t\\]\nKita bisa membandingkan orde-orde metode Adams-Bashforth dengan menyelesaikan MNA tersebut.\n\nScript file bandingkan_ab.m - nama file bebas\n\n\n\nf = @(t, y) y - t .^ 2 + 1;\na = 0;\nb = 2;\nalpha = 0.5;\nN = 10;\n\n[t_orde2, w_orde2] = adams_bashforth_orde2(f, a, b, N, alpha);\n[t_orde3, w_orde3] = adams_bashforth_orde3(f, a, b, N, alpha);\n[t_orde4, w_orde4] = adams_bashforth_orde4(f, a, b, N, alpha);\n[t_orde5, w_orde5] = adams_bashforth_orde5(f, a, b, N, alpha);\n\nsln = @(t) (t + 1) .^ 2 - 0.5 * exp(t);\ny_eksak = sln(t);\n\n[t, y_eksak, w_orde2, w_orde3, w_orde4, w_orde5]\n\nhold on;\nfplot(sln, [a, b], 'b');\nscatter(t_orde2, w_orde2, 'r');\nscatter(t_orde3, w_orde3, 'g');\nscatter(t_orde4, w_orde4, 'm');\nscatter(t_orde5, w_orde5, 'c');\nlegend(\"Eksak\", \"orde 2\", \"orde 3\", \"orde 4\", \"orde 5\")\nlegend('location', 'northwest') % agar kotak keterangan di atas kiri\n\nans =\n\n        0   0.5000   0.5000   0.5000   0.5000   0.5000\n   0.2000   0.8293   0.8293   0.8293   0.8293   0.8293\n   0.4000   1.2141   1.2161   1.2141   1.2141   1.2141\n   0.6000   1.6489   1.6540   1.6493   1.6489   1.6489\n   0.8000   2.1272   2.1366   2.1283   2.1273   2.1272\n   1.0000   2.6409   2.6561   2.6428   2.6411   2.6408\n   1.2000   3.1799   3.2033   3.1831   3.1803   3.1799\n   1.4000   3.7324   3.7667   3.7372   3.7330   3.7324\n   1.6000   4.2835   4.3324   4.2905   4.2844   4.2836\n   1.8000   4.8152   4.8834   4.8253   4.8166   4.8153\n   2.0000   5.3055   5.3992   5.3196   5.3075   5.3057"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul4.html#penjelasan-tanpa-kode-metode-multistep-implisit-metode-adams-moulton",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul4.html#penjelasan-tanpa-kode-metode-multistep-implisit-metode-adams-moulton",
    "title": "Modul 4 Persamaan Diferensial Numerik: Metode Multistep",
    "section": "(penjelasan tanpa kode) Metode Multistep Implisit: Metode Adams-Moulton",
    "text": "(penjelasan tanpa kode) Metode Multistep Implisit: Metode Adams-Moulton\nMetode implisit lebih sulit digunakan daripada metode eksplisit. Metode implisit dengan sendirinya tidak bisa langsung digunakan, sehingga tidak bisa langsung dimasukkan ke dalam program.\nBiasanya, apabila suatu MNA PDB orde 1 (dengan fungsi \\(f\\left(t,y\\right)\\) yang diketahui) ingin diselesaikan denegan metode implisit, maka rumus metode implisit harus dimanipulasi aljabar terlebih dahulu, hingga diperoleh bentuk \\(w_{i+1} = \\dots\\) tanpa ada suku \\(w_{i+1}\\) sama sekali di ruas kanan.\nHasil manipulasi aljabar bisa berbeda-beda untuk fungsi \\(f\\left(t,y\\right)\\) yang berbeda. Sehingga, apabila metode Adams-Moulton ingin dibuat programnya, maka kode programnya akan sedikit berbeda (yaitu berbeda di hasil manipulasi aljabar) untuk tiap MNA, dan hasil manipulasi aljabar harus dibuat kodenya secara manual untuk tiap MNA.\nOleh karena itu, metode Adams-Moulton itu sendiri sangat tidak praktis apabila ingin dibuat programnya.\nNamun, ada metode Adams yang tetap memanfaatkan metode Adams-Moulton tetapi cenderung lebih baik daripada metode Adams-Bashforth, yaitu metode predictor-corrector yang akan dibahas selanjutnya. Karena itulah, metode Adams-Moulton masih dipaparkan di sini.\nBentuk umum rumus untuk metode \\(n\\)-step Adams-Moulton bisa ditulis sebagai berikut.\n\\[w_{i+1} = w_i + \\frac{h}{\\text{pembagi}} \\left[ c_1 f\\left(t_{i+1},w_{i+1}\\right) + c_0 f\\left(t_i,w_i\\right) + \\dots + c_{-n+1} f\\left(t_{i-n+1},w_{i-n+1}\\right) \\right]\\]\n\\[\\begin{array}{cc|ccccc}\n    \\text{pembagi} & c_1 & c_0 & c_{-1} & c_{-2} & c_{-3} \\\\\n    1 & 1 &&&&& \\\\\n    2 & 1 & 1 &&&& \\\\\n    12 & 5 & 8 & -1 &&& \\\\\n    24 & 9 & 19 & -5 & 1 && \\\\\n    720 & 251 & 646 & -264 & 106 & -19\n\\end{array}\\]\n\nOrde: banyaknya koefisien taknol yang mengkali \\(f\\)\n\\(n\\)-step, \\(n\\): banyaknya koefisien taknol yang mengkali \\(f\\), kecuali koefisien yang mengkali \\(f\\left(t_{i+1},w_{i+1}\\right)\\) kalau ada\n\nUntuk metode Adams-Moulton, berlaku: orde = \\(n+1\\).\nKedua ini tidak dibahas:\n\nmetode Adams-Moulton orde 1, yaitu metode backward Euler.\nmetode Adams-Moulton orde 2, yaitu metode trapezoidal (integrasi numerik).\n\n\nTwo-step Adams-Moulton (orde 3)\n\\[\\begin{array}{cc|ccccc}\n    \\text{pembagi} & c_1 & c_0 & c_{-1} & c_{-2} & c_{-3} \\\\\n    1 & 1 &&&&& \\\\\n    2 & 1 & 1 &&&& \\\\\n    \\textcolor{red}{12} & \\textcolor{red}{5} & \\textcolor{red}{8} & \\textcolor{red}{-1} &&& \\\\\n    24 & 9 & 19 & -5 & 1 && \\\\\n    720 & 251 & 646 & -264 & 106 & -19\n\\end{array}\\]\n\\[\n\\begin{aligned}\nw_0 & =\\alpha, \\quad w_1=\\alpha_1, \\\\\nw_{i+1} & =w_i+\\frac{h}{12}\\left[5 f\\left(t_{i+1}, w_{i+1}\\right)+8 f\\left(t_i, w_i\\right)-f\\left(t_{i-1}, w_{i-1}\\right)\\right]\n\\end{aligned}\n\\]\nBisa ditulis:\n\\[\n\\begin{aligned}\nw_0 &= \\alpha, \\\\\nw_1 &= \\alpha_1, \\\\\nm_0 &= f\\left(t_{i+1}, w_{i+1}\\right) \\\\\nm_1 &= f\\left(t_i, w_i\\right) \\\\\nm_2 &= f\\left(t_{i-1}, w_{i-1}\\right) \\\\\nw_{i+1} &=w_i+\\frac{h}{12}\\left[5 m_0+8 m_1-m_2\\right]\n\\end{aligned}\n\\]\n\n\nThree-step Adams-Moulton (orde 4)\n\\[\\begin{array}{cc|ccccc}\n    \\text{pembagi} & c_1 & c_0 & c_{-1} & c_{-2} & c_{-3} \\\\\n    1 & 1 &&&&& \\\\\n    2 & 1 & 1 &&&& \\\\\n    12 & 5 & 8 & -1 &&& \\\\\n    \\textcolor{red}{24} & \\textcolor{red}{9} & \\textcolor{red}{19} & \\textcolor{red}{-5} & \\textcolor{red}{1} && \\\\\n    720 & 251 & 646 & -264 & 106 & -19\n\\end{array}\\]\n\\[\n\\begin{aligned}\nw_0 & =\\alpha, \\quad w_1=\\alpha_1, \\quad w_2=\\alpha_2, \\\\\nw_{i+1} & =w_i+\\frac{h}{24}\\left[9 f\\left(t_{i+1}, w_{i+1}\\right)+19 f\\left(t_i, w_i\\right)-5 f\\left(t_{i-1}, w_{i-1}\\right)+f\\left(t_{i-2}, w_{i-2}\\right)\\right]\n\\end{aligned}\n\\]\nBisa ditulis:\n\\[\n\\begin{aligned}\nw_0 &= \\alpha, \\\\\nw_1 &= \\alpha_1, \\quad w_2=\\alpha_2, \\\\\nm_0 &= f\\left(t_{i+1}, w_{i+1}\\right) \\\\\nm_1 &= f\\left(t_i, w_i\\right) \\\\\nm_2 &= f\\left(t_{i-1}, w_{i-1}\\right) \\\\\nm_3 &= f\\left(t_{i-2}, w_{i-2}\\right) \\\\\nw_{i+1} &= w_i+\\frac{h}{24}\\left[9 m_0+19 m_1-5 m_2+m_3\\right]\n\\end{aligned}\n\\]\n\n\nFour-step Adams-Moulton (orde 5)\n\\[\\begin{array}{cc|ccccc}\n    \\text{pembagi} & c_1 & c_0 & c_{-1} & c_{-2} & c_{-3} \\\\\n    1 & 1 &&&&& \\\\\n    2 & 1 & 1 &&&& \\\\\n    12 & 5 & 8 & -1 &&& \\\\\n    24 & 9 & 19 & -5 & 1 && \\\\\n    \\textcolor{red}{720} & \\textcolor{red}{251} & \\textcolor{red}{646} & \\textcolor{red}{-264} & \\textcolor{red}{106} & \\textcolor{red}{-19}\n\\end{array}\\]\n\\[\n\\begin{aligned}\nw_0= & \\alpha, \\quad w_1=\\alpha_1, \\quad w_2=\\alpha_2, \\quad w_3=\\alpha_3, \\\\\nw_{i+1}= & w_i+\\frac{h}{720}\\left[251 f\\left(t_{i+1}, w_{i+1}\\right)+646 f\\left(t_i, w_i\\right)\\right. \\\\\n& \\left.-264 f\\left(t_{i-1}, w_{i-1}\\right)+106 f\\left(t_{i-2}, w_{i-2}\\right)-19 f\\left(t_{i-3}, w_{i-3}\\right)\\right]\n\\end{aligned}\n\\]\nBisa ditulis:\n\\[\n\\begin{aligned}\nw_0 &= \\alpha, \\\\\nw_1 &= \\alpha_1, \\quad w_2=\\alpha_2, \\quad w_3=\\alpha_3, \\\\\nm_0 &= f\\left(t_{i+1}, w_{i+1}\\right) \\\\\nm_1 &= f\\left(t_i, w_i\\right) \\\\\nm_2 &= f\\left(t_{i-1}, w_{i-1}\\right) \\\\\nm_3 &= f\\left(t_{i-2}, w_{i-2}\\right) \\\\\nm_4 &= f\\left(t_{i-3}, w_{i-3}\\right) \\\\\nw_{i+1} &= w_i+\\frac{h}{720}\\left[251 m_0+646 m_1\\right. \\\\\n& \\left.-264 m_2+106 m_3-19 m_4\\right]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul4.html#metode-adams-predictor-corrector-orde-n",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul4.html#metode-adams-predictor-corrector-orde-n",
    "title": "Modul 4 Persamaan Diferensial Numerik: Metode Multistep",
    "section": "Metode Adams Predictor-Corrector orde \\(n\\)",
    "text": "Metode Adams Predictor-Corrector orde \\(n\\)\nMetode implisit tidak praktis digunakan dengan sendirinya. Namun, metode implisit pada umumnya lebih akurat daripada metode eksplisit dengan orde yang sama.\nRumus metode implisit seolah-olah merupakan persamaan yang harus dipenuhi oleh \\(w_{i+1}\\) (yang muncul di ruas kiri serta ruas kanan).\nSehingga, kita bisa saja mencoba memodifikasi metode multistep eksplisit: di tiap iterasi, setelah menghitung nilai \\(w_{i+1}\\) menggunakan metode Adams-Bashforth orde \\(n\\), kita bisa memasukkan nilai \\(w_{i+1}\\) tersebut ke dalam ruas kanan rumus metode Adams-Moulton orde \\(n\\) untuk memperoleh aproksimasi \\(w_{i+1}\\) yang lebih baik (toh metode Adams-Moulton orde \\(n\\) umumnya lebih akurat daripada metode Adams-Bashforth orde \\(n\\)).\nIde ini disebut metode Adams predictor-corrector orde \\(n\\): metode Adams-Bashforth orde \\(n\\) memprediksi (menghitung, mengaproksimasi) nilai \\(w_{i+1}\\) yang kemudian dikoreksi (diperbaiiki) oleh metode Adams-Moulton orde \\(n\\) (yang lebih akurat).\nSecara kode program, modifikasi ini hanya menambahkan satu/dua baris saja ke program metode Adams-Bashforth orde \\(n\\), yaitu rumus metode Adams-Moulton orde \\(n\\) di dalam for loop yang sama.\nNote: antara metode Adams-Bashforth dan metode Adams-Moulton, ordenya sama = pembaginya sama.\n\nMetode Adams predictor-corrector orde 3\nMetode Adams-Bashforth orde 3 (three-step) diikuti metode Adams-Moulton orde 3 (two-step).\n\\[\\begin{array}{cc|ccccc}\n    \\text{pembagi} & c_1 & c_0 & c_{-1} & c_{-2} & c_{-3} & c_{-4} \\\\\n    1 & \\hspace{0.5cm} & 1 &&&& \\\\\n    2 & \\hspace{0.5cm} & 3 & -1 &&& \\\\\n    \\textcolor{red}{12} & \\hspace{0.5cm} & \\textcolor{red}{23} & \\textcolor{red}{-16} & \\textcolor{red}{5} && \\\\\n    24 & \\hspace{0.5cm} & 55 & -59 & 37 & -9 & \\\\\n    720 & \\hspace{0.5cm} & 1901 & -2774 & 2616 & -1274 & 251\n\\end{array}\\]\n\\[\\begin{array}{cc|ccccc}\n    \\text{pembagi} & c_1 & c_0 & c_{-1} & c_{-2} & c_{-3} \\\\\n    1 & 1 &&&&& \\\\\n    2 & 1 & 1 &&&& \\\\\n    \\textcolor{red}{12} & \\textcolor{red}{5} & \\textcolor{red}{8} & \\textcolor{red}{-1} &&& \\\\\n    24 & 9 & 19 & -5 & 1 && \\\\\n    720 & 251 & 646 & -264 & 106 & -19\n\\end{array}\\]\nBisa ditulis:\n\\[\n\\begin{aligned}\nw_{1}&=\\alpha, \\\\\nw_{2}&=\\alpha_{1}, \\quad w_{3}=\\alpha_{2}, \\\\\nm_1 &= f\\left(t_{i}, w_{i}\\right) \\\\\nm_2 &= f\\left(t_{i-1}, w_{i-1}\\right) \\\\\nm_3 &= f\\left(t_{i-2}, w_{i-2}\\right) \\\\\nw_{i+1}&=w_{i}+\\frac{h}{12}\\left[23 m_1-16 m_2+5 m_3\\right] \\\\\nm_0 &= f\\left(t_{i+1}, w_{i+1}\\right) \\\\\nw_{i+1} &=w_i+\\frac{h}{12}\\left[5 m_0+8 m_1-m_2\\right]\n\\end{aligned}\n\\]\n\nFunction file adams_pc_orde3.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = adams_pc_orde3(f, a, b, N, alpha)\n  % Inisiasi variabel awal\n  h = (b - a) / N;\n  t = zeros(N + 1, 1);\n  w = zeros(N + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  \n  % Hitung w(2), w(3) menggunakan metode Runge-Kutta orde 4\n  for i = 1 : 2\n      t(i + 1) = t(i) + h;\n      k1 = h * f(t(i), w(i));\n      k2 = h * f(t(i) + (h/2), w(i) + (k1/2));\n      k3 = h * f(t(i) + (h/2), w(i) + (k2/2));\n      k4 = h * f(t(i + 1), w(i) + k3);\n      w(i+1) = w(i) + (k1 + 2*k2 + 2*k3 + k4) / 6;\n  endfor\n  \n  % Algoritma utama Adams Predictor-Corrector orde 3\n  for i = 3 : N\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    m2 = f(t(i-1), w(i-1));\n    m3 = f(t(i-2), w(i-2));\n    % Adams-Bashforth orde 3 (three-step)\n    w(i+1) = w(i) + (h/12) * (23*m1 - 16*m2 + 5*m3);\n    % Adams-Moulton orde 3 (two-step)\n    m0 = f(t(i+1), w(i+1));\n    w(i+1) = w(i) + (h/12) * (5*m0 + 8*m1 - m2);\n  endfor\nendfunction\n\n\n\n\nMisalkan diberikan MNA sebagai berikut, yang ingin diselesaikan secara numerik dengan \\(N = 10\\):\n\\[y' = y - t^2 + 1\\] \\[0 \\le t \\le 2\\] \\[y(0) = 0.5\\]\nyang kebetulan memiliki solusi eksak:\n\\[y\\left(t\\right) = \\left( t + 1 \\right)^2 - 0.5 e^t\\]\n\nScript file coba_adams_pc_orde3.m - nama file bebas\n\n\n\nf = @(t, y) y - t .^ 2 + 1;\na = 0;\nb = 2;\nalpha = 0.5;\nN = 10;\n\n[t, w] = adams_pc_orde3(f, a, b, N, alpha);\n\nsln = @(t) (t + 1) .^ 2 - 0.5 * exp(t);\ny_eksak = sln(t);\n\nerr_pc3 = abs(y_eksak - w);\nerr_pc3_total = sum(err_pc3); % norm L1 (taxicab/Manhattan)\n\ndisp(\"Tabel aproksimasi w, solusi eksak y, dan error:\");\n[t, w, y_eksak, err_pc3]\ndisp(\"Error total (norm L1):\");\ndisp(err_pc3_total);\n\nhold on;\nfplot(sln, [a, b], 'b');\nscatter(t, w, 'r');\nlegend(\"Solusi Eksak\", \"Adams Predictor-Corrector orde 3\")\nlegend('location', 'northwest')\n\nTabel aproksimasi w, solusi eksak y, dan error:\nans =\n\n        0   0.5000   0.5000        0\n   0.2000   0.8293   0.8293   0.0000\n   0.4000   1.2141   1.2141   0.0000\n   0.6000   1.6489   1.6489   0.0000\n   0.8000   2.1272   2.1272   0.0001\n   1.0000   2.6408   2.6409   0.0001\n   1.2000   3.1798   3.1799   0.0002\n   1.4000   3.7322   3.7324   0.0002\n   1.6000   4.2832   4.2835   0.0003\n   1.8000   4.8147   4.8152   0.0005\n   2.0000   5.3048   5.3055   0.0006\n\nError total (norm L1):\n2.0431e-03\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetode Adams predictor-corrector orde 4\nMetode Adams-Bashforth orde 4 (four-step) diikuti metode Adams-Moulton orde 4 (three-step).\n\\[\\begin{array}{cc|ccccc}\n    \\text{pembagi} & c_1 & c_0 & c_{-1} & c_{-2} & c_{-3} & c_{-4} \\\\\n    1 & \\hspace{0.5cm} & 1 &&&& \\\\\n    2 & \\hspace{0.5cm} & 3 & -1 &&& \\\\\n    12 & \\hspace{0.5cm} & 23 & -16 & 5 && \\\\\n    \\textcolor{red}{24} & \\hspace{0.5cm} & \\textcolor{red}{55} & \\textcolor{red}{-59} & \\textcolor{red}{37} & \\textcolor{red}{-9} & \\\\\n    720 & \\hspace{0.5cm} & 1901 & -2774 & 2616 & -1274 & 251\n\\end{array}\\]\n\\[\\begin{array}{cc|ccccc}\n    \\text{pembagi} & c_1 & c_0 & c_{-1} & c_{-2} & c_{-3} \\\\\n    1 & 1 &&&&& \\\\\n    2 & 1 & 1 &&&& \\\\\n    12 & 5 & 8 & -1 &&& \\\\\n    \\textcolor{red}{24} & \\textcolor{red}{9} & \\textcolor{red}{19} & \\textcolor{red}{-5} & \\textcolor{red}{1} && \\\\\n    720 & 251 & 646 & -264 & 106 & -19\n\\end{array}\\]\nBisa ditulis:\n\\[\n\\begin{aligned}\nw_{1}&=\\alpha, \\\\\nw_{2}&=\\alpha_{1}, \\quad w_{3}=\\alpha_{2}, \\quad w_{4}=\\alpha_{3} \\\\\nm_1 &= f\\left(t_{i}, w_{i}\\right) \\\\\nm_2 &= f\\left(t_{i-1}, w_{i-1}\\right) \\\\\nm_3 &= f\\left(t_{i-2}, w_{i-2}\\right) \\\\\nm_4 &= f\\left(t_{i-3}, w_{i-3}\\right) \\\\\nw_{i+1}&=w_{i}+\\frac{h}{24}\\left[55 m_1-59 m_2+37 m_3-9 m_4\\right] \\\\\nm_0 &= f\\left(t_{i+1}, w_{i+1}\\right) \\\\\nw_{i+1} &= w_i+\\frac{h}{24}\\left[9 m_0+19 m_1-5 m_2+m_3\\right]\n\\end{aligned}\n\\]\n\nFunction file adams_pc_orde4.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = adams_pc_orde4(f, a, b, N, alpha)\n  % Inisiasi variabel awal\n  h = (b - a) / N;\n  t = zeros(N + 1, 1);\n  w = zeros(N + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  \n  % Hitung w(2), w(3), w(4) menggunakan metode Runge-Kutta orde 4\n  for i = 1 : 3\n      t(i + 1) = t(i) + h;\n      k1 = h * f(t(i), w(i));\n      k2 = h * f(t(i) + (h/2), w(i) + (k1/2));\n      k3 = h * f(t(i) + (h/2), w(i) + (k2/2));\n      k4 = h * f(t(i + 1), w(i) + k3);\n      w(i+1) = w(i) + (k1 + 2*k2 + 2*k3 + k4) / 6;\n  endfor\n  \n  % Algoritma utama Adams Predictor-Corrector orde 4\n  for i = 4 : N\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    m2 = f(t(i-1), w(i-1));\n    m3 = f(t(i-2), w(i-2));\n    m4 = f(t(i-3), w(i-3));\n    % Adams-Bashforth orde 4 (four-step)\n    w(i+1) = w(i) + (h/24) * (55*m1 - 59*m2 + 37*m3 - 9*m4);\n    % Adams-Moulton orde 4 (three-step)\n    m0 = f(t(i+1), w(i+1));\n    w(i+1) = w(i) + (h/24) * (9*m0 + 19*m1 - 5*m2 + m3);\n  endfor\nendfunction\n\n\n\n\nMisalkan diberikan MNA sebagai berikut, yang ingin diselesaikan secara numerik dengan \\(N = 10\\):\n\\[y' = y - t^2 + 1\\] \\[0 \\le t \\le 2\\] \\[y(0) = 0.5\\]\nyang kebetulan memiliki solusi eksak:\n\\[y\\left(t\\right) = \\left( t + 1 \\right)^2 - 0.5 e^t\\]\nKita bisa membandingkan orde-orde metode Adams Predictor-Corrector dengan menyelesaikan MNA tersebut.\n\nScript file bandingkan_adams_pc.m - nama file bebas\n\n\n\nf = @(t, y) y - t .^ 2 + 1;\na = 0;\nb = 2;\nalpha = 0.5;\nN = 10;\n\n[t_pc3, w_pc3] = adams_pc_orde3(f, a, b, N, alpha);\n[t_pc4, w_pc4] = adams_pc_orde4(f, a, b, N, alpha);\n\nsln = @(t) (t + 1) .^ 2 - 0.5 * exp(t);\ny_eksak = sln(t);\n\nerr_pc3 = abs(y_eksak - w_pc3);\nerr_pc4 = abs(y_eksak - w_pc4);\n\n[t, y_eksak, w_pc3, err_pc3, w_pc4, err_pc4]\n\nhold on;\nfplot(sln, [a, b], 'b');\nscatter(t_pc3, w_pc3, 'r');\nscatter(t_pc4, w_pc4, 'g');\nlegend(\"Solusi Eksak\", \"orde 3\", \"orde 4\")\nlegend('location', 'northwest')\n\nans =\n\n        0   0.5000   0.5000        0   0.5000        0\n   0.2000   0.8293   0.8293   0.0000   0.8293   0.0000\n   0.4000   1.2141   1.2141   0.0000   1.2141   0.0000\n   0.6000   1.6489   1.6489   0.0000   1.6489   0.0000\n   0.8000   2.1272   2.1272   0.0001   2.1272   0.0000\n   1.0000   2.6409   2.6408   0.0001   2.6408   0.0000\n   1.2000   3.1799   3.1798   0.0002   3.1799   0.0000\n   1.4000   3.7324   3.7322   0.0002   3.7324   0.0000\n   1.6000   4.2835   4.2832   0.0003   4.2834   0.0001\n   1.8000   4.8152   4.8147   0.0005   4.8151   0.0001\n   2.0000   5.3055   5.3048   0.0006   5.3054   0.0001"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul2.html",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul2.html",
    "title": "Modul 2 Persamaan Diferensial Numerik: Plotting Fungsi, Metode Euler, Metode Taylor",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul2.html#plotting-fungsi",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul2.html#plotting-fungsi",
    "title": "Modul 2 Persamaan Diferensial Numerik: Plotting Fungsi, Metode Euler, Metode Taylor",
    "section": "Plotting Fungsi",
    "text": "Plotting Fungsi\nSebelum mulai mempelajari metode-metode untuk menyelesaikan persamaan diferensial secara numerik, kita akan membahas terlebih dahulu tentang teknis plotting fungsi, juga sedikit tambahan materi mengenai fungsi.\nMisalnya kita punya fungsi \\(g(x)=2x\\), suatu fungsi matematis (terkadang disebut “pure function” di dunia pemrograman). Ada dua cara untuk mendefinisikannya di Octave.\nCara pertama, yang sudah dibahas di pertemuan sebelumnya, adalah menggunakan keyword function:\n\nfunction y = g(x)\n  y = 2*x;\nendfunction\n\nSehingga bisa dipanggil:\n\ng(3)\n\nans = 6\n\n\nCara kedua, yang lebih praktis, adalah dengan membuat yang namanya anonymous function. Perhatikan syntax berikut:\n\ng = @(x) 2*x;\ng(3)\n\nans = 6\n\n\nTerlihat lebih sederhana, dan cukup mirip dengan penulisan matematis \\(g(x)=2x\\). Sebutannya anonymous function karena sebenarnya fungsinya tidak memiliki nama yang tetap, kebetulan saja kali ini bisa diakses melalui variabel g yang menyimpannya. Secara umum, penulisannya adalah seperti berikut:\nnama_fungsi = @(input1, input2, ..., input_terakhir) rumus;\nSehingga misalnya kita bisa menuliskan fungsi \\(h(x,y) = x^2 + y^3\\), lalu menghitung \\(h(4,5)\\), sebagai berikut:\n\nh = @(x,y) x^2 + y^3;\nh(4,5)\n\nans = 141\n\n\nSelanjutnya, kita akan membahas tentang plotting.\nMisalkan kita memiliki titik-titik \\((0,0)\\), \\((\\frac{\\pi}{2},1)\\), \\((\\pi,0)\\), dan \\((\\frac{3\\pi}{2},-1)\\). Kita bisa membuat dua array, yaitu satu array yang menyimpan tiap nilai x, dan satu lagi untuk menyimpan tiap nilai y.\nKemudian, kita bisa menggambar plot yang menyambung titik-titik tersebut dengan fungsi plot:\n\nx = [0, pi/2, pi, 3*pi/2];\ny = [0, 1, 0, -1];\nplot(x,y)\n\n\n\n\n\n\n\n\nTitik-titik tersebut sebenarnya adalah hasil dari fungsi \\(\\sin(x)\\) yang diterapkan pada nilai \\(x=0, \\frac{\\pi}{2}, \\pi, \\frac{3\\pi}{2}\\).\nSebenarnya, kita bisa saja hanya membuat array nilai x, kemudian memperoleh array nilai y dengan memasukkan array x ke dalam fungsi \\(\\sin(x)\\), agar tiap nilai pada array x diterapkan fungsi \\(\\sin(x)\\). Penerapan fungsi pada tiap elemen array seperti itu sering disebut broadcasting.\n\nx = [0, pi/2, pi, 3*pi/2];\ny = sin(x);\nplot(x,y)\n\n\n\n\n\n\n\n\nUntuk plot yang menyambung-nyambung titik-titik, plotnya sudah bagus. Namun, bagaimana kalau misalnya kita ingin membuat plot fungsi \\(\\sin(x)\\) itu sendiri, misalnya pada interval \\([0,5]\\)?\nCaranya, kita tinggal memperbanyak titik di array x tersebut, agar lebih presisi. Makin banyak titiknya, makin akurat gambarnya.\nTenang saja, kita tidak perlu pegal-pegal mengetik titik-titik \\([0, 0.1, 0.2, ..., 4.9, 5]\\). Di Octave, ada syntax untuk membuat array dari titik-titik pada interval \\([a,b]\\) dengan step size \\(h\\), yaitu sebagai berikut:\nnama_array = a : h : b\nMisalnya, untuk menyimpan titik-titik pada interval \\([0,5]\\) dengan step size 0.1, ketik:\n\nx = 0 : 0.1 : 5\n\nx =\n\n Columns 1 through 8:\n\n         0    0.1000    0.2000    0.3000    0.4000    0.5000    0.6000    0.7000\n\n Columns 9 through 16:\n\n    0.8000    0.9000    1.0000    1.1000    1.2000    1.3000    1.4000    1.5000\n\n Columns 17 through 24:\n\n    1.6000    1.7000    1.8000    1.9000    2.0000    2.1000    2.2000    2.3000\n\n Columns 25 through 32:\n\n    2.4000    2.5000    2.6000    2.7000    2.8000    2.9000    3.0000    3.1000\n\n Columns 33 through 40:\n\n    3.2000    3.3000    3.4000    3.5000    3.6000    3.7000    3.8000    3.9000\n\n Columns 41 through 48:\n\n    4.0000    4.1000    4.2000    4.3000    4.4000    4.5000    4.6000    4.7000\n\n Columns 49 through 51:\n\n    4.8000    4.9000    5.0000\n\n\n\nSehingga, kita bisa membuat plot \\(\\sin(x)\\) pada interval \\([0,5]\\) seperti berikut:\n\nx = 0 : 0.1 : 5;\ny = sin(x);\nplot(x,y)\n\n\n\n\n\n\n\n\nKita bisa menambahkan judul pada plot dengan title\n\nx = 0 : 0.1 : 5;\ny = sin(x);\nplot(x,y);\ntitle(\"Sinus pada [0,5]\");\n\n\n\n\n\n\n\n\nWarnanya bisa ditentukan, misal menjadi merah (‘r’), hijau (‘g’), atau biru (‘b’), dengan menambah keterangan di plot\n\nx = 0 : 0.1 : 5;\ny = sin(x);\nplot(x, y, 'r');\ntitle(\"Sinus pada [0,5]\");\n\n\n\n\n\n\n\n\nPilihan warna lainnya bisa dilihat di link berikut: https://docs.octave.org/latest/Colors.html\nKalau mau, kita bisa mem-plot titik-titiknya saja (tanpa disambung-sambung), menggunakan scatter:\n\nx = 0 : 0.1 : 5;\ny = sin(x);\nscatter(x,y)\n\n\n\n\n\n\n\n\nSeperti di plot, kita juga bisa menentukan warna di scatter:\n\nx = 0 : 0.1 : 5;\ny = sin(x);\nscatter(x, y, 'g')\n\n\n\n\n\n\n\n\nSebenarnya, ada cara yang lebih otomatis untuk mem-plot fungsi, yaitu menggunakan fplot. Kita tinggal memberikan:\n\nfungsi yang ingin dibuat gambarnya\ninterval \\([a,b]\\) yang kita inginkan\n(opsional) warna yang kita inginkan\n\n\nf = @(x) sin(x);\nfplot(f, [0, 5], 'r')\n\n\n\n\n\n\n\n\nNamun, cara ini khusus fungsi kontinu, bahkan langsung menambahkan keterangan yang belum tentu sesuai dengan yang kita inginkan. Agar lebih fleksibel, kita akan lebih sering menggunakan cara manual saja, yaitu dengan membuat array x, menghitung array y, dan memanggil plot.\nKita coba contoh lain yuk! Misalnya kita ingin membuat plot dari fungsi \\(f(x) = x^3\\) pada interval \\([-1,1]\\). Kita bisa coba definisikan fungsinya dulu, lalu buat array x dan y nya:\n\nf = @(x) x^3;\nx = 0 : 0.1 : 5;\ny = f(x);\n\nerror: for x^y, only square matrix arguments are permitted and one argument must be scalar.  Use .^ for elementwise power.\nerror: called from\n    @&lt;anonymous&gt; at line 1 column 11\n\n\nLho, kok error?\nPerhatikan bahwa kita memasukkan array x ke dalam fungsi \\(f(x) = x^3\\). Untuk contoh yang tadi, fungsi \\(\\sin(x)\\), ketika kita memasukkan array x, Octave paham bahwa tiap nilai pada array perlu diterapkan fungsi \\(\\sin\\).\nNamun, kali ini, Octave melihat bahwa ada array yang dipangkatkan tiga. Octave memandang array sebagai matriks dengan satu baris saja (atau satu kolom saja), sehingga Octave mencoba melakukan parpangkatan matriks. Padahal, syarat perpangkatan matriks adalah matriksnya harus persegi. Array ini bukanlah matriks persegi, sehingga jadilah error.\nLalu, bagaimana cara memberi tahu Octave bahwa perpangkatan yang kita maksud adalah perpangkatan per elemen (elementwise)?\nAda syntax khusus untuk itu, yaitu menggunakan .^ daripada ^\nMari kita coba lagi, kali ini membuat plot dengan step size 0.05:\n\nf = @(x) x.^3;\nx = -1 : 0.05 : 1;\ny = f(x);\nplot(x,y)\n\n\n\n\n\n\n\n\nFun fact: apabila ingin menggunakan fplot (daripada plot) untuk mem-plot suatu fungsi, dan apabila ada perpangkatan di dalam definisi fungsi tersebut, maka penulisannya juga harus menggunakan .^ daripada ^\nBagaimana kalau kita mau plot lebih dari satu fungsi? Kita tetap membuat satu array x saja, lalu membuat array y untuk tiap fungsi, seperti berikut:\n\nx = -1 : 0.05 : 1;\ny1 = sin(x);\ny2 = cos(x);\ny3 = tan(x);\nhold on;\nplot(x, y1, 'r');\nplot(x, y2, 'g');\nplot(x, y3, 'b');\n\n\n\n\n\n\n\n\nAda baris hold on. Apa itu?\nBaris itu memastikan bahwa semua plot tetap di satu window yang sama, sehingga di satu gambar yang sama (daripada terpisah-pisah).\n(Kalian bisa coba, kalau tidak ada baris hold on, maka plot fungsi \\(\\sin\\), \\(\\cos\\), dan \\(\\tan\\) akan terpisah semua)\nNantinya, kalian juga bisa menambahkan baris hold off kalau kalian ingin plot selanjutnya buka di window yang baru lagi.\nBaris itu memastikan bahwa semua plot muncul secara bersamaan. Seandainya tidak ada baris hold on, hanya plot terakhir yang akan muncul. Kalian bisa coba hilangkan baris tersebut, maka hanya plot \\(\\tan\\) yang akan terlihat.\n(Fun fact: hold on nantinya bisa saja dimatikan dengan hold off.)\nKita juga bisa menambahkan legenda (legend) atau keterangan, seperti berikut. Tuliskan keterangannya secara berurutan, sesuai dengan urutan mem-plot fungsi.\n\nx = -1 : 0.05 : 1;\ny1 = sin(x);\ny2 = cos(x);\ny3 = tan(x);\nhold on;\nplot(x, y1, 'r');\nplot(x, y2, 'g');\nplot(x, y3, 'b');\nlegend(\"Sinus\", \"Kosinus\", \"Tangen\");\n\n\n\n\n\n\n\n\nSedikit tambahan, kita bisa menyimpan fungsi ke dalam sejenis array yang khusus (sehingga bisa diakses melalui indeks), yang bernama cell array.\nMisalnya kita ingin menyimpan fungsi \\(f(x)=3x^2\\), \\(g(x)=6\\) (fungsi konstan), dan \\(h(x,y) = \\sin(x) + \\cos(y)\\), di dalam satu cell array bernama array_fungsi. Penulisannya menggunakan kurung kurawal { } dan indeksnya juga menggunakan kurung kurawal, seperti berikut:\n\nf = @(x) 3 * x.^2;\ng = @(x) 6;\nh = @(x,y) sin(x) + cos(y);\narray_fungsi = {f, g, h};\n\narray_fungsi{3}(pi/2, 0)\n\nans = 2\n\n\nPerhatikan bahwa kita bisa mengindeks cell array tersebut untuk memperoleh suatu fungsi yang kemudian langsung bisa dipanggil. Misalnya, dipilih indeks ketiga yaitu fungsi \\(h(x,y)\\), kemudian langsung dipanggil dengan \\(x=\\frac{\\pi}{2}\\) dan \\(y=0\\).\nSebenarnya, cell array ini adalah sejenis array yang bisa menyimpan apapun (tidak seperti array biasa yang hanya bisa menyimpan nilai numerik).\n\ntest_cell = {9, 8, 7};\ntest_cell{2} * 3\n\nans = 24\n\n\nNamun, broadcasting tidak berlaku pada cell array, sehingga cell array jarang digunakan (toh Octave paling sering digunakan untuk perhitungan numerik).\nArray biasa dan cell array di Octave, bagaikan array numpy dan list di Python."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul2.html#metode-euler",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul2.html#metode-euler",
    "title": "Modul 2 Persamaan Diferensial Numerik: Plotting Fungsi, Metode Euler, Metode Taylor",
    "section": "Metode Euler",
    "text": "Metode Euler\nMetode Euler adalah metode paling dasar dalam mencari solusi dari permasalahan nilai awal dari suatu PD.\nMisalkan kita mempunyai suatu persamaan diferensial dengan nilai awal:\n\\[y^{\\prime}=f(t, y), a \\leq t \\leq b\\] \\[y(a)=\\alpha\\]\nmaka solusi secara numeriknya adalah \\(w_i= y(t_i)\\), dengan:\n\\[w_1=\\alpha\\] \\[w_{i+1}=w_i+h f\\left(t_i, w_i\\right), \\quad i=1,2, \\ldots, N\\]\ndengan \\(N+1\\in \\mathbb{N}\\) menyatakan banyaknya titik nantinya.\nSolusi kita akan berupa titik (yang nantinya dapat menggunakan interpolasi untuk nilai yang tidak dimuat di \\(w_i\\))\nMetode Euler juga bisa ditulis:\n\\[w_1=\\alpha\\]\ndiikuti iterasi untuk \\(i=1,2, \\ldots, N\\),\n\\[m_1 = f\\left(t_i, w_i\\right)\\] \\[w_{i+1}=w_i+h m_1\\]\nMetode Euler membutuhkan\n\nfungsi \\(f\\left(t,y\\right)\\) dalam MNA \\(y' = f\\left(t,y\\right)\\)\ninterval \\([a,b]\\)\nniali \\(N\\), agar digunakan \\(N+1\\) titik, yaitu sebagai pembagi dalam perhitungan step size \\(h = \\frac{b-a}{N}\\)\n\\(\\alpha\\) (alpha) sebagai nilai awal dalam \\(y(a) = \\alpha\\)\n\nsehingga programnya (fungsi metode Euler) bisa ditulis sebagai berikut:\n\nFunction file euler.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = euler(f, a, b, N, alpha)\n  h = (b - a) / N;\n  t = zeros(N + 1, 1);\n  w = zeros(N + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1 : N\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    w(i + 1) = w(i) + h * m1;\n  endfor\nendfunction\n\n\n\n\nPerhatikan: kode di atas berupa fungsi (lebih tepatnya diawali dengan function), sehingga\n\nlazimnya di simpan sebagai satu file tersendiri, yaitu sebagai function file, agar nantinya bisa dipanggil dari file lain\nsebagai function file, nama file nya harus sama persis dengan nama fungsinya; di sini, nama file nya harus euler.m\n\nSekarang akan kita coba gunakan untuk menyelesaikan suatu MNA (masalah nilai awal) PDB orde 1. Misal diberikan MNA sebagai berikut:\n\\[y^{\\prime}=y-t^2+1\\] \\[0 \\leq t \\leq 2\\] \\[y(0)=0.5\\]\nmaka kita dapat mendefinisikan\n\nf = @(t, y) y-t^2+1,\na=0,\nb=2, dan\nalpha \\(=0.5\\)\n\nsehingga untuk \\(N=10\\), diperoleh kode dan hasil sebagai berikut:\n\nf = @(t, y) (y-t^2 + 1);\na = 0;\nb = 2;\nN = 10;\nalpha= 0.5;\n[t_euler, w_euler] = euler(f, a, b, N, alpha);\n\n\n[t_euler, w_euler]\n\nans =\n\n        0   0.5000\n   0.2000   0.8000\n   0.4000   1.1520\n   0.6000   1.5504\n   0.8000   1.9885\n   1.0000   2.4582\n   1.2000   2.9498\n   1.4000   3.4518\n   1.6000   3.9501\n   1.8000   4.4282\n   2.0000   4.8658\n\n\n\nSebenarnya, MNA tersebut bisa dihitung solusi eksaknya, yaitu\n\\[y(t)=(t+1)^2- 0.5 e^t\\]\nsehingga kita bisa menghitung error metode Euler:\n\nTulis fungsi solusi eksak sebagai anonymous function\nTerapkan fungsi tersebut pada array t untuk memperoleh array y (yaitu nilai solusi eksak pada tiap nilai t)\nHitung mutlak dari selisih antara array w (hasil aproksimasi metode Euler) dengan array y, untuk memperoleh array baru yaitu error metode Euler\n\n\nsln = @(t) (t + 1).^2 - 0.5 * exp(t);\ny_eksak = sln(t_euler);\nerr_euler = abs(y_eksak - w_euler);\n\nSekarang, kita bisa menampilkan empat kolom berdampingan (membentuk tabel): nilai t, nilai w, nilai y (eksak), dan error.\n\n[t_euler, w_euler, y_eksak, err_euler]\n\nans =\n\n        0   0.5000   0.5000        0\n   0.2000   0.8000   0.8293   0.0293\n   0.4000   1.1520   1.2141   0.0621\n   0.6000   1.5504   1.6489   0.0985\n   0.8000   1.9885   2.1272   0.1387\n   1.0000   2.4582   2.6409   0.1827\n   1.2000   2.9498   3.1799   0.2301\n   1.4000   3.4518   3.7324   0.2806\n   1.6000   3.9501   4.2835   0.3334\n   1.8000   4.4282   4.8152   0.3870\n   2.0000   4.8658   5.3055   0.4397\n\n\n\nUntuk visualisasinya, kita akan membuat plot dari hasil yang kita peroleh.\nKita tambahkan kode berikut pada file, untuk membandingkan plot solusi eksak dengan plot dari titik-titik hasil algoritma.\n\nhold on;\nfplot(sln, [a, b], 'b');\nscatter(t_euler, w_euler, 'r');\nlegend('Solusi eksak', 'Metode Euler');\ntitle(\"Metode Euler\");\n\n\n\n\n\n\n\n\nSaat dijalankan, akan muncul jendela pop-up yang berisi plot yang telah dibuat.\n\nPenjelasan:\n\nsln berisi fungsi referensi kita untuk di-plot dan dibandingkan.\nfplot(f, [a, b]) akan menampilkan plot dari suatu fungsi f dengan domain [a, b]. Argumen tambahan ‘b’ memberi warna biru pada plot.\nhold on akan menahan plot yang ada agar kita bisa menampilkan banyak plot sekaligus.\nscatter(x, y) akan menampilkan x-y scatter plot.\nlegend memberi legenda/keterangan pada plot yang telah dibuat. Legenda tersebut dimasukkan berurutan mulai dari plot yang didefinsikan terlebih dahulu\ntitle memberi judul pada plot\n\nSecara keseluruhan, kodenya menjadi seperti berikut.\n\nScript file coba_euler.m - nama file bebas\n\n\n\n% setup\nf = @(t, y) (y-t^2 + 1);\na = 0;\nb = 2;\nN = 10;\nalpha= 0.5;\n\n% hitung metode Euler\n[t_euler, w_euler] = euler(f, a, b, N, alpha);\n\n% solusi eksak\nsln = @(t) (t + 1).^2 - 0.5 * exp(t);\ny_eksak = sln(t_euler); % hitung solusi eksak di tiap titik t\n\n% error: nilai mutlak dari selisih\nerr_euler = abs(y_eksak - w_euler);\n\n% error total: jumlahan dari nilai mutlak dari selisih\n% menghitung error seperti ini disebut norm L1 (juga disebut taxicab/Manhattan)\nerr_euler_total = sum(err_euler);\n\n% tampilkan sejumlah kolom menjadi seperti tabel\ndisp(\"Tabel aproksimasi w, solusi eksak y, dan error:\");\n[t_euler, w_euler, y_eksak, err_euler]\n\n% tampilkan juga error total\ndisp(\"Error total (norm L1):\");\ndisp(err_euler_total);\n\n% plotting\nhold on;\nfplot(sln, [a, b], 'b');\nscatter(t_euler, w_euler, 'r');\nlegend('Solusi eksak', 'Metode Euler');\ntitle(\"Metode Euler\");\n\nTabel aproksimasi w, solusi eksak y, dan error:\nans =\n\n        0   0.5000   0.5000        0\n   0.2000   0.8000   0.8293   0.0293\n   0.4000   1.1520   1.2141   0.0621\n   0.6000   1.5504   1.6489   0.0985\n   0.8000   1.9885   2.1272   0.1387\n   1.0000   2.4582   2.6409   0.1827\n   1.2000   2.9498   3.1799   0.2301\n   1.4000   3.4518   3.7324   0.2806\n   1.6000   3.9501   4.2835   0.3334\n   1.8000   4.4282   4.8152   0.3870\n   2.0000   4.8658   5.3055   0.4397\n\nError total (norm L1):\n2.1822\n\n\n\n\n\n\n\n\n\n\n\n\nKode ini tidak diawali dengan function, sehingga tidak tergolong function file, melainkan tergolong script file. Sesuai istilahnya, script file bisa berisi apapun yang ingin kita run dengan Octave."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul2.html#metode-taylor-orde-n",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul2.html#metode-taylor-orde-n",
    "title": "Modul 2 Persamaan Diferensial Numerik: Plotting Fungsi, Metode Euler, Metode Taylor",
    "section": "Metode Taylor orde \\(n\\)",
    "text": "Metode Taylor orde \\(n\\)\nMetode Taylor orde \\(n\\) adalah perluasan dari metode Euler (di mana metode Taylor orde 1 sama saja dengan metode Euler). Rumus iterasinya bisa ditulis sebagai berikut:\n\\[w_1 = \\alpha\\]\n\\[\\begin{align*}\nT^{(n)} \\left(t_i, w_i\\right) &= f\\left(t_i, w_i\\right) + \\frac{h}{2}f'\\left(t_i, w_i\\right) + \\cdots + \\frac{h^{n-1}}{n!} f^{\\left(n-1\\right)} \\left(t_i,w_i\\right) \\\\\n\\end{align*}\\]\n\\[w_{i+1} = w_i + hT^{(n)} \\left(t_i, w_i\\right) \\]\nPerhatikan bahwa, dengan metode Taylor orde \\(n\\), kita perlu memperoleh terlebih dahulu rumus analitik untuk sejumlah turunan (terhadap \\(t\\)) dari \\(f\\left(t_i, w_i\\right)\\) yaitu \\(f', f'', \\dots, f^{(n-1)}\\).\nKebetulan, untuk metode Euler, yaitu metode Taylor orde 1 (\\(n=1\\)), kita tidak perlu menghitung turunan fungsinya sama sekali.\nUntuk mempermudah pemrograman, kita coba tulis ulang rumus \\(T^{(n)} \\left(t_i, w_i\\right)\\) dengan sumasi:\n\\[\\begin{align*}\nT^{(n)} \\left(t_i, w_i\\right) &= f\\left(t_i, w_i\\right) + \\frac{h}{2}f'\\left(t_i, w_i\\right) + \\cdots + \\frac{h^{n-1}}{n!} f^{\\left(n-1\\right)} \\left(t_i,w_i\\right) \\\\\n&= \\sum_{j=1}^{n} \\frac{h^{j-1}}{j!} f^{\\left(j-1\\right)} \\left(t_i,w_i\\right) \\\\\n&= f\\left(t_i,w_i\\right) + \\sum_{j=2}^{n} \\frac{h^{j-1}}{j!} f^{\\left(j-1\\right)} \\left(t_i,w_i\\right)\n\\end{align*}\\]\nDengan demikian, kita bisa menyimpan fungsi-fungsi \\(f', f'', \\dots, f^{(n-1)}\\) di dalam suatu cell array, misal dinamakan fp, sehingga\n\nkita bisa mengakses turunan ke-\\(i\\) dengan menulis fp{i}\norde \\(n\\) untuk metode Taylor bisa ditentukan menggunakan panjang cell array tersebut, yaitu n = length(fp) + 1;\njika cell array kosong (tidak ada fungsi turunan), otomatis \\(n=1\\) dan algoritmanya menjadi sama saja dengan metode Euler (sesuai harapan)\npenjumlahannya bisa menggunakan for loop sederhana\nkita cukup mendefinisikan fungsi metode Taylor ini sekali saja di Octave, daripada harus membuat definisi terpisah untuk orde 2, orde 3, orde 4, dan seterusnya (di mana banyaknya fungsi turunan memang berbeda)\n\nSetelah manipulasi tersebut, secara keseluruhan, metode Taylor orde \\(n\\) bisa ditulis:\n\\[w_1 = \\alpha\\]\n\\[\\begin{align*}\nT^{(n)} \\left(t_i, w_i\\right) &= f\\left(t_i, w_i\\right) + \\frac{h}{2}f'\\left(t_i, w_i\\right) + \\cdots + \\frac{h^{n-1}}{n!} f^{\\left(n-1\\right)} \\left(t_i,w_i\\right) \\\\\n&= \\sum_{j=1}^{n} \\frac{h^{j-1}}{j!} f^{\\left(j-1\\right)} \\left(t_i,w_i\\right) \\\\\n&= f\\left(t_i,w_i\\right) + \\sum_{j=2}^{n} \\frac{h^{j-1}}{j!} f^{\\left(j-1\\right)} \\left(t_i,w_i\\right)\n\\end{align*}\\]\n\\[w_{i+1} = w_i + hT^{(n)} \\left(t_i, w_i\\right) \\]\nAtau lebih singkatnya:\n\\[w_1 = \\alpha\\]\n\\[T^{(n)} \\left(t_i, w_i\\right) = f\\left(t_i,w_i\\right) + \\sum_{j=2}^{n} \\frac{h^{j-1}}{j!} f^{\\left(j-1\\right)} \\left(t_i,w_i\\right)\\]\n\\[w_{i+1} = w_i + hT^{(n)} \\left(t_i, w_i\\right) \\]\n\nFunction file taylor.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = taylor(f, fp, a, b, N, alpha)\n  h = (b - a) / N;\n  n = length(fp) + 1;\n  t = zeros(n + 1, 1);\n  w = zeros(n + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1 : N\n    t(i + 1) = t(i) + h;\n    \n    T = f(t(i), w(i));\n    for j = 2 : n\n      T += h^(j-1) * fp{j-1}(t(i),w(i)) / factorial(j);\n    endfor\n    \n    w(i + 1) = w(i) + h * T;\n  endfor\nendfunction\n\n\n\n\nContoh penggunaan:\nMisalkan diberikan MNA sebagai berikut, yang diminta untuk diselesaikan secara numerik dengan metode Taylor orde 4:\n\\[y' = y - t^2 + 1\\] \\[0 \\le t \\le 2\\] \\[y(0) = 0.5\\]\nMaka, dengan \\(y' = f\\left(t, y\\right) = y - t^2 + 1\\), bisa dihitung:\n\\[f'\\left(t, y\\right) = y - t^2 + 1 - 2t\\]\n\\[f''\\left(t, y\\right) = y - t^2 - 2t - 1\\]\n\\[f^{(3)}\\left(t, y\\right) = y - t^2 - 2t - 1, \\hspace{0.2cm} \\text{kebetulan sama persis dengan} \\hspace{0.2cm} f''\\left(t, y\\right)\\]\n\nScript file coba_taylor4.m - nama file bebas\n\n\n\n% contoh pakai: subbab 5.3 example 1b (orde 4)\n\n% f(t_i, w_i)\nf0 = @(t,y) y - t^2 + 1;\n\n% f'(t_i, w_i)\nf1 = @(t,y) y - t^2 + 1 - 2*t;\n\n% f''(t_i, w_i)\nf2 = @(t,y) y - t^2 - 2*t - 1;\n\n% f'''(t_i, w_i)\nf3 = @(t,y) y - t^2 - 2*t - 1;\n\n% hitung pada interval [0,2], N=10, y(0)=alpha=0.5\n[t, w] = taylor(f0, {f1, f2, f3}, 0, 2, 10, 0.5);\n% otomatis Taylor orde 4 karena\n% ada tiga fungsi turunan f1, f2, f3\n% yang diinput di cell array\n\n% bandingkan dengan Tabel 5.4\n[t, w]\n\nans =\n\n        0   0.5000\n   0.2000   0.8293\n   0.4000   1.2141\n   0.6000   1.6489\n   0.8000   2.1272\n   1.0000   2.6409\n   1.2000   3.1800\n   1.4000   3.7324\n   1.6000   4.2835\n   1.8000   4.8152\n   2.0000   5.3056\n\n\n\n\n\n\nKita bisa membandingkan antara solusi eksak, metode Euler, dan metode Taylor orde 4, baik dalam menampilkan tabel iterasi maupun menampilkan plot:\n\nScript file bandingkan_taylor.m - nama file bebas\n\n\n\n% fungsi f(t,y) dan turunan pertama, kedua, ketiga\nf0 = @(t,y) y - t^2 + 1;\nf1 = @(t,y) y - t^2 + 1 - 2*t;\nf2 = @(t,y) y - t^2 - 2*t - 1;\nf3 = @(t,y) y - t^2 - 2*t - 1;\n\na = 0;\nb = 2;\nN = 10;\nalpha = 0.5;\n\n% menghitung metode Euler dan metode Taylor orde 4\n[t_euler, w_euler] = euler(f0, a, b, N, alpha);\n[t_taylor, w_taylor] = taylor(f0, {f1,f2,f3}, a, b, N, alpha);\n\n% solusi eksak\nsln = @(t) (t + 1).^2 - 0.5 * exp(t);\ny_eksak = sln(t_euler);\n\n% tampilkan tabel\n[t_euler, w_euler, w_taylor, y_eksak]\n\n% plotting\nhold on;\nfplot(sln, [a, b], 'b');\nscatter(t_euler, w_euler, 'r');\nscatter(t_taylor, w_taylor, 'g');\nlegend(\"Solusi Eksak\", \"Metode Euler\", \"Metode Taylor orde 4\");\n\nans =\n\n        0   0.5000   0.5000   0.5000\n   0.2000   0.8000   0.8293   0.8293\n   0.4000   1.1520   1.2141   1.2141\n   0.6000   1.5504   1.6489   1.6489\n   0.8000   1.9885   2.1272   2.1272\n   1.0000   2.4582   2.6409   2.6409\n   1.2000   2.9498   3.1800   3.1799\n   1.4000   3.4518   3.7324   3.7324\n   1.6000   3.9501   4.2835   4.2835\n   1.8000   4.4282   4.8152   4.8152\n   2.0000   4.8658   5.3056   5.3055"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/tugas1.html",
    "href": "semuahalaman/modulprak/2024/genap/metnum/tugas1.html",
    "title": "Tugas 1 Praktikum Metode Numerik",
    "section": "",
    "text": "Kembali ke Metode Numerik\nSemester Genap Tahun Ajaran 2023/2024\nPetunjuk Umum:"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/tugas1.html#ketentuan-soal",
    "href": "semuahalaman/modulprak/2024/genap/metnum/tugas1.html#ketentuan-soal",
    "title": "Tugas 1 Praktikum Metode Numerik",
    "section": "Ketentuan Soal",
    "text": "Ketentuan Soal\nBuatlah suatu program yang bisa menerima input untuk mengaproksimasi akar dari fungsi \\(f(x)\\) pada interval \\([0.01, 0.4+(t+1)/10]\\), dengan \\(t = (\\text{NPM} \\mod 3) - 1\\) , dan\n\\[\\begin{equation}\n    f(x) = \\frac{\\cos^3\\left(a\\right)}{\\sqrt{1+\\cos^2(t)}\\ln(x+x^2)\\cos^3\\left(b\\right)}\n\\end{equation}\\]\ndengan\n\\[\\begin{align*}\n    a &= \\dfrac{x^2+x-2}{(3x^3-x^2+3x-1)^t}\\\\\n    b &= \\dfrac{x}{(x^2-4x+8)^{2-t}}\n\\end{align*}\\]\nNote: pada python (NumPy dan SymPy), notasi \\(\\ln(x)\\) dinyatakan dengan fungsi log(x)\nserta batas toleransi \\(10^{-6}\\) atau enam angka di belakang koma (menggunakan Absolute Error), dan batasan \\(50\\) iterasi (sehingga metode dipaksa berhenti setelah \\(50\\) iterasi walaupun batas toleransi belum tercapai, agar tidak mungkin terjadi infinite loop). Perhatikan bahwa fungsi Anda beserta intervalnya mengandung \\(t\\), yang berarti setiap fungsi berbeda-beda tergantung NPM Anda."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/tugas1.html#metode-yang-digunakan",
    "href": "semuahalaman/modulprak/2024/genap/metnum/tugas1.html#metode-yang-digunakan",
    "title": "Tugas 1 Praktikum Metode Numerik",
    "section": "Metode yang Digunakan",
    "text": "Metode yang Digunakan\nMetode aproksimasi akar yang wajib Anda gunakan adalah:\n\n[30] Metode Bisection (tampilkan titik tengah saja); dan\n[30] Metode Fixed-Point (dengan \\(g(x)=x-f(x)\\)) dan tebakan awal = batas atas interval.\n\nSelain itu, terdapat metode aproksimasi akar yang tidak wajib kalian buat, namun apabila dikerjakan akan menjadi nilai tambah apabila terdapat kekurangan pada program yang telah kalian buat. Metode tambahan yang dapat digunakan adalah:\n\nMetode Regula Falsi (tampilkan titik tengah saja); dan\nMetode Steffensen (dengan \\(g(x)=x-f(x)\\)) dan tebakan awal = batas atas interval."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/tugas1.html#tabel-iterasi",
    "href": "semuahalaman/modulprak/2024/genap/metnum/tugas1.html#tabel-iterasi",
    "title": "Tugas 1 Praktikum Metode Numerik",
    "section": "Tabel Iterasi",
    "text": "Tabel Iterasi\n\n[15] Dalam menampilkan hasil iterasi dari metode-metode yang digunakan, program diharapkan bisa menampilkan satu tabel iterasi yang membandingkan keseluruhan metode yang kalian buat.\n[5] Ketika salah satu metode mencapai batas toleransi sebelum metode lainnya, diharapkan sisa data pada tabel menjadi kata “Selesai”, kata “Fin” (atau “Finished”), huruf “V” (centang), atau semacamnya (jangan lupa berikan keterangan arti kata/hurufnya) yang menandakan bahwa metode tersebut telah selesai sebelum metode lainnya."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/tugas1.html#error-handling",
    "href": "semuahalaman/modulprak/2024/genap/metnum/tugas1.html#error-handling",
    "title": "Tugas 1 Praktikum Metode Numerik",
    "section": "Error Handling",
    "text": "Error Handling\n\n[5] Program diharapkan tidak menjadi error ketika ada pembagian nol, melainkan program tetap menampilkan tabel iterasi, dengan data “NaN” (dari NumPy) untuk mengisi kekosongan hasil iterasi setelah terjadinya pembagian nol atau ketika program gagal menemukan akar karena hal lain (misalkan pada bisection jika \\(f(a)\\cdot f(b)&gt;0\\))."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/tugas1.html#kerapian-program",
    "href": "semuahalaman/modulprak/2024/genap/metnum/tugas1.html#kerapian-program",
    "title": "Tugas 1 Praktikum Metode Numerik",
    "section": "Kerapian Program",
    "text": "Kerapian Program\n\n[5] Keseluruhan program Anda dikemas di dalam satu subprogram atau fungsi (function) yang bisa menerima sembarang fungsi, batas toleransi, batas iterasi, interval dan/atau satu/dua tebakan awal (boleh melalui input user maupun melalui argumen/parameter fungsi).\n[5] Program Anda bisa berjalan berulang kali (dengan beberapa kali input dan output) sesuai permintaan user, tanpa harus berhenti dan di-run ulang secara manual terlebih dahulu."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/tugas1.html#kesimpulan",
    "href": "semuahalaman/modulprak/2024/genap/metnum/tugas1.html#kesimpulan",
    "title": "Tugas 1 Praktikum Metode Numerik",
    "section": "Kesimpulan",
    "text": "Kesimpulan\n\n[5] Bandingkan hasil dari tiap metode yang Anda gunakan. Analisa hasil yang Anda dapatkan pada tabel iterasi kemudian tuliskan kesimpulan dari hasil tersebut, yaitu dapat mengenai metode mana yang berhasil selesai dan memenuhi toleransi, metode mana yang paling cepat konvergen, metode mana yang gagal (jika ada), dan sebagainya."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul4.html",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul4.html",
    "title": "Modul 4: Integrasi Numerik",
    "section": "",
    "text": "Kembali ke Metode Numerik"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul4.html#metode-newton-cotes",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul4.html#metode-newton-cotes",
    "title": "Modul 4: Integrasi Numerik",
    "section": "Metode Newton-Cotes",
    "text": "Metode Newton-Cotes\n\nPengantar integrasi numerik\nDi kalkulus, kita sudah mempelajari integral Riemann, yang melibatkan penjumlahan luas sejumlah persegi panjang, yang secara keseluruhan mengaproksimasi luas di bawah kurva (yang berupa fungsi). Makin banyak persegi panjang, maka hasil perhitungan menjadi semakin akurat. Sebenarnya, itu sudah termasuk integrasi numerik (sayangnya, secara pemrograman, kita tidak bisa membuat limit menuju tak hingga).\nIntegrasi numerik juga disebut “kuadratur numerik” atau “kuadratur” saja.\nDi mata kuliah metode numerik, salah satu teknik integrasi numerik (untuk menghitung integral tentu) yang kita pelajari disebut metode Newton-Cotes, yang secara teori melibatkan aproksimasi fungsi dengan polinom interpolasi Lagrange, kemudian dihitung integral analitik dari polinom interpolasi Lagrange tersebut. Semua titik-titik yang digunakan untuk interpolasi (disebut nodes) ada di dalam interval integral tentu, dan jarak antar titik-titik tersebut menggunakan step size yang konstan, yang bisa kita sebut \\(h\\) (seperti biasa).\nUntungnya, setelah dilakukan penyederhanaan dan manipulasi aljabar, bentuk rumus yang dihasilkan oleh metode Newton-Cotes menjadi cukup singkat dan sederhana. Sehingga, pada prakteknya, ketika menggunakan metode Newton-Cotes, kita tinggal menggunakan rumus hasil akhirnya; kita tidak perlu lagi pusing dengan interpolasi Lagrange.\nIntegral tentu pasti memliki batas bawah \\(a\\) dan batas atas \\(b\\) (bisa dianggap sebagai batasan interval di mana integrasi akan dilakukan), dan bisa ditulis \\(\\int_{a}^{b} f\\left(x\\right) dx\\). Untuk interpolasi yang dilakukan dalam metode Newton-Cotes, secara keseluruhan ada dua cara untuk memilih nodes yang akan diberlakukan interpolasi, yaitu dengan melibatkan ujung interval integrasi (dianggap interval tutup \\([a,b]\\) atau closed interval) maupun tidak melibatkan ujung interval (dianggap interval buka \\((a,b)\\) atau open interval). Dengan demikian, rumus metode Newton Cotes bisa dikategorikan menjadi dua jenis, yaitu closed Newton-Cotes dan open Newton-Cotes, tergantung teknis interpolasi apakah melibatkan titik ujung interval atau tidak. Tentu saja, rumusnya menjadi berbeda.\nBaik untuk closed Newton-Cotes maupun open Newton-Cotes, banyaknya nodes yang berbeda juga menghasilkan rumus yang berbeda. Karena closed Newton-Cotes melibatkan titik ujung interval, maka diperlukan minimal dua nodes (yaitu kedua titik ujung interval). Sedangkan, untuk open Newton-Cotes, minimal banyaknya nodes cukup satu saja.\n\n\nMetode closed Newton-Cotes\nDalam penulisan berbagai variasi rumus closed Newton-Cotes, digunakan variabel \\(n\\) apabila telah digunakan \\((n+1)\\) nodes untuk interpolasi, dan titik-titik tersebut biasanya ditulis \\(x_0, x_1, x_2, \\dots, x_n\\), yaitu \\(x_i\\) untuk \\(i=0,1,2,\\dots,n\\).\nNilai \\(n\\) terkecil yang mungkin adalah \\(n=1\\) (di mana digunakan \\(n+1=2\\) nodes untuk interpolasi), dan sering disebut “trapezoidal rule”, karena luas yang sebenarnya dihitung memang kebetulan berbentuk trapezoid. (Pada gambar berikut ini, \\(f(x)\\) adalah fungsi yang ingin diintegralkan, sedangkan \\(P_1 (x)\\) adalah polinom interpolasi Lagrange yang mengaproksimasi \\(f(x)\\) pada nodes yang telah ditentukan.)\n\n\n\np1 integral croptime Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org) copy_page-0001.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.3, “Elements of Numerical Integration”. Hlm. 194\nSedangkan, rumus closed Newton-Cotes untuk \\(n=2\\) (menggunakan \\(n+1=3\\) nodes untuk interpolasi) disebut “Simpson’s rule”.\nPerhatikan bahwa, secara umum, \\((n+1)\\) titik yang digunakan seolah-olah membagi interval \\([a,b]\\) menjadi \\(n\\) subinterval. Misalnya, pada gambar berikut, metode Simpson dengan \\(n=2\\) (menggunakan tiga titik: \\(x_0, x_1, x_2\\)) terlihat seperti membagi interval \\([a,b]\\) menjadi \\(n=2\\) subinterval, yaitu \\([x_0, x_1]\\) dan \\([x_1, x_2]\\).\n\n\n\np2 integral croptime Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org) copy_page-0002.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.3, “Elements of Numerical Integration”. Hlm. 195\nBerikut penjabaran beberapa rumus closed Newton-Cotes untuk mengaproksimasi integral tentu pada interval tutup \\([a,b]\\), masing-masing menggunakan titik-titik \\(x_i = x_0 + ih\\) untuk \\(i = 0, 1, \\dots, n\\), serta step size \\(h = \\frac{b-a}{n}\\). Di sini, dibuat \\(x_0 = a\\) dan \\(x_n = b\\).\n\\(n=1\\) (trapezoidal rule):\n\\[\\int_a^b f \\left( x \\right) dx \\approx \\frac{h}{2} \\left[ f(x_0) + f(x_1)\\right]\\]\ndengan \\(h = b-a\\).\n\\(n=2\\) (Simpson’s rule):\n\\[\\int_a^b f \\left( x \\right) dx \\approx \\frac{h}{3} \\left[ f(x_0) + 4f(x_1) + f(x_2)\\right]\\]\ndengan \\(h = \\frac{b-a}{2}\\).\n\\(n=3\\) (Simpson’s Three-Eights rule):\n\\[\\int_a^b f \\left( x \\right) dx \\approx \\frac{3h}{8} \\left[ f(x_0) + 3f(x_1) + 3f(x_2) + f(x_3)\\right]\\]\ndengan \\(h = \\frac{b-a}{3}\\).\n\\(n=4\\) (Boole’s rule):\n\\[\\int_a^b f \\left( x \\right) dx \\approx \\frac{2h}{45} \\left[ 7f(x_0) + 32f(x_1) + 12f(x_2) + 32f(x_3) + 7f(x_4)\\right]\\]\ndengan \\(h = \\frac{b-a}{4}\\).\nKarena rumusnya sudah ada, pembuatan program untuk metode closed Newton-Cotes tergolong mudah.\n\n# n = 1 (Trapezoidal rule)\ndef TrapezoidalRule(f,a,b):\n    # f adalah fungsi\n    h = b-a\n    x = [a, b] # list nilai x\n    hasil = (h/2) * ( f(x[0]) + f(x[1]) )\n    return hasil\n\n# n = 2 (Simpson's rule)\ndef SimpsonsRule(f,a,b):\n    h = (b-a)/2\n    x = [a, a+h, b]\n    hasil = (h/3) * ( f(x[0]) + 4*f(x[1]) + f(x[2]) )\n    return hasil\n\n# n = 3 (Simpson's Three-Eights rule)\ndef SimpsonsThreeEightsRule(f,a,b):\n    h = (b-a)/3\n    x = [a, a+h, a + 2*h, b]\n    hasil = (3*h/8) * ( f(x[0]) + 3*f(x[1]) + 3*f(x[2]) + f(x[3]) )\n    return hasil\n\n# n = 4 (Boole's rule)\ndef BoolesRule(f,a,b):\n    h = (b-a)/4\n    x = [a, a+h, a + 2*h, a + 3*h, b]\n    hasil = (2*h/45) * ( 7*f(x[0]) + 32*f(x[1]) + 12*f(x[2]) + 32*f(x[3]) + 7*f(x[4]) )\n    return hasil\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Metode closed Newton-Cotes untuk integral tentu\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah integral: \"))\nupper_bound = eval(input(\"Masukkan batas atas integral: \"))\nprint()\n\n# Menghitung aproksimasi integral func(x) untuk n=1,2,3,4\nhasil_closed_1 = TrapezoidalRule(func, lower_bound, upper_bound)\nhasil_closed_2 = SimpsonsRule(func, lower_bound, upper_bound)\nhasil_closed_3 = SimpsonsThreeEightsRule(func, lower_bound, upper_bound)\nhasil_closed_4 = BoolesRule(func, lower_bound, upper_bound)\n\n# Menampilkan hasil\nprint(\"Berikut hasil aproksimasi integral dengan closed Newton-Cotes:\")\nprint(f\"n=1: {hasil_closed_1} (Trapezoidal rule)\")\nprint(f\"n=2: {hasil_closed_2} (Simpson's rule)\")\nprint(f\"n=3: {hasil_closed_3} (Simpson's Three-Eights rule)\")\nprint(f\"n=4: {hasil_closed_4} (Boole's rule)\")\n\nMetode closed Newton-Cotes untuk integral tentu\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = sin(x)\nMasukkan batas bawah integral: 0\nMasukkan batas atas integral: pi/4\n\nBerikut hasil aproksimasi integral dengan closed Newton-Cotes:\nn=1: 0.2776801836348979 (Trapezoidal rule)\nn=2: 0.292932637839748 (Simpson's rule)\nn=3: 0.29291070254917145 (Simpson's Three-Eights rule)\nn=4: 0.29289318256126384 (Boole's rule)\n\n\n\n\nMetode open Newton-Cotes\nDalam penulisan berbagai variasi rumus open Newton-Cotes, digunakan variabel \\(n\\) apabila telah digunakan \\((n+1)\\) nodes untuk interpolasi.\nNilai \\(n\\) terkecil yang mungkin adalah \\(n=0\\) (di mana digunakan \\(n+1=1\\) nodes untuk interpolasi), dan sering disebut “midpoint rule”, karena satu titik yang digunakan tersebut kebetulan berada di tengah-tengah interval \\((a,b)\\), sehingga menjadi midpoint atau titik tengah dari interval integerasi.\nBerikut penjabaran beberapa rumus open Newton-Cotes untuk mengaproksimasi integral tentu pada interval buka \\((a,b)\\), masing-masing menggunakan titik-titik \\(x_i = x_0 + ih\\) untuk \\(i = 0, 1, \\dots, n\\), serta step size \\(h = \\frac{b-a}{n+2}\\). Di sini, dibuat \\(x_0 = a+h\\) dan \\(x_n = b-h\\).\n\\(n=0\\) (midpoint rule):\n\\[\\int_{a}^{b} f\\left(x\\right) dx \\approx 2hf(x_0)\\]\ndengan \\(h = \\frac{b-a}{2}\\).\n\\(n=1\\):\n\\[\\int_{a}^{b} f\\left(x\\right) dx \\approx \\frac{3h}{2} \\left[ f(x_0) + f(x_1) \\right]\\]\ndengan \\(h = \\frac{b-a}{3}\\).\n\\(n=2\\):\n\\[\\int_{a}^{b} f\\left(x\\right) dx \\approx \\frac{4h}{3} \\left[ 2f(x_0) - f(x_1) + 2f(x_2) \\right]\\]\ndengan \\(h = \\frac{b-a}{4}\\).\n\\(n=3\\):\n\\[\\int_{a}^{b} f\\left(x\\right) dx \\approx \\frac{5h}{24} \\left[ 11f(x_0) + f(x_1) + f(x_2) + 11f(x_3) \\right]\\]\ndengan \\(h = \\frac{b-a}{5}\\).\nLagi-lagi, karena semua rumus sudah ada dan tinggal digunakan, pembuatan program untuk metode open Newton-Cotes tergolong mudah.\n\n# n = 0 (Midpoint rule)\ndef OpenNC_n0(f,a,b):\n    # f adalah fungsi\n    h = (b-a)/2\n    x = [a+h] # list nilai x\n    hasil = 2*h*f(x[0])\n    return hasil\n\n# n = 1\ndef OpenNC_n1(f,a,b):\n    h = (b-a)/3\n    x = [a+h, a + 2*h] # list nilai x\n    hasil = (3*h/2) * ( f(x[0]) + f(x[1]) )\n    return hasil\n\n# n = 2\ndef OpenNC_n2(f,a,b):\n    h = (b-a)/4\n    x = [a+h, a + 2*h, a + 3*h]\n    hasil = (4*h/3) * ( 2*f(x[0]) - f(x[1]) + 2*f(x[2]) )\n    return hasil\n\n# n = 3\ndef OpenNC_n3(f,a,b):\n    h = (b-a)/5\n    x = [a+h, a + 2*h, a + 3*h, a + 4*h]\n    hasil = (5*h/24) * ( 11*f(x[0]) + f(x[1]) + f(x[2]) + 11*f(x[3]) )\n    return hasil\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Metode open Newton-Cotes untuk integral tentu\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah integral: \"))\nupper_bound = eval(input(\"Masukkan batas atas integral: \"))\nprint()\n\n# Menghitung aproksimasi integral func(x) untuk n=1,2,3,4\nhasil_open_0 = OpenNC_n0(func, lower_bound, upper_bound)\nhasil_open_1 = OpenNC_n1(func, lower_bound, upper_bound)\nhasil_open_2 = OpenNC_n2(func, lower_bound, upper_bound)\nhasil_open_3 = OpenNC_n3(func, lower_bound, upper_bound)\n\n# Menampilkan hasil\nprint(\"Berikut hasil aproksimasi integral dengan open Newton-Cotes:\")\nprint(f\"n=0: {hasil_open_0} (Midpoint rule)\")\nprint(f\"n=1: {hasil_open_1}\")\nprint(f\"n=2: {hasil_open_2}\")\nprint(f\"n=3: {hasil_open_3}\")\n\nMetode open Newton-Cotes untuk integral tentu\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = sin(x)\nMasukkan batas bawah integral: 0\nMasukkan batas atas integral: pi/4\n\nBerikut hasil aproksimasi integral dengan open Newton-Cotes:\nn=0: 0.30055886494217315 (Midpoint rule)\nn=1: 0.29798754218726264\nn=2: 0.2928586591925902\nn=3: 0.29286922813608435\n\n\n\n\nTabel Ringkasan Metode Newton-Cotes\nUntuk n=0,1,2,3,4, kita bisa meringkas hasil untuk semua metode Newton-Cotes (baik closed maupun open) di dalam satu tabel, di mana - baris pertama adalah nilai n, - baris kedua adalah hasil closed Newton-Cotes yang sesuai untuk tiap nilai n, dan - baris ketiga adalah hasil open Newton-Cotes yang sesuai.\nUntuk nilai n yang tidak mungkin, seperti n=0 untuk closed Newton-Cotes, itu bisa dikosongkan saja.\nSeperti biasa, kita bisa menggunakan tabulate. Kali ini, karena tabel cukup sederhana, kita bisa langsung menyusun tabel dalam bentuk list-di-dalam-list secara manual, yang kemudian akan diolah oleh tabulate.\n\n# Closed Newton-Cotes, n = 1 (Trapezoidal rule)\ndef TrapezoidalRule(f,a,b):\n    # f adalah fungsi\n    h = b-a\n    x = [a, b] # list nilai x\n    hasil = (h/2) * ( f(x[0]) + f(x[1]) )\n    return hasil\n\n# Closed Newton-Cotes, n = 2 (Simpson's rule)\ndef SimpsonsRule(f,a,b):\n    h = (b-a)/2\n    x = [a, a+h, b]\n    hasil = (h/3) * ( f(x[0]) + 4*f(x[1]) + f(x[2]) )\n    return hasil\n\n# Closed Newton-Cotes, n = 3 (Simpson's Three-Eights rule)\ndef SimpsonsThreeEightsRule(f,a,b):\n    h = (b-a)/3\n    x = [a, a+h, a + 2*h, b]\n    hasil = (3*h/8) * ( f(x[0]) + 3*f(x[1]) + 3*f(x[2]) + f(x[3]) )\n    return hasil\n\n# Closed Newton-Cotes, n = 4 (Boole's rule)\ndef BoolesRule(f,a,b):\n    h = (b-a)/4\n    x = [a, a+h, a + 2*h, a + 3*h, b]\n    hasil = (2*h/45) * ( 7*f(x[0]) + 32*f(x[1]) + 12*f(x[2]) + 32*f(x[3]) + 7*f(x[4]) )\n    return hasil\n\n\n# Open Newton-Cotes, n = 0 (Midpoint rule)\ndef OpenNC_n0(f,a,b):\n    # f adalah fungsi\n    h = (b-a)/2\n    x = [a+h] # list nilai x\n    hasil = 2*h*f(x[0])\n    return hasil\n\n# Open Newton-Cotes, n = 1\ndef OpenNC_n1(f,a,b):\n    h = (b-a)/3\n    x = [a+h, a + 2*h] # list nilai x\n    hasil = (3*h/2) * ( f(x[0]) + f(x[1]) )\n    return hasil\n\n# Open Newton-Cotes, n = 2\ndef OpenNC_n2(f,a,b):\n    h = (b-a)/4\n    x = [a+h, a + 2*h, a + 3*h]\n    hasil = (4*h/3) * ( 2*f(x[0]) - f(x[1]) + 2*f(x[2]) )\n    return hasil\n\n# Open Newton-Cotes, n = 3\ndef OpenNC_n3(f,a,b):\n    h = (b-a)/5\n    x = [a+h, a + 2*h, a + 3*h, a + 4*h]\n    hasil = (5*h/24) * ( 11*f(x[0]) + f(x[1]) + f(x[2]) + 11*f(x[3]) )\n    return hasil\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\nfrom tabulate import tabulate\n\nprint(\"Tabel metode closed (n=1,2,3,4) dan open (n=0,1,2,3) Newton-Cotes\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah integral: \"))\nupper_bound = eval(input(\"Masukkan batas atas integral: \"))\nprint()\n\n# Menghitung metode closed Newton-Cotes untuk n=0,1,2,3\nhasil_closed_1 = TrapezoidalRule(func, lower_bound, upper_bound)\nhasil_closed_2 = SimpsonsRule(func, lower_bound, upper_bound)\nhasil_closed_3 = SimpsonsThreeEightsRule(func, lower_bound, upper_bound)\nhasil_closed_4 = BoolesRule(func, lower_bound, upper_bound)\n\n# Menghitung metode open Newton-Cotes untuk n=1,2,3,4\nhasil_open_0 = OpenNC_n0(func, lower_bound, upper_bound)\nhasil_open_1 = OpenNC_n1(func, lower_bound, upper_bound)\nhasil_open_2 = OpenNC_n2(func, lower_bound, upper_bound)\nhasil_open_3 = OpenNC_n3(func, lower_bound, upper_bound)\n\n# Menyusun tabel secara manual\ntabel_mentah = [\n    [\"n\", \"0\", \"1\", \"2\", \"3\", \"4\"],\n    [\"closed\", \"\", hasil_closed_1, hasil_closed_2, hasil_closed_3, hasil_closed_4],\n    [\"open\", hasil_open_0, hasil_open_1, hasil_open_2, hasil_open_3, \"\"]\n]\n\ntabel_olahan = tabulate(tabel_mentah, tablefmt=\"pretty\", floatfmt=\".10f\",\n                        headers=\"firstrow\")\n\nprint(\"Hasil tabel metode Newton-Cotes:\")\nprint(tabel_olahan)\n\nTabel metode closed (n=1,2,3,4) dan open (n=0,1,2,3) Newton-Cotes\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = sin(x)\nMasukkan batas bawah integral: 0\nMasukkan batas atas integral: pi/4\n\nHasil tabel metode Newton-Cotes:\n+--------+---------------------+---------------------+--------------------+---------------------+---------------------+\n|   n    |          0          |          1          |         2          |          3          |          4          |\n+--------+---------------------+---------------------+--------------------+---------------------+---------------------+\n| closed |                     | 0.2776801836348979  | 0.292932637839748  | 0.29291070254917145 | 0.29289318256126384 |\n|  open  | 0.30055886494217315 | 0.29798754218726264 | 0.2928586591925902 | 0.29286922813608435 |                     |\n+--------+---------------------+---------------------+--------------------+---------------------+---------------------+"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul4.html#integrasi-numerik-komposit",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul4.html#integrasi-numerik-komposit",
    "title": "Modul 4: Integrasi Numerik",
    "section": "Integrasi numerik komposit",
    "text": "Integrasi numerik komposit\n\nRumus umum\nUntuk interval yang tidak besar, metode Newton-Cotes cukup akurat. Ingat bahwa metode Newton-Cotes bersandar pada polinom interpolasi Lagrange, yang sering naik-turun atau berosilasi, sehingga berisiko terlalu jauh berbeda dari fungsi yang aslinya, apalagi sekitar titik pertama dan titik terakhir yang digunakan untuk interpolasi. (Fun fact: masalah osilasi ini disebut fenomena Runge.) Risiko tersebut membuat metode Newton-Cotes kurang cocok untuk interval yang besar, karena hasil aproksimasi luasnya menjadi kurang akurat.\nNamun, kita bisa saja memecah suatu integral tentu menjadi sejumlah integral yang masing-masing memiliki interval yang lebih kecil (yang merupakan subinterval dari interval integrasi aslinya), kemudian menerapkan metode Newton-Cotes untuk masing-masing integral. Teknik ini disebut integrasi numerik komposit.\nTentu saja, untuk suatu integral tentu \\(\\int_{A}^{B} f\\left(x\\right) dx\\), kita bisa bebas memilih bagaimana cara memecah interval integrasi yang asli, \\([A,B]\\), menjadi beberapa subinterval. Namun, untuk mempermudah pemrograman, kita bisa memecah \\([A,B]\\) menjadi sejumlah \\(N\\) subinterval (akan kita sebut \\(N\\) “subinterval besar”) yang sama panjang, masing-masing memiliki panjang \\(\\frac{B-A}{N}\\). Kemudian, metode Newton-Cotes yang dipilih bisa diterapkan untuk masing-masing subinterval besar \\([a_i,b_i] \\subseteq [A,B]\\), dengan \\(i=1,2,3,\\dots,N\\). Sehingga, berlaku \\(a_1=A\\) dan \\(b_N=B\\), serta berlaku \\(a_2=b_1\\), \\(a_3=b_2\\) dan seterusnya, atau bisa dituliskan \\(a_i=b_{i-1}\\) untuk \\(i=2,3,4,\\dots,N\\).\n\\[\\int_{A}^{B} f\\left(x\\right) dx = \\int_{a_1}^{b_1} f\\left(x\\right) dx + \\int_{a_2}^{b_2} f\\left(x\\right) dx + \\cdots + \\int_{a_N}^{b_N} f\\left(x\\right) dx\\]\nTeknis perhitungan metode Newton-Cotes bisa melibatkan penggunaan beberapa titik pada \\([a_i,b_i]\\). Sehingga, subinterval besar \\([a_i, b_i]\\), secara tidak langsung, dipecah menjadi beberapa subinterval kecil.\nMisalnya, ketika menerapkan metode Simpson pada \\([a_1,b_1]\\), digunakan \\(h=\\frac{b_1-a_1}{2}\\), yang memecah subinterval besar \\([a_1,b_1]\\) menjadi dua subinterval kecil yaitu \\(\\left[a_1,a_1+h\\right]\\) dan \\(\\left[a_1+h,b_1\\right]\\). Sehingga, untuk metode Simpson komposit, banyaknya subinterval kecil \\(n=2N\\). Perhatikan gambar berikut dengan \\(N=4\\), \\(n=8\\).\n\n\n\np5 integral croptime Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org) copy_page-0005.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.4, “Composite Numerical Integration”. Hlm. 204\nPada gambar di atas, digunakan metode Simpson komposit untuk \\(N=4\\) subinterval besar. Masing-masing subinterval besar (misalnya subinterval besar ke-\\(i\\) untuk \\(i=1,2,\\dots,N\\)) menggunakan titik-titik \\(x_{i-1}\\), \\(x_i\\), dan \\(x_{i+1}\\).\nTerlihat bahwa masing-masing subinterval besar (misalnya subinterval besar ke-3, yang diwarnai biru gelap) terbagi lagi menjadi dua subinterval kecil, sehingga banyaknya subinterval kecil \\(n=2N=8\\). Secara keseluruhan, digunakan sebanyak \\((n+1)\\) titik, yaitu \\(x_0, x_1, x_2, \\dots, x_n\\). Untuk gambar di atas, digunakan \\(n+1=9\\) titik yaitu \\(x_0, x_1, x_2, \\dots, x_8\\).\nDengan demikian, ada dua cara untuk membuat program integrasi numerik komposit, yaitu 1. hanya melihat tiap subinterval besar sampai \\(N\\), kemudian memanggil fungsi metode Newton-Cotes yang sesuai untuk tiap subinterval besar; atau 2. melihat semua subinterval kecil sampai \\(n\\) (sehingga nantinya menggunakan rumus khusus)\nCara yang pertama menghasilkan program yang cukup fleksibel, bisa menerima sembarang metode Newton-Cotes (atau bahkan sembarang metode integrasi numerik) dan kodenya tetap sama. Cara yang kedua melibatkan rumus khusus (seperti yang diberikan di buku), baik untuk metode Simpson komposit, metode trapezoidal komposit, maupun metode midpoint komposit, ataupun yang lainnya.\nBerikut ini, kita akan membuat program dengan cara pertama.\n\ndef KompositUmum(FungsiNC, fungsi_x, A, B, N):\n    # awalnya belum ada luas yang dihitung, masih nol\n    hasil_akhir = 0\n\n    # panjang tiap subinterval besar\n    H = (B-A)/N\n\n    # titik ujung atau batasan dari subinterval besar pertama [a_1, b_1]:\n    a_i = A\n    b_i = A+H\n    # nama variabel a_i, b_i karena akan diubah-ubah\n\n    # lakukan metode Newton-Cotes yang diberikan untuk tiap subinterval besar\n    for i in range(N):\n        hasil_subinterval = FungsiNC(fungsi_x, a_i, b_i)\n        hasil_akhir += hasil_subinterval\n\n        # lanjut ke subinterval besar berikutnya\n        a_i = b_i # karena a_i = b_{i-1}\n        b_i += H\n    \n    return hasil_akhir\n\nKemudian, kita bisa menggunakan fungsi tersebut dengan sembarang fungsi metode Newton-Cotes. Sebagai contoh, berikut metode Simpson komposit:\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Integrasi Numerik Komposit Simpson dengan rumus umum\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah: \"))\nupper_bound = eval(input(\"Masukkan batas atas: \"))\npartisi_besar = eval(input(\"Masukkan jumlah subinterval besar (N): \"))\nprint()\n\n# bisa diganti dengan fungsi closed/open Newton-Cotes yang manapun\nFungsiNC = SimpsonsRule\n# (harus sudah terdefinisi dulu)\n\nhasil = KompositUmum(FungsiNC, func, lower_bound, upper_bound, partisi_besar)\nprint(\"Hasil integrasi numerik:\")\nprint(hasil)\n\nIntegrasi Numerik Komposit Simpson dengan rumus umum\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = x * log(x)\nMasukkan batas bawah: 1\nMasukkan batas atas: 2\nMasukkan jumlah subinterval besar (N): 2\n\nHasil integrasi numerik:\n0.6363098297969493\n\n\n\n\n(Pengayaan) Rumus khusus\nUntuk cara kedua, di buku Burden, sudah dilakukan penjabaran sehingga diperoleh rumus khusus untuk beberapa metode Newton-Cotes komposit, yaitu: * Metode Simpson Komposit (composite Simpson’s rule) * Metode Trapezoidal Komposit (composite trapezoidal rule) * Metode Midpoint Komposit (composite midpoint rule)\nMasing-masing rumus khusus langsung melihat semua \\(n\\) subinterval kecil yang terbentuk oleh \\((n+1)\\) titik yang digunakan. Namun, dibandingkan dengan cara yang sebelumnya (rumus umum), hasil akhirnya akan sama persis. Berikut rumus khususnya, untuk integral tentu \\(\\int_{a}^{b} f\\left(x\\right) dx\\) yang kemudian dibagi menjadi \\(n\\) subinterval kecil, di mana tiap subinterval kecil memiliki panjang \\(h\\) sesuai ketentuan metodenya.\n\nMetode Simpson Komposit\n\n\\[\\int_{a}^{b} f\\left(x\\right) dx \\approx \\frac{h}{3} \\left[ f(a) + 2\\sum_{j=1}^{(n/2)-1} f(x_{2j}) + 4\\sum_{j=1}^{n/2} f(x_{2j-1}) + f(b) \\right]\\]\ndi mana \\(n\\) harus genap, \\(h = (b-a)/n\\), dan \\(x_j = a + jh\\) untuk \\(j = 0, 1, \\dots, n\\).\n\nMetode Trapezoidal Komposit\n\n\\[\\int_{a}^{b} f\\left(x\\right) dx \\approx \\frac{h}{2} \\left[ f(a) + 2\\sum_{j=1}^{n-1} f(x_j) + f(b) \\right]\\]\ndi mana \\(n\\) adalah bilangan bulat positif, \\(h = (b-a)/n\\), dan \\(x_j = a + jh\\) untuk \\(j = 0, 1, \\dots, n\\).\n\nMetode Midpoint Komposit\n\n\\[\\int_{a}^{b} f\\left(x\\right) dx \\approx 2h \\sum_{j=0}^{n/2} f\\left(x_{2j}\\right)\\]\ndi mana \\(n\\) harus genap, \\(h = (b-a)/(n+2)\\), dan \\(x_j = a + jh\\) untuk \\(j=0,1,\\dots,n\\).\nAdanya syarat \\(n\\) genap untuk metode Simpson komposit dan metode midpoint komposit disebabkan hubungan antara \\(n\\) dan \\(N\\) yang melibatkan perkalian 2 untuk kedua metode komposit tersebut (serta sumasi dilakukan hingga \\(n/2\\)). Sedangkan, untuk metode trapezoidal komposit, berlaku \\(n = N\\); yaitu, istilah “subinterval kecil” dan “subinterval besar” ternyata sama saja (khusus trapezoidal).\nSebelumnya, sudah ditampilkan gambar proses partisi untuk metode Simpson komposit, di mana terlihat perbedaan antara subinterval kecil (ada sebanyak \\(n\\)) dan subinterval besar (ada sebanyak \\(N\\)), serta terlihat \\(n=2N\\).\nBerikut gambar untuk metode trapezoidal komposit, di mana \\(n=N\\), atau tidak ada perbedaan antara subinterval kecil dan subinterval besar:\n\n\n\np6_1 integral croptime Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org) copy_page-0006.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.4, “Composite Numerical Integration”. Hlm. 207\nSedangkan, berikut di bawah ini adalah gambar untuk metode midpoint komposit, dengan \\(n=10\\) dan \\(N=6\\), di mana banyaknya subinterval kecil terhitung dari titik \\(x_0\\) sampai \\(x_n\\), sedangkan banyaknya subinterval besar terhitung dari \\(a=x_{-1}\\) sampai \\(b=x_{n+1}\\). Kali ini, berlaku \\(n=2N-2\\).\nPerhatikan bahwa metode midpoint termasuk open Newton-Cotes, tidak seperti metode trapezoidal dan metode Simpson yang termasuk closed Newton-Cotes. Sehingga, untuk metode midpoint komposit, titik-titik pada ujung interval, yaitu titik \\(a=x_{-1}\\) dan \\(b=x_{n+1}\\), itu sama sekali tidak terlibat dalam perhitungan; berkurangnya dua titik itu menyebabkan yang tadinya \\(n=2N\\) (gambarnya sama dengan Simpson komposit) itu menjadi \\(n=2N-2\\).\n\n\n\np6_2 integral croptime Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org) copy_page-0006 copy.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.4, “Composite Numerical Integration”. Hlm. 207\nProses pemrograman untuk rumus-rumus tersebut melibatkan proses iterasi untuk menghitung sumasi/penjumlahan yang ada pada rumusnya.\n\ndef CompSimpson(f,a,b,n):\n    if n%2 == 1: # jika n ganjil\n        return \"banyaknya subinterval kecil harus genap\"\n    elif n%2 == 0: # jika n genap (sudah benar)\n        # panjang tiap subinterval kecil\n        h = (b-a)/n\n        \n        # list semua titik x\n        X = []\n        # ada n subinterval kecil, maka ada (n+1) titik, x0 = a\n        for i in range(n+1): # untuk i = 0, 1, 2, ..., n\n            # titik dengan indeks i, dari x_0 = a, x_1, x_2, sampai x_n = b\n            x_i = a + i*h\n\n            # tambahkan ke list x\n            X.append(x_i) \n        # sampai sini, list x sudah lengkap\n\n        # menghitung kedua sumasi:\n        sum1 = 0 # untuk sumasi f(x_{2j})\n        sum2 = 0 # untuk sumasi f(x_{2j-1})\n        for j in range (1, int(n/2)): # untuk j = 1, 2, ..., (n/2)-1\n            sum1 += f(X[2*j])\n            sum2 += f(X[2*j-1])\n        \n        # sumasi yang kedua ternyata sampai j=(n/2),\n        # sehingga kita tambahkan sekali lagi\n        j = int(n/2)\n        sum2 += f(X[2*j-1])\n\n        # gunakan rumus\n        hasil = (h/3) * ( f(a) + 2*sum1 + 4*sum2 + f(b) )\n        return hasil\n\ndef CompTrapezoidal(f,a,b,n):\n    # panjang tiap subinterval kecil\n    h = (b-a)/n\n\n    # list semua titik x\n    X = []\n    # ada n subinterval kecil, maka ada (n+1) titik, x0 = a\n    for i in range(n+1): # untuk i = 0, 1, 2, ..., n\n        # titik dengan indeks i, dari x_0 = a, x_1, x_2, sampai x_n = b\n        x_i = a + i*h\n\n        # tambahkan ke list x\n        X.append(x_i) \n    # sampai sini, list x sudah lengkap\n\n    # menghitung sumasi\n    sumasi = 0\n    for j in range(1,n): # untuk j = 1, 2, ..., n-1\n        sumasi += f(X[j])\n    \n    # gunakan rumus\n    hasil = (h/2) * ( f(a) + 2*sumasi + f(b) )\n    return hasil\n\ndef CompMidpoint(f,a,b,n):\n    if n%2==1: # jika n ganjil\n        return \"banyaknya subinterval kecil harus genap\"\n    elif n%2==0: # jika n genap (sudah benar)\n        # panjang tiap subinterval kecil\n        h = (b-a)/(n+2)\n        # (dibagi n+2 karena metode Midpoint termasuk OPEN Newton-Cotes)\n\n        # list semua titik x\n        X = []\n        # ada n subinterval kecil, maka ada (n+1) titik, x0 = a + h\n        # (x0 = a + h karena OPEN Newton-Cotes)\n        for i in range(n+1): # untuk i = 0, 1, 2, ..., n\n            # titik dengan indeks i, dari x_0 = (a+h), x_1, x_2, sampai x_n\n            x_i = (a+h) + i*h\n            # supaya, jika i=0, maka x_i = x_0 = a+h\n\n            # tambahkan ke list x\n            X.append(x_i) \n        # sampai sini, list x sudah lengkap\n\n        # menghitung sumasi\n        sumasi = 0\n        for j in range (0, int(n/2)+1): # untuk j = 0, 1, 2, ..., n/2\n            sumasi += f(X[2*j])\n        \n        # gunakan rumus\n        hasil = 2 * h * sumasi\n        return hasil\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Integrasi Numerik Komposit dengan rumus khusus\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah: \"))\nupper_bound = eval(input(\"Masukkan batas atas: \"))\npartisi = eval(input(\"Masukkan jumlah partisi / subinterval kecil (n): \"))\nprint()\n\nsimpson_komposit = CompSimpson(func, lower_bound, upper_bound, partisi)\ntrapezoidal_komposit = CompTrapezoidal(func, lower_bound, upper_bound, partisi)\nmidpoint_komposit = CompMidpoint(func, lower_bound, upper_bound, partisi)\n\nprint(\"Hasil integrasi numerik komposit:\")\nprint(\"{0} (Metode Simpson Komposit)\".format(simpson_komposit))\nprint(\"{0} (Metode Trapezoidal Komposit)\".format(trapezoidal_komposit))\nprint(\"{0} (Metode Midpoint Komposit)\".format(midpoint_komposit))\n\nIntegrasi Numerik Komposit dengan rumus khusus\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = x * log(x)\nMasukkan batas bawah: 1\nMasukkan batas atas: 2\nMasukkan jumlah partisi / subinterval kecil (n): 4\n\nHasil integrasi numerik komposit:\n0.6363098297969492 (Metode Simpson Komposit)\n0.639900477687986 (Metode Trapezoidal Komposit)\n0.6330963650576533 (Metode Midpoint Komposit)\n\n\n\n\n(Pengayaan) membandingkan rumus umum dengan rumus khusus\nPerhitungan dengan rumus umum melibatkan banyaknya subinterval besar \\(N\\), sedangkan perhitungan dengan rumus khusus melibatkan banyaknya subinterval kecil \\(n\\). Hubungan di antara kedua nilai tersebut tergantung metode Newton-Cotes yang digunakan untuk metode komposit. Apabila kita memilih nilai \\(N\\) besar dan \\(n\\) kecil yang tepat, maka hasil rumus umum dan rumus khusus akan sama (atau hampir sama, karena masalah round-off error).\nMari kita coba untuk mengaproksimasi nilai dari integral tentu \\(\\int_{1}^{2} x \\ln(x) dx\\).\n\n# fungsi ln dari numpy bernama log\nfrom numpy import log\n\n# fungsi yang ingin diintegralkan\ndef func(x):\n    return x * log(x)\n\n\nlower_bound = 1\nupper_bound = 2\n\nUntuk metode trapezoidal komposit, berlaku \\(n=N\\). Jika \\(N=4\\), maka \\(n=4\\). Mari kita bandingkan:\n\n# Untuk trapezoidal komposit\nN = 4\nn = N\n\n\n# Rumus umum\nKompositUmum(TrapezoidalRule, func, lower_bound, upper_bound, N)\n\n0.6399004776879859\n\n\n\n# Rumus khusus\nCompTrapezoidal(func, lower_bound, upper_bound, n)\n\n0.639900477687986\n\n\nUntuk metode Simpson komposit, berlaku \\(n=2N\\). Jika \\(N=4\\), maka \\(n=8\\). Mari kita bandingkan:\n\n# Untuk Simpson komposit\nN = 4\nn = 2*N\n\n\n# Rumus umum\nKompositUmum(SimpsonsRule, func, lower_bound, upper_bound, N)\n\n0.6362953646399339\n\n\n\n# Rumus khusus\nCompSimpson(func, lower_bound, upper_bound, n)\n\n0.636295364639934\n\n\nUntuk metode midpoint komposit, berlaku \\(n=2N-2\\). Jika \\(N=4\\), maka \\(n=6\\). Mari kita bandingkan:\n\n# Untuk midpoint komposit\nN = 4\nn = 2*N - 2\n\n\n# Rumus umum\nKompositUmum(OpenNC_n0, func, lower_bound, upper_bound, N)\n\n0.634492808115908\n\n\n\n# Rumus khusus\nCompMidpoint(func, lower_bound, upper_bound, n)\n\n0.634492808115908"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul4.html#kuadratur-adaptif-adaptive-quadrature",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul4.html#kuadratur-adaptif-adaptive-quadrature",
    "title": "Modul 4: Integrasi Numerik",
    "section": "Kuadratur Adaptif (Adaptive Quadrature)",
    "text": "Kuadratur Adaptif (Adaptive Quadrature)\nUmumnya, metode komposit (dengan pemilihan subinterval yang sama panjang) sangatlah efektif, kecuali ketika bentuk fungsi sangat bervariasi sepanjang interval integrasi: terkadang “liar”, terkadang “tenang”.\nBeberapa contoh fungsi yang bentuknya sangat bervariasi adalah \\(f(x) = e^{-3x} \\sin 4x\\) pada interval \\([0,2]\\) dan \\(f(x) = \\frac{100}{x^2} \\sin \\left( \\frac{10}{x} \\right)\\) pada interval \\([1,3]\\).\nUntuk fungsi-fungsi seperti itu, alangkah baiknya apabila kita bisa memilih beberapa subinterval dengan panjang yang berbeda-beda, menyesuaikan dengan bentuk fungsi, agar hasil integrasi numerik menjadi lebih akurat.\nTernyata, kita bisa melakukan partisi (memecah interval integrasi menjadi sejumlah subinterval) secara rekursif, terus membuat partisi dan menghitung integral sampai hasil integrasi numerik cukup akurat, memenuhi suatu batas toleransi yang kita tetapkan. Metode ini disebut kuadratur adaptif (adaptive quadrature), karena seolah-olah program bisa beradaptasi untuk mempersempit subinterval ketika bentuk fungsi sangat “liar”, tetapi tidak perlu mempersempit subinterval ketika bentuk fungsi cukup “tenang”.\nPerhatikan bahwa metode kuadratur adaptif ini bersifat rekursif (terus membuat partisi secara rekursif selama batas toleransi belum terpenuhi), tidak seperti metode komposit yang telah dibahas sebelumnya di mana banyaknya partisi (dan panjang tiap subinterval) sudah ditentukan dari awal.\nKuadratur adaptif menghitung nilai integral menggunakan suatu metode yang bisa kita tentukan. Apabila digunakan metode Simpson untuk menghitung integral tersebut (seperti di buku), maka metodenya secara keseluruhan disebut metode Simpson adaptif (Adaptive Simpson’s method).\nMisalkan metode integral yang dipilih disebut \\(S(a,b)\\) untuk menghitung integral pada interval \\([a,b]\\). Jika diberikan toleransi sebesar \\(\\varepsilon\\) (epsilon) dan suatu “faktor/pengkali toleransi” pengkali_tol, langkah-langkah untuk kuadratur adaptif menggunakan metode \\(S\\) untuk menghitung \\(\\int_{a}^{b} f\\left(x\\right) dx\\) bisa dituliskan sebagai berikut:\n\nHitung titik tengah m = (a+b)/2\nHitung hasil_keseluruhan = S(a, b)\nHitung hasil_gabung = S(a, m) + S(m, b)\nApabila |hasil_gabung - hasil_keseluruhan| &gt; pengkali_tol * epsilon, toleransi belum terpenuhi, sehingga hasil kuadratur adaptif pada \\([a,b]\\) akan sama dengan hasil kuadratur adaptif pada \\([a,m]\\) ditambah hasil kuadratur adaptif pada \\([m,b]\\) (di sini dilakukan proses rekursif, yaitu memanggil fungsi kuadratur adaptif untuk interval \\([a,m]\\) dan memanggil fungsi kuadratur adaptif untuk interval \\([m,b]\\)). Inilah tahapan mempersempit interval.\nNamun, apabila toleransi sudah terpenuhi, maka hasil kuadratur adaptif adalah hasil_gabung. Ternyata, interval tidak perlu dipersempit lagi.\n\nPada langkah-langkah di atas, apabila toleransi belum terpenuhi untuk interval utama, bisa saja misalnya hasil kuadratur adaptif pada \\([a,m]\\) nantinya sudah memenuhi toleransi, tetapi hasil kuadratur adaptif pada \\([m,b]\\) belum memenuhi toleransi juga. Maka, interval \\([a,m]\\) tidak akan dipersempit, tetapi interval \\([m,b]\\) perlu dipersempit lagi, dan akan dilakukan proses rekursif lagi (memanggil fungsi kuadratur adaptif lagi) dengan interval yang lebih kecil. Inilah sifat “adaptif” yang dimiliki oleh metode kuadratur adaptif, yaitu bisa menyesuaikan: terkadang mempersempit interval, terkadang tidak dipersempit karena tidak perlu (sudah memenuhi toleransi).\nFaktor/pengkali toleransi yang umum digunakan adalah 15, terutama untuk metode Simpson adaptif. Namun, pengkali toleransi sebaiknya diperkecil apabila fungsi sangatlah liar, misalnya menjadi 10 saja, atau bahkan lebih kecil lagi. Kita akan menggunakan pengkali_tol = 10.\n\ndef KuadraturAdaptif(FungsiIntegrasi, f, a, b, tol, pengkali_tol=10):\n    # titik tengah\n    m = (a+b)/2\n\n    # nilai integrasi numerik pada [a,b]\n    hasil_keseluruhan = FungsiIntegrasi(f, a, b)\n\n    # menggabungkan hasil integrasi numerik pada [a,m] dengan hasil pada [m,b]\n    hasil_kiri = FungsiIntegrasi(f, a, m)\n    hasil_kanan = FungsiIntegrasi(f, m, b)\n    hasil_gabung = hasil_kiri + hasil_kanan\n\n    if abs(hasil_gabung - hasil_keseluruhan) &gt; pengkali_tol * tol:\n\n        # jika batas toleransi belum dipenuhi, maka partisi jadi dua subinterval\n        # lalu lakukan kuadratur adaptif untuk tiap subinterval\n\n        adaptif_kiri = KuadraturAdaptif(\n            FungsiIntegrasi, f, a, m, tol/2, pengkali_tol)\n        \n        adaptif_kanan = KuadraturAdaptif(\n            FungsiIntegrasi, f, m, b, tol/2, pengkali_tol)\n\n        # lalu jumlahkan hasil kuadratur adaptif kedua subinterval\n        # menjadi hasil akhir untuk interval utama\n        hasil_akhir = adaptif_kiri + adaptif_kanan\n    else:\n        # jika batas toleransi sudah terpenuhi, gunakan saja hasil gabung nya\n        # sebagai hasil akhir\n        hasil_akhir = hasil_gabung\n    \n    return hasil_akhir\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Simpson Adaptif: Kuadratur Adaptif dengan metode Simpson\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah: \"))\nupper_bound = eval(input(\"Masukkan batas atas: \"))\ntoleransi = eval(input(\"Masukkan toleransi (epsilon): \"))\npengkali_toleransi = eval(input(\"Masukkan pengkali toleransi: \"))\nprint()\n\n# bisa diganti dengan fungsi integrasi numerik yang manapun,\n# kebetulan di sini ingin menggunakan metode Simpson\nFungsiIntegrasi = SimpsonsRule\n# (harus sudah terdefinisi dulu)\n\nhasil = KuadraturAdaptif(\n    FungsiIntegrasi, func, lower_bound, upper_bound,\n    toleransi, pengkali_toleransi\n    )\n\nprint(\"Hasil Simpson Adaptif:\")\nprint(hasil)\n\nSimpson Adaptif: Kuadratur Adaptif dengan metode Simpson\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = (100/(x**2)) * sin(10/x)\nMasukkan batas bawah: 1\nMasukkan batas atas: 3\nMasukkan toleransi (epsilon): 10**-4\nMasukkan pengkali toleransi: 10\n\nHasil Simpson Adaptif:\n-1.426014810049443\n\n\n\n(Pengayaan) melihat semua titik yang digunakan\nKita bisa sedikit memodifikasi fungsi KuadraturAdaptif agar menyimpan semua nilai x yang dijadikan batasan subinterval, kemudian juga memberikan output berupa list nilai x tersebut.\n\ndef ModifikasiKuadraturAdaptif(FungsiIntegrasi, f, a, b, tol, pengkali_tol=10):\n    # titik tengah\n    m = (a+b)/2\n\n    # list semua titik yang digunakan sebagai batasan subinterval\n    list_x = [a, b]\n    # nanti akan ditambahkan\n\n    # nilai integrasi numerik pada [a,b]\n    hasil_keseluruhan = FungsiIntegrasi(f, a, b)\n\n    # menggabungkan hasil integrasi numerik pada [a,m] dengan hasil pada [m,b]\n    hasil_kiri = FungsiIntegrasi(f, a, m)\n    hasil_kanan = FungsiIntegrasi(f, m, b)\n    hasil_gabung = hasil_kiri + hasil_kanan\n\n    if abs(hasil_gabung - hasil_keseluruhan) &gt; pengkali_tol * tol:\n\n        # jika batas toleransi belum dipenuhi, maka partisi jadi dua subinterval\n        # lalu lakukan kuadratur adaptif untuk tiap subinterval\n\n        adaptif_kiri, list_kiri = ModifikasiKuadraturAdaptif(\n            FungsiIntegrasi, f, a, m, tol/2, pengkali_tol)\n        \n        adaptif_kanan, list_kanan = ModifikasiKuadraturAdaptif(\n            FungsiIntegrasi, f, m, b, tol/2, pengkali_tol)\n\n        # menambahkan semua titik yang digunakan ke list_x\n        for angka in list_kiri:\n            if not (angka in list_x): # kalau belum ada\n                list_x.append(angka)\n        for angka in list_kanan:\n            if not (angka in list_x):\n                list_x.append(angka)\n\n        # lalu jumlahkan hasil kuadratur adaptif kedua subinterval\n        # menjadi hasil akhir untuk interval utama\n        hasil_akhir = adaptif_kiri + adaptif_kanan\n    else:\n        # jika batas toleransi sudah terpenuhi, gunakan saja hasil gabung nya\n        # sebagai hasil akhir\n        hasil_akhir = hasil_gabung\n    \n    # sortir list_x secara ascending\n    list_x.sort()\n\n    return hasil_akhir, list_x\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Simpson Adaptif: Kuadratur Adaptif dengan metode Simpson\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah: \"))\nupper_bound = eval(input(\"Masukkan batas atas: \"))\ntoleransi = eval(input(\"Masukkan toleransi (epsilon): \"))\npengkali_toleransi = eval(input(\"Masukkan pengkali toleransi: \"))\nprint()\n\nhasil, list_x = ModifikasiKuadraturAdaptif(\n    SimpsonsRule, func, lower_bound, upper_bound,\n    toleransi, pengkali_toleransi\n    )\n\nprint(\"Hasil Simpson Adaptif:\")\nprint(hasil)\nprint()\n\nprint(\"List semua titik yang digunakan sebagai batasan subinterval:\")\nprint(list_x)\nprint(\"yaitu sebanyak {0} titik\".format(len(list_x)))\n\nSimpson Adaptif: Kuadratur Adaptif dengan metode Simpson\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = (100/(x**2)) * sin(10/x)\nMasukkan batas bawah: 1\nMasukkan batas atas: 3\nMasukkan toleransi (epsilon): 10**-4\nMasukkan pengkali toleransi: 10\n\nHasil Simpson Adaptif:\n-1.426014810049443\n\nList semua titik yang digunakan sebagai batasan subinterval:\n[1, 1.03125, 1.0625, 1.09375, 1.125, 1.15625, 1.1875, 1.25, 1.3125, 1.375, 1.4375, 1.5, 1.5625, 1.625, 1.6875, 1.75, 1.875, 2.0, 2.125, 2.25, 2.375, 2.5, 2.75, 3]\nyaitu sebanyak 24 titik\n\n\nAnda bisa mencoba menerapkan kuadratur adaptif (dengan program yang telah dimodifikasi) untuk menghitung integral dari \\(f(x) = \\frac{100}{x^2} \\sin \\left( \\frac{10}{x} \\right)\\) pada \\([1,3]\\) dengan toleransi \\(10^{-4}\\) dan pengkali toleransi sebesar 10, kemudian membandingkan titik-titik yang digunakan di situ dengan Figure 4.14 di buku (bisa dihitung, ada 24 titik):\n\n\n\nintegral realcrop p226 Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org)_page-0001 copy.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.6, “Adaptive Quadrature Methods”. Hlm. 226\n(Pada program yang dimodifikasi tersebut, tidak ada modifikasi pada metode kuadratur adaptif itu sendiri; modifikasi yang dilakukan hanyalah agar program juga mengeluarkan output berupa titik-titik yang digunakan sebagai batasan subinterval.)\n\n\n(Pengayaan) kode non-rekursif dari buku\nBerikut implementasi non-rekursif untuk kuadratur adaptif berdasarkan pseudocode di buku (Algorithm 4.3). Perlu dicatat bahwa, bahkan menurut buku (halaman 224, kalimat terakhir), “The method is easier to implement using a recursive programming language.” (karena pseudocode yang diberikan mengasumsikan bahwa bahasa pemrograman yang digunakan tidak bisa menjalankan fungsi rekursif.)\nDi sini, kuadratur adaptif yang harusnya dilakukan secara rekursif malah dipaksakan agar dilakukan secara “iteratif”. Variabel i menandakan sisa interval yang perlu ditelusuri. Bisa dibayangkan, [FA, FB] memiliki titik tengah FC, sehingga dipartisi menjadi [FA, FC] dan [FC, FB]. Kemudian, titik tengah dari [FA, FC] adalah FD, dan titik tengah dari [FC, FB] adalah FE. Sehingga, kedudukan tiap titik dari kiri ke kanan adalah (FA, FD, FC, FE, FB). (Sebenarnya, FA, FB, FC, FD, dan FE adalah nilai fungsi, bukan titik x nya.)\nEntah bagaimana caranya, pseudocode tersebut melakukan penyimpanan data secara strategis agar tidak lupa akan semua subinterval yang perlu dihitung integralnya secara numerik (sayangnya menggunakan terlalu banyak “array” yang di sini diimplementasikan sebagai dictionary, dan menggunakan terlalu banyak variabel seperti variabel v1, v2, …, v8 yang kegunaannya tidak jelas dari penamaan variabelnya). Setelah melakukan partisi dan menyimpan semua subinterval dari kanan ke kiri, perhitungan integrasi numerik dilakukan dari subinterval paling kiri sampai interval paling kanan, dan tiap hasil perhitungan integral langsung ditambahkan ke APP yaitu variabel yang menyimpan hasil aproksimasi untuk keseluruhan integral.\nMenariknya, permasalahan mengubah kode rekursif (seperti yang kita buat sebelumnya) menjadi kode “iteratif” (seperti yang ada di buku) tidak jarang ditemui, dan solusi yang paling sering digunakan adalah “implement your own stack”. Tumpukan atau stack adalah salah satu struktur data yang dipelajari di mata kuliah Struktur Data (sering disebut “DSA” atau data structures and algorithms di kurikulum internasional) yang kebetulan merupakan mata kuliah wajib untuk program studi S1 Matematika.\n\n# Algoritma 4.3 di buku halaman 224-225\ndef AdaptifBurden(a_konstan, b_konstan, TOL_konstan, N):\n    # === Step 1 ===\n    APP = 0\n    i = 1\n\n    TOL, a, b, h, FA, FC, FB, S, L = {}, {}, {}, {}, {}, {}, {}, {}, {}\n\n    TOL[i] = 10 * TOL_konstan\n    a[i] = a_konstan\n    h[i] = (b_konstan - a_konstan)/2\n    FA[i] = f(a_konstan)\n    FC[i] = f(a_konstan + h[i])\n    FB[i] = f(b_konstan)\n\n    S[i] = h[i] * ( FA[i] + 4 * FC[i] + FB[i] )/3\n    #   (Approximation from Simpson's\n    #   method for entire interval.)\n\n    L[i] = 1\n\n    # === Step 2 ===\n    # While i &gt; 0 do Steps 3-5.\n    while i &gt; 0:\n        # === Step 3 ===\n        FD = f( a[i] +     h[i]/2 )\n        FE = f( a[i] + 3 * h[i]/2 )\n\n        S1 = h[i] * ( FA[i] + 4 * FD + FC[i] )/6\n        #   (Approximations from Simpson's\n        #   method for halves of subintervals.)\n\n        S2 = h[i] * ( FC[i] + 4 * FE + FB[i] )/6\n\n        #   (Save data at this level.)\n        v1 = a[i]\n        v2 = FA[i]\n        v3 = FC[i]\n        v4 = FB[i]\n        v5 = h[i]\n        v6 = TOL[i]\n        v7 = S[i]\n        v8 = L[i]\n\n        # === Step 4 ===\n\n        i = i - 1\n        #   (Delete the level.)\n\n        # === Step 5 ===\n        if abs(S1 + S2 - v7) &lt; v6:\n            APP = APP + (S1 + S2)\n        elif (v8 &gt;= N):\n            return \"LEVEL EXCEEDED\"\n            # STOP.\n            #   (Procedure fails.)\n        else:\n            #   (Add one level.)\n            \n            #   (Data for right half subinterval.)\n            i = i + 1\n            a[i] = v1 + v5\n            FA[i] = v3\n            FC[i] = FE\n            FB[i] = v4\n            h[i] = (v5)/2\n            TOL[i] = (v6)/2\n            S[i] = S2\n            L[i] = v8 + 1\n\n            #   (Data for left half subinterval.)\n            i = i + 1\n            a[i] = v1\n            FA[i] = v2\n            FC[i] = FD\n            FB[i] = v3\n            h[i] = h[i-1]\n            TOL[i] = TOL[i-1]\n            S[i] = S1\n            L[i] = L[i-1]\n    \n    # === Step 6 ===\n    return APP\n    # STOP.\n    #   (APP approximates I to within TOL.)\n\n\n# Contoh fungsi\nfrom numpy import sin\ndef f(x):\n    hasil = (100/(x**2)) * sin(10/x)\n    return hasil\n\nprint(AdaptifBurden(1, 3, 10**-4, N=7))\n# sepertinya N terkecil agar tidak muncul \"LEVEL EXCEEDED\" adalah N=7\n\nprint(\n\"\"\"\nThe graph of the function f(x) = (100/x^2) sin(10/x) for x in [1,3] is shown in\nFigure 4.14. Using the Adaptive Quadrature Algorithm 4.3 with tolerance 10^-4\nto approximate \\int_{1}^{3} f(x) dx produces -1.426014, a result that is\naccurate to within 1.1 x 10^-5.\n\"\"\"\n)\n\n-1.4260148100494467\n\nThe graph of the function f(x) = (100/x^2) sin(10/x) for x in [1,3] is shown in\nFigure 4.14. Using the Adaptive Quadrature Algorithm 4.3 with tolerance 10^-4\nto approximate \\int_{1}^{3} f(x) dx produces -1.426014, a result that is\naccurate to within 1.1 x 10^-5."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul4.html#kuadratur-gauss-gaussian-quadrature-pada-interval--11",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul4.html#kuadratur-gauss-gaussian-quadrature-pada-interval--11",
    "title": "Modul 4: Integrasi Numerik",
    "section": "Kuadratur Gauss (Gaussian Quadrature), pada interval \\([-1,1]\\)",
    "text": "Kuadratur Gauss (Gaussian Quadrature), pada interval \\([-1,1]\\)\nMetode kuadratur Gauss (Gaussian Quadrature), atau lebih tepatnya disebut metode kuadratur Gauss-Legendre (Gauss-Legendre Quadrature), adalah suatu metode integrasi numerik yang melibatkan polinom Legendre monik ke-\\(n\\). Kita akan memerlukan akar-akar dari polinom Legendre ke-\\(n\\), untuk nilai \\(n\\) yang ditentukan. Mari kita bahas polinom Legendre terlebih dahulu. (Untuk ke depannya, kita akan menyebut metode ini “kuadratur Gauss” saja, meskipun nama yang lebih tepat adalah kuadratur Gauss-Legendre.)\nPolinom Legendre ke-\\(n\\), akan kita tulis \\(P_n (x)\\), adalah polinom (dengan nilai \\(n\\) tertentu yang berupa bilangan cacah, yaitu \\(n = 0, 1, 2, \\dots\\)) yang memenuhi beberapa sifat istimewa. Beberapa di antara sifat-sifat istimewa tersebut adalah:\n\nPolinom Legendre ke-\\(n\\) memiliki pangkat tertinggi \\(x^n\\).\nPolinom Legendre ke-\\(n\\) memiliki tepat \\(n\\) akar yang semuanya berupa bilangan riil, dan semua akar-akar tersebut terletak di antara \\(-1 \\le x \\le 1\\).\nAkar-akar polinom Legendre bersifat “simeteris”, yaitu, apabila misal \\(x\\) adalah salah satu akar untuk suatu polinom Legendre, maka \\(-x\\) juga merupakan akar dari polinom Legendre tersebut.\n\nMaksud istilah “akar” adalah nilai \\(x\\) yang membuat \\(P_n (x) = 0\\).\nUntuk kuadratur Gauss, kita akan memanfaatkan polinom Legendre yang monik. Polinom yang monik (monic polynomial) adalah polinom yang pangkat tertingginya dikali 1. Misalnya, \\(x^2 - 4\\) bersifat monik, tetapi kalau misalnya kita kalikan 3, kita dapatkan \\(3x^2 - 12\\), yang tidak lagi monik. Sehingga, kita bisa membuat \\(3x^2 - 12\\) menjadi monik dengan dibagi 3.\nArtinya, kalau kita mendapatkan polinom yang tidak monik, kita bisa menjadikannya monik, membaginya dengan apapun pengkali pangkat tertinggi.\nMenurut buku, polinom Legendre monik untuk beberapa nilai \\(n\\) pertama adalah:\n\\[P_0 (x) = 1, \\hspace{0.5cm} P_1 (x) = x, \\hspace{0.5cm} P_2 (x) = x^2 - \\frac{1}{3}\\]\n\\[P_3 (x) = x^3 - \\frac{3}{5} x, \\hspace{0.5cm} P_4 (x) = x^4 - \\frac{6}{7} x^2 + \\frac{3}{35}\\]\nDi metode numerik, tidak dibahas cara mendapatkan polinom Legendre, atau cara menentukan semua \\(n\\) akar dari polinom Legendre ke-\\(n\\) untuk sembarang \\(n\\) bilangan cacah. Biasanya, semua data yang diperlukan sudah tersedia di tabel.\nMari kita lanjut pembahasan kita. Kuadratur Gauss adalah metode aproksimasi integral pada interval \\([-1,1]\\), dengan bentuk aproksimasi sebagai berikut:\n\\[\\int_{-1}^{1} f\\left(x\\right) dx \\approx \\sum_{i=1}^{n} c_i f\\left(x_i\\right)\\]\ndi mana \\(x_1, x_2, \\dots, x_n\\) adalah akar-akar dari polinom Legendre monik ke-\\(n\\), dan koefisien \\(c_1, c_2, \\dots, c_n\\) dihitung sebagai berikut, untuk $i = 1, 2, , n $:\n\\[c_i = \\int_{-1}^{1} \\prod_{j=1 \\\\ j \\ne i}^{n} \\frac{x - x_j}{x_i - x_j} dx\\]\nBiasanya, untuk nilai \\(n\\) yang ditentukan, nilai \\(x_i\\) dan \\(c_i\\) untuk \\(i = 1, 2, \\dots, n\\) sudah dihitung sebelumnya dan tercatat dalam bentuk tabel, sehingga kita tidak perlu lagi pusing dengan polinom Legendre ataupun cara mendapatkan koefisien-koefisien tersebut.\nUntungnya, numpy sudah memiliki fitur untuk langsung memperoleh semua akar \\(x_n\\) untuk polinom Legendre monik ke-n serta semua koefisien \\(c_n\\) untuk kuadratur Gauss, untuk apapun bilangan bulat positif \\(n\\) yang kita berikan. Misalnya, untuk \\(n=4\\):\n\nimport numpy as np\n\n\nn = 4\narray_akar, array_koefisien = np.polynomial.legendre.leggauss(n)\nprint(array_akar)\nprint(array_koefisien)\n\n[-0.86113631 -0.33998104  0.33998104  0.86113631]\n[0.34785485 0.65214515 0.65214515 0.34785485]\n\n\nBandingkan dengan tabel:\n\n\n\nTable4_12_Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org).png\n\n\nSumber tabel: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.7, “Gaussian Quadrature”. Hlm. 232\nSehingga, keseluruhan kode Python untuk kuadratur Gauss pada interval \\([-1,1]\\) bisa kita tuliskan sesingkat ini:\n\nimport numpy as np\n\ndef KuadraturGauss_11(f, n):\n    hasil = 0\n\n    # array x_i dan c_i\n    array_x, array_c = np.polynomial.legendre.leggauss(n)\n\n    # sumasi c_i * f(x_i)\n    for i in range(n):\n        hasil += array_c[i] * f( array_x[i] )\n    \n    return hasil\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Kuadratur Gauss pada interval [-1,1]\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nn = eval(input(\"Masukkan bilangan bulat positif (n): \"))\nprint()\n\nhasil_integral = KuadraturGauss_11(func, n)\n\nprint(f\"Hasil kuadratur Gauss pada interval [-1,1] dengan n = {n} adalah:\")\nprint(hasil_integral)\n\nKuadratur Gauss pada interval [-1,1]\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = exp(x) * cos(x)\nMasukkan bilangan bulat positif (n): 3\n\nHasil kuadratur Gauss pada interval [-1,1] dengan n = 3 adalah:\n1.9333904692642978\n\n\n\n(Pengayaan) Memperoleh \\(x_i\\) dan \\(c_i\\) secara “manual”\nsympy bisa menghasilkan polinom Legendre ke-\\(n\\) untuk apapun bilangan cacah \\(n\\) yang kita inginkan, bahkan sympy juga bisa menentukan semua \\(n\\) akar tersebut.\nMari kita import dulu:\n\nimport sympy\nx = sympy.symbols(\"x\")\n\nContoh untuk n=0 dan n=1, menurut sympy:\n\nLegendre0 = sympy.legendre(0, x)\nsympy.pprint(Legendre0)\n\n1\n\n\n\nsympy.pprint(sympy.legendre(1, x))\n\nx\n\n\nSejauh ini, masih sesuai dengan buku, sudah monik. Bagaimana dengan n=4?\n\nLegendre4 = sympy.legendre(4, x)\nsympy.pprint(Legendre4)\n\n    4       2    \n35⋅x    15⋅x    3\n───── - ───── + ─\n  8       4     8\n\n\nTernyata, menurut sympy, polinom Legendre tidak harus monik. Untungnya, kita bisa meminta sympy untuk menjadikannya monik.\n\nMonicLegendre4 = sympy.monic(Legendre4)\nsympy.pprint(MonicLegendre4)\n\n        2     \n 4   6⋅x    3 \nx  - ──── + ──\n      7     35\n\n\nKemudian, kita bisa menggunakan sympy.nroots untuk mendapatkan list semua akar dari polinom Legendre.\n\nAkarLegendre4 = sympy.nroots(MonicLegendre4)\nprint(AkarLegendre4)\n\n[-0.861136311594053, -0.339981043584856, 0.339981043584856, 0.861136311594053]\n\n\nMari kita buat fungsi untuk mendapatkan list akar-akar dari polinom Legendre monik ke-\\(n\\).\n\nimport sympy\nx = sympy.symbols(\"x\")\n\ndef AkarLegendre(n):\n    # P_n (x) untuk n yang diberikan\n    PolinomLegendre = sympy.legendre(n, x)\n\n    if n &gt; 1: # tadi sudah kita coba, untuk n=0 dan n=1 ternyata sudah monik\n        # selain n=0 dan n=1, kita perlu pastikan dia monik\n        PolinomLegendre = sympy.monic(PolinomLegendre)\n    \n    # memperoleh list semua akar\n    if n == 0: # ingat, banyaknya akar adalah n. Kalau n=0 berarti tiada akar\n        list_akar = []\n    else:\n        list_akar_sympy = sympy.nroots(PolinomLegendre)\n        # bisa saja list tersebut berisi bilangan yang masih berbentuk sympy,\n        # mari kita jadikan angka biasa atau angka Python dulu\n        list_akar = []\n        for angka_sympy in list_akar_sympy:\n            angka_biasa = float(angka_sympy)\n            list_akar.append(angka_biasa)\n    \n    return list_akar\n\nBisa dicoba:\n\nAkarLegendre(4)\n\n[-0.8611363115940526,\n -0.33998104358485626,\n 0.33998104358485626,\n 0.8611363115940526]\n\n\nMumpung kita sudah bisa memperoleh list semua akar secara pemrograman, mari kita coba memperoleh list semua koefisien \\(c_i\\) secara pemrograman juga (menggunakan list akar \\(x_i\\) tersebut). Perhatikan bahwa perkalian pecahan di atas terlihat seperti pada interpolasi Lagrange. Sehingga, kode kita akan mirip dengan kode interpolasi Lagrange. Ternyata, seperti pada interpolasi Lagrange, hasil perkalian tersebut menghasilkan polinom, sehingga integralnya pasti bisa dihitung secara analitik.\nSelain turunan analitik, sympy juga bisa menghitung integral secara analitik. Misalnya, untuk integral tak tentu, \\(\\int 3x^2 dx\\), yaitu integral \\(3x^2\\) terhadap \\(x\\):\n\nhasil_tak_tentu = sympy.integrate(3 * x**2, x)\nsympy.pprint(hasil_tak_tentu)\n\n 3\nx \n\n\nsympy juga bisa menghitung nilai integral tentu, misalnya \\(\\int_{-2}^{5} 3x^2 dx\\):\n\nhasil_tentu = sympy.integrate(3 * x**2, (x, -2, 5) )\nprint(hasil_tentu)\n\n133\n\n\nNamun, kita hanya akan memanfaatkan fitur ini untuk menentukan koefisien \\(c_i\\) saja.\n\ndef KoefisienLegendre(list_akar):\n    list_c = []\n    n = len(list_akar) # n adalah banyaknya akar\n\n    for i in range(n): # banyaknya koefisien adalah n juga\n        # kita tentukan hasil kali pecahannya dulu (dengan x dari sympy)\n        L = 1 # kode sangat mirip dengan interpolasi Lagrange, fungsi L\n        for j in range(n): # perkalian dilakukan dari j=1 sampai j=n\n            if j != i: # perhatikan syarat j != i pada perkalian\n                L *= ( x - list_akar[j] ) / ( list_akar[i] - list_akar[j] )\n        # sampai sini, hasil kali pecahan sudah selesai, tinggal diintegralkan\n        # (perhatikan bahwa L yaitu hasil kali pecahan ini berupa polinom)\n\n        # kita perlu integral L, terhadap x, dari x = -1 sampai x = 1\n        hasil_integral = sympy.integrate(L, (x, -1, 1))\n        # sebenarnya bisa dilakukan pakai metode yang telah dibahas sebelumnya,\n        # itu kalau mau full numerik :) tapi ini analitik aja, masih polinom\n\n        # ubah dari bentuk sympy jadi bentuk angka\n        hasil_integral = float(hasil_integral)\n\n        # hasil integral tersebut adalah koefisien kita. Tambahkan ke list\n        list_c.append(hasil_integral)\n    \n    # sampai sini, list koefisien sudah jadi\n    return list_c\n\nKemudian, barulah kita bisa menyusun program untuk kuadratur Gauss pada interval \\([-1,1]\\):\n\ndef KuadraturGauss_11_manual(f, n):\n    hasil = 0\n\n    # list x_i dan c_i\n    list_x = AkarLegendre(n)\n    list_c = KoefisienLegendre(list_x)\n\n    # sumasi c_i * f(x_i)\n    for i in range(n):\n        hasil += list_c[i] * f( list_x[i] )\n    \n    return hasil\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Kuadratur Gauss pada interval [-1,1]\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nn = eval(input(\"Masukkan bilangan bulat positif (n): \"))\nprint()\n\nhasil_integral = KuadraturGauss_11_manual(func, n)\n\nprint(f\"Hasil kuadratur Gauss pada interval [-1,1] dengan n = {n} adalah:\")\nprint(hasil_integral)\n\nKuadratur Gauss pada interval [-1,1]\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = exp(x) * cos(x)\nMasukkan bilangan bulat positif (n): 3\n\nHasil kuadratur Gauss pada interval [-1,1] dengan n = 3 adalah:\n1.9333904692642974\n\n\nPerhatikan bahwa, menurut dokumentasi numpy (https://numpy.org/doc/stable/reference/generated/numpy.polynomial.legendre.leggauss.html),\n\nThe results have only been tested up to degree 100, higher degrees may be problematic.\n\nyaitu, untuk nilai \\(n &gt; 100\\), numpy belum tentu memberikan hasil yang benar. Kami berharap bahwa, cara yang lebih manual yang sudah dibuat sebelumnya, memberikan hasil yang dijamin akurat untuk apapun nilai n. (Sayangnya, cara manual jauh lebih lambat daripada cara numpy apabila digunakan nilai n yang sangat besar. Jadi, masing-masing cara ada kelebihan dan kekurangan yang bisa menjadi pertimbangan untuk Anda memilih ingin menggunakan yang mana.)\nApabila Anda penasaran lebih lanjut tentang kuadratur Gauss dan polinom Legendre, seperti cara membentuk sembarang polinom Legendre (dengan rumus rekursif), bahkan hingga cara memperoleh semua akar polinom Legendre menggunakan metode root-finding dengan beberapa tebakan awal yang sesuai, silakan belajar dari link berikut ini:\nhttps://rosettacode.org/wiki/Numerical_integration/Gauss-Legendre_Quadrature\nFun fact: himpunan semua polinom Legendre membentuk (basis untuk) suatu ruang fungsi, yaitu ruang vektor dengan vektor berupa fungsi, pada interval \\([-1,1]\\). Anggota himpunannya tak terhingga banyaknya, karena ada n=0,1,2,3, dan seterusnya. Definisi hasil kali dalam yang digunakan adalah integral perkalian dua fungsi pada interval \\([-1,1]\\). Semua polinom Legendre saling ortogonal, yaitu hasil kali dalam untuk sembarang dua polinom Legendre yang berbeda adalah nol. Sehingga, himpunan polinom Legendre adalah himpunan ortogonal. Salah satu cara membentuk polinom Legendre adalah dengan menerapkan proses Gram-Schmidt pada vektor 1, \\(x\\), \\(x^2\\), \\(x^3\\), dan seterusnya. Konsep ruang fungsi, fungsi ortogonal dan sebagainya, termasuk serba-serbi “polinom ortogonal” seperti polinom Legendre, dipelajari lebih lanjut di “analisis fungsional” (functional analysis), dan salah satu prasyaratnya pastinya adalah aljabar linier."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul4.html#kuadratur-gauss-untuk-sembarang-interval-gaussian-quadrature-on-arbitrary-intervals",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul4.html#kuadratur-gauss-untuk-sembarang-interval-gaussian-quadrature-on-arbitrary-intervals",
    "title": "Modul 4: Integrasi Numerik",
    "section": "Kuadratur Gauss untuk sembarang interval (Gaussian Quadrature on Arbitrary Intervals)",
    "text": "Kuadratur Gauss untuk sembarang interval (Gaussian Quadrature on Arbitrary Intervals)\nSembarang integral \\(\\int_{a}^{b} f\\left(x\\right) dx\\) bisa diubah menjadi integral pada \\([-1,1]\\), dengan nilai integral yang tetap sama:\n\\[\\int_{a}^{b} f\\left(x\\right) dx = \\int_{-1}^{1} f\\left( \\frac{(b-a)t + (b+a)}{2} \\right) \\frac{(b-a)}{2} dt\\]\nSehingga, dengan melakukan perubahan variabel tersebut, kuadratur Gauss sebenarnya bisa diterapkan pada sembarang interval \\([a,b]\\), yaitu diubah terlebih dahulu menjadi integral pada \\([-1,1]\\).\nUntuk pemrograman, jika perlu dihitung \\(\\int_{a}^{b} f\\left(x\\right) dx\\), mari kita definisikan fungsi baru \\(g(t)\\):\n\\[g(t) = f\\left( \\frac{(b-a)t + (b+a)}{2} \\right) \\frac{(b-a)}{2}\\]\nagar\n\\[\\int_{a}^{b} f\\left(x\\right) dx = \\int_{-1}^{1} f\\left( \\frac{(b-a)t + (b+a)}{2} \\right) \\frac{(b-a)}{2} dt = \\int_{-1}^{1} g\\left(t\\right) dt\\]\nsehingga kita tinggal menghitung \\(\\int_{-1}^{1} g\\left(t\\right) dt\\) menggunakan kuadratur Gauss.\n\ndef KuadraturGaussUmum(f, a, b, n):\n    # mendefinisikan fungsi g(t)\n    def g(t):\n        hasil_g = f( ( (b-a)*t + (b+a) )/2 ) * (b-a)/2\n        return hasil_g\n    \n    # tinggal melakukan kuadratur Gauss [-1,1] untuk fungsi g, itulah hasilnya\n    hasil_integral = KuadraturGauss_11(g, n)\n    return hasil_integral\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Kuadratur Gauss untuk sembarang interval\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah (a): \"))\nupper_bound = eval(input(\"Masukkan batas atas (b): \"))\nn = eval(input(\"Masukkan bilangan bulat positif (n): \"))\nprint()\n\nhasil_integral = KuadraturGaussUmum(func, lower_bound, upper_bound, n)\n\nprint(f\"Hasil kuadratur Gauss pada interval [{lower_bound},{upper_bound}] dengan n = {n} adalah:\")\nprint(hasil_integral)\n\nKuadratur Gauss untuk sembarang interval\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = x**6 - x**2 * sin(2*x)\nMasukkan batas bawah (a): 1\nMasukkan batas atas (b): 3\nMasukkan bilangan bulat positif (n): 2\n\nHasil kuadratur Gauss pada interval [1,3] dengan n = 2 adalah:\n306.8199344959197"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul2.html",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul2.html",
    "title": "Modul 2 Metode Numerik: Interpolasi",
    "section": "",
    "text": "Kembali ke Metode Numerik\nOutline"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul2.html#penjelasan-ide-dengan-contoh-indeks-mulai-dari-1",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul2.html#penjelasan-ide-dengan-contoh-indeks-mulai-dari-1",
    "title": "Modul 2 Metode Numerik: Interpolasi",
    "section": "Penjelasan ide dengan contoh (indeks mulai dari 1)",
    "text": "Penjelasan ide dengan contoh (indeks mulai dari 1)\nMisal diketahui empat titik yaitu \\((x_1, y_1)\\), \\((x_2, y_2)\\), \\((x_3, y_3)\\), dan \\((x_4, y_4)\\). Ide polinom interpolasi Lagrange adalah membuat fungsi \\(P(x)\\) sebagai berikut (yang diduga akan berupa polinom):\n\\[P(x) = y_1 L_{4,1} (x) + y_2 L_{4,2} (x) + y_3 L_{4,3} (x) + y_4 L_{4,4} (x)\\]\nLalu apa itu fungsi \\(L_{n,k} (x)\\)? Pada subscript (tulisan di sebelah bawah), bilangan pertama adalah \\(n\\) atau banyaknya titik, sedangkan bilangan kedua adalah \\(k\\) atau titik ke-\\(k\\). Fungsi \\(L_{n,k} (x)\\) ini memang bergantung \\(k\\), artinya tiap titik dipasangkan dengan suatu fungsi \\(L_{n,k} (x)\\) yang sesuai.\nFungsi \\(L_{4,k} (x)\\) tersebut diharapkan memiliki sifat sebagai berikut:\n\\[P(x_1) = \\color{blue}{y_1 * 1} + \\color{red}{y_2 * 0} + \\color{red}{y_3 * 0} + \\color{red}{y_4 * 0} = \\color{blue}{y_1}\\]\n\\[P(x_2) = \\color{red}{y_1 * 0} + \\color{blue}{y_2 * 1} + \\color{red}{y_3 * 0} + \\color{red}{y_4 * 0} = \\color{blue}{y_2}\\]\n\\[P(x_3) = \\color{red}{y_1 * 0} + \\color{red}{y_2 * 0} + \\color{blue}{y_3 * 1} + \\color{red}{y_4 * 0} = \\color{blue}{y_3}\\]\n\\[P(x_4) = \\color{red}{y_1 * 0} + \\color{red}{y_2 * 0} + \\color{red}{y_3 * 0} + \\color{blue}{y_4 * 1} = \\color{blue}{y_4}\\]\nArtinya, \\(L_{n,k} (x_k) = 1\\), sedangkan \\(L_{n,k} (x_i) = 0\\) untuk nilai \\(i\\) selain \\(k\\) (lebih tepatnya, bernilai nol ketika ada titik ke-\\(i\\) yaitu titik selain titik ke-\\(k\\)). Sebenarnya, kita tidak peduli apa nilai \\(L_{n,k} (x)\\) untuk apapun nilai \\(x\\) selain titik yang diketahui.\nMengingat sifat yang diharapkan, kita bisa merancang fungsi \\(L_{4,k} (x)\\) sebagai berikut untuk \\(k = 1, 2, 3, 4\\):\n\\[L_{4,1} (x) = \\frac{(x-x_2)(x-x_3)(x-x_4)}{(x_1-x_2)(x_1-x_3)(x_1-x_4)}\\]\n\\[L_{4,2} (x) = \\frac{(x-x_1)(x-x_3)(x-x_4)}{(x_2-x_1)(x_2-x_3)(x_2-x_4)}\\]\n\\[L_{4,3} (x) = \\frac{(x-x_1)(x-x_2)(x-x_4)}{(x_3-x_1)(x_3-x_2)(x_3-x_4)}\\]\n\\[L_{4,4} (x) = \\frac{(x-x_1)(x-x_2)(x-x_3)}{(x_4-x_1)(x_4-x_2)(x_4-x_3)}\\]\nPerhatikan: * bagian pembilang terdiri dari perkalian \\((x-x_i)\\) untuk semua \\(i\\) kecuali \\(i=k\\). Tujuannya, ketika \\(L_{4,k} (x)\\) itu disubstitusikan \\(x=x_i\\) untuk \\(i\\) selain \\(k\\), hasilnya menjadi \\(L_{4,k} (x_i) = 0\\), kecuali untuk \\(x=x_k\\) itu hasilnya tidak nol. * bagian penyebut/pembagi itu sebenarnya sama saja dengan pembilang, tapi disubstitusikan \\(x=x_k\\). Tujuannya, ketika \\(L_{4,k} (x)\\) disubstitusikan dengan \\(x=x_k\\), apapun hasil taknol dari pembilang itu dibagi dengan dirinya sendiri agar menjadi \\(L_{4,k} (x_k) = 1\\).\nDengan demikian, \\(P(x)\\) bisa terbentuk. Perhatikan bahwa \\(L_{n,k} (x)\\) berbentuk polinom, sehingga \\(P(x)\\) yang terbentuk juga akan berupa polinom. Sehingga, metode polinom interpolasi Lagrange berhasil menghasilkan polinom interpolasi. Ide ini berlaku umum untuk banyaknya titik \\(n\\) sebesar apapun.\nPerhatikan bahwa masing-masing fungsi \\(L_{4,k} (x)\\) bisa dituliskan sebagai berikut:\n\\[L_{4,1} (x) = \\frac{(x-x_2)}{(x_1-x_2)} * \\frac{(x-x_3)}{(x_1-x_3)} * \\frac{(x-x_4)}{(x_1-x_4)}\\]\n\\[L_{4,2} (x) = \\frac{(x-x_1)}{(x_2-x_1)} * \\frac{(x-x_3)}{(x_2-x_3)} * \\frac{(x-x_4)}{(x_2-x_4)}\\]\n\\[L_{4,3} (x) = \\frac{(x-x_1)}{(x_3-x_1)} * \\frac{(x-x_2)}{(x_3-x_2)} * \\frac{(x-x_4)}{(x_3-x_4)}\\]\n\\[L_{4,4} (x) = \\frac{(x-x_1)}{(x_4-x_1)} * \\frac{(x-x_2)}{(x_4-x_2)} * \\frac{(x-x_3)}{(x_4-x_3)}\\]\natau, di mana warna merah artinya tidak dituliskan,\n\\[\\text{Untuk } k=1, \\text{ } L_{4,1} (x) = \\color{red}{\\frac{(x-x_1)}{(x_1-x_1)} * } \\color{black}{\\frac{(x-x_2)}{(x_1-x_2)} * \\frac{(x-x_3)}{(x_1-x_3)} * \\frac{(x-x_4)}{(x_1-x_4)}}\\]\n\\[\\text{Untuk } k=2, \\text{ } L_{4,2} (x) = \\frac{(x-x_1)}{(x_2-x_1)} \\color{red}{* \\frac{(x-x_2)}{(x_2-x_2)}} \\color{black}{* \\frac{(x-x_3)}{(x_2-x_3)} * \\frac{(x-x_4)}{(x_2-x_4)}}\\]\n\\[\\text{Untuk } k=3, \\text{ } L_{4,3} (x) = \\frac{(x-x_1)}{(x_3-x_1)} * \\frac{(x-x_2)}{(x_3-x_2)} \\color{red}{* \\frac{(x-x_3)}{(x_3-x_3)}} \\color{black}{* \\frac{(x-x_4)}{(x_3-x_4)}}\\]\n\\[\\text{Untuk } k=4, \\text{ } L_{4,4} (x) = \\frac{(x-x_1)}{(x_4-x_1)} * \\frac{(x-x_2)}{(x_4-x_2)} * \\frac{(x-x_3)}{(x_4-x_3)} \\color{red}{* \\frac{(x-x_4)}{(x_4-x_4)}}\\]\nDengan demikian, pembentukan fungsi \\(L_{n,k} (x)\\) secara pemrograman bisa dilakukan dengan perkalian iteratif, seperti iterasi \\(i = 1, 2, 3, 4\\), tetapi dengan syarat \\(i \\ne k\\)."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul2.html#bentuk-umum-indeks-mulai-dari-0-dan-kode",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul2.html#bentuk-umum-indeks-mulai-dari-0-dan-kode",
    "title": "Modul 2 Metode Numerik: Interpolasi",
    "section": "Bentuk umum (indeks mulai dari 0) dan kode",
    "text": "Bentuk umum (indeks mulai dari 0) dan kode\nBila diberikan \\(n+1\\) titik \\(x_0, x_1, \\dots, x_n\\), dan \\(f\\) adalah fungsi yang nilainya pada titik-titik tersebut diberikan, maka polinom interpolasi Lagrange ke-n didefinisikan sebagai\n\\[P(x) = f(x_0) L_{n,0}(x_0) + f(x_1) L_{n,1}(x_1) + \\cdots f(x_n) L_{n,n}(x_n)\\]\ndi mana, untuk setiap \\(k = 0, 1, \\dots, n\\),\n\\[L_{n,k}(x) = \\prod_{\\substack{i=0 \\\\ i\\ne k}}^{n} \\frac{x - x_i}{x_k - x_i}\\]\ndi mana \\(\\Pi\\) atau pi besar melambangkan perkalian yang “berulang” atau “teriterasi”, layaknya \\(\\Sigma\\) (sigma besar) yang melambangkan penjumlahan yang “berulang” atau “teriterasi”. Perhatikan syarat \\(i\\ne k\\).\n\nimport sympy\nx = sympy.symbols('x')\n\n# jaga-jaga ada konstanta pi pada data titik-titik yang diberikan\nfrom numpy import pi\n\ndef LagrangePol(x, x_points, y_points):\n    pol = 0 # nilai awal polinom sebelum ditambahkan apa-apa\n    n = len(x_points) # n adalah banyak titik\n    for k in range(n): # membuat y*L_(n,k) untuk tiap k\n        L = 1 # nilai awal fungsi L\n        for i in range(n):\n            if i!=k: # syarat i != k\n                L *= ((x-x_points[i])/(x_points[k]-x_points[i])) # iterasi perkalian\n        pol += y_points[k]*L # menambahkan pasangan y*L ke polinom\n    return pol\n\n\ntitik_x = eval(input(\"Masukkan list nilai x : \"))\ntitik_y = eval(input(\"Masukkan list nilai fungsi di titik-titik tersebut : \"))\neval_x = eval(input(\"Masukkan nilai x yang akan diaproksimasi nilai fungsinya : \"))\n\ny_lagrange = LagrangePol(x, titik_x, titik_y)\n# bentuk masih berantakan, sehingga perlu disederhanakan:\ny_sederhana = sympy.simplify(y_lagrange)\n# perlu diubah menjadi function biasa agar bisa disubstitusikan nilai x:\ny_function = sympy.lambdify(x, y_sederhana)\n# akhirnya bisa substitusi:\nnilai_y = y_function(eval_x)\n\nprint(\"Polinom hasil interpolasi Lagrange:\")\nsympy.pprint(y_lagrange)\nprint(\"Disederhanakan:\")\nsympy.pprint(y_sederhana)\nprint(\"Aproksimasi nilai fungsi di x = {0} adalah y = {1:.5f}\".format(eval_x, nilai_y))\n\nMasukkan list nilai x : [1, 2, 3, 4]\nMasukkan list nilai fungsi di titik-titik tersebut : [1, 4, 9, 16]\nMasukkan nilai x yang akan diaproksimasi nilai fungsinya : 1.5\nPolinom hasil interpolasi Lagrange:\n⎛4   x⎞ ⎛3   x⎞             ⎛    x⎞                             ⎛x   1⎞       \n⎜─ - ─⎟⋅⎜─ - ─⎟⋅(2 - x) + 4⋅⎜2 - ─⎟⋅(3 - x)⋅(x - 1) + 9⋅(4 - x)⋅⎜─ - ─⎟⋅(x - 2\n⎝3   3⎠ ⎝2   2⎠             ⎝    2⎠                             ⎝2   2⎠       \n\n       ⎛x   1⎞ ⎛x    ⎞        \n) + 16⋅⎜─ - ─⎟⋅⎜─ - 1⎟⋅(x - 3)\n       ⎝3   3⎠ ⎝2    ⎠        \nDisederhanakan:\n 2\nx \nAproksimasi nilai fungsi di x = 1.5 adalah y = 2.25000"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul2.html#kode-versi-sederhana",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul2.html#kode-versi-sederhana",
    "title": "Modul 2 Metode Numerik: Interpolasi",
    "section": "Kode Versi Sederhana",
    "text": "Kode Versi Sederhana\nNDD memiliki bentuk sebagai berikut :\n\\[P_n (x) = f[x_0] + \\sum_{k=1}^{n} f[x_0, x_1, \\dots, x_k](x-x_0)(x-x_1)\\dots (x-x_k)\\]\ndi mana \\(f[x_k] = f(x_k)\\) dan\n\\[f[x_i, x_{i+1}, \\dots, x_{i+k}] = \\frac{f[x_{i+1}, x_{i+2}, \\dots, x_{i+k}]-f[x_i, x_{i+1}, \\dots, x_{i+k-1}]}{x_{i+k} - x_i}\\]\nPada rumusan di atas, \\(f[x_i x_{i+1}, \\dots, x_{i+k}]\\) disebut k-th divided difference relatif terhadap \\(x_i x_{i+1}, \\dots, x_{i+k}\\).\nDalam membentuk polinomial interpolasi dengan NDD, seringkali tabel divided difference dibuat untuk memudahkan. Tabel tersebut berbentuk seperti berikut.\n\n\n\ncrop table3_9 page 126 Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org) copy.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Bab 3, “Interpolation and Polynomial Approximation”. Subbab 3.3, “Divided Differences”. Hlm. 126\nAda dua cara pembentukan polinomial interpolasi dengan DD, yaitu cara Forward dan Backward.\n\nForward DD menggunakan baris paling atas dari setiap kolom pada tabel DD.\n\n\\[P_n (x) = f[x_0] + \\sum_{k=1}^{n} f[x_0, x_1, \\dots, x_k] (x-x_0) (x-x_1) \\dots (x-x_{k-1})\\]\n\nBackward DD menggunakan baris paling akhir dari setiap kolom pada tabel DD.\n\n\\[P_n (x) = f[x_n] + \\sum_{k=1}^{n} f[x_n, x_{n-1}, \\dots, x_{n-k}] (x-x_n) (x-x_{n-1}) \\dots (x - x_{n-k+1})\\]\nKode Python untuk menginterpolasi titik-titik data dengan menggunakan NDD adalah sebagai berikut.\n\nimport sympy\nx = sympy.symbols('x')\n\n# jaga-jaga ada konstanta pi pada data titik-titik yang diberikan\nfrom numpy import pi\n\ndef DDTableGenerator(x_points, y_points): #buat fungsi untuk membuat tabel DD\n    DDTable = [y_points] #kolom-kolom pada tabel. Kolom pertama berisi f\n    for column in range(1,len(y_points)):\n        DDcolumn = [] #isi dari setiap kolom\n        for row in range(len(DDTable[-1])-1): #mulai mengisi kolom tabel\n            DD = (DDTable[-1][row+1]-DDTable[-1][row])/(x_points[column+row]-x_points[row])\n            DDcolumn.append(DD)\n        DDTable.append(DDcolumn) #tambahkan kolom yang telah diisi ke tabel\n    return DDTable\n\ndef ForwardDD(x, x_points, y_points):\n    DDTable = DDTableGenerator(x_points,y_points)\n    pol = DDTable[0][0] #nilai dari polinom. Inisiasi : suku pertama po\n    mult_term = 1 #variabel untuk menyimpan nilai dari (x-x0)(x-x\n    for k in range(1,len(DDTable)):\n        mult_term*=(x-x_points[k-1]) #menghitung (x-x0)(x-x1)...(x-x(n-1))\n        pol+=DDTable[k][0]*mult_term #menghitung nilai interpolasi\n    return pol\n\ndef BackwardDD(x, x_points, y_points):\n    DDTable = DDTableGenerator(x_points,y_points)\n    pol = DDTable[0][-1] #nilai dari polinom. Inisiasi : suku pertama po\n    mult_term = 1 #variabel untuk menyimpan nilai dari (x-xn)(x-x\n    for k in range(1,len(DDTable)):\n        mult_term*=(x-x_points[-k]) #menghitung (x-xn)(x-x(n-1))...(x-x1)\n        pol+=DDTable[k][-1]*mult_term #menghitung nilai interpolasi\n    return pol\n\n\ntitik_x = eval(input('Masukkan list nilai x : '))\ntitik_y = eval(input('Masukkan list nilai fungsi di titik-titik tersebut : '))\neval_x = eval(input('Masukkan nilai x yang akan diaproksimasi nilai fungsinya : '))\n\nforw_pol = ForwardDD(x, titik_x,titik_y)\nback_pol = BackwardDD(x, titik_x,titik_y)\n\nforw_sederhana = sympy.simplify(forw_pol)\nback_sederhana = sympy.simplify(back_pol)\n\nforw_function = sympy.lambdify(x, forw_sederhana)\nback_function = sympy.lambdify(x, back_sederhana)\n\nnilai_forw = forw_function(eval_x)\nnilai_back = back_function(eval_x)\n\nprint(\"Polinom hasil foward DD:\")\nsympy.pprint(forw_pol)\nprint(\"disederhanakan:\")\nsympy.pprint(forw_sederhana)\nprint(\"Polinom hasil backward DD:\")\nsympy.pprint(back_pol)\nprint(\"disederhanakan:\")\nsympy.pprint(back_sederhana)\n\nprint(\"Aproksimasi nilai fungsi di x = {0} adalah : \".format(eval_x))\nprint(\"Forward DD : {0:.5f}\".format(nilai_forw))\nprint(\"Backward DD : {0:.5f}\".format(nilai_back))\n\nMasukkan list nilai x : [1, 2, 3, 4]\nMasukkan list nilai fungsi di titik-titik tersebut : [1, 4, 9, 16]\nMasukkan nilai x yang akan diaproksimasi nilai fungsinya : 1.5\nPolinom hasil foward DD:\n3.0⋅x + 1.0⋅(x - 2)⋅(x - 1) - 2.0\ndisederhanakan:\n     2\n1.0⋅x \nPolinom hasil backward DD:\n7.0⋅x + 1.0⋅(x - 4)⋅(x - 3) - 12.0\ndisederhanakan:\n     2\n1.0⋅x \nAproksimasi nilai fungsi di x = 1.5 adalah : \nForward DD : 2.25000\nBackward DD : 2.25000"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul2.html#kode-versi-tabel-bagus",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul2.html#kode-versi-tabel-bagus",
    "title": "Modul 2 Metode Numerik: Interpolasi",
    "section": "Kode Versi Tabel Bagus",
    "text": "Kode Versi Tabel Bagus\nKode versi sebelumnya lebih sederhana, namun sayangnya tidak bisa menampilkan tabel divided difference. Kode yang akan dijelaskan di bagian ini, walaupun lebih rumit, tetapi pada akhirnya lebih intuitif, karena nantinya proses pembuatan polinom Forward DD dan Backward DD akan langsung menggunakan data dari tabel yang sudah dibentuk. (Lagipula, enak kan kalo bisa liat tabelnya? Hehe)\nKita review kembali, metode interpolasi Newton Divided Difference (NDD) melibatkan pembuatan tabel besar seperti berikut:\n\n\n\ncrop table3_9 page 126 Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org) copy.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Bab 3, “Interpolation and Polynomial Approximation”. Subbab 3.3, “Divided Differences”. Hlm. 126\nData pada dua kolom pertama adalah data titik \\((x, y)\\) yang diketahui, sedangkan perhitungan data pada tiap kolom lainnya (first divided differences, second divided differences, dll.) itu bergantung pada kolom sebelumnya.\nPembuatan tabel Newton Divided Differences (NDD) melibatkan suatu fungsi \\(f\\) dengan kurung siku, dengan rumus sesuai tabel di atas. Istilah “divided differences” artinya “beda/selisih yang saling dibagi”, sesuai rumus \\(f\\) tersebut.\nKetika hanya terdiri dari satu input, \\(f[x_k] = f(x_k) = y_k\\), untuk suatu data titik \\((x_k, y_k)\\) yang diketahui.\nSecara umum, rumusnya adalah\n\\[f[x_i, x_{i+1}, \\dots, x_{i+k}] = \\frac{f[x_{i+1}, x_{i+2}, \\dots, x_{i+k}]-f[x_i, x_{i+1}, \\dots, x_{i+k-1}]}{x_{i+k} - x_i}\\]\nUntuk titik yang banyak, penulisan nama fungsi \\(f[\\dots]\\) bisa menjadi sangat panjang. Perhatikan bahwa isi inputnya selalu berurutan, misal dari \\(x_a\\) sampai \\(x_b\\). Kita bisa mendefinisikan suatu fungsi untuk mempersingkat penulisan tersebut, misal kita namakan F-rentang atau kita singkat FR:\n\\[\\text{FR}(a, b) = f[x_a, x_{a+1}, x_{a+2}, \\dots, x_{b-2}, x_{b-1}, x_b]\\]\nyaitu fungsi yang sebenarnya menerima input berupa rentang nilai \\(x_k\\) dari \\(x_a\\) (\\(k=a\\)) sampai \\(x_b\\) (\\(k=b\\)).\nMaka, rumus \\(f\\) di atas dapat disingkat menjadi\n\\[\\text{FR}(a, a+k) = \\frac{\\text{FR}(a+1, a+k) - \\text{FR}(a, a+k-1)}{x_{a+k}-x_a}\\]\nDengan memasang \\(b = a+k\\), diperoleh\n\\[\\text{FR}(a, b) = \\frac{\\text{FR}(a+1, b) - \\text{FR}(a, b-1)}{x_b-x_a}\\]\nMenariknya, pada tabel,\n\nnilai \\(\\text{FR}(a, b-1)\\) selalu terletak di sebelah kiri atas dari \\(\\text{FR}(a, b)\\)\nnilai \\(\\text{FR}(a+1, b)\\) selalu terletak di sebelah kiri bawah dari \\(\\text{FR}(a, b)\\)\n\nDengan demikian, bisa saja kita memrogram perhitungan NDD menggunakan tabel.\nSeolah-olah, rumusnya adalah “kiri bawah dikurang kiri atas, dibagi \\(x_b - x_a\\)”.\nSelain itu, untuk data sebanyak \\(n+1\\),\n\nada sebanyak \\(n\\) kolom divided difference.\ndengan banyak kotak kosong (seperti pada gambar di atas), tabel utama terdiri dari \\(2n+1\\) baris dan \\(n+1\\) kolom, termasuk kolom \\(f(x_i)\\) tetapi tidak termasuk kolom \\(x_i\\).\n\nDengan demikian, kita dapat menghitung banyaknya data (yang kita anggap sebanyak \\(n+1\\)), kemudian menghitung \\(n\\) (tinggal dikurang 1), lalu mulai membangun tabel berdasarkan sifat baris dan kolom tersebut.\nIstilah “tabel utama” yang kita gunakan di sini merujuk pada tabel divided difference dari kolom \\(f(x_k)\\) sampai kolom divided difference ke-n, tanpa adanya kolom \\(x_i\\) maupun \\(i\\). Untuk ke depannya, tabel divided difference yang lengkap (yang termasuk kolom \\(x_i\\) dan \\(i\\)) akan kita sebut “tabel besar”, dibedakan dengan tabel utama.\n\nfrom tabulate import tabulate\n\n# jaga-jaga ada konstanta pi pada data titik-titik yang diberikan\nfrom numpy import pi\n\n# menyusun tabel Newton Divided Differences (NDD)\ndef CreateDDTable(list_x, list_y):\n    # === Menyusun tabel utama === #\n    # mengandung kolom f(x_i) serta semua kolom divided difference\n\n    MainDDTable = []\n    banyak_data = len(list_x) # = n + 1\n    n = banyak_data - 1\n    \n    # mengisi tabel dengan string kosong\n    # ingat: 2n+1 baris, n+1 kolom\n    for i in range(2*n+1):\n        calon_baris = []\n        for j in range(n+1):\n            calon_baris.append(\"\")\n        MainDDTable.append(calon_baris)\n    \n    # mengisi kolom pertama dengan nilai y_i = f(x_i)\n    for i in range(0, 2*n+1, 2): # untuk tiap baris, lompat 2\n        MainDDTable[i][0] = list_y[int(i/2)]\n    \n    # iterasi mengisi tiap kolom divided difference\n    for j in range(1, n+1): # untuk tiap kolom divided difference\n        # nilai a dan b untuk DD yang paling atas pada kolom\n        a = 0\n        b = j # nilai b pertama adalah j, selalu sesuai kolom DD ke-j\n        for i in range(j, 2*n - j + 1, 2): # untuk tiap baris, lompat 2\n            # iterasi dimulai dari baris j,\n            # baris terakhir adalah baris dengan indeks 2*n - j.\n            # Alasannya: total baris sebanyak 2*n + 1 (indeks 2*n),\n            # dan secara umum, pada kolom DD ke-j, perhitungan DD terakhir\n            # adalah pada j baris sebelum baris terakhir pada tabel,\n            # sehingga baris terakhir tersebut ada pada indeks 2*n - j.\n            # Pada for loop, kita gunakan 2*n - j + 1\n            # agar baris terakhir menjadi 2*n - j (karena keanehan Python)\n\n            # kiri bawah dikurang kiri atas, dibagi (x_b - x_a)\n            MainDDTable[i][j] = (MainDDTable[i+1][j-1] - MainDDTable[i-1][j-1])/(list_x[b] - list_x[a])\n            # memperbarui nilai a dan b untuk iterasi selanjutnya\n            a += 1\n            b += 1\n    \n    # === Menyusun tabel besar === #\n\n    # duplikasi MainDDTable\n    BigDDTable = []\n    for row in MainDDTable:\n        calon_baris = []\n        for col in row:\n            calon_baris.append(col)\n        BigDDTable.append(calon_baris)\n\n    # tempel kolom nilai i dan x_i di sebelah kiri tabel\n    for i in range(2*n+1):\n        indeks_x = int(i/2)\n        if i % 2 == 0: # baris berindeks genap, seperti baris pertama (i=0)\n            BigDDTable[i].insert(0, list_x[indeks_x])\n            BigDDTable[i].insert(0, indeks_x)\n        else:\n            BigDDTable[i].insert(0, \"\")\n            BigDDTable[i].insert(0, \"\")\n    \n    # menyusun list semua header\n    semua_header = [\"i\", \"x_i\", \"f(x_i)\"]\n    for k in range(1, n+1):\n        semua_header.append(\"DD ke-\" + str(k))\n\n    olahan_BigDDTable = tabulate(BigDDTable, headers=semua_header,\n                                 tablefmt=\"orgtbl\")\n    \n    return MainDDTable, olahan_BigDDTable\n\n\ntitik_x = eval(input('Masukkan list nilai x : '))\ntitik_y = eval(input('Masukkan list nilai fungsi di titik-titik tersebut : '))\n\ntabel_utama, tabel_olahan = CreateDDTable(titik_x, titik_y)\n\nprint(\"Tabel Newton Divided Difference:\")\nprint(tabel_olahan)\n\nMasukkan list nilai x : [1.0, 1.3, 1.6, 1.9, 2.2]\nMasukkan list nilai fungsi di titik-titik tersebut : [0.7651977, 0.6200860, 0.4554022, 0.2818186, 0.1103623]\nTabel Newton Divided Difference:\n| i   | x_i   | f(x_i)    | DD ke-1             | DD ke-2              | DD ke-3             | DD ke-4               |\n|-----+-------+-----------+---------------------+----------------------+---------------------+-----------------------|\n| 0   | 1.0   | 0.7651977 |                     |                      |                     |                       |\n|     |       |           | -0.4837056666666664 |                      |                     |                       |\n| 1   | 1.3   | 0.620086  |                     | -0.10873388888888935 |                     |                       |\n|     |       |           | -0.548946           |                      | 0.06587839506172834 |                       |\n| 2   | 1.6   | 0.4554022 |                     | -0.04944333333333385 |                     | 0.0018251028806604353 |\n|     |       |           | -0.5786120000000003 |                      | 0.06806851851852086 |                       |\n| 3   | 1.9   | 0.2818186 |                     | 0.011818333333334928 |                     |                       |\n|     |       |           | -0.5715209999999994 |                      |                     |                       |\n| 4   | 2.2   | 0.1103623 |                     |                      |                     |                       |\n\n\nNantinya, dari tabel NDD yang sudah lengkap, ada dua jenis polinom interpolasi NDD yang dapat diperoleh, yaitu Newton Forward-Difference dan Newton Backward-Difference, tergantung nilai mana pada tabel yang digunakan. Misalkan ada data sebanyak \\(n+1\\) titik, yaitu \\(x_0, x_1, x_2, \\dots, x_{n-1}, x_n\\). Maka, akan ada sebanyak \\(n\\) kolom divided differences pada tabel.\n\nNewton Forward-Difference (juga disebut Forward DD) menggunakan baris paling atas dari setiap kolom pada tabel DD.\n\n\\[P_n (x) = f[x_0] + \\sum_{k=1}^{n} f[x_0, x_1, \\dots, x_k] \\left( \\prod_{j=0}^{k-1} (x-x_j) \\right)\\]\n\nNewton Backward-Difference (juga disebut Backward DD) menggunakan baris paling akhir dari setiap kolom pada tabel DD.\n\n\\[P_n (x) = f[x_n] + \\sum_{k=1}^{n} f[x_{n-k}, \\dots, x_{n-1}, x_n] \\left( \\prod_{j=n-k+1}^{n} (x-x_j) \\right)\\]\nCatatan: \\(f[x_n, x_{n-1}, \\dots, x_{n-k}] = f[x_{n-k}, \\dots, x_{n-1}, x_n]\\). Artinya, penulisan terbalik (seperti di beberapa sumber referensi Metode Numerik) sebenarnya tidak mempengaruhi perhitungan.\nMenyingkat penulisan dengan \\(\\text{FR}(a, b)\\), kita peroleh:\n\nForward DD\n\n\\[P_n (x) = f[x_0] + \\sum_{k=1}^{n} \\text{FR}(0, k) \\left( \\prod_{j=0}^{k-1} (x-x_j) \\right)\\]\natau, mengingat bahwa \\(\\text{FR}(0, 0) = f[x_0]\\), kemudian menjabarkan,\n[ \\[\\begin{align*}\nP_n (x) = \\text{FR}(0, 0) &+ \\text{FR}(0, 1) (x-x_0) \\\\\n&+ \\text{FR}(0, 2) (x-x_0)(x-x_1) \\\\\n&+ \\dots \\\\\n&+ \\text{FR}(0, n)\\prod_{j=0}^{n-1} (x-x_j)\n\\end{align*}\\] ]\n\nBackward DD\n\n\\[P_n (x) = f[x_n] + \\sum_{k=1}^{n} \\text{FR}(n-k, n) \\left( \\prod_{j=n-k+1}^{n} (x-x_j) \\right)\\]\natau, mengingat bahwa \\(\\text{FR}(n, n) = f[x_n]\\), kemudian menjabarkan,\n[ \\[\\begin{align*}\nP_n (x) = \\text{FR}(n, n) &+ \\text{FR}(n-1, n) (x-x_n) \\\\\n&+ \\text{FR}(n-2, n) (x-x_{n-1}) (x-x_n) \\\\\n&+ \\dots \\\\\n&+ \\text{FR}(0, n) \\prod_{j=1}^{n} (x-x_j)\n\\end{align*}\\] ]\n\n# jaga-jaga ada konstanta pi pada data titik-titik yang diberikan\nfrom numpy import pi\n\nfrom tabulate import tabulate\n\nimport sympy\nx = sympy.symbols('x')\n\ndef ForwardDD(tabel_utama, list_x):\n    banyak_data = len(tabel_utama[0])\n    pol = 0\n    for k in range(0, banyak_data): # tiap suku penjumlahan\n        suku = tabel_utama[k][k] # FR(0, k)\n        for j in range(0, k): # perkalian dari j=0 sampai j=k-1\n            suku *= (x - list_x[j])\n        pol += suku\n    return pol\n\ndef BackwardDD(tabel_utama, list_x):\n    banyak_data = len(tabel_utama[0])\n    n = banyak_data - 1\n    pol = 0\n    for k in range(banyak_data): # tiap suku penjumlahan\n        suku = tabel_utama[2*n-k][k] # FR(n-k, k)\n        for j in range(n-k+1, n+1): # perkalian dari j=n-k+1 sampai j=n\n            suku *= (x - list_x[j])\n        pol += suku\n    return pol\n\n# Kita asumsikan function/fungsi CreateDDTable sudah terdefinisi sebelumnya.\n# Kalau belum terdefinisi, boleh copy-paste definisi fungsinya ke sini\n\n\ntitik_x = eval(input('Masukkan list nilai x : '))\ntitik_y = eval(input('Masukkan list nilai fungsi di titik-titik tersebut : '))\neval_x = eval(input('Masukkan nilai x yang akan diaproksimasi nilai fungsinya : '))\n\ntabel_utama, tabel_olahan = CreateDDTable(titik_x, titik_y)\n\nprint(\"Tabel Newton Divided Difference:\")\nprint(tabel_olahan)\nprint() # jaga jarak dengan print yang selanjutnya\n\nforw_pol = ForwardDD(tabel_utama, titik_x)\nback_pol = BackwardDD(tabel_utama, titik_x)\n\nforw_sederhana = sympy.simplify(forw_pol)\nback_sederhana = sympy.simplify(back_pol)\n\nforw_function = sympy.lambdify(x, forw_sederhana)\nback_function = sympy.lambdify(x, back_sederhana)\n\nnilai_forw = forw_function(eval_x)\nnilai_back = back_function(eval_x)\n\nprint(\"Polinom hasil foward DD:\")\nsympy.pprint(forw_pol)\nprint()\nprint(\"disederhanakan:\")\nsympy.pprint(forw_sederhana)\nprint()\n\nprint(\"Polinom hasil backward DD:\")\nsympy.pprint(back_pol)\nprint()\nprint(\"disederhanakan:\")\nsympy.pprint(back_sederhana)\nprint()\n\nprint(\"Aproksimasi nilai fungsi di x = {0} adalah : \".format(eval_x))\nprint(\"Forward DD : {0}\".format(nilai_forw))\nprint(\"Backward DD : {0}\".format(nilai_back))\n\nMasukkan list nilai x : [1.0, 1.3, 1.6, 1.9, 2.2]\nMasukkan list nilai fungsi di titik-titik tersebut : [0.7651977, 0.6200860, 0.4554022, 0.2818186, 0.1103623]\nMasukkan nilai x yang akan diaproksimasi nilai fungsinya : 1.5\nTabel Newton Divided Difference:\n| i   | x_i   | f(x_i)    | DD ke-1             | DD ke-2              | DD ke-3             | DD ke-4               |\n|-----+-------+-----------+---------------------+----------------------+---------------------+-----------------------|\n| 0   | 1.0   | 0.7651977 |                     |                      |                     |                       |\n|     |       |           | -0.4837056666666664 |                      |                     |                       |\n| 1   | 1.3   | 0.620086  |                     | -0.10873388888888935 |                     |                       |\n|     |       |           | -0.548946           |                      | 0.06587839506172834 |                       |\n| 2   | 1.6   | 0.4554022 |                     | -0.04944333333333385 |                     | 0.0018251028806604353 |\n|     |       |           | -0.5786120000000003 |                      | 0.06806851851852086 |                       |\n| 3   | 1.9   | 0.2818186 |                     | 0.011818333333334928 |                     |                       |\n|     |       |           | -0.5715209999999994 |                      |                     |                       |\n| 4   | 2.2   | 0.1103623 |                     |                      |                     |                       |\n\nPolinom hasil foward DD:\n-0.483705666666666⋅x + (0.108733888888889 - 0.108733888888889⋅x)⋅(x - 1.3) + (\n0.00182510288066044⋅x - 0.00182510288066044)⋅(x - 1.9)⋅(x - 1.6)⋅(x - 1.3) + (\n0.0658783950617283⋅x - 0.0658783950617283)⋅(x - 1.6)⋅(x - 1.3) + 1.24890336666\n667\n\ndisederhanakan:\n                     4                       3                      2         \n0.00182510288066044⋅x  + 0.0552927983538978⋅x  - 0.343046604938247⋅x  + 0.0733\n\n                                  \n913477366034⋅x + 0.977735055967085\n\nPolinom hasil backward DD:\n-0.571520999999999⋅x + (0.00182510288066044⋅x - 0.00237263374485857)⋅(x - 2.2)\n⋅(x - 1.9)⋅(x - 1.6) + (0.0118183333333349⋅x - 0.0224548333333364)⋅(x - 2.2) +\n (0.0680685185185209⋅x - 0.108909629629633)⋅(x - 2.2)⋅(x - 1.9) + 1.3677085\n\ndisederhanakan:\n                     4                       3                      2         \n0.00182510288066044⋅x  + 0.0552927983538978⋅x  - 0.343046604938247⋅x  + 0.0733\n\n                                  \n913477366035⋅x + 0.977735055967086\n\nAproksimasi nilai fungsi di x = 1.5 adalah : \nForward DD : 0.5118199942386829\nBackward DD : 0.511819994238684"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul0.html",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul0.html",
    "title": "Modul 0 Metode Numerik: Review Python, NumPy, Matplotlib",
    "section": "",
    "text": "Kembali ke Metode Numerik\nCatatan: Modul 0 ini adalah modul pengantar/review yang tidak dibahas ketika sesi praktikum.\nBerikut topik-topik yang akan dibahas pada Modul 0 ini:"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul0.html#review-python",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul0.html#review-python",
    "title": "Modul 0 Metode Numerik: Review Python, NumPy, Matplotlib",
    "section": "Review Python",
    "text": "Review Python\n\nOperasi, Variabel, dan Comment\nDi Python, kita bisa melakukan beberapa operasi aritmetika, menggunakan simbol sebagai berikut:\n(+) untuk penjumlahan\n(-) untuk pengurangan\n(*) untuk perkalian\n(/) untuk pembagian\n(**) untuk pangkat\n(%) untuk operasi mod atau modulo (sisa pembagian)\n(//) untuk operasi div (hasil bagi tanpa sisa)\n\nprint(5 + 2)\nprint(5 - 2)\nprint(5 * 2)\nprint(5 / 2)\nprint(5 ** 2)\nprint(5 % 2)\nprint(5 // 2)\n\n7\n3\n10\n2.5\n25\n1\n2\n\n\nSeandainya kita tidak menggunakan print untuk menampilkan hasil perhitungan,\n\n5 + 2\n\n7\n\n\n\n5 - 2\n5 * 2\n\n10\n\n\nmaka hanya hasil dari baris terakhir yang akan ditampilkan. Oleh karena itu, sangat disarankan untuk SELALU menuliskan print, termasuk untuk baris terakhir, agar modifikasi program menjadi lebih mudah dan cepat, apalagi ketika ingin menambah baris baru.\nPerhatikan bahwa tanda % sudah dikhususkan untuk modulo, sehingga artinya BUKAN PERSEN, ya! Persen dalam Python bisa dituliskan sebagai pembagian dengan 100 (sesuai definisi persen), misalnya untuk 50% atau 21%:\n\nprint(50/100)\nprint(21/100)\n\n0.5\n0.21\n\n\nKita bisa menyimpan nilai (termasuk hasil perhitungan) ke suatu tempat penyimpanan yang disebut variabel. Tiap variabel memiliki nama tersendiri, yang kita definisikan sendiri. Proses penyimpanan nilai ke suatu variabel disebut proses assignment, yang memiliki syntax (cara penulisan) sebagai berikut:\ncontoh_variabel = 23\ndi mana 23 adalah contoh nilai yang ingin dipasang ke contoh variabel yang kita beri nama “contoh_variabel”. Untuk assignment, tanda = cukup ditulis sekali saja, ya!\nKemudian, kita bisa menggunakan print untuk menampilkan isi variabel tersebut.\n\ncontoh_variabel = 23\nprint(contoh_variabel)\n\n23\n\n\nJangan sampai salah ketik, ya! Penggunaan huruf besar/kecil perlu diperhatikan, jangan sampai tertukar.\n\nprint(contoh_Variabel)\n\nNameError: name 'contoh_Variabel' is not defined\n\n\nKita mendapat error “name ‘contoh_Variabel’ is not defined”, artinya ‘contoh_Variabel’ itu tidak didefinisikan, karena Python menganggap itu berbeda dengan contoh_variabel yang memang sudah kita definisikan. Tentu kita tetap bisa mendefinisikannya:\n\ncontoh_variabel = 23\ncontoh_Variabel = 45\nprint(contoh_variabel)\nprint(contoh_Variabel)\n\n23\n45\n\n\nAda beberapa hal yang dilarang dalam penamaan variabel.\n\nNama variabel hanya boleh terdiri dari huruf, angka, dan tanda _\nNama variabel tidak boleh diawali angka\n\nContoh penamaan yang valid (boleh, bisa diterima):\n\nabc1 = 21\nxyz9000 = 3\n\nKarena valid, variabel berhasil tersimpan dengan baik, sehingga bisa dilihat isinya:\n\nprint(abc1)\nprint(xyz9000)\n\n21\n3\n\n\nContoh penamaan yang dilarang (akan menghasilkan error):\n\n999nama = 10\n\nSyntaxError: invalid decimal literal (678666226.py, line 1)\n\n\nSelain keterangan spesifik seperti “invalid decimal literal”, kita juga bisa mendapatkan keterangan error yang lebih umum yaitu “invalid syntax” atau “syntax tidak valid”. Karena terjadi error, proses assignment tidak berhasil, sehingga kita tidak bisa melihat isinya karena variabel tersebut memang gagal didefinisikan:\n\nprint(999nama)\n\nSyntaxError: invalid decimal literal (4165728206.py, line 1)\n\n\nKita juga bisa menggunakan variabel, seperti mengoperasikan variabel untuk menghasilkan nilai baru:\n\nprint(abc1 * 10)\nprint(abc1 / xyz9000)\n\n210\n7.0\n\n\nBahkan, kita bisa memasang hasil operasi tersebut ke variabel lain:\n\nhasil_bagi = abc1 / xyz9000\nprint(hasil_bagi)\n\n7.0\n\n\nPerhatikan potongan kode berikut.\n\na = 6\nb = 3\nprint(a / b)\na, b = b, a\nprint(a / b)\n\n2.0\n0.5\n\n\nPada baris 4, kita menukar nilai pada variabel a dan b. Python bisa meng-assign lebih dari 1 variabel dalam 1 baris, cukup dengan memisahkan tiap variabel dan nilai dengan , (tanda koma).\n\nx, y, z = 0, 1, 2\nprint(x)\nprint(y)\nprint(z)\n\n0\n1\n2\n\n\nWalaupun cara tersebut berlaku untuk sebanyak-banyaknya variabel, pada umumnya lebih baik melakukan assignment satu variabel per baris saja agar kode tetap mudah dibaca, apalagi fitur tersebut hanya ada di bahasa pemrograman Python.\nPenukaran variabel tetap bisa dilakukan sesuai cara yang dipelajari di mata kuliah Algortma dan Pemrograman, yaitu dengan bantuan variabel yang bisa dinamakan temp atau semacamnya (variabel dummy yang “tidak penting” dan hanya digunakan untuk bantuan sementara saja):\n\nc = 10\nd = 5\nprint(c/d)\ntemp = d\nd = c\nc = temp\nprint(c/d)\n\n2.0\n0.5\n\n\natau sama saja,\n\nc = 10\nd = 5\nprint(c/d)\ntemp = c\nc = d\nd = temp\nprint(c/d)\n\n2.0\n0.5\n\n\nTerkadang, program yang kita buat bisa menjadi rumit, sehingga kita perlu menambahkan semacam penjelasan atau catatan supaya orang lain bisa lebih memahami kode kita. Di Python, kita bisa menambahkan comment atau semacam catatan di samping kanan tiap baris (atau pada baris tersendiri), dimulai dengan tanda #\n\nprint(\"Selamat pagi\") # buat apa? gapapa iseng aja\n# print(\"Selamat siang\")\nprint(\"Selamat sore\") # wah dari pagi langsung sore\n\nSelamat pagi\nSelamat sore\n\n\nPython tidak memperhatikan comment sama sekali. Adanya fitur comment hanyalah untuk membantu kita sebagai programmer.\n\n\nString dan Formatting\nDi Python, selain tipe data numerik/angka, ada juga yang dinamakan “string”, yaitu kumpulan huruf/karakter/kata, yang bisa diawali dan diakhiri dengan tanda petik ’ atau tanda kutip ”\n\nmata_kuliah = \"Metode Numerik\"\ndepartemen = 'matematika'\ngelar = 'S1'\nprint(mata_kuliah)\nprint(departemen)\nprint(gelar)\n\nMetode Numerik\nmatematika\nS1\n\n\nPenggunaan tanda petik ataupun tanda kutip itu sama-sama valid, yang penting konsisten.\nSuatu string bisa dicek “panjang”nya, atau jumlah karakter di dalam string (termasuk spasi, koma, dan sebagainya), dengan len (artinya length):\n\npanjang1 = len(mata_kuliah)\npanjang2 = len(departemen)\npanjang3 = len(gelar)\nprint(panjang1)\nprint(panjang2)\nprint(panjang3)\n\n14\n10\n2\n\n\nString juga bisa digabung dengan semacam “penjumlahan” atau penggabungan (juga disebut string concatenation):\n\nnama_depan = \"Johan\"\nnama_tengah = \"Frederik\"\nnama_belakang = \"Steffensen\"\nprint(nama_depan + nama_belakang)\nprint(nama_depan + nama_tengah + nama_belakang)\n\nJohanSteffensen\nJohanFrederikSteffensen\n\n\nPerhatikan bahwa, pada ketiga string yang kita definisikan, tidak ada spasi, sehingga dalam penggabungannya itu juga tidak ada spasi.\nPenggabungan string tidak harus antar variabel, bisa juga antar nilai, atau bahkan antara variabel dengan nilai.\n\nprint(\"Halo! Nama saya \" + nama_depan)\n\nHalo! Nama saya Johan\n\n\nKita telah menggabungkan string “Halo! Nama saya” dengan variabel nama_depan (perhatikan bahwa string tersebut diakhiri satu spasi).\n\nprint(nama_belakang + \", \" + nama_depan + \" \" + nama_tengah)\n\nSteffensen, Johan Frederik\n\n\nDi sini, kita telah menggabungkan variabel nama_belakang dengan suatu string yang tediri dari dua karakter (yaitu koma dan spasi), yang kemudian digabungkan dengan variabel nama_depan, kemudian suatu string yang terdiri dari spasi saja, dan akhirnya dengan variabel nama_tengah.\nPenjumlahan yang dilakukan secara berulang kali adalah perkalian. Begitu juga untuk string:\n\nprint(3 * \"Belajar\")\nprint(\"Panik\" * 5)\n\nBelajarBelajarBelajar\nPanikPanikPanikPanikPanik\n\n\nKita juga bisa mengubah atau mengkonversi nilai selain string (seperti angka) agar menjadi string dan bisa digabungkan juga, menggunakan str. Contohnya,\n\nnilai_semester = 2\nstring_semester = str(nilai_semester)\nprint(\"Saya masih semester \" + string_semester)\n\nSaya masih semester 2\n\n\nSeandainya kita tidak mengkonversi nilai tersebut, akan terjadi error:\n\nnilai_semester = 2\nprint(\"Saya masih semester \" + nilai_semester)\n\nTypeError: can only concatenate str (not \"int\") to str\n\n\nPython hanya paham cara menggabungkan string dengan string, bukan string dengan selain string, sehingga kita harus mengkonversi nilai tersebut menjadi string terlebih dahulu.\nSebaliknya, kita juga bisa “menghilangkan tanda petik/kutip” dari suatu string (misalnya untuk mengkonversi kembali menjadi angka), dengan eval.\n\nangka_semester = eval(string_semester)\nsemester_atas = 2 + angka_semester\nstring_atas = str(semester_atas)\nprint(\"Dia sudah semester \" + string_atas)\n\nDia sudah semester 4\n\n\nSeandainya tidak digunakan eval,\n\nsemester_atas =  2 + string_semester\n\nTypeError: unsupported operand type(s) for +: 'int' and 'str'\n\n\nLagi-lagi, Python tidak paham penjumlahan antara bilangan dengan string.\nAda cara lain untuk memadukan nilai string dengan variabel yang berisi string, yaitu dengan yang namanya string formatting. Sejak Python 3.6, ada yang namanya f-strings, yang diawali dengan huruf “f” tepat sebelum penulisan string. Pada suatu f-string, kita bisa menggunakan kurung kurawal yaitu { dan } untuk menggantikan isi string dengan suatu variabel, yang nama variabelnya kita masukkan ke dalam kurung kurawal tersebut.\nMisalnya, kita bisa memasukkan nilai variabel mata_kuliah di dalam suatu f-string, seperti berikut:\n\nprint(f\"Saya sedang mengikuti praktikum {mata_kuliah}.\")\n\nSaya sedang mengikuti praktikum Metode Numerik.\n\n\nTentu, kita bisa menyisipkan lebih dari satu variabel.\n\nprint(f\"Saya sedang mengikuti praktikum {mata_kuliah} untuk mendapatkan gelar {gelar}.\")\n\nSaya sedang mengikuti praktikum Metode Numerik untuk mendapatkan gelar S1.\n\n\nSelain menggunakan f-string, kita juga bisa menggunakan .format() pada akhir string (fitur ini sudah ada sejak Python 3.0), dengan syntax sebagai berikut:\n\nprint(\"Saya sedang mengikuti praktikum {0} untuk mendapatkan gelar {1}\".format(mata_kuliah, gelar))\n\nSaya sedang mengikuti praktikum Metode Numerik untuk mendapatkan gelar S1\n\n\nAgar kode lebih mudah dibaca,\n\nkalimat = \"Saya sedang mengikuti praktikum {0} untuk mendapatkan gelar {1}\".format(mata_kuliah, gelar)\nprint(kalimat)\n\nSaya sedang mengikuti praktikum Metode Numerik untuk mendapatkan gelar S1\n\n\nPerhatikan bahwa, dengan cara .format(), kita harus mengisi tempat penyisipan dengan {0}, {1}, {2}, dan seterusnya tergantung banyaknya penyisipan, kemudian variabel-variabel yang ingin disisipkan itu baru ditempel di akhir, yaitu di dalam kurung .format().\nLagi-lagi, kedua cara sama-sama valid, yang penting konsisten. Ketika hendak menggunakan f-string, jangan tiba-tiba mengetik .format() pada akhir f-string.\nSebagai tambahan, kita bisa menyisipkan angka, dan kita juga bisa mempersingkat penulisannya menjadi beberapa angka di belakang koma, misalnya cukup 7 angka di belakang koma:\n\nakar_dua = 2**(1/2)\nprint(\"Akar dua bernilai kurang lebih {0:.7f}\".format(akar_dua))\nprint(\"atau lebih tepatnya {0}\".format(akar_dua))\n\nAkar dua bernilai kurang lebih 1.4142136\natau lebih tepatnya 1.4142135623730951\n\n\nBeberapa link (pengayaan, tidak wajib) untuk mempelajari string formatting lebih lanjut:\n\nhttps://www.w3schools.com/python/ref_string_format.asp\nhttps://realpython.com/python-string-formatting/\n\n\n\nInput nilai\nSelain mengeluarkan output atau menampilkan nilai, Python juga bisa menerima nilai (yang kemudian dipasangkan ke variabel), menggunakan input(pesan), di mana pesan yang ada di dalam kurung itu bisa berisi pertanyaan yang ingin ditanyakan, atau keterangan yang diminta:\n\nangkatan = input(\"Masukkan angkatan: \")\nprint(\"Anda angkatan \" + angkatan)\n\nMasukkan angkatan: 2022\nAnda angkatan 2022\n\n\nPerhatikan bahwa input telah masuk dalam bentuk string, sehingga bisa langsung digabungkan dengan string lainnya. Karena masih berbentuk string, operasi aritmetika tidak sesuai harapan:\n\nangka = input(\"Masukkan angka: \")\ndobel = angka / 2\nprint(\"Setelah dibagi dua, angka tersebut menjadi \" + str(dobel))\n\nMasukkan angka: 24\n\n\nTypeError: unsupported operand type(s) for /: 'str' and 'int'\n\n\nTerjadi error karena operasi pembagian tidak bisa dilakukan pada string. Oleh karena itu, kita juga perlu eval agar nilai yang masuk itu dihilangkan tanda petik/kutipnya agar tidak lagi berbentuk string.\n\nangka = eval(input(\"Masukkan angka: \"))\ndobel = angka / 2\nprint(\"Setelah dibagi dua, angka tersebut menjadi \" + str(dobel))\n\nMasukkan angka: 24\nSetelah dibagi dua, angka tersebut menjadi 12.0\n\n\nKombinasi eval(input(pesan)) akan sering digunakan selama praktikum Metode Numerik.\n\n\nList\nSuatu list bisa menyimpan beberapa nilai sekaligus, yang masing-masing disebut elemen dari list tersebut. Pendefinisiannya menggunakan kurung siku, di mana tiap elemen dituliskan di dalamnya, saling dipisahkan dengan koma:\n\nbuah = [\"apel\", \"pisang\", \"jeruk\"]\nprint(buah)\n\n['apel', 'pisang', 'jeruk']\n\n\nTiap elemen memiliki posisi atau indeks (index). Di Python, indeks dimulai dari 0 (nol). Kita bisa memeriksa elemen pada indeks ke-sekian di list, dengan menuliskan nama list tersebut, diikuti dengan kurung siku yang berisi indeks ke berapa yang ingin dilihat nilainya.\n\nprint(buah[0])\nprint(buah[1])\nprint(buah[2])\n\napel\npisang\njeruk\n\n\nSuatu list bisa berisi beragam tipe data, tidak hanya string tetapi juga angka, atau bahkan keduanya sekaligus.\n\ndata_diri = [\"Guido van Rossum\", 1956, \"Belanda\", \"Pembuat bahasa pemrograman Python\"]\nprint(\"Nama: \" + data_diri[0])\nprint(\"Tahun kelahiran: \" + str(data_diri[1]))\nprint(\"Kewarganegaraan: \" + data_diri[2])\nprint(\"Dikenal sebagai: \" + data_diri[3])\n\nNama: Guido van Rossum\nTahun kelahiran: 1956\nKewarganegaraan: Belanda\nDikenal sebagai: Pembuat bahasa pemrograman Python\n\n\nKita dapat menambahkan elemen baru pada akhir list menggunakan .append()\n\nprima = [2, 3, 5]\nprint(prima)\nprima.append(7)\nprint(prima)\n\n[2, 3, 5]\n[2, 3, 5, 7]\n\n\n\n\nPernyataan Kondisional\nSeringkali kita dihadapi oleh beberapa kondisi. Misalkan pada metode Bisection, kalian perlu mengecek apakah nilai fungsi di ujung-ujung intervalnya berbeda tanda atau tidak. Jika tidak, metode tidak bisa berjalan. Maka, kita perlu menggunakan pernyataan kondisional.\nTerdapat tiga pernyataan kondisional: * If…else berguna jika hanya ada satu kondisi yang perlu dicek, dan perlu ada aksi yang dijalankan jika kondisi tidak terpenuhi. * If…elif berguna jika ada lebih dari satu kondisi yang perlu dicek, dan tidak ada aksi yang dijalankan apabila semua kondisi tidak terpenuhi. * If…elif…else berguna jika ada lebih dari satu kondisi yang perlu dicek, dan perlu ada aksi yang dijalankan jika kondisi tidak terpenuhi.\nAdvanced note: Ada pernyataan kondisional lain, yaitu try…except, naum akan dijelaskan pada bagian selanjutnya\n\nx = eval(input('Masukkan bilangan: '))\nif x &lt; 0:\n    print('Haha')\nelif x &gt;= 0 and x &lt;= 4:\n    print('Hehe')\nelse:\n    print('Hoho')\n\nMasukkan bilangan: 2\nHehe\n\n\n\n\nLooping\nKebanyakan metode pada Metnum bersifat iteratif, artinya algoritmanya dijalankan berulang hingga tercapai batas tertentu (biasanya terdapat nilai toleransi antara aproksimasi dengan nilai eksaknya). Looping pada Python biasanya menggunakan for loop dan while loop.\nfor loop digunakan ketika kita mengetahui berapa kali kita harus mengulang perintah. Beberapa cara untuk for loop:\n\nfor i in range(a, b, n) : Loop ini akan membuat for loop berjalan mulai dari a hingga b - 1 dengan step sebesar n. Argumen n bersifat opsional dengan nilai default 1. Jika menggunakan range(b), maka bisa dianggap a = 0.\nfor i in list atau for i in string : Loop ini akan membuat for loop mengiterasikan tiap elemen list atau karakter string yang akan disimpan pada i. while loop digunakan ketika ada syarat tertentu yang harus dipenuhi untuk mengulang perintah tersebut.\nwhile cond : Loop ini akan membuat while loop berjalan selama cond bernilai True . Berhati-hatilah dalam menggunakan while loop. Pastikan kondisi yang dimasukkan akan bisa bernilai False . Jika tidak, maka kode akan stuck di infinite loop.\n\nAdvanced note: range() sejatinya adalah fungsi yang mengoutput list angka dengan aturan seperti di atas.\n\nprint('FOR LOOP EXAMPLE 1')\nfor i in range(3):\n    print('Print 3 kali')\nprint('FOR LOOP EXAMPLE 2')\nfor i in range(1, 4):\n    print(2 * i)\nprint('FOR LOOP EXAMPLE 3')\nfor i in range(1, 10, 3):\n    print('Angka sekarang:', i)\nprint('FOR LOOP EXAMPLE 4')\nfor i in [1, 4, 8, 2]:\n    print(i)\nprint('FOR LOOP EXAMPLE 5')\nfor i in 'mondstad':\n    if i == 'd':\n        print(i)\nprint('WHILE LOOP EXAMPLE')\ni = 0\nwhile i &lt;= 5:\n    print('Hati-hati while')\n    i += 1\nprint('While iteration DONE')\n\nFOR LOOP EXAMPLE 1\nPrint 3 kali\nPrint 3 kali\nPrint 3 kali\nFOR LOOP EXAMPLE 2\n2\n4\n6\nFOR LOOP EXAMPLE 3\nAngka sekarang: 1\nAngka sekarang: 4\nAngka sekarang: 7\nFOR LOOP EXAMPLE 4\n1\n4\n8\n2\nFOR LOOP EXAMPLE 5\nd\nd\nWHILE LOOP EXAMPLE\nHati-hati while\nHati-hati while\nHati-hati while\nHati-hati while\nHati-hati while\nHati-hati while\nWhile iteration DONE"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul0.html#error-handling",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul0.html#error-handling",
    "title": "Modul 0 Metode Numerik: Review Python, NumPy, Matplotlib",
    "section": "Error Handling",
    "text": "Error Handling\nMisalkan kalian membuat program tentang menghitung kebalikan dari suatu bilangan bulat. Tentu bilangan selain nol memiliki kebalikan. Namun, apa yang terjadi jika kalian memasukkan 0 sebagai input? Pasti error.\nError pada program mengakibatkan program terhenti di tengah-tengah, sehingga belum semua baris dieksekusi. Mungkin tidak berpengaruh banyak jika programnya digunakan untuk sendiri, namun seandainya kalian membuat program yang digunakan untuk mengatur server perusahaan, entah apa jadinya kalau programnya error.\nUntuk itu, terdapat cara untuk mengatasi error tersebut. Di Python, kalian dapat menggunakan try…except . Ini adalah penyataan kondisional serupa dengan if…else , namun pengecekan dilakukan pada bagian try . Jika pada bagian tersebut tidak ada masalah yang menyebabkab error, maka bagian except tidak dijalankan. Sebaliknya, jika error, maka bagian except akan dijalankan. Ada beberapa macam error di Python:\n\nZeroDivisionError : Error ini keluar jika terdapat pembagian dengan nol.\nValueError : Error ini keluar jika tipe data yang dimasukkan tidak bisa diproses karena tidak sesuai. dll. Silahkan cari di Google :)\n\nAdvanced note: Kalian dapat mengecek tipe data pada python dengan fungsi type() .\n\ntry:\n    x = int(input('Masukkan integer taknol: '))\n    print(1 / x)\nexcept:\n    print('Yhaa programnya error :(')\n\nMasukkan integer taknol: 0\nYhaa programnya error :("
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul0.html#numpy",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul0.html#numpy",
    "title": "Modul 0 Metode Numerik: Review Python, NumPy, Matplotlib",
    "section": "NumPy",
    "text": "NumPy\nNumPy adalah package Python yng sangat multifungsi. Kita akan menggunakan NumPy untuk membuat array yang elemennya hanya mempunyai satu tipe data. NumPy juga mempunyai fungsi fungsi seperti sin, cos, log, dll.\nMula-mula, kita perlu meng-import package NumPy.\n\nimport numpy as np\n\nJika pada langkah ini kalian menemukan error, kemungkinan besar kalian belum mempunyai package NumPy terinstal. Jika kalian menggunakan Jupyter Notebook atau Spyder melalui Anaconda, kalian bisa mencoba mengikuti langkah ini:\n\nBuka Anaconda Prompt\nKetik conda install numpy (Jika tidak berhasil gunakan pip install numpy )\nTunggu hingga proses mengunduh selesai.\n\nAlternatif yang lebih mudah adalah langsung mengetik pip install numpy (atau !pip install numpy dengan tanda seru) pada Jupyter Notebook (bisa juga pada Google Colaboratory), kemudian menutup dan membuka kembali Jupyter Notebook:\n\npip install numpy\n\nRequirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.24.2)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n!pip install numpy\n\nRequirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.24.2)\n\n\nNumpy Array\nSeperti yang sudah dikatakan sebelumnya, list bukan array karena dapat diisi dengan berbagai tipe data. Kalau begitu, bagaimana array yang benar? Di NumPy, ada fungsi bernama array yang berfungsi mengubah list menjadi array.\n\nA = np.array([True, 4, 7.5, 'Jean'])\nB = np.array([5, 6.2])\nC = np.array([4, 2, -1, -3])\ntype(A)\n\nnumpy.ndarray\n\n\nTerlihat tipe data dari A bukan list, melainkan numpy.ndarray. Perhatikan juga bahwa kita mengisi list yang akan dijadikan array A dan B dengan beragam tipe data…\n\nprint(A)\nprint(B)\nprint(C)\n\n['True' '4' '7.5' 'Jean']\n[5.  6.2]\n[ 4  2 -1 -3]\n\n\n…maka tipe datanya akan berubah menjadi sama. Karena NumPy array hanya bisa menyimpan satu tipe data, maka jika tipenya berbeda akan berubah. Urutan pengecekannya adalah string , float , integer , boolean (tipe data boolean menyimpan nilai 1 jika True dan 0 jika False ).\nKita juga dapat membuat array 2 dimensi seperti matriks, dan jika di-print, maka outputnya juga seperti matriks.\n\nP = np.array([[1, 2],[-1, 0]])\nQ = np.array([[4, -1],[5, 0]])\nR = np.array([[1, 2, 4, 5], [-1, -8, 9, 11], [3, -2, -4, 6]])\n\nDi sini kalian juga bisa melakukan indexing dan slicing seperti halnya pada liat.\n\nprint(A[0])\nprint(B[-1])\nprint(P[0])\nprint(Q[0,1])\nprint()\nprint(A[2:])\nprint(R[1:])\nprint(R[1, 2:])\nprint(R[:, 1])\n\nTrue\n6.2\n[1 2]\n-1\n\n['7.5' 'Jean']\n[[-1 -8  9 11]\n [ 3 -2 -4  6]]\n[ 9 11]\n[ 2 -8 -2]\n\n\nOperasi aritmatika juga dapat diterapkan pada NumPy array. Operasi aritmatika antar dua NumPy array akan dilakukan secara element- wise, artinya operasinya dilakukan tiap elemen (bukan seperti dot product pada aljabar linear).\n\nA = np.array([1, 4, 7, 10])\nB = np.array([1, 2, 3, 4])\n#operasi pada array\nprint(A + B)\nprint(A - B)\nprint(A * B)\nprint(A / B)\nprint(A % B)\nprint(A // B)\nprint(A ** B)\n\n[ 2  6 10 14]\n[0 2 4 6]\n[ 1  8 21 40]\n[1.         2.         2.33333333 2.5       ]\n[0 0 1 2]\n[1 2 2 2]\n[    1    16   343 10000]\n\n\nSelain itu, operasi aritmatika juga bisa dilakukan dengan skalar. Operasi aritmatika antara NumPy array dengan suatu skalar akan dilakukan seolah-olah skalar tersebut adalah NumPy array berukuran sama yang isinya skalar tersebut. Istilahnya biasanya disebut Broadcasting\n\nprint(A + 2)\nprint(C * 3)\nprint(P ** 2)\nprint(1 / R)\n\n[ 3  6  9 12]\n[12  6 -3 -9]\n[[1 4]\n [1 0]]\n[[ 1.          0.5         0.25        0.2       ]\n [-1.         -0.125       0.11111111  0.09090909]\n [ 0.33333333 -0.5        -0.25        0.16666667]]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/latintegrasinum.html",
    "href": "semuahalaman/modulprak/2024/genap/metnum/latintegrasinum.html",
    "title": "Latihan (Wajib) Integrasi Numerik",
    "section": "",
    "text": "Kembali ke Metode Numerik\nDiberikan: Senin/Selasa, 29/30 April 2024 (ketika praktikum Integrasi Numerik)\nDeadline: Minggu, 5 Mei 2024, 23.59 WIB\nSecara pemrograman, kerjakan lima soal berikut (yang ada di buku Burden):\n\nExercise Set 4.3 no 1a, 1b\nExercise Set 4.4 no 8b\nExercise Set 4.6 no 3a\nExercise Set 4.7 no 1a\n\nAnda dipersilakan memanfaatkan modul praktikum, terutama Modul 4 tentang Integrasi Numerik.\nSetelah selesai, kumpulkan file .ipynb nya di link berikut (sesuai kelas):\n\n(Kelas A): https://bit.ly/LatihanMetodeNumerikA2024\n(Kelas B): https://bit.ly/LatihanMetodeNumerikB2024\n(Kelas C): https://bit.ly/LatihanMetodeNumerikC2024\n(Kelas D): https://bit.ly/LatihanMetodeNumerikD2024\n(Kelas E): https://bit.ly/LatihanMetodeNumerikE2024\n(Kelas F): https://bit.ly/LatihanMetodeNumerikF2024"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul6.html",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul6.html",
    "title": "Modul 6 Kalkulin 2024 Genap: Hasil Kali Dalam, Dekomposisi QR, Bentuk Kuadratik",
    "section": "",
    "text": "Kembali ke Kalkulin"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul6.html#memeriksa-aksioma-hasil-kali-dalam",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul6.html#memeriksa-aksioma-hasil-kali-dalam",
    "title": "Modul 6 Kalkulin 2024 Genap: Hasil Kali Dalam, Dekomposisi QR, Bentuk Kuadratik",
    "section": "Memeriksa Aksioma Hasil Kali Dalam",
    "text": "Memeriksa Aksioma Hasil Kali Dalam"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul6.html#dekomposisi-qr-secara-manual",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul6.html#dekomposisi-qr-secara-manual",
    "title": "Modul 6 Kalkulin 2024 Genap: Hasil Kali Dalam, Dekomposisi QR, Bentuk Kuadratik",
    "section": "Dekomposisi QR secara manual",
    "text": "Dekomposisi QR secara manual"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul6.html#dekomposisi-qr-secara-otomatis",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul6.html#dekomposisi-qr-secara-otomatis",
    "title": "Modul 6 Kalkulin 2024 Genap: Hasil Kali Dalam, Dekomposisi QR, Bentuk Kuadratik",
    "section": "Dekomposisi QR secara otomatis",
    "text": "Dekomposisi QR secara otomatis"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul6.html#mengubah-bentuk-kuadratik-ke-dalam-bentuk-textbfxt-atextbfx",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul6.html#mengubah-bentuk-kuadratik-ke-dalam-bentuk-textbfxt-atextbfx",
    "title": "Modul 6 Kalkulin 2024 Genap: Hasil Kali Dalam, Dekomposisi QR, Bentuk Kuadratik",
    "section": "Mengubah bentuk kuadratik ke dalam bentuk \\(\\textbf{x}^T A\\textbf{x}\\)",
    "text": "Mengubah bentuk kuadratik ke dalam bentuk \\(\\textbf{x}^T A\\textbf{x}\\)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul6.html#eksplorasi-geometri-bentuk-kuadratik",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul6.html#eksplorasi-geometri-bentuk-kuadratik",
    "title": "Modul 6 Kalkulin 2024 Genap: Hasil Kali Dalam, Dekomposisi QR, Bentuk Kuadratik",
    "section": "Eksplorasi geometri bentuk kuadratik",
    "text": "Eksplorasi geometri bentuk kuadratik"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul4.html",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul4.html",
    "title": "Modul 4 Kalkulin: Koordinat Polar dan Fungsi Multivariabel",
    "section": "",
    "text": "Kembali ke Kalkulin"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul4.html#koordinat-polar",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul4.html#koordinat-polar",
    "title": "Modul 4 Kalkulin: Koordinat Polar dan Fungsi Multivariabel",
    "section": "Koordinat Polar",
    "text": "Koordinat Polar"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul4.html#fungsi-multivariabel-bernilai-riil",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul4.html#fungsi-multivariabel-bernilai-riil",
    "title": "Modul 4 Kalkulin: Koordinat Polar dan Fungsi Multivariabel",
    "section": "Fungsi Multivariabel Bernilai Riil",
    "text": "Fungsi Multivariabel Bernilai Riil"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html",
    "title": "Modul 2 Kalkulin: Basic LaTeX Part 2",
    "section": "",
    "text": "Kembali ke Kalkulin"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#outline",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#outline",
    "title": "Modul 2 Kalkulin: Basic LaTeX Part 2",
    "section": "Outline",
    "text": "Outline"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#structured-documents",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#structured-documents",
    "title": "Modul 2 Kalkulin: Basic LaTeX Part 2",
    "section": "Structured Documents",
    "text": "Structured Documents\n\nClick here to open the example document in Overleaf\n\n\n\n\nClick to open the paper\nClick to open this exercise in Overleaf\nclick here to see my solution\nhttp://pdos.csail.mit.edu/scigen/"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#figures-and-tables",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#figures-and-tables",
    "title": "Modul 2 Kalkulin: Basic LaTeX Part 2",
    "section": "Figures and Tables",
    "text": "Figures and Tables"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#bibliographies",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#bibliographies",
    "title": "Modul 2 Kalkulin: Basic LaTeX Part 2",
    "section": "Bibliographies",
    "text": "Bibliographies"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#exercise-putting-it-all-together",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#exercise-putting-it-all-together",
    "title": "Modul 2 Kalkulin: Basic LaTeX Part 2",
    "section": "Exercise: Putting it All Together",
    "text": "Exercise: Putting it All Together\n\nClick to download example image\nClick to download example bib file"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#whats-next",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#whats-next",
    "title": "Modul 2 Kalkulin: Basic LaTeX Part 2",
    "section": "What’s Next?",
    "text": "What’s Next?\n\n\n\nhttps://www.overleaf.com/latex/examples\nhttp://texample.net/"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#installing-latex",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#installing-latex",
    "title": "Modul 2 Kalkulin: Basic LaTeX Part 2",
    "section": "Installing LaTeX",
    "text": "Installing LaTeX\n\nhttp://en.wikipedia.org/wiki/Comparison_of_TeX_editors"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#penutup",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul2.html#penutup",
    "title": "Modul 2 Kalkulin: Basic LaTeX Part 2",
    "section": "Penutup",
    "text": "Penutup"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/kalkulin2024genap.html",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/kalkulin2024genap.html",
    "title": "Praktikum Kalkulin (Kalkulus 2 & Aljabar Linier 1) 2024 Genap (Kurikulum 2020)",
    "section": "",
    "text": "Kembali ke Praktikum\n\nTimeline\n\nModul 1: Basic LaTeX Part 1, 23-24 Februari 2024\nModul 2: Basic LaTeX Part 2, 28-30 Februari 2024\nModul 3: LaTeX Beamer, 7-9 Maret 2024\nModul 4: Koordinat Polar dan Fungsi Multivariabel, 13-15 Maret 2024\nModul 5: Nilai Eigen, Diagonalisasi, Ortogonalitas, 24-26 April 2024\nModul 6: Hasil Kali Dalam, Dekomposisi QR, Bentuk Kuadratik, 2-4 Mei 2024\nModul 7: Transformasi Linier Umum, 8-11 Mei 2024\nModul 8: Integral Lipat, Pemrograman dengan Wolfram Mathematica, 15-17 Mei 2024\nTugas Praktikum Kalkulus 2\nDiberikan: Kamis, 23 Mei 2024\nDeadline: Minggu, 26 Mei 2024, 23.59 WIB\nTugas Praktikum Aljabar Linier 1\nDiberikan: Selasa, 28 Mei 2024\nDeadline: Minggu, 2 Juni 2024, 23.59 WIB"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul4.html",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul4.html",
    "title": "Pertemuan 4 : Data Visualization (seaborn)",
    "section": "",
    "text": "Kembali ke EDA"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul4.html#listseriesarray",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul4.html#listseriesarray",
    "title": "Pertemuan 4 : Data Visualization (seaborn)",
    "section": "List/Series/Array",
    "text": "List/Series/Array\n\n#Mengambil isinya saja dari kolom sepal length dan sepal width\nlength = iris['sepal_length'].values\nwidth = iris['sepal_width'].values\nprint(length, width)\n\n[5.1 4.9 4.7 4.6 5.  5.4 4.6 5.  4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1\n 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.  5.  5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.\n 5.5 4.9 4.4 5.1 5.  4.5 4.4 5.  5.1 4.8 5.1 4.6 5.3 5.  7.  6.4 6.9 5.5\n 6.5 5.7 6.3 4.9 6.6 5.2 5.  5.9 6.  6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1\n 6.3 6.1 6.4 6.6 6.8 6.7 6.  5.7 5.5 5.5 5.8 6.  5.4 6.  6.7 6.3 5.6 5.5\n 5.5 6.1 5.8 5.  5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3\n 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.  6.9 5.6 7.7 6.3 6.7 7.2\n 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.  6.9 6.7 6.9 5.8 6.8\n 6.7 6.7 6.3 6.5 6.2 5.9] [3.5 3.  3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.  3.  4.  4.4 3.9 3.5\n 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.  3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2\n 3.5 3.6 3.  3.4 3.5 2.3 3.2 3.5 3.8 3.  3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3\n 2.8 2.8 3.3 2.4 2.9 2.7 2.  3.  2.2 2.9 2.9 3.1 3.  2.7 2.2 2.5 3.2 2.8\n 2.5 2.8 2.9 3.  2.8 3.  2.9 2.6 2.4 2.4 2.7 2.7 3.  3.4 3.1 2.3 3.  2.5\n 2.6 3.  2.6 2.3 2.7 3.  2.9 2.9 2.5 2.8 3.3 2.7 3.  2.9 3.  3.  2.5 2.9\n 2.5 3.6 3.2 2.7 3.  2.5 2.8 3.2 3.  3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2\n 2.8 3.  2.8 3.  2.8 3.8 2.8 2.8 2.6 3.  3.4 3.1 3.  3.1 3.1 3.1 2.7 3.2\n 3.3 3.  2.5 3.  3.4 3. ]\n\n\n\nsns.scatterplot(x=length, y=width)\n\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul4.html#dataframe-dan-kolomnya",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul4.html#dataframe-dan-kolomnya",
    "title": "Pertemuan 4 : Data Visualization (seaborn)",
    "section": "Dataframe dan kolomnya",
    "text": "Dataframe dan kolomnya\n\nsns.scatterplot(x=iris['sepal_length'], y=iris['sepal_width'])\n\nplt.show()\n\n\n\n\n\n\n\n\natau\n\nsns.scatterplot(x='sepal_length', y='sepal_width', data=iris)\n\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul4.html#olah-dataframe",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul4.html#olah-dataframe",
    "title": "Pertemuan 4 : Data Visualization (seaborn)",
    "section": "Olah dataframe",
    "text": "Olah dataframe\n\nsns.boxplot(data=iris)\n\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul4.html#distribution-plot",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul4.html#distribution-plot",
    "title": "Pertemuan 4 : Data Visualization (seaborn)",
    "section": "Distribution Plot",
    "text": "Distribution Plot\n\nsns.displot(iris['petal_length'])\n\nplt.show()\n\n\n\n\n\n\n\n\n\niris['petal_length'].skew()\n\n-0.27488417975101276\n\n\n\nsns.displot(iris['sepal_width'])\n\nplt.show()\n\n\n\n\n\n\n\n\n\niris['sepal_width'].skew()\n\n0.31896566471359966\n\n\n\nsns.histplot(iris['sepal_length'])\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.histplot(iris['sepal_width'])\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Histogram kumulatif dari sepal width\nsns.histplot(iris['sepal_width'], cumulative=True)\n\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul4.html#count-plot",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul4.html#count-plot",
    "title": "Pertemuan 4 : Data Visualization (seaborn)",
    "section": "Count Plot",
    "text": "Count Plot\n\n#tips dari seaborn\ntips=sns.load_dataset('tips')\ntips\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n\n\n\n\n244 rows × 7 columns\n\n\n\n\n\n# Histogram kumulatif dari sepal width\nsns.countplot(x='day', data=tips)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Histogram kumulatif dari sepal width\nsns.countplot(x=tips['day'])\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Histogram kumulatif dari sepal width\nsns.countplot(x='sex', data=tips, palette='Accent', hue='sex')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Histogram kumulatif dari sepal width\nsns.countplot(x='day', data=tips, palette='Blues', hue='sex')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Histogram kumulatif dari sepal width\nsns.countplot(x='sex', data=tips, palette='Blues', hue='day')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n#Jika ingin mengammbar dalam sumbu vertikal ya y=\nsns.countplot(y='day', data=tips, palette='Blues', hue='sex')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.countplot(x='sex', data=tips, hue='smoker')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.countplot(x='smoker', data=tips, hue='sex')\n\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul4.html#heatmap",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul4.html#heatmap",
    "title": "Pertemuan 4 : Data Visualization (seaborn)",
    "section": "Heatmap",
    "text": "Heatmap\n\niris.drop('species', axis=1, inplace=True)\niris\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\n\n\n1\n4.9\n3.0\n1.4\n0.2\n\n\n2\n4.7\n3.2\n1.3\n0.2\n\n\n3\n4.6\n3.1\n1.5\n0.2\n\n\n4\n5.0\n3.6\n1.4\n0.2\n\n\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\n\n\n146\n6.3\n2.5\n5.0\n1.9\n\n\n147\n6.5\n3.0\n5.2\n2.0\n\n\n148\n6.2\n3.4\n5.4\n2.3\n\n\n149\n5.9\n3.0\n5.1\n1.8\n\n\n\n\n150 rows × 4 columns\n\n\n\n\n\nkorelasi_iris = iris.corr()\nkorelasi_iris\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\n\n\nsepal_length\n1.000000\n-0.117570\n0.871754\n0.817941\n\n\nsepal_width\n-0.117570\n1.000000\n-0.428440\n-0.366126\n\n\npetal_length\n0.871754\n-0.428440\n1.000000\n0.962865\n\n\npetal_width\n0.817941\n-0.366126\n0.962865\n1.000000\n\n\n\n\n\n\n\n\nsns.heatmap(iris.corr())\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.heatmap(iris.corr(), cmap='YlGnBu')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.heatmap(iris.corr(), cmap='YlGnBu')\n\nplt.xticks(rotation=45)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.heatmap(iris.corr(), cmap='YlGnBu')\n\nplt.yticks(rotation=45)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.heatmap(iris.corr(), cmap='YlGnBu')\n\nplt.xticks(rotation=45)\n\nplt.yticks(rotation=45)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.heatmap(korelasi_iris[(korelasi_iris &gt;= 0.5)])\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.heatmap(korelasi_iris[(korelasi_iris &gt;= 0.5) | (korelasi_iris &lt;= -0.2)])\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.heatmap(korelasi_iris[(korelasi_iris &gt;= 0.5) | (korelasi_iris &lt;= -0.2)], annot = True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.heatmap(korelasi_iris[(korelasi_iris &gt;= 0.5) | (korelasi_iris &lt;= -0.2)], annot = True, cmap='Blues')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.heatmap(korelasi_iris[(korelasi_iris &gt;= 0.5) | (korelasi_iris &lt;= -0.2) ], annot = True, cmap = 'Blues', linewidth = 1, linecolor = 'black')\n\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul4.html#scatter-plot",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul4.html#scatter-plot",
    "title": "Pertemuan 4 : Data Visualization (seaborn)",
    "section": "Scatter Plot",
    "text": "Scatter Plot\n\niris = sns.load_dataset('iris')\niris\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n...\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n146\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n147\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n148\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n149\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\n150 rows × 5 columns\n\n\n\n\n\nsns.scatterplot(x='sepal_length', y='sepal_width', data=iris, palette='Accent_r', hue='species')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.regplot(x='sepal_length', y='sepal_width', data=iris)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.regplot(x='petal_length', y='petal_width', data=iris)\n\nplt.show()\n\n\n\n\n\n\n\n\n\niris['petal_length'].corr(iris['petal_width'])\n\n0.9628654314027963"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul4.html#box-plot",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul4.html#box-plot",
    "title": "Pertemuan 4 : Data Visualization (seaborn)",
    "section": "Box Plot",
    "text": "Box Plot\n\nsns.boxplot(x='petal_length', data=iris)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.boxplot(x='sepal_width', data=iris)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n?sns.countplot"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul2.html",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul2.html",
    "title": "Pertemuan 2 : Data Cleaning with Pandas",
    "section": "",
    "text": "Kembali ke EDA"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul2.html#concatenate-merge",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul2.html#concatenate-merge",
    "title": "Pertemuan 2 : Data Cleaning with Pandas",
    "section": "Concatenate & Merge",
    "text": "Concatenate & Merge\n\nConcatenate\n\nConcatenate digunakan untuk menggabungkan 2 atau lebih series/dataframe. Argumen axis= digunakan untuk mengatur opsi penggabungan data menurut index baris atau index kolom. Berikut contoh penggunaan pada 2 series :\n\nimport numpy as np\nimport pandas as pd\n\nseries1 = pd.Series(['a','b','c'])\nseries2 = pd.Series(['x','y','z'])\n\n\naxis=0 (default) akan menggabungkan data pada index baris.\n\npd.concat([series1,series2], axis=0)\n\n0    a\n1    b\n2    c\n0    x\n1    y\n2    z\ndtype: object\n\n\n\naxis=1 akan menggabungkan data pada index kolom.\n\npd.concat([series1,series2], axis=1)\n\n\n\n\n\n\n\n\n0\n1\n\n\n\n\n0\na\nx\n\n\n1\nb\ny\n\n\n2\nc\nz\n\n\n\n\n\n\n\n\nignore_index=True akan mengabaikan index awal dari masing-masing data sehingga hasil penggabungan memiliki index baru.\n\npd.concat([series1,series2], ignore_index=True)\n\n0    a\n1    b\n2    c\n3    x\n4    y\n5    z\ndtype: object\n\n\n\nKita dapat menambahkan keys sebagai penanda dari masing-masing series sebelum digabungkan.\n\npd.concat([series1,series2], keys=['Series 1','Series 2'])\n\nSeries 1  0    a\n          1    b\n          2    c\nSeries 2  0    x\n          1    y\n          2    z\ndtype: object\n\n\n\n\n\n\n\n\nTip\n\n\n\nHasil penggabungan dengan argumen keys= akan menambahkan keys sebagai index gabungan, sehingga pada contoh di atas, index dari masing-masing value adalah sebuah tuple yang merupakan pasangan index gabungan dan index masing-masing.\n\npd.concat([series1,series2], keys=['Series 1','Series 2']).index\n\nMultiIndex([('Series 1', 0),\n            ('Series 1', 1),\n            ('Series 1', 2),\n            ('Series 2', 0),\n            ('Series 2', 1),\n            ('Series 2', 2)],\n           )\n\n\n\n\n\nBerikut contoh penggunaan pada DataFrame :\n\ndf1=pd.DataFrame({'col 1':['a','b','c'],'col 2':[0,1,2]})\ndf2=pd.DataFrame({'col 1':['x','y','z'],'col 2':[4,5,6]})\n\n\ndf1\n\n\n\n\n\n\n\n\ncol 1\ncol 2\n\n\n\n\n0\na\n0\n\n\n1\nb\n1\n\n\n2\nc\n2\n\n\n\n\n\n\n\n\ndf2\n\n\n\n\n\n\n\n\ncol 1\ncol 2\n\n\n\n\n0\nx\n4\n\n\n1\ny\n5\n\n\n2\nz\n6\n\n\n\n\n\n\n\n\naxis=0 (default) akan menggabungkan data pada index baris.\n\npd.concat([df1,df2])\n\n\n\n\n\n\n\n\ncol 1\ncol 2\n\n\n\n\n0\na\n0\n\n\n1\nb\n1\n\n\n2\nc\n2\n\n\n0\nx\n4\n\n\n1\ny\n5\n\n\n2\nz\n6\n\n\n\n\n\n\n\n\naxis=1 akan menggabungkan data pada index kolom.\n\npd.concat([df1,df2], axis=1)\n\n\n\n\n\n\n\n\ncol 1\ncol 2\ncol 1\ncol 2\n\n\n\n\n0\na\n0\nx\n4\n\n\n1\nb\n1\ny\n5\n\n\n2\nc\n2\nz\n6\n\n\n\n\n\n\n\n\nPerhatikan bahwa nama kolom df1 dan df2 sama. Misalkan kita menggabungkan 2 dataframe dengan nama kolom yang berbeda.\n\ndf3=pd.DataFrame({'col 2':[3,4,5],'col 3':['m','n','o']})\ndf3\n\n\n\n\n\n\n\n\ncol 2\ncol 3\n\n\n\n\n0\n3\nm\n\n\n1\n4\nn\n\n\n2\n5\no\n\n\n\n\n\n\n\nConcatenate pada DataFrame melihat index kolom sebagai acuan untuk penggabungan pada axis=0 (baris).\n\npd.concat([df1,df3])\n\n\n\n\n\n\n\n\ncol 1\ncol 2\ncol 3\n\n\n\n\n0\na\n0\nNaN\n\n\n1\nb\n1\nNaN\n\n\n2\nc\n2\nNaN\n\n\n0\nNaN\n3\nm\n\n\n1\nNaN\n4\nn\n\n\n2\nNaN\n5\no\n\n\n\n\n\n\n\nKarena df1 dan df3 memiliki nama kolom yang berbeda, maka terjadi penggabungan baris sekaligus kolom.\n\nUntuk kolom yang beririsan, bisa menggunakan argumen join= untuk mengatur bagaimana penggabungan dilakukan (pada keseluruhan data atau pada data yang beririsan saja)\n\npd.concat([df1,df3], join='inner') # df1 ⋂ df3\n\n\n\n\n\n\n\n\ncol 2\n\n\n\n\n0\n0\n\n\n1\n1\n\n\n2\n2\n\n\n0\n3\n\n\n1\n4\n\n\n2\n5\n\n\n\n\n\n\n\n\npd.concat([df1,df3], join='outer') # df1 ⋃ df3\n\n\n\n\n\n\n\n\ncol 1\ncol 2\ncol 3\n\n\n\n\n0\na\n0\nNaN\n\n\n1\nb\n1\nNaN\n\n\n2\nc\n2\nNaN\n\n\n0\nNaN\n3\nm\n\n\n1\nNaN\n4\nn\n\n\n2\nNaN\n5\no\n\n\n\n\n\n\n\n\n\n\nMerge\n\nFungsi merge pada pandas digunakan untuk menggabungkan 2 atau lebih dataframe berdasarkan index kolom tertentu.\n\nkaryawan = pd.DataFrame({'id':[1,2,3,4],'nama':['Joko','Alvin','Rafi','Lita']})\nkaryawan\n\n\n\n\n\n\n\n\nid\nnama\n\n\n\n\n0\n1\nJoko\n\n\n1\n2\nAlvin\n\n\n2\n3\nRafi\n\n\n3\n4\nLita\n\n\n\n\n\n\n\n\ngaji = pd.DataFrame({'id':[2,1,3,5,4,6],'gaji':[100.0,200.0,300.0,400.0,500.0,600.0]})\ngaji\n\n\n\n\n\n\n\n\nid\ngaji\n\n\n\n\n0\n2\n100.0\n\n\n1\n1\n200.0\n\n\n2\n3\n300.0\n\n\n3\n5\n400.0\n\n\n4\n4\n500.0\n\n\n5\n6\n600.0\n\n\n\n\n\n\n\n\npd.merge(karyawan, gaji, on='id')\n\n\n\n\n\n\n\n\nid\nnama\ngaji\n\n\n\n\n0\n1\nJoko\n200.0\n\n\n1\n2\nAlvin\n100.0\n\n\n2\n3\nRafi\n300.0\n\n\n3\n4\nLita\n500.0\n\n\n\n\n\n\n\nData nama karyawan dan gaji digabungkan dalam 1 dataframe, dengan nilai-nilai pada kolom id sebagai acuan.\n\n\n\n\n\n\nMerge & Join\n\n\n\nPada modul ini, hanya dibahas mengenai dasar penggunaan fungsi merge untuk menggabungkan dataset. Untuk penggunaan lebih spesifik dengan argumen left=, right=, left_on=, right_on= dan how= akan dibahas pada materi Data Wrangling"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul2.html#df.info",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul2.html#df.info",
    "title": "Pertemuan 2 : Data Cleaning with Pandas",
    "section": "df.info()",
    "text": "df.info()\n\nMethod .info() dapat digunakan untuk melihat informasi dasar suatu dataframe seperti jumlah entri keseluruhan, nama kolom, jumlah nilai non-null tiap kolom, tipe data tiap kolom hingga penggunaan memori suatu dataframe\nMisalkan kita gunakan dataset pokemon pada modul sebelumnya,\n\ndf = pd.read_csv('https://raw.githubusercontent.com/farhanage/dataset-for-study/main/pokemon_data.csv')\ndf.head()\n\n\n\n\n\n\n\n\n#\nName\nType 1\nType 2\nHP\nAttack\nDefense\nSp. Atk\nSp. Def\nSpeed\nGeneration\nLegendary\n\n\n\n\n0\n1\nBulbasaur\nGrass\nPoison\n45\n49\n49\n65\n65\n45\n1\nFalse\n\n\n1\n2\nIvysaur\nGrass\nPoison\n60\n62\n63\n80\n80\n60\n1\nFalse\n\n\n2\n3\nVenusaur\nGrass\nPoison\n80\n82\n83\n100\n100\n80\n1\nFalse\n\n\n3\n3\nVenusaurMega Venusaur\nGrass\nPoison\n80\n100\n123\n122\n120\n80\n1\nFalse\n\n\n4\n4\nCharmander\nFire\nNaN\n39\n52\n43\n60\n50\n65\n1\nFalse\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 800 entries, 0 to 799\nData columns (total 12 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   #           800 non-null    int64 \n 1   Name        800 non-null    object\n 2   Type 1      800 non-null    object\n 3   Type 2      414 non-null    object\n 4   HP          800 non-null    int64 \n 5   Attack      800 non-null    int64 \n 6   Defense     800 non-null    int64 \n 7   Sp. Atk     800 non-null    int64 \n 8   Sp. Def     800 non-null    int64 \n 9   Speed       800 non-null    int64 \n 10  Generation  800 non-null    int64 \n 11  Legendary   800 non-null    bool  \ndtypes: bool(1), int64(8), object(3)\nmemory usage: 69.7+ KB"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul2.html#missing-values",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul2.html#missing-values",
    "title": "Pertemuan 2 : Data Cleaning with Pandas",
    "section": "Missing Values",
    "text": "Missing Values\n\nTerdapat 2 tipe missing value.\n\nData bernilai NaN (Not a Number)\nData bernilai 0 (Null)\n\n\n\n\n\n\n\nNull\n\n\n\nData bernilai 0 (Null) tidak selalu bersifat sebagai data yang hilang, bisa juga data memang memiliki data yang bernilai 0. Oleh karena itu, penting bagi kita untuk mengetahui konteks dari data yang dianalisis.\n\n\n\n\ndf = pd.DataFrame({\"Evan\" : [np.nan,100,95,94,99],\"Boy\" : [100,np.nan,95,99,94],\"Maxwell\" : [95,100,99,np.nan,94]})\ndf\n\n\n\n\n\n\n\n\nEvan\nBoy\nMaxwell\n\n\n\n\n0\nNaN\n100.0\n95.0\n\n\n1\n100.0\nNaN\n100.0\n\n\n2\n95.0\n95.0\n99.0\n\n\n3\n94.0\n99.0\nNaN\n\n\n4\n99.0\n94.0\n94.0\n\n\n\n\n\n\n\nUntuk melihat data mana saja yang mengandung value NaN (Not a Number), kita gunakan method .isna() atau .isnull(). (Kedua method ini memiliki fungsi yang sama dan dapat digunakan secara bergantian/salah satu saja)\n\ndf.isna()\n\n\n\n\n\n\n\n\nEvan\nBoy\nMaxwell\n\n\n\n\n0\nTrue\nFalse\nFalse\n\n\n1\nFalse\nTrue\nFalse\n\n\n2\nFalse\nFalse\nFalse\n\n\n3\nFalse\nFalse\nTrue\n\n\n4\nFalse\nFalse\nFalse\n\n\n\n\n\n\n\nUntuk melihat jumlah value NaN pada data, tambahkan method .sum() pada kode di atas.\n\ndf.isna().sum()\n\nEvan       1\nBoy        1\nMaxwell    1\ndtype: int64\n\n\n\n\n\n\n\n\nMethod .sum()\n\n\n\nMethod .sum() digunakan untuk menjumlahkan nilai-nilai pada tiap kolom dataframe (Juga dalam suatu Series).\n\n\nUntuk melihat entri-entri yang memiliki nilai NaN pada kolom tertentu, lakukan filtering pada dataframe dengan df['&lt;nama-kolom&gt;'].isna() sebagai kondisi yang diinginkan.\n\ndf[df['Evan'].isna()]   # Entri yang memiliki nilai `NaN` pada kolom `Evan`\n\n\n\n\n\n\n\n\nEvan\nBoy\nMaxwell\n\n\n\n\n0\nNaN\n100.0\n95.0"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul2.html#duplicates",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul2.html#duplicates",
    "title": "Pertemuan 2 : Data Cleaning with Pandas",
    "section": "Duplicates",
    "text": "Duplicates\n\nData duplikat pada dataframe adalah entri yang memiliki nilai yang sama pada setiap kolom. Jika terdapat setidaknya 1 nilai kolom yang berbeda antara 2 entri, data tersebut bukanlah sebuah duplikat.\n\ndf = pd.DataFrame({\n    \"id\" : [1,2,3,4,3,6],\n    \"Karyawan\" : ['Joko','Alvin','Rafi','Lita','Rafi','Jennie'],\n    \"Gaji\" : [100.0, 200.0, 300.0, 400.0, 300.0, 600.0]})\ndf\n\n\n\n\n\n\n\n\nid\nKaryawan\nGaji\n\n\n\n\n0\n1\nJoko\n100.0\n\n\n1\n2\nAlvin\n200.0\n\n\n2\n3\nRafi\n300.0\n\n\n3\n4\nLita\n400.0\n\n\n4\n3\nRafi\n300.0\n\n\n5\n6\nJennie\n600.0\n\n\n\n\n\n\n\nUntuk melihat data yang memiliki duplikat pada dataframe, kita gunakan method .duplicated().\n\ndf.duplicated()\n\n0    False\n1    False\n2    False\n3    False\n4     True\n5    False\ndtype: bool\n\n\nPerhatikan bahwa data yang terbaca sebagai duplikat adalah data yang muncul setelah kemunculan data pertama kali (data duplikat pertama tidak dianggap sebagai duplikat)\nDengan cara yang sama seperti pada Missing Value, kita bisa menggunakan method .sum() untuk melihat jumlah data duplikat pada suatu dataframe.\n\ndf.duplicated().sum()\n\n1\n\n\nUntuk melihat entri-entri yang memiliki nilai duplikat pada kolom tertentu, lakukan filtering pada dataframe dengan df['&lt;nama-kolom&gt;'].duplicated() sebagai kondisi yang diinginkan.\n\ndf[df['id'].duplicated()]   # Entri yang memiliki nilai `id` duplikat\n\n\n\n\n\n\n\n\nid\nKaryawan\nGaji\n\n\n\n\n4\n3\nRafi\n300.0"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul2.html#descriptive-statistics",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul2.html#descriptive-statistics",
    "title": "Pertemuan 2 : Data Cleaning with Pandas",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\n\nUntuk mengidentifikasi apakah terdapat data yang salah, jika kita perlu tahu konteks data tersebut. Seperti bagaimana cara data diperoleh? Apakah ada batas-batas nilai pada variabel-variabel tertentu?\nSalah satu cara mudah untuk mengidentifikasi persebaran suatu data adalah dengan melihat statistik deskriptif suatu data. Kita bisa menggunakan method .describe() untuk melihat ukuran persebaran data dari masing-masing variabel pada suatu dataframe.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/farhanage/dataset-for-study/main/pokemon_data.csv')\ndf.head()\n\n\n\n\n\n\n\n\n#\nName\nType 1\nType 2\nHP\nAttack\nDefense\nSp. Atk\nSp. Def\nSpeed\nGeneration\nLegendary\n\n\n\n\n0\n1\nBulbasaur\nGrass\nPoison\n45\n49\n49\n65\n65\n45\n1\nFalse\n\n\n1\n2\nIvysaur\nGrass\nPoison\n60\n62\n63\n80\n80\n60\n1\nFalse\n\n\n2\n3\nVenusaur\nGrass\nPoison\n80\n82\n83\n100\n100\n80\n1\nFalse\n\n\n3\n3\nVenusaurMega Venusaur\nGrass\nPoison\n80\n100\n123\n122\n120\n80\n1\nFalse\n\n\n4\n4\nCharmander\nFire\nNaN\n39\n52\n43\n60\n50\n65\n1\nFalse\n\n\n\n\n\n\n\n\ndf.describe()\n\n\n\n\n\n\n\n\n#\nHP\nAttack\nDefense\nSp. Atk\nSp. Def\nSpeed\nGeneration\n\n\n\n\ncount\n800.000000\n800.000000\n800.000000\n800.000000\n800.000000\n800.000000\n800.000000\n800.00000\n\n\nmean\n362.813750\n69.258750\n79.001250\n73.842500\n72.820000\n71.902500\n68.277500\n3.32375\n\n\nstd\n208.343798\n25.534669\n32.457366\n31.183501\n32.722294\n27.828916\n29.060474\n1.66129\n\n\nmin\n1.000000\n1.000000\n5.000000\n5.000000\n10.000000\n20.000000\n5.000000\n1.00000\n\n\n25%\n184.750000\n50.000000\n55.000000\n50.000000\n49.750000\n50.000000\n45.000000\n2.00000\n\n\n50%\n364.500000\n65.000000\n75.000000\n70.000000\n65.000000\n70.000000\n65.000000\n3.00000\n\n\n75%\n539.250000\n80.000000\n100.000000\n90.000000\n95.000000\n90.000000\n90.000000\n5.00000\n\n\nmax\n721.000000\n255.000000\n190.000000\n230.000000\n194.000000\n230.000000\n180.000000\n6.00000\n\n\n\n\n\n\n\nNamun, metode ini hanya dapat digunakan pada data numerik. Sehingga untuk data non-numerik, perlu pemahaman lebih lanjut mengenai konteks data dan metode yang digunakan untuk mengonfirmasi validitas data."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul2.html#memperbaiki-format-data-yang-salah",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul2.html#memperbaiki-format-data-yang-salah",
    "title": "Pertemuan 2 : Data Cleaning with Pandas",
    "section": "Memperbaiki Format Data yang Salah",
    "text": "Memperbaiki Format Data yang Salah\n\nTerdapat lebih dari 1 cara untuk memperbaiki format data yang salah. Tidak disalahkan bagi anda untuk mencarinya di internet sendiri. Silakan merujuk pada berbagai sumber. Salah satunya adalah jawaban dari pertanyaan pada forum StackOverflow berikut : Link"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul2.html#mengimputasi-sel-yang-kosong",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul2.html#mengimputasi-sel-yang-kosong",
    "title": "Pertemuan 2 : Data Cleaning with Pandas",
    "section": "Mengimputasi sel yang kosong",
    "text": "Mengimputasi sel yang kosong\n\n\ndf.fillna(value='&lt;value&gt;', inplace=True)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul2.html#menghapus-data-duplikat",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul2.html#menghapus-data-duplikat",
    "title": "Pertemuan 2 : Data Cleaning with Pandas",
    "section": "Menghapus data duplikat",
    "text": "Menghapus data duplikat\n\n\ndf.drop_duplicates(inplace=True)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/eda2024genap.html",
    "href": "semuahalaman/modulprak/2024/genap/eda/eda2024genap.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Kembali ke Praktikum\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPertemuan 1 : Python for Data Analysis\n\n\n\nFeb 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPertemuan 2 : Data Cleaning with Pandas\n\n\n\nApr 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPertemuan 3 : Simple Data Visualization (matplotlib)\n\n\n\nApr 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPertemuan 4 : Data Visualization (seaborn)\n\n\n\nApr 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPertemuan 5 : Time Series Visualization\n\n\n\nMay 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPertemuan 6 : Interactive Data Visualization (plotly)\n\n\n\nMay 14, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-3.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-3.html",
    "title": "Tugas 03 (End to End Machine Learning Klasifikasi)",
    "section": "",
    "text": "Kembali ke Sains Data\n\n\n\nKerjakan secara individu\nKerjakan tugas ini dengan bahasa pemrograman python. Anda disarankan menggunakan jupyter untuk mengerjakan tugas ini.\nUntuk setiap proses sains data (pembersihan data, transformasi data, EDA, dan pemodela ) yang dilakukan Anda diperlukan untuk menuliskan justifikasi-nya. Justifikasi-nya dapat berupa penjelasan singkat mengenai proses yang dilakukan, dan penjelasan mengenai alasan mengapa anda melakukan proses tersebut.\nFile yang harus diunggah terdiri dari:\n\nbeberapa model dalam format .pkl. Penamaan untuk model dibebaskan, namun harus jelas mengenai model apa yang disimpan.\nsatu file python notebook (file berbentuk .ipynb BUKAN .py) dengan ketentuan serupa.\n\nSemua file disatukan dalam 1 (satu) file .zip, dengan format penamaan: Nama_NPM_Kelas SIAK Sains Data_Tugas3PrakSainsData.zip. contoh: Itadori-Yuji_190688675_A_Tugas3PrakSainsData.zip\nBatas pengumpulan tugas ini adalah 21 April 2023 pukul 23.59. Tugas dikumpulkan sesuai dengan link berikut: https://ristek.link/tugas-sains-data-03\nDilarang melakukan plagiarisme atau menduplikasi dalam mengerjakan tugas ini. Apabila terdapat kesamaan program atau penjelasan pada tugas yang dikumpulkan, NILAI TUGAS PRAKTIKUM SAINS DATA ANDA LANGSUNG MENJADI 0 TANPA PERINGATAN bagi semua pihak yang terlibat plagiarisme dalam tugas ini.\nGunakan module (python package) yang telah dipelajari di praktikum atau kelas. Anda diperbolehkan untuk menggunakan module (python package) lain dengan catatan bahwa Anda harus menuliskan penjelasan singkat mengenai module tersebut.\nApabila ada yang ingin ditanyakan anda dapat bertanya pada kolom komentar atau, silakan mengontak salah satu kontak berikut:\n\nLINE: Tulus Setiawan (WA/LINE: tlsnew/081213679316)\n\n\n\n\n\n[akses-data]: https://drive.google.com/open?id=19WogXg2YgH7tNhAXESJ7SaITOWGGu2HX&authuser=carlesoctavianus%40gmail.com&usp=drive_fs\nKerjakan secara end-to-end (pembersihan data, transformasi data , EDA, dan pemodelan) untuk mengklasifikasikan harga ponsel berdasarkan data yang diberikan. Gunakan metode yang telah dipelajari di praktikum ataupun kelas (model Klasifikasi)."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-3.html#petunjuk-umum",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-3.html#petunjuk-umum",
    "title": "Tugas 03 (End to End Machine Learning Klasifikasi)",
    "section": "",
    "text": "Kerjakan secara individu\nKerjakan tugas ini dengan bahasa pemrograman python. Anda disarankan menggunakan jupyter untuk mengerjakan tugas ini.\nUntuk setiap proses sains data (pembersihan data, transformasi data, EDA, dan pemodela ) yang dilakukan Anda diperlukan untuk menuliskan justifikasi-nya. Justifikasi-nya dapat berupa penjelasan singkat mengenai proses yang dilakukan, dan penjelasan mengenai alasan mengapa anda melakukan proses tersebut.\nFile yang harus diunggah terdiri dari:\n\nbeberapa model dalam format .pkl. Penamaan untuk model dibebaskan, namun harus jelas mengenai model apa yang disimpan.\nsatu file python notebook (file berbentuk .ipynb BUKAN .py) dengan ketentuan serupa.\n\nSemua file disatukan dalam 1 (satu) file .zip, dengan format penamaan: Nama_NPM_Kelas SIAK Sains Data_Tugas3PrakSainsData.zip. contoh: Itadori-Yuji_190688675_A_Tugas3PrakSainsData.zip\nBatas pengumpulan tugas ini adalah 21 April 2023 pukul 23.59. Tugas dikumpulkan sesuai dengan link berikut: https://ristek.link/tugas-sains-data-03\nDilarang melakukan plagiarisme atau menduplikasi dalam mengerjakan tugas ini. Apabila terdapat kesamaan program atau penjelasan pada tugas yang dikumpulkan, NILAI TUGAS PRAKTIKUM SAINS DATA ANDA LANGSUNG MENJADI 0 TANPA PERINGATAN bagi semua pihak yang terlibat plagiarisme dalam tugas ini.\nGunakan module (python package) yang telah dipelajari di praktikum atau kelas. Anda diperbolehkan untuk menggunakan module (python package) lain dengan catatan bahwa Anda harus menuliskan penjelasan singkat mengenai module tersebut.\nApabila ada yang ingin ditanyakan anda dapat bertanya pada kolom komentar atau, silakan mengontak salah satu kontak berikut:\n\nLINE: Tulus Setiawan (WA/LINE: tlsnew/081213679316)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-3.html#soal",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-3.html#soal",
    "title": "Tugas 03 (End to End Machine Learning Klasifikasi)",
    "section": "",
    "text": "[akses-data]: https://drive.google.com/open?id=19WogXg2YgH7tNhAXESJ7SaITOWGGu2HX&authuser=carlesoctavianus%40gmail.com&usp=drive_fs\nKerjakan secara end-to-end (pembersihan data, transformasi data , EDA, dan pemodelan) untuk mengklasifikasikan harga ponsel berdasarkan data yang diberikan. Gunakan metode yang telah dipelajari di praktikum ataupun kelas (model Klasifikasi)."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/sainsdata2023.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/sainsdata2023.html",
    "title": "Praktikum Sains Data 2023 Genap (Kurikulum 2020)",
    "section": "",
    "text": "Kembali ke Praktikum\nModul ini adalah salinan dari: https://github.com/carlesoctav/sains-data-2023\n\nTimeline\n\nmodul-tahun-lalu\npraktikum-1: 1 Maret 2023, presensi ristek.link/presensi-sains-data-01\npraktikum-2: 8 Maret 2023, presensi ristek.link/presensi-sains-data-02\npraktikum-3: 15 Maret 2023, presensi ristek.link/presensi-sains-data-03\nTugas-1: 22 Maret 2023, tempat pengumpulan: bit.ly/Tugas1PrakSainsData\nTugas-2: 21 April 2023, tempat pengumpulan: https://ristek.link/tugas-sains-data-02\nTugas-3: 21 April 2023, tempat pengumpulan: https://ristek.link/tugas-sains-data-03\npraktikum-4: 26 April 2023, presensi ristek.link/presensi-sains-data-04\npraktikum-5: 3 Mei 2023, presensi ristek.link/presensi-sains-data-05\npraktikum-6: 10 Mei 2023, presensi ristek.link/presensi-sains-data-06\ntugas-akhir"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html",
    "title": "Week 05 (Introduction to Keras and TensorFlow)",
    "section": "",
    "text": "Kembali ke Sains Data\n\nTensorFlow: Python-based, free, open source machine learning platform developed by Google that enables manipulation of mathematical expressions over numerical tensors, computes gradients automatically, supports CPUs, GPUs, TPUs, allows easy distribution of computation across machines, and can be exported to other runtimes for easy deployment in practical settings.\nKeras: a deep learning API for Python, built on top of TensorFlow, known for its convenient model definition and training, initially developed for research with fast experimentation, and can run on various hardware types, including GPU, TPU, and CPU, and scale to multiple machines seamlessly while prioritizing developer experience.\n\n\n\n\n\n# !pip install tensorflow # uncomment if you don't have tensorflow installed\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n\n\n\n# All-ones or all-zeros tensors\n\nx = tf.ones(shape = (2,1)) # 2x3 matrix of ones, similar to np.ones((2,1))\nprint(x)\n\nx = tf.zeros(shape = (2,1)) # 2x3 matrix of zeros, similar to np.zeros((2,1))\nprint(x)\n\n\ntf.Tensor(\n[[1.]\n [1.]], shape=(2, 1), dtype=float32)\ntf.Tensor(\n[[0.]\n [0.]], shape=(2, 1), dtype=float32)\n\n\n\nx.__class__\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\n# Random tensors\n\n# create a tensor with random values from a normal distribution\nx = tf.random.normal(shape = (2,3), mean = 0, stddev = 1)\nprint(x)\n\n# create a tensor with random values from a uniform distribution\nx = tf.random.uniform(shape = (2,3), minval = 0, maxval = 1)\nprint(x)\n\ntf.Tensor(\n[[ 0.63700163  1.8413717   0.12851602]\n [-1.0153099  -1.3446143   1.6644784 ]], shape=(2, 3), dtype=float32)\ntf.Tensor(\n[[0.838336   0.8172778  0.42057896]\n [0.21810079 0.07237494 0.9222772 ]], shape=(2, 3), dtype=float32)\n\n\n\n# numpy array are assignable while tensors are not\nx = np.random.normal(loc = 0, scale = 1, size = (2,3))\nx[0,0] = 100\nprint(x)\n\n[[ 1.00000000e+02 -1.25304057e+00 -1.18967720e+00]\n [ 4.74877369e-01 -8.13430401e-02 -4.57822064e-01]]\n\n\n\n# numpy array are assignable while tensors are not\nx = tf.ones(shape = (2,3))\nx[0,0] = 100\nprint(x)\n\nTypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n\n\n\n# Creating a TensorFlow variable\nv = tf.Variable(initial_value = tf.random.normal(shape = (2,3)))\nprint(v)\nprint()\n\nv.assign(tf.zeros(shape = (2,3)))\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[-0.10799041,  2.325188  , -0.20042379],\n       [ 0.48759696,  0.53195345,  0.29525948]], dtype=float32)&gt;\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[0., 0., 0.],\n       [0., 0., 0.]], dtype=float32)&gt;\n\n\n\n# Assigning a value to a subset of a TensorFlow variable\nv[0,0].assign(100)\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[100.,   0.,   0.],\n       [  0.,   0.,   0.]], dtype=float32)&gt;\n\n\n\n# adding to the current value\nv.assign_add(tf.ones(shape = (2,3)))\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[101.,   1.,   1.],\n       [  1.,   1.,   1.]], dtype=float32)&gt;\n\n\n\n# just like numpy, TensorFlow offers a large collection of tensor operations to express\n# mathematical formulas.\na = tf.ones((2, 2))\nb = tf.square(a)\nc = tf.sqrt(a)\nd = b + c\ne = tf.matmul(a, b)\ne *= d\nprint(e)\n\ntf.Tensor(\n[[4. 4.]\n [4. 4.]], shape=(2, 2), dtype=float32)\n\n\nSo far, TensorFlow seems to look a lot like NumPy. But here’s something NumPy can’t do: retrieve the gradient of any differentiable expression with respect to any of its inputs. Just open a GradientTape scope, apply some computation to one or several input tensors, and retrieve the gradient of the result with respect to the inputs\n\n# Using the GradientTape\ninput_var = tf.Variable(initial_value = 3.0)\nwith tf.GradientTape() as tape:\n    result = tf.square(input_var)\ngrad = tape.gradient(result, input_var)\nprint(grad)\n\ntf.Tensor(6.0, shape=(), dtype=float32)\n\n\n\n# Using GradientTape with constant tensor inputs\ninput_var = tf.constant(3.0)\nwith tf.GradientTape() as tape:\n    tape.watch(input_var)\n    result = tf.square(input_var)\ngrad = tape.gradient(result, input_var)\nprint(grad)\n\ntf.Tensor(6.0, shape=(), dtype=float32)\n\n\n\n# Using nested gradient tapes to compute second-order gradients\ntime = tf.Variable(0.0)\nwith tf.GradientTape() as outer_tape:\n    with tf.GradientTape() as inner_tape:\n        position = 4.9 * time ** 2\n    speed = inner_tape.gradient(position, time) \nacceleration = outer_tape.gradient(speed, time)\n\nprint(speed)\nprint(acceleration)\n\n\ntf.Tensor(0.0, shape=(), dtype=float32)\ntf.Tensor(9.8, shape=(), dtype=float32)\n\n\n\n\n\n\n# Generating two classes of random points in a 2D plane\nnum_samples_per_class, num_classes = 1000, 2\nnegative_samples = np.random.multivariate_normal(mean = [0,3], cov = [[1,0.5],[0.5,1]], size = num_samples_per_class)\npositive_samples = np.random.multivariate_normal(mean = [3,0], cov = [[1,0.5],[0.5,1]], size = num_samples_per_class)\n\ninputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)\ntargets = np.vstack((np.zeros((num_samples_per_class, 1), dtype = 'float32'), np.ones((num_samples_per_class, 1), dtype = 'float32')))\n\n\nimport matplotlib.pyplot as plt\nplt.scatter(inputs[:, 0], inputs[:, 1], c=targets[:, 0])\nplt.show()\n\n\n\n\n\n\n\n\n\n# Creating the linear classifier variables\ninput_dim = 2\noutput_dim = 1\nW = tf.Variable(tf.random.normal(shape = (input_dim, output_dim)))\nb = tf.Variable(tf.random.normal(shape = (output_dim,)))\n\n\n\n# the forward pass\ndef model(inputs):\n    return tf.sigmoid(tf.matmul(inputs, W) + b)\n    \n# The mean squared error loss function\n\ndef entropy_loss(targets, predictions):\n    per_sample_losses = - targets * tf.math.log(predictions) - (1 - targets) * tf.math.log(1 - predictions)\n    return tf.reduce_mean(per_sample_losses)\n\n\n# training step \nlearning_rate = 0.1\ndef training_step(inputs, targets):\n    with tf.GradientTape() as tape:\n        predictions = model(inputs)\n        loss = square_loss(targets, predictions)\n        grad_loss_wrt_W, grad_loss_wrt_b = tape.gradient(loss, [W, b])\n        W.assign_sub(learning_rate * grad_loss_wrt_W)\n        b.assign_sub(learning_rate * grad_loss_wrt_b)\n        return loss\n\n\n\n\n\n# training loop/process/epoch\nfor step in range(100):\n    loss = training_step(inputs, targets)\n    print(f\"Loss at step {step}: {loss:.4f}\")\n\nLoss at step 0: 0.0495\nLoss at step 1: 0.0473\nLoss at step 2: 0.0454\nLoss at step 3: 0.0436\nLoss at step 4: 0.0420\nLoss at step 5: 0.0406\nLoss at step 6: 0.0392\nLoss at step 7: 0.0380\nLoss at step 8: 0.0369\nLoss at step 9: 0.0358\nLoss at step 10: 0.0348\nLoss at step 11: 0.0339\nLoss at step 12: 0.0330\nLoss at step 13: 0.0322\nLoss at step 14: 0.0315\nLoss at step 15: 0.0308\nLoss at step 16: 0.0301\nLoss at step 17: 0.0295\nLoss at step 18: 0.0289\nLoss at step 19: 0.0283\nLoss at step 20: 0.0278\nLoss at step 21: 0.0273\nLoss at step 22: 0.0268\nLoss at step 23: 0.0263\nLoss at step 24: 0.0259\nLoss at step 25: 0.0255\nLoss at step 26: 0.0251\nLoss at step 27: 0.0247\nLoss at step 28: 0.0243\nLoss at step 29: 0.0240\nLoss at step 30: 0.0236\nLoss at step 31: 0.0233\nLoss at step 32: 0.0230\nLoss at step 33: 0.0227\nLoss at step 34: 0.0224\nLoss at step 35: 0.0221\nLoss at step 36: 0.0218\nLoss at step 37: 0.0215\nLoss at step 38: 0.0213\nLoss at step 39: 0.0210\nLoss at step 40: 0.0208\nLoss at step 41: 0.0205\nLoss at step 42: 0.0203\nLoss at step 43: 0.0201\nLoss at step 44: 0.0198\nLoss at step 45: 0.0196\nLoss at step 46: 0.0194\nLoss at step 47: 0.0192\nLoss at step 48: 0.0190\nLoss at step 49: 0.0188\nLoss at step 50: 0.0186\nLoss at step 51: 0.0185\nLoss at step 52: 0.0183\nLoss at step 53: 0.0181\nLoss at step 54: 0.0179\nLoss at step 55: 0.0178\nLoss at step 56: 0.0176\nLoss at step 57: 0.0174\nLoss at step 58: 0.0173\nLoss at step 59: 0.0171\nLoss at step 60: 0.0170\nLoss at step 61: 0.0168\nLoss at step 62: 0.0167\nLoss at step 63: 0.0166\nLoss at step 64: 0.0164\nLoss at step 65: 0.0163\nLoss at step 66: 0.0162\nLoss at step 67: 0.0160\nLoss at step 68: 0.0159\nLoss at step 69: 0.0158\nLoss at step 70: 0.0157\nLoss at step 71: 0.0155\nLoss at step 72: 0.0154\nLoss at step 73: 0.0153\nLoss at step 74: 0.0152\nLoss at step 75: 0.0151\nLoss at step 76: 0.0150\nLoss at step 77: 0.0149\nLoss at step 78: 0.0148\nLoss at step 79: 0.0147\nLoss at step 80: 0.0146\nLoss at step 81: 0.0145\nLoss at step 82: 0.0144\nLoss at step 83: 0.0143\nLoss at step 84: 0.0142\nLoss at step 85: 0.0141\nLoss at step 86: 0.0140\nLoss at step 87: 0.0139\nLoss at step 88: 0.0138\nLoss at step 89: 0.0137\nLoss at step 90: 0.0136\nLoss at step 91: 0.0135\nLoss at step 92: 0.0135\nLoss at step 93: 0.0134\nLoss at step 94: 0.0133\nLoss at step 95: 0.0132\nLoss at step 96: 0.0131\nLoss at step 97: 0.0131\nLoss at step 98: 0.0130\nLoss at step 99: 0.0129\n\n\n\npredictions = model(inputs)\nprint(predictions)\nplt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:, 0] &gt; 0.5)\nplt.show()\n\ntf.Tensor(\n[[0.04117302]\n [0.02456259]\n [0.00931301]\n ...\n [0.9823857 ]\n [0.9144001 ]\n [0.98359877]], shape=(2000, 1), dtype=float32)\n\n\n\n\n\n\n\n\n\n\n\n\nSo, the APIs that we will often use when building a neural network in Keras are keras.layers and keras.models.\nSimply put, each keras.layers is responsible for data processing (taking input and producing output), while keras.models is the API for connecting one keras.layers to another.\n\n# Using the Keras Sequential API to build a linear classifier\nmodel = keras.Sequential([\n    keras.layers.InputLayer(input_shape  = (2,)), # input layers (stateless layer)\n    keras.layers.Dense(units = 10, activation = 'relu'), # FC  layer (stateful layer)\n    keras.layers.Dense(units = 1, activation = 'sigmoid'), # FC layer (stateful layer)\n])\n\n\n\n# plotting the model\nkeras.utils.plot_model(model, show_shapes = True, show_layer_names = True, rankdir = 'TB', expand_nested = False, dpi = 96)\n\n\n\n\n\n\n\n\nOnce the model architecture is defined, you still have to choose three more things:\n\nLoss function (objective function)—The quantity that will be minimized during training. It represents a measure of success for the task at hand\nOptimizer—Determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent (SGD).\nMetrics—The measures of success you want to monitor during training and validation, such as classification accuracy. Unlike the loss, training will not optimize directly for these metrics. As such, metrics don’t need to be differentiable.\n\nOnce you’ve picked your loss, optimizer, and metrics, you can use the built-in compile() and fit() methods to start training your model.\nThe compile() method configures the training process\n\n# we can pass strings to the loss and metrics arguments\nmodel.compile(optimizer=\"sgd\",\n              loss=\"sparse_binary_crossentropy\",\n              metrics=[\"accuracy\"])\n\n# or we can pass loss and metrics objects (both produce the same result)\nmodel.compile(optimizer=keras.optimizers.RMSprop(),\n              loss=keras.losses.BinaryCrossentropy(),\n              metrics=[keras.metrics.BinaryAccuracy()])\n\n\n# benefit of using objects is that we can configure them\n# dont run this code\n\nclass my_custom_loss(keras.losses.Loss):\n    pass\n\nclass my_custom_metric_1(keras.metrics.Metric):\n    pass\n\nclass my_custom_metric_2(keras.metrics.Metric):\n    pass \n\nmodel.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-4),\n              loss=my_custom_loss,\n              metrics=[my_custom_metric_1, my_custom_metric_2]\n)\n\nThe built-in loss functions and metrics can be found in keras.losses and keras.metrics documentation.\nAfter compile(), the next method is fit(), which implements the training loop itself. The key arguments of fit() include the data to train on, which is typically passed as NumPy arrays or a TensorFlow Dataset object. The number of epochs to train for is also specified, indicating how many times the training loop should iterate over the passed data. Additionally, the batch size to use within each epoch of mini-batch gradient descent is specified, indicating the number of training examples considered to compute the gradients for one weight update step.\nThe fit() method returns a History object, which contains a record of the loss and metric values observed during training. This record is stored as a dictionary, with keys being the name of the metrics and values being a list of values recorded at each epoch.\n\nmodel.compile(optimizer=\"rmsprop\",\n              loss=\"binary_crossentropy\",\n              metrics=[\"accuracy\"])\n\n\nx_train = inputs\ny_train = targets\nhistory = model.fit(x_train, y_train, batch_size=64, epochs=3, validation_split=0.2)\n\nEpoch 1/3\n25/25 [==============================] - 1s 17ms/step - loss: 0.1882 - accuracy: 0.9937 - val_loss: 0.2297 - val_accuracy: 0.9825\nEpoch 2/3\n25/25 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.9956 - val_loss: 0.1806 - val_accuracy: 0.9875\nEpoch 3/3\n25/25 [==============================] - 0s 5ms/step - loss: 0.1119 - accuracy: 0.9969 - val_loss: 0.1423 - val_accuracy: 0.9875\n\n\n\nhistory.history\n\n# plotting the loss and accuracy curves\nplt.plot(history.history['loss'], label = 'training loss')\nplt.plot(history.history['val_loss'], label = 'validation loss')\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n\ninstead of using model(new_data) to make predictions, we use model.predict(new_data) to make predictions on new data.\n\nnew_inputs = np.random.uniform(low = -1, high = 3, size = (256, 2))\npredictions = model.predict(new_inputs, batch_size=128)\n\n2/2 [==============================] - 0s 5ms/step\n\n\n\nprint(predictions)\n\n[[0.08076628]\n [0.09871415]\n [0.461069  ]\n [0.1276516 ]\n [0.4253592 ]\n [0.11114225]\n [0.25637963]\n [0.6989103 ]\n [0.30173382]\n [0.9123289 ]\n [0.2240395 ]\n [0.86962867]\n [0.2930864 ]\n [0.7623196 ]\n [0.8919245 ]\n [0.85015684]\n [0.9198693 ]\n [0.3118358 ]\n [0.29436693]\n [0.41225567]\n [0.62281114]\n [0.20957854]\n [0.2546269 ]\n [0.14533882]\n [0.39954668]\n [0.72597396]\n [0.72029203]\n [0.14848693]\n [0.89544886]\n [0.23350693]\n [0.13677543]\n [0.6027528 ]\n [0.04975716]\n [0.62043774]\n [0.12495781]\n [0.41638136]\n [0.40849304]\n [0.75599575]\n [0.10711117]\n [0.7210298 ]\n [0.16202773]\n [0.58192235]\n [0.08633437]\n [0.652066  ]\n [0.2231856 ]\n [0.24822547]\n [0.12730986]\n [0.29572365]\n [0.49881336]\n [0.26938245]\n [0.38568485]\n [0.541473  ]\n [0.36511543]\n [0.8816863 ]\n [0.19856545]\n [0.16809542]\n [0.6914996 ]\n [0.8430513 ]\n [0.63214254]\n [0.58684945]\n [0.39648739]\n [0.53129727]\n [0.28006184]\n [0.08559055]\n [0.59670126]\n [0.59945154]\n [0.14749527]\n [0.06490649]\n [0.8320455 ]\n [0.05914058]\n [0.3041497 ]\n [0.09569068]\n [0.6649947 ]\n [0.94342   ]\n [0.09614404]\n [0.3644968 ]\n [0.14465587]\n [0.26501516]\n [0.9422459 ]\n [0.65699536]\n [0.43875617]\n [0.8261676 ]\n [0.3133958 ]\n [0.08528826]\n [0.8137045 ]\n [0.39755583]\n [0.7245124 ]\n [0.8646786 ]\n [0.45526022]\n [0.1089195 ]\n [0.8604254 ]\n [0.1271291 ]\n [0.79923344]\n [0.567212  ]\n [0.6395396 ]\n [0.21270584]\n [0.31966135]\n [0.7625292 ]\n [0.08406034]\n [0.19414133]\n [0.08797505]\n [0.7415017 ]\n [0.22738719]\n [0.10201294]\n [0.59394836]\n [0.15788662]\n [0.17561007]\n [0.49508384]\n [0.5141838 ]\n [0.23656489]\n [0.06821493]\n [0.64166445]\n [0.64123726]\n [0.1364974 ]\n [0.48136458]\n [0.23007919]\n [0.4225439 ]\n [0.09589957]\n [0.59364146]\n [0.11582101]\n [0.6668776 ]\n [0.4442284 ]\n [0.55769634]\n [0.2534748 ]\n [0.16375524]\n [0.614452  ]\n [0.30898425]\n [0.17131504]\n [0.26918182]\n [0.7705017 ]\n [0.17490432]\n [0.8457906 ]\n [0.10823403]\n [0.6434072 ]\n [0.49629235]\n [0.74100196]\n [0.1309076 ]\n [0.51234263]\n [0.24122484]\n [0.28107983]\n [0.48853737]\n [0.5556593 ]\n [0.20772368]\n [0.14975631]\n [0.81019986]\n [0.66698325]\n [0.24100578]\n [0.05778646]\n [0.3698141 ]\n [0.91120934]\n [0.13073047]\n [0.8811323 ]\n [0.39972985]\n [0.85394675]\n [0.66812456]\n [0.48931998]\n [0.4537211 ]\n [0.24272834]\n [0.46721923]\n [0.18894011]\n [0.15586214]\n [0.9342805 ]\n [0.30149692]\n [0.4530156 ]\n [0.15281224]\n [0.934635  ]\n [0.3286551 ]\n [0.39501598]\n [0.2766213 ]\n [0.76871574]\n [0.67721754]\n [0.27642325]\n [0.6427387 ]\n [0.40615624]\n [0.48434645]\n [0.10460112]\n [0.9212326 ]\n [0.4006667 ]\n [0.24021053]\n [0.08514579]\n [0.21338533]\n [0.15677902]\n [0.30154642]\n [0.89081264]\n [0.7027856 ]\n [0.9134173 ]\n [0.53125733]\n [0.8643418 ]\n [0.18493299]\n [0.14839399]\n [0.08097934]\n [0.775004  ]\n [0.10088727]\n [0.06921735]\n [0.57083726]\n [0.15554827]\n [0.52106285]\n [0.32004246]\n [0.8300294 ]\n [0.11779615]\n [0.38728583]\n [0.6445805 ]\n [0.53003836]\n [0.37730247]\n [0.27931693]\n [0.9237554 ]\n [0.11332725]\n [0.81208193]\n [0.71356636]\n [0.06837884]\n [0.51704925]\n [0.0962389 ]\n [0.48069826]\n [0.41898265]\n [0.6878413 ]\n [0.39789453]\n [0.45776066]\n [0.08413587]\n [0.3788709 ]\n [0.7022963 ]\n [0.17948987]\n [0.25018048]\n [0.855532  ]\n [0.37432045]\n [0.49866596]\n [0.8766561 ]\n [0.10196138]\n [0.17670257]\n [0.6918482 ]\n [0.47626173]\n [0.11777903]\n [0.16932143]\n [0.7426942 ]\n [0.4911234 ]\n [0.8153233 ]\n [0.05526225]\n [0.34923232]\n [0.8453157 ]\n [0.06809001]\n [0.05592364]\n [0.11232523]\n [0.07958123]\n [0.1647198 ]\n [0.25184157]\n [0.27640557]\n [0.66381747]\n [0.6710669 ]\n [0.16793445]\n [0.9276973 ]\n [0.4350676 ]\n [0.27129552]\n [0.22650854]\n [0.76537824]\n [0.89772046]\n [0.3098401 ]\n [0.79777443]]\n\n\n\n# check the shape of the predictions\nprint(predictions.shape)\n\n(256, 1)\n\n\n\n# get class predictions\npredictions_class = np.round(predictions)\nprint(predictions_class)\n\n[[0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]]\n\n\n\n\n\nFor those interested in learning more about TensorFlow and Keras, I personally believe that the documentation available on the web is good enough. However, if you prefer reading a book, I recommend “Deep Learning with Python” by Francois Chollet, the creator of Keras. This book essentially summarizes the content of the documentation in a more cohesive and structured manner.\n\n\n\n\nChollet, F. (2021). Deep Learning with Python. Manning Publications.\nTensorFlow. (n.d.). Retrieved from https://www.tensorflow.org/\nKeras. (n.d.). Retrieved from https://keras.io/"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html#prerequisites",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html#prerequisites",
    "title": "Week 05 (Introduction to Keras and TensorFlow)",
    "section": "",
    "text": "# !pip install tensorflow # uncomment if you don't have tensorflow installed\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html#all-about-tensors-and-tensorflow",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html#all-about-tensors-and-tensorflow",
    "title": "Week 05 (Introduction to Keras and TensorFlow)",
    "section": "",
    "text": "# All-ones or all-zeros tensors\n\nx = tf.ones(shape = (2,1)) # 2x3 matrix of ones, similar to np.ones((2,1))\nprint(x)\n\nx = tf.zeros(shape = (2,1)) # 2x3 matrix of zeros, similar to np.zeros((2,1))\nprint(x)\n\n\ntf.Tensor(\n[[1.]\n [1.]], shape=(2, 1), dtype=float32)\ntf.Tensor(\n[[0.]\n [0.]], shape=(2, 1), dtype=float32)\n\n\n\nx.__class__\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\n# Random tensors\n\n# create a tensor with random values from a normal distribution\nx = tf.random.normal(shape = (2,3), mean = 0, stddev = 1)\nprint(x)\n\n# create a tensor with random values from a uniform distribution\nx = tf.random.uniform(shape = (2,3), minval = 0, maxval = 1)\nprint(x)\n\ntf.Tensor(\n[[ 0.63700163  1.8413717   0.12851602]\n [-1.0153099  -1.3446143   1.6644784 ]], shape=(2, 3), dtype=float32)\ntf.Tensor(\n[[0.838336   0.8172778  0.42057896]\n [0.21810079 0.07237494 0.9222772 ]], shape=(2, 3), dtype=float32)\n\n\n\n# numpy array are assignable while tensors are not\nx = np.random.normal(loc = 0, scale = 1, size = (2,3))\nx[0,0] = 100\nprint(x)\n\n[[ 1.00000000e+02 -1.25304057e+00 -1.18967720e+00]\n [ 4.74877369e-01 -8.13430401e-02 -4.57822064e-01]]\n\n\n\n# numpy array are assignable while tensors are not\nx = tf.ones(shape = (2,3))\nx[0,0] = 100\nprint(x)\n\nTypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n\n\n\n# Creating a TensorFlow variable\nv = tf.Variable(initial_value = tf.random.normal(shape = (2,3)))\nprint(v)\nprint()\n\nv.assign(tf.zeros(shape = (2,3)))\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[-0.10799041,  2.325188  , -0.20042379],\n       [ 0.48759696,  0.53195345,  0.29525948]], dtype=float32)&gt;\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[0., 0., 0.],\n       [0., 0., 0.]], dtype=float32)&gt;\n\n\n\n# Assigning a value to a subset of a TensorFlow variable\nv[0,0].assign(100)\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[100.,   0.,   0.],\n       [  0.,   0.,   0.]], dtype=float32)&gt;\n\n\n\n# adding to the current value\nv.assign_add(tf.ones(shape = (2,3)))\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[101.,   1.,   1.],\n       [  1.,   1.,   1.]], dtype=float32)&gt;\n\n\n\n# just like numpy, TensorFlow offers a large collection of tensor operations to express\n# mathematical formulas.\na = tf.ones((2, 2))\nb = tf.square(a)\nc = tf.sqrt(a)\nd = b + c\ne = tf.matmul(a, b)\ne *= d\nprint(e)\n\ntf.Tensor(\n[[4. 4.]\n [4. 4.]], shape=(2, 2), dtype=float32)\n\n\nSo far, TensorFlow seems to look a lot like NumPy. But here’s something NumPy can’t do: retrieve the gradient of any differentiable expression with respect to any of its inputs. Just open a GradientTape scope, apply some computation to one or several input tensors, and retrieve the gradient of the result with respect to the inputs\n\n# Using the GradientTape\ninput_var = tf.Variable(initial_value = 3.0)\nwith tf.GradientTape() as tape:\n    result = tf.square(input_var)\ngrad = tape.gradient(result, input_var)\nprint(grad)\n\ntf.Tensor(6.0, shape=(), dtype=float32)\n\n\n\n# Using GradientTape with constant tensor inputs\ninput_var = tf.constant(3.0)\nwith tf.GradientTape() as tape:\n    tape.watch(input_var)\n    result = tf.square(input_var)\ngrad = tape.gradient(result, input_var)\nprint(grad)\n\ntf.Tensor(6.0, shape=(), dtype=float32)\n\n\n\n# Using nested gradient tapes to compute second-order gradients\ntime = tf.Variable(0.0)\nwith tf.GradientTape() as outer_tape:\n    with tf.GradientTape() as inner_tape:\n        position = 4.9 * time ** 2\n    speed = inner_tape.gradient(position, time) \nacceleration = outer_tape.gradient(speed, time)\n\nprint(speed)\nprint(acceleration)\n\n\ntf.Tensor(0.0, shape=(), dtype=float32)\ntf.Tensor(9.8, shape=(), dtype=float32)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html#an-end-to-end-example-a-linear-classifier-in-pure-tensorflow",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html#an-end-to-end-example-a-linear-classifier-in-pure-tensorflow",
    "title": "Week 05 (Introduction to Keras and TensorFlow)",
    "section": "",
    "text": "# Generating two classes of random points in a 2D plane\nnum_samples_per_class, num_classes = 1000, 2\nnegative_samples = np.random.multivariate_normal(mean = [0,3], cov = [[1,0.5],[0.5,1]], size = num_samples_per_class)\npositive_samples = np.random.multivariate_normal(mean = [3,0], cov = [[1,0.5],[0.5,1]], size = num_samples_per_class)\n\ninputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)\ntargets = np.vstack((np.zeros((num_samples_per_class, 1), dtype = 'float32'), np.ones((num_samples_per_class, 1), dtype = 'float32')))\n\n\nimport matplotlib.pyplot as plt\nplt.scatter(inputs[:, 0], inputs[:, 1], c=targets[:, 0])\nplt.show()\n\n\n\n\n\n\n\n\n\n# Creating the linear classifier variables\ninput_dim = 2\noutput_dim = 1\nW = tf.Variable(tf.random.normal(shape = (input_dim, output_dim)))\nb = tf.Variable(tf.random.normal(shape = (output_dim,)))\n\n\n\n# the forward pass\ndef model(inputs):\n    return tf.sigmoid(tf.matmul(inputs, W) + b)\n    \n# The mean squared error loss function\n\ndef entropy_loss(targets, predictions):\n    per_sample_losses = - targets * tf.math.log(predictions) - (1 - targets) * tf.math.log(1 - predictions)\n    return tf.reduce_mean(per_sample_losses)\n\n\n# training step \nlearning_rate = 0.1\ndef training_step(inputs, targets):\n    with tf.GradientTape() as tape:\n        predictions = model(inputs)\n        loss = square_loss(targets, predictions)\n        grad_loss_wrt_W, grad_loss_wrt_b = tape.gradient(loss, [W, b])\n        W.assign_sub(learning_rate * grad_loss_wrt_W)\n        b.assign_sub(learning_rate * grad_loss_wrt_b)\n        return loss\n\n\n\n\n\n# training loop/process/epoch\nfor step in range(100):\n    loss = training_step(inputs, targets)\n    print(f\"Loss at step {step}: {loss:.4f}\")\n\nLoss at step 0: 0.0495\nLoss at step 1: 0.0473\nLoss at step 2: 0.0454\nLoss at step 3: 0.0436\nLoss at step 4: 0.0420\nLoss at step 5: 0.0406\nLoss at step 6: 0.0392\nLoss at step 7: 0.0380\nLoss at step 8: 0.0369\nLoss at step 9: 0.0358\nLoss at step 10: 0.0348\nLoss at step 11: 0.0339\nLoss at step 12: 0.0330\nLoss at step 13: 0.0322\nLoss at step 14: 0.0315\nLoss at step 15: 0.0308\nLoss at step 16: 0.0301\nLoss at step 17: 0.0295\nLoss at step 18: 0.0289\nLoss at step 19: 0.0283\nLoss at step 20: 0.0278\nLoss at step 21: 0.0273\nLoss at step 22: 0.0268\nLoss at step 23: 0.0263\nLoss at step 24: 0.0259\nLoss at step 25: 0.0255\nLoss at step 26: 0.0251\nLoss at step 27: 0.0247\nLoss at step 28: 0.0243\nLoss at step 29: 0.0240\nLoss at step 30: 0.0236\nLoss at step 31: 0.0233\nLoss at step 32: 0.0230\nLoss at step 33: 0.0227\nLoss at step 34: 0.0224\nLoss at step 35: 0.0221\nLoss at step 36: 0.0218\nLoss at step 37: 0.0215\nLoss at step 38: 0.0213\nLoss at step 39: 0.0210\nLoss at step 40: 0.0208\nLoss at step 41: 0.0205\nLoss at step 42: 0.0203\nLoss at step 43: 0.0201\nLoss at step 44: 0.0198\nLoss at step 45: 0.0196\nLoss at step 46: 0.0194\nLoss at step 47: 0.0192\nLoss at step 48: 0.0190\nLoss at step 49: 0.0188\nLoss at step 50: 0.0186\nLoss at step 51: 0.0185\nLoss at step 52: 0.0183\nLoss at step 53: 0.0181\nLoss at step 54: 0.0179\nLoss at step 55: 0.0178\nLoss at step 56: 0.0176\nLoss at step 57: 0.0174\nLoss at step 58: 0.0173\nLoss at step 59: 0.0171\nLoss at step 60: 0.0170\nLoss at step 61: 0.0168\nLoss at step 62: 0.0167\nLoss at step 63: 0.0166\nLoss at step 64: 0.0164\nLoss at step 65: 0.0163\nLoss at step 66: 0.0162\nLoss at step 67: 0.0160\nLoss at step 68: 0.0159\nLoss at step 69: 0.0158\nLoss at step 70: 0.0157\nLoss at step 71: 0.0155\nLoss at step 72: 0.0154\nLoss at step 73: 0.0153\nLoss at step 74: 0.0152\nLoss at step 75: 0.0151\nLoss at step 76: 0.0150\nLoss at step 77: 0.0149\nLoss at step 78: 0.0148\nLoss at step 79: 0.0147\nLoss at step 80: 0.0146\nLoss at step 81: 0.0145\nLoss at step 82: 0.0144\nLoss at step 83: 0.0143\nLoss at step 84: 0.0142\nLoss at step 85: 0.0141\nLoss at step 86: 0.0140\nLoss at step 87: 0.0139\nLoss at step 88: 0.0138\nLoss at step 89: 0.0137\nLoss at step 90: 0.0136\nLoss at step 91: 0.0135\nLoss at step 92: 0.0135\nLoss at step 93: 0.0134\nLoss at step 94: 0.0133\nLoss at step 95: 0.0132\nLoss at step 96: 0.0131\nLoss at step 97: 0.0131\nLoss at step 98: 0.0130\nLoss at step 99: 0.0129\n\n\n\npredictions = model(inputs)\nprint(predictions)\nplt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:, 0] &gt; 0.5)\nplt.show()\n\ntf.Tensor(\n[[0.04117302]\n [0.02456259]\n [0.00931301]\n ...\n [0.9823857 ]\n [0.9144001 ]\n [0.98359877]], shape=(2000, 1), dtype=float32)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html#deep-learning-with-keras",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html#deep-learning-with-keras",
    "title": "Week 05 (Introduction to Keras and TensorFlow)",
    "section": "",
    "text": "So, the APIs that we will often use when building a neural network in Keras are keras.layers and keras.models.\nSimply put, each keras.layers is responsible for data processing (taking input and producing output), while keras.models is the API for connecting one keras.layers to another.\n\n# Using the Keras Sequential API to build a linear classifier\nmodel = keras.Sequential([\n    keras.layers.InputLayer(input_shape  = (2,)), # input layers (stateless layer)\n    keras.layers.Dense(units = 10, activation = 'relu'), # FC  layer (stateful layer)\n    keras.layers.Dense(units = 1, activation = 'sigmoid'), # FC layer (stateful layer)\n])\n\n\n\n# plotting the model\nkeras.utils.plot_model(model, show_shapes = True, show_layer_names = True, rankdir = 'TB', expand_nested = False, dpi = 96)\n\n\n\n\n\n\n\n\nOnce the model architecture is defined, you still have to choose three more things:\n\nLoss function (objective function)—The quantity that will be minimized during training. It represents a measure of success for the task at hand\nOptimizer—Determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent (SGD).\nMetrics—The measures of success you want to monitor during training and validation, such as classification accuracy. Unlike the loss, training will not optimize directly for these metrics. As such, metrics don’t need to be differentiable.\n\nOnce you’ve picked your loss, optimizer, and metrics, you can use the built-in compile() and fit() methods to start training your model.\nThe compile() method configures the training process\n\n# we can pass strings to the loss and metrics arguments\nmodel.compile(optimizer=\"sgd\",\n              loss=\"sparse_binary_crossentropy\",\n              metrics=[\"accuracy\"])\n\n# or we can pass loss and metrics objects (both produce the same result)\nmodel.compile(optimizer=keras.optimizers.RMSprop(),\n              loss=keras.losses.BinaryCrossentropy(),\n              metrics=[keras.metrics.BinaryAccuracy()])\n\n\n# benefit of using objects is that we can configure them\n# dont run this code\n\nclass my_custom_loss(keras.losses.Loss):\n    pass\n\nclass my_custom_metric_1(keras.metrics.Metric):\n    pass\n\nclass my_custom_metric_2(keras.metrics.Metric):\n    pass \n\nmodel.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-4),\n              loss=my_custom_loss,\n              metrics=[my_custom_metric_1, my_custom_metric_2]\n)\n\nThe built-in loss functions and metrics can be found in keras.losses and keras.metrics documentation.\nAfter compile(), the next method is fit(), which implements the training loop itself. The key arguments of fit() include the data to train on, which is typically passed as NumPy arrays or a TensorFlow Dataset object. The number of epochs to train for is also specified, indicating how many times the training loop should iterate over the passed data. Additionally, the batch size to use within each epoch of mini-batch gradient descent is specified, indicating the number of training examples considered to compute the gradients for one weight update step.\nThe fit() method returns a History object, which contains a record of the loss and metric values observed during training. This record is stored as a dictionary, with keys being the name of the metrics and values being a list of values recorded at each epoch.\n\nmodel.compile(optimizer=\"rmsprop\",\n              loss=\"binary_crossentropy\",\n              metrics=[\"accuracy\"])\n\n\nx_train = inputs\ny_train = targets\nhistory = model.fit(x_train, y_train, batch_size=64, epochs=3, validation_split=0.2)\n\nEpoch 1/3\n25/25 [==============================] - 1s 17ms/step - loss: 0.1882 - accuracy: 0.9937 - val_loss: 0.2297 - val_accuracy: 0.9825\nEpoch 2/3\n25/25 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.9956 - val_loss: 0.1806 - val_accuracy: 0.9875\nEpoch 3/3\n25/25 [==============================] - 0s 5ms/step - loss: 0.1119 - accuracy: 0.9969 - val_loss: 0.1423 - val_accuracy: 0.9875\n\n\n\nhistory.history\n\n# plotting the loss and accuracy curves\nplt.plot(history.history['loss'], label = 'training loss')\nplt.plot(history.history['val_loss'], label = 'validation loss')\nplt.legend()"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html#inference-using-a-model-after-training",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html#inference-using-a-model-after-training",
    "title": "Week 05 (Introduction to Keras and TensorFlow)",
    "section": "",
    "text": "instead of using model(new_data) to make predictions, we use model.predict(new_data) to make predictions on new data.\n\nnew_inputs = np.random.uniform(low = -1, high = 3, size = (256, 2))\npredictions = model.predict(new_inputs, batch_size=128)\n\n2/2 [==============================] - 0s 5ms/step\n\n\n\nprint(predictions)\n\n[[0.08076628]\n [0.09871415]\n [0.461069  ]\n [0.1276516 ]\n [0.4253592 ]\n [0.11114225]\n [0.25637963]\n [0.6989103 ]\n [0.30173382]\n [0.9123289 ]\n [0.2240395 ]\n [0.86962867]\n [0.2930864 ]\n [0.7623196 ]\n [0.8919245 ]\n [0.85015684]\n [0.9198693 ]\n [0.3118358 ]\n [0.29436693]\n [0.41225567]\n [0.62281114]\n [0.20957854]\n [0.2546269 ]\n [0.14533882]\n [0.39954668]\n [0.72597396]\n [0.72029203]\n [0.14848693]\n [0.89544886]\n [0.23350693]\n [0.13677543]\n [0.6027528 ]\n [0.04975716]\n [0.62043774]\n [0.12495781]\n [0.41638136]\n [0.40849304]\n [0.75599575]\n [0.10711117]\n [0.7210298 ]\n [0.16202773]\n [0.58192235]\n [0.08633437]\n [0.652066  ]\n [0.2231856 ]\n [0.24822547]\n [0.12730986]\n [0.29572365]\n [0.49881336]\n [0.26938245]\n [0.38568485]\n [0.541473  ]\n [0.36511543]\n [0.8816863 ]\n [0.19856545]\n [0.16809542]\n [0.6914996 ]\n [0.8430513 ]\n [0.63214254]\n [0.58684945]\n [0.39648739]\n [0.53129727]\n [0.28006184]\n [0.08559055]\n [0.59670126]\n [0.59945154]\n [0.14749527]\n [0.06490649]\n [0.8320455 ]\n [0.05914058]\n [0.3041497 ]\n [0.09569068]\n [0.6649947 ]\n [0.94342   ]\n [0.09614404]\n [0.3644968 ]\n [0.14465587]\n [0.26501516]\n [0.9422459 ]\n [0.65699536]\n [0.43875617]\n [0.8261676 ]\n [0.3133958 ]\n [0.08528826]\n [0.8137045 ]\n [0.39755583]\n [0.7245124 ]\n [0.8646786 ]\n [0.45526022]\n [0.1089195 ]\n [0.8604254 ]\n [0.1271291 ]\n [0.79923344]\n [0.567212  ]\n [0.6395396 ]\n [0.21270584]\n [0.31966135]\n [0.7625292 ]\n [0.08406034]\n [0.19414133]\n [0.08797505]\n [0.7415017 ]\n [0.22738719]\n [0.10201294]\n [0.59394836]\n [0.15788662]\n [0.17561007]\n [0.49508384]\n [0.5141838 ]\n [0.23656489]\n [0.06821493]\n [0.64166445]\n [0.64123726]\n [0.1364974 ]\n [0.48136458]\n [0.23007919]\n [0.4225439 ]\n [0.09589957]\n [0.59364146]\n [0.11582101]\n [0.6668776 ]\n [0.4442284 ]\n [0.55769634]\n [0.2534748 ]\n [0.16375524]\n [0.614452  ]\n [0.30898425]\n [0.17131504]\n [0.26918182]\n [0.7705017 ]\n [0.17490432]\n [0.8457906 ]\n [0.10823403]\n [0.6434072 ]\n [0.49629235]\n [0.74100196]\n [0.1309076 ]\n [0.51234263]\n [0.24122484]\n [0.28107983]\n [0.48853737]\n [0.5556593 ]\n [0.20772368]\n [0.14975631]\n [0.81019986]\n [0.66698325]\n [0.24100578]\n [0.05778646]\n [0.3698141 ]\n [0.91120934]\n [0.13073047]\n [0.8811323 ]\n [0.39972985]\n [0.85394675]\n [0.66812456]\n [0.48931998]\n [0.4537211 ]\n [0.24272834]\n [0.46721923]\n [0.18894011]\n [0.15586214]\n [0.9342805 ]\n [0.30149692]\n [0.4530156 ]\n [0.15281224]\n [0.934635  ]\n [0.3286551 ]\n [0.39501598]\n [0.2766213 ]\n [0.76871574]\n [0.67721754]\n [0.27642325]\n [0.6427387 ]\n [0.40615624]\n [0.48434645]\n [0.10460112]\n [0.9212326 ]\n [0.4006667 ]\n [0.24021053]\n [0.08514579]\n [0.21338533]\n [0.15677902]\n [0.30154642]\n [0.89081264]\n [0.7027856 ]\n [0.9134173 ]\n [0.53125733]\n [0.8643418 ]\n [0.18493299]\n [0.14839399]\n [0.08097934]\n [0.775004  ]\n [0.10088727]\n [0.06921735]\n [0.57083726]\n [0.15554827]\n [0.52106285]\n [0.32004246]\n [0.8300294 ]\n [0.11779615]\n [0.38728583]\n [0.6445805 ]\n [0.53003836]\n [0.37730247]\n [0.27931693]\n [0.9237554 ]\n [0.11332725]\n [0.81208193]\n [0.71356636]\n [0.06837884]\n [0.51704925]\n [0.0962389 ]\n [0.48069826]\n [0.41898265]\n [0.6878413 ]\n [0.39789453]\n [0.45776066]\n [0.08413587]\n [0.3788709 ]\n [0.7022963 ]\n [0.17948987]\n [0.25018048]\n [0.855532  ]\n [0.37432045]\n [0.49866596]\n [0.8766561 ]\n [0.10196138]\n [0.17670257]\n [0.6918482 ]\n [0.47626173]\n [0.11777903]\n [0.16932143]\n [0.7426942 ]\n [0.4911234 ]\n [0.8153233 ]\n [0.05526225]\n [0.34923232]\n [0.8453157 ]\n [0.06809001]\n [0.05592364]\n [0.11232523]\n [0.07958123]\n [0.1647198 ]\n [0.25184157]\n [0.27640557]\n [0.66381747]\n [0.6710669 ]\n [0.16793445]\n [0.9276973 ]\n [0.4350676 ]\n [0.27129552]\n [0.22650854]\n [0.76537824]\n [0.89772046]\n [0.3098401 ]\n [0.79777443]]\n\n\n\n# check the shape of the predictions\nprint(predictions.shape)\n\n(256, 1)\n\n\n\n# get class predictions\npredictions_class = np.round(predictions)\nprint(predictions_class)\n\n[[0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]]"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html#additional-notes",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html#additional-notes",
    "title": "Week 05 (Introduction to Keras and TensorFlow)",
    "section": "",
    "text": "For those interested in learning more about TensorFlow and Keras, I personally believe that the documentation available on the web is good enough. However, if you prefer reading a book, I recommend “Deep Learning with Python” by Francois Chollet, the creator of Keras. This book essentially summarizes the content of the documentation in a more cohesive and structured manner."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html#references",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html#references",
    "title": "Week 05 (Introduction to Keras and TensorFlow)",
    "section": "",
    "text": "Chollet, F. (2021). Deep Learning with Python. Manning Publications.\nTensorFlow. (n.d.). Retrieved from https://www.tensorflow.org/\nKeras. (n.d.). Retrieved from https://keras.io/"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-03.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-03.html",
    "title": "Week 03(End to End Machine Learning)",
    "section": "",
    "text": "Kembali ke Sains Data\n\n\n\n\nimport library yang dibutuhkan terlebih dahulu untuk pengolahan dan visualisasi data.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\n\n\nUpload dataset yang akan digunakan dan observasi click disini\n\nsalary =  pd.read_csv('Salary_dataset.csv')\nsalary\n\n\n\n\n\n\n\n\nUnnamed: 0\nYearsExperience\nSalary\n\n\n\n\n0\n0\n1.2\n39344.0\n\n\n1\n1\n1.4\n46206.0\n\n\n2\n2\n1.6\n37732.0\n\n\n3\n3\n2.1\n43526.0\n\n\n4\n4\n2.3\n39892.0\n\n\n5\n5\n3.0\n56643.0\n\n\n6\n6\n3.1\n60151.0\n\n\n7\n7\n3.3\n54446.0\n\n\n8\n8\n3.3\n64446.0\n\n\n9\n9\n3.8\n57190.0\n\n\n10\n10\n4.0\n63219.0\n\n\n11\n11\n4.1\n55795.0\n\n\n12\n12\n4.1\n56958.0\n\n\n13\n13\n4.2\n57082.0\n\n\n14\n14\n4.6\n61112.0\n\n\n15\n15\n5.0\n67939.0\n\n\n16\n16\n5.2\n66030.0\n\n\n17\n17\n5.4\n83089.0\n\n\n18\n18\n6.0\n81364.0\n\n\n19\n19\n6.1\n93941.0\n\n\n20\n20\n6.9\n91739.0\n\n\n21\n21\n7.2\n98274.0\n\n\n22\n22\n8.0\n101303.0\n\n\n23\n23\n8.3\n113813.0\n\n\n24\n24\n8.8\n109432.0\n\n\n25\n25\n9.1\n105583.0\n\n\n26\n26\n9.6\n116970.0\n\n\n27\n27\n9.7\n112636.0\n\n\n28\n28\n10.4\n122392.0\n\n\n29\n29\n10.6\n121873.0\n\n\n\n\n\n\n\n\nsalary.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 30 entries, 0 to 29\nData columns (total 3 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   Unnamed: 0       30 non-null     int64  \n 1   YearsExperience  30 non-null     float64\n 2   Salary           30 non-null     float64\ndtypes: float64(2), int64(1)\nmemory usage: 848.0 bytes\n\n\n\n\n\nMelihat jumlah data null pada dataset\n\nsalary.isna().sum()\n\nUnnamed: 0         0\nYearsExperience    0\nSalary             0\ndtype: int64\n\n\nMelihat jumlah data duplikat pada dataset\n\nsalary.duplicated().sum()\n\n0\n\n\nMenghapus kolom ‘Unnamed :0’ dari DataFrame secara permanen\n\nsalary.drop('Unnamed: 0', axis=1, inplace=True)\n\n\nsalary\n\n\n\n\n\n\n\n\nYearsExperience\nSalary\n\n\n\n\n0\n1.2\n39344.0\n\n\n1\n1.4\n46206.0\n\n\n2\n1.6\n37732.0\n\n\n3\n2.1\n43526.0\n\n\n4\n2.3\n39892.0\n\n\n5\n3.0\n56643.0\n\n\n6\n3.1\n60151.0\n\n\n7\n3.3\n54446.0\n\n\n8\n3.3\n64446.0\n\n\n9\n3.8\n57190.0\n\n\n10\n4.0\n63219.0\n\n\n11\n4.1\n55795.0\n\n\n12\n4.1\n56958.0\n\n\n13\n4.2\n57082.0\n\n\n14\n4.6\n61112.0\n\n\n15\n5.0\n67939.0\n\n\n16\n5.2\n66030.0\n\n\n17\n5.4\n83089.0\n\n\n18\n6.0\n81364.0\n\n\n19\n6.1\n93941.0\n\n\n20\n6.9\n91739.0\n\n\n21\n7.2\n98274.0\n\n\n22\n8.0\n101303.0\n\n\n23\n8.3\n113813.0\n\n\n24\n8.8\n109432.0\n\n\n25\n9.1\n105583.0\n\n\n26\n9.6\n116970.0\n\n\n27\n9.7\n112636.0\n\n\n28\n10.4\n122392.0\n\n\n29\n10.6\n121873.0\n\n\n\n\n\n\n\n\n\n\nMengubah setiap nilai di kolom Salary dan mengubah nama kolomnya di DataFrame secara permanen\n\nsalary['Salary'] = salary['Salary']/1000\nsalary.rename(columns={'Salary' : 'Salary (1000 $)'}, inplace=True)\n\nMelihat statistik deskriptif dari DataFrame\n\nsalary.describe()\n\n\n\n\n\n\n\n\nYearsExperience\nSalary (1000 $)\n\n\n\n\ncount\n30.000000\n30.00000\n\n\nmean\n5.413333\n76.00400\n\n\nstd\n2.837888\n27.41443\n\n\nmin\n1.200000\n37.73200\n\n\n25%\n3.300000\n56.72175\n\n\n50%\n4.800000\n65.23800\n\n\n75%\n7.800000\n100.54575\n\n\nmax\n10.600000\n122.39200\n\n\n\n\n\n\n\n\nplt.scatter(salary['YearsExperience'],salary['Salary (1000 $)'])\nplt.plot(salary['YearsExperience'],salary['Salary (1000 $)'])\nplt.xlabel('Year Experience')\nplt.ylabel('Salary (1000 $)')\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, (ax_box, ax_hist) = plt.subplots(2, 1, figsize=(6, 6), sharex='col',\n                                      gridspec_kw={\"height_ratios\": (.15, .85)})\n\nsns.boxplot(data=salary, x='Salary (1000 $)', ax=ax_box, color='crimson')\nsns.histplot(data=salary, x='Salary (1000 $)', ax=ax_hist, binwidth=10.)\nsns.rugplot(data=salary, x='Salary (1000 $)', ax=ax_hist, height=0.05, color='gold', lw=2.)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax_box, ax_hist) = plt.subplots(2, 1, figsize=(6, 6), sharex='col',\n                                      gridspec_kw={\"height_ratios\": (.15, .85)})\n\nsns.boxplot(data=salary, x='YearsExperience', ax=ax_box, color='crimson')\nsns.histplot(data=salary, x='YearsExperience', ax=ax_hist, binwidth=1.)\nsns.rugplot(data=salary, x='YearsExperience', ax=ax_hist, height=0.05, color='gold', lw=2.)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\ncorr = salary.corr()\nsns.heatmap(corr, vmin=-1, center=0, vmax=1, annot=True)\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.subplots(figsize=(6,6))\n\nsns.regplot(data = salary, x='YearsExperience', y='Salary (1000 $)', color='k', marker='+')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nKarena pada dataset ini, fitur yang ada hanya 2, tidak ada masalah dan data sudah rapi, maka untuk step feature engineering akan skip dan lanjut ke tahap modelling.\n\n\n\n\nX = salary[['YearsExperience']]\ny = salary[['Salary (1000 $)']]\n\n\nX\n\n\n\n\n\n\n\n\nYearsExperience\n\n\n\n\n0\n1.2\n\n\n1\n1.4\n\n\n2\n1.6\n\n\n3\n2.1\n\n\n4\n2.3\n\n\n5\n3.0\n\n\n6\n3.1\n\n\n7\n3.3\n\n\n8\n3.3\n\n\n9\n3.8\n\n\n10\n4.0\n\n\n11\n4.1\n\n\n12\n4.1\n\n\n13\n4.2\n\n\n14\n4.6\n\n\n15\n5.0\n\n\n16\n5.2\n\n\n17\n5.4\n\n\n18\n6.0\n\n\n19\n6.1\n\n\n20\n6.9\n\n\n21\n7.2\n\n\n22\n8.0\n\n\n23\n8.3\n\n\n24\n8.8\n\n\n25\n9.1\n\n\n26\n9.6\n\n\n27\n9.7\n\n\n28\n10.4\n\n\n29\n10.6\n\n\n\n\n\n\n\n\ny\n\n\n\n\n\n\n\n\nSalary (1000 $)\n\n\n\n\n0\n39.344\n\n\n1\n46.206\n\n\n2\n37.732\n\n\n3\n43.526\n\n\n4\n39.892\n\n\n5\n56.643\n\n\n6\n60.151\n\n\n7\n54.446\n\n\n8\n64.446\n\n\n9\n57.190\n\n\n10\n63.219\n\n\n11\n55.795\n\n\n12\n56.958\n\n\n13\n57.082\n\n\n14\n61.112\n\n\n15\n67.939\n\n\n16\n66.030\n\n\n17\n83.089\n\n\n18\n81.364\n\n\n19\n93.941\n\n\n20\n91.739\n\n\n21\n98.274\n\n\n22\n101.303\n\n\n23\n113.813\n\n\n24\n109.432\n\n\n25\n105.583\n\n\n26\n116.970\n\n\n27\n112.636\n\n\n28\n122.392\n\n\n29\n121.873\n\n\n\n\n\n\n\nSplit dataset menjadi data train dan data test dengan komposisi pembagian yang sering digunakan\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape\n\n((24, 1), (6, 1), (24, 1), (6, 1))\n\n\nImport terlebih dahulu package yang akan digunakan untuk modelling\n\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train,y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\ny_pred = lr.predict(X_test)\n\n\nfrom sklearn.metrics import mean_squared_error, r2_score\nprint(mean_squared_error(y_pred,y_test))\nprint(r2_score(y_pred,y_test))\n\n49.830096855908344\n0.8961838737587329\n\n\n \nDimana:\n\\(n\\) : jumlah data\n\\(Y_i\\) : nilai actual\n\\(\\hat{Y}_{i}\\): nilai predict\n\\(RSS\\) : sum of squared residuals\n\\(TSS\\) : total sum of squares\n\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n\n[[115.79121011 112.636     ]\n [ 71.49927809  67.939     ]\n [102.59786866 113.813     ]\n [ 75.26880422  83.089     ]\n [ 55.47879205  64.446     ]\n [ 60.19069971  57.19      ]]\n\n\n\n\n\n\n\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n\n\n\nheart = pd.read_csv('heart.csv')\nheart\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrtbps\nchol\nfbs\nrestecg\nthalachh\nexng\noldpeak\nslp\ncaa\nthall\noutput\n\n\n\n\n0\n63\n1\n3\n145\n233\n1\n0\n150\n0\n2.3\n0\n0\n1\n1\n\n\n1\n37\n1\n2\n130\n250\n0\n1\n187\n0\n3.5\n0\n0\n2\n1\n\n\n2\n41\n0\n1\n130\n204\n0\n0\n172\n0\n1.4\n2\n0\n2\n1\n\n\n3\n56\n1\n1\n120\n236\n0\n1\n178\n0\n0.8\n2\n0\n2\n1\n\n\n4\n57\n0\n0\n120\n354\n0\n1\n163\n1\n0.6\n2\n0\n2\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n298\n57\n0\n0\n140\n241\n0\n1\n123\n1\n0.2\n1\n0\n3\n0\n\n\n299\n45\n1\n3\n110\n264\n0\n1\n132\n0\n1.2\n1\n0\n3\n0\n\n\n300\n68\n1\n0\n144\n193\n1\n1\n141\n0\n3.4\n1\n2\n3\n0\n\n\n301\n57\n1\n0\n130\n131\n0\n1\n115\n1\n1.2\n1\n1\n3\n0\n\n\n302\n57\n0\n1\n130\n236\n0\n0\n174\n0\n0.0\n1\n1\n2\n0\n\n\n\n\n303 rows × 14 columns\n\n\n\n\n# Membaca .txt tentang kolom - kolom dataset yang diberikan pada soal\nwith open('about dataset.txt', 'r') as f:\n  print(f.read())\n\nAbout datasets\n1. age - age in years \n2. sex - sex (1 = male; 0 = female) \n3. cp - chest pain type (1 = typical angina; 2 = atypical angina; 3 = non-anginal pain; 0 = asymptomatic) \n4. trestbps - resting blood pressure (in mm Hg on admission to the hospital) \n5. chol - serum cholestoral in mg/dl \n6. fbs - fasting blood sugar &gt; 120 mg/dl (1 = true; 0 = false) \n7. restecg - resting electrocardiographic results (1 = normal; 2 = having ST-T wave abnormality; 0 = hypertrophy) \n8. thalach - maximum heart rate achieved \n9. exang - exercise induced angina (1 = yes; 0 = no) \n10. oldpeak - ST depression induced by exercise relative to rest \n11. slope - the slope of the peak exercise ST segment (2 = upsloping; 1 = flat; 0 = downsloping) \n12. ca - number of major vessels (0-3) colored by flourosopy \n13. thal - 2 = normal; 1 = fixed defect; 3 = reversable defect \n14. output - the predicted attribute - diagnosis of heart disease (0 = less chance of heart attack, 1 = higher chance of heart attack)\n\n\n\n\nheart.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 303 entries, 0 to 302\nData columns (total 14 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       303 non-null    int64  \n 1   sex       303 non-null    int64  \n 2   cp        303 non-null    int64  \n 3   trtbps    303 non-null    int64  \n 4   chol      303 non-null    int64  \n 5   fbs       303 non-null    int64  \n 6   restecg   303 non-null    int64  \n 7   thalachh  303 non-null    int64  \n 8   exng      303 non-null    int64  \n 9   oldpeak   303 non-null    float64\n 10  slp       303 non-null    int64  \n 11  caa       303 non-null    int64  \n 12  thall     303 non-null    int64  \n 13  output    303 non-null    int64  \ndtypes: float64(1), int64(13)\nmemory usage: 33.3 KB\n\n\n\nheart.output.value_counts()\n\n1    165\n0    138\nName: output, dtype: int64\n\n\n\n\n\n\nheart.describe()\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrtbps\nchol\nfbs\nrestecg\nthalachh\nexng\noldpeak\nslp\ncaa\nthall\noutput\n\n\n\n\ncount\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n\n\nmean\n54.366337\n0.683168\n0.966997\n131.623762\n246.264026\n0.148515\n0.528053\n149.646865\n0.326733\n1.039604\n1.399340\n0.729373\n2.313531\n0.544554\n\n\nstd\n9.082101\n0.466011\n1.032052\n17.538143\n51.830751\n0.356198\n0.525860\n22.905161\n0.469794\n1.161075\n0.616226\n1.022606\n0.612277\n0.498835\n\n\nmin\n29.000000\n0.000000\n0.000000\n94.000000\n126.000000\n0.000000\n0.000000\n71.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n47.500000\n0.000000\n0.000000\n120.000000\n211.000000\n0.000000\n0.000000\n133.500000\n0.000000\n0.000000\n1.000000\n0.000000\n2.000000\n0.000000\n\n\n50%\n55.000000\n1.000000\n1.000000\n130.000000\n240.000000\n0.000000\n1.000000\n153.000000\n0.000000\n0.800000\n1.000000\n0.000000\n2.000000\n1.000000\n\n\n75%\n61.000000\n1.000000\n2.000000\n140.000000\n274.500000\n0.000000\n1.000000\n166.000000\n1.000000\n1.600000\n2.000000\n1.000000\n3.000000\n1.000000\n\n\nmax\n77.000000\n1.000000\n3.000000\n200.000000\n564.000000\n1.000000\n2.000000\n202.000000\n1.000000\n6.200000\n2.000000\n4.000000\n3.000000\n1.000000\n\n\n\n\n\n\n\n\npd.plotting.scatter_matrix(heart[['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']], figsize=(15,12)) # plot data yang numerik dan kontinu\nplt.show()\n\n\n\n\n\n\n\n\nPlot diatas saya ingin melihat korelasi secara kasar antara fitur - fitur yang numerik dan kontinu, melalui scatter plot, serta range nilai datanya melalui histogramnya.\nMelalui scatter plot dapat kita lihat bahwa kita belum bisa menyimpulkan korelasi antara fitur - fitur, karena persebarannya sebagian besar sangat acak. Melalui histogram dapat dilihat bahwa range nilainya cukup berjauhan (oldpeak 0 sampai 6, sedangkan chol 100 sampai 500+), sehingga perlu dilakukan standarisasi pada data numerik nantinya dengan StandardScaler\n\ncorr = heart.corr()\nplt.subplots(figsize=(10,10))\nsns.heatmap(corr, vmin=-1, center=0, vmax=1, annot=True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nX = heart.drop('output',axis=1).copy()\ny = heart.iloc[:,[-1]]\n\n\nX\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrtbps\nchol\nfbs\nrestecg\nthalachh\nexng\noldpeak\nslp\ncaa\nthall\n\n\n\n\n0\n63\n1\n3\n145\n233\n1\n0\n150\n0\n2.3\n0\n0\n1\n\n\n1\n37\n1\n2\n130\n250\n0\n1\n187\n0\n3.5\n0\n0\n2\n\n\n2\n41\n0\n1\n130\n204\n0\n0\n172\n0\n1.4\n2\n0\n2\n\n\n3\n56\n1\n1\n120\n236\n0\n1\n178\n0\n0.8\n2\n0\n2\n\n\n4\n57\n0\n0\n120\n354\n0\n1\n163\n1\n0.6\n2\n0\n2\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n298\n57\n0\n0\n140\n241\n0\n1\n123\n1\n0.2\n1\n0\n3\n\n\n299\n45\n1\n3\n110\n264\n0\n1\n132\n0\n1.2\n1\n0\n3\n\n\n300\n68\n1\n0\n144\n193\n1\n1\n141\n0\n3.4\n1\n2\n3\n\n\n301\n57\n1\n0\n130\n131\n0\n1\n115\n1\n1.2\n1\n1\n3\n\n\n302\n57\n0\n1\n130\n236\n0\n0\n174\n0\n0.0\n1\n1\n2\n\n\n\n\n303 rows × 13 columns\n\n\n\n\ny\n\n\n\n\n\n\n\n\noutput\n\n\n\n\n0\n1\n\n\n1\n1\n\n\n2\n1\n\n\n3\n1\n\n\n4\n1\n\n\n...\n...\n\n\n298\n0\n\n\n299\n0\n\n\n300\n0\n\n\n301\n0\n\n\n302\n0\n\n\n\n\n303 rows × 1 columns\n\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nheart.columns\n\nIndex(['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh',\n       'exng', 'oldpeak', 'slp', 'caa', 'thall', 'output'],\n      dtype='object')\n\n\n\nsc = StandardScaler()\ncol = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']\nX_train.loc[:,col] = sc.fit_transform(X_train.loc[:,col])\n\n\nX_train\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrtbps\nchol\nfbs\nrestecg\nthalachh\nexng\noldpeak\nslp\ncaa\nthall\n\n\n\n\n132\n-1.356798\n1\n1\n-0.616856\n0.914034\n0\n1\n0.532781\n0\n-0.920864\n2\n0\n2\n\n\n202\n0.385086\n1\n0\n1.169491\n0.439527\n0\n0\n-1.753582\n1\n-0.193787\n2\n0\n3\n\n\n196\n-0.921327\n1\n2\n1.169491\n-0.300704\n0\n1\n-0.139679\n0\n2.350982\n1\n0\n2\n\n\n75\n0.058483\n0\n1\n0.276318\n0.059921\n0\n0\n0.487950\n0\n0.351521\n1\n0\n2\n\n\n176\n0.602822\n1\n0\n-0.795490\n-0.319684\n1\n1\n0.443119\n1\n0.351521\n2\n2\n3\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n188\n-0.485856\n1\n2\n0.574042\n-0.262744\n0\n1\n0.577611\n0\n-0.375556\n1\n1\n3\n\n\n71\n-0.376988\n1\n2\n-2.165023\n-0.376625\n0\n1\n0.174136\n1\n-0.920864\n2\n1\n3\n\n\n106\n1.582631\n1\n3\n1.764940\n-0.243763\n1\n0\n-0.856969\n0\n-0.829979\n1\n1\n2\n\n\n270\n-0.921327\n1\n0\n-0.616856\n0.040941\n0\n0\n-0.274171\n0\n-0.193787\n2\n0\n3\n\n\n102\n0.929425\n0\n1\n0.574042\n-0.983994\n0\n1\n1.294902\n0\n-0.920864\n2\n2\n2\n\n\n\n\n242 rows × 13 columns\n\n\n\n\nX_test.loc[:,col] = sc.transform(X_test.loc[:,col])\nX_test\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrtbps\nchol\nfbs\nrestecg\nthalachh\nexng\noldpeak\nslp\ncaa\nthall\n\n\n\n\n179\n0.276218\n1\n0\n1.169491\n0.553408\n0\n0\n-1.708752\n1\n-0.375556\n1\n1\n1\n\n\n228\n0.493954\n1\n3\n2.360389\n0.781172\n0\n0\n0.398289\n0\n-0.739095\n1\n0\n3\n\n\n111\n0.276218\n1\n2\n1.169491\n-2.293633\n1\n1\n1.025918\n0\n-0.739095\n2\n1\n3\n\n\n246\n0.167350\n0\n0\n0.216773\n3.077785\n0\n0\n-0.005187\n1\n0.805944\n1\n2\n3\n\n\n60\n1.800367\n0\n2\n-1.212304\n0.344625\n1\n0\n-0.901800\n0\n-0.920864\n2\n1\n2\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n249\n1.582631\n1\n2\n0.574042\n0.135842\n0\n0\n-0.184510\n0\n0.896828\n1\n3\n3\n\n\n104\n-0.485856\n1\n2\n-0.080952\n-0.965014\n0\n1\n0.577611\n0\n-0.920864\n2\n0\n2\n\n\n300\n1.473764\n1\n0\n0.812222\n-1.021955\n1\n1\n-0.408663\n0\n2.169213\n1\n2\n3\n\n\n193\n0.602822\n1\n0\n0.871767\n0.667290\n0\n0\n-0.363832\n1\n1.623905\n1\n2\n3\n\n\n184\n-0.485856\n1\n0\n1.169491\n-0.072941\n0\n0\n-0.991461\n0\n1.442136\n1\n0\n3\n\n\n\n\n61 rows × 13 columns\n\n\n\n\n\n\n\nlog_regr = LogisticRegression()\nsvc = SVC()\ndt = DecisionTreeClassifier()\nrf = RandomForestClassifier()\n\n\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n# melakukan cross validation pada masing-masing metode\nlr_score = cross_val_score(log_regr, X_train, y_train, cv=kfold, scoring='f1').mean()\nsvc_score = cross_val_score(svc, X_train, y_train, cv=kfold, scoring='f1').mean()\ndt_score = cross_val_score(dt, X_train, y_train, cv=kfold, scoring='f1').mean()\nrf_score = cross_val_score(rf, X_train, y_train, cv=kfold, scoring='f1').mean()\n\n\nfor i in [lr_score, svc_score, dt_score, rf_score]:\n    print(i)\n\n0.838821143443002\n0.8530945548368415\n0.7278904812545365\n0.8365591551305837\n\n\n\n\n\n\nparams = {'C':[0.01,0.05,0.1,0.7,0.5,1,5,10,50,100],     # hyperparameter yang akan dievaluasi untuk SVC\n             'kernel':['poly','rbf']}\n\ngrid_search = GridSearchCV(svc, params, cv=kfold, scoring='f1')\ngrid_search.fit(X_train,y_train)\n\n\ngrid_search.best_params_, grid_search.cv_results_['mean_test_score'].max()\n\n({'C': 0.7, 'kernel': 'rbf'}, 0.8596614105205573)\n\n\n\nmodel = grid_search.best_estimator_\nmodel.fit(X_train,y_train)\n\nC:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n\n\nSVC(C=0.7)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SVCSVC(C=0.7)\n\n\n\ny_pred = model.predict(X_test)\ny_pred\n\narray([0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)\n\n\n\n\n\n\nf1_score(y_test,y_pred)\n\n0.8923076923076922\n\n\n\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n\ndef evaluation_parametrics(name,y_val, y_pred):\n    \n    print(\"\\n------------------------{}------------------------\\n\".format(name))\n\n    cm_test = confusion_matrix(y_val, y_pred)\n    t1 = ConfusionMatrixDisplay(cm_test)    \n    print(\"\\nClassification Report for Data Test\\n\")\n    print(classification_report(y_val, y_pred))   \n    print(\"--------------------------------------------------------------------------\")\n\n    t1.plot()\n\n\nevaluation_parametrics(\"Machine Learning - Classification\", y_test, y_pred)\n\n\n------------------------Machine Learning - Classification------------------------\n\n\nClassification Report for Data Test\n\n              precision    recall  f1-score   support\n\n           0       0.89      0.86      0.88        29\n           1       0.88      0.91      0.89        32\n\n    accuracy                           0.89        61\n   macro avg       0.89      0.88      0.88        61\nweighted avg       0.89      0.89      0.89        61\n\n--------------------------------------------------------------------------\n\n\n\n\n\n\n\n\n\n\n\n\nimage.png\n\n\nPerbandingan data actual dan data prediksi\n\nprint(np.concatenate((y_test.values.reshape(len(y_test),1),y_pred.reshape(len(y_pred),1)),1))\n\n[[0 0]\n [0 1]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [1 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [0 1]\n [0 1]\n [1 1]\n [0 0]\n [1 1]\n [1 0]\n [0 0]\n [0 0]\n [1 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [0 0]\n [0 0]]\n\n\n\n\n\n\nfrom sklearn.inspection import permutation_importance\nresult = permutation_importance(model, X_test, y_test, n_repeats=10,\n                                scoring='f1', random_state=42)\n\n\nresult_sorted = []\ncolumns_sorted = []\n\nfor res, col in sorted(zip(result.importances_mean, X_test.columns.values), reverse=True):\n  result_sorted.append(res)\n  columns_sorted.append(col)\n\nsns.barplot(x = result_sorted, y = columns_sorted)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSimpan model ke dalam file dan model siap digunakan untuk predict\n\nimport joblib\njoblib.dump(model,'model_SVC.pkl')\n\n['model_SVC.pkl']"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-03.html#regression",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-03.html#regression",
    "title": "Week 03(End to End Machine Learning)",
    "section": "",
    "text": "import library yang dibutuhkan terlebih dahulu untuk pengolahan dan visualisasi data.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\n\n\nUpload dataset yang akan digunakan dan observasi click disini\n\nsalary =  pd.read_csv('Salary_dataset.csv')\nsalary\n\n\n\n\n\n\n\n\nUnnamed: 0\nYearsExperience\nSalary\n\n\n\n\n0\n0\n1.2\n39344.0\n\n\n1\n1\n1.4\n46206.0\n\n\n2\n2\n1.6\n37732.0\n\n\n3\n3\n2.1\n43526.0\n\n\n4\n4\n2.3\n39892.0\n\n\n5\n5\n3.0\n56643.0\n\n\n6\n6\n3.1\n60151.0\n\n\n7\n7\n3.3\n54446.0\n\n\n8\n8\n3.3\n64446.0\n\n\n9\n9\n3.8\n57190.0\n\n\n10\n10\n4.0\n63219.0\n\n\n11\n11\n4.1\n55795.0\n\n\n12\n12\n4.1\n56958.0\n\n\n13\n13\n4.2\n57082.0\n\n\n14\n14\n4.6\n61112.0\n\n\n15\n15\n5.0\n67939.0\n\n\n16\n16\n5.2\n66030.0\n\n\n17\n17\n5.4\n83089.0\n\n\n18\n18\n6.0\n81364.0\n\n\n19\n19\n6.1\n93941.0\n\n\n20\n20\n6.9\n91739.0\n\n\n21\n21\n7.2\n98274.0\n\n\n22\n22\n8.0\n101303.0\n\n\n23\n23\n8.3\n113813.0\n\n\n24\n24\n8.8\n109432.0\n\n\n25\n25\n9.1\n105583.0\n\n\n26\n26\n9.6\n116970.0\n\n\n27\n27\n9.7\n112636.0\n\n\n28\n28\n10.4\n122392.0\n\n\n29\n29\n10.6\n121873.0\n\n\n\n\n\n\n\n\nsalary.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 30 entries, 0 to 29\nData columns (total 3 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   Unnamed: 0       30 non-null     int64  \n 1   YearsExperience  30 non-null     float64\n 2   Salary           30 non-null     float64\ndtypes: float64(2), int64(1)\nmemory usage: 848.0 bytes\n\n\n\n\n\nMelihat jumlah data null pada dataset\n\nsalary.isna().sum()\n\nUnnamed: 0         0\nYearsExperience    0\nSalary             0\ndtype: int64\n\n\nMelihat jumlah data duplikat pada dataset\n\nsalary.duplicated().sum()\n\n0\n\n\nMenghapus kolom ‘Unnamed :0’ dari DataFrame secara permanen\n\nsalary.drop('Unnamed: 0', axis=1, inplace=True)\n\n\nsalary\n\n\n\n\n\n\n\n\nYearsExperience\nSalary\n\n\n\n\n0\n1.2\n39344.0\n\n\n1\n1.4\n46206.0\n\n\n2\n1.6\n37732.0\n\n\n3\n2.1\n43526.0\n\n\n4\n2.3\n39892.0\n\n\n5\n3.0\n56643.0\n\n\n6\n3.1\n60151.0\n\n\n7\n3.3\n54446.0\n\n\n8\n3.3\n64446.0\n\n\n9\n3.8\n57190.0\n\n\n10\n4.0\n63219.0\n\n\n11\n4.1\n55795.0\n\n\n12\n4.1\n56958.0\n\n\n13\n4.2\n57082.0\n\n\n14\n4.6\n61112.0\n\n\n15\n5.0\n67939.0\n\n\n16\n5.2\n66030.0\n\n\n17\n5.4\n83089.0\n\n\n18\n6.0\n81364.0\n\n\n19\n6.1\n93941.0\n\n\n20\n6.9\n91739.0\n\n\n21\n7.2\n98274.0\n\n\n22\n8.0\n101303.0\n\n\n23\n8.3\n113813.0\n\n\n24\n8.8\n109432.0\n\n\n25\n9.1\n105583.0\n\n\n26\n9.6\n116970.0\n\n\n27\n9.7\n112636.0\n\n\n28\n10.4\n122392.0\n\n\n29\n10.6\n121873.0\n\n\n\n\n\n\n\n\n\n\nMengubah setiap nilai di kolom Salary dan mengubah nama kolomnya di DataFrame secara permanen\n\nsalary['Salary'] = salary['Salary']/1000\nsalary.rename(columns={'Salary' : 'Salary (1000 $)'}, inplace=True)\n\nMelihat statistik deskriptif dari DataFrame\n\nsalary.describe()\n\n\n\n\n\n\n\n\nYearsExperience\nSalary (1000 $)\n\n\n\n\ncount\n30.000000\n30.00000\n\n\nmean\n5.413333\n76.00400\n\n\nstd\n2.837888\n27.41443\n\n\nmin\n1.200000\n37.73200\n\n\n25%\n3.300000\n56.72175\n\n\n50%\n4.800000\n65.23800\n\n\n75%\n7.800000\n100.54575\n\n\nmax\n10.600000\n122.39200\n\n\n\n\n\n\n\n\nplt.scatter(salary['YearsExperience'],salary['Salary (1000 $)'])\nplt.plot(salary['YearsExperience'],salary['Salary (1000 $)'])\nplt.xlabel('Year Experience')\nplt.ylabel('Salary (1000 $)')\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, (ax_box, ax_hist) = plt.subplots(2, 1, figsize=(6, 6), sharex='col',\n                                      gridspec_kw={\"height_ratios\": (.15, .85)})\n\nsns.boxplot(data=salary, x='Salary (1000 $)', ax=ax_box, color='crimson')\nsns.histplot(data=salary, x='Salary (1000 $)', ax=ax_hist, binwidth=10.)\nsns.rugplot(data=salary, x='Salary (1000 $)', ax=ax_hist, height=0.05, color='gold', lw=2.)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax_box, ax_hist) = plt.subplots(2, 1, figsize=(6, 6), sharex='col',\n                                      gridspec_kw={\"height_ratios\": (.15, .85)})\n\nsns.boxplot(data=salary, x='YearsExperience', ax=ax_box, color='crimson')\nsns.histplot(data=salary, x='YearsExperience', ax=ax_hist, binwidth=1.)\nsns.rugplot(data=salary, x='YearsExperience', ax=ax_hist, height=0.05, color='gold', lw=2.)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\ncorr = salary.corr()\nsns.heatmap(corr, vmin=-1, center=0, vmax=1, annot=True)\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.subplots(figsize=(6,6))\n\nsns.regplot(data = salary, x='YearsExperience', y='Salary (1000 $)', color='k', marker='+')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nKarena pada dataset ini, fitur yang ada hanya 2, tidak ada masalah dan data sudah rapi, maka untuk step feature engineering akan skip dan lanjut ke tahap modelling.\n\n\n\n\nX = salary[['YearsExperience']]\ny = salary[['Salary (1000 $)']]\n\n\nX\n\n\n\n\n\n\n\n\nYearsExperience\n\n\n\n\n0\n1.2\n\n\n1\n1.4\n\n\n2\n1.6\n\n\n3\n2.1\n\n\n4\n2.3\n\n\n5\n3.0\n\n\n6\n3.1\n\n\n7\n3.3\n\n\n8\n3.3\n\n\n9\n3.8\n\n\n10\n4.0\n\n\n11\n4.1\n\n\n12\n4.1\n\n\n13\n4.2\n\n\n14\n4.6\n\n\n15\n5.0\n\n\n16\n5.2\n\n\n17\n5.4\n\n\n18\n6.0\n\n\n19\n6.1\n\n\n20\n6.9\n\n\n21\n7.2\n\n\n22\n8.0\n\n\n23\n8.3\n\n\n24\n8.8\n\n\n25\n9.1\n\n\n26\n9.6\n\n\n27\n9.7\n\n\n28\n10.4\n\n\n29\n10.6\n\n\n\n\n\n\n\n\ny\n\n\n\n\n\n\n\n\nSalary (1000 $)\n\n\n\n\n0\n39.344\n\n\n1\n46.206\n\n\n2\n37.732\n\n\n3\n43.526\n\n\n4\n39.892\n\n\n5\n56.643\n\n\n6\n60.151\n\n\n7\n54.446\n\n\n8\n64.446\n\n\n9\n57.190\n\n\n10\n63.219\n\n\n11\n55.795\n\n\n12\n56.958\n\n\n13\n57.082\n\n\n14\n61.112\n\n\n15\n67.939\n\n\n16\n66.030\n\n\n17\n83.089\n\n\n18\n81.364\n\n\n19\n93.941\n\n\n20\n91.739\n\n\n21\n98.274\n\n\n22\n101.303\n\n\n23\n113.813\n\n\n24\n109.432\n\n\n25\n105.583\n\n\n26\n116.970\n\n\n27\n112.636\n\n\n28\n122.392\n\n\n29\n121.873\n\n\n\n\n\n\n\nSplit dataset menjadi data train dan data test dengan komposisi pembagian yang sering digunakan\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape\n\n((24, 1), (6, 1), (24, 1), (6, 1))\n\n\nImport terlebih dahulu package yang akan digunakan untuk modelling\n\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train,y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\ny_pred = lr.predict(X_test)\n\n\nfrom sklearn.metrics import mean_squared_error, r2_score\nprint(mean_squared_error(y_pred,y_test))\nprint(r2_score(y_pred,y_test))\n\n49.830096855908344\n0.8961838737587329\n\n\n \nDimana:\n\\(n\\) : jumlah data\n\\(Y_i\\) : nilai actual\n\\(\\hat{Y}_{i}\\): nilai predict\n\\(RSS\\) : sum of squared residuals\n\\(TSS\\) : total sum of squares\n\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n\n[[115.79121011 112.636     ]\n [ 71.49927809  67.939     ]\n [102.59786866 113.813     ]\n [ 75.26880422  83.089     ]\n [ 55.47879205  64.446     ]\n [ 60.19069971  57.19      ]]"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-03.html#classification",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-03.html#classification",
    "title": "Week 03(End to End Machine Learning)",
    "section": "",
    "text": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n\n\n\nheart = pd.read_csv('heart.csv')\nheart\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrtbps\nchol\nfbs\nrestecg\nthalachh\nexng\noldpeak\nslp\ncaa\nthall\noutput\n\n\n\n\n0\n63\n1\n3\n145\n233\n1\n0\n150\n0\n2.3\n0\n0\n1\n1\n\n\n1\n37\n1\n2\n130\n250\n0\n1\n187\n0\n3.5\n0\n0\n2\n1\n\n\n2\n41\n0\n1\n130\n204\n0\n0\n172\n0\n1.4\n2\n0\n2\n1\n\n\n3\n56\n1\n1\n120\n236\n0\n1\n178\n0\n0.8\n2\n0\n2\n1\n\n\n4\n57\n0\n0\n120\n354\n0\n1\n163\n1\n0.6\n2\n0\n2\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n298\n57\n0\n0\n140\n241\n0\n1\n123\n1\n0.2\n1\n0\n3\n0\n\n\n299\n45\n1\n3\n110\n264\n0\n1\n132\n0\n1.2\n1\n0\n3\n0\n\n\n300\n68\n1\n0\n144\n193\n1\n1\n141\n0\n3.4\n1\n2\n3\n0\n\n\n301\n57\n1\n0\n130\n131\n0\n1\n115\n1\n1.2\n1\n1\n3\n0\n\n\n302\n57\n0\n1\n130\n236\n0\n0\n174\n0\n0.0\n1\n1\n2\n0\n\n\n\n\n303 rows × 14 columns\n\n\n\n\n# Membaca .txt tentang kolom - kolom dataset yang diberikan pada soal\nwith open('about dataset.txt', 'r') as f:\n  print(f.read())\n\nAbout datasets\n1. age - age in years \n2. sex - sex (1 = male; 0 = female) \n3. cp - chest pain type (1 = typical angina; 2 = atypical angina; 3 = non-anginal pain; 0 = asymptomatic) \n4. trestbps - resting blood pressure (in mm Hg on admission to the hospital) \n5. chol - serum cholestoral in mg/dl \n6. fbs - fasting blood sugar &gt; 120 mg/dl (1 = true; 0 = false) \n7. restecg - resting electrocardiographic results (1 = normal; 2 = having ST-T wave abnormality; 0 = hypertrophy) \n8. thalach - maximum heart rate achieved \n9. exang - exercise induced angina (1 = yes; 0 = no) \n10. oldpeak - ST depression induced by exercise relative to rest \n11. slope - the slope of the peak exercise ST segment (2 = upsloping; 1 = flat; 0 = downsloping) \n12. ca - number of major vessels (0-3) colored by flourosopy \n13. thal - 2 = normal; 1 = fixed defect; 3 = reversable defect \n14. output - the predicted attribute - diagnosis of heart disease (0 = less chance of heart attack, 1 = higher chance of heart attack)\n\n\n\n\nheart.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 303 entries, 0 to 302\nData columns (total 14 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       303 non-null    int64  \n 1   sex       303 non-null    int64  \n 2   cp        303 non-null    int64  \n 3   trtbps    303 non-null    int64  \n 4   chol      303 non-null    int64  \n 5   fbs       303 non-null    int64  \n 6   restecg   303 non-null    int64  \n 7   thalachh  303 non-null    int64  \n 8   exng      303 non-null    int64  \n 9   oldpeak   303 non-null    float64\n 10  slp       303 non-null    int64  \n 11  caa       303 non-null    int64  \n 12  thall     303 non-null    int64  \n 13  output    303 non-null    int64  \ndtypes: float64(1), int64(13)\nmemory usage: 33.3 KB\n\n\n\nheart.output.value_counts()\n\n1    165\n0    138\nName: output, dtype: int64\n\n\n\n\n\n\nheart.describe()\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrtbps\nchol\nfbs\nrestecg\nthalachh\nexng\noldpeak\nslp\ncaa\nthall\noutput\n\n\n\n\ncount\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n303.000000\n\n\nmean\n54.366337\n0.683168\n0.966997\n131.623762\n246.264026\n0.148515\n0.528053\n149.646865\n0.326733\n1.039604\n1.399340\n0.729373\n2.313531\n0.544554\n\n\nstd\n9.082101\n0.466011\n1.032052\n17.538143\n51.830751\n0.356198\n0.525860\n22.905161\n0.469794\n1.161075\n0.616226\n1.022606\n0.612277\n0.498835\n\n\nmin\n29.000000\n0.000000\n0.000000\n94.000000\n126.000000\n0.000000\n0.000000\n71.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n47.500000\n0.000000\n0.000000\n120.000000\n211.000000\n0.000000\n0.000000\n133.500000\n0.000000\n0.000000\n1.000000\n0.000000\n2.000000\n0.000000\n\n\n50%\n55.000000\n1.000000\n1.000000\n130.000000\n240.000000\n0.000000\n1.000000\n153.000000\n0.000000\n0.800000\n1.000000\n0.000000\n2.000000\n1.000000\n\n\n75%\n61.000000\n1.000000\n2.000000\n140.000000\n274.500000\n0.000000\n1.000000\n166.000000\n1.000000\n1.600000\n2.000000\n1.000000\n3.000000\n1.000000\n\n\nmax\n77.000000\n1.000000\n3.000000\n200.000000\n564.000000\n1.000000\n2.000000\n202.000000\n1.000000\n6.200000\n2.000000\n4.000000\n3.000000\n1.000000\n\n\n\n\n\n\n\n\npd.plotting.scatter_matrix(heart[['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']], figsize=(15,12)) # plot data yang numerik dan kontinu\nplt.show()\n\n\n\n\n\n\n\n\nPlot diatas saya ingin melihat korelasi secara kasar antara fitur - fitur yang numerik dan kontinu, melalui scatter plot, serta range nilai datanya melalui histogramnya.\nMelalui scatter plot dapat kita lihat bahwa kita belum bisa menyimpulkan korelasi antara fitur - fitur, karena persebarannya sebagian besar sangat acak. Melalui histogram dapat dilihat bahwa range nilainya cukup berjauhan (oldpeak 0 sampai 6, sedangkan chol 100 sampai 500+), sehingga perlu dilakukan standarisasi pada data numerik nantinya dengan StandardScaler\n\ncorr = heart.corr()\nplt.subplots(figsize=(10,10))\nsns.heatmap(corr, vmin=-1, center=0, vmax=1, annot=True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nX = heart.drop('output',axis=1).copy()\ny = heart.iloc[:,[-1]]\n\n\nX\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrtbps\nchol\nfbs\nrestecg\nthalachh\nexng\noldpeak\nslp\ncaa\nthall\n\n\n\n\n0\n63\n1\n3\n145\n233\n1\n0\n150\n0\n2.3\n0\n0\n1\n\n\n1\n37\n1\n2\n130\n250\n0\n1\n187\n0\n3.5\n0\n0\n2\n\n\n2\n41\n0\n1\n130\n204\n0\n0\n172\n0\n1.4\n2\n0\n2\n\n\n3\n56\n1\n1\n120\n236\n0\n1\n178\n0\n0.8\n2\n0\n2\n\n\n4\n57\n0\n0\n120\n354\n0\n1\n163\n1\n0.6\n2\n0\n2\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n298\n57\n0\n0\n140\n241\n0\n1\n123\n1\n0.2\n1\n0\n3\n\n\n299\n45\n1\n3\n110\n264\n0\n1\n132\n0\n1.2\n1\n0\n3\n\n\n300\n68\n1\n0\n144\n193\n1\n1\n141\n0\n3.4\n1\n2\n3\n\n\n301\n57\n1\n0\n130\n131\n0\n1\n115\n1\n1.2\n1\n1\n3\n\n\n302\n57\n0\n1\n130\n236\n0\n0\n174\n0\n0.0\n1\n1\n2\n\n\n\n\n303 rows × 13 columns\n\n\n\n\ny\n\n\n\n\n\n\n\n\noutput\n\n\n\n\n0\n1\n\n\n1\n1\n\n\n2\n1\n\n\n3\n1\n\n\n4\n1\n\n\n...\n...\n\n\n298\n0\n\n\n299\n0\n\n\n300\n0\n\n\n301\n0\n\n\n302\n0\n\n\n\n\n303 rows × 1 columns\n\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nheart.columns\n\nIndex(['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh',\n       'exng', 'oldpeak', 'slp', 'caa', 'thall', 'output'],\n      dtype='object')\n\n\n\nsc = StandardScaler()\ncol = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']\nX_train.loc[:,col] = sc.fit_transform(X_train.loc[:,col])\n\n\nX_train\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrtbps\nchol\nfbs\nrestecg\nthalachh\nexng\noldpeak\nslp\ncaa\nthall\n\n\n\n\n132\n-1.356798\n1\n1\n-0.616856\n0.914034\n0\n1\n0.532781\n0\n-0.920864\n2\n0\n2\n\n\n202\n0.385086\n1\n0\n1.169491\n0.439527\n0\n0\n-1.753582\n1\n-0.193787\n2\n0\n3\n\n\n196\n-0.921327\n1\n2\n1.169491\n-0.300704\n0\n1\n-0.139679\n0\n2.350982\n1\n0\n2\n\n\n75\n0.058483\n0\n1\n0.276318\n0.059921\n0\n0\n0.487950\n0\n0.351521\n1\n0\n2\n\n\n176\n0.602822\n1\n0\n-0.795490\n-0.319684\n1\n1\n0.443119\n1\n0.351521\n2\n2\n3\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n188\n-0.485856\n1\n2\n0.574042\n-0.262744\n0\n1\n0.577611\n0\n-0.375556\n1\n1\n3\n\n\n71\n-0.376988\n1\n2\n-2.165023\n-0.376625\n0\n1\n0.174136\n1\n-0.920864\n2\n1\n3\n\n\n106\n1.582631\n1\n3\n1.764940\n-0.243763\n1\n0\n-0.856969\n0\n-0.829979\n1\n1\n2\n\n\n270\n-0.921327\n1\n0\n-0.616856\n0.040941\n0\n0\n-0.274171\n0\n-0.193787\n2\n0\n3\n\n\n102\n0.929425\n0\n1\n0.574042\n-0.983994\n0\n1\n1.294902\n0\n-0.920864\n2\n2\n2\n\n\n\n\n242 rows × 13 columns\n\n\n\n\nX_test.loc[:,col] = sc.transform(X_test.loc[:,col])\nX_test\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrtbps\nchol\nfbs\nrestecg\nthalachh\nexng\noldpeak\nslp\ncaa\nthall\n\n\n\n\n179\n0.276218\n1\n0\n1.169491\n0.553408\n0\n0\n-1.708752\n1\n-0.375556\n1\n1\n1\n\n\n228\n0.493954\n1\n3\n2.360389\n0.781172\n0\n0\n0.398289\n0\n-0.739095\n1\n0\n3\n\n\n111\n0.276218\n1\n2\n1.169491\n-2.293633\n1\n1\n1.025918\n0\n-0.739095\n2\n1\n3\n\n\n246\n0.167350\n0\n0\n0.216773\n3.077785\n0\n0\n-0.005187\n1\n0.805944\n1\n2\n3\n\n\n60\n1.800367\n0\n2\n-1.212304\n0.344625\n1\n0\n-0.901800\n0\n-0.920864\n2\n1\n2\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n249\n1.582631\n1\n2\n0.574042\n0.135842\n0\n0\n-0.184510\n0\n0.896828\n1\n3\n3\n\n\n104\n-0.485856\n1\n2\n-0.080952\n-0.965014\n0\n1\n0.577611\n0\n-0.920864\n2\n0\n2\n\n\n300\n1.473764\n1\n0\n0.812222\n-1.021955\n1\n1\n-0.408663\n0\n2.169213\n1\n2\n3\n\n\n193\n0.602822\n1\n0\n0.871767\n0.667290\n0\n0\n-0.363832\n1\n1.623905\n1\n2\n3\n\n\n184\n-0.485856\n1\n0\n1.169491\n-0.072941\n0\n0\n-0.991461\n0\n1.442136\n1\n0\n3\n\n\n\n\n61 rows × 13 columns\n\n\n\n\n\n\n\nlog_regr = LogisticRegression()\nsvc = SVC()\ndt = DecisionTreeClassifier()\nrf = RandomForestClassifier()\n\n\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n# melakukan cross validation pada masing-masing metode\nlr_score = cross_val_score(log_regr, X_train, y_train, cv=kfold, scoring='f1').mean()\nsvc_score = cross_val_score(svc, X_train, y_train, cv=kfold, scoring='f1').mean()\ndt_score = cross_val_score(dt, X_train, y_train, cv=kfold, scoring='f1').mean()\nrf_score = cross_val_score(rf, X_train, y_train, cv=kfold, scoring='f1').mean()\n\n\nfor i in [lr_score, svc_score, dt_score, rf_score]:\n    print(i)\n\n0.838821143443002\n0.8530945548368415\n0.7278904812545365\n0.8365591551305837\n\n\n\n\n\n\nparams = {'C':[0.01,0.05,0.1,0.7,0.5,1,5,10,50,100],     # hyperparameter yang akan dievaluasi untuk SVC\n             'kernel':['poly','rbf']}\n\ngrid_search = GridSearchCV(svc, params, cv=kfold, scoring='f1')\ngrid_search.fit(X_train,y_train)\n\n\ngrid_search.best_params_, grid_search.cv_results_['mean_test_score'].max()\n\n({'C': 0.7, 'kernel': 'rbf'}, 0.8596614105205573)\n\n\n\nmodel = grid_search.best_estimator_\nmodel.fit(X_train,y_train)\n\nC:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n\n\nSVC(C=0.7)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SVCSVC(C=0.7)\n\n\n\ny_pred = model.predict(X_test)\ny_pred\n\narray([0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)\n\n\n\n\n\n\nf1_score(y_test,y_pred)\n\n0.8923076923076922\n\n\n\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n\ndef evaluation_parametrics(name,y_val, y_pred):\n    \n    print(\"\\n------------------------{}------------------------\\n\".format(name))\n\n    cm_test = confusion_matrix(y_val, y_pred)\n    t1 = ConfusionMatrixDisplay(cm_test)    \n    print(\"\\nClassification Report for Data Test\\n\")\n    print(classification_report(y_val, y_pred))   \n    print(\"--------------------------------------------------------------------------\")\n\n    t1.plot()\n\n\nevaluation_parametrics(\"Machine Learning - Classification\", y_test, y_pred)\n\n\n------------------------Machine Learning - Classification------------------------\n\n\nClassification Report for Data Test\n\n              precision    recall  f1-score   support\n\n           0       0.89      0.86      0.88        29\n           1       0.88      0.91      0.89        32\n\n    accuracy                           0.89        61\n   macro avg       0.89      0.88      0.88        61\nweighted avg       0.89      0.89      0.89        61\n\n--------------------------------------------------------------------------\n\n\n\n\n\n\n\n\n\n\n\n\nimage.png\n\n\nPerbandingan data actual dan data prediksi\n\nprint(np.concatenate((y_test.values.reshape(len(y_test),1),y_pred.reshape(len(y_pred),1)),1))\n\n[[0 0]\n [0 1]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [1 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [0 1]\n [0 1]\n [1 1]\n [0 0]\n [1 1]\n [1 0]\n [0 0]\n [0 0]\n [1 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [0 0]\n [0 0]]\n\n\n\n\n\n\nfrom sklearn.inspection import permutation_importance\nresult = permutation_importance(model, X_test, y_test, n_repeats=10,\n                                scoring='f1', random_state=42)\n\n\nresult_sorted = []\ncolumns_sorted = []\n\nfor res, col in sorted(zip(result.importances_mean, X_test.columns.values), reverse=True):\n  result_sorted.append(res)\n  columns_sorted.append(col)\n\nsns.barplot(x = result_sorted, y = columns_sorted)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSimpan model ke dalam file dan model siap digunakan untuk predict\n\nimport joblib\njoblib.dump(model,'model_SVC.pkl')\n\n['model_SVC.pkl']"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-01.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-01.html",
    "title": "Week 01 (Data Transformation)",
    "section": "",
    "text": "Kembali ke Sains Data\n\n\nPada module ini kita akan coba mememahami package pandas, yang merupakan package inti dalam sains-data. kita akan coba melakukan beberapa transformasi data menggunakan pandas.\nsebelum itu, python module di bawah ini yang akan digunakan selama praktikum.\n\nimport numpy as np\nimport pandas as pd\n\n\n\n\npandas.Series sangat mirip dengan array NumPy (bahkan dibangun di atas objek array NumPy). Yang membedakan array NumPy dari sebuah Series adalah bahwa sebuah Series dapat memiliki label index, yang berarti dapat diindeks dengan label, bukan hanya lokasi nomor saja. Selain itu, sebuah Series tidak perlu menyimpan data numerik, ia dapat menyimpan objek Python sembarang.\n\n\nPaling mudah, ktia dapat membuat pd.Series dengan python list\n\nmy_index= ['a','b','c','d','e']\nmy_data= [1,2,3,4,5]\nmy_series= pd.Series(data=my_data, index=my_index)\n\n\nprint(my_series)\nprint(my_series.__class__)\n\na    1\nb    2\nc    3\nd    4\ne    5\ndtype: int64\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n\n\n\nKita juga dapat membuat pd.Series dengan dictionary\n\n# creating a series from a dictionary\nmy_dict= {'a':1, 'b':2, 'c':3, 'd':4, 'e':5}\nmy_series_dict= pd.Series(my_dict)\n\n\nprint(my_series_dict)\nprint(my_series_dict.__class__)\n\na    1\nb    2\nc    3\nd    4\ne    5\ndtype: int64\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n\n\n\n\n# Imaginary Sales Data for 1st and 2nd Quarters for Global Company\nq1 = {'Japan': 80, 'China': 450, 'India': 200, 'USA': 250}\nq2 = {'Brazil': 100,'China': 500, 'India': 210,'USA': 260}\n\n\n# Creating a Series from a Dictionary q1 and q2\nq1_series= pd.Series(q1)\nq2_series= pd.Series(q2)\n\n\nprint(q1_series)\n\nJapan     80\nChina    450\nIndia    200\nUSA      250\ndtype: int64\n\n\nKita dapat mengindeks dengan label\n\n# call values of q1_series based on named index\nprint(q1_series['Japan'])\nprint(q1_series['China'])\nprint(q1_series['India'])\n\n80\n450\n200\n\n\nkita dapat tetap dapat mengindeks dengan integer\n\n# u can also call values of q1_series based on positional index\nprint(q1_series[0])\nprint(q1_series[1])\nprint(q1_series[2])\n\n80\n450\n200\n\n\nhati-hati dalam melakukan indexing dengan label. bisa saja terjadi error jika label tidak ada di dalam pd.series\n\n# remember named index is case sensitive\ntry:\n    print(q1_series['japan'])\nexcept:\n    print('something went wrong')\n\nsomething went wrong\n\n\nOperasi aritmatik sederhana pada pd.Series bersifat broadcasting\n\n# operations with arithmetic on series are broadcasted to all values\nprint(q1_series*2)\n\nJapan    160\nChina    900\nIndia    400\nUSA      500\ndtype: int64\n\n\n\nprint(q1_series+1000)\n\nJapan    1080\nChina    1450\nIndia    1200\nUSA      1250\ndtype: int64\n\n\n\n# operation between series are also broadcasted\nprint(q1_series+q2_series)\n\nBrazil      NaN\nChina     950.0\nIndia     410.0\nJapan       NaN\nUSA       510.0\ndtype: float64\n\n\n\nprint(q1_series.add(q2_series, fill_value=0))\n\nBrazil    100.0\nChina     950.0\nIndia     410.0\nJapan      80.0\nUSA       510.0\ndtype: float64\n\n\n\n\n\n\nSebuah pd.DataFrame terdiri dari beberapa pd.Series yang berbagi nilai indeks.\n\nmy_data= np.random.randint(0,100,12).reshape(4,3)\nmy_data\n\narray([[25, 59, 18],\n       [75, 54, 65],\n       [29, 21,  7],\n       [32, 69, 16]])\n\n\nKita akan membuat pd.Dataframe melalui python list. Perhatikan bahwa kita dapat memberikan nama pada kolom dan baris\n\nmy_index= [\"jakarta\", \"bandung\", \"surabaya\", \"medan\"]\nmy_columns= [\"apple\", \"orange\", \"banana\"]\n\ndf= pd.DataFrame(data=my_data, index=my_index, columns=my_columns)\ndf\n\n\n\n\n\n\n\n\napple\norange\nbanana\n\n\n\n\njakarta\n25\n59\n18\n\n\nbandung\n75\n54\n65\n\n\nsurabaya\n29\n21\n7\n\n\nmedan\n32\n69\n16\n\n\n\n\n\n\n\n\ndf_2= pd.DataFrame(data=my_data)\ndf_2\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n25\n59\n18\n\n\n1\n75\n54\n65\n\n\n2\n29\n21\n7\n\n\n3\n32\n69\n16\n\n\n\n\n\n\n\n\ndf_3= pd.DataFrame(data=my_data, columns=my_columns)\ndf_3\n\n\n\n\n\n\n\n\napple\norange\nbanana\n\n\n\n\n0\n25\n59\n18\n\n\n1\n75\n54\n65\n\n\n2\n29\n21\n7\n\n\n3\n32\n69\n16\n\n\n\n\n\n\n\n\n\nJika berkas .py atau .ipynb Anda berada di lokasi folder yang sama persis dengan berkas .csv yang ingin Anda baca, cukup berikan nama berkas sebagai string, misalnya:\ndf = pd.read_csv('[some_file.csv')\nBerikan s berkas jika Anda berada di direktori yang berbeda. Jalur berkas harus 100% benar agar ini berfungsi. Misalnya:\ndf = pd.read_csv(\"C:\\\\Users\\\\myself\\\\files\\\\some_file.csv\")\nsebelum itu, kalian dapat mendownload data tersebut melalui link berikut\nDownload\n\npwd\n\n'c:\\\\Users\\\\user\\\\Documents\\\\root\\\\personal\\\\github-personal\\\\sains-data-2023\\\\main-module'\n\n\n\ndf_tips= pd.read_csv('./data/tips.csv')\n\n\ndf_tips\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\nSat1766\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\nSat3880\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\nSat17\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n9.39\nMichelle Hardin\n3511451626698139\nThur672\n\n\n\n\n244 rows × 11 columns\n\n\n\n\n\n\n\n# mengecek nama kolom\ndf_tips.columns\n\nIndex(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size',\n       'price_per_person', 'Payer Name', 'CC Number', 'Payment ID'],\n      dtype='object')\n\n\n\n# mengecek \ndf_tips.index\n\nRangeIndex(start=0, stop=244, step=1)\n\n\n\ndf_tips.head(5)\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n\n\n\n\n\n\ndf_tips.tail(5)\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\nSat1766\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\nSat3880\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\nSat17\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n9.39\nMichelle Hardin\n3511451626698139\nThur672\n\n\n\n\n\n\n\n\ndf_tips.describe().transpose()\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\ntotal_bill\n244.0\n1.978594e+01\n8.902412e+00\n3.070000e+00\n1.334750e+01\n1.779500e+01\n2.412750e+01\n5.081000e+01\n\n\ntip\n244.0\n2.998279e+00\n1.383638e+00\n1.000000e+00\n2.000000e+00\n2.900000e+00\n3.562500e+00\n1.000000e+01\n\n\nsize\n244.0\n2.569672e+00\n9.510998e-01\n1.000000e+00\n2.000000e+00\n2.000000e+00\n3.000000e+00\n6.000000e+00\n\n\nprice_per_person\n244.0\n7.888197e+00\n2.914234e+00\n2.880000e+00\n5.800000e+00\n7.255000e+00\n9.390000e+00\n2.027000e+01\n\n\nCC Number\n244.0\n2.563496e+15\n2.369340e+15\n6.040679e+10\n3.040731e+13\n3.525318e+15\n4.553675e+15\n6.596454e+15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndf_tips.head(5)\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n\n\n\n\n\n\nprint(df_tips[\"size\"] ==3)\nconditional_size = df_tips[\"size\"] ==3\n\n0      False\n1       True\n2       True\n3      False\n4      False\n       ...  \n239     True\n240    False\n241    False\n242    False\n243    False\nName: size, Length: 244, dtype: bool\n\n\n\ndf_tips[conditional_size].head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n16\n10.33\n1.67\nFemale\nNo\nSun\nDinner\n3\n3.44\nElizabeth Foster\n4240025044626033\nSun9715\n\n\n17\n16.29\n3.71\nMale\nNo\nSun\nDinner\n3\n5.43\nJohn Pittman\n6521340257218708\nSun2998\n\n\n18\n16.97\n3.50\nFemale\nNo\nSun\nDinner\n3\n5.66\nLaura Martinez\n30422275171379\nSun2789\n\n\n\n\n\n\n\n\nconditional= (df_tips[\"size\"]==3) & (df_tips[\"total_bill\"]&gt;20)\nprint(conditional)\n\n0      False\n1      False\n2       True\n3      False\n4      False\n       ...  \n239     True\n240    False\n241    False\n242    False\n243    False\nLength: 244, dtype: bool\n\n\n\ndf_tips[conditional].head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n19\n20.65\n3.35\nMale\nNo\nSat\nDinner\n3\n6.88\nTimothy Oneal\n6568069240986485\nSat9213\n\n\n35\n24.06\n3.60\nMale\nNo\nSat\nDinner\n3\n8.02\nJoseph Mullins\n5519770449260299\nSat632\n\n\n39\n31.27\n5.00\nMale\nNo\nSat\nDinner\n3\n10.42\nMr. Brandon Berry\n6011525851069856\nSat6373\n\n\n48\n28.55\n2.05\nMale\nNo\nSun\nDinner\n3\n9.52\nAustin Fisher\n6011481668986587\nSun4142\n\n\n\n\n\n\n\n\ndf_tips[(df_tips[\"size\"]==3) & (df_tips[\"total_bill\"]&gt;20)].head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n19\n20.65\n3.35\nMale\nNo\nSat\nDinner\n3\n6.88\nTimothy Oneal\n6568069240986485\nSat9213\n\n\n35\n24.06\n3.60\nMale\nNo\nSat\nDinner\n3\n8.02\nJoseph Mullins\n5519770449260299\nSat632\n\n\n39\n31.27\n5.00\nMale\nNo\nSat\nDinner\n3\n10.42\nMr. Brandon Berry\n6011525851069856\nSat6373\n\n\n48\n28.55\n2.05\nMale\nNo\nSun\nDinner\n3\n9.52\nAustin Fisher\n6011481668986587\nSun4142\n\n\n\n\n\n\n\n\nweekend= [\"Sun\", \"Sat\"]\nconditional_in= df_tips[\"day\"].isin(weekend)\ndf_tips[conditional_in].head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n\n\n\n\n\n\ndf_tips.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n\n\n\n\n\n\n\n\n\ndf_tips[\"day\"].unique()\n\narray(['Sun', 'Sat', 'Thur', 'Fri'], dtype=object)\n\n\n\ndf_tips.drop_duplicates([\"day\",\"time\"])[[\"day\",\"time\"]]\n\n\n\n\n\n\n\n\nday\ntime\n\n\n\n\n0\nSun\nDinner\n\n\n19\nSat\nDinner\n\n\n77\nThur\nLunch\n\n\n90\nFri\nDinner\n\n\n220\nFri\nLunch\n\n\n243\nThur\nDinner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprint(df_tips[\"day\"])\nprint(\"=======\")\nprint(df_tips.day)\n\n0       Sun\n1       Sun\n2       Sun\n3       Sun\n4       Sun\n       ... \n239     Sat\n240     Sat\n241     Sat\n242     Sat\n243    Thur\nName: day, Length: 244, dtype: object\n=======\n0       Sun\n1       Sun\n2       Sun\n3       Sun\n4       Sun\n       ... \n239     Sat\n240     Sat\n241     Sat\n242     Sat\n243    Thur\nName: day, Length: 244, dtype: object\n\n\n\ndf_tips[[\"day\",\"time\"]]\n\n\n\n\n\n\n\n\nday\ntime\n\n\n\n\n0\nSun\nDinner\n\n\n1\nSun\nDinner\n\n\n2\nSun\nDinner\n\n\n3\nSun\nDinner\n\n\n4\nSun\nDinner\n\n\n...\n...\n...\n\n\n239\nSat\nDinner\n\n\n240\nSat\nDinner\n\n\n241\nSat\nDinner\n\n\n242\nSat\nDinner\n\n\n243\nThur\nDinner\n\n\n\n\n244 rows × 2 columns\n\n\n\n\n\n\n\ndf_tips[\"tips_percentage\"]= df_tips[\"tip\"]/df_tips[\"total_bill\"]*100\n\ndf_tips.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\ntips_percentage\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n5.944673\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n16.054159\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n16.658734\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n13.978041\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n14.680765\n\n\n\n\n\n\n\n\n\n\n\ndf_tips.rename(columns={\"tips_percentage\":\"tips_percentage_%\"}, inplace=True)\ndf_tips.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\ntips_percentage_%\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n5.944673\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n16.054159\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n16.658734\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n13.978041\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n14.680765\n\n\n\n\n\n\n\n\n\n\n\n#relocate tips_percentage_% column to the rightmost\ncols= list(df_tips.columns)\ncols= [cols[-1]]+ cols[:-2]\n\ndf_tips= df_tips[cols]\n\n\ndf_tips\n\n\n\n\n\n\n\n\ntips_percentage_%\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\n\n\n\n\n0\n5.944673\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\n\n\n1\n16.054159\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\n\n\n2\n16.658734\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\n\n\n3\n13.978041\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\n\n\n4\n14.680765\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n20.392697\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\n\n\n240\n7.358352\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\n\n\n241\n8.822232\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\n\n\n242\n9.820426\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\n\n\n243\n15.974441\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n9.39\nMichelle Hardin\n3511451626698139\n\n\n\n\n244 rows × 11 columns"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-01.html#prerequisites",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-01.html#prerequisites",
    "title": "Week 01 (Data Transformation)",
    "section": "",
    "text": "Pada module ini kita akan coba mememahami package pandas, yang merupakan package inti dalam sains-data. kita akan coba melakukan beberapa transformasi data menggunakan pandas.\nsebelum itu, python module di bawah ini yang akan digunakan selama praktikum.\n\nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-01.html#series",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-01.html#series",
    "title": "Week 01 (Data Transformation)",
    "section": "",
    "text": "pandas.Series sangat mirip dengan array NumPy (bahkan dibangun di atas objek array NumPy). Yang membedakan array NumPy dari sebuah Series adalah bahwa sebuah Series dapat memiliki label index, yang berarti dapat diindeks dengan label, bukan hanya lokasi nomor saja. Selain itu, sebuah Series tidak perlu menyimpan data numerik, ia dapat menyimpan objek Python sembarang.\n\n\nPaling mudah, ktia dapat membuat pd.Series dengan python list\n\nmy_index= ['a','b','c','d','e']\nmy_data= [1,2,3,4,5]\nmy_series= pd.Series(data=my_data, index=my_index)\n\n\nprint(my_series)\nprint(my_series.__class__)\n\na    1\nb    2\nc    3\nd    4\ne    5\ndtype: int64\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n\n\n\nKita juga dapat membuat pd.Series dengan dictionary\n\n# creating a series from a dictionary\nmy_dict= {'a':1, 'b':2, 'c':3, 'd':4, 'e':5}\nmy_series_dict= pd.Series(my_dict)\n\n\nprint(my_series_dict)\nprint(my_series_dict.__class__)\n\na    1\nb    2\nc    3\nd    4\ne    5\ndtype: int64\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n\n\n\n\n# Imaginary Sales Data for 1st and 2nd Quarters for Global Company\nq1 = {'Japan': 80, 'China': 450, 'India': 200, 'USA': 250}\nq2 = {'Brazil': 100,'China': 500, 'India': 210,'USA': 260}\n\n\n# Creating a Series from a Dictionary q1 and q2\nq1_series= pd.Series(q1)\nq2_series= pd.Series(q2)\n\n\nprint(q1_series)\n\nJapan     80\nChina    450\nIndia    200\nUSA      250\ndtype: int64\n\n\nKita dapat mengindeks dengan label\n\n# call values of q1_series based on named index\nprint(q1_series['Japan'])\nprint(q1_series['China'])\nprint(q1_series['India'])\n\n80\n450\n200\n\n\nkita dapat tetap dapat mengindeks dengan integer\n\n# u can also call values of q1_series based on positional index\nprint(q1_series[0])\nprint(q1_series[1])\nprint(q1_series[2])\n\n80\n450\n200\n\n\nhati-hati dalam melakukan indexing dengan label. bisa saja terjadi error jika label tidak ada di dalam pd.series\n\n# remember named index is case sensitive\ntry:\n    print(q1_series['japan'])\nexcept:\n    print('something went wrong')\n\nsomething went wrong\n\n\nOperasi aritmatik sederhana pada pd.Series bersifat broadcasting\n\n# operations with arithmetic on series are broadcasted to all values\nprint(q1_series*2)\n\nJapan    160\nChina    900\nIndia    400\nUSA      500\ndtype: int64\n\n\n\nprint(q1_series+1000)\n\nJapan    1080\nChina    1450\nIndia    1200\nUSA      1250\ndtype: int64\n\n\n\n# operation between series are also broadcasted\nprint(q1_series+q2_series)\n\nBrazil      NaN\nChina     950.0\nIndia     410.0\nJapan       NaN\nUSA       510.0\ndtype: float64\n\n\n\nprint(q1_series.add(q2_series, fill_value=0))\n\nBrazil    100.0\nChina     950.0\nIndia     410.0\nJapan      80.0\nUSA       510.0\ndtype: float64"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-01.html#data-frame",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-01.html#data-frame",
    "title": "Week 01 (Data Transformation)",
    "section": "",
    "text": "Sebuah pd.DataFrame terdiri dari beberapa pd.Series yang berbagi nilai indeks.\n\nmy_data= np.random.randint(0,100,12).reshape(4,3)\nmy_data\n\narray([[25, 59, 18],\n       [75, 54, 65],\n       [29, 21,  7],\n       [32, 69, 16]])\n\n\nKita akan membuat pd.Dataframe melalui python list. Perhatikan bahwa kita dapat memberikan nama pada kolom dan baris\n\nmy_index= [\"jakarta\", \"bandung\", \"surabaya\", \"medan\"]\nmy_columns= [\"apple\", \"orange\", \"banana\"]\n\ndf= pd.DataFrame(data=my_data, index=my_index, columns=my_columns)\ndf\n\n\n\n\n\n\n\n\napple\norange\nbanana\n\n\n\n\njakarta\n25\n59\n18\n\n\nbandung\n75\n54\n65\n\n\nsurabaya\n29\n21\n7\n\n\nmedan\n32\n69\n16\n\n\n\n\n\n\n\n\ndf_2= pd.DataFrame(data=my_data)\ndf_2\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n25\n59\n18\n\n\n1\n75\n54\n65\n\n\n2\n29\n21\n7\n\n\n3\n32\n69\n16\n\n\n\n\n\n\n\n\ndf_3= pd.DataFrame(data=my_data, columns=my_columns)\ndf_3\n\n\n\n\n\n\n\n\napple\norange\nbanana\n\n\n\n\n0\n25\n59\n18\n\n\n1\n75\n54\n65\n\n\n2\n29\n21\n7\n\n\n3\n32\n69\n16\n\n\n\n\n\n\n\n\n\nJika berkas .py atau .ipynb Anda berada di lokasi folder yang sama persis dengan berkas .csv yang ingin Anda baca, cukup berikan nama berkas sebagai string, misalnya:\ndf = pd.read_csv('[some_file.csv')\nBerikan s berkas jika Anda berada di direktori yang berbeda. Jalur berkas harus 100% benar agar ini berfungsi. Misalnya:\ndf = pd.read_csv(\"C:\\\\Users\\\\myself\\\\files\\\\some_file.csv\")\nsebelum itu, kalian dapat mendownload data tersebut melalui link berikut\nDownload\n\npwd\n\n'c:\\\\Users\\\\user\\\\Documents\\\\root\\\\personal\\\\github-personal\\\\sains-data-2023\\\\main-module'\n\n\n\ndf_tips= pd.read_csv('./data/tips.csv')\n\n\ndf_tips\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\nSat1766\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\nSat3880\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\nSat17\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n9.39\nMichelle Hardin\n3511451626698139\nThur672\n\n\n\n\n244 rows × 11 columns\n\n\n\n\n\n\n\n# mengecek nama kolom\ndf_tips.columns\n\nIndex(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size',\n       'price_per_person', 'Payer Name', 'CC Number', 'Payment ID'],\n      dtype='object')\n\n\n\n# mengecek \ndf_tips.index\n\nRangeIndex(start=0, stop=244, step=1)\n\n\n\ndf_tips.head(5)\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n\n\n\n\n\n\ndf_tips.tail(5)\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\nSat1766\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\nSat3880\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\nSat17\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n9.39\nMichelle Hardin\n3511451626698139\nThur672\n\n\n\n\n\n\n\n\ndf_tips.describe().transpose()\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\ntotal_bill\n244.0\n1.978594e+01\n8.902412e+00\n3.070000e+00\n1.334750e+01\n1.779500e+01\n2.412750e+01\n5.081000e+01\n\n\ntip\n244.0\n2.998279e+00\n1.383638e+00\n1.000000e+00\n2.000000e+00\n2.900000e+00\n3.562500e+00\n1.000000e+01\n\n\nsize\n244.0\n2.569672e+00\n9.510998e-01\n1.000000e+00\n2.000000e+00\n2.000000e+00\n3.000000e+00\n6.000000e+00\n\n\nprice_per_person\n244.0\n7.888197e+00\n2.914234e+00\n2.880000e+00\n5.800000e+00\n7.255000e+00\n9.390000e+00\n2.027000e+01\n\n\nCC Number\n244.0\n2.563496e+15\n2.369340e+15\n6.040679e+10\n3.040731e+13\n3.525318e+15\n4.553675e+15\n6.596454e+15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndf_tips.head(5)\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n\n\n\n\n\n\nprint(df_tips[\"size\"] ==3)\nconditional_size = df_tips[\"size\"] ==3\n\n0      False\n1       True\n2       True\n3      False\n4      False\n       ...  \n239     True\n240    False\n241    False\n242    False\n243    False\nName: size, Length: 244, dtype: bool\n\n\n\ndf_tips[conditional_size].head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n16\n10.33\n1.67\nFemale\nNo\nSun\nDinner\n3\n3.44\nElizabeth Foster\n4240025044626033\nSun9715\n\n\n17\n16.29\n3.71\nMale\nNo\nSun\nDinner\n3\n5.43\nJohn Pittman\n6521340257218708\nSun2998\n\n\n18\n16.97\n3.50\nFemale\nNo\nSun\nDinner\n3\n5.66\nLaura Martinez\n30422275171379\nSun2789\n\n\n\n\n\n\n\n\nconditional= (df_tips[\"size\"]==3) & (df_tips[\"total_bill\"]&gt;20)\nprint(conditional)\n\n0      False\n1      False\n2       True\n3      False\n4      False\n       ...  \n239     True\n240    False\n241    False\n242    False\n243    False\nLength: 244, dtype: bool\n\n\n\ndf_tips[conditional].head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n19\n20.65\n3.35\nMale\nNo\nSat\nDinner\n3\n6.88\nTimothy Oneal\n6568069240986485\nSat9213\n\n\n35\n24.06\n3.60\nMale\nNo\nSat\nDinner\n3\n8.02\nJoseph Mullins\n5519770449260299\nSat632\n\n\n39\n31.27\n5.00\nMale\nNo\nSat\nDinner\n3\n10.42\nMr. Brandon Berry\n6011525851069856\nSat6373\n\n\n48\n28.55\n2.05\nMale\nNo\nSun\nDinner\n3\n9.52\nAustin Fisher\n6011481668986587\nSun4142\n\n\n\n\n\n\n\n\ndf_tips[(df_tips[\"size\"]==3) & (df_tips[\"total_bill\"]&gt;20)].head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n19\n20.65\n3.35\nMale\nNo\nSat\nDinner\n3\n6.88\nTimothy Oneal\n6568069240986485\nSat9213\n\n\n35\n24.06\n3.60\nMale\nNo\nSat\nDinner\n3\n8.02\nJoseph Mullins\n5519770449260299\nSat632\n\n\n39\n31.27\n5.00\nMale\nNo\nSat\nDinner\n3\n10.42\nMr. Brandon Berry\n6011525851069856\nSat6373\n\n\n48\n28.55\n2.05\nMale\nNo\nSun\nDinner\n3\n9.52\nAustin Fisher\n6011481668986587\nSun4142\n\n\n\n\n\n\n\n\nweekend= [\"Sun\", \"Sat\"]\nconditional_in= df_tips[\"day\"].isin(weekend)\ndf_tips[conditional_in].head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n\n\n\n\n\n\ndf_tips.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n\n\n\n\n\n\n\n\n\ndf_tips[\"day\"].unique()\n\narray(['Sun', 'Sat', 'Thur', 'Fri'], dtype=object)\n\n\n\ndf_tips.drop_duplicates([\"day\",\"time\"])[[\"day\",\"time\"]]\n\n\n\n\n\n\n\n\nday\ntime\n\n\n\n\n0\nSun\nDinner\n\n\n19\nSat\nDinner\n\n\n77\nThur\nLunch\n\n\n90\nFri\nDinner\n\n\n220\nFri\nLunch\n\n\n243\nThur\nDinner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprint(df_tips[\"day\"])\nprint(\"=======\")\nprint(df_tips.day)\n\n0       Sun\n1       Sun\n2       Sun\n3       Sun\n4       Sun\n       ... \n239     Sat\n240     Sat\n241     Sat\n242     Sat\n243    Thur\nName: day, Length: 244, dtype: object\n=======\n0       Sun\n1       Sun\n2       Sun\n3       Sun\n4       Sun\n       ... \n239     Sat\n240     Sat\n241     Sat\n242     Sat\n243    Thur\nName: day, Length: 244, dtype: object\n\n\n\ndf_tips[[\"day\",\"time\"]]\n\n\n\n\n\n\n\n\nday\ntime\n\n\n\n\n0\nSun\nDinner\n\n\n1\nSun\nDinner\n\n\n2\nSun\nDinner\n\n\n3\nSun\nDinner\n\n\n4\nSun\nDinner\n\n\n...\n...\n...\n\n\n239\nSat\nDinner\n\n\n240\nSat\nDinner\n\n\n241\nSat\nDinner\n\n\n242\nSat\nDinner\n\n\n243\nThur\nDinner\n\n\n\n\n244 rows × 2 columns\n\n\n\n\n\n\n\ndf_tips[\"tips_percentage\"]= df_tips[\"tip\"]/df_tips[\"total_bill\"]*100\n\ndf_tips.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\ntips_percentage\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n5.944673\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n16.054159\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n16.658734\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n13.978041\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n14.680765\n\n\n\n\n\n\n\n\n\n\n\ndf_tips.rename(columns={\"tips_percentage\":\"tips_percentage_%\"}, inplace=True)\ndf_tips.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\ntips_percentage_%\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n5.944673\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n16.054159\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n16.658734\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n13.978041\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n14.680765\n\n\n\n\n\n\n\n\n\n\n\n#relocate tips_percentage_% column to the rightmost\ncols= list(df_tips.columns)\ncols= [cols[-1]]+ cols[:-2]\n\ndf_tips= df_tips[cols]\n\n\ndf_tips\n\n\n\n\n\n\n\n\ntips_percentage_%\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\n\n\n\n\n0\n5.944673\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\n\n\n1\n16.054159\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\n\n\n2\n16.658734\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\n\n\n3\n13.978041\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\n\n\n4\n14.680765\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n20.392697\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\n\n\n240\n7.358352\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\n\n\n241\n8.822232\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\n\n\n242\n9.820426\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\n\n\n243\n15.974441\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n9.39\nMichelle Hardin\n3511451626698139\n\n\n\n\n244 rows × 11 columns"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-akhir.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-akhir.html",
    "title": "Tugas Akhir",
    "section": "",
    "text": "Tugas Akhir\nKembali ke Persamaan Diferensial Numerik\nTulisan di bawah ini adalah salinan dari: https://linevoom.line.me/post/1168595921012325899\n[TUGAS AKHIR PRAKTIKUM SAINS DATA dan PDNUM]\nSelamat sore, warga Departemen Matematika!\nBerikut ini adalah tugas praktikum yang harus dikerjakan bagi mahasiswa yang mengambil mata kuliah Sains Data dan PDNum.\nhttps://drive.google.com/drive/folders/10hEyh6MTFnrx2kwC4IEL74cOCo-_NoNQ\nTugas dikerjakan secara individu dengan ketentuan yang sudah tentukan di masing masing tugas yang tertera pada tautan di atas.\nTugas dikumpulkan paling lambat pada hari Rabu, 21 Juni 2023 pukul 23.59 WIB melalui tautan berikut.\nSains Data: https://forms.gle/4i2tj8Zf7v7kDPoG7\nPDNum: https://forms.gle/m8s6iqyufpH9g3fUA\nDemikian informasi yang dapat kami sampaikan. Jika ada pertanyaan lebih lanjut, silakan hubungi kontak berikut.\nNarahubung:\n■ Justin (LINE: iamjustin10)\n■ Carles (LINE: Carles_octavianus)\n■ Tulus (LINE: tlsnew)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-02.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-02.html",
    "title": "Tugas Praktikum 2 PD Numerik",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\n\n\n\nTugas ini dikerjakan secara individu.\nTerdapat satu (1) soal yang harus dijawab.\nFile yang harus diunggah terdiri dari:\n\nbeberapa function file sesuai kebutuhan. Penamaan untuk function file dibebaskan, selama masih relevan dengan isi fungsinya (dilarang menamakan function file “adamsorde5.m” jika isinya adalah metode Runge-Kutta).\nsatu (1) script file untuk jawaban. Penamaannya adalah “soal.m” untuk soal yang diberikan.\nsatu (1) file PDF untuk penjelasan keseluruhan soal. Penjelasan diketik dalam Word atau sejenisnya dengan format penamaan “Penjelasan.pdf”.\n\nSemua file disatukan dalam satu file .zip dengan format penamaan:\n[Nama]_[NPM]_[Kelas SIAK]_Tugas 2_Prak PDNum.zip\nContoh: “Cristiano-Ronaldo_2101234567_C_Tugas 2_Prak PDNum.zip”\nBatas pengumpulan tugas ini adalah Minggu, 16 April 2023, pukul 23.59 WIB.\nTugas dikumpulkan melalui gform sesuai dengan kelas masing-masing:\nLink: https://bit.ly/Tugas2PrakPDNum (akses menggunakan akun @sci atau @ui)\nDilarang melakukan plagiarisme. Jika terdapat mahasisya yang terindikasi melakukan plagiarisme, maka mahasiswa tersebut memperoleh nilai 0 untuk tugas ini.\nApabila ada yang ingin ditanyakan anda dapat bertanya pada kolom komentar atau, silakan mengontak salah satu kontak berikut:\n\nLINE: iamjustin10 (Justin)\n\n\n\n\n\nArthur adalah seorang pelajar yang menyukai matematika dan pemrograman. Suatu hari, saat Arthur sedang membaca kitab Burden, dia menemukan algoritma Adams predictor-corrector dan menyadari jika cara kerja dari metode tersebut merupakan gabungan dari metode one-step Runge-Kutta orde 4, metode multistep eksplisit Adams-Bashforth 4-step, dan metode multistep implisit Adams-Moulton 3-step.\nArthur penasaran apakah metode predictor-corrector ini bisa dibuat dengan metode yang berbeda dari jenis yang sama. Dia pun mencoba mengubah metode multistep eksplisit dan implisitnya dengan Adams-Bashforth 5-step dan Adams-Moulton 4-step, dengan harapan aproksimasinya akan lebih akurat.\nBantulah Arthur dalam membuat algoritma dari metode buatannya, dan bandingkan dengan metode Adams predictor-corrector sebelumnya. Ujilah menggunakan IVP:\n\\(y^{\\prime}=y-t^2+1,\\; 0\\leq t\\leq2,\\; y(0)=0.5\\)\ndengan stepsize \\(h=0.1\\), jika diketahui solusi eksak dari IVP tersebut adalah\n\\(y(t)=(t+1)^2-0.5 e^t\\)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-02.html#petunjuk-pengumpulan-tugas",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-02.html#petunjuk-pengumpulan-tugas",
    "title": "Tugas Praktikum 2 PD Numerik",
    "section": "",
    "text": "Tugas ini dikerjakan secara individu.\nTerdapat satu (1) soal yang harus dijawab.\nFile yang harus diunggah terdiri dari:\n\nbeberapa function file sesuai kebutuhan. Penamaan untuk function file dibebaskan, selama masih relevan dengan isi fungsinya (dilarang menamakan function file “adamsorde5.m” jika isinya adalah metode Runge-Kutta).\nsatu (1) script file untuk jawaban. Penamaannya adalah “soal.m” untuk soal yang diberikan.\nsatu (1) file PDF untuk penjelasan keseluruhan soal. Penjelasan diketik dalam Word atau sejenisnya dengan format penamaan “Penjelasan.pdf”.\n\nSemua file disatukan dalam satu file .zip dengan format penamaan:\n[Nama]_[NPM]_[Kelas SIAK]_Tugas 2_Prak PDNum.zip\nContoh: “Cristiano-Ronaldo_2101234567_C_Tugas 2_Prak PDNum.zip”\nBatas pengumpulan tugas ini adalah Minggu, 16 April 2023, pukul 23.59 WIB.\nTugas dikumpulkan melalui gform sesuai dengan kelas masing-masing:\nLink: https://bit.ly/Tugas2PrakPDNum (akses menggunakan akun @sci atau @ui)\nDilarang melakukan plagiarisme. Jika terdapat mahasisya yang terindikasi melakukan plagiarisme, maka mahasiswa tersebut memperoleh nilai 0 untuk tugas ini.\nApabila ada yang ingin ditanyakan anda dapat bertanya pada kolom komentar atau, silakan mengontak salah satu kontak berikut:\n\nLINE: iamjustin10 (Justin)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-02.html#soal",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-02.html#soal",
    "title": "Tugas Praktikum 2 PD Numerik",
    "section": "",
    "text": "Arthur adalah seorang pelajar yang menyukai matematika dan pemrograman. Suatu hari, saat Arthur sedang membaca kitab Burden, dia menemukan algoritma Adams predictor-corrector dan menyadari jika cara kerja dari metode tersebut merupakan gabungan dari metode one-step Runge-Kutta orde 4, metode multistep eksplisit Adams-Bashforth 4-step, dan metode multistep implisit Adams-Moulton 3-step.\nArthur penasaran apakah metode predictor-corrector ini bisa dibuat dengan metode yang berbeda dari jenis yang sama. Dia pun mencoba mengubah metode multistep eksplisit dan implisitnya dengan Adams-Bashforth 5-step dan Adams-Moulton 4-step, dengan harapan aproksimasinya akan lebih akurat.\nBantulah Arthur dalam membuat algoritma dari metode buatannya, dan bandingkan dengan metode Adams predictor-corrector sebelumnya. Ujilah menggunakan IVP:\n\\(y^{\\prime}=y-t^2+1,\\; 0\\leq t\\leq2,\\; y(0)=0.5\\)\ndengan stepsize \\(h=0.1\\), jika diketahui solusi eksak dari IVP tersebut adalah\n\\(y(t)=(t+1)^2-0.5 e^t\\)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/pdnum2023.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/pdnum2023.html",
    "title": "Praktikum Persamaan Diferensial Numerik 2023 Genap (Kurikulum 2020)",
    "section": "",
    "text": "Kembali ke Praktikum\nModul ini adalah salinan dari: https://github.com/carlesoctav/pdnum-2023\n\nTimeline\n\npraktikum-1: 1 Maret 2023, presensi [TODO: link]\npraktikum-2, praktikum-2.2: 8 Maret 2023, presensi [TODO: link]\npraktikum-3: 15 Maret 2023, presensi[TODO: link]\nTugas-1 (PDNUM): 22 Maret 2023, tempat pengumpulan: https://bit.ly/Tugas1PrakPDNum\nTugas-2 (PDNUM): 16 April 2023, tempat pengumpulan: https://bit.ly/Tugas2PrakPDNum\nTugas-3 (PDNUM): 16 April 2023, tempat pengumpulan: https://ristek.link/Tugas3PrakPDNum\npraktikum-4\npraktikum-5 : 3 Mei 2023, presensi bit.ly/PresensiPrak5PDNum\npraktikum-6\ntugas-akhir"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-05.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-05.html",
    "title": "Week-05 (Finite Difference Methods)",
    "section": "",
    "text": "Week-05 (Finite Difference Methods)\nKembali ke Persamaan Diferensial Numerik\nyang akan dibahas - Metode Beda Hingga untuk Masalah Linear\n\nMetode Beda Hingga untuk Masalah Nonlinear\n\nMetode ini digunakan untuk mengaproksimasi masalah linear dalam bentuk:\n\\[\\begin{gathered}\ny^{\\prime \\prime}=p(x) y^{\\prime}+q(x) y+r(x), \\quad a \\leq x \\leq b \\\\\ny(a)=\\alpha, y(b)=\\beta\n\\end{gathered}\\]\n\\[\\begin{gathered}\nw_{0}=\\alpha, \\quad w_{n+1}=\\beta \\\\\n-\\left(1+\\frac{h}{2} p\\left(x_{i}\\right)\\right) w_{i-1}+\\left(2+h^{2} q\\left(x_{i}\\right)\\right) w_{i}-\\left(1-\\frac{h}{2} p\\left(x_{i}\\right)\\right) w_{i+1}=-h^{2} r\\left(x_{i}\\right)\n\\end{gathered}\\]\nBentuk tersebut dapat dibuat sebagai suatu SPL:\n\\[\nA \\mathbf{w}=\\mathbf{b}\n\\]\n\n\\(\\mathbf{w}=\\left[\\begin{array}{c}w_{1} \\\\ w_{2} \\\\ \\vdots \\\\ w_{N-1} \\\\ w_{N}\\end{array}\\right], \\quad\\) and \\(\\quad \\mathbf{b}=\\left[\\begin{array}{c}-h^{2} r\\left(x_{1}\\right)+\\left(1+\\frac{h}{2} p\\left(x_{1}\\right)\\right) w_{0} \\\\ -h^{2} r\\left(x_{2}\\right) \\\\ \\vdots \\\\ -h^{2} r\\left(x_{N-1}\\right) \\\\ -h^{2} r\\left(x_{N}\\right)+\\left(1-\\frac{h}{2} p\\left(x_{N}\\right)\\right) w_{N+1}\\end{array}\\right]\\).\nSPL tersebut akan diselesaikan dengan metode faktorisasi Crout (lihat algoritma 6.7). (basicly ini nyari inverse A secara linear, makanya runtime dari algortima ini adalah \\(O(n)\\))\nAlgoritma dari metode beda hingga linear:\nfunction [xt,w]=linfdm(p,q,r,a_boundary,b_boundary,alpha,beta,n)\n  h=(b_boundary-a_boundary)/(n+1); %stepsize\n  a=zeros(n,1); %diagonal sistem persamaannya\n  b=zeros(n,1); % right diagonal sistem persamaannya\n  c=zeros(n,1); %left diagonal sistem persamaannya\n  d=zeros(n,1); %vektor b (Ay=b) pada sistem persamaannya\n  l=zeros(n,1); % main diagonal of lower triangle matrix\n  u=zeros(n,1); %right diagonal of upper triangle matrix\n  z= zeros(n,1); %solution of Lz=b\n  w=zeros(n+1,1); %solusi aproksimasi dengan linear fdm\n  xt=[a_boundary:h:b_boundary]; %mesh_point\n  x=a_boundary+h;\n\n  %konstruksi matrix tridiagonalnya\n  a(1)=2+(h^2)*q(x);\n  b(1)= -1+(h/2)*p(x);\n  d(1)=-h^2*r(x) +(1+(h/2)*p(x))*alpha;\n\n  for i = 2:n-1\n    x= a_boundary+i*h;\n    a(i)=2+h^2*q(x); %diagonal\n    b(i)=-1+(h/2)*p(x);\n    c(i)=-1-(h/2)*p(x);\n    d(i)=-h^2*r(x);\n  endfor\n\n  x=b_boundary-h;\n  a(n)=2+h^2*q(x);\n  c(n)=-1-(h/2)*p(x);\n  d(n)=-h^2*r(x)+(1-(h/2)*p(x))*beta;\n\n  %matriks tridiagonalnya sudah didapatkan,\n  %akan diselesaikan dengan LU Decomposition (crout factorization)\n\n  l(1)= a(1);\n  u(1)=b(1)/a(1);\n  z(1)=d(1)/l(1);\n\n  for i= 2:n-1\n    l(i)=a(i)-c(i)*u(i-1);\n    u(i)=b(i)/l(i);\n    z(i)=(d(i)-c(i)*z(i-1))/l(i);\n\n  endfor\n\n  l(n)=a(n)-c(n)*u(n-1);\n  z(n)=(d(n)-c(n)*z(n-1))/l(n);\n\n  %konstruksi akhir w-nya\n  w(n+1)=beta;\n  w(n)=z(n);\n  for i = n-1:-1:1\n    w(i)=z(i)-u(i)*w(i+1);\n  endfor\n\n  w=[alpha;w];\n  xt=transpose(xt);\n\nendfunction\nAkan kita uji dengan masalah syarat batas:\n\\[\n\\begin{aligned}\ny^{\\prime \\prime} & =-\\frac{4}{x} y^{\\prime}-\\frac{2}{x^2} y+\\frac{2 \\ln x}{x^2}, \\quad 1 \\leq x \\leq 2 \\\\\ny(1) & =\\frac{1}{2}, \\quad y(2)=\\ln 2\n\\end{aligned}\n\\] Solusi eksak: \\[\ny(x)=\\frac{4}{x}-\\frac{2}{x^2}+\\ln x-\\frac{3}{2}\n\\]\np= @(x) (-4/x); %function p(x)\nq= @(x) (-2/x^2);%function q(x)\nr=@(x) 2*log(x)/(x^2); %function r(x)\na_boundary=1; %batas kiri domain\nb_boundary=2; %batas kanan domain\nn=19; %banyaknya partisi (agar h=0.05 pilih n=19)\nalpha=0.5; %y(a)=alpha\nbeta=log(2); %y(b)=beta\n[x_grid,w]=linfdm(p,q,r,a_boundary,b_boundary,alpha,beta,n) %memangil fungsinya\n\nf_anal=@(x)4./x -2./(x.^2) +log(x)-1.5;\nsol_anal=f_anal(x_grid)\nerror=abs(sol_anal-w);\n\n[x_grid,w,sol_anal,error]\n\n\n%bikint tabel dan grafiknya :D\n\nfplot(f_anal, [a_boundary,b_boundary],'b')\nhold on;\nscatter(x_grid,w,'r')\nlegend('solusi analitik', 'solusi linear FDM');\nlegend(\"location\", \"northwest\");\nMetode ini digunakan untuk mengaproksimasi masalah linear dalam bentuk:\n\\[\n\\begin{gathered}\ny^{\\prime \\prime}=f\\left(x, y, y^{\\prime}\\right), \\quad a \\leq x \\leq b \\\\\ny(a)=\\alpha, y(b)=\\beta\n\\end{gathered}\n\\]\nAproksimasi menggunakan metode ini serupa dengan saat menggunakan metode beda hingga linear, dengan perbedaan kita juga menambahkan metode Newton dalam penyelesaiannya.\nAlgoritma dari metode beda hingga nonlinear:\nfunction [t_grid,w]=nonlinear_FDM_naive(f,f_y,f_yprime,a,b,n,alpha,beta,max_iter,TOL)\n  h=(b-a)/(n+1); %sepsize\n  w=zeros(n,1); %vektor solusi aproksimasi\n  t_grid=[a:h:b]; %mesh_poitnya\n  J=zeros(n,n); %matriks jacobian\n  F=zeros(n,1); %vektor fungsi  F=(f_1,f_2,...,f_n) yang dievaluasi di x_k\n\n  for i=1:n %inisialisasi solusi awal\n    w(i)=alpha+i*(beta-alpha)/(b-a)*h;\n  endfor\n  k=1;\n  while k&lt;=max_iter %lakukan iterasi jika masih belum didapat kriteria stopnya\n\n    %solve nonlinear sistem tersebut dengan metode newton\n    x=a+h;\n    %kontruksi matriks Jacobian, dan vektor F-nya\n    t=(w(2)-alpha)/(2*h);\n    J(1,1)=2+h^2*f_y(x,w(1),t); %main diagoanal\n    J(1,2)=-1+(h/2)*f_yprime(x,w(1),t); %right diagonal\n    F(1)=(2*w(1)-w(2)-alpha+h^2*f(x,w(1),t));\n    for i =2:n-1\n      x=a+i*h;\n      t=(w(i+1)-w(i-1))/(2*h);\n      J(i,i)=2+h^2*f_y(x,w(i),t); %main diagoanal\n      J(i,i+1)=-1+(h/2)*f_yprime(x,w(i),t); %main diagoanal\n      J(i,i-1)=-1-(h/2)*f_yprime(x,w(i),t); %left diagoanal\n      F(i)=(2*w(i)-w(i+1)-w(i-1)+h^2*f(x,w(i),t));\n    endfor\n     x=b-h;\n     t=(beta-w(n-1))/(2*h);\n     J(n,n)=2+h^2*f_y(x,w(n),t); %main diagonal\n     J(n,n-1)=-1-(h/2)*f_yprime(x,w(n),t); %right diagonal\n     F(n)=(2*w(n)-w(n-1)-beta+h^2*f(x,w(n),t));\n\n\n\n    v=inverse(J)*F; %vector v adalah product dari J^-1 F\n    w= w-v; % lakukan update nilai pada w\n\n    if norm(v,2)&lt;= TOL %kriteria stop jika norm(v)&lt;=toleransinya\n      break;\n     else\n        k=k+1; %jika belum memenuhi kriteria stop terus lanjut iterasinya (memperbaiki nilai w)\n    endif\n  endwhile\n  w=[alpha ; w ; beta]; %konstruksi akhir w\n  t_grid=transpose(t_grid); % %transpose meshpoint\n  % untuk konsistensi dimensi saja\n\nendfunction\n\nGunakan metode beda hingga nonlinear dengan \\(h=0.1\\) dan toleransi \\(10^{-4}\\) untuk mengaproksimasi BVP berikut: \\[\n\\begin{aligned}\ny^{\\prime \\prime} & =y^{\\prime}+2(y-\\ln x)^3-\\frac{1}{x}, \\quad 2 \\leq x \\leq 3 \\\\\ny(2) & =\\frac{1}{2}+\\ln 2, \\quad y(3)=\\frac{1}{3}+\\ln 3\n\\end{aligned}\n\\] Solusi eksak: \\[\ny(x)=\\frac{1}{x}+\\ln x\n\\]\n\nf=@(x,y,yp) yp+2*(y-log(x))^3-1/x ; %fungsi f pada y=f(x,y,y')\nf_y=@(x,y,yp) 6*(y-log(x))^2; %turunan fungsi f terhadap y\nf_yp=@(x,y,yp) 1; %turunan fungsi f terhadap yprime\na=2; %left boundary\nb=3; %right boundary\nalpha=0.5+log(2); %y(a)\nbeta=1/3+ log(3); %y(b)\nn=9; %banyaknya partisi (pilih n=9 sehingga h=0.1)\nmaxiter=30; %masksimal iterasi newton methodnya\nTOL=10^(-4); %toleransi nilai (untuk kriteria stop)\n\n%memanggil fungsi nonlinear_FDM_naive\n[x_grid,w]=nonlinear_FDM_naive(f,f_y,f_yp,a,b,n,alpha,beta,maxiter,TOL)\nf_anal= @(x) 1./x +log(x); %sol analitik\n\n%membuat grafiknya\nfplot(f_anal, [a,b],'b')\nhold on;\nscatter(x_grid,w,'r')\nlegend('solusi analitik', 'solusi linear FDM');\nlegend(\"location\", \"northwest\");\n\n\n\n\n%membuat tabel saja.\n\nsol_anal=f_anal(x_grid); %sol analitik di meshpoint\nerror=abs(w-sol_anal); %error\n[x_grid,w,sol_anal,error]"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-03.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-03.html",
    "title": "Week-03 (Multistep dan Sistem persamaan differential)",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-03.html#multistep",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-03.html#multistep",
    "title": "Week-03 (Multistep dan Sistem persamaan differential)",
    "section": "Multistep",
    "text": "Multistep\nMetode-metode sebelumnya, seperi Euler, Runge-Kutta, dan kawan-kawannya adalah metode jenis one-step, karena kita hanya menggunakan informasi dari satu nilai \\(t_{i}\\). Pada modul berikut akan dijelaskan mengenai metode multistep, dimana kita menggunakan lebih dari satu nilai \\(t_{i}\\) untuk membuat aproksimasi.\nTerdapat dua jenis metode multistep, yaitu:\n\nMultistep eksplisit, dimana kita mengaproksimasi nilai pada \\(t_{i+1}\\) menggunakan nilai \\(t\\) sebelumnya.\nMultistep implisit, dimana kita mengaproksimasi nilai pada \\(t_{i+1}\\) menggunakan nilai pada \\(t\\) sebelumnya, sekaligus nilai pada \\(t_{i+1}\\) itu sendiri.\n\nUntuk bagian awal, kita hanya akan menggunakan multistep eksplisit, dan multistep implisit akan dijelaskan kemudian menggunakan cara lain.\n\nMultistep Eksplisit: Metode \\(n\\)-step Adams-Bashforth\nMetode \\(n\\)-step Adams-Bashforth menggunakan \\(n\\) titik sebelumnya untuk mengaproksimasi nilai. Karena metode ini adalah metode multistep, maka \\(n\\) nilai awalnya pun harus diperoleh terlebih dahulu. Misal kita ingin menggunakan metode Adams-Bashforth orde 3 , maka \\(w_{1}, w_{2}\\), dan \\(w_{3}\\) harus ada terlebih dahulu sebelum dilanjutkan ke metode Adams-Bashforth. Nilai-nilai awal tersebut dapat diperoleh dari metode-metode one-step sebelumnya, seperti metode Runge-Kutta, yang akan kita gunakan.\nBerikut rumus untuk metode \\(n\\)-step Adams-Bashforth, masing-masing sesuai dengan jumlah step nya.\n\nTwo-step Adams Bashforth\n\n\\[\n\\begin{gathered}\nw_{0}=\\alpha, \\quad w_{1}=\\alpha_{1}, \\\\\nw_{i+1}=w_{i}+\\frac{h}{2}\\left[3 f\\left(t_{i}, w_{i}\\right)-f\\left(t_{i-1}, w_{i-1}\\right)\\right]\n\\end{gathered}\n\\]\n\nThree-step Adams-Bashforth\n\n\\[\n\\begin{gathered}\nw_{0}=\\alpha, \\quad w_{1}=\\alpha_{1}, \\quad w_{2}=\\alpha_{2}, \\\\\nw_{i+1}=w_{i}+\\frac{h}{12}\\left[23 f\\left(t_{i}, w_{i}\\right)-16 f\\left(t_{i-1}, w_{i-1}\\right)+5 f\\left(t_{i-2}, w_{i-2}\\right)\\right]\n\\end{gathered}\n\\]\n\nFour-step Adams-Bashforth\n\n\\[\n\\begin{gathered}\nw_{0}=\\alpha, \\quad w_{1}=\\alpha_{1}, \\quad w_{2}=\\alpha_{2}, \\quad w_{3}=\\alpha_{3} \\\\\nw_{i+1}=w_{i}+\\frac{h}{24}\\left[55 f\\left(t_{i}, w_{i}\\right)-59 f\\left(t_{i-1}, w_{i-1}\\right)+37 f\\left(t_{i-2}, w_{i-2}\\right)-9 f\\left(t_{i-3}, w_{i-3}\\right)\\right]\n\\end{gathered}\n\\]\n\nFive-step Adams-Bashforth\n\n\\[\n\\begin{gathered}\nw_{0}=\\alpha, \\quad w_{1}=\\alpha_{1}, \\quad w_{2}=\\alpha_{2}, \\quad w_{3}=\\alpha_{3}, \\quad w_{4}=\\alpha_{4}, \\\\\nw_{i+1}=w_{i}+\\frac{h}{720}\\left[1901 f\\left(t_{i}, w_{i}\\right)-2774 f\\left(t_{i-1}, w_{i-1}\\right)+2616 f\\left(t_{i-2}, w_{i-2}\\right)\\right. \\\\\n\\left.-1274 f\\left(t_{i-3}, w_{i-3}\\right)+251 f\\left(t_{i-4}, w_{i-4}\\right)\\right]\n\\end{gathered}\n\\]\nprogram untuk two-step Adams-Bashforth:\n\n%function_file\nfunction [t, w] = adams2(f, a, b, n, alpha)\n  % Inisiasi variabel awal\n  h = (b - a) / n;\n  t = zeros(n + 1, 1);\n  w = zeros(n + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  \n  % Mencari t(2) dan w(2) menggunakan Runge-Kutta orde 4\n  i = 1;\n  t(i + 1) = t(i) + h;\n  m1 = h * f(t(i), w(i));\n  m2 = h * f(t(i) + (h/2), w(i) + (m1/2));\n  m3 = h * f(t(i) + (h/2), w(i) + (m2/2));\n  m4 = h * f(t(i + 1), w(i) + m3);\n  w(i+1) = w(i) + (m1 + 2*m2 + 2*m3 + m4) / 6;\n  \n  % Algoritma utama Adams-Bashforth\n  for i = 2:n\n    t(i + 1) = t(i) + h;\n    k1 = f(t(i), w(i));\n    k2 = f(t(i-1), w(i-1));\n    w(i+1) = w(i) + (h/2) * (3*k1 - k2);\n  endfor\nendfunction\n\nBerikut ini adalah contoh pengerjaaannya dengan menggunakan metode two-step Adams-Bashforth.\n\n%script file\nf = @(t, y) (y - t ^ 2 + 1);\na = 0;\nb = 2;\nalpha = 0.5;\nn=20\n[t1, w1] = adams2(f,a,b,n,alpha)\n\n[t1,w1]\n\nsln = @(t) (t + 1) ^ 2 - 0.5 * exp(t);\n\nfplot(sln, [0, 2], 'k');\nhold on;\nscatter(t1, w1, 'r');\n\n\n\nMultistep Implisit: Metode \\(n\\)-step Adams-Moulton\nSerupa dengan metode adams-bashforth, bedanya persamaan iteratif \\(w_{i+1}\\) belum dalam bentuk yang dapat dihitung langsung (melainkan bentuknya implisit). Berikut ini adalah list persamaan iteratifnya (diambil dari buku burden).\n\nAdams-Moulton Two-Step Implicit Method \\[\n\\begin{aligned}\nw_0 & =\\alpha, \\quad w_1=\\alpha_1, \\\\\nw_{i+1} & =w_i+\\frac{h}{12}\\left[5 f\\left(t_{i+1}, w_{i+1}\\right)+8 f\\left(t_i, w_i\\right)-f\\left(t_{i-1}, w_{i-1}\\right)\\right],\n\\end{aligned}\n\\]\nAdams-Moulton Three-Step Implicit Method\n\n\\[\n\\begin{aligned}\nw_0 & =\\alpha, \\quad w_1=\\alpha_1, \\quad w_2=\\alpha_2, \\\\\nw_{i+1} & =w_i+\\frac{h}{24}\\left[9 f\\left(t_{i+1}, w_{i+1}\\right)+19 f\\left(t_i, w_i\\right)-5 f\\left(t_{i-1}, w_{i-1}\\right)+f\\left(t_{i-2}, w_{i-2}\\right)\\right],\n\\end{aligned}\n\\]\n\nAdams-Moulton Four-Step Implicit Method\n\n\\[\n\\begin{aligned}\nw_0= & \\alpha, \\quad w_1=\\alpha_1, \\quad w_2=\\alpha_2, \\quad w_3=\\alpha_3, \\\\\nw_{i+1}= & w_i+\\frac{h}{720}\\left[251 f\\left(t_{i+1}, w_{i+1}\\right)+646 f\\left(t_i, w_i\\right)\\right. \\\\\n& \\left.-264 f\\left(t_{i-1}, w_{i-1}\\right)+106 f\\left(t_{i-2}, w_{i-2}\\right)-19 f\\left(t_{i-3}, w_{i-3}\\right)\\right],\n\\end{aligned}\n\\]\nBentuk umum program yang akan dihasilkan\n\n%function_file\nfunction [t, w] = adam-moulton-general(f, a, b, n, alpha)\n  [\n    Inisialisai awal ...\n  ]\n  \n  [\n\n    Mencari nilai w_i lainnya yang dibutuhkan dengan rungge kutta jika \n    nilai awal tersebut tidak diberikan dengan runge-kutta\n  ]\n  \n  % Algoritma utama Adams-Bashforth\n\n\n  [\n    Iteratif algoritma adams-moulton\n\n    pada saat mencari $w_{i+1}$ gunakan metode numerik favorit anda.\n  ]\n\nendfunction\n\nTinjau bahwa, jika \\(f\\) linear, kita bisa mencarinya nilai bentuk explisit \\(W_{i+1}\\) dengan mudah. Dengan demikian, kita bisa mengganti metode numerik yang digunakan untuk mencari \\(w_{i+1}\\) dengan metode analitik.\n\n\nMultistep: Metode \\(n\\)-step Adams-Moulton-Bashforth (predictor-corrector)\nMenggunakan nilai \\(w_{i+1}\\) yang didapat secara implisit dari metode adams-moulton, kita masukkan ke dalam metode adams-bashforth untuk mengupdate nilai nilai \\(w_{i+1}\\) kembali.\nLihat contoh pada pada sub-chapter berikutnya."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-03.html#solusi-numerik-sistem-persamaan-differential",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-03.html#solusi-numerik-sistem-persamaan-differential",
    "title": "Week-03 (Multistep dan Sistem persamaan differential)",
    "section": "solusi numerik sistem Persamaan Differential",
    "text": "solusi numerik sistem Persamaan Differential\n\nRungge kutta untuk sistem persamaan differential (vectorize)\n\n%function_file\nfunction [t,w] = rk4_sys(f, a, b, n, y0)\n  %f :differential equation y_p = f(t,y)\n  %a :initial time\n  %b :final time\n  %n :number of steps\n  %y0 :initial value\n\n  h=(b-a)/n;\n  t=[a:h:b];\n  s= length(y0);\n  w=zeros(s,n+1);\n  w(:,1)=y0;\n\n  for i=1:n\n    k1=f(t(i),w(:,i));\n    k2=f(t(i)+h/2,w(:,i)+h*k1/2);\n    k3=f(t(i)+h/2,w(:,i)+h*k2/2);\n    k4=f(t(i)+h,w(:,i)+h*k3);\n    w(:,i+1)=w(:,i)+h*(k1+2*k2+2*k3+k4)/6;\n\nyang perlu dicatat disini fungsi f merupakan fungsi anonimus yang mengeluarkan vektor hasil evaluasinya.\nberikut ini adalah contoh penggunaan fungsi rk4_sys untuk sistem persamaan differential.\n\\[\n\\begin{aligned}\n& I_1^{\\prime}=f_1\\left(t, I_1, I_2\\right)=-4 I_1+3 I_2+6, \\quad I_1(0)=0 \\\\\n& I_2^{\\prime}=f_2\\left(t, I_1, I_2\\right)=0.6 I_1^{\\prime}-0.2 I_2=-2.4 I_1+1.6 I_2+3.6, \\quad I_2(0)=0 .\n\\end{aligned}\n\\] Persamasalahan berikut akan dikerjakan dengan rk4_sys dengan mengunakan titik awal \\(t_0=0\\) dan \\(t_{n+1}=1\\) dengan \\(n=10\\) partisi.\n\n%script file\nf=@(t, I) [-4 * I(1)+ 3 * I(2)+6 ; -2.4*I(1) + 1.6 * I(2)+3.6] % fungsi\n% perhatikan bahwa  I addalah vektor (hence ada I(1) dan I(2))\ny0=[0;0] % nilai awal\na=0 % titik awal\nb=1 % titik akhir\nn=10 % banyaknya partisi.\n\n[t_sys, w_sys] = rk4_sys(f,a,b,n,y0)\n\ntranspose([t_sys ; w_sys]) %rapikan format\n\nCobalah jalankan kode di atas dan lihat hasilnya. selanjutnya bandingkan hasil dengan jawaban pada buku.\n\n\n\nPredictor-Corrector: Metode Adams-Bashforth-Moulton 2-step untuk sistem persamaan differential (vectorize)\n\n% the multi-step second order method Adams-Bashforth-Moulton \n\n%function_file\nfunction [t,w] = abm2_sys(f,a,b,n,y0)\n  h=(b-a)/n;\n  t=[a:h:b];\n  s= length(y0);\n  w=zeros(s,n+1);\n  w(:,1)=y0;\n\n  w_serch= rk4_sys(f,a,b,n,y0);\n\n  w(:,2)= w_serch(:,2);\n\n  wnm1 = f(t(1),y0);\n  wn= f(t(2),y1);\n\n  for i=2:n\n    ws=w(:,i)+h/2*(3*wn-wnm1); % predictor\n    wnp1= f(t(i+1),ws); % predictor\n\n    w(:,i+1)=w(:,i)+h/2*(wn+wnp1); % corrector\n    wnm1=wn;\n    wn=f(t(i),w(:,i)); %corector"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02.html",
    "title": "Week-02 (IO, conditional, loop,script, and function)",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02.html#io",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02.html#io",
    "title": "Week-02 (IO, conditional, loop,script, and function)",
    "section": "IO",
    "text": "IO\nDalam pemrograman, seringkali pengguna diminta memberi suatu input, entah suatu nilai, string, dll., ke program, lalu program tersebut akan menggunakan input tersebut sebagai nilai dari suatu variabel. Hal ini juga dapat dilakukan pada Octave. Untuk membuat Octave meminta input dari user, gunakan syntax input(prompt), dengan prompt adalah string yang berisi pesan dalam input.\n\n    A = input(\"Masukkan suatu angka:\")\n\nJika tidak ingin membuat pesan input, cukup isi “” sebagai prompt\n\n    A = input(\"\")\n\nPerlu diketahui bahwa input yang diberikan pengguna akan dievaluasi sebagai ekspresi. Jadi, bisa saja input yang diberikan akan dievaluasi sebagai kode Octave. Sebagai contoh, jika kita memasukkan operasi bilangan pada inpu ….\n\nB = input(\"Operasi bilangan: \")\n\n… , maka operasi tersebut akan dievaluasi dan memberikan hasil operasinya. Jika kita memasukkan kode Octave, seperti meng-assign suatu variabel …\n\nC = input(\"Assign variabel: \")\n\n…, maka nilai dari variabel yagn di-assign akan masuk ke variabel input …\n\nx\n\nsekaligus variabel yang di-assign di dalam input. Jika kalian ingin agar input yang dimasukkan tidak dievaluasi, input tersebut dapat diubah terlebih dahulu menjadi string.\n\n D = input(\"Masukkan suatu string: \")\n\n\ntypeinfo(D) % untuk menentukan tipe data variabel\n\nBisa juga dengan menambah argumen pada input() menjadi input(prompt, “s”). Jika menambahkan argumen, maka apapun input yang kalian masukkan akan menjadi string tanpa perlu menggunakan tanda petik.\n\nE = input(\"Masukkan suatu string: \", \"s\")\n\n\ntypeinfo(E)\n\nSelain menggunakan input(), kita juga bisa menggunakan syntax menu(title, op1, op2, …). Syntax tersebut akan memunculkan kotak dialog dengan judul title dan pilihan op1, op2, dst. (sesuai yang dimasukkan). Syntax ini sangat berguna untuk program-program interaktif karena mempunyai GUI sendiri.\n\nF = menu(\"Pilih salah satu\", \"Pilihan 1\", \"Pilihan 2\", \"Pilihan 3\")\n\nTergantung pilihan kalian, variabel yang mengandung menu() akan diisi bilangan dari 1 hingga n tergantung banyaknya pilihan.\nUntuk output, mungkin cukup untuk memanggil variabel itu sendiri, seperti…\n\nC\n\n…, namun kalian juga bisa hanya memunculkan nilai dari variabelnya tanpa sekaligus memunculkan variabel tersebut dengan menggunakan syntax disp(). Syntax ini digunakan jika yang di-output hanya suatu variabel atau string simpel, dll.\n\ndisp(C)\n\n\ndisp(\"Ini adalah string\")\n\nJika yang ingin dimunculkan adalah pesan yang membutuhkan banyak formatting, kalian bisa menggunakan syntax printf(). Syntax tersebut dapat melakukan formatting pesan agar dapat menerima variabel selain string.\n\nx=input(\"masukkan nilai x: \")\n\n\nprintf(\"Ini adalah string %d\", x)\n\nPada contoh di atas, kita ingin agar variabel x dapat di-output bersama dengan pesan string. Kita menggunakan %d agar nilai x dapat di-print sebagai bilangan desimal. Jika variabelnya berisi string, maka gunakan %s. Jika variabelnya berisi float, gunakan %f untuk print dalam bentuk desimal, atau %.nf untuk sekaligus mengatur angka di belakang koma sebanyak n.\n\nprintf(\"pi = %.3f\", pi)\n\nJika float tersebut ingin di-print dalam notasi saintifik, gunakan %e atau %E. Keduanya hanya berbeda di hasil output yang berupa E (besar) ataupun e (kecil).\n\nprintf(\"pi = %.3e\", pi)\n\nJika ingin print karakter persen itu sendiri (%), gunakan %%.\nJika ada lebih dari satu formatting di satu printf(), maka variabelnya juga harus dimasukkan secara berurutan.\n\nprintf(\"pi = %.3f dan e = %.3e\", pi, e)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02.html#conditional",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02.html#conditional",
    "title": "Week-02 (IO, conditional, loop,script, and function)",
    "section": "Conditional",
    "text": "Conditional\nSeperti halnya bahas pemrograman, Octave pun juga memiliki conditional statements. Secara umum, conditional statement pada Octave berbentuk:\n\ncond\n  body\nendcond\n\nPada potongan kode di atas, cond adalah jenis conditional statement yagn digunakan, bisa berupa if, for, dan lainnya, body berisi kode yang dijalankan ketika cond terpenuhi, dan endcond adalah bagian penutup dari conditional statement, bisa berupa endif, endfor, dan lainnya tergantung cond apa yang digunakan.\nOperasi dasar yang digunakan pada conditional statements adalah operasi perbandingan, dimana pada dasarnya, dua atau lebih nilai dibandingkan dengan operator dan dicek apakah memenuhi atau tidak. Jika memenuhi, maka nilainya 1, dan jika tidak, maka nilainya 0. Ada 6 operator dasar untuk perbandingan:\n- sama dengan (==)\n- lebih dari (&gt;)\n- kurang dari (&lt;)\n- lebih dari atau sama dengan (&gt;=)\n- kurang dari atau sama dengan (&lt;=)\n- tidak sama dengan (!= atau ~=)\n\n2&lt;3\n\n\n4==5\n\nSelain operator di atas, ada juga syntax untuk perbandingan:\n- isequal(a, b, c, ...) mengecek apakah a, b, dan c semuanya sama.\n- strcmp(s1, s2) mengecek apakah s1 dan s2 adalah string yang sama.\n- strncmp(s1, s2, n) mengecek apakah n karakter pertama pada s1 dan s2 sama.\n- strcmpi(s1, s2) mirip strcmp(), namun tidak case-sensitive.\n- strncmpi(s1, s2, n) mirip strncmp(), namun tidak case-sensitive.\n\nisequal(1, 3, 5)\n\n\nstrcmp(\"ayam\", \"Ayam\")\n\n\nstrcmpi(\"ayam\", \"Ayam\")\n\n\nstrncmp(\"sayamakan\", \"saya makan\", 4)\n\nBerikut beberapa jenis conditional statement pada Octave. Kode-kode ini akan ditulis di editor.\nIf adalah conditional statement dasar dalam decision-making melalui perbandingan nilai. If memiliki 3 bentuk. Bentuk pertama:\n\nif (cond)\n  body;\nendif\n\nBentuk ini adalah bentuk paling simpel dalam menggunakan if. Jika cond bernilai 1, maka body dieksekusi, dan sebaliknya. Contoh:\n\nx = input( \"Masukkan nilai x: \")\nif x &gt; 0\n    printf(\"%d adalah bilangan positif.\\n\", x);\nendif\n\nBukanlah if jika tidak ada else. Untuk menggunakannya, cukup menyelipkan bagian else layaknya if sehingga menjadi:\n\nif (cond)\n  body1;\nelse\n  body2;\nendif\n\nContoh:\n\nx = input(\"Masukkan x: \");\nif mod(x, 2) == 0\n  printf(\"x genap.\\n\");\nelse\n  printf(\"x ganjil.\\n\");\nendif\n\nKita pun juga dapat membuat lebih dari 2 condition selain if dan else. Cukup tambahkan bagian elseif. Kita dapat menambahkan berapapun banyaknya elseif sesuka hati (dan komputer), selama bagian akhirnya adalah else.\n\nif (cond1)\n  body1;\nelseif (cond2)\n  body2;\nelse\n  body3;\nendif\n\nUntuk beberapa kasus, lebih jelas jika kita menggunakan model kode seperti di atas. Namun, terkadang kita ingin membuat program berjalan sesuai input, dan jika menggunakan if-else, kodenya akan terlihat jelek. Maka, kita juga bisa menggantinya dengan kode switch. Bentuk umum dari switch adalah:\n\nswitch (var)\n  case lab1\n    body1;\n  case lab2\n    body2;\n  otherwise\n    body3;\nendswitch\n\nPada kode di atas, var akan dicocokkan dengan lab1, lab2, dst. yang sesuai. Jika tidak ada yang sesuai, kode akan masuk ke bagian otherwise. Layaknya elseif, kita juga dapat menambahkan berapapun banyaknya case sesuka hati, selama terdapat paling tidak satu case (bahkan bagian otherwise opsional).\nContoh:\n\nmnu = input(\"Masukkan metode: \");\nswitch (mnu)\n  case 1\n    printf(\"Bisection.\\n\")\n  case 2\n    printf(\"Regula Falsi.\\n\")\n  otherwise\n    printf(\"Input tidak valid.\\n\")\nendswitch\n\nJika case berisi array, kode akan masuk case tersebut jika var sesuai dengan salah satu elemen di array tersebut.\n\nA = 7;\nswitch (A)\n  case {6, 7}\n    printf(\"A adalah 6 atau 7\");\n  otherwise\n    printf(\"A bukanlah 6 ataupun 7\");\nendswitch\n\nBentuk umum dari for adalah:"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02.html#loops",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02.html#loops",
    "title": "Week-02 (IO, conditional, loop,script, and function)",
    "section": "Loops",
    "text": "Loops\n\nLoops: For loop\n\nfor var = expr\n  body;\nendfor\n\nBiasanya isi dari expr adalah a:b, yang menyebabkan var diiterasi dari a hingga b. Secara umum, for akan meng-assign tiap kolom pada expr ke var (bentuk range a:b secara umum adalah vektor baris, sehingga iterasi kolom pada a:b adalah dari a hingga b). Contoh:\n\nfib = ones(1, 10); % ones(1, 10) = matriks 1x10 berisi 1.\nfor i = 3: 10\n  fib(i) = fib(i-1) + fib(i-2);\nendfor\ndisp(fib)\n\nKarena iterasinya antar kolom, maka jika expr adalah suatu matriks, maka var akan diiterasi sebagai vektor kolom. Contoh:\n\nfor i = [1, 2, 3; 4, 5, 6; 7, 8, 9]\n  i\nendfor\n\nBentuk umum dari while adalah:\n\n\nLoops: while\n\nwhile (cond)\n  body;\nendwhile\n\nSerupa dengan if, while akan menjalankan body jika cond bernilai taknol. Namun, akan diulang terus hingga cond bernilai nol, baru berhenti.\n\nfib = ones(1, 10);\ni = 3;\nwhile i &lt;= 10\n  fib(i) = fib(i-1) + fib(i-2);\n  i++;\nendwhile\ndisp(fib)\n\nPada contoh di atas, penting untuk memasukkan bagian i++ agar suatu saat nilai i akan lebih dari 10. Hati-hati menggunakan while, karena dapat mengakibatkan infinite loop.\n\n\nLoops: Do\nBentuk umum dari do adalah:\n\ndo\n  body\nuntil (cond)\n\nSekilas, do terlihat serupa dengan while. Yang membedakannya adalah do akan terus menjalankan body ketika cond bernilai 0 dan berhenti ketika cond bernilai taknol. Kondisi cond pada do juga berada di akhir, sehingga body pasti akan dijalankan paling tidak sekali. Perbedaan kecil selanjutnya adalah do tidak memakai enddo seperti layaknya endif, endwhile, dan sejenisnya.\n\nfib = ones(1, 10);\ni = 2;\ndo\n  i++;\n  fib(i) = fib(i-1) + fib(i-2);\nuntil i == 10\ndisp(fib)\n\n\n\nLoops: Break dan Continue\nbreak dan continue adalah dua statement yang digunakan dan hanya digunakan dalam loop. Statement break akan langsung mengeluarkan program dari loop, sedangkan continue akan langsung menuju iterasi selanjutnya tanpa menyelesaikan sisa kode pada badan loop.\nContoh perbedaan break dan continue:\n\na = [];\nfor i = 1:10\n  if mod(i, 5) == 0\n    break;\n  endif\n  a = [a, i];\nendfor\ndisp(a)\n\n\na = [];\nfor i = 1:10\n  if mod(i, 5) == 0\n    continue;\n  endif\n  a = [a, i];\nendfor\ndisp(a)\n\n\n\nFunction dan Script File\nSebelum kita lanjutkan, kita harus terlebih dahulu mengetahui tentang function file dan script file.\nFunction file adalah file yang dapat digunakan oleh Octave untuk memanggil fungsi yang telah didefinisikan di dalamnya. Function file ini berguna jika kalian ingin menggunakan fungsi tersebut secara berkala.\nScript file adalah file yang berisi kumpulan perintah Octave, layaknya script pemrograman. Script file berguna untuk pemrograman dan menjalankan/menyimpan suatu urutan perintah, sehingga bisa dijalankan kembali nantinya. Untuk selanjutnya, script file akan disebut “program”.\nPermasalahannya, kedua jenis file tersebut mempunyai ekstensi yang serupa (.m), namun function file tidak dapat dijalankan layaknya program.\nMisal kita mempunyai fungsi yang ingin disimpan dalam program bernama testfile.m (untuk sekarang kita akan abaikan dulu maksud dari tiap bagian dari fungsi ini. Intinya fungsi ini akan menampilkan variabel message yang kita masukkan.\n\nfunction test(message)\n  printf(\"%s\\n\", message);\nendfunction\n\ntest(\"AyatoBoba\");\n\nJika program tersebut dijalankan, akan muncul pesan peringatan…\nwarning: function name 'test' does not agree with function filename...\n…dan mungkin saja akan diikuti error lain. Jika kalian ingin membuat program, jangan gunakan function di line pertama yang dieksekusi.\nSekarang kita modifikasi testfile.m di atas.\n\n1;\nfunction test(message)\n  printf(\"%s\\n\", message);\nendfunction\n\ntest(\"AyatoBoba\");\n\nDi sini, kita menambahkan line yang tidak berpengaruh apa-apa dalam program kita sebelum line pendefinisian fungsi. Untuk membedakan function file dengan program, Octave mengecek perintah pertama yang dieksekusi. Jika perintah tersebut adalah pendefinisian fungsi, maka file tersebut akan dianggap sebagai function file, dan jika bukan, maka file tersebut akan dianggap sebagai program.\nSekarang kita masuk ke fungsi, pendefinisian, dan embel-embelnya. Fungsi adalah suatu bagian dari program yang nantinya akan dipanggil. Fungsi sangat berguna jika bagian program\ntersebut nantinya akan digunakan berkali-kali. Fungsi juga berguna agar pengorganisasian kode program lebih bagus. Syntax untuk pendefinisian fungsi adalah:\n\nfunction name\n  body\nendfunction\n ```\n\n\nPotongan kode di atas akan membuat fungsi name dengan body adalah isi dari fungsi tersebut. Untuk memanggil fungsi tersebut, cukup dengan memanggil name. Contoh:\n\n\n```{python}\nfunction bangun\n  printf(\"BANGUN!!!!!\\n\");\nendfunction\n\nbangun;\n\nPada kedua contoh di atas, fungsinya tidak benar-benar memberikan suatu value, melainkan hanya sekedar output. Dalam kebanyakan kasus, kita menggunakan fungsi agar bisa mendapatkan suatu nilai yang dapat di-assign ke suatu variabel. Agar kita bisa mendapatkan value, maka kita harus meng-assign variabel untuk return. Strukturnya menjadi:\n\nfunction retval = name (args)\n  body\nendfunction\n\nretval adalah variabel lokal (namanya tidak harus retval) yang akan digunakan sebagai return value sehingga dapat di-assign. retval bisa berupa variabel, jika kita ingin me-return satu value, ataupun bisa berupa list dari variabel jika ingin me-return lebih dari satu value. Contoh return satu nilai:\n\nfunction x = quadratic(a)\n  x = a^2;\nendfunction\n\ny = quadratic(2);\ndisp(y);\n\ncontoh return lebih dari satu nilai:\n\nfunction [am, gm] = AMGM(v)\n  am = sum(v) / length(v);\n  gm = nthroot(prod(v), length(v));\nendfunction\n\n\nV = [1, 2, 3, 4, 5, 6, 7, 8, 9];\n[amean, gmean] = AMGM(V);\nprintf(\"Arithmetic mean of %s is %g\\n\", mat2str(V), amean);\nprintf(\"Geometric mean of %s is %g\\n\", mat2str(V), gmean);\n\nOctave juga mempunyai syntax return sendiri. Namun, return pada Octave tidak digunakan untuk me-return suatu value, melainkan untuk keluar dari fungsi (serupa dengan break pada loop)."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02.html#acknowledgement",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02.html#acknowledgement",
    "title": "Week-02 (IO, conditional, loop,script, and function)",
    "section": "Acknowledgement",
    "text": "Acknowledgement\nKak ojan: untuk module tahun lalu-nya :D."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul7.html",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul7.html",
    "title": "Modul 7 Praktikum Metode Numerik: Metode Iteratif untuk SPL",
    "section": "",
    "text": "Modul 7 Praktikum Metode Numerik: Metode Iteratif untuk SPL\nKembali ke Metode Numerik\n\nBeberapa jenis norm vektor\nMasalah copy untuk array numpy\nMetode Jacobi, algoritma praktis\nMetode Gauss-Seidel, algoritma praktis\nMetode Relaksasi (SOR), algoritma praktis\n(Pengayaan) Metode Jacobi, dalam bentuk matriks (teoritis)\n(Pengayaan) Metode Gauss-Seidel, dalam bentuk matriks (teoritis)\n(Pengayaan) Metode SOR, dalam bentuk matriks (teoritis)\n\nModul praktikum ini diawali dengan pembahasan tentang beberapa jenis norm vektor. Kemudian, metode yang dibahas di modul kali ini, utamanya hanyalah “versi praktis” untuk algoritma metode Jacobi, metode Gauss-Seidel, dan metode relaksasi (SOR). Metode Gauss-Seidel adalah perbaikan dari metode Jacobi, dan metode SOR adalah perbaikan dari metode Gauss-Seidel. Istilah “versi praktis” di sini maksudnya agar dibedakan dari bentuk matriks \\(T\\textbf{x}+\\textbf{c}\\) (sebagai materi pengayaan) untuk metode-metode tersebut.\nInti sari dari ketiga metode tersebut adalah perumuman dari metode fixed-point (dari bab 2, metode numerik untuk root-finding), yang tadinya dilakukan untuk satu variabel/persamaan saja, menjadi dilakukan untuk beberapa variabel/persamaan sekaligus (yang kebetulan membentuk SPL). Langkah paling pertama dalam mempersiapkan penyelesaian SPL dengan metode-metode tersebut adalah seperti melakukan pindah ruas ke sebelah kanan untuk semua suku kecuali variabel pada diagonal, mirip dengan ide substitusi balik. Langkah ini tersirat ketika menuliskan bentuk umum metode-metode tersebut dalam bentuk sumasi. Selain itu, seperti metode fixed-point, diperlukan tebakan awal untuk nilai tiap variabel.\nUntuk perumuman metode fixed-point yang lebih umum lagi, yaitu untuk sistem persamaan yang tidak harus linier (tidak harus berbentuk SPL), dibahas di bab 10.1 di buku Burden. Bab 8, 9, dan 10 di buku Burden dibahas di mata kuliah pilihan program studi S1 Matematika yang bernama “Matematika Numerik”, dengan prasyarat Metode Numerik.\nPembahasan teoritis di kelas (perkuliahan) Metode Numerik juga mencakup pembahasan metode Jacobi, metode Gauss-Seidel, dan metode SOR dalam bentuk matriks, dengan bentuk umum \\(T\\textbf{x}+\\textbf{c}\\). Bentuk matriks untuk metode-metode tersebut tidak menjadi fokus di praktikum (bahkan di buku Burden, akhir halaman 452, juga disebut bahwa bentuk matriks tersebut biasanya hanya digunakan untuk pembahasan teoritis), tetapi tetap disediakan di modul praktikum ini sebagai materi pengayaan.\n\n\n1. Beberapa jenis norm vektor\nAda beberapa jenis norm vektor, yaitu semacam ukuran “besar” (magnitude) atau “panjang” untuk vektor. Salah satu kegunaannya adalah membandingkan “ukuran” antara dua vektor, yang mana yang lebih besar/kecil. Tiga jenis norm yang terkenal adalah:\n\nEuclidean norm, sering disebut 2-norm atau \\(L_2\\)-norm, dan perhitungannya seperti menggunakan teorema Pythagoras. Penulisan: \\(||\\textbf{v}||_2\\)\nInfinity norm (norm tak hingga), terkadang disebut \\(L_{\\infty}\\)-norm, yaitu sama saja maksimum dari semua mutlak elemen vektor. Penulisan: \\(||\\textbf{v}||_{\\infty}\\)\nManhattan distance atau Taxicab norm, sering disebut 1-norm atau \\(L_1\\)-norm, yaitu menjumlahkan mutlak tiap elemen vektor. Penulisan: \\(||\\textbf{v}||_1\\)\n\nNumpy bisa menghitung beberapa jenis norm, termasuk ketiga jenis norm di atas, menggunakan numpy.linalg.norm(vektor, jenis_norm), di mana vektor dibuat dengan numpy.array.\n\nimport numpy as np\n\n\nvektor_kecil = np.array([3,-4])\nprint(vektor_kecil)\n\n[ 3 -4]\n\n\nContoh norm-2, dengan option ord=2:\n\nnp.linalg.norm(vektor_kecil, ord=2)\n\n5.0\n\n\nOutput adalah 5, karena \\(||\\textbf{v}||_2=\\sqrt{3^2+\\left(-4\\right)^2}=\\sqrt{25}=5\\).\nSebenarnya, “ord” tidak harus ditulis:\n\nnp.linalg.norm(vektor_kecil, 2)\n\n5.0\n\n\nContoh norm-infinity, dengan option ord=numpy.inf:\n\nnp.linalg.norm(vektor_kecil, np.inf)\n\n4.0\n\n\nOutput adalah 4, karena \\(||\\textbf{v}||_{\\infty} = \\max \\left( |3|, |-4| \\right) = \\max \\left( 3, 4 \\right) = 4\\).\nContoh norm-1:\n\nnp.linalg.norm(vektor_kecil, 1)\n\n7.0\n\n\nOutput adalah 7, karena \\(||\\textbf{v}||_1 = |3| + |-4| = 3+4=7\\).\nMasing-masing jenis norm memiliki kelebihan dan kekurangan. (Untuk ke depannya, kita akan menggunakan norm-infinity, sesuai buku Burden). Apapun jenis norm yang Anda gunakan, untuk perhitungan apapun, pastikan Anda konsisten selalu menggunakan jenis norm yang sama dari awal sampai akhir perhitungan.\nUntuk jenis norm lainnya, bisa baca lebih lanjut di dokumentasi numpy (pada keterangan option “ord”): https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html\n\n\n2. Masalah copy untuk array numpy\nAda satu hal yang perlu dibahas sebelum melanjutkan ke pembahasan metode iteratif untuk SPL.\nSalah satu kekurangan numpy (dan Python secara umum) adalah bahwa kita tidak bisa meng-copy suatu array (ataupun list) dengan assignment. Melakukan assignment seolah-olah hanya membuat “sinonim”, sehingga perubahan pada salah satu array/list juga akan mengubah array/list yang satunya (istilahnya shallow copy). Perhatikan,\n\nimport numpy as np\n\n\narray1 = np.array([9, 8, 7, 6])\nprint(array1)\n\n[9 8 7 6]\n\n\n\n# Apakah cara copy seperti ini?\narray2 = array1\n\n\nprint(array2)\n\n[9 8 7 6]\n\n\nSeandainya array2 diubah…\n\narray2[2] = 15\nprint(array2)\n\n[ 9  8 15  6]\n\n\n… maka array1 juga mengalami perubahan yang sama.\n\nprint(array1)\n\n[ 9  8 15  6]\n\n\nCara copy yang tepat untuk array maupun list adalah menggunakan akhiran .copy() seperti berikut ini.\n\narray3 = array1.copy()\nprint(array3)\n\n[ 9  8 15  6]\n\n\nSehingga, perubahan pada salah satu tidak akan mempengaruhi yang satunya lagi. Artinya, copy telah dilakukan secara sempurna (disebut deep copy).\n\narray3[3] = 20\nprint(array3)\nprint(array1)\n\n[ 9  8 15 20]\n[ 9  8 15  6]\n\n\nUntuk ke depannya, kita akan sering menggunakan .copy().\nFun fact: sepertinya, permasalahan shallow copy ini berhubungan erat dengan cara dibuatnya module numpy yang sebenarnya tersambung dengan bahasa pemrograman C, yang juga memiliki keanehan yang serupa untuk array.\n\n\n3. Metode Jacobi, algoritma praktis\nMisalkan vektor \\(\\textbf{x}^{(k)} = \\left( x_1^{(k)}, x_2^{(k)}, \\dots, x_n^{(k)} \\right)^t\\) (ditranspos agar berupa vektor kolom) adalah hasil aproksimasi pada iterasi ke-k untuk solusi SPL \\(n\\)-variabel \\(A\\textbf{x}=\\textbf{b}\\).\nMetode Jacobi memiliki formula sebagai berikut:\n\\[x_i^{(k)} = \\frac{1}{a_{ii}} \\left[ \\sum_{j=1,j\\ne i}^{n} \\left(-a_{ij}x_j^{(k-1)} \\right) + b_i \\right],\\hspace{0.5cm} i = 1, 2, \\dots, n \\]\nKriteria pemberhentian iterasi bisa berupa * error mutlak: \\(||\\textbf{x}^{(k)}-\\textbf{x}^{(k-1)}|| &lt; \\epsilon\\) * error relatif: \\(\\frac{||\\textbf{x}^{(k)}-\\textbf{x}^{(k-1)}||}{||\\textbf{x}^{(k)}||} &lt; \\epsilon\\)\nPada kode berikut ini, kita akan menggunakan error mutlak dan norm tak hingga.\n\nimport numpy as np\n\ndef Jacobi(matriks, tebakan_awal, tol):\n    # banyaknya baris pada matriks, atau sama saja banyaknya variabel\n    n = np.shape(matriks)[0]\n\n    # definisikan vektor x0 sebagai tebakan awal\n    x0 = tebakan_awal.copy()\n\n    # yang akan diubah nilainya adalah vektor x,\n    x = x0.copy()\n    # sedangkan vektor x0 tetap disimpan,\n    # agar nanti bisa dibandingkan untuk perhitungan error\n\n    # berikut ini, iterasi pertama dilakukan sebelum while loop\n    # karena error belum diketahui\n\n    # metode Jacobi untuk tiap i\n    for i in range(n):\n        # konstanta pada SPL\n        b = matriks[i, n]\n\n        # menerapkan rumus metode Jacobi\n        for j in range(n):\n            if j != i:\n                b = b - matriks[i,j] * x0[j]\n                        # a_ij * x_j\n        x[i] = b/matriks[i,i] # hasil aproksimasi Jacobi\n    \n    # untuk iterasi kedua dan seterusnya, masuk ke while loop\n\n    while np.linalg.norm(x-x0, np.inf) &gt; tol: # kriteria pemberhentian\n        # x0 sudah bukan lagi tebakan awal, tetapi menjadi vektor x(k-1):\n        x0 = x\n        # kemudian nilai yang baru akan disimpan pada vektor x(k) berikut:\n        x = x0.copy()\n\n        # metode Jacobi untuk tiap i, kode sama persis dengan yang di atas\n        for i in range(n):\n            b = matriks[i, n]\n            for j in range(n):\n                if j != i:\n                    b = b - matriks[i,j] * x0[j]\n            x[i] = b/matriks[i,i]\n    \n    # jika keluar while loop maka metode selesai, x(k) adalah vektor hasil akhir\n    return x\n\n\nmatriks_diperbesar = np.array(eval(input(\"Masukkan matriks diperbesar: \"))).astype(float)\ntebakan_awal = np.array(eval(input(\"Masukkan tebakan awal: \")), dtype=float)\n# catatan: .astype(float) dan dtype=float melakukan hal yang sama,\n# dengan cara penggunaan yang sedikit berbeda:\n# - numpy.array(...).astype(float)\n# - numpy.array(..., dtype=float)\n# tidak ada salahnya apabila menggunakan salah satu saja (lebih baik konsisten)\n\ntoleransi = eval(input(\"Masukkan toleransi: \"))\n\nhasil = Jacobi(matriks_diperbesar, tebakan_awal, toleransi)\nprint(\"Hasil metode Jacobi adalah:\")\nprint(hasil)\n\nMasukkan matriks diperbesar: [ [10, -1, 2, 0, 6], [-1, 11, -1, 3, 25], [2, -1, 10, -1, -11], [0, 3, -1, 8, 15] ]\nMasukkan tebakan awal: [0,0,0,0]\nMasukkan toleransi: 10**-4\nHasil metode Jacobi adalah:\n[ 0.99998973  2.00001582 -1.00001257  1.00001924]\n\n\n\n\n4. Metode Gauss-Seidel, algoritma praktis\nMetode Gauss-Seidel adalah modifikasi/perkembangan dari metode Jacobi, di mana semua nilai \\(x_i\\) yang digunakan untuk perhitungan adalah selalu yang terbaru. Artinya, ketika menghitung \\(x_i^{(k)}\\), meskipun nilai-nilai \\(x_{i+1}, \\dots, x_n\\) yang digunakan adalah dari iterasi sebelumnya, nilai-nilai \\(x_1, x_2, \\dots, x_{i-1}\\) yang digunakan adalah yang baru saja dihitung, yaitu dari iterasi yang sama. Hal ini tidak seperti metode Jacobi yang selalu menggunakan nilai-nilai dari iterasi sebelumnya.\nOleh karena itu, untuk metode Gauss-Seidel, penulisan sumasi dipisah menjadi dua bagian, yaitu satu bagian untuk penggunaan nilai-nilai dari iterasi yang sama \\((k)\\), dan satu bagian untuk penggunaan nilai-nilai dari iterasi sebelumnya \\((k-1)\\).\n\\[x_i^{(k)} = \\frac{1}{a_{ii}} \\left[ -\\sum_{j=1}^{i-1} \\left( a_{ij}x_j^{(k)} \\right) - \\sum_{j=i+1}^{n} \\left( a_{ij}x_j^{(k-1)} \\right) + b_i \\right],\\hspace{0.5cm} i = 1, 2, \\dots, n \\]\nAkibat selalu menggunakan nilai-nilai terbaru, metode Gauss-Seidel cenderung lebih cepat konvergen memenuhi toleransi daripada metode Jacobi.\n\nimport numpy as np\n\ndef GaussSeidel(matriks, tebakan_awal, tol):\n    # banyaknya baris pada matriks, atau sama saja banyaknya variabel\n    n = np.shape(matriks)[0]\n\n    # definisikan vektor x0 sebagai tebakan awal\n    x0 = tebakan_awal.copy()\n\n    # yang akan diubah nilainya adalah vektor x,\n    x = x0.copy()\n    # sedangkan vektor x0 tetap disimpan,\n    # karena metode Gauss-Seidel membutuhkan nilai pada iterasi\n    # sebelumnya dan juga iterasi yang sedang dilakukan\n\n    # berikut ini, iterasi pertama dilakukan sebelum while loop\n    # karena error belum diketahui\n\n    # metode Gauss-Seidel untuk tiap i\n    for i in range(n):\n        # konstanta pada SPL\n        b = matriks[i,n]\n\n        # menerapkan rumus metode Gauss-Seidel\n        for j in range(n):\n            if j != i:\n                if j &lt; i: # jika di sebelah kiri diagonal, sudah dihitung\n                    b = b - matriks[i,j] * x[j] # gunakan x_j dari vektor x(k)\n                else: # jika di sebelah kanan diagonal, belum dihitung\n                    b = b - matriks[i,j] * x0[j] # gunakan x_j dari x(k-1)\n        x[i] = b/matriks[i,i] # hasil aproksimasi Gauss-Seidel\n\n    # untuk iterasi kedua dan seterusnya, masuk ke while loop\n    \n    while np.linalg.norm(x-x0, np.inf) &gt; tol: # kriteria pemberhentian\n        # x0 sudah bukan lagi tebakan awal, tetapi menjadi vektor x(k-1):\n        x0 = x\n        # kemudian nilai yang baru akan disimpan pada vektor x(k) berikut:\n        x = x0.copy()\n\n        # metode Gauss-Seidel untuk tiap i, kode sama persis dengan yang di atas\n        for i in range(n):\n            b = matriks[i,n]\n            for j in range(n):\n                if j != i:\n                    if j &lt; i:\n                        b = b - matriks[i,j] * x[j]\n                    else:\n                        b = b - matriks[i,j] * x0[j]\n            x[i] = b/matriks[i,i]\n    \n    # jika keluar while loop maka metode selesai, x(k) adalah vektor hasil akhir\n    return x\n\n\nmatriks_diperbesar = np.array(eval(input(\"Masukkan matriks diperbesar: \"))).astype(float)\ntebakan_awal = np.array(eval(input(\"Masukkan tebakan awal: \")), dtype=float)\ntoleransi = eval(input(\"Masukkan toleransi: \"))\n\nhasil = GaussSeidel(matriks_diperbesar, tebakan_awal, toleransi)\nprint(\"Hasil Gauss-Seidel adalah:\")\nprint(hasil)\n\nMasukkan matriks diperbesar: [ [10, -1, 2, 0, 6], [-1, 11, -1, 3, 25], [2, -1, 10, -1, -11], [0, 3, -1, 8, 15] ]\nMasukkan tebakan awal: [0,0,0,0]\nMasukkan toleransi: 10**-4\nHasil Gauss-Seidel adalah:\n[ 1.00000836  2.00000117 -1.00000275  0.99999922]\n\n\n\n\n5. Metode Relaksasi (SOR), algoritma praktis\nMetode relaksasi (relaxation methods) adalah metode untuk mempercepat kekonvergenan dari solusi yang dihasilkan oleh metode iteratif untuk SPL (dalam hal ini, metode Gauss-Seidel). Berdasarkan besar faktor relaksasi \\(\\omega\\), metode relaksasi terbagi menjadi dua jenis, yaitu * metode under relaxation jika \\(0 &lt; \\omega &lt; 1\\) * metode over relaxation jika \\(\\omega &gt; 1\\)\nSesuai buku Burden, pembahasan kita akan fokus ke metode over relaxation. Metode over relaxation yang diterapkan terus-menerus untuk tiap iterasi Gauss-Seidel disebut metode Successive Over-Relaxation (SOR).\nUntuk sembarang nilai omega, rumus metode relaksasi sebagai modifikasi Gauss-Seidel bisa dituliskan sebagai berikut:\n\\[x_i^{(k)} = \\left(1-\\omega\\right)x_i^{(k-1)} + \\frac{\\omega}{a_{ii}} \\left[ -\\sum_{j=1}^{i-1} \\left( a_{ij}x_j^{(k)} \\right) - \\sum_{j=i+1}^{n} \\left( a_{ij}x_j^{(k-1)} \\right) + b_i \\right],\\hspace{0.5cm} i = 1, 2, \\dots, n \\]\nCatatan: jika \\(\\omega = 1\\), diperoleh metode Gauss-Seidel yang telah dibahas sebelumnya (tanpa relaksasi).\n\nimport numpy as np\n\ndef SOR(matriks, tebakan_awal, omega, tol):\n    # banyaknya baris pada matriks, atau sama saja banyaknya variabel\n    n = np.shape(matriks)[0]\n\n    # definisikan vektor x0 sebagai tebakan awal\n    x0 = tebakan_awal.copy()\n\n    # yang akan diubah nilainya adalah vektor x,\n    x = x0.copy()\n    # sedangkan vektor x0 tetap disimpan,\n    # karena metode SOR (seperti Gauss-Seidel) membutuhkan nilai pada iterasi\n    # sebelumnya dan juga iterasi yang sedang dilakukan\n\n    # berikut ini, iterasi pertama dilakukan sebelum while loop\n    # karena error belum diketahui\n\n    # metode SOR untuk tiap i\n    for i in range(n):\n        # sejauh ini masih sama persis dengan Gauss-Seidel:\n        b = matriks[i,n]\n        for j in range(n):\n            if j != i:\n                if j &lt; i:\n                    b = b - matriks[i,j] * x[j]\n                else:\n                    b = b - matriks[i,j] * x0[j]\n        \n        # bedanya dengan metode Gauss-Seidel hanya di baris berikut:\n        x[i] = (1-omega) * x0[i] + omega*b/matriks[i,i] # hasil aproksimasi SOR\n    \n    # untuk iterasi kedua dan seterusnya, masuk ke while loop\n\n    while np.linalg.norm(x-x0, np.inf) &gt; tol: # kriteria pemberhentian\n        # x0 sudah bukan lagi tebakan awal, tetapi menjadi vektor x(k-1):\n        x0 = x\n        # kemudian nilai yang baru akan disimpan pada vektor x(k) berikut:\n        x = x0.copy()\n\n        # metode SOR untuk tiap i, kode sama persis dengan yang di atas\n        for i in range(n):\n            b = matriks[i,n]\n            for j in range(n):\n                if j != i:\n                    if j &lt; i:\n                        b = b - matriks[i,j] * x[j]\n                    else:\n                        b = b - matriks[i,j] * x0[j]\n            x[i] = (1-omega) * x0[i] + omega*b/matriks[i,i]\n    \n    # jika keluar while loop maka metode selesai, x(k) adalah vektor hasil akhir\n    return x\n\n\nmatriks_diperbesar = np.array(eval(input(\"Masukkan matriks diperbesar: \"))).astype(float)\ntebakan_awal = np.array(eval(input(\"Masukkan tebakan awal: \")), dtype=float)\nomega = eval(input(\"Masukkan faktor relaksasi (omega): \"))\ntoleransi = eval(input(\"Masukkan toleransi: \"))\n\nhasil = SOR(matriks_diperbesar, tebakan_awal, omega, toleransi)\nprint(\"Hasil SOR adalah:\")\nprint(hasil)\n\nMasukkan matriks diperbesar: [ [4, 3, 0, 24], [3, 4, -1, 30], [0, -1, 4, -24] ]\nMasukkan tebakan awal: [0,0,0]\nMasukkan faktor relaksasi (omega): 1.25\nMasukkan toleransi: 10**-4\nHasil SOR adalah:\n[ 2.99998919  4.00000321 -4.9999937 ]\n\n\n\n\n6. (Pengayaan) Metode Jacobi, dalam bentuk matriks (teoritis)\nSecara konsep, metode iteratif untuk SPL bisa dianggap sebagai semacam perumuman dari metode fixed-point, yang tadinya hanya satu variabel/persamaan menjadi banyak variabel/persamaan. Bentuk sumasi untuk masing-masing metode memang terlihat agak berbeda satu sama lain (seperti tidak bisa disamakan atau dibuat bentuk umumnya), terutama antara metode Jacobi dan metode Gauss-Seidel. Namun, mengingat asal-usulnya sebagai perumuman metode fixed-point, dan berhubung sistem persamaan yang ingin diselesaikan bersifat linier (membentuk SPL), metode iteratif untuk SPL bisa dituliskan dalam suatu bentuk umum menggunakan matriks (bentuk matriks), yakni\n\\[\\textbf{x}^{(k)} = T\\textbf{x}^{(k-1)} + \\textbf{c}\\]\ndi mana isi matriks \\(T\\) dan vektor konstanta \\(\\textbf{c}\\) ditentukan tergantung metode iteratif yang digunakan: apakah metode Jacobi, metode Gauss-Seidel, atau metode SOR.\nSekilas, bentuk umum tersebut memang terlihat lebih sederhana, seperti betapa sederhananya metode fixed-point. Namun, secara perhitungan, perkalian matriks bisa memakan waktu yang relatif lama, sehingga versi praktis yang telah dibahas sebelumnya lah yang lebih cocok untuk dibuat program maupun untuk perhitungan manual.\nMeskipun demikian, bentuk umum di atas masih ada kegunaannya, khususnya untuk mempermudah pembahasan teoritis seperti analisis error. Berikut ini, kita tetap akan membahas bentuk matriks untuk ketiga metode tersebut sebagai materi pengayaan.\nSebelumnya, dari SPL \\(A\\textbf{x}=\\textbf{b}\\), kita bisa “memecah” matriks koefisien \\(A\\) menjadi tiga bagian, yaitu \\(A = (-L_{neg}) + D + (-U_{neg})\\) atau sama saja \\(A = D - L_{neg} - U_{neg}\\): * Matriks \\((-L_{neg})\\) adalah matriks segitiga bawah menggunakan elemen matriks \\(A\\) yang berada di bawah diagonal, sedangkan sisanya nol. * Matriks \\(D\\) adalah matriks diagonal yang menggunakan elemen diagonal matriks \\(A\\), sedangkan sisanya nol. * Matriks \\((-U_{neg})\\) adalah matriks segitiga atas yang menggunakan elemen \\(A\\) yang berada di atas diagonal, sedangkan sisanya nol.\nPerhatikan bahwa matriks \\((-L_{neg})\\) dan \\((-U_{neg})\\) dituliskan dengan tanda minus. Sebenarnya, nilai elemen segitiga bawah/atas yang disimpan ke matriks \\(L_{neg}\\) dan \\(U_{neg}\\) ini adalah negatif dari nilai aslinya di matriks \\(A\\). Sehinga, matriks segitiga bawah/atas yang memuat nilai aslinya bisa ditulis dengan minus: \\((-L_{neg})\\) dan \\((-U_{neg})\\). Keterangan “neg” maksudnya negatif, sehingga minus negatif menjadi kembali positif atau menjadi nilai aslinya. Hati-hati, pembahasan di buku Burden tidak melibatkan keterangan “neg”, sehingga langsung ditulis misalnya \\(A=D-L-U\\).\n\\[A = \\begin{bmatrix}\na_{11} & a_{12} & \\dots & a_{1n} \\\\\na_{21} & a_{22} & \\dots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{n1} & a_{n2} & \\dots & a_{nn}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\na_{11} & 0 & \\dots & 0 \\\\\n0 & a_{22} & \\dots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\dots & a_{nn}\n\\end{bmatrix}\n-\n\\begin{bmatrix}\n0 & 0 & \\dots & 0 \\\\\n-a_{21} & 0 & \\dots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n-a_{n1} & -a_{n2} & \\dots & 0\n\\end{bmatrix}\n-\n\\begin{bmatrix}\n0 & -a_{12} & \\dots & -a_{1n} \\\\\n0 & 0 & \\dots & -a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\dots & 0\n\\end{bmatrix}\n\\\\\nA = D - L_{neg} - U_{neg}\n\\]\nDengan demikian, kita bisa menyusun fungsi untuk memisahkan matriks koefisien \\(A\\) menjadi \\(D - L_{neg} - U_{neg}\\).\n\ndef PisahDLnegUneg(matriks_A):\n    # memperoleh ukuran n x n dari matriks A, ambil banyaknya baris aja\n    n = np.shape(matriks_A)[0]\n\n    # buat dulu matriks D, Lneg dan Uneg, ukuran n x n, sementara nol semua\n    D = np.zeros((n,n))\n    Lneg = np.zeros((n,n))\n    Uneg = np.zeros((n,n))\n\n    # double for loop melihat tiap elemen di matriks A...\n    for i in range(n): # baris ke-i\n        for j in range(n): # kolom ke-j\n            if i == j: # jika elemen diagonal...\n                # ... maka simpan ke matriks D\n                D[i, j] = matriks_A[i, j]\n            elif i &gt; j: # jika lebih ke bawah daripada ke kanan...\n                # ... maka simpan ke matriks Lneg (karena segitiga bawah)\n                Lneg[i, j] = -matriks_A[i, j] # (jangan lupa dibuat negatif)\n            else: # selain itu (berarti segitiga atas)\n                # simpan ke matriks Uneg, jangan lupa dibuat negatif\n                Uneg[i, j] = -matriks_A[i, j]\n    \n    # return tiga matriks sekaligus sebagai satu kesatuan\n    return (D, Lneg, Uneg)\n\n\n# Contoh\nmatriks_koef = np.array([\n    [1, 2, 3],\n    [4, 5, 6],\n    [7, 8, 9]\n])\n\nD, Lneg, Uneg = PisahDLnegUneg(matriks_koef)\nprint(D)\nprint(Lneg)\nprint(Uneg)\n\n[[1. 0. 0.]\n [0. 5. 0.]\n [0. 0. 9.]]\n[[ 0.  0.  0.]\n [-4.  0.  0.]\n [-7. -8.  0.]]\n[[ 0. -2. -3.]\n [ 0.  0. -6.]\n [ 0.  0.  0.]]\n\n\nSelanjutnya, kita bisa menuliskan matriks \\(T_j\\) dan vektor konstanta \\(\\textbf{c}_j\\) untuk metode Jacobi sebagai berikut:\n\\[T_j = D^{-1}\\left(L_{neg}+U_{neg}\\right), \\hspace{0.5cm} \\textbf{c}_j = D^{-1}\\textbf{b}\\]\nsehingga rumus iterasi metode Jacobi menjadi\n\\[\\textbf{x}^{(k)} = T_j\\textbf{x}^{(k-1)} + \\textbf{c}_j\\]\n\ndef JacobiTeoritis(matriks_koefisien, vektor_b, tebakan_awal, tol):\n    # pisahkan dulu\n    D, Lneg, Uneg = PisahDLnegUneg(matriks_koefisien)\n\n    # susun matriks T_j dan vektor konstanta c_j\n    D_invers = np.linalg.inv(D)\n    Tj = np.matmul( D_invers, Lneg+Uneg )\n    cj = np.matmul( D_invers, vektor_b )\n\n    # iterasi pertama\n\n    # x(k-1), salin dari tebakan awal\n    xk_1 = tebakan_awal.copy()\n\n    # x(k), rumus metode Jacobi bentuk matriks\n    xk = np.matmul( Tj, xk_1 ) + cj\n\n    # iterasi kedua dan seterusnya dalam while loop\n\n    while np.linalg.norm(xk_1 - xk, np.inf) &gt; tol: # kriteria pemberhentian\n        # yang sebelumnya menjadi x(k) itu sekarang menjadi x(k-1)\n        xk_1 = xk\n\n        # lakukan iterasi untuk memperoleh x(k) yang baru\n        xk = np.matmul( Tj, xk_1 ) + cj\n\n    # jika sudah keluar while loop, toleransi sudah terpenuhi\n    return xk\n\n\nmatriks_koef = np.array(eval(input(\"Masukkan matriks koefisien A: \"))).astype(float)\nvektor_b = np.array(eval(input(\"Masukkan vektor b: \"))).astype(float)\ntebakan_awal = np.array(eval(input(\"Masukkan tebakan awal: \")), dtype=float)\n\ntoleransi = eval(input(\"Masukkan toleransi: \"))\n\nhasil = JacobiTeoritis(matriks_koef, vektor_b, tebakan_awal, toleransi)\nprint(\"Hasil metode Jacobi (teoritis) adalah:\")\nprint(hasil)\n\nMasukkan matriks koefisien A: [ [10, -1, 2, 0], [-1, 11, -1, 3], [2, -1, 10, -1], [0, 3, -1, 8] ]\nMasukkan vektor b: [6, 25, -11, 15]\nMasukkan tebakan awal: [0, 0, 0, 0]\nMasukkan toleransi: 10**-4\nHasil metode Jacobi (teoritis) adalah:\n[ 0.99998973  2.00001582 -1.00001257  1.00001924]\n\n\n\n\n7. (Pengayaan) Metode Gauss-Seidel, dalam bentuk matriks (teoritis)\nUntuk metode Gauss-Seidel, kita definisikan matriks \\(T_g\\) dan vektor konstanta \\(\\textbf{c}_g\\) sebagai berikut:\n\\[T_g = \\left( D - L_{neg} \\right)^{-1} U_{neg}, \\hspace{0.5cm} \\textbf{c}_g = \\left( D - L_{neg} \\right)^{-1} \\textbf{b}\\]\nSehingga, rumus iterasi untuk metode Gauss-Seidel bentuk matriks bisa ditulis:\n\\[\\textbf{x}^{(k)} = T_g \\textbf{x}^{(k-1)} + \\textbf{c}_g\\]\n\ndef GaussSeidelTeoritis(matriks_koefisien, vektor_b, tebakan_awal, tol):\n    # pisahkan dulu\n    D, Lneg, Uneg = PisahDLnegUneg(matriks_koefisien)\n\n    # susun matriks T_g dan vektor konstanta c_g\n    DminusLneg_invers = np.linalg.inv(D - Lneg)\n    Tg = np.matmul( DminusLneg_invers, Uneg )\n    cg = np.matmul( DminusLneg_invers, vektor_b )\n\n    # iterasi pertama\n\n    # x(k-1), salin dari tebakan awal\n    xk_1 = tebakan_awal.copy()\n\n    # x(k), rumus metode Gauss-Seidel bentuk matriks\n    xk = np.matmul( Tg, xk_1 ) + cg\n\n    # iterasi kedua dan seterusnya dalam while loop\n\n    while np.linalg.norm(xk_1 - xk, np.inf) &gt; tol: # kriteria pemberhentian\n        # yang sebelumnya menjadi x(k) itu sekarang menjadi x(k-1)\n        xk_1 = xk\n\n        # lakukan iterasi untuk memperoleh x(k) yang baru\n        xk = np.matmul( Tg, xk_1 ) + cg\n\n    # jika sudah keluar while loop, toleransi sudah terpenuhi\n    return xk\n\n\nmatriks_koef = np.array(eval(input(\"Masukkan matriks koefisien A: \"))).astype(float)\nvektor_b = np.array(eval(input(\"Masukkan vektor b: \"))).astype(float)\ntebakan_awal = np.array(eval(input(\"Masukkan tebakan awal: \")), dtype=float)\n\ntoleransi = eval(input(\"Masukkan toleransi: \"))\n\nhasil = GaussSeidelTeoritis(matriks_koef, vektor_b, tebakan_awal, toleransi)\nprint(\"Hasil metode Gauss-Seidel (teoritis) adalah:\")\nprint(hasil)\n\nMasukkan matriks koefisien A: [ [10, -1, 2, 0], [-1, 11, -1, 3], [2, -1, 10, -1], [0, 3, -1, 8] ]\nMasukkan vektor b: [6, 25, -11, 15]\nMasukkan tebakan awal: [0, 0, 0, 0]\nMasukkan toleransi: 10**-4\nHasil metode Gauss-Seidel (teoritis) adalah:\n[ 1.00000836  2.00000117 -1.00000275  0.99999922]\n\n\n\n\n8. (Pengayaan) Metode SOR, dalam bentuk matriks (teoritis)\nUntuk metode SOR, diberikan suatu nilai omega, kita definisikan matriks \\(T_{\\omega}\\) dan vektor konstanta \\(\\textbf{c}_{\\omega}\\) sebagai berikut:\n\\[T_{\\omega} = \\left( D-\\omega L \\right)^{-1}\\left[ (1-\\omega)D + \\omega U \\right], \\hspace{0.5cm} \\textbf{c}_{\\omega} = \\omega \\left( D-\\omega L\\right)^{-1} \\textbf{b}\\]\nSehingga, rumus iterasi untuk metode SOR bentuk matriks bisa ditulis:\n\\[\\textbf{x}^{(k)} = T_{\\omega} \\textbf{x}^{(k-1)} + \\textbf{c}_{\\omega}\\]\n\ndef SORTeoritis(matriks_koefisien, vektor_b, tebakan_awal, omega, tol):\n    # pisahkan dulu\n    D, Lneg, Uneg = PisahDLnegUneg(matriks_koefisien)\n\n    # susun matriks T_omega dan vektor konstanta c_omega\n    DminusomegaLneg_invers = np.linalg.inv( D - omega * Lneg)\n    T_omega = np.matmul ( DminusomegaLneg_invers, (1-omega)*D + omega*Uneg )\n    c_omega = omega * np.matmul( DminusomegaLneg_invers, vektor_b )\n\n    # iterasi pertama\n\n    # x(k-1), salin dari tebakan awal\n    xk_1 = tebakan_awal.copy()\n\n    # x(k), rumus metode SOR bentuk matriks\n    xk = np.matmul( T_omega, xk_1 ) + c_omega\n\n    # iterasi kedua dan seterusnya dalam while loop\n\n    while np.linalg.norm(xk_1 - xk, np.inf) &gt; tol: # kriteria pemberhentian\n        # yang sebelumnya menjadi x(k) itu sekarang menjadi x(k-1)\n        xk_1 = xk\n\n        # lakukan iterasi untuk memperoleh x(k) yang baru\n        xk = np.matmul( T_omega, xk_1 ) + c_omega\n\n    # jika sudah keluar while loop, toleransi sudah terpenuhi\n    return xk\n\n\nmatriks_koef = np.array(eval(input(\"Masukkan matriks koefisien A: \"))).astype(float)\nvektor_b = np.array(eval(input(\"Masukkan vektor b: \"))).astype(float)\ntebakan_awal = np.array(eval(input(\"Masukkan tebakan awal: \")), dtype=float)\nomega = eval(input(\"Masukkan faktor relaksasi (omega): \"))\ntoleransi = eval(input(\"Masukkan toleransi: \"))\n\nhasil = SORTeoritis(matriks_koef, vektor_b, tebakan_awal, omega, toleransi)\nprint(\"Hasil metode SOR (teoritis) adalah:\")\nprint(hasil)\n\nMasukkan matriks koefisien A: [ [4, 3, 0], [3, 4, -1], [0, -1, 4] ]\nMasukkan vektor b: [24, 30, -24]\nMasukkan tebakan awal: [0, 0, 0]\nMasukkan faktor relaksasi (omega): 1.25\nMasukkan toleransi: 10**-4\nHasil metode SOR (teoritis) adalah:\n[ 2.99998919  4.00000321 -4.9999937 ]"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul5.html",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul5.html",
    "title": "Modul 5: Integrasi Numerik",
    "section": "",
    "text": "Modul 5: Integrasi Numerik\nKembali ke Metode Numerik\n\nPengantar integrasi numerik dan metode Newton-Cotes (penjelasan tanpa kode)\nMetode closed Newton-Cotes\nMetode open Newton-Cotes\nTabel Ringkasan Metode Newton-Cotes\nIntegrasi numerik komposit: rumus umum\nIntegrasi numerik komposit: rumus khusus\nKuadratur adaptif (Adaptive Quadrature)\nKuadratur Gauss (Gaussian Quadrature), pada interval \\([-1,1]\\)\nKuadratur Gauss untuk sembarang interval (Gaussian Quadrature on Arbitrary Intervals)\n\n\n\n1. Pengantar integrasi numerik dan metode Newton-Cotes (penjelasan tanpa kode)\nDi kalkulus, kita sudah mempelajari integral Riemann, yang melibatkan penjumlahan luas sejumlah persegi panjang, yang secara keseluruhan mengaproksimasi luas di bawah kurva (yang berupa fungsi). Makin banyak persegi panjang, maka hasil perhitungan menjadi semakin akurat. Sebenarnya, itu sudah termasuk integrasi numerik (sayangnya, secara pemrograman, kita tidak bisa membuat limit menuju tak hingga).\nIntegrasi numerik juga disebut “kuadratur numerik” atau “kuadratur” saja.\nDi mata kuliah metode numerik, salah satu teknik integrasi numerik (untuk menghitung integral tentu) yang kita pelajari disebut metode Newton-Cotes, yang secara teori melibatkan aproksimasi fungsi dengan polinom interpolasi Lagrange, kemudian dihitung integral analitik dari polinom interpolasi Lagrange tersebut. Semua titik-titik yang digunakan untuk interpolasi (disebut nodes) ada di dalam interval integral tentu, dan jarak antar titik-titik tersebut menggunakan step size yang konstan, yang bisa kita sebut \\(h\\) (seperti biasa).\nUntungnya, setelah dilakukan penyederhanaan dan manipulasi aljabar, bentuk rumus yang dihasilkan oleh metode Newton-Cotes menjadi cukup singkat dan sederhana. Sehingga, pada prakteknya, ketika menggunakan metode Newton-Cotes, kita tinggal menggunakan rumus hasil akhirnya; kita tidak perlu lagi pusing dengan interpolasi Lagrange.\nIntegral tentu pasti memliki batas bawah \\(a\\) dan batas atas \\(b\\) (bisa dianggap sebagai batasan interval di mana integrasi akan dilakukan), dan bisa ditulis \\(\\int_{a}^{b} f\\left(x\\right) dx\\). Untuk interpolasi yang dilakukan dalam metode Newton-Cotes, secara keseluruhan ada dua cara untuk memilih nodes yang akan diberlakukan interpolasi, yaitu dengan melibatkan ujung interval integrasi (dianggap interval tutup \\([a,b]\\) atau closed interval) maupun tidak melibatkan ujung interval (dianggap interval buka \\((a,b)\\) atau open interval). Dengan demikian, rumus metode Newton Cotes bisa dikategorikan menjadi dua jenis, yaitu closed Newton-Cotes dan open Newton-Cotes, tergantung teknis interpolasi apakah melibatkan titik ujung interval atau tidak. Tentu saja, rumusnya menjadi berbeda.\nBaik untuk closed Newton-Cotes maupun open Newton-Cotes, banyaknya nodes yang berbeda juga menghasilkan rumus yang berbeda. Karena closed Newton-Cotes melibatkan titik ujung interval, maka diperlukan minimal dua nodes (yaitu kedua titik ujung interval). Sedangkan, untuk open Newton-Cotes, minimal banyaknya nodes cukup satu saja.\n\n\n2. Metode closed Newton-Cotes\nDalam penulisan berbagai variasi rumus closed Newton-Cotes, digunakan variabel \\(n\\) apabila telah digunakan \\((n+1)\\) nodes untuk interpolasi, dan titik-titik tersebut biasanya ditulis \\(x_0, x_1, x_2, \\dots, x_n\\), yaitu \\(x_i\\) untuk \\(i=0,1,2,\\dots,n\\).\nNilai \\(n\\) terkecil yang mungkin adalah \\(n=1\\) (di mana digunakan \\(n+1=2\\) nodes untuk interpolasi), dan sering disebut “trapezoidal rule”, karena luas yang sebenarnya dihitung memang kebetulan berbentuk trapezoid. (Pada gambar berikut ini, \\(f(x)\\) adalah fungsi yang ingin diintegralkan, sedangkan \\(P_1 (x)\\) adalah polinom interpolasi Lagrange yang mengaproksimasi \\(f(x)\\) pada nodes yang telah ditentukan.)\n\n\n\np1 integral croptime Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org) copy_page-0001.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.3, “Elements of Numerical Integration”. Hlm. 194\nSedangkan, rumus closed Newton-Cotes untuk \\(n=2\\) (menggunakan \\(n+1=3\\) nodes untuk interpolasi) disebut “Simpson’s rule”.\nPerhatikan bahwa, secara umum, \\((n+1)\\) titik yang digunakan seolah-olah membagi interval \\([a,b]\\) menjadi \\(n\\) subinterval. Misalnya, pada gambar berikut, metode Simpson dengan \\(n=2\\) (menggunakan tiga titik: \\(x_0, x_1, x_2\\)) terlihat seperti membagi interval \\([a,b]\\) menjadi \\(n=2\\) subinterval, yaitu \\([x_0, x_1]\\) dan \\([x_1, x_2]\\).\n\n\n\np2 integral croptime Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org) copy_page-0002.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.3, “Elements of Numerical Integration”. Hlm. 195\nBerikut penjabaran beberapa rumus closed Newton-Cotes untuk mengaproksimasi integral tentu pada interval tutup \\([a,b]\\), masing-masing menggunakan titik-titik \\(x_i = x_0 + ih\\) untuk \\(i = 0, 1, \\dots, n\\), serta step size \\(h = \\frac{b-a}{n}\\). Di sini, dibuat \\(x_0 = a\\) dan \\(x_n = b\\).\n\\(n=1\\) (trapezoidal rule):\n\\[\\int_a^b f \\left( x \\right) dx \\approx \\frac{h}{2} \\left[ f(x_0) + f(x_1)\\right]\\]\ndengan \\(h = b-a\\).\n\\(n=2\\) (Simpson’s rule):\n\\[\\int_a^b f \\left( x \\right) dx \\approx \\frac{h}{3} \\left[ f(x_0) + 4f(x_1) + f(x_2)\\right]\\]\ndengan \\(h = \\frac{b-a}{2}\\).\n\\(n=3\\) (Simpson’s Three-Eights rule):\n\\[\\int_a^b f \\left( x \\right) dx \\approx \\frac{3h}{8} \\left[ f(x_0) + 3f(x_1) + 3f(x_2) + f(x_3)\\right]\\]\ndengan \\(h = \\frac{b-a}{3}\\).\n\\(n=4\\) (Boole’s rule):\n\\[\\int_a^b f \\left( x \\right) dx \\approx \\frac{2h}{45} \\left[ 7f(x_0) + 32f(x_1) + 12f(x_2) + 32f(x_3) + 7f(x_4)\\right]\\]\ndengan \\(h = \\frac{b-a}{4}\\).\nKarena rumusnya sudah ada, pembuatan program untuk metode closed Newton-Cotes tergolong mudah.\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Metode closed Newton-Cotes untuk integral tentu\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah integral: \"))\nupper_bound = eval(input(\"Masukkan batas atas integral: \"))\nprint()\n\n# n = 1 (Trapezoidal rule)\ndef TrapezoidalRule(f,a,b):\n    # f adalah fungsi\n    h = b-a\n    x = [a, b] # list nilai x\n    hasil = (h/2) * ( f(x[0]) + f(x[1]) )\n    return hasil\n\n# n = 2 (Simpson's rule)\ndef SimpsonsRule(f,a,b):\n    h = (b-a)/2\n    x = [a, a+h, b]\n    hasil = (h/3) * ( f(x[0]) + 4*f(x[1]) + f(x[2]) )\n    return hasil\n\n# n = 3 (Simpson's Three-Eights rule)\ndef SimpsonsThreeEightsRule(f,a,b):\n    h = (b-a)/3\n    x = [a, a+h, a + 2*h, b]\n    hasil = (3*h/8) * ( f(x[0]) + 3*f(x[1]) + 3*f(x[2]) + f(x[3]) )\n    return hasil\n\n# n = 4 (Boole's rule)\ndef BoolesRule(f,a,b):\n    h = (b-a)/4\n    x = [a, a+h, a + 2*h, a + 3*h, b]\n    hasil = (2*h/45) * ( 7*f(x[0]) + 32*f(x[1]) + 12*f(x[2]) + 32*f(x[3]) + 7*f(x[4]) )\n    return hasil\n\n# Menghitung aproksimasi integral func(x) untuk n=1,2,3,4\nhasil_closed_1 = TrapezoidalRule(func, lower_bound, upper_bound)\nhasil_closed_2 = SimpsonsRule(func, lower_bound, upper_bound)\nhasil_closed_3 = SimpsonsThreeEightsRule(func, lower_bound, upper_bound)\nhasil_closed_4 = BoolesRule(func, lower_bound, upper_bound)\n\n# Menampilkan hasil\nprint(\"Berikut hasil aproksimasi integral dengan closed Newton-Cotes:\")\nprint(f\"n=1: {hasil_closed_1} (Trapezoidal rule)\")\nprint(f\"n=2: {hasil_closed_2} (Simpson's rule)\")\nprint(f\"n=3: {hasil_closed_3} (Simpson's Three-Eights rule)\")\nprint(f\"n=4: {hasil_closed_4} (Boole's rule)\")\n\nMetode closed Newton-Cotes untuk integral tentu\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = sin(x)\nMasukkan batas bawah integral: 0\nMasukkan batas atas integral: pi/4\n\nBerikut hasil aproksimasi integral dengan closed Newton-Cotes:\nn=1: 0.2776801836348979 (Trapezoidal rule)\nn=2: 0.292932637839748 (Simpson's rule)\nn=3: 0.29291070254917145 (Simpson's Three-Eights rule)\nn=4: 0.29289318256126384 (Boole's rule)\n\n\n\n\n3. Metode open Newton-Cotes\nDalam penulisan berbagai variasi rumus open Newton-Cotes, digunakan variabel \\(n\\) apabila telah digunakan \\((n+1)\\) nodes untuk interpolasi.\nNilai \\(n\\) terkecil yang mungkin adalah \\(n=0\\) (di mana digunakan \\(n+1=1\\) nodes untuk interpolasi), dan sering disebut “midpoint rule”, karena satu titik yang digunakan tersebut kebetulan berada di tengah-tengah interval \\((a,b)\\), sehingga menjadi midpoint atau titik tengah dari interval integerasi.\nBerikut penjabaran beberapa rumus open Newton-Cotes untuk mengaproksimasi integral tentu pada interval buka \\((a,b)\\), masing-masing menggunakan titik-titik \\(x_i = x_0 + ih\\) untuk \\(i = 0, 1, \\dots, n\\), serta step size \\(h = \\frac{b-a}{n+2}\\). Di sini, dibuat \\(x_0 = a+h\\) dan \\(x_n = b-h\\).\n\\(n=0\\) (midpoint rule):\n\\[\\int_{a}^{b} f\\left(x\\right) dx \\approx 2hf(x_0)\\]\ndengan \\(h = \\frac{b-a}{2}\\).\n\\(n=1\\):\n\\[\\int_{a}^{b} f\\left(x\\right) dx \\approx \\frac{3h}{2} \\left[ f(x_0) + f(x_1) \\right]\\]\ndengan \\(h = \\frac{b-a}{3}\\).\n\\(n=2\\):\n\\[\\int_{a}^{b} f\\left(x\\right) dx \\approx \\frac{4h}{3} \\left[ 2f(x_0) - f(x_1) + 2f(x_2) \\right]\\]\ndengan \\(h = \\frac{b-a}{4}\\).\n\\(n=3\\):\n\\[\\int_{a}^{b} f\\left(x\\right) dx \\approx \\frac{5h}{24} \\left[ 11f(x_0) + f(x_1) + f(x_2) + 11f(x_3) \\right]\\]\ndengan \\(h = \\frac{b-a}{5}\\).\nLagi-lagi, karena semua rumus sudah ada dan tinggal digunakan, pembuatan program untuk metode open Newton-Cotes tergolong mudah.\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Metode open Newton-Cotes untuk integral tentu\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah integral: \"))\nupper_bound = eval(input(\"Masukkan batas atas integral: \"))\nprint()\n\n# n = 0 (Midpoint rule)\ndef OpenNC_n0(f,a,b):\n    # f adalah fungsi\n    h = (b-a)/2\n    x = [a+h] # list nilai x\n    hasil = 2*h*f(x[0])\n    return hasil\n\n# n = 1\ndef OpenNC_n1(f,a,b):\n    h = (b-a)/3\n    x = [a+h, a + 2*h] # list nilai x\n    hasil = (3*h/2) * ( f(x[0]) + f(x[1]) )\n    return hasil\n\n# n = 2\ndef OpenNC_n2(f,a,b):\n    h = (b-a)/4\n    x = [a+h, a + 2*h, a + 3*h]\n    hasil = (4*h/3) * ( 2*f(x[0]) - f(x[1]) + 2*f(x[2]) )\n    return hasil\n\n# n = 3\ndef OpenNC_n3(f,a,b):\n    h = (b-a)/5\n    x = [a+h, a + 2*h, a + 3*h, a + 4*h]\n    hasil = (5*h/24) * ( 11*f(x[0]) + f(x[1]) + f(x[2]) + 11*f(x[3]) )\n    return hasil\n\n# Menghitung aproksimasi integral func(x) untuk n=1,2,3,4\nhasil_open_0 = OpenNC_n0(func, lower_bound, upper_bound)\nhasil_open_1 = OpenNC_n1(func, lower_bound, upper_bound)\nhasil_open_2 = OpenNC_n2(func, lower_bound, upper_bound)\nhasil_open_3 = OpenNC_n3(func, lower_bound, upper_bound)\n\n# Menampilkan hasil\nprint(\"Berikut hasil aproksimasi integral dengan open Newton-Cotes:\")\nprint(f\"n=0: {hasil_open_0} (Midpoint rule)\")\nprint(f\"n=1: {hasil_open_1}\")\nprint(f\"n=2: {hasil_open_2}\")\nprint(f\"n=3: {hasil_open_3}\")\n\nMetode open Newton-Cotes untuk integral tentu\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = sin(x)\nMasukkan batas bawah integral: 0\nMasukkan batas atas integral: pi/4\n\nBerikut hasil aproksimasi integral dengan open Newton-Cotes:\nn=0: 0.30055886494217315 (Midpoint rule)\nn=1: 0.29798754218726264\nn=2: 0.2928586591925902\nn=3: 0.29286922813608435\n\n\n\n\n4. Tabel Ringkasan Metode Newton-Cotes\nUntuk n=0,1,2,3,4, kita bisa meringkas hasil untuk semua metode Newton-Cotes (baik closed maupun open) di dalam satu tabel, di mana - baris pertama adalah nilai n, - baris kedua adalah hasil closed Newton-Cotes yang sesuai untuk tiap nilai n, dan - baris ketiga adalah hasil open Newton-Cotes yang sesuai.\nUntuk nilai n yang tidak mungkin, seperti n=0 untuk closed Newton-Cotes, itu bisa dikosongkan saja.\nSeperti biasa, kita bisa menggunakan tabulate. Kali ini, karena tabel cukup sederhana, kita bisa langsung menyusun tabel dalam bentuk list-di-dalam-list secara manual, yang kemudian akan diolah oleh tabulate.\n\nfrom numpy import sin, cos, tan, log, exp, pi\nfrom tabulate import tabulate\n\nprint(\"Tabel metode closed (n=1,2,3,4) dan open (n=0,1,2,3) Newton-Cotes\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah integral: \"))\nupper_bound = eval(input(\"Masukkan batas atas integral: \"))\nprint()\n\n# Menghitung metode closed Newton-Cotes untuk n=0,1,2,3\nhasil_closed_1 = TrapezoidalRule(func, lower_bound, upper_bound)\nhasil_closed_2 = SimpsonsRule(func, lower_bound, upper_bound)\nhasil_closed_3 = SimpsonsThreeEightsRule(func, lower_bound, upper_bound)\nhasil_closed_4 = BoolesRule(func, lower_bound, upper_bound)\n\n# Menghitung metode open Newton-Cotes untuk n=1,2,3,4\nhasil_open_0 = OpenNC_n0(func, lower_bound, upper_bound)\nhasil_open_1 = OpenNC_n1(func, lower_bound, upper_bound)\nhasil_open_2 = OpenNC_n2(func, lower_bound, upper_bound)\nhasil_open_3 = OpenNC_n3(func, lower_bound, upper_bound)\n\n# Menyusun tabel secara manual\ntabel_mentah = [\n    [\"n\", \"0\", \"1\", \"2\", \"3\", \"4\"],\n    [\"closed\", \"\", hasil_closed_1, hasil_closed_2, hasil_closed_3, hasil_closed_4],\n    [\"open\", hasil_open_0, hasil_open_1, hasil_open_2, hasil_open_3, \"\"]\n]\n\ntabel_olahan = tabulate(tabel_mentah, tablefmt=\"pretty\", floatfmt=\".10f\",\n                        headers=\"firstrow\")\n\nprint(\"Hasil tabel metode Newton-Cotes:\")\nprint(tabel_olahan)\n\nTabel metode closed (n=1,2,3,4) dan open (n=0,1,2,3) Newton-Cotes\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = sin(x)\nMasukkan batas bawah integral: 0\nMasukkan batas atas integral: pi/4\n\nHasil tabel metode Newton-Cotes:\n+--------+---------------------+---------------------+--------------------+---------------------+---------------------+\n|   n    |          0          |          1          |         2          |          3          |          4          |\n+--------+---------------------+---------------------+--------------------+---------------------+---------------------+\n| closed |                     | 0.2776801836348979  | 0.292932637839748  | 0.29291070254917145 | 0.29289318256126384 |\n|  open  | 0.30055886494217315 | 0.29798754218726264 | 0.2928586591925902 | 0.29286922813608435 |                     |\n+--------+---------------------+---------------------+--------------------+---------------------+---------------------+\n\n\n\n\n5. Integrasi numerik komposit: rumus umum\nUntuk interval yang tidak besar, metode Newton-Cotes cukup akurat. Ingat bahwa metode Newton-Cotes bersandar pada polinom interpolasi Lagrange, yang sering naik-turun atau berosilasi, sehingga berisiko terlalu jauh berbeda dari fungsi yang aslinya, apalagi sekitar titik pertama dan titik terakhir yang digunakan untuk interpolasi. (Fun fact: masalah osilasi ini disebut fenomena Runge.) Risiko tersebut membuat metode Newton-Cotes kurang cocok untuk interval yang besar, karena hasil aproksimasi luasnya menjadi kurang akurat.\nNamun, kita bisa saja memecah suatu integral tentu menjadi sejumlah integral yang masing-masing memiliki interval yang lebih kecil (yang merupakan subinterval dari interval integrasi aslinya), kemudian menerapkan metode Newton-Cotes untuk masing-masing integral. Teknik ini disebut integrasi numerik komposit.\nTentu saja, untuk suatu integral tentu \\(\\int_{A}^{B} f\\left(x\\right) dx\\), kita bisa bebas memilih bagaimana cara memecah interval integrasi yang asli, \\([A,B]\\), menjadi beberapa subinterval. Namun, untuk mempermudah pemrograman, kita bisa memecah \\([A,B]\\) menjadi sejumlah \\(N\\) subinterval (akan kita sebut \\(N\\) “subinterval besar”) yang sama panjang, masing-masing memiliki panjang \\(\\frac{B-A}{N}\\). Kemudian, metode Newton-Cotes yang dipilih bisa diterapkan untuk masing-masing subinterval besar \\([a_i,b_i] \\subseteq [A,B]\\), dengan \\(i=1,2,3,\\dots,N\\). Sehingga, berlaku \\(a_1=A\\) dan \\(b_N=B\\), serta berlaku \\(a_2=b_1\\), \\(a_3=b_2\\) dan seterusnya, atau bisa dituliskan \\(a_i=b_{i-1}\\) untuk \\(i=2,3,4,\\dots,N\\).\n\\[\\int_{A}^{B} f\\left(x\\right) dx = \\int_{a_1}^{b_1} f\\left(x\\right) dx + \\int_{a_2}^{b_2} f\\left(x\\right) dx + \\cdots + \\int_{a_N}^{b_N} f\\left(x\\right) dx\\]\nTeknis perhitungan metode Newton-Cotes bisa melibatkan penggunaan beberapa titik pada \\([a_i,b_i]\\). Sehingga, subinterval besar \\([a_i, b_i]\\), secara tidak langsung, dipecah menjadi beberapa subinterval kecil.\nMisalnya, ketika menerapkan metode Simpson pada \\([a_1,b_1]\\), digunakan \\(h=\\frac{b_1-a_1}{2}\\), yang memecah subinterval besar \\([a_1,b_1]\\) menjadi dua subinterval kecil yaitu \\(\\left[a_1,a_1+h\\right]\\) dan \\(\\left[a_1+h,b_1\\right]\\). Sehingga, untuk metode Simpson komposit, banyaknya subinterval kecil \\(n=2N\\). Perhatikan gambar berikut dengan \\(N=4\\), \\(n=8\\).\n\n\n\np5 integral croptime Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org) copy_page-0005.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.4, “Composite Numerical Integration”. Hlm. 204\nPada gambar di atas, digunakan metode Simpson komposit untuk \\(N=4\\) subinterval besar. Masing-masing subinterval besar (misalnya subinterval besar ke-\\(i\\) untuk \\(i=1,2,\\dots,N\\)) menggunakan titik-titik \\(x_{i-1}\\), \\(x_i\\), dan \\(x_{i+1}\\).\nTerlihat bahwa masing-masing subinterval besar (misalnya subinterval besar ke-3, yang diwarnai biru gelap) terbagi lagi menjadi dua subinterval kecil, sehingga banyaknya subinterval kecil \\(n=2N=8\\). Secara keseluruhan, digunakan sebanyak \\((n+1)\\) titik, yaitu \\(x_0, x_1, x_2, \\dots, x_n\\). Untuk gambar di atas, digunakan \\(n+1=9\\) titik yaitu \\(x_0, x_1, x_2, \\dots, x_8\\).\nDengan demikian, ada dua cara untuk membuat program integrasi numerik komposit, yaitu 1. hanya melihat tiap subinterval besar sampai \\(N\\), kemudian memanggil fungsi metode Newton-Cotes yang sesuai untuk tiap subinterval besar; atau 2. melihat semua subinterval kecil sampai \\(n\\) (sehingga nantinya menggunakan rumus khusus)\nCara yang pertama menghasilkan program yang cukup fleksibel, bisa menerima sembarang metode Newton-Cotes (atau bahkan sembarang metode integrasi numerik) dan kodenya tetap sama. Cara yang kedua melibatkan rumus khusus (seperti yang diberikan di buku), baik untuk metode Simpson komposit, metode trapezoidal komposit, maupun metode midpoint komposit, ataupun yang lainnya.\nBerikut ini, kita akan membuat program dengan cara pertama.\n\ndef KompositUmum(FungsiNC, fungsi_x, A, B, N):\n    # awalnya belum ada luas yang dihitung, masih nol\n    hasil_akhir = 0\n\n    # panjang tiap subinterval besar\n    H = (B-A)/N\n\n    # titik ujung atau batasan dari subinterval besar pertama [a_1, b_1]:\n    a_i = A\n    b_i = A+H\n    # nama variabel a_i, b_i karena akan diubah-ubah\n\n    # lakukan metode Newton-Cotes yang diberikan untuk tiap subinterval besar\n    for i in range(N):\n        hasil_subinterval = FungsiNC(fungsi_x, a_i, b_i)\n        hasil_akhir += hasil_subinterval\n\n        # lanjut ke subinterval besar berikutnya\n        a_i = b_i # karena a_i = b_{i-1}\n        b_i += H\n    \n    return hasil_akhir\n\nPerhatikan bahwa fungsi tersebut seperti “membungkus” apapun fungsi metode Newton-Cotes yang diberikan. Istilahnya, fungsi tersebut merupakan “wrapper function”.\nKemudian, kita bisa menerapkan wrapper function tersebut ke sembarang fungsi metode Newton-Cotes. Sebagai contoh, berikut metode Simpson komposit:\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Integrasi Numerik Komposit Simpson dengan rumus umum\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah: \"))\nupper_bound = eval(input(\"Masukkan batas atas: \"))\npartisi_besar = eval(input(\"Masukkan jumlah subinterval besar (N): \"))\nprint()\n\n# bisa diganti dengan fungsi closed/open Newton-Cotes yang manapun\nFungsiNC = SimpsonsRule\n# (harus sudah terdefinisi dulu)\n\nhasil = KompositUmum(FungsiNC, func, lower_bound, upper_bound, partisi_besar)\nprint(\"Hasil integrasi numerik:\")\nprint(hasil)\n\nIntegrasi Numerik Komposit Simpson dengan rumus umum\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = x * log(x)\nMasukkan batas bawah: 1\nMasukkan batas atas: 2\nMasukkan jumlah subinterval besar (N): 2\n\nHasil integrasi numerik:\n0.6363098297969493\n\n\n\n\n6. Integrasi numerik komposit: rumus khusus\nUntuk cara kedua, di buku Burden, sudah dilakukan penjabaran sehingga diperoleh rumus khusus untuk beberapa metode Newton-Cotes komposit, yaitu: * Metode Simpson Komposit (composite Simpson’s rule) * Metode Trapezoidal Komposit (composite trapezoidal rule) * Metode Midpoint Komposit (composite midpoint rule)\nMasing-masing rumus khusus langsung melihat semua \\(n\\) subinterval kecil yang terbentuk oleh \\((n+1)\\) titik yang digunakan. Namun, dibandingkan dengan cara yang sebelumnya (rumus umum), hasil akhirnya akan sama persis. Berikut rumus khususnya, untuk integral tentu \\(\\int_{a}^{b} f\\left(x\\right) dx\\) yang kemudian dibagi menjadi \\(n\\) subinterval kecil, di mana tiap subinterval kecil memiliki panjang \\(h\\) sesuai ketentuan metodenya.\n\nMetode Simpson Komposit\n\n\\[\\int_{a}^{b} f\\left(x\\right) dx \\approx \\frac{h}{3} \\left[ f(a) + 2\\sum_{j=1}^{(n/2)-1} f(x_{2j}) + 4\\sum_{j=1}^{n/2} f(x_{2j-1}) + f(b) \\right]\\]\ndi mana \\(n\\) harus genap, \\(h = (b-a)/n\\), dan \\(x_j = a + jh\\) untuk \\(j = 0, 1, \\dots, n\\).\n\nMetode Trapezoidal Komposit\n\n\\[\\int_{a}^{b} f\\left(x\\right) dx \\approx \\frac{h}{2} \\left[ f(a) + 2\\sum_{j=1}^{n-1} f(x_j) + f(b) \\right]\\]\ndi mana \\(n\\) adalah bilangan bulat positif, \\(h = (b-a)/n\\), dan \\(x_j = a + jh\\) untuk \\(j = 0, 1, \\dots, n\\).\n\nMetode Midpoint Komposit\n\n\\[\\int_{a}^{b} f\\left(x\\right) dx \\approx 2h \\sum_{j=0}^{n/2} f\\left(x_{2j}\\right)\\]\ndi mana \\(n\\) harus genap, \\(h = (b-a)/(n+2)\\), dan \\(x_j = a + jh\\) untuk \\(j=0,1,\\dots,n\\).\nAdanya syarat \\(n\\) genap untuk metode Simpson komposit dan metode midpoint komposit disebabkan hubungan antara \\(n\\) dan \\(N\\) yang melibatkan perkalian 2 untuk kedua metode komposit tersebut (serta sumasi dilakukan hingga \\(n/2\\)). Sedangkan, untuk metode trapezoidal komposit, berlaku \\(n = N\\); yaitu, istilah “subinterval kecil” dan “subinterval besar” ternyata sama saja (khusus trapezoidal).\nSebelumnya, sudah ditampilkan gambar proses partisi untuk metode Simpson komposit, di mana terlihat perbedaan antara subinterval kecil (ada sebanyak \\(n\\)) dan subinterval besar (ada sebanyak \\(N\\)), serta terlihat \\(n=2N\\).\nBerikut gambar untuk metode trapezoidal komposit, di mana \\(n=N\\), atau tidak ada perbedaan antara subinterval kecil dan subinterval besar:\n\n\n\np6_1 integral croptime Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org) copy_page-0006.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.4, “Composite Numerical Integration”. Hlm. 207\nSedangkan, berikut di bawah ini adalah gambar untuk metode midpoint komposit, dengan \\(n=10\\) dan \\(N=6\\), di mana banyaknya subinterval kecil terhitung dari titik \\(x_0\\) sampai \\(x_n\\), sedangkan banyaknya subinterval besar terhitung dari \\(a=x_{-1}\\) sampai \\(b=x_{n+1}\\). Kali ini, berlaku \\(n=2N-2\\).\nPerhatikan bahwa metode midpoint termasuk open Newton-Cotes, tidak seperti metode trapezoidal dan metode Simpson yang termasuk closed Newton-Cotes. Sehingga, untuk metode midpoint komposit, titik-titik pada ujung interval, yaitu titik \\(a=x_{-1}\\) dan \\(b=x_{n+1}\\), itu sama sekali tidak terlibat dalam perhitungan; berkurangnya dua titik itu menyebabkan yang tadinya \\(n=2N\\) (gambarnya sama dengan Simpson komposit) itu menjadi \\(n=2N-2\\).\n\n\n\np6_2 integral croptime Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org) copy_page-0006 copy.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.4, “Composite Numerical Integration”. Hlm. 207\nProses pemrograman untuk rumus-rumus tersebut melibatkan proses iterasi untuk menghitung sumasi/penjumlahan yang ada pada rumusnya.\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Integrasi Numerik Komposit dengan rumus khusus\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah: \"))\nupper_bound = eval(input(\"Masukkan batas atas: \"))\npartisi = eval(input(\"Masukkan jumlah partisi / subinterval kecil (n): \"))\nprint()\n\ndef CompSimpson(f,a,b,n):\n    if n%2 == 1: # jika n ganjil\n        return \"banyaknya subinterval kecil harus genap\"\n    elif n%2 == 0: # jika n genap (sudah benar)\n        # panjang tiap subinterval kecil\n        h = (b-a)/n\n        \n        # list semua titik x\n        X = []\n        # ada n subinterval kecil, maka ada (n+1) titik, x0 = a\n        for i in range(n+1): # untuk i = 0, 1, 2, ..., n\n            # titik dengan indeks i, dari x_0 = a, x_1, x_2, sampai x_n = b\n            x_i = a + i*h\n\n            # tambahkan ke list x\n            X.append(x_i) \n        # sampai sini, list x sudah lengkap\n\n        # menghitung kedua sumasi:\n        sum1 = 0 # untuk sumasi f(x_{2j})\n        sum2 = 0 # untuk sumasi f(x_{2j-1})\n        for j in range (1, int(n/2)): # untuk j = 1, 2, ..., (n/2)-1\n            sum1 += f(X[2*j])\n            sum2 += f(X[2*j-1])\n        \n        # sumasi yang kedua ternyata sampai j=(n/2),\n        # sehingga kita tambahkan sekali lagi\n        j = int(n/2)\n        sum2 += f(X[2*j-1])\n\n        # gunakan rumus\n        hasil = (h/3) * ( f(a) + 2*sum1 + 4*sum2 + f(b) )\n        return hasil\n\ndef CompTrapezoidal(f,a,b,n):\n    # panjang tiap subinterval kecil\n    h = (b-a)/n\n\n    # list semua titik x\n    X = []\n    # ada n subinterval kecil, maka ada (n+1) titik, x0 = a\n    for i in range(n+1): # untuk i = 0, 1, 2, ..., n\n        # titik dengan indeks i, dari x_0 = a, x_1, x_2, sampai x_n = b\n        x_i = a + i*h\n\n        # tambahkan ke list x\n        X.append(x_i) \n    # sampai sini, list x sudah lengkap\n\n    # menghitung sumasi\n    sumasi = 0\n    for j in range(1,n): # untuk j = 1, 2, ..., n-1\n        sumasi += f(X[j])\n    \n    # gunakan rumus\n    hasil = (h/2) * ( f(a) + 2*sumasi + f(b) )\n    return hasil\n\ndef CompMidpoint(f,a,b,n):\n    if n%2==1: # jika n ganjil\n        return \"banyaknya subinterval kecil harus genap\"\n    elif n%2==0: # jika n genap (sudah benar)\n        # panjang tiap subinterval kecil\n        h = (b-a)/(n+2)\n        # (dibagi n+2 karena metode Midpoint termasuk OPEN Newton-Cotes)\n\n        # list semua titik x\n        X = []\n        # ada n subinterval kecil, maka ada (n+1) titik, x0 = a + h\n        # (x0 = a + h karena OPEN Newton-Cotes)\n        for i in range(n+1): # untuk i = 0, 1, 2, ..., n\n            # titik dengan indeks i, dari x_0 = (a+h), x_1, x_2, sampai x_n\n            x_i = (a+h) + i*h\n            # supaya, jika i=0, maka x_i = x_0 = a+h\n\n            # tambahkan ke list x\n            X.append(x_i) \n        # sampai sini, list x sudah lengkap\n\n        # menghitung sumasi\n        sumasi = 0\n        for j in range (0, int(n/2)+1): # untuk j = 0, 1, 2, ..., n/2\n            sumasi += f(X[2*j])\n        \n        # gunakan rumus\n        hasil = 2 * h * sumasi\n        return hasil\n\nsimpson_komposit = CompSimpson(func, lower_bound, upper_bound, partisi)\ntrapezoidal_komposit = CompTrapezoidal(func, lower_bound, upper_bound, partisi)\nmidpoint_komposit = CompMidpoint(func, lower_bound, upper_bound, partisi)\n\nprint(\"Hasil integrasi numerik komposit:\")\nprint(\"{0} (Metode Simpson Komposit)\".format(simpson_komposit))\nprint(\"{0} (Metode Trapezoidal Komposit)\".format(trapezoidal_komposit))\nprint(\"{0} (Metode Midpoint Komposit)\".format(midpoint_komposit))\n\nIntegrasi Numerik Komposit dengan rumus khusus\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = x * log(x)\nMasukkan batas bawah: 1\nMasukkan batas atas: 2\nMasukkan jumlah partisi / subinterval kecil (n): 4\n\nHasil integrasi numerik komposit:\n0.6363098297969492 (Metode Simpson Komposit)\n0.639900477687986 (Metode Trapezoidal Komposit)\n0.6330963650576533 (Metode Midpoint Komposit)\n\n\nBONUS: membandingkan rumus umum dengan rumus khusus\nPerhitungan dengan rumus umum melibatkan banyaknya subinterval besar \\(N\\), sedangkan perhitungan dengan rumus khusus melibatkan banyaknya subinterval kecil \\(n\\). Hubungan di antara kedua nilai tersebut tergantung metode Newton-Cotes yang digunakan untuk metode komposit. Apabila kita memilih nilai \\(N\\) besar dan \\(n\\) kecil yang tepat, maka hasil rumus umum dan rumus khusus akan sama (atau hampir sama, karena masalah round-off error).\nMari kita coba untuk mengaproksimasi nilai dari integral tentu \\(\\int_{1}^{2} x \\ln(x) dx\\).\n\n# fungsi ln dari numpy bernama log\nfrom numpy import log\n\n# fungsi yang ingin diintegralkan\ndef func(x):\n    return x * log(x)\n\n\nlower_bound = 1\nupper_bound = 2\n\nUntuk metode trapezoidal komposit, berlaku \\(n=N\\). Jika \\(N=4\\), maka \\(n=4\\). Mari kita bandingkan:\n\n# Untuk trapezoidal komposit\nN = 4\nn = N\n\n\n# Rumus umum\nKompositUmum(TrapezoidalRule, func, lower_bound, upper_bound, N)\n\n0.6399004776879859\n\n\n\n# Rumus khusus\nCompTrapezoidal(func, lower_bound, upper_bound, n)\n\n0.639900477687986\n\n\nUntuk metode Simpson komposit, berlaku \\(n=2N\\). Jika \\(N=4\\), maka \\(n=8\\). Mari kita bandingkan:\n\n# Untuk Simpson komposit\nN = 4\nn = 2*N\n\n\n# Rumus umum\nKompositUmum(SimpsonsRule, func, lower_bound, upper_bound, N)\n\n0.6362953646399339\n\n\n\n# Rumus khusus\nCompSimpson(func, lower_bound, upper_bound, n)\n\n0.636295364639934\n\n\nUntuk metode midpoint komposit, berlaku \\(n=2N-2\\). Jika \\(N=4\\), maka \\(n=6\\). Mari kita bandingkan:\n\n# Untuk midpoint komposit\nN = 4\nn = 2*N - 2\n\n\n# Rumus umum\nKompositUmum(OpenNC_n0, func, lower_bound, upper_bound, N)\n\n0.634492808115908\n\n\n\n# Rumus khusus\nCompMidpoint(func, lower_bound, upper_bound, n)\n\n0.634492808115908\n\n\n\n\n7. Kuadratur Adaptif (Adaptive Quadrature)\nUmumnya, metode komposit (dengan pemilihan subinterval yang sama panjang) sangatlah efektif, kecuali ketika bentuk fungsi sangat bervariasi sepanjang interval integrasi: terkadang “liar”, terkadang “tenang”.\nBeberapa contoh fungsi yang bentuknya sangat bervariasi adalah \\(f(x) = e^{-3x} \\sin 4x\\) pada interval \\([0,2]\\) dan \\(f(x) = \\frac{100}{x^2} \\sin \\left( \\frac{10}{x} \\right)\\) pada interval \\([1,3]\\).\nUntuk fungsi-fungsi seperti itu, alangkah baiknya apabila kita bisa memilih beberapa subinterval dengan panjang yang berbeda-beda, menyesuaikan dengan bentuk fungsi, agar hasil integrasi numerik menjadi lebih akurat.\nTernyata, kita bisa melakukan partisi (memecah interval integrasi menjadi sejumlah subinterval) secara rekursif, terus membuat partisi dan menghitung integral sampai hasil integrasi numerik cukup akurat, memenuhi suatu batas toleransi yang kita tetapkan. Metode ini disebut kuadratur adaptif (adaptive quadrature), karena seolah-olah program bisa beradaptasi untuk mempersempit subinterval ketika bentuk fungsi sangat “liar”, tetapi tidak perlu mempersempit subinterval ketika bentuk fungsi cukup “tenang”.\nPerhatikan bahwa metode kuadratur adaptif ini bersifat rekursif (terus membuat partisi secara rekursif selama batas toleransi belum terpenuhi), tidak seperti metode komposit yang telah dibahas sebelumnya di mana banyaknya partisi (dan panjang tiap subinterval) sudah ditentukan dari awal.\nKuadratur adaptif menghitung nilai integral menggunakan suatu metode yang bisa kita tentukan. Apabila digunakan metode Simpson untuk menghitung integral tersebut (seperti di buku), maka metodenya secara keseluruhan disebut metode Simpson adaptif (Adaptive Simpson’s method).\nMisalkan metode integral yang dipilih disebut \\(S(a,b)\\) untuk menghitung integral pada interval \\([a,b]\\). Jika diberikan toleransi sebesar \\(\\varepsilon\\) (epsilon) dan suatu “faktor/pengkali toleransi” pengkali_tol, langkah-langkah untuk kuadratur adaptif menggunakan metode \\(S\\) untuk menghitung \\(\\int_{a}^{b} f\\left(x\\right) dx\\) bisa dituliskan sebagai berikut: 1. Hitung titik tengah m = (a+b)/2 2. Hitung hasil_keseluruhan = S(a, b) 3. Hitung hasil_gabung = S(a, m) + S(m, b) 4. Apabila |hasil_gabung - hasil_keseluruhan| &gt; pengkali_tol * epsilon, toleransi belum terpenuhi, sehingga hasil kuadratur adaptif pada \\([a,b]\\) akan sama dengan hasil kuadratur adaptif pada \\([a,m]\\) ditambah hasil kuadratur adaptif pada \\([m,b]\\) (di sini dilakukan proses rekursif, yaitu memanggil fungsi kuadratur adaptif untuk interval \\([a,m]\\) dan memanggil fungsi kuadratur adaptif untuk interval \\([m,b]\\)). Inilah tahapan mempersempit interval. 5. Namun, apabila toleransi sudah terpenuhi, maka hasil kuadratur adaptif adalah hasil_gabung. Ternyata, interval tidak perlu dipersempit lagi.\nPada langkah-langkah di atas, apabila toleransi belum terpenuhi untuk interval utama, bisa saja misalnya hasil kuadratur adaptif pada \\([a,m]\\) nantinya sudah memenuhi toleransi, tetapi hasil kuadratur adaptif pada \\([m,b]\\) belum memenuhi toleransi juga. Maka, interval \\([a,m]\\) tidak akan dipersempit, tetapi interval \\([m,b]\\) perlu dipersempit lagi, dan akan dilakukan proses rekursif lagi (memanggil fungsi kuadratur adaptif lagi) dengan interval yang lebih kecil. Inilah sifat “adaptif” yang dimiliki oleh metode kuadratur adaptif, yaitu bisa menyesuaikan: terkadang mempersempit interval, terkadang tidak dipersempit karena tidak perlu (sudah memenuhi toleransi).\nFaktor/pengkali toleransi yang umum digunakan adalah 15, terutama untuk metode Simpson adaptif. Namun, pengkali toleransi sebaiknya diperkecil apabila fungsi sangatlah liar, misalnya menjadi 10 saja, atau bahkan lebih kecil lagi. Kita akan menggunakan pengkali_tol = 10.\n\ndef KuadraturAdaptif(FungsiIntegrasi, f, a, b, tol, pengkali_tol=10):\n    # titik tengah\n    m = (a+b)/2\n\n    # nilai integrasi numerik pada [a,b]\n    hasil_keseluruhan = FungsiIntegrasi(f, a, b)\n\n    # menggabungkan hasil integrasi numerik pada [a,m] dengan hasil pada [m,b]\n    hasil_kiri = FungsiIntegrasi(f, a, m)\n    hasil_kanan = FungsiIntegrasi(f, m, b)\n    hasil_gabung = hasil_kiri + hasil_kanan\n\n    if abs(hasil_gabung - hasil_keseluruhan) &gt; pengkali_tol * tol:\n\n        # jika batas toleransi belum dipenuhi, maka partisi jadi dua subinterval\n        # lalu lakukan kuadratur adaptif untuk tiap subinterval\n\n        adaptif_kiri = KuadraturAdaptif(\n            FungsiIntegrasi, f, a, m, tol/2, pengkali_tol)\n        \n        adaptif_kanan = KuadraturAdaptif(\n            FungsiIntegrasi, f, m, b, tol/2, pengkali_tol)\n\n        # lalu jumlahkan hasil kuadratur adaptif kedua subinterval\n        # menjadi hasil akhir untuk interval utama\n        hasil_akhir = adaptif_kiri + adaptif_kanan\n    else:\n        # jika batas toleransi sudah terpenuhi, gunakan saja hasil gabung nya\n        # sebagai hasil akhir\n        hasil_akhir = hasil_gabung\n    \n    return hasil_akhir\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Simpson Adaptif: Kuadratur Adaptif dengan metode Simpson\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah: \"))\nupper_bound = eval(input(\"Masukkan batas atas: \"))\ntoleransi = eval(input(\"Masukkan toleransi (epsilon): \"))\npengkali_toleransi = eval(input(\"Masukkan pengkali toleransi: \"))\nprint()\n\n# bisa diganti dengan fungsi integrasi numerik yang manapun,\n# kebetulan di sini ingin menggunakan metode Simpson\nFungsiIntegrasi = SimpsonsRule\n# (harus sudah terdefinisi dulu)\n\nhasil = KuadraturAdaptif(\n    FungsiIntegrasi, func, lower_bound, upper_bound,\n    toleransi, pengkali_toleransi\n    )\n\nprint(\"Hasil Simpson Adaptif:\")\nprint(hasil)\n\nSimpson Adaptif: Kuadratur Adaptif dengan metode Simpson\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = (100/(x**2)) * sin(10/x)\nMasukkan batas bawah: 1\nMasukkan batas atas: 3\nMasukkan toleransi (epsilon): 10**-4\nMasukkan pengkali toleransi: 10\n\nHasil Simpson Adaptif:\n-1.426014810049443\n\n\nBONUS: melihat semua titik yang digunakan\nKita bisa sedikit memodifikasi fungsi KuadraturAdaptif agar menyimpan semua nilai x yang dijadikan batasan subinterval, kemudian juga memberikan output berupa list nilai x tersebut.\n\ndef ModifikasiKuadraturAdaptif(FungsiIntegrasi, f, a, b, tol, pengkali_tol=10):\n    # titik tengah\n    m = (a+b)/2\n\n    # list semua titik yang digunakan sebagai batasan subinterval\n    list_x = [a, b]\n    # nanti akan ditambahkan\n\n    # nilai integrasi numerik pada [a,b]\n    hasil_keseluruhan = FungsiIntegrasi(f, a, b)\n\n    # menggabungkan hasil integrasi numerik pada [a,m] dengan hasil pada [m,b]\n    hasil_kiri = FungsiIntegrasi(f, a, m)\n    hasil_kanan = FungsiIntegrasi(f, m, b)\n    hasil_gabung = hasil_kiri + hasil_kanan\n\n    if abs(hasil_gabung - hasil_keseluruhan) &gt; pengkali_tol * tol:\n\n        # jika batas toleransi belum dipenuhi, maka partisi jadi dua subinterval\n        # lalu lakukan kuadratur adaptif untuk tiap subinterval\n\n        adaptif_kiri, list_kiri = ModifikasiKuadraturAdaptif(\n            FungsiIntegrasi, f, a, m, tol/2, pengkali_tol)\n        \n        adaptif_kanan, list_kanan = ModifikasiKuadraturAdaptif(\n            FungsiIntegrasi, f, m, b, tol/2, pengkali_tol)\n\n        # menambahkan semua titik yang digunakan ke list_x\n        for angka in list_kiri:\n            if not (angka in list_x): # kalau belum ada\n                list_x.append(angka)\n        for angka in list_kanan:\n            if not (angka in list_x):\n                list_x.append(angka)\n\n        # lalu jumlahkan hasil kuadratur adaptif kedua subinterval\n        # menjadi hasil akhir untuk interval utama\n        hasil_akhir = adaptif_kiri + adaptif_kanan\n    else:\n        # jika batas toleransi sudah terpenuhi, gunakan saja hasil gabung nya\n        # sebagai hasil akhir\n        hasil_akhir = hasil_gabung\n    \n    # sortir list_x secara ascending\n    list_x.sort()\n\n    return hasil_akhir, list_x\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Simpson Adaptif: Kuadratur Adaptif dengan metode Simpson\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah: \"))\nupper_bound = eval(input(\"Masukkan batas atas: \"))\ntoleransi = eval(input(\"Masukkan toleransi (epsilon): \"))\npengkali_toleransi = eval(input(\"Masukkan pengkali toleransi: \"))\nprint()\n\nhasil, list_x = ModifikasiKuadraturAdaptif(\n    SimpsonsRule, func, lower_bound, upper_bound,\n    toleransi, pengkali_toleransi\n    )\n\nprint(\"Hasil Simpson Adaptif:\")\nprint(hasil)\nprint()\n\nprint(\"List semua titik yang digunakan sebagai batasan subinterval:\")\nprint(list_x)\nprint(\"yaitu sebanyak {0} titik\".format(len(list_x)))\n\nSimpson Adaptif: Kuadratur Adaptif dengan metode Simpson\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = (100/(x**2)) * sin(10/x)\nMasukkan batas bawah: 1\nMasukkan batas atas: 3\nMasukkan toleransi (epsilon): 10**-4\nMasukkan pengkali toleransi: 10\n\nHasil Simpson Adaptif:\n-1.426014810049443\n\nList semua titik yang digunakan sebagai batasan subinterval:\n[1, 1.03125, 1.0625, 1.09375, 1.125, 1.15625, 1.1875, 1.25, 1.3125, 1.375, 1.4375, 1.5, 1.5625, 1.625, 1.6875, 1.75, 1.875, 2.0, 2.125, 2.25, 2.375, 2.5, 2.75, 3]\nyaitu sebanyak 24 titik\n\n\nAnda bisa mencoba menerapkan kuadratur adaptif (dengan program yang telah dimodifikasi) untuk menghitung integral dari \\(f(x) = \\frac{100}{x^2} \\sin \\left( \\frac{10}{x} \\right)\\) pada \\([1,3]\\) dengan toleransi \\(10^{-4}\\) dan pengkali toleransi sebesar 10, kemudian membandingkan titik-titik yang digunakan di situ dengan Figure 4.14 di buku (bisa dihitung, ada 24 titik):\n\n\n\nintegral realcrop p226 Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org)_page-0001 copy.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.6, “Adaptive Quadrature Methods”. Hlm. 226\n(Pada program yang dimodifikasi tersebut, tidak ada modifikasi pada metode kuadratur adaptif itu sendiri; modifikasi yang dilakukan hanyalah agar program juga mengeluarkan output berupa titik-titik yang digunakan sebagai batasan subinterval.)\nBONUS 2: kode non-rekursif dari buku\nBerikut implementasi non-rekursif untuk kuadratur adaptif berdasarkan pseudocode di buku (Algorithm 4.3). Perlu dicatat bahwa, bahkan menurut buku (halaman 224, kalimat terakhir), “The method is easier to implement using a recursive programming language.” (karena pseudocode yang diberikan mengasumsikan bahwa bahasa pemrograman yang digunakan tidak bisa menjalankan fungsi rekursif.)\nDi sini, kuadratur adaptif yang harusnya dilakukan secara rekursif malah dipaksakan agar dilakukan secara “iteratif”. Variabel i menandakan sisa interval yang perlu ditelusuri. Bisa dibayangkan, [FA, FB] memiliki titik tengah FC, sehingga dipartisi menjadi [FA, FC] dan [FC, FB]. Kemudian, titik tengah dari [FA, FC] adalah FD, dan titik tengah dari [FC, FB] adalah FE. Sehingga, kedudukan tiap titik dari kiri ke kanan adalah (FA, FD, FC, FE, FB). (Sebenarnya, FA, FB, FC, FD, dan FE adalah nilai fungsi, bukan titik x nya.)\nEntah bagaimana caranya, pseudocode tersebut melakukan penyimpanan data secara strategis agar tidak lupa akan semua subinterval yang perlu dihitung integralnya secara numerik (sayangnya menggunakan terlalu banyak “array” yang di sini diimplementasikan sebagai dictionary, dan menggunakan terlalu banyak variabel seperti variabel v1, v2, …, v8 yang kegunaannya tidak jelas dari penamaan variabelnya). Setelah melakukan partisi dan menyimpan semua subinterval dari kanan ke kiri, perhitungan integrasi numerik dilakukan dari subinterval paling kiri sampai interval paling kanan, dan tiap hasil perhitungan integral langsung ditambahkan ke APP yaitu variabel yang menyimpan hasil aproksimasi untuk keseluruhan integral.\nMenariknya, permasalahan mengubah kode rekursif (seperti yang kita buat sebelumnya) menjadi kode “iteratif” (seperti yang ada di buku) tidak jarang ditemui, dan solusi yang paling sering digunakan adalah “implement your own stack”. Tumpukan atau stack adalah salah satu struktur data yang dipelajari di mata kuliah Struktur Data (sering disebut “DSA” atau data structures and algorithms di kurikulum internasional) yang kebetulan merupakan mata kuliah wajib untuk program studi S1 Matematika.\n\n# Algoritma 4.3 di buku halaman 224-225\ndef AdaptifBurden(a_konstan, b_konstan, TOL_konstan, N):\n    # === Step 1 ===\n    APP = 0\n    i = 1\n\n    TOL, a, b, h, FA, FC, FB, S, L = {}, {}, {}, {}, {}, {}, {}, {}, {}\n\n    TOL[i] = 10 * TOL_konstan\n    a[i] = a_konstan\n    h[i] = (b_konstan - a_konstan)/2\n    FA[i] = f(a_konstan)\n    FC[i] = f(a_konstan + h[i])\n    FB[i] = f(b_konstan)\n\n    S[i] = h[i] * ( FA[i] + 4 * FC[i] + FB[i] )/3\n    #   (Approximation from Simpson's\n    #   method for entire interval.)\n\n    L[i] = 1\n\n    # === Step 2 ===\n    # While i &gt; 0 do Steps 3-5.\n    while i &gt; 0:\n        # === Step 3 ===\n        FD = f( a[i] +     h[i]/2 )\n        FE = f( a[i] + 3 * h[i]/2 )\n\n        S1 = h[i] * ( FA[i] + 4 * FD + FC[i] )/6\n        #   (Approximations from Simpson's\n        #   method for halves of subintervals.)\n\n        S2 = h[i] * ( FC[i] + 4 * FE + FB[i] )/6\n\n        #   (Save data at this level.)\n        v1 = a[i]\n        v2 = FA[i]\n        v3 = FC[i]\n        v4 = FB[i]\n        v5 = h[i]\n        v6 = TOL[i]\n        v7 = S[i]\n        v8 = L[i]\n\n        # === Step 4 ===\n\n        i = i - 1\n        #   (Delete the level.)\n\n        # === Step 5 ===\n        if abs(S1 + S2 - v7) &lt; v6:\n            APP = APP + (S1 + S2)\n        elif (v8 &gt;= N):\n            return \"LEVEL EXCEEDED\"\n            # STOP.\n            #   (Procedure fails.)\n        else:\n            #   (Add one level.)\n            \n            #   (Data for right half subinterval.)\n            i = i + 1\n            a[i] = v1 + v5\n            FA[i] = v3\n            FC[i] = FE\n            FB[i] = v4\n            h[i] = (v5)/2\n            TOL[i] = (v6)/2\n            S[i] = S2\n            L[i] = v8 + 1\n\n            #   (Data for left half subinterval.)\n            i = i + 1\n            a[i] = v1\n            FA[i] = v2\n            FC[i] = FD\n            FB[i] = v3\n            h[i] = h[i-1]\n            TOL[i] = TOL[i-1]\n            S[i] = S1\n            L[i] = L[i-1]\n    \n    # === Step 6 ===\n    return APP\n    # STOP.\n    #   (APP approximates I to within TOL.)\n\n\n# Contoh fungsi\nfrom numpy import sin\ndef f(x):\n    hasil = (100/(x**2)) * sin(10/x)\n    return hasil\n\nprint(AdaptifBurden(1, 3, 10**-4, N=7))\n# sepertinya N terkecil agar tidak muncul \"LEVEL EXCEEDED\" adalah N=7\n\nprint(\n\"\"\"\nThe graph of the function f(x) = (100/x^2) sin(10/x) for x in [1,3] is shown in\nFigure 4.14. Using the Adaptive Quadrature Algorithm 4.3 with tolerance 10^-4\nto approximate \\int_{1}^{3} f(x) dx produces -1.426014, a result that is\naccurate to within 1.1 x 10^-5.\n\"\"\"\n)\n\n-1.4260148100494467\n\nThe graph of the function f(x) = (100/x^2) sin(10/x) for x in [1,3] is shown in\nFigure 4.14. Using the Adaptive Quadrature Algorithm 4.3 with tolerance 10^-4\nto approximate \\int_{1}^{3} f(x) dx produces -1.426014, a result that is\naccurate to within 1.1 x 10^-5.\n\n\n\n\n\n8. Kuadratur Gauss (Gaussian Quadrature), pada interval \\([-1,1]\\)\nMetode kuadratur Gauss (Gaussian Quadrature), atau lebih tepatnya disebut metode kuadratur Gauss-Legendre (Gauss-Legendre Quadrature), adalah suatu metode integrasi numerik yang melibatkan polinom Legendre monik ke-\\(n\\). Kita akan memerlukan akar-akar dari polinom Legendre ke-\\(n\\), untuk nilai \\(n\\) yang ditentukan. Mari kita bahas polinom Legendre terlebih dahulu. (Untuk ke depannya, kita akan menyebut metode ini “kuadratur Gauss” saja, meskipun nama yang lebih tepat adalah kuadratur Gauss-Legendre.)\nPolinom Legendre ke-\\(n\\), akan kita tulis \\(P_n (x)\\), adalah polinom (dengan nilai \\(n\\) tertentu yang berupa bilangan cacah, yaitu \\(n = 0, 1, 2, \\dots\\)) yang memenuhi beberapa sifat istimewa. Beberapa di antara sifat-sifat istimewa tersebut adalah: * Polinom Legendre ke-\\(n\\) memiliki pangkat tertinggi \\(x^n\\). * Polinom Legendre ke-\\(n\\) memiliki tepat \\(n\\) akar yang semuanya berupa bilangan riil, dan semua akar-akar tersebut terletak di antara \\(-1 \\le x \\le 1\\). * Akar-akar polinom Legendre bersifat “simeteris”, yaitu, apabila misal \\(x\\) adalah salah satu akar untuk suatu polinom Legendre, maka \\(-x\\) juga merupakan akar dari polinom Legendre tersebut.\nMaksud istilah “akar” adalah nilai \\(x\\) yang membuat \\(P_n (x) = 0\\).\nUntuk kuadratur Gauss, kita akan memanfaatkan polinom Legendre yang monik. Polinom yang monik (monic polynomial) adalah polinom yang pangkat tertingginya dikali 1. Misalnya, \\(x^2 - 4\\) bersifat monik, tetapi kalau misalnya kita kalikan 3, kita dapatkan \\(3x^2 - 12\\), yang tidak lagi monik. Sehingga, kita bisa membuat \\(3x^2 - 12\\) menjadi monik dengan dibagi 3.\nArtinya, kalau kita mendapatkan polinom yang tidak monik, kita bisa menjadikannya monik, membaginya dengan apapun pengkali pangkat tertinggi.\nMenurut buku, polinom Legendre monik untuk beberapa nilai \\(n\\) pertama adalah:\n\\[P_0 (x) = 1, \\hspace{0.5cm} P_1 (x) = x, \\hspace{0.5cm} P_2 (x) = x^2 - \\frac{1}{3}\\]\n\\[P_3 (x) = x^3 - \\frac{3}{5} x, \\hspace{0.5cm} P_4 (x) = x^4 - \\frac{6}{7} x^2 + \\frac{3}{35}\\]\nDi metode numerik, tidak dibahas cara mendapatkan polinom Legendre, atau cara menentukan semua \\(n\\) akar dari polinom Legendre ke-\\(n\\) untuk sembarang \\(n\\) bilangan cacah. Biasanya, semua data yang diperlukan sudah tersedia di tabel. Untungnya, sympy bisa menghasilkan polinom Legendre ke-\\(n\\) untuk apapun bilangan cacah \\(n\\) yang kita inginkan, bahkan sympy juga bisa menentukan semua \\(n\\) akar tersebut.\nMari kita import dulu:\n\nimport sympy\nx = sympy.symbols(\"x\")\n\nContoh untuk n=0 dan n=1, menurut sympy:\n\nLegendre0 = sympy.legendre(0, x)\nsympy.pprint(Legendre0)\n\n1\n\n\n\nsympy.pprint(sympy.legendre(1, x))\n\nx\n\n\nSejauh ini, masih sesuai dengan buku, sudah monik. Bagaimana dengan n=4?\n\nLegendre4 = sympy.legendre(4, x)\nsympy.pprint(Legendre4)\n\n    4       2    \n35⋅x    15⋅x    3\n───── - ───── + ─\n  8       4     8\n\n\nTernyata, menurut sympy, polinom Legendre tidak harus monik. Untungnya, kita bisa meminta sympy untuk menjadikannya monik.\n\nMonicLegendre4 = sympy.monic(Legendre4)\nsympy.pprint(MonicLegendre4)\n\n        2     \n 4   6⋅x    3 \nx  - ──── + ──\n      7     35\n\n\nKemudian, kita bisa menggunakan sympy.nroots untuk mendapatkan list semua akar dari polinom Legendre.\n\nAkarLegendre4 = sympy.nroots(MonicLegendre4)\nprint(AkarLegendre4)\n\n[-0.861136311594053, -0.339981043584856, 0.339981043584856, 0.861136311594053]\n\n\nMari kita buat fungsi untuk mendapatkan list akar-akar dari polinom Legendre monik ke-\\(n\\).\n\nimport sympy\nx = sympy.symbols(\"x\")\n\ndef AkarLegendre(n):\n    # P_n (x) untuk n yang diberikan\n    PolinomLegendre = sympy.legendre(n, x)\n\n    if n &gt; 1: # tadi sudah kita coba, untuk n=0 dan n=1 ternyata sudah monik\n        # selain n=0 dan n=1, kita perlu pastikan dia monik\n        PolinomLegendre = sympy.monic(PolinomLegendre)\n    \n    # memperoleh list semua akar\n    if n == 0: # ingat, banyaknya akar adalah n. Kalau n=0 berarti tiada akar\n        list_akar = []\n    else:\n        list_akar_sympy = sympy.nroots(PolinomLegendre)\n        # bisa saja list tersebut berisi bilangan yang masih berbentuk sympy,\n        # mari kita jadikan angka biasa atau angka Python dulu\n        list_akar = []\n        for angka_sympy in list_akar_sympy:\n            angka_biasa = float(angka_sympy)\n            list_akar.append(angka_biasa)\n    \n    return list_akar\n\nBisa dicoba:\n\nAkarLegendre(4)\n\n[-0.8611363115940526,\n -0.33998104358485626,\n 0.33998104358485626,\n 0.8611363115940526]\n\n\nMari kita lanjut pembahasan kita. Kuadratur Gauss adalah metode aproksimasi integral pada interval \\([-1,1]\\), dengan bentuk aproksimasi sebagai berikut:\n\\[\\int_{-1}^{1} f\\left(x\\right) dx \\approx \\sum_{i=1}^{n} c_i f\\left(x_i\\right)\\]\ndi mana \\(x_1, x_2, \\dots, x_n\\) adalah akar-akar dari polinom Legendre monik ke-\\(n\\), dan koefisien \\(c_1, c_2, \\dots, c_n\\) dihitung sebagai berikut, untuk $i = 1, 2, , n $:\n\\[c_i = \\int_{-1}^{1} \\prod_{j=1 \\\\ j \\ne i}^{n} \\frac{x - x_j}{x_i - x_j} dx\\]\nBiasanya, untuk nilai \\(n\\) yang ditentukan, nilai \\(x_i\\) dan \\(c_i\\) untuk \\(i = 1, 2, \\dots, n\\) sudah dihitung sebelumnya dan tercatat dalam bentuk tabel, sehingga kita tidak perlu lagi pusing dengan polinom Legendre ataupun cara mendapatkan koefisien-koefisien tersebut.\nMumpung kita sudah bisa memperoleh list semua akar secara pemrograman, mari kita coba memperoleh list semua koefisien \\(c_i\\) secara pemrograman juga (menggunakan list akar \\(x_i\\) tersebut). Perhatikan bahwa perkalian pecahan di atas terlihat seperti pada interpolasi Lagrange. Sehingga, kode kita akan mirip dengan kode interpolasi Lagrange. Ternyata, seperti pada interpolasi Lagrange, hasil perkalian tersebut menghasilkan polinom, sehingga integralnya pasti bisa dihitung secara analitik.\nSelain turunan analitik, sympy juga bisa menghitung integral secara analitik. Misalnya, untuk integral tak tentu, \\(\\int 3x^2 dx\\), yaitu integral \\(3x^2\\) terhadap \\(x\\):\n\nhasil_tak_tentu = sympy.integrate(3 * x**2, x)\nsympy.pprint(hasil_tak_tentu)\n\n 3\nx \n\n\nsympy juga bisa menghitung nilai integral tentu, misalnya \\(\\int_{-2}^{5} 3x^2 dx\\):\n\nhasil_tentu = sympy.integrate(3 * x**2, (x, -2, 5) )\nprint(hasil_tentu)\n\n133\n\n\nNamun, kita hanya akan memanfaatkan fitur ini untuk menentukan koefisien \\(c_i\\) saja.\n\ndef KoefisienLegendre(list_akar):\n    list_c = []\n    n = len(list_akar) # n adalah banyaknya akar\n\n    for i in range(n): # banyaknya koefisien adalah n juga\n        # kita tentukan hasil kali pecahannya dulu (dengan x dari sympy)\n        L = 1 # kode sangat mirip dengan interpolasi Lagrange, fungsi L\n        for j in range(n): # perkalian dilakukan dari j=1 sampai j=n\n            if j != i: # perhatikan syarat j != i pada perkalian\n                L *= ( x - list_akar[j] ) / ( list_akar[i] - list_akar[j] )\n        # sampai sini, hasil kali pecahan sudah selesai, tinggal diintegralkan\n        # (perhatikan bahwa L yaitu hasil kali pecahan ini berupa polinom)\n\n        # kita perlu integral L, terhadap x, dari x = -1 sampai x = 1\n        hasil_integral = sympy.integrate(L, (x, -1, 1))\n        # sebenarnya bisa dilakukan pakai metode yang telah dibahas sebelumnya,\n        # itu kalau mau full numerik :) tapi ini analitik aja, masih polinom\n\n        # ubah dari bentuk sympy jadi bentuk angka\n        hasil_integral = float(hasil_integral)\n\n        # hasil integral tersebut adalah koefisien kita. Tambahkan ke list\n        list_c.append(hasil_integral)\n    \n    # sampai sini, list koefisien sudah jadi\n    return list_c\n\nKemudian, barulah kita bisa menyusun program untuk kuadratur Gauss pada interval \\([-1,1]\\):\n\ndef KuadraturGauss_11(f, n):\n    hasil = 0\n\n    # list x_i dan c_i\n    list_x = AkarLegendre(n)\n    list_c = KoefisienLegendre(list_x)\n\n    # sumasi c_i * f(x_i)\n    for i in range(n):\n        hasil += list_c[i] * f( list_x[i] )\n    \n    return hasil\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Kuadratur Gauss pada interval [-1,1]\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nn = eval(input(\"Masukkan bilangan bulat positif (n): \"))\nprint()\n\nhasil_integral = KuadraturGauss_11(func, n)\n\nprint(f\"Hasil kuadratur Gauss pada interval [-1,1] dengan n = {n} adalah:\")\nprint(hasil_integral)\n\nKuadratur Gauss pada interval [-1,1]\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = exp(x) * cos(x)\nMasukkan bilangan bulat positif (n): 3\n\nHasil kuadratur Gauss pada interval [-1,1] dengan n = 3 adalah:\n1.9333904692642974\n\n\nBONUS: “cara cepat”\nSebenarnya, numpy sudah memiliki fitur untuk langsung memperoleh semua akar \\(x_n\\) untuk polinom Legendre monik ke-n serta semua koefisien \\(c_n\\) untuk kuadratur Gauss-Legendre, untuk apapun bilangan bulat positif \\(n\\) yang kita berikan. Misalnya, untuk \\(n=4\\):\n\nimport numpy as np\nn = 4\narray_akar, array_koefisien = np.polynomial.legendre.leggauss(n)\nprint(array_akar)\nprint(array_koefisien)\n\n[-0.86113631 -0.33998104  0.33998104  0.86113631]\n[0.34785485 0.65214515 0.65214515 0.34785485]\n\n\nBandingkan dengan tabel:\n\n\n\nTable4_12_Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org).png\n\n\nSumber tabel: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.7, “Gaussian Quadrature”. Hlm. 232\nSehingga, keseluruhan kode Python untuk kuadratur Gauss-Legendre pada interval \\([-1,1]\\) bisa kita tuliskan sesingkat ini (tanpa harus membuat fungsi untuk menentukan akar-akar polinom Legendre maupun koefisien Gauss-Legendre yang diperlukan):\n\nimport numpy as np\n\ndef KuadraturGauss_11_bonus(f, n):\n    hasil = 0\n\n    # array x_i dan c_i\n    array_x, array_c = np.polynomial.legendre.leggauss(n)\n\n    # sumasi c_i * f(x_i)\n    for i in range(n):\n        hasil += array_c[i] * f( array_x[i] )\n    \n    return hasil\n\nCara ini tidak langsung kami ajarkan ketika praktikum, agar kalian tidak lupa belajar/mempraktikkan cara memperoleh koefisien \\(c_n\\) melalui integral. Lagipula, menurut dokumentasi numpy (https://numpy.org/doc/stable/reference/generated/numpy.polynomial.legendre.leggauss.html),\n\nThe results have only been tested up to degree 100, higher degrees may be problematic.\n\nyaitu, untuk nilai \\(n &gt; 100\\), numpy belum tentu memberikan hasil yang benar. Kami berharap bahwa, cara yang lebih manual yang sudah dibuat sebelumnya, memberikan hasil yang dijamin akurat untuk apapun nilai n. (Sayangnya, cara manual jauh lebih lambat daripada cara numpy apabila digunakan nilai n yang sangat besar. Jadi, masing-masing cara ada kelebihan dan kekurangan yang bisa menjadi pertimbangan untuk Anda memilih ingin menggunakan yang mana.)\nApabila Anda penasaran lebih lanjut tentang kuadratur Gauss dan polinom Legendre, seperti cara membentuk sembarang polinom Legendre (dengan rumus rekursif), bahkan hingga cara memperoleh semua akar polinom Legendre menggunakan metode root-finding dengan beberapa tebakan awal yang sesuai, silakan belajar dari link berikut ini:\nhttps://rosettacode.org/wiki/Numerical_integration/Gauss-Legendre_Quadrature\nFun fact: himpunan semua polinom Legendre membentuk (basis untuk) suatu ruang fungsi, yaitu ruang vektor dengan vektor berupa fungsi, pada interval \\([-1,1]\\). Anggota himpunannya tak terhingga banyaknya, karena ada n=0,1,2,3, dan seterusnya. Definisi hasil kali dalam yang digunakan adalah integral perkalian dua fungsi pada interval \\([-1,1]\\). Semua polinom Legendre saling ortogonal, yaitu hasil kali dalam untuk sembarang dua polinom Legendre yang berbeda adalah nol. Sehingga, himpunan polinom Legendre adalah himpunan ortogonal. Salah satu cara membentuk polinom Legendre adalah dengan menerapkan proses Gram-Schmidt pada vektor 1, \\(x\\), \\(x^2\\), \\(x^3\\), dan seterusnya. Konsep ruang fungsi, fungsi ortogonal dan sebagainya, termasuk serba-serbi “polinom ortogonal” seperti polinom Legendre, dipelajari lebih lanjut di “analisis fungsional” (functional analysis), dan salah satu prasyaratnya pastinya adalah aljabar linier.\n\n\n9. Kuadratur Gauss untuk sembarang interval (Gaussian Quadrature on Arbitrary Intervals)\nSembarang integral \\(\\int_{a}^{b} f\\left(x\\right) dx\\) bisa diubah menjadi integral pada \\([-1,1]\\), dengan nilai integral yang tetap sama:\n\\[\\int_{a}^{b} f\\left(x\\right) dx = \\int_{-1}^{1} f\\left( \\frac{(b-a)t + (b+a)}{2} \\right) \\frac{(b-a)}{2} dt\\]\nSehingga, dengan melakukan perubahan variabel tersebut, kuadratur Gauss sebenarnya bisa diterapkan pada sembarang interval \\([a,b]\\), yaitu diubah terlebih dahulu menjadi integral pada \\([-1,1]\\).\nUntuk pemrograman, jika perlu dihitung \\(\\int_{a}^{b} f\\left(x\\right) dx\\), mari kita definisikan fungsi baru \\(g(t)\\):\n\\[g(t) = f\\left( \\frac{(b-a)t + (b+a)}{2} \\right) \\frac{(b-a)}{2}\\]\nagar\n\\[\\int_{a}^{b} f\\left(x\\right) dx = \\int_{-1}^{1} f\\left( \\frac{(b-a)t + (b+a)}{2} \\right) \\frac{(b-a)}{2} dt = \\int_{-1}^{1} g\\left(t\\right) dt\\]\nsehingga kita tinggal menghitung \\(\\int_{-1}^{1} g\\left(t\\right) dt\\) menggunakan kuadratur Gauss.\n\ndef KuadraturGaussUmum(f, a, b, n):\n    # mendefinisikan fungsi g(t)\n    def g(t):\n        hasil_g = f( ( (b-a)*t + (b+a) )/2 ) * (b-a)/2\n        return hasil_g\n    \n    # tinggal melakukan kuadratur Gauss [-1,1] untuk fungsi g, itulah hasilnya\n    hasil_integral = KuadraturGauss_11(g, n)\n    return hasil_integral\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Kuadratur Gauss untuk sembarang interval\")\nprint(\"Masukkan rumus fungsi yang akan diintegralkan:\")\nformula = input(\"f(x) = \")\ndef func(x):\n    return eval(formula)\n\nlower_bound = eval(input(\"Masukkan batas bawah (a): \"))\nupper_bound = eval(input(\"Masukkan batas atas (b): \"))\nn = eval(input(\"Masukkan bilangan bulat positif (n): \"))\nprint()\n\nhasil_integral = KuadraturGaussUmum(func, lower_bound, upper_bound, n)\n\nprint(f\"Hasil kuadratur Gauss pada interval [{lower_bound},{upper_bound}] dengan n = {n} adalah:\")\nprint(hasil_integral)\n\nKuadratur Gauss untuk sembarang interval\nMasukkan rumus fungsi yang akan diintegralkan:\nf(x) = x**6 - x**2 * sin(2*x)\nMasukkan batas bawah (a): 1\nMasukkan batas atas (b): 3\nMasukkan bilangan bulat positif (n): 2\n\nHasil kuadratur Gauss pada interval [1,3] dengan n = 2 adalah:\n306.8199344959197"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul3.html",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul3.html",
    "title": "Review matplotlib",
    "section": "",
    "text": "Praktikum Metode Numerik 2023 Semester Genap\nModul Pertemuan 3: Interpolasi\nKembali ke Metode Numerik\nOUTLINE"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul3.html#penjelasan-ide-dengan-contoh-indeks-mulai-dari-1",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul3.html#penjelasan-ide-dengan-contoh-indeks-mulai-dari-1",
    "title": "Review matplotlib",
    "section": "Penjelasan ide dengan contoh (indeks mulai dari 1)",
    "text": "Penjelasan ide dengan contoh (indeks mulai dari 1)\nMisal diketahui empat titik yaitu \\((x_1, y_1)\\), \\((x_2, y_2)\\), \\((x_3, y_3)\\), dan \\((x_4, y_4)\\). Ide polinom interpolasi Lagrange adalah membuat fungsi \\(P(x)\\) sebagai berikut (yang diduga akan berupa polinom):\n\\[P(x) = y_1 L_{4,1} (x) + y_2 L_{4,2} (x) + y_3 L_{4,3} (x) + y_4 L_{4,4} (x)\\]\nLalu apa itu fungsi \\(L_{n,k} (x)\\)? Pada subscript (tulisan di sebelah bawah), bilangan pertama adalah \\(n\\) atau banyaknya titik, sedangkan bilangan kedua adalah \\(k\\) atau titik ke-\\(k\\). Fungsi \\(L_{n,k} (x)\\) ini memang bergantung \\(k\\), artinya tiap titik dipasangkan dengan suatu fungsi \\(L_{n,k} (x)\\) yang sesuai.\nFungsi \\(L_{4,k} (x)\\) tersebut diharapkan memiliki sifat sebagai berikut:\n\\[P(x_1) = \\color{blue}{y_1 * 1} + \\color{red}{y_2 * 0} + \\color{red}{y_3 * 0} + \\color{red}{y_4 * 0} = \\color{blue}{y_1}\\]\n\\[P(x_2) = \\color{red}{y_1 * 0} + \\color{blue}{y_2 * 1} + \\color{red}{y_3 * 0} + \\color{red}{y_4 * 0} = \\color{blue}{y_2}\\]\n\\[P(x_3) = \\color{red}{y_1 * 0} + \\color{red}{y_2 * 0} + \\color{blue}{y_3 * 1} + \\color{red}{y_4 * 0} = \\color{blue}{y_3}\\]\n\\[P(x_4) = \\color{red}{y_1 * 0} + \\color{red}{y_2 * 0} + \\color{red}{y_3 * 0} + \\color{blue}{y_4 * 1} = \\color{blue}{y_4}\\]\nArtinya, \\(L_{n,k} (x_k) = 1\\), sedangkan \\(L_{n,k} (x_i) = 0\\) untuk nilai \\(i\\) selain \\(k\\) (lebih tepatnya, bernilai nol ketika ada titik ke-\\(i\\) yaitu titik selain titik ke-\\(k\\)). Sebenarnya, kita tidak peduli apa nilai \\(L_{n,k} (x)\\) untuk apapun nilai \\(x\\) selain titik yang diketahui.\nMengingat sifat yang diharapkan, kita bisa merancang fungsi \\(L_{4,k} (x)\\) sebagai berikut untuk \\(k = 1, 2, 3, 4\\):\n\\[L_{4,1} (x) = \\frac{(x-x_2)(x-x_3)(x-x_4)}{(x_1-x_2)(x_1-x_3)(x_1-x_4)}\\]\n\\[L_{4,2} (x) = \\frac{(x-x_1)(x-x_3)(x-x_4)}{(x_2-x_1)(x_2-x_3)(x_2-x_4)}\\]\n\\[L_{4,3} (x) = \\frac{(x-x_1)(x-x_2)(x-x_4)}{(x_3-x_1)(x_3-x_2)(x_3-x_4)}\\]\n\\[L_{4,4} (x) = \\frac{(x-x_1)(x-x_2)(x-x_3)}{(x_4-x_1)(x_4-x_2)(x_4-x_3)}\\]\nPerhatikan: * bagian pembilang terdiri dari perkalian \\((x-x_i)\\) untuk semua \\(i\\) kecuali \\(i=k\\). Tujuannya, ketika \\(L_{4,k} (x)\\) itu disubstitusikan \\(x=x_i\\) untuk \\(i\\) selain \\(k\\), hasilnya menjadi \\(L_{4,k} (x_i) = 0\\), kecuali untuk \\(x=x_k\\) itu hasilnya tidak nol. * bagian penyebut/pembagi itu sebenarnya sama saja dengan pembilang, tapi disubstitusikan \\(x=x_k\\). Tujuannya, ketika \\(L_{4,k} (x)\\) disubstitusikan dengan \\(x=x_k\\), apapun hasil taknol dari pembilang itu dibagi dengan dirinya sendiri agar menjadi \\(L_{4,k} (x_k) = 1\\).\nDengan demikian, \\(P(x)\\) bisa terbentuk. Perhatikan bahwa \\(L_{n,k} (x)\\) berbentuk polinom, sehingga \\(P(x)\\) yang terbentuk juga akan berupa polinom. Sehingga, metode polinom interpolasi Lagrange berhasil menghasilkan polinom interpolasi. Ide ini berlaku umum untuk banyaknya titik \\(n\\) sebesar apapun.\nPerhatikan bahwa masing-masing fungsi \\(L_{4,k} (x)\\) bisa dituliskan sebagai berikut:\n\\[L_{4,1} (x) = \\frac{(x-x_2)}{(x_1-x_2)} * \\frac{(x-x_3)}{(x_1-x_3)} * \\frac{(x-x_4)}{(x_1-x_4)}\\]\n\\[L_{4,2} (x) = \\frac{(x-x_1)}{(x_2-x_1)} * \\frac{(x-x_3)}{(x_2-x_3)} * \\frac{(x-x_4)}{(x_2-x_4)}\\]\n\\[L_{4,3} (x) = \\frac{(x-x_1)}{(x_3-x_1)} * \\frac{(x-x_2)}{(x_3-x_2)} * \\frac{(x-x_4)}{(x_3-x_4)}\\]\n\\[L_{4,4} (x) = \\frac{(x-x_1)}{(x_4-x_1)} * \\frac{(x-x_2)}{(x_4-x_2)} * \\frac{(x-x_3)}{(x_4-x_3)}\\]\natau, di mana warna merah artinya tidak dituliskan,\n\\[\\text{Untuk } k=1, \\text{ } L_{4,1} (x) = \\color{red}{\\frac{(x-x_1)}{(x_1-x_1)} * } \\color{black}{\\frac{(x-x_2)}{(x_1-x_2)} * \\frac{(x-x_3)}{(x_1-x_3)} * \\frac{(x-x_4)}{(x_1-x_4)}}\\]\n\\[\\text{Untuk } k=2, \\text{ } L_{4,2} (x) = \\frac{(x-x_1)}{(x_2-x_1)} \\color{red}{* \\frac{(x-x_2)}{(x_2-x_2)}} \\color{black}{* \\frac{(x-x_3)}{(x_2-x_3)} * \\frac{(x-x_4)}{(x_2-x_4)}}\\]\n\\[\\text{Untuk } k=3, \\text{ } L_{4,3} (x) = \\frac{(x-x_1)}{(x_3-x_1)} * \\frac{(x-x_2)}{(x_3-x_2)} \\color{red}{* \\frac{(x-x_3)}{(x_3-x_3)}} \\color{black}{* \\frac{(x-x_4)}{(x_3-x_4)}}\\]\n\\[\\text{Untuk } k=4, \\text{ } L_{4,4} (x) = \\frac{(x-x_1)}{(x_4-x_1)} * \\frac{(x-x_2)}{(x_4-x_2)} * \\frac{(x-x_3)}{(x_4-x_3)} \\color{red}{* \\frac{(x-x_4)}{(x_4-x_4)}}\\]\nDengan demikian, pembentukan fungsi \\(L_{n,k} (x)\\) secara pemrograman bisa dilakukan dengan perkalian iteratif, seperti iterasi \\(i = 1, 2, 3, 4\\), tetapi dengan syarat \\(i \\ne k\\)."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul3.html#bentuk-umum-indeks-mulai-dari-0-dan-kode",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul3.html#bentuk-umum-indeks-mulai-dari-0-dan-kode",
    "title": "Review matplotlib",
    "section": "Bentuk umum (indeks mulai dari 0) dan kode",
    "text": "Bentuk umum (indeks mulai dari 0) dan kode\nBila diberikan \\(n+1\\) titik \\(x_0, x_1, \\dots, x_n\\), dan \\(f\\) adalah fungsi yang nilainya pada titik-titik tersebut diberikan, maka polinom interpolasi Lagrange ke-n didefinisikan sebagai\n\\[P(x) = f(x_0) L_{n,0}(x_0) + f(x_1) L_{n,1}(x_1) + \\cdots f(x_n) L_{n,n}(x_n)\\]\ndi mana, untuk setiap \\(k = 0, 1, \\dots, n\\),\n\\[L_{n,k}(x) = \\prod_{\\substack{i=0 \\\\ i\\ne k}}^{n} \\frac{x - x_i}{x_k - x_i}\\]\ndi mana \\(\\Pi\\) atau pi besar melambangkan perkalian yang “berulang” atau “teriterasi”, layaknya \\(\\Sigma\\) (sigma besar) yang melambangkan penjumlahan yang “berulang” atau “teriterasi”. Perhatikan syarat \\(i\\ne k\\).\n\nimport sympy\nx = sympy.symbols('x')\n\n# jaga-jaga ada konstanta pi pada data titik-titik yang diberikan\nfrom numpy import pi\n\ntitik_x = eval(input(\"Masukkan list nilai x : \"))\ntitik_y = eval(input(\"Masukkan list nilai fungsi di titik-titik tersebut : \"))\neval_x = eval(input(\"Masukkan nilai x yang akan diaproksimasi nilai fungsinya : \"))\n\ndef LagrangePol(x, x_points, y_points):\n    pol = 0 # nilai awal polinom sebelum ditambahkan apa-apa\n    n = len(x_points) # n adalah banyak titik\n    for k in range(n): # membuat y*L_(n,k) untuk tiap k\n        L = 1 # nilai awal fungsi L\n        for i in range(n):\n            if i!=k: # syarat i != k\n                L *= ((x-x_points[i])/(x_points[k]-x_points[i])) # iterasi perkalian\n        pol += y_points[k]*L # menambahkan pasangan y*L ke polinom\n    return pol\n\ny_lagrange = LagrangePol(x, titik_x, titik_y)\n# bentuk masih berantakan, sehingga perlu disederhanakan:\ny_sederhana = sympy.simplify(y_lagrange)\n# perlu diubah menjadi function biasa agar bisa disubstitusikan nilai x:\ny_function = sympy.lambdify(x, y_sederhana)\n# akhirnya bisa substitusi:\nnilai_y = y_function(eval_x)\n\nprint(\"Polinom hasil interpolasi Lagrange:\")\nsympy.pprint(y_lagrange)\nprint(\"Disederhanakan:\")\nsympy.pprint(y_sederhana)\nprint(\"Aproksimasi nilai fungsi di x = {0} adalah y = {1:.5f}\".format(eval_x, nilai_y))\n\nMasukkan list nilai x : [1, 2, 3, 4]\nMasukkan list nilai fungsi di titik-titik tersebut : [1, 4, 9, 16]\nMasukkan nilai x yang akan diaproksimasi nilai fungsinya : 1.5\nPolinom hasil interpolasi Lagrange:\n⎛4   x⎞ ⎛3   x⎞             ⎛    x⎞                             ⎛x   1⎞       \n⎜─ - ─⎟⋅⎜─ - ─⎟⋅(2 - x) + 4⋅⎜2 - ─⎟⋅(3 - x)⋅(x - 1) + 9⋅(4 - x)⋅⎜─ - ─⎟⋅(x - 2\n⎝3   3⎠ ⎝2   2⎠             ⎝    2⎠                             ⎝2   2⎠       \n\n       ⎛x   1⎞ ⎛x    ⎞        \n) + 16⋅⎜─ - ─⎟⋅⎜─ - 1⎟⋅(x - 3)\n       ⎝3   3⎠ ⎝2    ⎠        \nDisederhanakan:\n 2\nx \nAproksimasi nilai fungsi di x = 1.5 adalah y = 2.25000"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul3.html#kode-versi-sederhana",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul3.html#kode-versi-sederhana",
    "title": "Review matplotlib",
    "section": "Kode Versi Sederhana",
    "text": "Kode Versi Sederhana\nNDD memiliki bentuk sebagai berikut :\n\\[P_n (x) = f[x_0] + \\sum_{k=1}^{n} f[x_0, x_1, \\dots, x_k](x-x_0)(x-x_1)\\dots (x-x_k)\\]\ndi mana \\(f[x_k] = f(x_k)\\) dan\n\\[f[x_i, x_{i+1}, \\dots, x_{i+k}] = \\frac{f[x_{i+1}, x_{i+2}, \\dots, x_{i+k}]-f[x_i, x_{i+1}, \\dots, x_{i+k-1}]}{x_{i+k} - x_i}\\]\nPada rumusan di atas, \\(f[x_i x_{i+1}, \\dots, x_{i+k}]\\) disebut k-th divided difference relatif terhadap \\(x_i x_{i+1}, \\dots, x_{i+k}\\).\nDalam membentuk polinomial interpolasi dengan NDD, seringkali tabel divided difference dibuat untuk memudahkan. Tabel tersebut berbentuk seperti berikut.\n\n\n\ncrop table3_9 page 126 Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org) copy.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Bab 3, “Interpolation and Polynomial Approximation”. Subbab 3.3, “Divided Differences”. Hlm. 126\nAda dua cara pembentukan polinomial interpolasi dengan DD, yaitu cara Forward dan Backward.\n\nForward DD menggunakan baris paling atas dari setiap kolom pada tabel DD.\n\n\\[P_n (x) = f[x_0] + \\sum_{k=1}^{n} f[x_0, x_1, \\dots, x_k] (x-x_0) (x-x_1) \\dots (x-x_{k-1})\\]\n\nBackward DD menggunakan baris paling akhir dari setiap kolom pada tabel DD.\n\n\\[P_n (x) = f[x_n] + \\sum_{k=1}^{n} f[x_n, x_{n-1}, \\dots, x_{n-k}] (x-x_n) (x-x_{n-1}) \\dots (x - x_{n-k+1})\\]\nKode Python untuk menginterpolasi titik-titik data dengan menggunakan NDD adalah sebagai berikut.\n\nimport sympy\nx = sympy.symbols('x')\n\n# jaga-jaga ada konstanta pi pada data titik-titik yang diberikan\nfrom numpy import pi\n\ntitik_x = eval(input('Masukkan list nilai x : '))\ntitik_y = eval(input('Masukkan list nilai fungsi di titik-titik tersebut : '))\neval_x = eval(input('Masukkan nilai x yang akan diaproksimasi nilai fungsinya : '))\n\ndef DDTableGenerator(x_points, y_points): #buat fungsi untuk membuat tabel DD\n    DDTable = [y_points] #kolom-kolom pada tabel. Kolom pertama berisi f\n    for column in range(1,len(y_points)):\n        DDcolumn = [] #isi dari setiap kolom\n        for row in range(len(DDTable[-1])-1): #mulai mengisi kolom tabel\n            DD = (DDTable[-1][row+1]-DDTable[-1][row])/(x_points[column+row]-x_points[row])\n            DDcolumn.append(DD)\n        DDTable.append(DDcolumn) #tambahkan kolom yang telah diisi ke tabel\n    return DDTable\n\ndef ForwardDD(x, x_points, y_points):\n    DDTable = DDTableGenerator(x_points,y_points)\n    pol = DDTable[0][0] #nilai dari polinom. Inisiasi : suku pertama po\n    mult_term = 1 #variabel untuk menyimpan nilai dari (x-x0)(x-x\n    for k in range(1,len(DDTable)):\n        mult_term*=(x-x_points[k-1]) #menghitung (x-x0)(x-x1)...(x-x(n-1))\n        pol+=DDTable[k][0]*mult_term #menghitung nilai interpolasi\n    return pol\n\ndef BackwardDD(x, x_points, y_points):\n    DDTable = DDTableGenerator(x_points,y_points)\n    pol = DDTable[0][-1] #nilai dari polinom. Inisiasi : suku pertama po\n    mult_term = 1 #variabel untuk menyimpan nilai dari (x-xn)(x-x\n    for k in range(1,len(DDTable)):\n        mult_term*=(x-x_points[-k]) #menghitung (x-xn)(x-x(n-1))...(x-x1)\n        pol+=DDTable[k][-1]*mult_term #menghitung nilai interpolasi\n    return pol\n\nforw_pol = ForwardDD(x, titik_x,titik_y)\nback_pol = BackwardDD(x, titik_x,titik_y)\n\nforw_sederhana = sympy.simplify(forw_pol)\nback_sederhana = sympy.simplify(back_pol)\n\nforw_function = sympy.lambdify(x, forw_sederhana)\nback_function = sympy.lambdify(x, back_sederhana)\n\nnilai_forw = forw_function(eval_x)\nnilai_back = back_function(eval_x)\n\nprint(\"Polinom hasil foward DD:\")\nsympy.pprint(forw_pol)\nprint(\"disederhanakan:\")\nsympy.pprint(forw_sederhana)\nprint(\"Polinom hasil backward DD:\")\nsympy.pprint(back_pol)\nprint(\"disederhanakan:\")\nsympy.pprint(back_sederhana)\n\nprint(\"Aproksimasi nilai fungsi di x = {0} adalah : \".format(eval_x))\nprint(\"Forward DD : {0:.5f}\".format(nilai_forw))\nprint(\"Backward DD : {0:.5f}\".format(nilai_back))\n\nMasukkan list nilai x : [1, 2, 3, 4]\nMasukkan list nilai fungsi di titik-titik tersebut : [1, 4, 9, 16]\nMasukkan nilai x yang akan diaproksimasi nilai fungsinya : 1.5\nPolinom hasil foward DD:\n3.0⋅x + 1.0⋅(x - 2)⋅(x - 1) - 2.0\ndisederhanakan:\n     2\n1.0⋅x \nPolinom hasil backward DD:\n7.0⋅x + 1.0⋅(x - 4)⋅(x - 3) - 12.0\ndisederhanakan:\n     2\n1.0⋅x \nAproksimasi nilai fungsi di x = 1.5 adalah : \nForward DD : 2.25000\nBackward DD : 2.25000"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul3.html#kode-versi-tabel-bagus",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul3.html#kode-versi-tabel-bagus",
    "title": "Review matplotlib",
    "section": "Kode Versi Tabel Bagus",
    "text": "Kode Versi Tabel Bagus\nKode versi sebelumnya lebih sederhana, namun sayangnya tidak bisa menampilkan tabel divided difference. Kode yang akan dijelaskan di bagian ini, walaupun lebih rumit, tetapi pada akhirnya lebih intuitif, karena nantinya proses pembuatan polinom Forward DD dan Backward DD akan langsung menggunakan data dari tabel yang sudah dibentuk. (Lagipula, enak kan kalo bisa liat tabelnya? Hehe)\nKita review kembali, metode interpolasi Newton Divided Difference (NDD) melibatkan pembuatan tabel besar seperti berikut:\n\n\n\ncrop table3_9 page 126 Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org) copy.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Bab 3, “Interpolation and Polynomial Approximation”. Subbab 3.3, “Divided Differences”. Hlm. 126\nData pada dua kolom pertama adalah data titik \\((x, y)\\) yang diketahui, sedangkan perhitungan data pada tiap kolom lainnya (first divided differences, second divided differences, dll.) itu bergantung pada kolom sebelumnya.\nPembuatan tabel Newton Divided Differences (NDD) melibatkan suatu fungsi \\(f\\) dengan kurung siku, dengan rumus sesuai tabel di atas. Istilah “divided differences” artinya “beda/selisih yang saling dibagi”, sesuai rumus \\(f\\) tersebut.\nKetika hanya terdiri dari satu input, \\(f[x_k] = f(x_k) = y_k\\), untuk suatu data titik \\((x_k, y_k)\\) yang diketahui.\nSecara umum, rumusnya adalah\n\\[f[x_i, x_{i+1}, \\dots, x_{i+k}] = \\frac{f[x_{i+1}, x_{i+2}, \\dots, x_{i+k}]-f[x_i, x_{i+1}, \\dots, x_{i+k-1}]}{x_{i+k} - x_i}\\]\nUntuk titik yang banyak, penulisan nama fungsi \\(f[\\dots]\\) bisa menjadi sangat panjang. Perhatikan bahwa isi inputnya selalu berurutan, misal dari \\(x_a\\) sampai \\(x_b\\). Kita bisa mendefinisikan suatu fungsi untuk mempersingkat penulisan tersebut, misal kita namakan F-rentang atau kita singkat FR:\n\\[\\text{FR}(a, b) = f[x_a, x_{a+1}, x_{a+2}, \\dots, x_{b-2}, x_{b-1}, x_b]\\]\nyaitu fungsi yang sebenarnya menerima input berupa rentang nilai \\(x_k\\) dari \\(x_a\\) (\\(k=a\\)) sampai \\(x_b\\) (\\(k=b\\)).\nMaka, rumus \\(f\\) di atas dapat disingkat menjadi\n\\[\\text{FR}(a, a+k) = \\frac{\\text{FR}(a+1, a+k) - \\text{FR}(a, a+k-1)}{x_{a+k}-x_a}\\]\nDengan memasang \\(b = a+k\\), diperoleh\n\\[\\text{FR}(a, b) = \\frac{\\text{FR}(a+1, b) - \\text{FR}(a, b-1)}{x_b-x_a}\\]\nMenariknya, pada tabel,\n\nnilai \\(\\text{FR}(a, b-1)\\) selalu terletak di sebelah kiri atas dari \\(\\text{FR}(a, b)\\)\nnilai \\(\\text{FR}(a+1, b)\\) selalu terletak di sebelah kiri bawah dari \\(\\text{FR}(a, b)\\)\n\nDengan demikian, bisa saja kita memrogram perhitungan NDD menggunakan tabel.\nSeolah-olah, rumusnya adalah “kiri bawah dikurang kiri atas, dibagi \\(x_b - x_a\\)”.\nSelain itu, untuk data sebanyak \\(n+1\\),\n\nada sebanyak \\(n\\) kolom divided difference.\ndengan banyak kotak kosong (seperti pada gambar di atas), tabel utama terdiri dari \\(2n+1\\) baris dan \\(n+1\\) kolom, termasuk kolom \\(f(x_i)\\) tetapi tidak termasuk kolom \\(x_i\\).\n\nDengan demikian, kita dapat menghitung banyaknya data (yang kita anggap sebanyak \\(n+1\\)), kemudian menghitung \\(n\\) (tinggal dikurang 1), lalu mulai membangun tabel berdasarkan sifat baris dan kolom tersebut.\nIstilah “tabel utama” yang kita gunakan di sini merujuk pada tabel divided difference dari kolom \\(f(x_k)\\) sampai kolom divided difference ke-n, tanpa adanya kolom \\(x_i\\) maupun \\(i\\). Untuk ke depannya, tabel divided difference yang lengkap (yang termasuk kolom \\(x_i\\) dan \\(i\\)) akan kita sebut “tabel besar”, dibedakan dengan tabel utama.\n\nfrom tabulate import tabulate\n\n# jaga-jaga ada konstanta pi pada data titik-titik yang diberikan\nfrom numpy import pi\n\n# menyusun tabel Newton Divided Differences (NDD)\ndef CreateDDTable(list_x, list_y):\n    # === Menyusun tabel utama === #\n    # mengandung kolom f(x_i) serta semua kolom divided difference\n\n    MainDDTable = []\n    banyak_data = len(list_x) # = n + 1\n    n = banyak_data - 1\n    \n    # mengisi tabel dengan string kosong\n    # ingat: 2n+1 baris, n+1 kolom\n    for i in range(2*n+1):\n        calon_baris = []\n        for j in range(n+1):\n            calon_baris.append(\"\")\n        MainDDTable.append(calon_baris)\n    \n    # mengisi kolom pertama dengan nilai y_i = f(x_i)\n    for i in range(0, 2*n+1, 2): # untuk tiap baris, lompat 2\n        MainDDTable[i][0] = list_y[int(i/2)]\n    \n    # iterasi mengisi tiap kolom divided difference\n    for j in range(1, n+1): # untuk tiap kolom divided difference\n        # nilai a dan b untuk DD yang paling atas pada kolom\n        a = 0\n        b = j # nilai b pertama adalah j, selalu sesuai kolom DD ke-j\n        for i in range(j, 2*n - j + 1, 2): # untuk tiap baris, lompat 2\n            # iterasi dimulai dari baris j,\n            # baris terakhir adalah baris dengan indeks 2*n - j.\n            # Alasannya: total baris sebanyak 2*n + 1 (indeks 2*n),\n            # dan secara umum, pada kolom DD ke-j, perhitungan DD terakhir\n            # adalah pada j baris sebelum baris terakhir pada tabel,\n            # sehingga baris terakhir tersebut ada pada indeks 2*n - j.\n            # Pada for loop, kita gunakan 2*n - j + 1\n            # agar baris terakhir menjadi 2*n - j (karena keanehan Python)\n\n            # kiri bawah dikurang kiri atas, dibagi (x_b - x_a)\n            MainDDTable[i][j] = (MainDDTable[i+1][j-1] - MainDDTable[i-1][j-1])/(list_x[b] - list_x[a])\n            # memperbarui nilai a dan b untuk iterasi selanjutnya\n            a += 1\n            b += 1\n    \n    # === Menyusun tabel besar === #\n\n    # duplikasi MainDDTable\n    BigDDTable = []\n    for row in MainDDTable:\n        calon_baris = []\n        for col in row:\n            calon_baris.append(col)\n        BigDDTable.append(calon_baris)\n\n    # tempel kolom nilai i dan x_i di sebelah kiri tabel\n    for i in range(2*n+1):\n        indeks_x = int(i/2)\n        if i % 2 == 0: # baris berindeks genap, seperti baris pertama (i=0)\n            BigDDTable[i].insert(0, list_x[indeks_x])\n            BigDDTable[i].insert(0, indeks_x)\n        else:\n            BigDDTable[i].insert(0, \"\")\n            BigDDTable[i].insert(0, \"\")\n    \n    # menyusun list semua header\n    semua_header = [\"i\", \"x_i\", \"f(x_i)\"]\n    for k in range(1, n+1):\n        semua_header.append(\"DD ke-\" + str(k))\n\n    olahan_BigDDTable = tabulate(BigDDTable, headers=semua_header,\n                                 tablefmt=\"orgtbl\")\n    \n    return MainDDTable, olahan_BigDDTable\n\n\ntitik_x = eval(input('Masukkan list nilai x : '))\ntitik_y = eval(input('Masukkan list nilai fungsi di titik-titik tersebut : '))\n\ntabel_utama, tabel_olahan = CreateDDTable(titik_x, titik_y)\n\nprint(\"Tabel Newton Divided Difference:\")\nprint(tabel_olahan)\n\nMasukkan list nilai x : [1.0, 1.3, 1.6, 1.9, 2.2]\nMasukkan list nilai fungsi di titik-titik tersebut : [0.7651977, 0.6200860, 0.4554022, 0.2818186, 0.1103623]\nTabel Newton Divided Difference:\n| i   | x_i   | f(x_i)    | DD ke-1             | DD ke-2              | DD ke-3             | DD ke-4               |\n|-----+-------+-----------+---------------------+----------------------+---------------------+-----------------------|\n| 0   | 1.0   | 0.7651977 |                     |                      |                     |                       |\n|     |       |           | -0.4837056666666664 |                      |                     |                       |\n| 1   | 1.3   | 0.620086  |                     | -0.10873388888888935 |                     |                       |\n|     |       |           | -0.548946           |                      | 0.06587839506172834 |                       |\n| 2   | 1.6   | 0.4554022 |                     | -0.04944333333333385 |                     | 0.0018251028806604353 |\n|     |       |           | -0.5786120000000003 |                      | 0.06806851851852086 |                       |\n| 3   | 1.9   | 0.2818186 |                     | 0.011818333333334928 |                     |                       |\n|     |       |           | -0.5715209999999994 |                      |                     |                       |\n| 4   | 2.2   | 0.1103623 |                     |                      |                     |                       |\n\n\nNantinya, dari tabel NDD yang sudah lengkap, ada dua jenis polinom interpolasi NDD yang dapat diperoleh, yaitu Newton Forward-Difference dan Newton Backward-Difference, tergantung nilai mana pada tabel yang digunakan. Misalkan ada data sebanyak \\(n+1\\) titik, yaitu \\(x_0, x_1, x_2, \\dots, x_{n-1}, x_n\\). Maka, akan ada sebanyak \\(n\\) kolom divided differences pada tabel.\n\nNewton Forward-Difference (juga disebut Forward DD) menggunakan baris paling atas dari setiap kolom pada tabel DD.\n\n\\[P_n (x) = f[x_0] + \\sum_{k=1}^{n} f[x_0, x_1, \\dots, x_k] \\left( \\prod_{j=0}^{k-1} (x-x_j) \\right)\\]\n\nNewton Backward-Difference (juga disebut Backward DD) menggunakan baris paling akhir dari setiap kolom pada tabel DD.\n\n\\[P_n (x) = f[x_n] + \\sum_{k=1}^{n} f[x_{n-k}, \\dots, x_{n-1}, x_n] \\left( \\prod_{j=n-k+1}^{n} (x-x_j) \\right)\\]\nCatatan: \\(f[x_n, x_{n-1}, \\dots, x_{n-k}] = f[x_{n-k}, \\dots, x_{n-1}, x_n]\\). Artinya, penulisan terbalik (seperti di beberapa sumber referensi Metode Numerik) sebenarnya tidak mempengaruhi perhitungan.\nMenyingkat penulisan dengan \\(\\text{FR}(a, b)\\), kita peroleh:\n\nForward DD\n\n\\[P_n (x) = f[x_0] + \\sum_{k=1}^{n} \\text{FR}(0, k) \\left( \\prod_{j=0}^{k-1} (x-x_j) \\right)\\]\natau, mengingat bahwa \\(\\text{FR}(0, 0) = f[x_0]\\), kemudian menjabarkan,\n[ \\[\\begin{align*}\nP_n (x) = \\text{FR}(0, 0) &+ \\text{FR}(0, 1) (x-x_0) \\\\\n&+ \\text{FR}(0, 2) (x-x_0)(x-x_1) \\\\\n&+ \\dots \\\\\n&+ \\text{FR}(0, n)\\prod_{j=0}^{n-1} (x-x_j)\n\\end{align*}\\] ]\n\nBackward DD\n\n\\[P_n (x) = f[x_n] + \\sum_{k=1}^{n} \\text{FR}(n-k, n) \\left( \\prod_{j=n-k+1}^{n} (x-x_j) \\right)\\]\natau, mengingat bahwa \\(\\text{FR}(n, n) = f[x_n]\\), kemudian menjabarkan,\n[ \\[\\begin{align*}\nP_n (x) = \\text{FR}(n, n) &+ \\text{FR}(n-1, n) (x-x_n) \\\\\n&+ \\text{FR}(n-2, n) (x-x_{n-1}) (x-x_n) \\\\\n&+ \\dots \\\\\n&+ \\text{FR}(0, n) \\prod_{j=1}^{n} (x-x_j)\n\\end{align*}\\] ]\n\n# jaga-jaga ada konstanta pi pada data titik-titik yang diberikan\nfrom numpy import pi\n\nfrom tabulate import tabulate\n\nimport sympy\nx = sympy.symbols('x')\n\ntitik_x = eval(input('Masukkan list nilai x : '))\ntitik_y = eval(input('Masukkan list nilai fungsi di titik-titik tersebut : '))\neval_x = eval(input('Masukkan nilai x yang akan diaproksimasi nilai fungsinya : '))\n\n# Kita asumsikan function/fungsi CreateDDTable sudah terdefinisi sebelumnya.\n# Kalau belum terdefinisi, boleh copy-paste definisi fungsinya ke sini\n\ntabel_utama, tabel_olahan = CreateDDTable(titik_x, titik_y)\n\nprint(\"Tabel Newton Divided Difference:\")\nprint(tabel_olahan)\nprint() # jaga jarak dengan print yang selanjutnya\n\ndef ForwardDD(tabel_utama, list_x):\n    banyak_data = len(tabel_utama[0])\n    pol = 0\n    for k in range(0, banyak_data): # tiap suku penjumlahan\n        suku = tabel_utama[k][k] # FR(0, k)\n        for j in range(0, k): # perkalian dari j=0 sampai j=k-1\n            suku *= (x - list_x[j])\n        pol += suku\n    return pol\n\ndef BackwardDD(tabel_utama, list_x):\n    banyak_data = len(tabel_utama[0])\n    n = banyak_data - 1\n    pol = 0\n    for k in range(banyak_data): # tiap suku penjumlahan\n        suku = tabel_utama[2*n-k][k] # FR(n-k, k)\n        for j in range(n-k+1, n+1): # perkalian dari j=n-k+1 sampai j=n\n            suku *= (x - list_x[j])\n        pol += suku\n    return pol\n\nforw_pol = ForwardDD(tabel_utama, titik_x)\nback_pol = BackwardDD(tabel_utama, titik_x)\n\nforw_sederhana = sympy.simplify(forw_pol)\nback_sederhana = sympy.simplify(back_pol)\n\nforw_function = sympy.lambdify(x, forw_sederhana)\nback_function = sympy.lambdify(x, back_sederhana)\n\nnilai_forw = forw_function(eval_x)\nnilai_back = back_function(eval_x)\n\nprint(\"Polinom hasil foward DD:\")\nsympy.pprint(forw_pol)\nprint()\nprint(\"disederhanakan:\")\nsympy.pprint(forw_sederhana)\nprint()\n\nprint(\"Polinom hasil backward DD:\")\nsympy.pprint(back_pol)\nprint()\nprint(\"disederhanakan:\")\nsympy.pprint(back_sederhana)\nprint()\n\nprint(\"Aproksimasi nilai fungsi di x = {0} adalah : \".format(eval_x))\nprint(\"Forward DD : {0}\".format(nilai_forw))\nprint(\"Backward DD : {0}\".format(nilai_back))\n\nMasukkan list nilai x : [1.0, 1.3, 1.6, 1.9, 2.2]\nMasukkan list nilai fungsi di titik-titik tersebut : [0.7651977, 0.6200860, 0.4554022, 0.2818186, 0.1103623]\nMasukkan nilai x yang akan diaproksimasi nilai fungsinya : 1.5\nTabel Newton Divided Difference:\n| i   | x_i   | f(x_i)    | DD ke-1             | DD ke-2              | DD ke-3             | DD ke-4               |\n|-----+-------+-----------+---------------------+----------------------+---------------------+-----------------------|\n| 0   | 1.0   | 0.7651977 |                     |                      |                     |                       |\n|     |       |           | -0.4837056666666664 |                      |                     |                       |\n| 1   | 1.3   | 0.620086  |                     | -0.10873388888888935 |                     |                       |\n|     |       |           | -0.548946           |                      | 0.06587839506172834 |                       |\n| 2   | 1.6   | 0.4554022 |                     | -0.04944333333333385 |                     | 0.0018251028806604353 |\n|     |       |           | -0.5786120000000003 |                      | 0.06806851851852086 |                       |\n| 3   | 1.9   | 0.2818186 |                     | 0.011818333333334928 |                     |                       |\n|     |       |           | -0.5715209999999994 |                      |                     |                       |\n| 4   | 2.2   | 0.1103623 |                     |                      |                     |                       |\n\nPolinom hasil foward DD:\n-0.483705666666666⋅x + (0.108733888888889 - 0.108733888888889⋅x)⋅(x - 1.3) + (\n0.00182510288066044⋅x - 0.00182510288066044)⋅(x - 1.9)⋅(x - 1.6)⋅(x - 1.3) + (\n0.0658783950617283⋅x - 0.0658783950617283)⋅(x - 1.6)⋅(x - 1.3) + 1.24890336666\n667\n\ndisederhanakan:\n                     4                       3                      2         \n0.00182510288066044⋅x  + 0.0552927983538978⋅x  - 0.343046604938247⋅x  + 0.0733\n\n                                  \n913477366034⋅x + 0.977735055967085\n\nPolinom hasil backward DD:\n-0.571520999999999⋅x + (0.00182510288066044⋅x - 0.00237263374485857)⋅(x - 2.2)\n⋅(x - 1.9)⋅(x - 1.6) + (0.0118183333333349⋅x - 0.0224548333333364)⋅(x - 2.2) +\n (0.0680685185185209⋅x - 0.108909629629633)⋅(x - 2.2)⋅(x - 1.9) + 1.3677085\n\ndisederhanakan:\n                     4                       3                      2         \n0.00182510288066044⋅x  + 0.0552927983538978⋅x  - 0.343046604938247⋅x  + 0.0733\n\n                                  \n913477366035⋅x + 0.977735055967086\n\nAproksimasi nilai fungsi di x = 1.5 adalah : \nForward DD : 0.5118199942386829\nBackward DD : 0.511819994238684"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul1.html",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul1.html",
    "title": "Outline",
    "section": "",
    "text": "Kembali ke Metode Numerik\nSelamat datang di praktikum Metode Numerik!\nPada praktikum ini, kalian akan diajarkan esensial-esensial yang dibutuhkan dan algoritma dasar untuk metode-metode pada Metnum.\nSemua modul telah diuji menggunakan Jupyter Notebook dengan Python 3.11, serta Google Colaboratory yang menggunakan Python 3.9. Semua kode pada modul masih bisa digunakan untuk semua Python versi 3.6 ke atas.\nKalian juga bisa menggunakan aplikasi/IDE (Integrated Development Environment) lainnya seperti PyCharm, Spyder, atau bahkan IDLE (IDLE adalah IDE bawaan Python yang diinstal dari python.org), namun kalian disarankan menggunakan Jupyter Notebook atau Google Colaboratory karena file tugas menggunakan file format .ipynb.\nBerikut topik-topik yang akan dibahas pada Modul 1 ini:\n\nReview Python\n\nOperasi, Variabel, dan Comment\nString dan Formatting\nInput nilai\nList\nPernyataan Kondisional\nLooping\n\nError Handling\nNumPy\nTabulate"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul1.html#operasi-variabel-dan-comment",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul1.html#operasi-variabel-dan-comment",
    "title": "Outline",
    "section": "Operasi, Variabel, dan Comment",
    "text": "Operasi, Variabel, dan Comment\nDi Python, kita bisa melakukan beberapa operasi aritmetika, menggunakan simbol sebagai berikut:\n(+) untuk penjumlahan\n(-) untuk pengurangan\n(*) untuk perkalian\n(/) untuk pembagian\n(**) untuk pangkat\n(%) untuk operasi mod atau modulo (sisa pembagian)\n(//) untuk operasi div (hasil bagi tanpa sisa)\n\nprint(5 + 2)\nprint(5 - 2)\nprint(5 * 2)\nprint(5 / 2)\nprint(5 ** 2)\nprint(5 % 2)\nprint(5 // 2)\n\n7\n3\n10\n2.5\n25\n1\n2\n\n\nSeandainya kita tidak menggunakan print untuk menampilkan hasil perhitungan,\n\n5 + 2\n\n7\n\n\n\n5 - 2\n5 * 2\n\n10\n\n\nmaka hanya hasil dari baris terakhir yang akan ditampilkan. Oleh karena itu, sangat disarankan untuk SELALU menuliskan print, termasuk untuk baris terakhir, agar modifikasi program menjadi lebih mudah dan cepat, apalagi ketika ingin menambah baris baru.\nPerhatikan bahwa tanda % sudah dikhususkan untuk modulo, sehingga artinya BUKAN PERSEN, ya! Persen dalam Python bisa dituliskan sebagai pembagian dengan 100 (sesuai definisi persen), misalnya untuk 50% atau 21%:\n\nprint(50/100)\nprint(21/100)\n\n0.5\n0.21\n\n\nKita bisa menyimpan nilai (termasuk hasil perhitungan) ke suatu tempat penyimpanan yang disebut variabel. Tiap variabel memiliki nama tersendiri, yang kita definisikan sendiri. Proses penyimpanan nilai ke suatu variabel disebut proses assignment, yang memiliki syntax (cara penulisan) sebagai berikut:\ncontoh_variabel = 23\ndi mana 23 adalah contoh nilai yang ingin dipasang ke contoh variabel yang kita beri nama “contoh_variabel”. Untuk assignment, tanda = cukup ditulis sekali saja, ya!\nKemudian, kita bisa menggunakan print untuk menampilkan isi variabel tersebut.\n\ncontoh_variabel = 23\nprint(contoh_variabel)\n\n23\n\n\nJangan sampai salah ketik, ya! Penggunaan huruf besar/kecil perlu diperhatikan, jangan sampai tertukar.\n\nprint(contoh_Variabel)\n\nNameError: name 'contoh_Variabel' is not defined\n\n\nKita mendapat error “name ‘contoh_Variabel’ is not defined”, artinya ‘contoh_Variabel’ itu tidak didefinisikan, karena Python menganggap itu berbeda dengan contoh_variabel yang memang sudah kita definisikan. Tentu kita tetap bisa mendefinisikannya:\n\ncontoh_variabel = 23\ncontoh_Variabel = 45\nprint(contoh_variabel)\nprint(contoh_Variabel)\n\n23\n45\n\n\nAda beberapa hal yang dilarang dalam penamaan variabel.\n\nNama variabel hanya boleh terdiri dari huruf, angka, dan tanda _\nNama variabel tidak boleh diawali angka\n\nContoh penamaan yang valid (boleh, bisa diterima):\n\nabc1 = 21\nxyz9000 = 3\n\nKarena valid, variabel berhasil tersimpan dengan baik, sehingga bisa dilihat isinya:\n\nprint(abc1)\nprint(xyz9000)\n\n21\n3\n\n\nContoh penamaan yang dilarang (akan menghasilkan error):\n\n999nama = 10\n\nSyntaxError: invalid decimal literal (678666226.py, line 1)\n\n\nSelain keterangan spesifik seperti “invalid decimal literal”, kita juga bisa mendapatkan keterangan error yang lebih umum yaitu “invalid syntax” atau “syntax tidak valid”. Karena terjadi error, proses assignment tidak berhasil, sehingga kita tidak bisa melihat isinya karena variabel tersebut memang gagal didefinisikan:\n\nprint(999nama)\n\nSyntaxError: invalid decimal literal (4165728206.py, line 1)\n\n\nKita juga bisa menggunakan variabel, seperti mengoperasikan variabel untuk menghasilkan nilai baru:\n\nprint(abc1 * 10)\nprint(abc1 / xyz9000)\n\n210\n7.0\n\n\nBahkan, kita bisa memasang hasil operasi tersebut ke variabel lain:\n\nhasil_bagi = abc1 / xyz9000\nprint(hasil_bagi)\n\n7.0\n\n\nPerhatikan potongan kode berikut.\n\na = 6\nb = 3\nprint(a / b)\na, b = b, a\nprint(a / b)\n\n2.0\n0.5\n\n\nPada baris 4, kita menukar nilai pada variabel a dan b. Python bisa meng-assign lebih dari 1 variabel dalam 1 baris, cukup dengan memisahkan tiap variabel dan nilai dengan , (tanda koma).\n\nx, y, z = 0, 1, 2\nprint(x)\nprint(y)\nprint(z)\n\n0\n1\n2\n\n\nWalaupun cara tersebut berlaku untuk sebanyak-banyaknya variabel, pada umumnya lebih baik melakukan assignment satu variabel per baris saja agar kode tetap mudah dibaca, apalagi fitur tersebut hanya ada di bahasa pemrograman Python.\nPenukaran variabel tetap bisa dilakukan sesuai cara yang dipelajari di mata kuliah Algortma dan Pemrograman, yaitu dengan bantuan variabel yang bisa dinamakan temp atau semacamnya (variabel dummy yang “tidak penting” dan hanya digunakan untuk bantuan sementara saja):\n\nc = 10\nd = 5\nprint(c/d)\ntemp = d\nd = c\nc = temp\nprint(c/d)\n\n2.0\n0.5\n\n\natau sama saja,\n\nc = 10\nd = 5\nprint(c/d)\ntemp = c\nc = d\nd = temp\nprint(c/d)\n\n2.0\n0.5\n\n\nTerkadang, program yang kita buat bisa menjadi rumit, sehingga kita perlu menambahkan semacam penjelasan atau catatan supaya orang lain bisa lebih memahami kode kita. Di Python, kita bisa menambahkan comment atau semacam catatan di samping kanan tiap baris (atau pada baris tersendiri), dimulai dengan tanda #\n\nprint(\"Selamat pagi\") # buat apa? gapapa iseng aja\n# print(\"Selamat siang\")\nprint(\"Selamat sore\") # wah dari pagi langsung sore\n\nSelamat pagi\nSelamat sore\n\n\nPython tidak memperhatikan comment sama sekali. Adanya fitur comment hanyalah untuk membantu kita sebagai programmer."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul1.html#string-dan-formatting",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul1.html#string-dan-formatting",
    "title": "Outline",
    "section": "String dan Formatting",
    "text": "String dan Formatting\nDi Python, selain tipe data numerik/angka, ada juga yang dinamakan “string”, yaitu kumpulan huruf/karakter/kata, yang bisa diawali dan diakhiri dengan tanda petik ’ atau tanda kutip ”\n\nmata_kuliah = \"Metode Numerik\"\ndepartemen = 'matematika'\ngelar = 'S1'\nprint(mata_kuliah)\nprint(departemen)\nprint(gelar)\n\nMetode Numerik\nmatematika\nS1\n\n\nPenggunaan tanda petik ataupun tanda kutip itu sama-sama valid, yang penting konsisten.\nSuatu string bisa dicek “panjang”nya, atau jumlah karakter di dalam string (termasuk spasi, koma, dan sebagainya), dengan len (artinya length):\n\npanjang1 = len(mata_kuliah)\npanjang2 = len(departemen)\npanjang3 = len(gelar)\nprint(panjang1)\nprint(panjang2)\nprint(panjang3)\n\n14\n10\n2\n\n\nString juga bisa digabung dengan semacam “penjumlahan” atau penggabungan (juga disebut string concatenation):\n\nnama_depan = \"Johan\"\nnama_tengah = \"Frederik\"\nnama_belakang = \"Steffensen\"\nprint(nama_depan + nama_belakang)\nprint(nama_depan + nama_tengah + nama_belakang)\n\nJohanSteffensen\nJohanFrederikSteffensen\n\n\nPerhatikan bahwa, pada ketiga string yang kita definisikan, tidak ada spasi, sehingga dalam penggabungannya itu juga tidak ada spasi.\nPenggabungan string tidak harus antar variabel, bisa juga antar nilai, atau bahkan antara variabel dengan nilai.\n\nprint(\"Halo! Nama saya \" + nama_depan)\n\nHalo! Nama saya Johan\n\n\nKita telah menggabungkan string “Halo! Nama saya” dengan variabel nama_depan (perhatikan bahwa string tersebut diakhiri satu spasi).\n\nprint(nama_belakang + \", \" + nama_depan + \" \" + nama_tengah)\n\nSteffensen, Johan Frederik\n\n\nDi sini, kita telah menggabungkan variabel nama_belakang dengan suatu string yang tediri dari dua karakter (yaitu koma dan spasi), yang kemudian digabungkan dengan variabel nama_depan, kemudian suatu string yang terdiri dari spasi saja, dan akhirnya dengan variabel nama_tengah.\nPenjumlahan yang dilakukan secara berulang kali adalah perkalian. Begitu juga untuk string:\n\nprint(3 * \"Belajar\")\nprint(\"Panik\" * 5)\n\nBelajarBelajarBelajar\nPanikPanikPanikPanikPanik\n\n\nKita juga bisa mengubah atau mengkonversi nilai selain string (seperti angka) agar menjadi string dan bisa digabungkan juga, menggunakan str. Contohnya,\n\nnilai_semester = 2\nstring_semester = str(nilai_semester)\nprint(\"Saya masih semester \" + string_semester)\n\nSaya masih semester 2\n\n\nSeandainya kita tidak mengkonversi nilai tersebut, akan terjadi error:\n\nnilai_semester = 2\nprint(\"Saya masih semester \" + nilai_semester)\n\nTypeError: can only concatenate str (not \"int\") to str\n\n\nPython hanya paham cara menggabungkan string dengan string, bukan string dengan selain string, sehingga kita harus mengkonversi nilai tersebut menjadi string terlebih dahulu.\nSebaliknya, kita juga bisa “menghilangkan tanda petik/kutip” dari suatu string (misalnya untuk mengkonversi kembali menjadi angka), dengan eval.\n\nangka_semester = eval(string_semester)\nsemester_atas = 2 + angka_semester\nstring_atas = str(semester_atas)\nprint(\"Dia sudah semester \" + string_atas)\n\nDia sudah semester 4\n\n\nSeandainya tidak digunakan eval,\n\nsemester_atas =  2 + string_semester\n\nTypeError: unsupported operand type(s) for +: 'int' and 'str'\n\n\nLagi-lagi, Python tidak paham penjumlahan antara bilangan dengan string.\nAda cara lain untuk memadukan nilai string dengan variabel yang berisi string, yaitu dengan yang namanya string formatting. Sejak Python 3.6, ada yang namanya f-strings, yang diawali dengan huruf “f” tepat sebelum penulisan string. Pada suatu f-string, kita bisa menggunakan kurung kurawal yaitu { dan } untuk menggantikan isi string dengan suatu variabel, yang nama variabelnya kita masukkan ke dalam kurung kurawal tersebut.\nMisalnya, kita bisa memasukkan nilai variabel mata_kuliah di dalam suatu f-string, seperti berikut:\n\nprint(f\"Saya sedang mengikuti praktikum {mata_kuliah}.\")\n\nSaya sedang mengikuti praktikum Metode Numerik.\n\n\nTentu, kita bisa menyisipkan lebih dari satu variabel.\n\nprint(f\"Saya sedang mengikuti praktikum {mata_kuliah} untuk mendapatkan gelar {gelar}.\")\n\nSaya sedang mengikuti praktikum Metode Numerik untuk mendapatkan gelar S1.\n\n\nSelain menggunakan f-string, kita juga bisa menggunakan .format() pada akhir string (fitur ini sudah ada sejak Python 3.0), dengan syntax sebagai berikut:\n\nprint(\"Saya sedang mengikuti praktikum {0} untuk mendapatkan gelar {1}\".format(mata_kuliah, gelar))\n\nSaya sedang mengikuti praktikum Metode Numerik untuk mendapatkan gelar S1\n\n\nAgar kode lebih mudah dibaca,\n\nkalimat = \"Saya sedang mengikuti praktikum {0} untuk mendapatkan gelar {1}\".format(mata_kuliah, gelar)\nprint(kalimat)\n\nSaya sedang mengikuti praktikum Metode Numerik untuk mendapatkan gelar S1\n\n\nPerhatikan bahwa, dengan cara .format(), kita harus mengisi tempat penyisipan dengan {0}, {1}, {2}, dan seterusnya tergantung banyaknya penyisipan, kemudian variabel-variabel yang ingin disisipkan itu baru ditempel di akhir, yaitu di dalam kurung .format().\nLagi-lagi, kedua cara sama-sama valid, yang penting konsisten. Ketika hendak menggunakan f-string, jangan tiba-tiba mengetik .format() pada akhir f-string.\nSebagai tambahan, kita bisa menyisipkan angka, dan kita juga bisa mempersingkat penulisannya menjadi beberapa angka di belakang koma, misalnya cukup 7 angka di belakang koma:\n\nakar_dua = 2**(1/2)\nprint(\"Akar dua bernilai kurang lebih {0:.7f}\".format(akar_dua))\nprint(\"atau lebih tepatnya {0}\".format(akar_dua))\n\nAkar dua bernilai kurang lebih 1.4142136\natau lebih tepatnya 1.4142135623730951\n\n\nBeberapa link (pengayaan, tidak wajib) untuk mempelajari string formatting lebih lanjut:\n\nhttps://www.w3schools.com/python/ref_string_format.asp\nhttps://realpython.com/python-string-formatting/"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul1.html#input-nilai",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul1.html#input-nilai",
    "title": "Outline",
    "section": "Input nilai",
    "text": "Input nilai\nSelain mengeluarkan output atau menampilkan nilai, Python juga bisa menerima nilai (yang kemudian dipasangkan ke variabel), menggunakan input(pesan), di mana pesan yang ada di dalam kurung itu bisa berisi pertanyaan yang ingin ditanyakan, atau keterangan yang diminta:\n\nangkatan = input(\"Masukkan angkatan: \")\nprint(\"Anda angkatan \" + angkatan)\n\nMasukkan angkatan: 2022\nAnda angkatan 2022\n\n\nPerhatikan bahwa input telah masuk dalam bentuk string, sehingga bisa langsung digabungkan dengan string lainnya. Karena masih berbentuk string, operasi aritmetika tidak sesuai harapan:\n\nangka = input(\"Masukkan angka: \")\ndobel = angka / 2\nprint(\"Setelah dibagi dua, angka tersebut menjadi \" + str(dobel))\n\nMasukkan angka: 24\n\n\nTypeError: unsupported operand type(s) for /: 'str' and 'int'\n\n\nTerjadi error karena operasi pembagian tidak bisa dilakukan pada string. Oleh karena itu, kita juga perlu eval agar nilai yang masuk itu dihilangkan tanda petik/kutipnya agar tidak lagi berbentuk string.\n\nangka = eval(input(\"Masukkan angka: \"))\ndobel = angka / 2\nprint(\"Setelah dibagi dua, angka tersebut menjadi \" + str(dobel))\n\nMasukkan angka: 24\nSetelah dibagi dua, angka tersebut menjadi 12.0\n\n\nKombinasi eval(input(pesan)) akan sering digunakan selama praktikum Metode Numerik."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul1.html#list",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul1.html#list",
    "title": "Outline",
    "section": "List",
    "text": "List\nSuatu list bisa menyimpan beberapa nilai sekaligus, yang masing-masing disebut elemen dari list tersebut. Pendefinisiannya menggunakan kurung siku, di mana tiap elemen dituliskan di dalamnya, saling dipisahkan dengan koma:\n\nbuah = [\"apel\", \"pisang\", \"jeruk\"]\nprint(buah)\n\n['apel', 'pisang', 'jeruk']\n\n\nTiap elemen memiliki posisi atau indeks (index). Di Python, indeks dimulai dari 0 (nol). Kita bisa memeriksa elemen pada indeks ke-sekian di list, dengan menuliskan nama list tersebut, diikuti dengan kurung siku yang berisi indeks ke berapa yang ingin dilihat nilainya.\n\nprint(buah[0])\nprint(buah[1])\nprint(buah[2])\n\napel\npisang\njeruk\n\n\nSuatu list bisa berisi beragam tipe data, tidak hanya string tetapi juga angka, atau bahkan keduanya sekaligus.\n\ndata_diri = [\"Guido van Rossum\", 1956, \"Belanda\", \"Pembuat bahasa pemrograman Python\"]\nprint(\"Nama: \" + data_diri[0])\nprint(\"Tahun kelahiran: \" + str(data_diri[1]))\nprint(\"Kewarganegaraan: \" + data_diri[2])\nprint(\"Dikenal sebagai: \" + data_diri[3])\n\nNama: Guido van Rossum\nTahun kelahiran: 1956\nKewarganegaraan: Belanda\nDikenal sebagai: Pembuat bahasa pemrograman Python\n\n\nKita dapat menambahkan elemen baru pada akhir list menggunakan .append()\n\nprima = [2, 3, 5]\nprint(prima)\nprima.append(7)\nprint(prima)\n\n[2, 3, 5]\n[2, 3, 5, 7]"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul1.html#pernyataan-kondisional",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul1.html#pernyataan-kondisional",
    "title": "Outline",
    "section": "Pernyataan Kondisional",
    "text": "Pernyataan Kondisional\nSeringkali kita dihadapi oleh beberapa kondisi. Misalkan pada metode Bisection, kalian perlu mengecek apakah nilai fungsi di ujung-ujung intervalnya berbeda tanda atau tidak. Jika tidak, metode tidak bisa berjalan. Maka, kita perlu menggunakan pernyataan kondisional.\nTerdapat tiga pernyataan kondisional: * If…else berguna jika hanya ada satu kondisi yang perlu dicek, dan perlu ada aksi yang dijalankan jika kondisi tidak terpenuhi. * If…elif berguna jika ada lebih dari satu kondisi yang perlu dicek, dan tidak ada aksi yang dijalankan apabila semua kondisi tidak terpenuhi. * If…elif…else berguna jika ada lebih dari satu kondisi yang perlu dicek, dan perlu ada aksi yang dijalankan jika kondisi tidak terpenuhi.\nAdvanced note: Ada pernyataan kondisional lain, yaitu try…except, naum akan dijelaskan pada bagian selanjutnya\n\nx = eval(input('Masukkan bilangan: '))\nif x &lt; 0:\n    print('Haha')\nelif x &gt;= 0 and x &lt;= 4:\n    print('Hehe')\nelse:\n    print('Hoho')\n\nMasukkan bilangan: 2\nHehe"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul1.html#looping",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul1.html#looping",
    "title": "Outline",
    "section": "Looping",
    "text": "Looping\nKebanyakan metode pada Metnum bersifat iteratif, artinya algoritmanya dijalankan berulang hingga tercapai batas tertentu (biasanya terdapat nilai toleransi antara aproksimasi dengan nilai eksaknya). Looping pada Python biasanya menggunakan for loop dan while loop.\nfor loop digunakan ketika kita mengetahui berapa kali kita harus mengulang perintah. Beberapa cara untuk for loop:\n\nfor i in range(a, b, n) : Loop ini akan membuat for loop berjalan mulai dari a hingga b - 1 dengan step sebesar n. Argumen n bersifat opsional dengan nilai default 1. Jika menggunakan range(b), maka bisa dianggap a = 0.\nfor i in list atau for i in string : Loop ini akan membuat for loop mengiterasikan tiap elemen list atau karakter string yang akan disimpan pada i. while loop digunakan ketika ada syarat tertentu yang harus dipenuhi untuk mengulang perintah tersebut.\nwhile cond : Loop ini akan membuat while loop berjalan selama cond bernilai True . Berhati-hatilah dalam menggunakan while loop. Pastikan kondisi yang dimasukkan akan bisa bernilai False . Jika tidak, maka kode akan stuck di infinite loop.\n\nAdvanced note: range() sejatinya adalah fungsi yang mengoutput list angka dengan aturan seperti di atas.\n\nprint('FOR LOOP EXAMPLE 1')\nfor i in range(3):\n    print('Print 3 kali')\nprint('FOR LOOP EXAMPLE 2')\nfor i in range(1, 4):\n    print(2 * i)\nprint('FOR LOOP EXAMPLE 3')\nfor i in range(1, 10, 3):\n    print('Angka sekarang:', i)\nprint('FOR LOOP EXAMPLE 4')\nfor i in [1, 4, 8, 2]:\n    print(i)\nprint('FOR LOOP EXAMPLE 5')\nfor i in 'mondstad':\n    if i == 'd':\n        print(i)\nprint('WHILE LOOP EXAMPLE')\ni = 0\nwhile i &lt;= 5:\n    print('Hati-hati while')\n    i += 1\nprint('While iteration DONE')\n\nFOR LOOP EXAMPLE 1\nPrint 3 kali\nPrint 3 kali\nPrint 3 kali\nFOR LOOP EXAMPLE 2\n2\n4\n6\nFOR LOOP EXAMPLE 3\nAngka sekarang: 1\nAngka sekarang: 4\nAngka sekarang: 7\nFOR LOOP EXAMPLE 4\n1\n4\n8\n2\nFOR LOOP EXAMPLE 5\nd\nd\nWHILE LOOP EXAMPLE\nHati-hati while\nHati-hati while\nHati-hati while\nHati-hati while\nHati-hati while\nHati-hati while\nWhile iteration DONE"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul4.html",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul4.html",
    "title": "Apa saja cara yang bisa dipakai untuk membuat plot di seaborn?",
    "section": "",
    "text": "Kembali ke EDA\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n#load dataset bawaan dari seaborn\niris = sns.load_dataset('iris')\niris\n\n\n  \n    \n      \n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n...\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n146\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n147\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n148\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n149\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\n150 rows × 5 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nApa saja cara yang bisa dipakai untuk membuat plot di seaborn?\n\nList/Series/array\nPandas Dataframe dan kolom\nLangsung Dataframenya\n\n*** List/Array/Series ***\n\n#Mengambil isinya saja kolom sepal length dan sepal width\nlength=iris['sepal_length'].values\nwidth=iris['sepal_width'].values\nprint(length,width)\n\n[5.1 4.9 4.7 4.6 5.  5.4 4.6 5.  4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1\n 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.  5.  5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.\n 5.5 4.9 4.4 5.1 5.  4.5 4.4 5.  5.1 4.8 5.1 4.6 5.3 5.  7.  6.4 6.9 5.5\n 6.5 5.7 6.3 4.9 6.6 5.2 5.  5.9 6.  6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1\n 6.3 6.1 6.4 6.6 6.8 6.7 6.  5.7 5.5 5.5 5.8 6.  5.4 6.  6.7 6.3 5.6 5.5\n 5.5 6.1 5.8 5.  5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3\n 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.  6.9 5.6 7.7 6.3 6.7 7.2\n 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.  6.9 6.7 6.9 5.8 6.8\n 6.7 6.7 6.3 6.5 6.2 5.9] [3.5 3.  3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.  3.  4.  4.4 3.9 3.5\n 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.  3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2\n 3.5 3.6 3.  3.4 3.5 2.3 3.2 3.5 3.8 3.  3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3\n 2.8 2.8 3.3 2.4 2.9 2.7 2.  3.  2.2 2.9 2.9 3.1 3.  2.7 2.2 2.5 3.2 2.8\n 2.5 2.8 2.9 3.  2.8 3.  2.9 2.6 2.4 2.4 2.7 2.7 3.  3.4 3.1 2.3 3.  2.5\n 2.6 3.  2.6 2.3 2.7 3.  2.9 2.9 2.5 2.8 3.3 2.7 3.  2.9 3.  3.  2.5 2.9\n 2.5 3.6 3.2 2.7 3.  2.5 2.8 3.2 3.  3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2\n 2.8 3.  2.8 3.  2.8 3.8 2.8 2.8 2.6 3.  3.4 3.1 3.  3.1 3.1 3.1 2.7 3.2\n 3.3 3.  2.5 3.  3.4 3. ]\n\n\n\nsns.scatterplot(x=length,y=width)\n\n\n\n\n\n\n\n\n*** Dataframe dan Nama Kolomnya ***\n\nsns.scatterplot(x=iris['sepal_length'],y=iris['sepal_width'])\n\n\n\n\n\n\n\n\n\nsns.scatterplot(x='sepal_length',y='sepal_width',data=iris)\n\n\n\n\n\n\n\n\n*** Langsung Menggunakan Dataframenya ***\n\nsns.boxplot(data=iris)\n\n\n\n\n\n\n\n\n\n\nYUK BELAJAR BUAT PLOTNYA\n\nScatter Plot\nDistribution Plot\nCount Plot\nBox Plot\nHeatmap (Benda)\n\n*** SCATTER PLOT ***\n\n#sns.scatterplot(x,y,data) xnya apa, y nya apa dan datanya apa jika pakai dataframe\n\n\nsns.scatterplot(x='sepal_length',y='sepal_width',data=iris)\n\n\n\n\n\n\n\n\n\n#Jika Menggunakan Matplotlib\nplt.scatter(x='sepal_length',y='sepal_width',data=iris)\n\n\n\n\n\n\n\n\n\n#Seaborn bisa menambahkan hue, Membagi warnanya berdasarkan sesuatu umumnya berdasarkan data kategorik\nsns.scatterplot(x='sepal_length',y='sepal_width',data=iris,hue='species')\n\n\n\n\n\n\n\n\n\n#Argumen pallete untuk mengasih warna\nsns.scatterplot(x='sepal_length',y='sepal_width',data=iris,hue='species',palette='Accent_r')\n\n\n\n\n\n\n\n\n\n#Bisa bikin scatterplot dengan ada garis regresinya\nsns.regplot(x='sepal_length',y='sepal_width',data=iris)\n\n\n\n\n\n\n\n\n\nsns.regplot(x='petal_length',y='petal_width',data=iris)\n\n\n\n\n\n\n\n\n\n#bisa mencari nilai korelasinya yaitu dengan .corr\niris['petal_length'].corr(iris['petal_width'])\n\n0.962865431402796\n\n\n*** DISTRIBUTION PLOT ***\n\nsns.distplot(iris['petal_length'])\n\nF:\\kim\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n  warnings.warn(msg, FutureWarning)\n\n\n\n\n\n\n\n\n\n\nsns.distplot(iris['sepal_width'])\n\nF:\\kim\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n  warnings.warn(msg, FutureWarning)\n\n\n\n\n\n\n\n\n\n\niris['sepal_width'].skew() #Distribusi Normal skewness nya 0\n\n0.31896566471359966\n\n\n\niris['petal_length'].skew()\n\n-0.27488417975101276\n\n\n\nsns.histplot(iris['sepal_width'])\n\n\n\n\n\n\n\n\n\nsns.histplot(iris['petal_width'])\n\n\n\n\n\n\n\n\n\n#Mencari kumulatif dari sepal width\nsns.histplot(iris['sepal_width'],cumulative=True)\n\n\n\n\n\n\n\n\n*** COUNT PLOT ***\n\n#Ganti data dengan data bawaan seaborn juga yaitu tips\ntips=sns.load_dataset('tips')\ntips.head(10)\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n5\n25.29\n4.71\nMale\nNo\nSun\nDinner\n4\n\n\n6\n8.77\n2.00\nMale\nNo\nSun\nDinner\n2\n\n\n7\n26.88\n3.12\nMale\nNo\nSun\nDinner\n4\n\n\n8\n15.04\n1.96\nMale\nNo\nSun\nDinner\n2\n\n\n9\n14.78\n3.23\nMale\nNo\nSun\nDinner\n2\n\n\n\n\n\n\n\n\nsns.countplot(x='day',data=tips)\n\n\n\n\n\n\n\n\n\nsns.countplot(x='sex',data=tips,palette='Accent')\n\n\n\n\n\n\n\n\n\nsns.countplot(x='day',data=tips,hue='sex',palette='Blues')\n\n\n\n\n\n\n\n\n\n#Jika ingin mengammbar dalam sumbu vertikal ya y=\nsns.countplot(x='sex',data=tips,hue='smoker')\n\n\n\n\n\n\n\n\n\nsns.countplot(y='sex',data=tips,hue='smoker')\n\n\n\n\n\n\n\n\n*** BOX PLOT ***\n\nsns.boxplot(x='sepal_width',data=iris)\n#Yang ditengah itu median, yang masih di kotakan berwarna sebelah kiri itu Q1 dan sebelah kanan itu Q3\n#untuk jarak kotak Biru ke garis verticalnya itu adalah 1.5 dikali (Q3-Q1)\n#Dan yang diluar dari garis vertical dianggap sebagai outlier\n\n\n\n\n\n\n\n\n\nsns.boxplot(x='petal_width',data=iris)\n#Kenapa jaraknya garisnya kecil? karena itu adalah nilai terkecil dan tidak ada lagi yang makin ke kiri\n\n\n\n\n\n\n\n\n*** HEATMAP ***\n\niris.drop('species', axis=1, inplace=True)\n\n\niris.corr()\n\n\n  \n    \n      \n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\n\n\nsepal_length\n1.000000\n-0.117570\n0.871754\n0.817941\n\n\nsepal_width\n-0.117570\n1.000000\n-0.428440\n-0.366126\n\n\npetal_length\n0.871754\n-0.428440\n1.000000\n0.962865\n\n\npetal_width\n0.817941\n-0.366126\n0.962865\n1.000000\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nsns.heatmap(iris.corr())\n\n\n\n\n\n\n\n\n\nsns.heatmap(iris.corr(),cmap='YlGnBu')\n\n\n\n\n\n\n\n\n\nsns.heatmap(iris.corr(),cmap='YlGnBu')\nplt.xticks(rotation=45)\n\n\n\n\n\n\n\n\n\n#Korelasi iris nya harus disimpan ke variabel baru agar code di bawah tidak error\nkorelasi_iris = iris.corr()\n\n\nsns.heatmap(korelasi_iris[(korelasi_iris &gt;= 0.5) | (korelasi_iris &lt;= -0.5)], annot = True, cmap = 'Blues', linewidth = 1, linecolor = 'black')"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul2.html",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul2.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke EDA\nimport pandas as pd\nimport numpy as np"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul2.html#concat-merge",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul2.html#concat-merge",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "1 Concat & Merge",
    "text": "1 Concat & Merge\nConcat (concatenate) berfungsi untuk menggabungkan 2 series atau data frame\n\ns1=pd.Series(['a','b','c'])\ns2=pd.Series(['x','y','z'])\n\n\npd.concat([s1,s2],axis=0) #indexnya mengikuti s1 dan s2\n\n0    a\n1    b\n2    c\n0    x\n1    y\n2    z\ndtype: object\n\n\n\npd.concat([s1,s2],ignore_index=True) #indexnya tidak mengikuti gabungan s1 dan s2\n\n0    a\n1    b\n2    c\n3    x\n4    y\n5    z\ndtype: object\n\n\n\npd.concat([s1,s2],keys=['s1','s2']) #nambahin level di depannya\n\ns1  0    a\n    1    b\n    2    c\ns2  0    x\n    1    y\n    2    z\ndtype: object\n\n\n\npd.concat([s1,s2],keys=['s1','s2'],names=['nama series', 'index'])\n\nnama series  index\ns1           0        a\n             1        b\n             2        c\ns2           0        x\n             1        y\n             2        z\ndtype: object\n\n\n\ndf1=pd.DataFrame({'col 1':['a','b','c'],'col 2':[0,1,2]})\ndf2=pd.DataFrame({'col 1':['x','y','z'],'col 2':[4,5,6]})\ndf1\n\n\n\n\n\n\n\n\ncol 1\ncol 2\n\n\n\n\n0\na\n0\n\n\n1\nb\n1\n\n\n2\nc\n2\n\n\n\n\n\n\n\n\ndf2\n\n\n\n\n\n\n\n\ncol 1\ncol 2\n\n\n\n\n0\nx\n4\n\n\n1\ny\n5\n\n\n2\nz\n6\n\n\n\n\n\n\n\n\npd.concat([df1,df2])  #default axis=0\n\n\n\n\n\n\n\n\ncol 1\ncol 2\n\n\n\n\n0\na\n0\n\n\n1\nb\n1\n\n\n2\nc\n2\n\n\n0\nx\n4\n\n\n1\ny\n5\n\n\n2\nz\n6\n\n\n\n\n\n\n\n\npd.concat([df1,df2], axis=1)\n\n\n\n\n\n\n\n\ncol 1\ncol 2\ncol 1\ncol 2\n\n\n\n\n0\na\n0\nx\n4\n\n\n1\nb\n1\ny\n5\n\n\n2\nc\n2\nz\n6\n\n\n\n\n\n\n\n\ndf3=pd.DataFrame({'col 3':['m','n','0'],'col 4':[40,50,60]})\ndf3\n\n\n\n\n\n\n\n\ncol 3\ncol 4\n\n\n\n\n0\nm\n40\n\n\n1\nn\n50\n\n\n2\n0\n60\n\n\n\n\n\n\n\n\npd.concat([df1,df3]) #Karena nama kolomnya df1 dan df3 berbeda makanya jadi NaN\n\n\n\n\n\n\n\n\ncol 1\ncol 2\ncol 3\ncol 4\n\n\n\n\n0\na\n0.0\nNaN\nNaN\n\n\n1\nb\n1.0\nNaN\nNaN\n\n\n2\nc\n2.0\nNaN\nNaN\n\n\n0\nNaN\nNaN\nm\n40.0\n\n\n1\nNaN\nNaN\nn\n50.0\n\n\n2\nNaN\nNaN\n0\n60.0\n\n\n\n\n\n\n\n\ndf4=pd.DataFrame({'col 2':[40,50,60], 'col 3':['m','n','0'],})\ndf4\n\n\n\n\n\n\n\n\ncol 2\ncol 3\n\n\n\n\n0\n40\nm\n\n\n1\n50\nn\n\n\n2\n60\n0\n\n\n\n\n\n\n\n\npd.concat([df1,df4],join='inner') #gabung hanya kolom yang beririsan\n\n\n\n\n\n\n\n\ncol 2\n\n\n\n\n0\n0\n\n\n1\n1\n\n\n2\n2\n\n\n0\n40\n\n\n1\n50\n\n\n2\n60\n\n\n\n\n\n\n\n\nmenu1 = pd.DataFrame({\"makanan\": [\"ayam\", \"sapi\"], \"harga1\": [10000, 20000]})\nmenu2 = pd.DataFrame({\"makanan\": [\"ayam\", \"sapi\"], \"harga2\": [40000, 50000]})\n\npd.merge(menu1,menu2,on='makanan')\n\n\n\n\n\n\n\n\nmakanan\nharga1\nharga2\n\n\n\n\n0\nayam\n10000\n40000\n\n\n1\nsapi\n20000\n50000\n\n\n\n\n\n\n\n\nmenu3 = pd.DataFrame({\"makanan\": [\"ayam\", \"ayam\"], \"harga3\": [20000, 25000]})\nmenu4 = pd.DataFrame({\"makanan\": [\"ayam\", \"ayam\"], \"harga4\": [50000, 65000]})\npd.merge(menu3,menu4,on='makanan')\n\n\n\n\n\n\n\n\nmakanan\nharga3\nharga4\n\n\n\n\n0\nayam\n20000\n50000\n\n\n1\nayam\n20000\n65000\n\n\n2\nayam\n25000\n50000\n\n\n3\nayam\n25000\n65000"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul2.html#operations",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul2.html#operations",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "2. Operations",
    "text": "2. Operations"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul2.html#to-numpy",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul2.html#to-numpy",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "2.1 to numpy",
    "text": "2.1 to numpy\n\ns1\n\n0    a\n1    b\n2    c\ndtype: object\n\n\n\ns1.to_numpy\n\n&lt;bound method IndexOpsMixin.to_numpy of 0    a\n1    b\n2    c\ndtype: object&gt;\n\n\n\ndf1=pd.DataFrame(np.random.randint(0,999,size=(4,6)),columns=['Gula','Tepung','Beras','Garem','Lada','Kecap'])\ndf1\n\n\n\n\n\n\n\n\nGula\nTepung\nBeras\nGarem\nLada\nKecap\n\n\n\n\n0\n935\n756\n795\n504\n994\n317\n\n\n1\n707\n537\n82\n892\n794\n249\n\n\n2\n1\n514\n668\n168\n239\n468\n\n\n3\n74\n11\n514\n801\n420\n864\n\n\n\n\n\n\n\n\ndf1.to_numpy\n\n&lt;bound method DataFrame.to_numpy of    Gula  Tepung  Beras  Garem  Lada  Kecap\n0   360     931    743    557   827    121\n1   911     762    637    344   722    413\n2   724     771    332    763   976    645\n3   955     460    680    507   281    973&gt;"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul2.html#sorting",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul2.html#sorting",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "2.2 Sorting",
    "text": "2.2 Sorting\n\ndf1.sort_index(axis=1) #urutin berdasarkan nama kolom\n\n\n\n\n\n\n\n\nBeras\nGarem\nGula\nKecap\nLada\nTepung\n\n\n\n\n0\n743\n557\n360\n121\n827\n931\n\n\n1\n637\n344\n911\n413\n722\n762\n\n\n2\n332\n763\n724\n645\n976\n771\n\n\n3\n680\n507\n955\n973\n281\n460\n\n\n\n\n\n\n\n\ndf1.sort_index(axis=1,ascending=False) #urutannya descending\n\n\n\n\n\n\n\n\nTepung\nLada\nKecap\nGula\nGarem\nBeras\n\n\n\n\n0\n931\n827\n121\n360\n557\n743\n\n\n1\n762\n722\n413\n911\n344\n637\n\n\n2\n771\n976\n645\n724\n763\n332\n\n\n3\n460\n281\n973\n955\n507\n680\n\n\n\n\n\n\n\n\ndf1.sort_values(by='Gula',ascending=False) #diurutin berdasarkan value 'Gula'\n\n\n\n\n\n\n\n\nGula\nTepung\nBeras\nGarem\nLada\nKecap\n\n\n\n\n0\n935\n756\n795\n504\n994\n317\n\n\n1\n707\n537\n82\n892\n794\n249\n\n\n3\n74\n11\n514\n801\n420\n864\n\n\n2\n1\n514\n668\n168\n239\n468"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul2.html#operasi-pada-dataset",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul2.html#operasi-pada-dataset",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "2.3 Operasi pada dataset",
    "text": "2.3 Operasi pada dataset\n\ndf1['Gula']+df1['Tepung'] #jumlahin gula dan tepung\n\n0    1291\n1    1673\n2    1495\n3    1415\ndtype: int32\n\n\n\ndf1['Gula dan Tepung']=df1['Gula']+df1['Tepung'] #hasilnya dimasukin ke kolom baru\ndf1\n\n\n\n\n\n\n\n\nGula\nTepung\nBeras\nGarem\nLada\nKecap\nGula dan Tepung\n\n\n\n\n0\n360\n931\n743\n557\n827\n121\n1291\n\n\n1\n911\n762\n637\n344\n722\n413\n1673\n\n\n2\n724\n771\n332\n763\n976\n645\n1495\n\n\n3\n955\n460\n680\n507\n281\n973\n1415\n\n\n\n\n\n\n\n\ndf1.apply(np.cumsum) #Membuat kumulatif\n\n\n\n\n\n\n\n\nGula\nTepung\nBeras\nGarem\nLada\nKecap\nGula dan Tepung\n\n\n\n\n0\n360\n931\n743\n557\n827\n121\n1291\n\n\n1\n1271\n1693\n1380\n901\n1549\n534\n2964\n\n\n2\n1995\n2464\n1712\n1664\n2525\n1179\n4459\n\n\n3\n2950\n2924\n2392\n2171\n2806\n2152\n5874\n\n\n\n\n\n\n\n\ndf1['Gula'][0]\n\n360\n\n\n\na1= df1.iloc[0]+df1.iloc[1] #operasinya dilakukan pada baris\ndf1.append(a1.transpose(),ignore_index=True) #Harus di transpose dulu yaa\n\n\n\n\n\n\n\n\nGula\nTepung\nBeras\nGarem\nLada\nKecap\nGula dan Tepung\nKecapPPN\n\n\n\n\n0\n360\n931\n743\n557\n827\n121\n1291\n133\n\n\n1\n911\n762\n637\n344\n722\n413\n1673\n454\n\n\n2\n724\n771\n332\n763\n976\n645\n1495\n709\n\n\n3\n955\n460\n680\n507\n281\n973\n1415\n1070\n\n\n4\n1271\n1693\n1380\n901\n1549\n534\n2964\n587\n\n\n\n\n\n\n\n\na1\n\nGula               1271\nTepung             1693\nBeras              1380\nGarem               901\nLada               1549\nKecap               534\nGula dan Tepung    2964\nKecapPPN            587\ndtype: int64"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul2.html#apply",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul2.html#apply",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "2.4 Apply",
    "text": "2.4 Apply\n\ndf1.apply(np.cumsum) #melakukan operasi cummulated sum untuk setiap kolom\n\n\n\n\n\n\n\n\nGula\nTepung\nBeras\nGarem\nLada\nKecap\nGula dan Tepung\n\n\n\n\n0\n360\n931\n743\n557\n827\n121\n1291\n\n\n1\n1271\n1693\n1380\n901\n1549\n534\n2964\n\n\n2\n1995\n2464\n1712\n1664\n2525\n1179\n4459\n\n\n3\n2950\n2924\n2392\n2171\n2806\n2152\n5874\n\n\n\n\n\n\n\n\ndf1.apply(lambda x: x.max()-x.min()) #Dapat dikombinasikan dengan fungsi lambda\n\nGula               595\nTepung             471\nBeras              411\nGarem              419\nLada               695\nKecap              852\nGula dan Tepung    382\ndtype: int64\n\n\n\ndf1.apply(lambda x: x[0]*x[1])\n\nGula                327960\nTepung              709422\nBeras               473291\nGarem               191608\nLada                597094\nKecap                49973\nGula dan Tepung    2159843\ndtype: int64\n\n\n\ndef pajak(x):    #define a function\n  return 1.1*x   #pajak 10 persen\n\n\ndf1['KecapPPN'] = df1['Kecap'].apply(lambda x: int(pajak(x)))\ndf1\n\n\n\n\n\n\n\n\nGula\nTepung\nBeras\nGarem\nLada\nKecap\nGula dan Tepung\nKecapPPN\n\n\n\n\n0\n360\n931\n743\n557\n827\n121\n1291\n133\n\n\n1\n911\n762\n637\n344\n722\n413\n1673\n454\n\n\n2\n724\n771\n332\n763\n976\n645\n1495\n709\n\n\n3\n955\n460\n680\n507\n281\n973\n1415\n1070"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul2.html#missing-values-duplicates",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul2.html#missing-values-duplicates",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "3. Missing Values & Duplicates",
    "text": "3. Missing Values & Duplicates\n\ndf = pd.DataFrame({\"Evan\" : [np.nan,100,95,94,99],\"Boy\" : [100,np.nan,95,99,94],\"Maxwell\" : [95,100,99,np.nan,94]})\ndf #berikut adalah dataframe, dapat terlihat missing values di representasikan sebagai NAN\n\n\n\n\n\n\n\n\nEvan\nBoy\nMaxwell\n\n\n\n\n0\nNaN\n100.0\n95.0\n\n\n1\n100.0\nNaN\n100.0\n\n\n2\n95.0\n95.0\n99.0\n\n\n3\n94.0\n99.0\nNaN\n\n\n4\n99.0\n94.0\n94.0\n\n\n\n\n\n\n\n\ndf.isna() #menampilkan lokasi dari data yang missing, direpresentasikan sebagai true\n\n\n\n\n\n\n\n\nEvan\nBoy\nMaxwell\n\n\n\n\n0\nTrue\nFalse\nFalse\n\n\n1\nFalse\nTrue\nFalse\n\n\n2\nFalse\nFalse\nFalse\n\n\n3\nFalse\nFalse\nTrue\n\n\n4\nFalse\nFalse\nFalse\n\n\n\n\n\n\n\n\ndf.isnull() #dengan isnull juga bisa\n\n\n\n\n\n\n\n\nEvan\nBoy\nMaxwell\n\n\n\n\n0\nTrue\nFalse\nFalse\n\n\n1\nFalse\nTrue\nFalse\n\n\n2\nFalse\nFalse\nFalse\n\n\n3\nFalse\nFalse\nTrue\n\n\n4\nFalse\nFalse\nFalse\n\n\n\n\n\n\n\n\ndf.isna().sum()    #jumlah value yg missing\n\nEvan       1\nBoy        1\nMaxwell    1\ndtype: int64\n\n\n\ndf.fillna(0) #menggantikan missing value dengan nilai \"0\"\n\n\n\n\n\n\n\n\nEvan\nBoy\nMaxwell\n\n\n\n\n0\n0.0\n100.0\n95.0\n\n\n1\n100.0\n0.0\n100.0\n\n\n2\n95.0\n95.0\n99.0\n\n\n3\n94.0\n99.0\n0.0\n\n\n4\n99.0\n94.0\n94.0\n\n\n\n\n\n\n\n\ndf.dropna() #menghapus baris yang mengandung \"NAN\"\n\n\n\n\n\n\n\n\nEvan\nBoy\nMaxwell\n\n\n\n\n2\n95.0\n95.0\n99.0\n\n\n4\n99.0\n94.0\n94.0\n\n\n\n\n\n\n\n\ndf.fillna(0) #Mengisi missing value dengan 0\n\n\n\n\n\n\n\n\nEvan\nBoy\nMaxwell\n\n\n\n\n0\n0.0\n100.0\n95.0\n\n\n1\n100.0\n0.0\n100.0\n\n\n2\n95.0\n95.0\n99.0\n\n\n3\n94.0\n99.0\n0.0\n\n\n4\n99.0\n94.0\n94.0\n\n\n\n\n\n\n\n\ndf['Evan']=df['Evan'].fillna(df['Evan'].median())\ndf\n\n\n\n\n\n\n\n\nEvan\nBoy\nMaxwell\n\n\n\n\n0\n97.0\n100.0\n95.0\n\n\n1\n100.0\nNaN\n100.0\n\n\n2\n95.0\n95.0\n99.0\n\n\n3\n94.0\n99.0\nNaN\n\n\n4\n99.0\n94.0\n94.0\n\n\n\n\n\n\n\n\ndf['Evan'].median() #Menghitung Median di kolom Evan\n\n97.0"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul2.html#string-operations",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul2.html#string-operations",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "4. String Operations",
    "text": "4. String Operations\n\nlist_nama = pd.Series([\"Evan Eka Wijaya\",\"Maxwell Thomson\",\"Raden Fadil Aji Saputra\"])\nlist_nama\n\n0            Evan Eka Wijaya\n1            Maxwell Thomson\n2    Raden Fadil Aji Saputra\ndtype: object\n\n\n\nlowercase = list_nama.str.lower() #mengubah semua anggota pada series menjadi huruf kecil\nlowercase\n\n0            evan eka wijaya\n1            maxwell thomson\n2    raden fadil aji saputra\ndtype: object\n\n\n\nuppercase = list_nama.str.upper() #mengubah semua anggota pada series menjadi kapital\nuppercase\n\n0            EVAN EKA WIJAYA\n1            MAXWELL THOMSON\n2    RADEN FADIL AJI SAPUTRA\ndtype: object\n\n\n\nlist_nama2 = pd.Series([\"     Evan\",\"Boy    \"]) #menghapuskan space di awal dan di akhir kata\nstrip = list_nama2.str.strip()\nstrip\n\n0    Evan\n1     Boy\ndtype: object\n\n\n\nsplit = list_nama.str.split(\" \") #memisahkan setiap kata pada series dengan tanda baca tertentu (contoh \" \")\n#dalam case ini setiap kata dipisahkan oleh space\nsplit\n\n0             [Evan, Eka, Wijaya]\n1              [Maxwell, Thomson]\n2    [Raden, Fadil, Aji, Saputra]\ndtype: object\n\n\n\ncat = list_nama.str.cat(sep=\" \") #gabungkan setiap anggota pada series dengan pemisah space (\" \")\ncat\n\n'Evan Eka Wijaya Maxwell Thomson Raden Fadil Aji Saputra'"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul2.html#count-values-max-min",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul2.html#count-values-max-min",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "5. count values, max, min",
    "text": "5. count values, max, min\n\nangka = pd.Series([1,2,3,4,3,5,4])\n\n\nangka.value_counts() #menghitung jumlah dari setiap komponen pada series, dapat terlihat terdapat 2 angka 4 dan 2 angka 3,dan sisanya 1\n\n4    2\n3    2\n5    1\n2    1\n1    1\ndtype: int64\n\n\n\nangka.value_counts(normalize=True) #mengembalikan banyaknya anggota dalam desimal\n\n4    0.285714\n3    0.285714\n5    0.142857\n2    0.142857\n1    0.142857\ndtype: float64\n\n\n\nangka.value_counts(bins=3) #membagi data menjadi 3 interval dan menghitung banyaknya anggota yang termasuk di interval\n\n(3.667, 5.0]      3\n(2.333, 3.667]    2\n(0.995, 2.333]    2\ndtype: int64\n\n\n\nframe = pd.DataFrame({\"Evan\" : [90,92,95,98],\n                      \"Maxwell\" : [91,91,89,99],\n                     \"Boy\" : [91,93,100,85]})\nframe\n\n\n\n\n\n\n\n\nEvan\nMaxwell\nBoy\n\n\n\n\n0\n90\n91\n91\n\n\n1\n92\n91\n93\n\n\n2\n95\n89\n100\n\n\n3\n98\n99\n85\n\n\n\n\n\n\n\n\nframe.count()\n\nEvan       4\nMaxwell    4\nBoy        4\ndtype: int64\n\n\n\nframe.count(axis=1)\n\n0    3\n1    3\n2    3\n3    3\ndtype: int64\n\n\n\nframe.count_value() #Gatau kenapa error ga jelas ajg\n\nAttributeError: 'DataFrame' object has no attribute 'count_value'\n\n\n\nframe.max() #mengembalikan nilai max dari masing masing kolom\n\nEvan        98\nMaxwell     99\nBoy        100\ndtype: int64\n\n\n\nframe.min() #mengembalikan nilai min dari masing masing kolom\n\nEvan       90\nMaxwell    89\nBoy        85\ndtype: int64\n\n\n\nframe.mean() #mengembalikan nilai rata rata dari masing masing kolom\n\nEvan       93.75\nMaxwell    92.50\nBoy        92.25\ndtype: float64\n\n\n\nframe.median() #Mengembalikan nilai median hwhw dari masing-masing kolom\n\nEvan       93.5\nMaxwell    91.0\nBoy        92.0\ndtype: float64\n\n\n\nframe.mean(axis=1)\n\n0    90.666667\n1    92.000000\n2    94.666667\n3    94.000000\ndtype: float64"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul2.html#aggregation-functions",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul2.html#aggregation-functions",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "6. Aggregation Functions",
    "text": "6. Aggregation Functions\nKalau belum, silakan download: dkikepadatankelurahan2013.csv\n\npath = 'F:\\Praktikum Semester 2\\EDA\\dkikepadatankelurahan2013.csv' #jangan lupa nama file.csv nya\ndki = pd.read_csv(path,sep=';')\n\n\ndki\n\n\n\n\n\n\n\n\nTAHUN\nNAMA PROVINSI\nNAMA KABUPATEN/KOTA\nNAMA KECAMATAN\nNAMA KELURAHAN\nLUAS WILAYAH (KM2)\nKEPADATAN (JIWA/KM2)\n35-39 Laki-Laki\n35-39 Perempuan\n40-44 Laki-Laki\n...\n55-59 Laki-Laki\n55-59 Perempuan\n60-64 Laki-Laki\n60-64 Perempuan\n65-69 Laki-Laki\n65-69 Perempuan\n70-74 Laki-Laki\n70-74 Perempuan\n&gt;75 Laki-Laki\n&gt;75 Perempuan\n\n\n\n\n0\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU UTR\nP. PANGGANG\n0,91\n6779\n231\n235\n233\n...\n98\n106\n72\n65\n36\n33\n33\n20\n13\n27\n\n\n1\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU UTR\nP. KELAPA\n3,76\n1705\n84\n88\n99\n...\n30\n39\n29\n24\n12\n21\n13\n5\n5\n8\n\n\n2\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU UTR\nP. HARAPAN\n3,59\n628\n255\n238\n232\n...\n139\n101\n73\n56\n18\n35\n24\n25\n18\n26\n\n\n3\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU SLT\nP. UNTUNG JAWA\n0,59\n3625\n199\n185\n178\n...\n97\n83\n58\n56\n40\n54\n26\n27\n16\n13\n\n\n4\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU SLT\nP. TIDUNG\n1,57\n3084\n98\n75\n73\n...\n37\n32\n22\n13\n18\n15\n10\n18\n11\n17\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n262\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nCIPAYUNG\nMUNJUL\n1,9\n12734\n1167\n1112\n1026\n...\n482\n482\n302\n291\n173\n137\n118\n94\n52\n51\n\n\n263\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nCIPAYUNG\nSETU\n3,25\n6028\n937\n928\n857\n...\n392\n354\n254\n211\n124\n115\n64\n83\n59\n64\n\n\n264\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nCIPAYUNG\nBAMBU APUS\n3,17\n8400\n1242\n1187\n1062\n...\n596\n476\n377\n250\n169\n179\n108\n96\n70\n84\n\n\n265\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nCIPAYUNG\nLUBANG BUAYA\n3,72\n18055\n3258\n2988\n2732\n...\n1376\n1308\n959\n739\n393\n385\n293\n291\n160\n165\n\n\n266\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nCIPAYUNG\nCEGER\n3,63\n5492\n1007\n930\n874\n...\n416\n390\n279\n214\n110\n153\n101\n53\n45\n44\n\n\n\n\n267 rows × 25 columns\n\n\n\n\ndki.describe() #ringkasan dataframe\n\n\n\n\n\n\n\n\nTAHUN\nKEPADATAN (JIWA/KM2)\n35-39 Laki-Laki\n35-39 Perempuan\n40-44 Laki-Laki\n40-44 Perempuan\n45-49 Laki-Laki\n45-49 Perempuan\n50-54 Laki-Laki\n50-54 Perempuan\n55-59 Laki-Laki\n55-59 Perempuan\n60-64 Laki-Laki\n60-64 Perempuan\n65-69 Laki-Laki\n65-69 Perempuan\n70-74 Laki-Laki\n70-74 Perempuan\n&gt;75 Laki-Laki\n&gt;75 Perempuan\n\n\n\n\ncount\n267.0\n267.000000\n267.000000\n267.000000\n267.000000\n267.000000\n267.000000\n267.000000\n267.000000\n267.000000\n267.000000\n267.000000\n267.000000\n267.000000\n267.000000\n267.000000\n267.000000\n267.000000\n267.000000\n267.000000\n\n\nmean\n2013.0\n21974.071161\n2264.157303\n1740.528090\n1675.644195\n2331.595506\n1643.711610\n1577.382022\n2259.314607\n1336.093633\n1178.636704\n1867.224719\n981.749064\n876.659176\n1403.288390\n683.599251\n607.011236\n1083.262172\n484.599251\n480.269663\n\n\nstd\n0.0\n15797.276753\n1740.545141\n1057.289862\n1014.907306\n2051.114031\n1158.863977\n1137.243632\n2540.761587\n1023.421706\n971.187785\n2207.402928\n924.674729\n839.510133\n1960.793725\n758.463034\n714.717419\n1574.043884\n607.659884\n583.769313\n\n\nmin\n2013.0\n628.000000\n84.000000\n75.000000\n73.000000\n80.000000\n66.000000\n62.000000\n34.000000\n29.000000\n30.000000\n32.000000\n22.000000\n13.000000\n12.000000\n14.000000\n10.000000\n5.000000\n5.000000\n7.000000\n\n\n25%\n2013.0\n11734.000000\n1186.000000\n1062.000000\n1023.000000\n1084.000000\n957.500000\n886.000000\n790.000000\n712.500000\n595.500000\n557.000000\n419.500000\n366.000000\n253.000000\n215.500000\n170.000000\n145.000000\n116.500000\n121.500000\n\n\n50%\n2013.0\n17304.000000\n1880.000000\n1631.000000\n1576.000000\n1714.000000\n1404.000000\n1315.000000\n1216.000000\n1107.000000\n909.000000\n889.000000\n650.000000\n587.000000\n413.000000\n354.000000\n285.000000\n260.000000\n200.000000\n204.000000\n\n\n75%\n2013.0\n29226.000000\n2768.500000\n2213.000000\n2112.500000\n2781.500000\n1949.000000\n1867.000000\n2623.500000\n1671.500000\n1405.500000\n2342.000000\n1186.500000\n1052.500000\n2097.500000\n928.500000\n836.500000\n1784.000000\n716.000000\n675.500000\n\n\nmax\n2013.0\n94166.000000\n13011.000000\n7488.000000\n7243.000000\n14731.000000\n8822.000000\n8352.000000\n17174.000000\n7480.000000\n6846.000000\n14326.000000\n6333.000000\n5476.000000\n11809.000000\n4758.000000\n4475.000000\n9233.000000\n3959.000000\n3526.000000\n\n\n\n\n\n\n\n\ndki.mean()\n\nTAHUN                    2013.000000\nKEPADATAN (JIWA/KM2)    21974.071161\n35-39 Laki-Laki          2264.157303\n35-39 Perempuan          1740.528090\n40-44 Laki-Laki          1675.644195\n40-44 Perempuan          2331.595506\n45-49 Laki-Laki          1643.711610\n45-49 Perempuan          1577.382022\n50-54 Laki-Laki          2259.314607\n50-54 Perempuan          1336.093633\n55-59 Laki-Laki          1178.636704\n55-59 Perempuan          1867.224719\n60-64 Laki-Laki           981.749064\n60-64 Perempuan           876.659176\n65-69 Laki-Laki          1403.288390\n65-69 Perempuan           683.599251\n70-74 Laki-Laki           607.011236\n70-74 Perempuan          1083.262172\n&gt;75 Laki-Laki             484.599251\n&gt;75  Perempuan            480.269663\ndtype: float64\n\n\n\ndki.median()\n\nTAHUN                    2013.0\nKEPADATAN (JIWA/KM2)    17304.0\n35-39 Laki-Laki          1880.0\n35-39 Perempuan          1631.0\n40-44 Laki-Laki          1576.0\n40-44 Perempuan          1714.0\n45-49 Laki-Laki          1404.0\n45-49 Perempuan          1315.0\n50-54 Laki-Laki          1216.0\n50-54 Perempuan          1107.0\n55-59 Laki-Laki           909.0\n55-59 Perempuan           889.0\n60-64 Laki-Laki           650.0\n60-64 Perempuan           587.0\n65-69 Laki-Laki           413.0\n65-69 Perempuan           354.0\n70-74 Laki-Laki           285.0\n70-74 Perempuan           260.0\n&gt;75 Laki-Laki             200.0\n&gt;75  Perempuan            204.0\ndtype: float64\n\n\n\n##BONUS\n#correlation antar feature + heatmap\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nhmat = dki.select_dtypes(exclude='object').corr()\ntop_corr_features = hmat.index[1:6]     #5 features saja\nplt.figure(figsize=(5,5))\nsns.heatmap(dki[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n\n\n\n\n\n\n\n\n\ndki.TAHUN.unique()\n\narray([2013], dtype=int64)\n\n\n\ndki['NAMA KABUPATEN/KOTA'].unique()\n\narray(['KAB.ADM.KEP.SERIBU', 'JAKARTA PUSAT', 'JAKARTA UTARA',\n       'JAKARTA BARAT', 'JAKARTA SELATAN', 'JAKARTA TIMUR'], dtype=object)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul2.html#grouping-pivot-table",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul2.html#grouping-pivot-table",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "7. Grouping & Pivot Table",
    "text": "7. Grouping & Pivot Table\n\nnp.random.seed(123)\n\njumlah_ternak = pd.DataFrame({\n    \"binatang\": [\"ayam\", \"bebek\", \"bebek\", \"ayam\", \"ayam\", \"bebek\", \"ayam\", \"ayam\"],\n    \"warna\": [\"kuning\", \"kuning\", \"coklat\", \"merah\", \"coklat\", \"coklat\", \"merah\", \"kuning\"],\n    \"jumlah 1\": np.random.randint(1,999,8),\n    \"jumlah 2\": np.random.randint(1,999,8)})\n\n\njumlah_ternak\n\n\n\n\n\n\n\n\nbinatang\nwarna\njumlah 1\njumlah 2\n\n\n\n\n0\nayam\nkuning\n511\n596\n\n\n1\nbebek\nkuning\n366\n107\n\n\n2\nbebek\ncoklat\n383\n124\n\n\n3\nayam\nmerah\n323\n570\n\n\n4\nayam\ncoklat\n989\n215\n\n\n5\nbebek\ncoklat\n99\n738\n\n\n6\nayam\nmerah\n743\n97\n\n\n7\nayam\nkuning\n18\n114\n\n\n\n\n\n\n\n\njumlah_ternak.groupby('binatang').sum() #jumlahnya berdasarkan nama binatang\n\n\n\n\n\n\n\n\njumlah 1\njumlah 2\n\n\nbinatang\n\n\n\n\n\n\nayam\n2584\n1592\n\n\nbebek\n848\n969\n\n\n\n\n\n\n\n\njumlah_ternak.groupby(['binatang','warna']).sum() #jumlahnya berdasarkan nama binatang\n\n\n\n\n\n\n\n\n\njumlah 1\njumlah 2\n\n\nbinatang\nwarna\n\n\n\n\n\n\nayam\ncoklat\n989\n215\n\n\nkuning\n529\n710\n\n\nmerah\n1066\n667\n\n\nbebek\ncoklat\n482\n862\n\n\nkuning\n366\n107\n\n\n\n\n\n\n\n\njumlah_ternak.groupby('binatang')['jumlah 1'].sum()   #Jumlah 1 berdasarkan binatang, dalam btk series\n\nbinatang\nayam     2584\nbebek     848\nName: jumlah 1, dtype: int32\n\n\n\njumlah_ternak.groupby('binatang')['jumlah 1'].sum().reset_index()   #Jumlah 1 berdasarkan binatang, dalam btk dataframe\n\n\n\n\n\n\n\n\nbinatang\njumlah 1\n\n\n\n\n0\nayam\n2584\n\n\n1\nbebek\n848\n\n\n\n\n\n\n\n\n#jumlah kombinasi antara binatang dan warna\nstay = jumlah_ternak.groupby(['binatang','warna'])['jumlah 1'].count().reset_index() #reset_index biar dataframe\nstay.rename(columns={'jumlah 1':'count'}, inplace=True)    #ganti nama\nstay.head()\n\n\n\n\n\n\n\n\nbinatang\nwarna\ncount\n\n\n\n\n0\nayam\ncoklat\n1\n\n\n1\nayam\nkuning\n2\n\n\n2\nayam\nmerah\n2\n\n\n3\nbebek\ncoklat\n2\n\n\n4\nbebek\nkuning\n1\n\n\n\n\n\n\n\n\n#atau bisa juga\nstay = jumlah_ternak.groupby(['binatang','warna']).agg('count').reset_index()  #reset_index biar dataframe\nstay = stay.iloc[:,0:3]   #ingin 3 kolom pertama saja\nstay.rename(columns={'jumlah 1':'count'}, inplace=True)    #ganti nama\nstay.head()\n\n\n\n\n\n\n\n\nbinatang\nwarna\ncount\n\n\n\n\n0\nayam\ncoklat\n1\n\n\n1\nayam\nkuning\n2\n\n\n2\nayam\nmerah\n2\n\n\n3\nbebek\ncoklat\n2\n\n\n4\nbebek\nkuning\n1\n\n\n\n\n\n\n\n\nstay.sort_values(by='count') #Mengurutkan berdasarkan count\n\n\n\n\n\n\n\n\nbinatang\nwarna\ncount\n\n\n\n\n0\nayam\ncoklat\n1\n\n\n4\nbebek\nkuning\n1\n\n\n1\nayam\nkuning\n2\n\n\n2\nayam\nmerah\n2\n\n\n3\nbebek\ncoklat\n2\n\n\n\n\n\n\n\n\npd.pivot_table(jumlah_ternak,values='jumlah 1',index=['binatang'],columns=['warna'])\n\n\n\n\n\n\n\nwarna\ncoklat\nkuning\nmerah\n\n\nbinatang\n\n\n\n\n\n\n\nayam\n989.0\n264.5\n533.0\n\n\nbebek\n241.0\n366.0\nNaN"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul2.html#latihan-soal",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul2.html#latihan-soal",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "Latihan Soal",
    "text": "Latihan Soal\n\ndki = pd.read_csv('https://raw.githubusercontent.com/maxwelth/ntar-dihapus/main/dkikepadatankelurahan2013.csv')\ndki.dropna(axis=1,inplace=True)\n\n\n1. Kabupaten/Kota mana yang memiliki jumlah penduduk terbesar untuk umur 35-39? Tampilkan dalam bentuk dataframe (Urutkan terbesar hingga terkecil)\n\ndki.groupby('NAMA KABUPATEN/KOTA')['35-39 Laki-Laki'].sum()\n\nNAMA KABUPATEN/KOTA\nJAKARTA BARAT         181626\nJAKARTA PUSAT          50256\nJAKARTA SELATAN       100867\nJAKARTA TIMUR         135669\nJAKARTA UTARA         135132\nKAB.ADM.KEP.SERIBU       980\nName: 35-39 Laki-Laki, dtype: int64\n\n\n\ndki.groupby('NAMA KABUPATEN/KOTA')['35-39 Perempuan'].sum()\n\nNAMA KABUPATEN/KOTA\nJAKARTA BARAT         106863\nJAKARTA PUSAT          47836\nJAKARTA SELATAN        98432\nJAKARTA TIMUR         130196\nJAKARTA UTARA          80461\nKAB.ADM.KEP.SERIBU       933\nName: 35-39 Perempuan, dtype: int64\n\n\n\nlakilaki1 = dki.groupby('NAMA KABUPATEN/KOTA')['35-39 Laki-Laki'].sum()\nperempuan1 = dki.groupby('NAMA KABUPATEN/KOTA')['35-39 Perempuan'].sum()\n\n\nlakilaki2=lakilaki1.reset_index() #Dengan menggunakan reset_index() dari series jadi data frame\nlakilaki2\n\n\n\n\n\n\n\n\nNAMA KABUPATEN/KOTA\n35-39 Laki-Laki\n\n\n\n\n0\nJAKARTA BARAT\n181626\n\n\n1\nJAKARTA PUSAT\n50256\n\n\n2\nJAKARTA SELATAN\n100867\n\n\n3\nJAKARTA TIMUR\n135669\n\n\n4\nJAKARTA UTARA\n135132\n\n\n5\nKAB.ADM.KEP.SERIBU\n980\n\n\n\n\n\n\n\n\nperempuan2=perempuan1.reset_index()\nperempuan2\n\n\n\n\n\n\n\n\nNAMA KABUPATEN/KOTA\n35-39 Perempuan\n\n\n\n\n0\nJAKARTA BARAT\n106863\n\n\n1\nJAKARTA PUSAT\n47836\n\n\n2\nJAKARTA SELATAN\n98432\n\n\n3\nJAKARTA TIMUR\n130196\n\n\n4\nJAKARTA UTARA\n80461\n\n\n5\nKAB.ADM.KEP.SERIBU\n933\n\n\n\n\n\n\n\n\ngabungan1 = (lakilaki1 + perempuan1).reset_index()\ngabungan1\n\n\n\n\n\n\n\n\nNAMA KABUPATEN/KOTA\n0\n\n\n\n\n0\nJAKARTA BARAT\n288489\n\n\n1\nJAKARTA PUSAT\n98092\n\n\n2\nJAKARTA SELATAN\n199299\n\n\n3\nJAKARTA TIMUR\n265865\n\n\n4\nJAKARTA UTARA\n215593\n\n\n5\nKAB.ADM.KEP.SERIBU\n1913\n\n\n\n\n\n\n\n\ngabungan1.columns = ['Kabupaten/Kota', 'Jumlah Penduduk 35-39']\ngabungan1 = gabungan1.sort_values(by=['Jumlah Penduduk 35-39'], ascending=False)\ngabungan1\n\n\n\n\n\n\n\n\nKabupaten/Kota\nJumlah Penduduk 35-39\n\n\n\n\n0\nJAKARTA BARAT\n288489\n\n\n3\nJAKARTA TIMUR\n265865\n\n\n4\nJAKARTA UTARA\n215593\n\n\n2\nJAKARTA SELATAN\n199299\n\n\n1\nJAKARTA PUSAT\n98092\n\n\n5\nKAB.ADM.KEP.SERIBU\n1913\n\n\n\n\n\n\n\n\n\n2. Kabupaten/Kota mana yang memiliki jumlah penduduk terbesar (segala umur)? Tampilkan dalam bentuk dataframe (Urutkan terbesar hingga terkecil)\n\nnamakolom = dki.columns.drop(['TAHUN', 'NAMA PROVINSI', 'NAMA KABUPATEN/KOTA', 'NAMA KECAMATAN',\n       'NAMA KELURAHAN', 'LUAS WILAYAH (KM2)', 'KEPADATAN (JIWA/KM2)']) #sisakan hanya kolom dengan jumlah penduduk\n\n\nnamakolom\n\nIndex(['35-39 Laki-Laki', '35-39 Perempuan', '40-44 Laki-Laki',\n       '40-44 Perempuan', '45-49 Laki-Laki', '45-49 Perempuan',\n       '50-54 Laki-Laki', '50-54 Perempuan', '55-59 Laki-Laki',\n       '55-59 Perempuan', '60-64 Laki-Laki', '60-64 Perempuan',\n       '65-69 Laki-Laki', '65-69 Perempuan', '70-74 Laki-Laki',\n       '70-74 Perempuan', '&gt;75 Laki-Laki', '&gt;75  Perempuan'],\n      dtype='object')\n\n\n\nb=0\nfor i in namakolom:\n  a = dki.groupby('NAMA KABUPATEN/KOTA')[i].sum()\n  b = a+b\n\n\nb\n\nNAMA KABUPATEN/KOTA\nJAKARTA BARAT         2316181\nJAKARTA PUSAT          500056\nJAKARTA SELATAN        878137\nJAKARTA TIMUR         1136447\nJAKARTA UTARA         1695623\nKAB.ADM.KEP.SERIBU       8308\ndtype: int64\n\n\n\ngabungan2 = b.reset_index()  #ke dataframe\ngabungan2.columns = ['Kabupaten', 'Jumlah Penduduk']  #memberi nama pada kolom\ngabungan2 = gabungan2.sort_values(by=['Jumlah Penduduk'], ascending=False) #Mengurutkan dari terbesar ke terkecil\ngabungan2\n\n\n\n\n\n\n\n\nKabupaten\nJumlah Penduduk\n\n\n\n\n0\nJAKARTA BARAT\n2316181\n\n\n4\nJAKARTA UTARA\n1695623\n\n\n3\nJAKARTA TIMUR\n1136447\n\n\n2\nJAKARTA SELATAN\n878137\n\n\n1\nJAKARTA PUSAT\n500056\n\n\n5\nKAB.ADM.KEP.SERIBU\n8308\n\n\n\n\n\n\n\n\n#Pertama-tama akan dipilih 3 kelurahan dg luas wilayah terkecil\ndki['NAMA KABUPATEN/KOTA'].value_counts()\n\nJAKARTA SELATAN       65\nJAKARTA TIMUR         65\nJAKARTA BARAT         56\nJAKARTA PUSAT         44\nJAKARTA UTARA         31\nKAB.ADM.KEP.SERIBU     6\nName: NAMA KABUPATEN/KOTA, dtype: int64\n\n\n\ndki['NAMA KABUPATEN/KOTA'].unique()\n\narray(['KAB.ADM.KEP.SERIBU', 'JAKARTA PUSAT', 'JAKARTA UTARA',\n       'JAKARTA BARAT', 'JAKARTA SELATAN', 'JAKARTA TIMUR'], dtype=object)\n\n\n\ndki['NAMA KABUPATEN/KOTA'].value_counts().index\n\nIndex(['JAKARTA SELATAN', 'JAKARTA TIMUR', 'JAKARTA BARAT', 'JAKARTA PUSAT',\n       'JAKARTA UTARA', 'KAB.ADM.KEP.SERIBU'],\n      dtype='object')\n\n\n\nnamakota = dki['NAMA KABUPATEN/KOTA'].value_counts().index\ndf_baru = pd.DataFrame()   #dataframe kosong\n\nfor i in namakota:\n  aa = dki[dki['NAMA KABUPATEN/KOTA']==i].sort_values(by='LUAS WILAYAH (KM2)',ascending=True)[0:3]  #subsetting 3 terkecil\n  df_baru = pd.concat([df_baru,aa])  #gabungkan\n\n\ndf_baru\n\n\n\n\n\n\n\n\nTAHUN\nNAMA PROVINSI\nNAMA KABUPATEN/KOTA\nNAMA KECAMATAN\nNAMA KELURAHAN\nLUAS WILAYAH (KM2)\nKEPADATAN (JIWA/KM2)\n35-39 Laki-Laki\n35-39 Perempuan\n40-44 Laki-Laki\n40-44 Perempuan\n45-49 Laki-Laki\n45-49 Perempuan\n50-54 Laki-Laki\n50-54 Perempuan\n55-59 Laki-Laki\n55-59 Perempuan\n60-64 Laki-Laki\n60-64 Perempuan\n65-69 Laki-Laki\n65-69 Perempuan\n70-74 Laki-Laki\n70-74 Perempuan\n&gt;75 Laki-Laki\n&gt;75 Perempuan\n\n\n\n\n142\n2013\nPROVINSI DKI JAKARTA\nJAKARTA SELATAN\nTEBET\nMANGGARAI SELATAN\n0.51\n52659\n1239\n1289\n1238\n1198\n1080\n1007\n790\n757\n607\n634\n361\n414\n212\n288\n218\n229\n127\n178\n\n\n150\n2013\nPROVINSI DKI JAKARTA\nJAKARTA SELATAN\nSETIA BUDI\nGUNTUR\n0.65\n7174\n208\n206\n186\n192\n181\n205\n168\n152\n140\n157\n114\n115\n62\n78\n55\n45\n37\n84\n\n\n187\n2013\nPROVINSI DKI JAKARTA\nJAKARTA SELATAN\nPANCORAN\nRAWA JATI\n0.67\n29915\n990\n985\n970\n902\n786\n683\n517\n527\n400\n439\n294\n309\n174\n200\n154\n126\n69\n80\n\n\n215\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nJATINEGARA\nKAMPUNG MELAYU\n0.48\n63973\n1361\n1154\n1236\n1050\n1016\n1029\n864\n848\n694\n601\n436\n409\n205\n294\n151\n173\n121\n159\n\n\n204\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nMATRAMAN\nKAYU MANIS\n0.57\n52740\n1377\n1336\n1271\n1337\n1173\n1144\n868\n899\n676\n690\n450\n450\n249\n276\n172\n219\n111\n185\n\n\n205\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nMATRAMAN\nPAL MERIAM\n0.65\n36818\n1101\n1061\n1061\n1001\n934\n879\n790\n722\n577\n563\n351\n398\n181\n240\n151\n169\n131\n204\n\n\n102\n2013\nPROVINSI DKI JAKARTA\nJAKARTA BARAT\nTAMBORA\nTAMBORA\n0.28\n45375\n968\n588\n544\n1132\n646\n593\n1239\n598\n522\n1120\n544\n451\n995\n460\n425\n885\n385\n368\n\n\n99\n2013\nPROVINSI DKI JAKARTA\nJAKARTA BARAT\nTAMAN SARI\nKEAGUNGAN\n0.32\n65800\n1673\n975\n932\n1907\n1117\n1017\n2134\n1030\n910\n1940\n941\n778\n1719\n817\n725\n1542\n662\n578\n\n\n103\n2013\nPROVINSI DKI JAKARTA\nJAKARTA BARAT\nTAMBORA\nKALI ANYAR\n0.32\n94166\n2532\n1567\n1530\n3097\n1775\n1554\n3329\n1549\n1275\n2824\n1251\n1022\n2273\n1035\n841\n1876\n808\n746\n\n\n48\n2013\nPROVINSI DKI JAKARTA\nJAKARTA PUSAT\nJOHAR BARU\nGALUR\n0.27\n79022\n999\n1060\n925\n982\n820\n795\n727\n621\n535\n436\n421\n259\n257\n139\n169\n124\n130\n64\n\n\n47\n2013\nPROVINSI DKI JAKARTA\nJAKARTA PUSAT\nJOHAR BARU\nKAMPUNG RAWA\n0.30\n86123\n1210\n1255\n1139\n1181\n972\n892\n830\n663\n663\n547\n495\n300\n339\n176\n189\n144\n175\n92\n\n\n29\n2013\nPROVINSI DKI JAKARTA\nJAKARTA PUSAT\nSENEN\nKWITANG\n0.45\n40724\n908\n793\n790\n727\n648\n667\n641\n513\n587\n459\n459\n310\n371\n157\n192\n105\n153\n95\n\n\n61\n2013\nPROVINSI DKI JAKARTA\nJAKARTA UTARA\nTANJUNG PRIOK\nWARAKAS\n1.09\n49384\n4224\n2608\n2342\n4950\n2968\n2790\n5758\n2738\n2664\n5402\n2338\n2234\n4572\n1858\n1749\n3607\n1347\n1235\n\n\n65\n2013\nPROVINSI DKI JAKARTA\nJAKARTA UTARA\nKOJA\nRAWA BADAK UTARA\n1.33\n31357\n3260\n2064\n1867\n3931\n2296\n2231\n4527\n2095\n1898\n3993\n1829\n1643\n3472\n1398\n1246\n2644\n996\n1023\n\n\n67\n2013\nPROVINSI DKI JAKARTA\nJAKARTA UTARA\nKOJA\nRAWA BADAK SELATAN\n1.33\n35441\n3910\n2420\n2294\n4714\n2626\n2681\n5307\n2239\n2110\n4349\n1925\n1641\n3566\n1423\n1339\n2762\n1036\n1121\n\n\n3\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU SLT\nP. UNTUNG JAWA\n0.59\n3625\n199\n185\n178\n176\n162\n139\n100\n119\n97\n83\n58\n56\n40\n54\n26\n27\n16\n13\n\n\n0\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU UTR\nP. PANGGANG\n0.91\n6779\n231\n235\n233\n210\n171\n158\n137\n126\n98\n106\n72\n65\n36\n33\n33\n20\n13\n27\n\n\n5\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU SLT\nP. PARI\n1.39\n1968\n113\n112\n108\n80\n66\n62\n61\n63\n37\n36\n32\n26\n21\n14\n17\n11\n8\n7\n\n\n\n\n\n\n\n\n#Selanjutnya akan dibuat 3 kelompok umur\ndf_baru.columns\n\nIndex(['TAHUN', 'NAMA PROVINSI', 'NAMA KABUPATEN/KOTA', 'NAMA KECAMATAN',\n       'NAMA KELURAHAN', 'LUAS WILAYAH (KM2)', 'KEPADATAN (JIWA/KM2)',\n       '35-39 Laki-Laki', '35-39 Perempuan', '40-44 Laki-Laki',\n       '40-44 Perempuan', '45-49 Laki-Laki', '45-49 Perempuan',\n       '50-54 Laki-Laki', '50-54 Perempuan', '55-59 Laki-Laki',\n       '55-59 Perempuan', '60-64 Laki-Laki', '60-64 Perempuan',\n       '65-69 Laki-Laki', '65-69 Perempuan', '70-74 Laki-Laki',\n       '70-74 Perempuan', '&gt;75 Laki-Laki', '&gt;75  Perempuan'],\n      dtype='object')\n\n\n\ndf_baru.columns[7:13]\n\nIndex(['35-39 Laki-Laki', '35-39 Perempuan', '40-44 Laki-Laki',\n       '40-44 Perempuan', '45-49 Laki-Laki', '45-49 Perempuan'],\n      dtype='object')\n\n\n\ndf_baru[df_baru.columns[7:13]].head()\n\n\n\n\n\n\n\n\n35-39 Laki-Laki\n35-39 Perempuan\n40-44 Laki-Laki\n40-44 Perempuan\n45-49 Laki-Laki\n45-49 Perempuan\n\n\n\n\n215\n1361\n1154\n1236\n1050\n1016\n1029\n\n\n204\n1377\n1336\n1271\n1337\n1173\n1144\n\n\n205\n1101\n1061\n1061\n1001\n934\n879\n\n\n142\n1239\n1289\n1238\n1198\n1080\n1007\n\n\n150\n208\n206\n186\n192\n181\n205\n\n\n\n\n\n\n\n\ndef kel1(x):\n  w = df_baru.columns[7:13]\n  wow = x[w[0]]+x[w[1]]+x[w[2]]+x[w[3]]+x[w[4]]+x[w[5]]   #kolom 1 ditambah kolom 2 dsb\n  return wow\n\ndef kel2(x):\n  w = df_baru.columns[13:19]\n  wow = x[w[0]]+x[w[1]]+x[w[2]]+x[w[3]]+x[w[4]]+x[w[5]]\n  return wow\n\ndef kel3(x):\n  w = df_baru.columns[19:25]\n  wow = x[w[0]]+x[w[1]]+x[w[2]]+x[w[3]]+x[w[4]]+x[w[5]]\n  return wow\n\n\ndf_baru['kelompok 1'] = df_baru.apply(lambda x: kel1(x), axis=1)\ndf_baru['kelompok 2'] = df_baru.apply(lambda x: kel2(x), axis=1)\ndf_baru['kelompok 3'] = df_baru.apply(lambda x: kel3(x), axis=1)\n\n\ndf_baru.head()\n\n\n\n\n\n\n\n\nTAHUN\nNAMA PROVINSI\nNAMA KABUPATEN/KOTA\nNAMA KECAMATAN\nNAMA KELURAHAN\nLUAS WILAYAH (KM2)\nKEPADATAN (JIWA/KM2)\n35-39 Laki-Laki\n35-39 Perempuan\n40-44 Laki-Laki\n40-44 Perempuan\n45-49 Laki-Laki\n45-49 Perempuan\n50-54 Laki-Laki\n50-54 Perempuan\n55-59 Laki-Laki\n55-59 Perempuan\n60-64 Laki-Laki\n60-64 Perempuan\n65-69 Laki-Laki\n65-69 Perempuan\n70-74 Laki-Laki\n70-74 Perempuan\n&gt;75 Laki-Laki\n&gt;75 Perempuan\nkelompok 1\nkelompok 2\nkelompok 3\n\n\n\n\n215\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nJATINEGARA\nKAMPUNG MELAYU\n0.48\n63973\n1361\n1154\n1236\n1050\n1016\n1029\n864\n848\n694\n601\n436\n409\n205\n294\n151\n173\n121\n159\n6846\n3852\n1103\n\n\n204\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nMATRAMAN\nKAYU MANIS\n0.57\n52740\n1377\n1336\n1271\n1337\n1173\n1144\n868\n899\n676\n690\n450\n450\n249\n276\n172\n219\n111\n185\n7638\n4033\n1212\n\n\n205\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nMATRAMAN\nPAL MERIAM\n0.65\n36818\n1101\n1061\n1061\n1001\n934\n879\n790\n722\n577\n563\n351\n398\n181\n240\n151\n169\n131\n204\n6037\n3401\n1076\n\n\n142\n2013\nPROVINSI DKI JAKARTA\nJAKARTA SELATAN\nTEBET\nMANGGARAI SELATAN\n0.51\n52659\n1239\n1289\n1238\n1198\n1080\n1007\n790\n757\n607\n634\n361\n414\n212\n288\n218\n229\n127\n178\n7051\n3563\n1252\n\n\n150\n2013\nPROVINSI DKI JAKARTA\nJAKARTA SELATAN\nSETIA BUDI\nGUNTUR\n0.65\n7174\n208\n206\n186\n192\n181\n205\n168\n152\n140\n157\n114\n115\n62\n78\n55\n45\n37\n84\n1178\n846\n361\n\n\n\n\n\n\n\n\n#sederhanakan dataframe dg column yang kita mau saja\ndf_baru = df_baru[['NAMA KABUPATEN/KOTA','NAMA KECAMATAN','NAMA KELURAHAN','kelompok 1','kelompok 2','kelompok 3']]\ndf_baru.head()\n\n\n\n\n\n\n\n\nNAMA KABUPATEN/KOTA\nNAMA KECAMATAN\nNAMA KELURAHAN\nkelompok 1\nkelompok 2\nkelompok 3\n\n\n\n\n215\nJAKARTA TIMUR\nJATINEGARA\nKAMPUNG MELAYU\n6846\n3852\n1103\n\n\n204\nJAKARTA TIMUR\nMATRAMAN\nKAYU MANIS\n7638\n4033\n1212\n\n\n205\nJAKARTA TIMUR\nMATRAMAN\nPAL MERIAM\n6037\n3401\n1076\n\n\n142\nJAKARTA SELATAN\nTEBET\nMANGGARAI SELATAN\n7051\n3563\n1252\n\n\n150\nJAKARTA SELATAN\nSETIA BUDI\nGUNTUR\n1178\n846\n361\n\n\n\n\n\n\n\n\n#buat kolom untuk persentase lansia\ndf_baru['persentase lansia'] = df_baru['kelompok 3'] / (df_baru['kelompok 1']+df_baru['kelompok 2']+df_baru['kelompok 3'])\ndf_baru.head()\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n\n\n\n\n\n\n\n\n\nNAMA KABUPATEN/KOTA\nNAMA KECAMATAN\nNAMA KELURAHAN\nkelompok 1\nkelompok 2\nkelompok 3\npersentase lansia\n\n\n\n\n215\nJAKARTA TIMUR\nJATINEGARA\nKAMPUNG MELAYU\n6846\n3852\n1103\n0.093467\n\n\n204\nJAKARTA TIMUR\nMATRAMAN\nKAYU MANIS\n7638\n4033\n1212\n0.094077\n\n\n205\nJAKARTA TIMUR\nMATRAMAN\nPAL MERIAM\n6037\n3401\n1076\n0.102340\n\n\n142\nJAKARTA SELATAN\nTEBET\nMANGGARAI SELATAN\n7051\n3563\n1252\n0.105512\n\n\n150\nJAKARTA SELATAN\nSETIA BUDI\nGUNTUR\n1178\n846\n361\n0.151363\n\n\n\n\n\n\n\n\n#urutkan dari terbesar\ndf_baru.sort_values(by='persentase lansia', ascending= False, inplace = True)\ndf_baru.head()\n\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n\n\n\n\n\n\n\n\n\nNAMA KABUPATEN/KOTA\nNAMA KECAMATAN\nNAMA KELURAHAN\nkelompok 1\nkelompok 2\nkelompok 3\npersentase lansia\n\n\n\n\n99\nJAKARTA BARAT\nTAMAN SARI\nKEAGUNGAN\n7621\n7733\n6043\n0.282423\n\n\n102\nJAKARTA BARAT\nTAMBORA\nTAMBORA\n4471\n4474\n3518\n0.282276\n\n\n61\nJAKARTA UTARA\nTANJUNG PRIOK\nWARAKAS\n19882\n21134\n14368\n0.259425\n\n\n65\nJAKARTA UTARA\nKOJA\nRAWA BADAK UTARA\n15649\n15985\n10779\n0.254144\n\n\n103\nJAKARTA BARAT\nTAMBORA\nKALI ANYAR\n12055\n11250\n7579\n0.245402\n\n\n\n\n\n\n\n\n### 'Keagungan', 'Tambora', 'Warakas', 'Rawa Badak Utara', 'Kali Anyar' menjadi 5 kelurahan pertama yang diprioritaskan untuk vaksinasi"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/eda2023genap.html",
    "href": "semuahalaman/modulprak/2023/genap/eda/eda2023genap.html",
    "title": "Praktikum Eksplorasi/EDA dan Visualisasi Data 2023 Genap (Kurikulum 2020)",
    "section": "",
    "text": "Kembali ke Praktikum\nIni adalah versi website (yang baru dibuat setelah semester ini berakhir) dari modul yang ada di link berikut: https://drive.google.com/drive/folders/1p9WCjmvWLHNUsxEfi0NCHFZEvqjj16nI?usp=sharing\n\nPertemuan 1: Modul 1\nPertemuan 2 & 3: Modul 2\nPertemuan 4: Modul 3\nPertemuan 5: Modul 4"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Tugas1.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Tugas1.html",
    "title": "Tugas 1 Praktikum Struktur Data: Array, Linked List, OOP",
    "section": "",
    "text": "Kembali ke Struktur Data (dengan Python)\nTugas ini diberikan pada hari dan tanggal: Minggu, 22 Oktober 2023\nLink soal dan petunjuk tugas (yaitu link menuju halaman ini):\nhttps://bit.ly/SoalTugas1PrakStrukdat2023Ganjil\n\n\n\nKerjakan secara individu.\nKerjakan tugas ini menggunakan bahasa pemrograman Python dengan file format berupa interactive Python notebook (yaitu file berbentuk .ipynb BUKAN .py), yang bisa dibuat misalnya menggunakan Jupyter Notebook atau Google Colaboratory.\nHarap sertakan penjelasan untuk setiap variabel yang digunakan dan setiap proses secara singkat di sebelah (atas/bawah/kanan) barisnya (dengan comment, #). Selain itu, sertakan juga penjelasan kode (yang bisa mencakupi idenya apa, bagaimana cara eksekusinya, atau tentang algoritma yang digunakan) pada cell di sebelah (atas/bawah) kode.\nFormat nama file untuk Tugas 1 ini adalah:\nKelas SIAK_Tugas1PrakStrukdat_Nama Lengkap_NPM.ipynb\nContoh penamaan yang benar:\nKelas C_Tugas1PrakStrukdat_Charles Antony Richard Hoare_2234567890.ipynb\nPengumpulan Tugas 1 dilakukan ke Google Forms berikut ini:\nhttps://bit.ly/KumpulTugas1PrakStrukdat2023Ganjil\nApabila ada yang ingin direvisi setelah pengumpulan, lakukan pengumpulan ulang di Google Forms yang sama, tambahkan keterangan bahwa ada revisi, dan tambahkan kata “revisi” pada bagian akhir nama file, contohnya menjadi\nKelas C_Tugas1PrakStrukdat_Charles Antony Richard Hoare_2234567890_revisi.ipynb\nKelas C_Tugas1PrakStrukdat_Charles Antony Richard Hoare_2234567890_revisi2.ipynb\nKelas C_Tugas1PrakStrukdat_Charles Antony Richard Hoare_2234567890_revisi3.ipynb\n(Revisi boleh dilakukan berkali-kali.)\nDengan durasi pengerjaan sekitar 2 (dua) minggu, tenggat waktu (deadline) pengumpulan Tugas 1 ini (termasuk revisi) adalah Minggu, 5 November 2023, 23.59 WIB.\nSesuai standar Universitas Indonesia, plagiarisme dilarang keras dan bisa menyebabkan nilai tugas praktikum menjadi nol untuk semua pihak yang terlibat, tanpa peringatan apapun. Namun, Anda boleh langsung menggunakan kode yang ada di modul praktikum.\nModule atau package Python yang boleh digunakan (di-import) untuk Tugas 1 ini hanyalah numpy dan graphviz. Apabila Anda berniat ingin menggunakan module lain, harap konfirmasikan ke narahubung terlebih dahulu (bisa saja diperbolehkan).\nNarahubung untuk Tugas 1 Praktikum Struktur Data adalah:\nBisma Rohpanca Joyosumarto (ID LINE: bisma_joyosumarto)\nSilakan hubungi narahubung di atas apabila ada yang ingin ditanyakan atau dikonfirmasikan.\n\n\n\n\nUntuk masing-masing dari kelima soal berikut ini, setelah menulis kode Anda, buatlah contoh running atau contoh penggunaannya (angka/data yang digunakan tidak harus sama dengan contoh di soal).\nNilai maksimal apabila tiap linked list yang terlibat di contoh running yang Anda buat juga ditampilkan dengan print_all dan juga graphviz.\n\nMenambahkan elemen array ke ujung linked list\n\nDiberikan suatu linked list dan suatu array atau list, buatlah fungsi add_array_to_sllist yang menambahkan masing-masing elemen array atau list tersebut ke ujung linked list.\nMengingat bahwa insertion pada ujung linked list adalah O(n), bagaimana kompleksitas waktu (time complexity) dari fungsi yang Anda buat? Berikan argumen atas jawaban Anda (tidak harus berupa tabel running time, boleh berupa paragraf).\n\nNilai maksimal apabila Anda berhasil membuat fungsi yang O(n) (atau lebih tepatnya O(n) + O(m), di mana n adalah ukuran mula-mula dari linked list dan m adalah ukuran array).\nContoh penggunaan fungsi:\n&gt;&gt;&gt; linkedlist1 = SLList()\n&gt;&gt;&gt; linkedlist1.head = SLNode(89)\n&gt;&gt;&gt; linkedlist1.head.next = SLNode(43)\n&gt;&gt;&gt; array1 = np.array([64, -12, 35, 98])\n&gt;&gt;&gt; add_array_to_sllist(linkedlist1, array1)\n&gt;&gt;&gt; linkedlist1.print_all()\nhead -&gt; 89 -&gt; 43 -&gt; 64 -&gt; -12 -&gt; 35 -&gt; 98 -&gt; None\nLinked list menjadi array\nDiberikan suatu linked list, buatlah fungsi sllist_to_array yang mengubahnya menjadi array. Nilai maksimal apabila definisi fungsi tidak melibatkan fitur .append maupun comprehension (baik list comprehension, set comprehension, maupun tuple comprehension).\nContoh penggunaan fungsi:\n&gt;&gt;&gt; linkedlist1 = SLList()\n&gt;&gt;&gt; array1 = np.array([10, 30, -47, 73])\n&gt;&gt;&gt; add_array_to_sllist(linkedlist1, array1)\n&gt;&gt;&gt; linkedlist1.print_all()\nhead -&gt; 10 -&gt; 30 -&gt; -47 -&gt; 73 -&gt; None\n&gt;&gt;&gt; array2 = sllist_to_array(linkedlist1)\n&gt;&gt;&gt; print(array2)\n[ 10  30 -47  73]\nSorting suatu linked list\n\nDiberikan suatu linked list, buatlah fungsi get_sorted_sllist yang mengembalikan (return) linked list tersebut dalam keadaan sudah terurut, di mana node dengan nilai data terkecil lah yang ditunjuk oleh head (sedangkan node dengan data terbesar ada di ujung linked list).\nBagaimana kompleksitas waktu (time complexity) dari fungsi yang Anda buat? Berikan argumen atas jawaban Anda (tidak harus berupa tabel running time, boleh berupa paragraf).\n\nNilai maksimal apabila\n\nAnda berhasil membuat fungsi yang O(n log n)\nFungsi yang Anda buat menghasilkan linked list baru tanpa mengubah linked list yang menjadi input\n\nContoh penggunaan fungsi:\n&gt;&gt;&gt; linkedlist1 = SLList()\n&gt;&gt;&gt; array1 = np.array([10, -3, 97, -48])\n&gt;&gt;&gt; add_array_to_sllist(linkedlist1, array1)\n&gt;&gt;&gt; linkedlist2 = get_sorted_sllist(linkedlist1)\n&gt;&gt;&gt; linkedlist2.print_all()\nhead -&gt; -48 -&gt; -3 -&gt; 10 -&gt; 97 -&gt; None\nHint: untuk soal ini, tidak ada larangan, linked list akan diperlakukan bagaimana hingga nantinya memperoleh linked list yang sudah terurut. Bahkan, apabila misalnya linked list ingin diubah menjadi bentuk lain terlebih dahulu, yang nantinya diubah kembali menjadi linked list, itu juga tidak masalah. Selama hasilnya adalah linked list yang terurut, tidak ada cara yang salah. Silakan berkreativitas :)\nMembuat method\nModifikasi definisi class linked list agar fungsi yang telah Anda buat di soal nomor 1, 2, dan 3 bisa digunakan sebagai method, misalnya bernama add_array, to_array, dan get_sorted\nContoh penggunaan method:\n&gt;&gt;&gt; linkedlist1 = SLList()\n&gt;&gt;&gt; array1 = np.array([81, -45, -27, 39])\n&gt;&gt;&gt; linkedlist1.add_array(array1)\n&gt;&gt;&gt; linkedlist2 = linkedlist1.get_sorted()\n&gt;&gt;&gt; array2 = linkedlist2.to_array()\n&gt;&gt;&gt; print(array2)\n[-45 -27  39  81]\nPenggabungan linked list dengan +\nModifikasi definisi class linked list agar dua linked list bisa “ditambahkan”. Berikut contoh yang berhasil:\n&gt;&gt;&gt; linkedlist1 = SLList()\n&gt;&gt;&gt; linkedlist1.add_array([9, 6, 2, 7])\n&gt;&gt;&gt; linkedlist2 = SLList()\n&gt;&gt;&gt; linkedlist2.add_array([10, 58, 3])\n&gt;&gt;&gt; linkedlist3 = linkedlist1 + linkedlist2\n&gt;&gt;&gt; linkedlist3.print_all()\nhead -&gt; 9 -&gt; 6 -&gt; 2 -&gt; 7 -&gt; 10 -&gt; 58 -&gt; 3 -&gt; None\nHint: gunakan operator overloading."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Tugas1.html#petunjuk-umum",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Tugas1.html#petunjuk-umum",
    "title": "Tugas 1 Praktikum Struktur Data: Array, Linked List, OOP",
    "section": "",
    "text": "Kerjakan secara individu.\nKerjakan tugas ini menggunakan bahasa pemrograman Python dengan file format berupa interactive Python notebook (yaitu file berbentuk .ipynb BUKAN .py), yang bisa dibuat misalnya menggunakan Jupyter Notebook atau Google Colaboratory.\nHarap sertakan penjelasan untuk setiap variabel yang digunakan dan setiap proses secara singkat di sebelah (atas/bawah/kanan) barisnya (dengan comment, #). Selain itu, sertakan juga penjelasan kode (yang bisa mencakupi idenya apa, bagaimana cara eksekusinya, atau tentang algoritma yang digunakan) pada cell di sebelah (atas/bawah) kode.\nFormat nama file untuk Tugas 1 ini adalah:\nKelas SIAK_Tugas1PrakStrukdat_Nama Lengkap_NPM.ipynb\nContoh penamaan yang benar:\nKelas C_Tugas1PrakStrukdat_Charles Antony Richard Hoare_2234567890.ipynb\nPengumpulan Tugas 1 dilakukan ke Google Forms berikut ini:\nhttps://bit.ly/KumpulTugas1PrakStrukdat2023Ganjil\nApabila ada yang ingin direvisi setelah pengumpulan, lakukan pengumpulan ulang di Google Forms yang sama, tambahkan keterangan bahwa ada revisi, dan tambahkan kata “revisi” pada bagian akhir nama file, contohnya menjadi\nKelas C_Tugas1PrakStrukdat_Charles Antony Richard Hoare_2234567890_revisi.ipynb\nKelas C_Tugas1PrakStrukdat_Charles Antony Richard Hoare_2234567890_revisi2.ipynb\nKelas C_Tugas1PrakStrukdat_Charles Antony Richard Hoare_2234567890_revisi3.ipynb\n(Revisi boleh dilakukan berkali-kali.)\nDengan durasi pengerjaan sekitar 2 (dua) minggu, tenggat waktu (deadline) pengumpulan Tugas 1 ini (termasuk revisi) adalah Minggu, 5 November 2023, 23.59 WIB.\nSesuai standar Universitas Indonesia, plagiarisme dilarang keras dan bisa menyebabkan nilai tugas praktikum menjadi nol untuk semua pihak yang terlibat, tanpa peringatan apapun. Namun, Anda boleh langsung menggunakan kode yang ada di modul praktikum.\nModule atau package Python yang boleh digunakan (di-import) untuk Tugas 1 ini hanyalah numpy dan graphviz. Apabila Anda berniat ingin menggunakan module lain, harap konfirmasikan ke narahubung terlebih dahulu (bisa saja diperbolehkan).\nNarahubung untuk Tugas 1 Praktikum Struktur Data adalah:\nBisma Rohpanca Joyosumarto (ID LINE: bisma_joyosumarto)\nSilakan hubungi narahubung di atas apabila ada yang ingin ditanyakan atau dikonfirmasikan."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Tugas1.html#soal",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Tugas1.html#soal",
    "title": "Tugas 1 Praktikum Struktur Data: Array, Linked List, OOP",
    "section": "",
    "text": "Untuk masing-masing dari kelima soal berikut ini, setelah menulis kode Anda, buatlah contoh running atau contoh penggunaannya (angka/data yang digunakan tidak harus sama dengan contoh di soal).\nNilai maksimal apabila tiap linked list yang terlibat di contoh running yang Anda buat juga ditampilkan dengan print_all dan juga graphviz.\n\nMenambahkan elemen array ke ujung linked list\n\nDiberikan suatu linked list dan suatu array atau list, buatlah fungsi add_array_to_sllist yang menambahkan masing-masing elemen array atau list tersebut ke ujung linked list.\nMengingat bahwa insertion pada ujung linked list adalah O(n), bagaimana kompleksitas waktu (time complexity) dari fungsi yang Anda buat? Berikan argumen atas jawaban Anda (tidak harus berupa tabel running time, boleh berupa paragraf).\n\nNilai maksimal apabila Anda berhasil membuat fungsi yang O(n) (atau lebih tepatnya O(n) + O(m), di mana n adalah ukuran mula-mula dari linked list dan m adalah ukuran array).\nContoh penggunaan fungsi:\n&gt;&gt;&gt; linkedlist1 = SLList()\n&gt;&gt;&gt; linkedlist1.head = SLNode(89)\n&gt;&gt;&gt; linkedlist1.head.next = SLNode(43)\n&gt;&gt;&gt; array1 = np.array([64, -12, 35, 98])\n&gt;&gt;&gt; add_array_to_sllist(linkedlist1, array1)\n&gt;&gt;&gt; linkedlist1.print_all()\nhead -&gt; 89 -&gt; 43 -&gt; 64 -&gt; -12 -&gt; 35 -&gt; 98 -&gt; None\nLinked list menjadi array\nDiberikan suatu linked list, buatlah fungsi sllist_to_array yang mengubahnya menjadi array. Nilai maksimal apabila definisi fungsi tidak melibatkan fitur .append maupun comprehension (baik list comprehension, set comprehension, maupun tuple comprehension).\nContoh penggunaan fungsi:\n&gt;&gt;&gt; linkedlist1 = SLList()\n&gt;&gt;&gt; array1 = np.array([10, 30, -47, 73])\n&gt;&gt;&gt; add_array_to_sllist(linkedlist1, array1)\n&gt;&gt;&gt; linkedlist1.print_all()\nhead -&gt; 10 -&gt; 30 -&gt; -47 -&gt; 73 -&gt; None\n&gt;&gt;&gt; array2 = sllist_to_array(linkedlist1)\n&gt;&gt;&gt; print(array2)\n[ 10  30 -47  73]\nSorting suatu linked list\n\nDiberikan suatu linked list, buatlah fungsi get_sorted_sllist yang mengembalikan (return) linked list tersebut dalam keadaan sudah terurut, di mana node dengan nilai data terkecil lah yang ditunjuk oleh head (sedangkan node dengan data terbesar ada di ujung linked list).\nBagaimana kompleksitas waktu (time complexity) dari fungsi yang Anda buat? Berikan argumen atas jawaban Anda (tidak harus berupa tabel running time, boleh berupa paragraf).\n\nNilai maksimal apabila\n\nAnda berhasil membuat fungsi yang O(n log n)\nFungsi yang Anda buat menghasilkan linked list baru tanpa mengubah linked list yang menjadi input\n\nContoh penggunaan fungsi:\n&gt;&gt;&gt; linkedlist1 = SLList()\n&gt;&gt;&gt; array1 = np.array([10, -3, 97, -48])\n&gt;&gt;&gt; add_array_to_sllist(linkedlist1, array1)\n&gt;&gt;&gt; linkedlist2 = get_sorted_sllist(linkedlist1)\n&gt;&gt;&gt; linkedlist2.print_all()\nhead -&gt; -48 -&gt; -3 -&gt; 10 -&gt; 97 -&gt; None\nHint: untuk soal ini, tidak ada larangan, linked list akan diperlakukan bagaimana hingga nantinya memperoleh linked list yang sudah terurut. Bahkan, apabila misalnya linked list ingin diubah menjadi bentuk lain terlebih dahulu, yang nantinya diubah kembali menjadi linked list, itu juga tidak masalah. Selama hasilnya adalah linked list yang terurut, tidak ada cara yang salah. Silakan berkreativitas :)\nMembuat method\nModifikasi definisi class linked list agar fungsi yang telah Anda buat di soal nomor 1, 2, dan 3 bisa digunakan sebagai method, misalnya bernama add_array, to_array, dan get_sorted\nContoh penggunaan method:\n&gt;&gt;&gt; linkedlist1 = SLList()\n&gt;&gt;&gt; array1 = np.array([81, -45, -27, 39])\n&gt;&gt;&gt; linkedlist1.add_array(array1)\n&gt;&gt;&gt; linkedlist2 = linkedlist1.get_sorted()\n&gt;&gt;&gt; array2 = linkedlist2.to_array()\n&gt;&gt;&gt; print(array2)\n[-45 -27  39  81]\nPenggabungan linked list dengan +\nModifikasi definisi class linked list agar dua linked list bisa “ditambahkan”. Berikut contoh yang berhasil:\n&gt;&gt;&gt; linkedlist1 = SLList()\n&gt;&gt;&gt; linkedlist1.add_array([9, 6, 2, 7])\n&gt;&gt;&gt; linkedlist2 = SLList()\n&gt;&gt;&gt; linkedlist2.add_array([10, 58, 3])\n&gt;&gt;&gt; linkedlist3 = linkedlist1 + linkedlist2\n&gt;&gt;&gt; linkedlist3.print_all()\nhead -&gt; 9 -&gt; 6 -&gt; 2 -&gt; 7 -&gt; 10 -&gt; 58 -&gt; 3 -&gt; None\nHint: gunakan operator overloading."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09a.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09a.html",
    "title": "Modul 9a Struktur Data: A-B Tree dan variasinya (B-Tree, 2-3 Tree, dsb)",
    "section": "",
    "text": "Kembali ke Struktur Data (dengan Python)\n\nimport numpy as np\nimport graphviz as gv\n\n\n\nA-B Tree, terkadang disebut \\((a,b)\\)-tree di mana \\(a, b \\in \\mathbb{Z}\\) dengan \\(2 \\le a \\le \\frac{b+1}{2}\\), adalah sejenis tree yang memenuhi sifat-sifat berikut:\n\nTiap node bisa menyimpan sejumlah key (atau data), maksimal sebanyak \\((b-1)\\)\nRoot (kalau tidak kosong) menyimpan minimal satu key\nSemua node selain root menyimpan sejumlah key, minimal sebanyak \\((a-1)\\)\nTiap node bisa memiliki sejumlah child, maksimal sebanyak \\(b\\)\nRoot diharapkan memiliki minimal dua child\nTiap internal node (yaitu selain leaf dan root) memiliki sejumlah child, minimal sebanyak \\(a\\)\nSemua leaf node ada di level yang sama\n\n\nclass ABtreeNode:\n    def __init__(self, b, key_dtype=object, emptydata=None):\n        self.keys = np.empty(b-1, dtype=key_dtype)\n        self.children = np.empty(b, dtype=ABtreeNode) # menyimpan pointer\n        self.emptydata = emptydata\n        self.clear_keys()\n        self.clear_children()\n\n    def clear_keys(self):\n        for i in range(len(self.keys)):\n            self.keys[i] = self.emptydata\n    \n    def clear_children(self):\n        for i in range(len(self.children)):\n            self.children[i] = None\n\n    def is_key_idx_empty(self, idx):\n        if self.keys[idx] == self.emptydata:\n            return True\n        else:\n            return False\n    \n    def is_children_idx_empty(self, idx):\n        if self.children[idx] == None:\n            return True\n        else:\n            return False\n\n    def is_full_keys(self):\n        # jika key terakhir tidak kosong, maka keys sudah penuh\n        return ( not self.is_key_idx_empty(len(self.children)-1) )\n\n    def is_leaf(self):\n        # jika pointer pertama saja sudah kosong, berarti tidak punya child\n        return self.is_children_idx_empty(0)\n\n    def get_nonempty_keys_amount(self):\n        all_keys_amount = len(self.keys)\n        n = 0\n        while (n &lt; all_keys_amount) and (not self.is_key_idx_empty(n)):\n            n += 1\n        return n\n    \n    # method ini sebaiknya hanya digunakan pada leaf node\n    def insert_key_get_carry(self, newkey, right_biased=False):\n        carry = self.emptydata\n        if self.is_full_keys():\n            n = len(self.keys)\n\n            # cari indeks yang layak untuk menyisipkan newkey\n            newkey_idx = 0\n            while ((newkey_idx &lt; n) and\n                   (self.keys[newkey_idx] &lt; newkey)):\n                newkey_idx += 1\n            \n            # seandainya newkey sudah disisipkan, tentukan indeks dari median\n            med_idx = n/2\n            if (not right_biased):\n                med_idx = int(np.floor(med_idx))\n            else:\n                med_idx = int(np.ceil(med_idx))\n            \n            # lakukan penyisipan sekaligus menentukan elemen carry (buangan)\n            if (med_idx &lt; newkey_idx):\n                carry = self.keys[med_idx] # ambil elemen buangan\n                for i in range(med_idx, newkey_idx): # geser elemen array\n                    self.keys[i] = self.keys[i+1]\n                self.keys[newkey_idx] = newkey # sisipkan\n            elif (med_idx == newkey_idx):\n                carry = newkey\n                # ternyata yang akan disisipkan ialah yang akan menjadi buangan\n                # sehingga array keys tidak perlu dimodifikasi\n            else: # med_idx &gt; newkey_idx\n                carry = self.keys[med_idx] # ambil elemen buangan\n                for i in range(med_idx, newkey_idx, -1): # geser elemen array\n                    self.keys[i] = self.keys[i-1]\n                self.keys[newkey_idx] = newkey # sisipkan\n            return carry\n        # jika array keys tidak penuh\n        n = self.get_nonempty_keys_amount()\n        self.keys[n] = newkey\n        # sekali bubble sort dari kanan ke kiri\n        i = n\n        while (i &gt; 0) and (self.keys[i-1] &gt; self.keys[i]):\n            # tukar\n            temp = self.keys[i-1]\n            self.keys[i-1] = self.keys[i]\n            self.keys[i] = temp\n            # lanjut ke elemen sebelah kirinya\n            i -= 1\n        return carry # sebenarnya self.emptydata, tapi gapapa biar konsisten\n\n\nclass LinkedABtree:\n    def __init__(self, a, b, key_dtype=object, emptydata=None):\n        self.root = None\n        self.a = a\n        self.b = b\n        self.key_dtype = key_dtype\n        self.emptydata = emptydata\n    \n    def is_empty(self):\n        if self.root == None:\n            return True\n        else:\n            return False\n    \n    def search(self, x):\n        if self.is_empty():\n            print(\"Error search: tree kosong\")\n            return None\n        temp = self.root\n        i = 0\n        n = temp.get_nonempty_keys_amount()\n        while (temp != None):\n            if (self.keys[i] == x):\n                return x\n            elif (i == 0 and x &lt; self.keys[i]):\n                temp = temp.children[0]\n                i = 0\n                if (temp != None):\n                    n = temp.get_nonempty_keys_amount()\n            elif (i == n-1) or (self.keys[i] &lt; x and x &lt; self.keys[i+1]):\n                temp = temp.children[i+1]\n                i = 0\n                if (temp != None):\n                    n = temp.get_nonempty_keys_amount()\n            else:\n                i += 1\n        # tidak ditemukan\n        return None\n\n    def split_node(self, node, newkey, right_biased=False):\n        old_n = node.get_nonempty_keys_amount()\n        new_n = old_n + 1\n        med_idx = (old_n)/2 # indeks untuk median\n        if (not right_biased): # teknik left-biased\n            med_idx = int(np.floor(med_idx))\n        else: # teknik right-biased\n            med_idx = int(np.ceil(med_idx))\n        \n        old_keys = node.keys\n        old_children = node.children\n        node.clear_keys()\n        node.clear_children()\n\n        left_child = ABtreeNode(b=self.b, key_dtype=self.key_dtype,\n                                emptydata=self.emptydata)\n        right_child = ABtreeNode(b=self.b, key_dtype=self.key_dtype,\n                                 emptydata=self.emptydata)\n        \n        newkey_idx = 0\n        while newkey_idx &lt; len(old_keys):\n            if (old_keys[i] &lt; newkey_idx):\n                newkey_idx += 1\n        new_keys = list(old_keys)\n        new_keys.insert(newkey_idx, newkey)\n        # sisipkan newkey di indeks newkey_idx\n\n        i = 0\n        while (i &lt; med_idx): # hingga sebelum posisi median\n            left_child.keys[i] = new_keys[i]\n            i += 1\n        node.keys[0] = new_keys[i] # khusus median, di root\n        i += 1\n        while (i &lt; new_n): # sisanya\n            right_child.keys[i-med_idx-1] = new_keys[i]\n            i += 1\n        \n        i = 0\n        while (i &lt; med_idx+1): # hingga pointer di sebelah kiri key median\n            left_child.children[i] = old_children[i]\n            i += 1\n        while (i &lt; old_n+1): # banyaknya pointer = (banyaknya key) + 1\n            right_child.children[i-med_idx-1] = old_children[i]\n            i += 1\n        \n        node.children[0] = left_child\n        node.children[1] = right_child\n        return node\n\n    def insert(self, newkey, right_biased=False):\n        if self.search(newkey) == None:\n            self.root = self.insert_rec(newkey, right_biased=right_biased,\n                                        current=self.root)\n        else:\n            print(\"Error insert: key sudah ada di tree, yaitu\", newkey)\n    def insert_rec(self, newkey, right_biased, current):\n        if current == None:\n            newnode = ABtreeNode(b=self.b, key_dtype=self.key_dtype,\n                                 emptydata=self.emptydata)\n            newnode.keys[0] = newkey\n            return newnode\n        \n        # variabel untuk menyimpan key \"buangan\" dari child node\n        # (dan key buangan itu nantinya akan dicoba dimasukkan ke keys)\n        # sementara kita buat \"kosong\" dulu karena belum ada buangan\n        carry = self.emptydata\n\n        n = current.get_nonempty_keys_amount()\n        if (not current.is_leaf()): # jika bukan leaf, akan lanjut ke child nya\n            if (newkey &lt; self.keys[0]):\n                current.children[0] = self.insert_rec(\n                    newkey, right_biased=right_biased,\n                    current=current.children[0]\n                    )\n            else:\n                for i in range(n):\n                    if ((i == n-1) or\n                        (self.keys[i] &lt; newkey and newkey &lt; self.keys[i+1])):\n                        current.children[i+1] = self.insert_rec(\n                            newkey, right_biased=right_biased, \n                            current=current.children[i+1]\n                            )\n                        break\n        # selain itu, jika current adalah leaf node\n        elif current.is_full_keys(): # jika current penuh, split\n            left_child, right_child, carry = self.split_node(\n                node=current, newkey=newkey, right_biased=right_biased\n            )\n            newkey_idx = current.try_insert_key(carry)\n            carry = None\n        else: # jika current (sebagai leaf node) tidak penuh\n            current.try_insert_key(newkey)\n        \n        return current\n\n    def delete(self, x):\n        pass\n\n\n\n\nB-Tree, berorder misalnya m, adalah sejenis A-B Tree atau \\((a,b)\\)-tree dengan\n\\[b=m\\] \\[a = \\left\\lceil \\frac{b}{2} \\right\\rceil = \\left\\lceil \\frac{m}{2} \\right\\rceil\\]\nSehingga, untuk implementasi B-Tree, kita tinggal meng-inherit dari LinkedABtree dan memilih nilai a dan b yang sesuai berdasarkan nilai m yang diberikan.\n\nclass LinkedBtree(LinkedABtree):\n    def __init__(self, m):\n        self.b = m\n        self.a = int(np.ceil(m/2))\n    \n    def get_m(self):\n        return self.b\n\n    def set_m(self, new_m):\n        self.b = new_m\n        self.a = int(np.ceil(new_m/2))\n\n\n\n\n\n\n2-3 Tree adalah suatu B-Tree dengan \\(m=3\\).\n(Lebih umumnya, 2-3 Tree atau \\((2,3)\\)-tree adalah suatu A-B Tree dengan \\(a=2\\) dan \\(b=3\\).)\n\nclass Linked23Tree(LinkedBtree):\n    def __init__(self):\n        super().__init__(m=3)\n    \n    # nonaktifkan fitur memasang nilai m dari LinkedBtree\n    def set_m(self, new_m):\n        print(\"Error 2-3 Tree: nilai m=3 tidak boleh diubah\")\n\n\n\n\n2-4 Tree, terkadang juga disebut 2-3-4 Tree, adalah suatu B-Tree dengan \\(m=4\\).\n(Lebih umumnya, 2-4 Tree atau \\((2,4)\\)-tree adalah suatu A-B Tree dengan \\(a=2\\) dan \\(b=4\\).)\n\nclass Linked24Tree(LinkedBtree):\n    def __init__(self):\n        super().__init__(m=4)\n    \n    # nonaktifkan fitur memasang nilai m dari LinkedBtree\n    def set_m(self, new_m):\n        print(\"Error 2-4 Tree: nilai m=4 tidak boleh diubah\")"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09a.html#todo-implementasi-a-b-tree-dengan-pointer",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09a.html#todo-implementasi-a-b-tree-dengan-pointer",
    "title": "Modul 9a Struktur Data: A-B Tree dan variasinya (B-Tree, 2-3 Tree, dsb)",
    "section": "",
    "text": "A-B Tree, terkadang disebut \\((a,b)\\)-tree di mana \\(a, b \\in \\mathbb{Z}\\) dengan \\(2 \\le a \\le \\frac{b+1}{2}\\), adalah sejenis tree yang memenuhi sifat-sifat berikut:\n\nTiap node bisa menyimpan sejumlah key (atau data), maksimal sebanyak \\((b-1)\\)\nRoot (kalau tidak kosong) menyimpan minimal satu key\nSemua node selain root menyimpan sejumlah key, minimal sebanyak \\((a-1)\\)\nTiap node bisa memiliki sejumlah child, maksimal sebanyak \\(b\\)\nRoot diharapkan memiliki minimal dua child\nTiap internal node (yaitu selain leaf dan root) memiliki sejumlah child, minimal sebanyak \\(a\\)\nSemua leaf node ada di level yang sama\n\n\nclass ABtreeNode:\n    def __init__(self, b, key_dtype=object, emptydata=None):\n        self.keys = np.empty(b-1, dtype=key_dtype)\n        self.children = np.empty(b, dtype=ABtreeNode) # menyimpan pointer\n        self.emptydata = emptydata\n        self.clear_keys()\n        self.clear_children()\n\n    def clear_keys(self):\n        for i in range(len(self.keys)):\n            self.keys[i] = self.emptydata\n    \n    def clear_children(self):\n        for i in range(len(self.children)):\n            self.children[i] = None\n\n    def is_key_idx_empty(self, idx):\n        if self.keys[idx] == self.emptydata:\n            return True\n        else:\n            return False\n    \n    def is_children_idx_empty(self, idx):\n        if self.children[idx] == None:\n            return True\n        else:\n            return False\n\n    def is_full_keys(self):\n        # jika key terakhir tidak kosong, maka keys sudah penuh\n        return ( not self.is_key_idx_empty(len(self.children)-1) )\n\n    def is_leaf(self):\n        # jika pointer pertama saja sudah kosong, berarti tidak punya child\n        return self.is_children_idx_empty(0)\n\n    def get_nonempty_keys_amount(self):\n        all_keys_amount = len(self.keys)\n        n = 0\n        while (n &lt; all_keys_amount) and (not self.is_key_idx_empty(n)):\n            n += 1\n        return n\n    \n    # method ini sebaiknya hanya digunakan pada leaf node\n    def insert_key_get_carry(self, newkey, right_biased=False):\n        carry = self.emptydata\n        if self.is_full_keys():\n            n = len(self.keys)\n\n            # cari indeks yang layak untuk menyisipkan newkey\n            newkey_idx = 0\n            while ((newkey_idx &lt; n) and\n                   (self.keys[newkey_idx] &lt; newkey)):\n                newkey_idx += 1\n            \n            # seandainya newkey sudah disisipkan, tentukan indeks dari median\n            med_idx = n/2\n            if (not right_biased):\n                med_idx = int(np.floor(med_idx))\n            else:\n                med_idx = int(np.ceil(med_idx))\n            \n            # lakukan penyisipan sekaligus menentukan elemen carry (buangan)\n            if (med_idx &lt; newkey_idx):\n                carry = self.keys[med_idx] # ambil elemen buangan\n                for i in range(med_idx, newkey_idx): # geser elemen array\n                    self.keys[i] = self.keys[i+1]\n                self.keys[newkey_idx] = newkey # sisipkan\n            elif (med_idx == newkey_idx):\n                carry = newkey\n                # ternyata yang akan disisipkan ialah yang akan menjadi buangan\n                # sehingga array keys tidak perlu dimodifikasi\n            else: # med_idx &gt; newkey_idx\n                carry = self.keys[med_idx] # ambil elemen buangan\n                for i in range(med_idx, newkey_idx, -1): # geser elemen array\n                    self.keys[i] = self.keys[i-1]\n                self.keys[newkey_idx] = newkey # sisipkan\n            return carry\n        # jika array keys tidak penuh\n        n = self.get_nonempty_keys_amount()\n        self.keys[n] = newkey\n        # sekali bubble sort dari kanan ke kiri\n        i = n\n        while (i &gt; 0) and (self.keys[i-1] &gt; self.keys[i]):\n            # tukar\n            temp = self.keys[i-1]\n            self.keys[i-1] = self.keys[i]\n            self.keys[i] = temp\n            # lanjut ke elemen sebelah kirinya\n            i -= 1\n        return carry # sebenarnya self.emptydata, tapi gapapa biar konsisten\n\n\nclass LinkedABtree:\n    def __init__(self, a, b, key_dtype=object, emptydata=None):\n        self.root = None\n        self.a = a\n        self.b = b\n        self.key_dtype = key_dtype\n        self.emptydata = emptydata\n    \n    def is_empty(self):\n        if self.root == None:\n            return True\n        else:\n            return False\n    \n    def search(self, x):\n        if self.is_empty():\n            print(\"Error search: tree kosong\")\n            return None\n        temp = self.root\n        i = 0\n        n = temp.get_nonempty_keys_amount()\n        while (temp != None):\n            if (self.keys[i] == x):\n                return x\n            elif (i == 0 and x &lt; self.keys[i]):\n                temp = temp.children[0]\n                i = 0\n                if (temp != None):\n                    n = temp.get_nonempty_keys_amount()\n            elif (i == n-1) or (self.keys[i] &lt; x and x &lt; self.keys[i+1]):\n                temp = temp.children[i+1]\n                i = 0\n                if (temp != None):\n                    n = temp.get_nonempty_keys_amount()\n            else:\n                i += 1\n        # tidak ditemukan\n        return None\n\n    def split_node(self, node, newkey, right_biased=False):\n        old_n = node.get_nonempty_keys_amount()\n        new_n = old_n + 1\n        med_idx = (old_n)/2 # indeks untuk median\n        if (not right_biased): # teknik left-biased\n            med_idx = int(np.floor(med_idx))\n        else: # teknik right-biased\n            med_idx = int(np.ceil(med_idx))\n        \n        old_keys = node.keys\n        old_children = node.children\n        node.clear_keys()\n        node.clear_children()\n\n        left_child = ABtreeNode(b=self.b, key_dtype=self.key_dtype,\n                                emptydata=self.emptydata)\n        right_child = ABtreeNode(b=self.b, key_dtype=self.key_dtype,\n                                 emptydata=self.emptydata)\n        \n        newkey_idx = 0\n        while newkey_idx &lt; len(old_keys):\n            if (old_keys[i] &lt; newkey_idx):\n                newkey_idx += 1\n        new_keys = list(old_keys)\n        new_keys.insert(newkey_idx, newkey)\n        # sisipkan newkey di indeks newkey_idx\n\n        i = 0\n        while (i &lt; med_idx): # hingga sebelum posisi median\n            left_child.keys[i] = new_keys[i]\n            i += 1\n        node.keys[0] = new_keys[i] # khusus median, di root\n        i += 1\n        while (i &lt; new_n): # sisanya\n            right_child.keys[i-med_idx-1] = new_keys[i]\n            i += 1\n        \n        i = 0\n        while (i &lt; med_idx+1): # hingga pointer di sebelah kiri key median\n            left_child.children[i] = old_children[i]\n            i += 1\n        while (i &lt; old_n+1): # banyaknya pointer = (banyaknya key) + 1\n            right_child.children[i-med_idx-1] = old_children[i]\n            i += 1\n        \n        node.children[0] = left_child\n        node.children[1] = right_child\n        return node\n\n    def insert(self, newkey, right_biased=False):\n        if self.search(newkey) == None:\n            self.root = self.insert_rec(newkey, right_biased=right_biased,\n                                        current=self.root)\n        else:\n            print(\"Error insert: key sudah ada di tree, yaitu\", newkey)\n    def insert_rec(self, newkey, right_biased, current):\n        if current == None:\n            newnode = ABtreeNode(b=self.b, key_dtype=self.key_dtype,\n                                 emptydata=self.emptydata)\n            newnode.keys[0] = newkey\n            return newnode\n        \n        # variabel untuk menyimpan key \"buangan\" dari child node\n        # (dan key buangan itu nantinya akan dicoba dimasukkan ke keys)\n        # sementara kita buat \"kosong\" dulu karena belum ada buangan\n        carry = self.emptydata\n\n        n = current.get_nonempty_keys_amount()\n        if (not current.is_leaf()): # jika bukan leaf, akan lanjut ke child nya\n            if (newkey &lt; self.keys[0]):\n                current.children[0] = self.insert_rec(\n                    newkey, right_biased=right_biased,\n                    current=current.children[0]\n                    )\n            else:\n                for i in range(n):\n                    if ((i == n-1) or\n                        (self.keys[i] &lt; newkey and newkey &lt; self.keys[i+1])):\n                        current.children[i+1] = self.insert_rec(\n                            newkey, right_biased=right_biased, \n                            current=current.children[i+1]\n                            )\n                        break\n        # selain itu, jika current adalah leaf node\n        elif current.is_full_keys(): # jika current penuh, split\n            left_child, right_child, carry = self.split_node(\n                node=current, newkey=newkey, right_biased=right_biased\n            )\n            newkey_idx = current.try_insert_key(carry)\n            carry = None\n        else: # jika current (sebagai leaf node) tidak penuh\n            current.try_insert_key(newkey)\n        \n        return current\n\n    def delete(self, x):\n        pass"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09a.html#b-tree-sebagai-kasus-khusus-dari-a-b-tree",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09a.html#b-tree-sebagai-kasus-khusus-dari-a-b-tree",
    "title": "Modul 9a Struktur Data: A-B Tree dan variasinya (B-Tree, 2-3 Tree, dsb)",
    "section": "",
    "text": "B-Tree, berorder misalnya m, adalah sejenis A-B Tree atau \\((a,b)\\)-tree dengan\n\\[b=m\\] \\[a = \\left\\lceil \\frac{b}{2} \\right\\rceil = \\left\\lceil \\frac{m}{2} \\right\\rceil\\]\nSehingga, untuk implementasi B-Tree, kita tinggal meng-inherit dari LinkedABtree dan memilih nilai a dan b yang sesuai berdasarkan nilai m yang diberikan.\n\nclass LinkedBtree(LinkedABtree):\n    def __init__(self, m):\n        self.b = m\n        self.a = int(np.ceil(m/2))\n    \n    def get_m(self):\n        return self.b\n\n    def set_m(self, new_m):\n        self.b = new_m\n        self.a = int(np.ceil(new_m/2))"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09a.html#variasi-b-tree",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09a.html#variasi-b-tree",
    "title": "Modul 9a Struktur Data: A-B Tree dan variasinya (B-Tree, 2-3 Tree, dsb)",
    "section": "",
    "text": "2-3 Tree adalah suatu B-Tree dengan \\(m=3\\).\n(Lebih umumnya, 2-3 Tree atau \\((2,3)\\)-tree adalah suatu A-B Tree dengan \\(a=2\\) dan \\(b=3\\).)\n\nclass Linked23Tree(LinkedBtree):\n    def __init__(self):\n        super().__init__(m=3)\n    \n    # nonaktifkan fitur memasang nilai m dari LinkedBtree\n    def set_m(self, new_m):\n        print(\"Error 2-3 Tree: nilai m=3 tidak boleh diubah\")\n\n\n\n\n2-4 Tree, terkadang juga disebut 2-3-4 Tree, adalah suatu B-Tree dengan \\(m=4\\).\n(Lebih umumnya, 2-4 Tree atau \\((2,4)\\)-tree adalah suatu A-B Tree dengan \\(a=2\\) dan \\(b=4\\).)\n\nclass Linked24Tree(LinkedBtree):\n    def __init__(self):\n        super().__init__(m=4)\n    \n    # nonaktifkan fitur memasang nilai m dari LinkedBtree\n    def set_m(self, new_m):\n        print(\"Error 2-4 Tree: nilai m=4 tidak boleh diubah\")"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul08.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul08.html",
    "title": "Modul 8 Struktur Data: Binary Tree, Binary Search Tree (BST)",
    "section": "",
    "text": "Kembali ke Struktur Data (dengan Python)\n\nimport numpy as np\nimport graphviz as gv\n\n\n\n\n\n\nclass ArrayBintree:\n    def __init__(self, dtype, height, emptydata=-9999):\n        self.dtype = dtype\n        self.height = height\n        self.emptydata = emptydata\n        self.array_size = 2**(height+1) - 1\n        self.array = np.empty(self.array_size, dtype=dtype)\n        for i in range(self.array_size):\n            self.array[i] = emptydata\n\n    def get_root(self):\n        root_data = self.array[0]\n        if root_data == self.emptydata:\n            return None\n        else:\n            return root_data\n\n    def set_root(self, newdata):\n        self.array[0] = newdata\n\n    def get_data(self, node_idx):\n        if node_idx &lt; self.array_size:\n            return self.array[node_idx]\n        else:\n            print(\"Error get_data: indeks di luar ukuran tree\")\n            return None\n\n    def set_data(self, node_idx, newdata):\n        if node_idx &lt; self.array_size:\n            self.array[node_idx] = newdata\n        else:\n            print(\"Error set_data: indeks di luar ukuran tree\")\n\n    def get_left_child_idx(self, node_idx):\n        left_idx = 2*node_idx + 1\n        if left_idx &lt; self.array_size:\n            return left_idx\n        else:\n            return -1\n\n    def get_left_child(self, node_idx):\n        left_idx = self.get_left_child_idx(node_idx)\n        if left_idx != -1:\n            data = self.array[left_idx]\n            if data != self.emptydata:\n                return data\n            else:\n                return None\n        else:\n            return None\n\n    def get_right_child_idx(self, node_idx):\n        right_idx = 2*node_idx + 2\n        if right_idx &lt; self.array_size:\n            return right_idx\n        else:\n            return -1\n\n    def get_right_child(self, node_idx):\n        right_idx = self.get_right_child_idx(node_idx)\n        if right_idx != -1:\n            data = self.array[right_idx]\n            if data != self.emptydata:\n                return data\n            else:\n                return None\n        else:\n            return None\n\n    def get_parent_idx(self, node_idx):\n        if node_idx == 0:\n            return -1\n        idx = int(np.floor( (node_idx - 1)/2 ))\n        return idx\n\n    # preorder: tengah, kiri, kanan\n    def get_preorder(self, current=0, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n\n        # tengah\n        current_data = self.array[current]\n        if current_data != self.emptydata:\n            result.append(current_data)\n\n        # kiri\n        left_idx = self.get_left_child_idx(current)\n        if left_idx != -1:\n            self.get_preorder(current=left_idx, result=result)\n\n        # kanan\n        right_idx = self.get_right_child_idx(current)\n        if right_idx != -1:\n            self.get_preorder(current=right_idx, result=result)\n\n        if is_starting_node:\n            return result\n\n    # inorder: kiri, tengah, kanan\n    def get_inorder(self, current=0, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n\n        # kiri\n        left_idx = self.get_left_child_idx(current)\n        if left_idx != -1:\n            self.get_inorder(current=left_idx, result=result)\n\n        # tengah\n        current_data = self.array[current]\n        if current_data != self.emptydata:\n            result.append(current_data)\n\n        # kanan\n        right_idx = self.get_right_child_idx(current)\n        if right_idx != -1:\n            self.get_inorder(current=right_idx, result=result)\n\n        if is_starting_node:\n            return result\n\n    # postorder: kiri, kanan, tengah\n    def get_postorder(self, current=0, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n\n        # kiri\n        left_idx = self.get_left_child_idx(current)\n        if left_idx != -1:\n            self.get_postorder(current=left_idx, result=result)\n\n        # kanan\n        right_idx = self.get_right_child_idx(current)\n        if right_idx != -1:\n            self.get_postorder(current=right_idx, result=result)\n\n        # tengah\n        current_data = self.array[current]\n        if current_data != self.emptydata:\n            result.append(current_data)\n\n        if is_starting_node:\n            return result\n\n    def get_digraph_simple(self):\n        digraph = gv.Digraph()\n        for idx in range(self.array_size):\n            data = self.array[idx]\n            if data != self.emptydata:\n                digraph.node(\"node\" + str(idx), label=str(data))\n                left_idx = self.get_left_child_idx(idx)\n                right_idx = self.get_right_child_idx(idx)\n                if left_idx != -1:\n                    digraph.edge(\"node\" + str(idx), \"node\" + str(left_idx))\n                    if self.array[left_idx] == self.emptydata:\n                        digraph.node(\"node\" + str(left_idx), label=\"NULL\", shape=\"none\")\n                if right_idx != -1:\n                    digraph.edge(\"node\" + str(idx), \"node\" + str(right_idx))\n                    if self.array[right_idx] == self.emptydata:\n                        digraph.node(\"node\" + str(right_idx), label=\"NULL\", shape=\"none\")\n        return digraph\n\n\narraybintree = ArrayBintree(int, 2)\n\n\nprint(arraybintree.array)\n\n[-9999 -9999 -9999 -9999 -9999 -9999 -9999]\n\n\n\narraybintree.set_root(10)\n\n\nprint(arraybintree.array)\n\n[   10 -9999 -9999 -9999 -9999 -9999 -9999]\n\n\n\ndisplay(arraybintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraybintree.set_data(\n    arraybintree.get_left_child_idx(0),\n    5\n)\n\n\nprint(arraybintree.array)\n\n[   10     5 -9999 -9999 -9999 -9999 -9999]\n\n\n\ndisplay(arraybintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraybintree.set_data(\n    arraybintree.get_right_child_idx(0),\n    19\n)\n\n\nprint(arraybintree.array)\n\n[   10     5    19 -9999 -9999 -9999 -9999]\n\n\n\ndisplay(arraybintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraybintree.set_data(\n    arraybintree.get_right_child_idx(arraybintree.get_left_child_idx(0)),\n    37\n)\n\n\nprint(arraybintree.array)\n\n[   10     5    19 -9999    37 -9999 -9999]\n\n\n\ndisplay(arraybintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraybintree.get_data(\n    arraybintree.get_right_child_idx(arraybintree.get_left_child_idx(0))\n)\n\n37\n\n\n\narraybintree.array[5] = 98\narraybintree.array[6] = 62\n\n\nprint(arraybintree.array)\n\n[   10     5    19 -9999    37    98    62]\n\n\n\ndisplay(arraybintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraybintree.array[3] = 25\n\n\nprint(arraybintree.array)\n\n[10  5 19 25 37 98 62]\n\n\n\ndisplay(arraybintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraybintree.get_preorder()\n\n[10, 5, 25, 37, 19, 98, 62]\n\n\n\narraybintree.get_inorder()\n\n[25, 5, 37, 10, 98, 19, 62]\n\n\n\narraybintree.get_postorder()\n\n[25, 37, 5, 98, 62, 19, 10]\n\n\n\n\n\n\nclass BintreeNode:\n    def __init__(self, data, left=None, right=None):\n        self.data = data\n        self.left = left\n        self.right = right\n\n\nclass LinkedBintree:\n    def __init__(self):\n        self.root = None\n\n    def is_empty(self):\n        if self.root == None:\n            return True\n        else:\n            return False\n\n    def get_root_data(self):\n        if self.is_empty():\n            print(\"Error get_root_data: tree sedang kosong\")\n            return None\n        else:\n            return self.root.data\n\n    def set_root_data(self, newdata):\n        if self.is_empty():\n            self.root = BintreeNode(newdata)\n        else:\n            self.root.data = newdata\n\n    # preorder: tengah, kiri, kanan\n    def get_preorder(self, current=None, result=None, get_addresses=False):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n            current = self.root\n\n        if current != None:\n            # tengah\n            if (not get_addresses):\n                result.append(current.data)\n            else:\n                result.append(current)\n\n            # kiri\n            if current.left != None:\n                self.get_preorder(current.left, result=result)\n            \n            # kanan\n            if current.right != None:\n                self.get_preorder(current.right, result=result)\n\n        if is_starting_node:\n            return result\n\n    # inorder: kiri, tengah, kanan\n    def get_inorder(self, current=None, result=None, get_addresses=False):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n            current = self.root\n\n        if current != None:\n            # kiri\n            if current.left != None:\n                self.get_inorder(current.left, result=result)\n            \n            # tengah\n            if (not get_addresses):\n                result.append(current.data)\n            else:\n                result.append(current)\n\n            # kanan\n            if current.right != None:\n                self.get_inorder(current.right, result=result)\n\n        if is_starting_node:\n            return result\n\n    # postorder: kiri, kanan, tengah\n    def get_postorder(self, current=None, result=None, get_addresses=False):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n            current = self.root\n\n        if current != None:\n            # kiri\n            if current.left != None:\n                self.get_postorder(current.left, result=result)\n            \n            # kanan\n            if current.right != None:\n                self.get_postorder(current.right, result=result)\n\n            # tengah\n            if (not get_addresses):\n                result.append(current.data)\n            else:\n                result.append(current)\n\n        if is_starting_node:\n            return result\n\n    # berdasarkan algoritma preorder traversal :D\n    def get_digraph_simple(self, current=None, node_name=None, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = gv.Digraph()\n            current = self.root\n            node_name = \"root\"\n        \n        if current != None:\n            # tengah\n            result.node(node_name, label=str(current.data))\n\n            # kiri\n            left_name = node_name + \"-&gt;left\"\n            result.edge(node_name, left_name)\n            self.get_digraph_simple(\n                current=current.left, node_name=left_name, result=result\n            )\n            \n            # kanan\n            right_name = node_name + \"-&gt;right\"\n            self.get_digraph_simple(\n                current=current.right, node_name=right_name, result=result\n            )\n            result.edge(node_name, right_name)\n        else:\n            result.node(node_name, label=\"NULL\", shape=\"none\")\n        \n        if is_starting_node:\n            return result\n\n\nlinkedbintree = LinkedBintree()\n\n\nprint(linkedbintree.root)\n\nNone\n\n\n\nlinkedbintree.root = BintreeNode(26)\n\n\nprint(linkedbintree.root)\n\n&lt;__main__.BintreeNode object at 0x10ccbd060&gt;\n\n\n\nprint(linkedbintree.root.data)\n\n26\n\n\n\nlinkedbintree.root.left = BintreeNode(89)\nlinkedbintree.root.right = BintreeNode(54)\n\n\ndisplay(linkedbintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbintree.root.left.right = BintreeNode(43)\n\n\ndisplay(linkedbintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nprint(linkedbintree.root.left.right.data)\n\n43\n\n\n\nlinkedbintree.root.right.right = BintreeNode(11)\nlinkedbintree.root.right.right.left = BintreeNode(72)\nlinkedbintree.root.right.right.right = BintreeNode(35)\n\n\ndisplay(linkedbintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbintree.root.left.right.left = BintreeNode(90)\nlinkedbintree.root.left.right.left.right = BintreeNode(16)\n\n\ndisplay(linkedbintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbintree.get_preorder()\n\n[26, 89, 43, 90, 16, 54, 11, 72, 35]\n\n\n\nlinkedbintree.get_inorder()\n\n[89, 90, 16, 43, 26, 54, 72, 11, 35]\n\n\n\nlinkedbintree.get_postorder()\n\n[16, 90, 43, 89, 72, 35, 11, 54, 26]\n\n\n\n\n\n\nBinary Search Tree (BST) adalah binary tree dengan beberapa sifat dan fitur tambahan. Sehingga, untuk implementasi BST, kita cukup menambahkan beberapa method ke class binary tree yang sudah dibuat. Daripada mengetik ulang semua method yang sudah dibuat di class binary tree, kita bisa menerapkan salah satu prinsip OOP yaitu inheritance, agar langsung mewariskan semua fitur yang sudah dibuat di implementasi binary tree.\nKarena lebih fleksibel (tidak ada keterbatasan ukuran), kita akan membuat BST dengan pointer (juga disebut linked BST) saja, berarti meng-inherit dari class LinkedBintree.\n(Membuat BST dengan array juga memungkinkan, meng-inherit dari class ArrayBintree, tetapi akan ada beberapa pertimbangan tambahan, misalnya untuk memastikan posisi node yang di-insert tidak melebihi kapastias array.)\n\nclass LinkedBST(LinkedBintree):\n    def __init__(self):\n        # menggunakan __init__ dari parent class,\n        # melalui super() yaitu parent class\n        super().__init__()\n    \n    # semua method dari LinkedBintree otomatis sudah terdefinisi\n\n    # cari elemen di BST\n    def search(self, x):\n        temp = self.root\n        while (temp != None):\n            if x == temp.data:\n                return x\n            elif x &lt; temp.data:\n                temp = temp.left\n            else:\n                temp = temp.right\n        return None\n\n    # insertion\n    def insert(self, newdata):\n        if self.root == None:\n            self.root = BintreeNode(newdata)\n            return\n        temp = self.root\n        while (temp != None):\n            if newdata == temp.data:\n                print(\"Error insert: data sudah ada di BST, yaitu\", newdata)\n                return\n            elif newdata &lt; temp.data:\n                if temp.left == None:\n                    temp.left = BintreeNode(newdata)\n                    return\n                else:\n                    temp = temp.left\n            else: # newdata &gt; temp.data\n                if temp.right == None:\n                    temp.right = BintreeNode(newdata)\n                    return\n                else:\n                    temp = temp.right\n\n    # deletion\n    def delete(self, x, inorder_pred=False):\n        if self.is_empty():\n            print(\"Error: BST kosong\")\n            return\n        prev = self.root\n        turn = \"\"\n        if x &lt; prev.data:\n            if prev.left == None:\n                print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                return\n            else:\n                temp = prev.left\n                turn = \"left\"\n        elif x &gt; prev.data:\n            if prev.right == None:\n                print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                return\n            else:\n                temp = prev.right\n                turn = \"right\"\n        else:\n            temp = prev\n        \n        while (temp != None):\n            if temp.data == x:\n                break\n            elif x &lt; temp.data:\n                if temp.left == None:\n                    print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                    return\n                else:\n                    prev = temp\n                    temp = temp.left\n                    turn = \"left\"\n            else: # x &gt; temp.data\n                if temp.right == None:\n                    print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                    return\n                else:\n                    prev = temp\n                    temp = temp.right\n                    turn = \"right\"\n        \n        # kasus 0 children\n        if (temp.left == None) and (temp.right == None):\n            if turn == \"left\":\n                prev.left = None\n            elif turn == \"right\":\n                prev.right = None\n            del temp\n            return\n\n        # kasus 1 child, di kiri\n        elif (temp.left != None) and (temp.right == None):\n            if turn == \"left\":\n                prev.left = temp.left\n            elif turn == \"right\":\n                prev.right = temp.left\n            del temp\n            return\n        \n        # kasus 1 child, di kanan\n        elif (temp.left == None) and (temp.right != None):\n            if turn == \"left\":\n                prev.left = temp.right\n            elif turn == \"right\":\n                prev.right = temp.right\n            del temp\n            return\n        \n        # kasus 2 children\n        elif inorder_pred: # metode inorder predecessor (left subtree)\n            inorder_left = []\n            self.get_inorder(current=temp.left, result=inorder_left)\n            replacement = inorder_left[-1] # elemen terakhir\n            self.delete(replacement, inorder_pred=inorder_pred)\n            temp.data = replacement\n            return\n        else: # metode inorder successor (right subtree)\n            inorder_right = []\n            self.get_inorder(current=temp.right, result=inorder_right)\n            replacement = inorder_right[0]\n            self.delete(replacement, inorder_pred=inorder_pred)\n            temp.data = replacement\n            return\n\n\nlinkedbst = LinkedBST()\n\n\nlinkedbst.insert(10)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(27)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(5)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(8)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(8)\n\nError insert: data sudah ada di BST, yaitu 8\n\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(16)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(38)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(3)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(9)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.get_preorder()\n\n[10, 5, 3, 8, 9, 27, 16, 38]\n\n\n\nlinkedbst.get_inorder()\n\n[3, 5, 8, 9, 10, 16, 27, 38]\n\n\n\nlinkedbst.get_postorder()\n\n[3, 9, 8, 5, 16, 38, 27, 10]\n\n\n\nlinkedbst.delete(50)\n\nError delete: tidak ditemukan data yang bernilai 50\n\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.delete(3)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.delete(8)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.delete(27)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.delete(10)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.delete(16, inorder_pred=True)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\n\n\nKita akan membuat LinkedBintree saja, karena height dari tree yang akan dibentuk tidak bisa ditentukan sebelum tree selesai terbentuk, sedangkan pembuatan ArrayBintree melibatkan penentuan height di awal-awal sebelum tree dibentuk.\nJika diberikan preorder dengan inorder, atau postorder dengan inorder, maka hanya ada satu binary tree yang mungkin.\nNamun, apabila diberikan preorder dengan postorder, maka binary tree yang dibentuk belum tentu unik. Meskipun demikian, apabila ditambahkan syarat bahwa binary tree yang dibentuk harus bersifat complete, maka binary tree yang dibentuk menjadi unik.\nOleh karena itu, untuk kasus diberikan preorder dengan postorder, ada algoritma biasa (tanpa syarat tersebut) dan algoritma dengan syarat tersebut.\n\n\n\ndef linkedbintree_from_preorder_inorder(\n        preorder, inorder, is_starting_node=True\n    ):\n    \n    # Nanti di paling bawah tree kalau inorder sudah kosong,\n    # tidak perlu buat node lagi; langsung return None (NULL)\n    if len(inorder) == 0:\n        return None\n\n    # 1. Di antara semua elemen inorder, mana yang paling kiri di preorder?\n    # Simpan index inorder nya\n    selesai = False\n    preorder_idx = 0\n    while (preorder_idx &lt; len(preorder)) and (not selesai):\n        # lihat tiap elemen preorder dari kiri ke kanan,\n        elemen_preorder = preorder[preorder_idx]\n        # dan untuk tiap elemen preorder, periksa satu-satu apakah sama dengan\n        # salah satu elemen inorder\n        inorder_idx = 0\n        while (inorder_idx &lt; len(inorder)) and (not selesai):\n            if inorder[inorder_idx] == elemen_preorder:\n                selesai = True\n            else:\n                inorder_idx += 1\n        preorder_idx += 1\n\n    # 2. Buatlah node dengan data di index tersebut di inorder.\n    # Kalau belum ada root (karena LinkedBintree belum dibentuk sama sekali),\n    # buatlah objek LinkedBintree dengan rootnya adalah node tersebut\n    current_root = BintreeNode(inorder[inorder_idx])\n    if is_starting_node:\n        result = LinkedBintree()\n        result.root = current_root\n\n    # 3. Pisah inorder menjadi dua bagian,\n    # yaitu sebelah kiri dari elemen inorder_idx dan sebelah kanan darinya\n    inorder_left = inorder[:inorder_idx]\n    inorder_right = inorder[(inorder_idx+1):]\n\n    current_root.left = linkedbintree_from_preorder_inorder(\n        preorder, inorder_left, is_starting_node=False\n    )\n    current_root.right = linkedbintree_from_preorder_inorder(\n        preorder, inorder_right, is_starting_node=False\n    )\n\n    if is_starting_node:\n        return result\n    else:\n        return current_root\n\n\nhasil_pre_in = linkedbintree_from_preorder_inorder(\n    preorder=[26, 89, 43, 90, 16, 54, 11, 72, 35],\n    inorder=[89, 90, 16, 43, 26, 54, 72, 11, 35]\n)\n\n\ndisplay(hasil_pre_in.get_digraph_simple())\n\n\n\n\n\n\n\n\n\n\n\nAlgoritma ini hampir sama dengan algoritma membentuk binary tree dari preorder dan inorder. Bedanya, di algoritma ini, dicari elemen inorder yang paling kanan di postorder, daripada yang paling kiri di preorder.\n\ndef linkedbintree_from_postorder_inorder(\n        postorder, inorder, is_starting_node=True\n    ):\n    \n    # Nanti di paling bawah tree kalau inorder sudah kosong,\n    # tidak perlu buat node lagi; langsung return None (NULL)\n    if len(inorder) == 0:\n        return None\n\n    # 1. Di antara semua elemen inorder, mana yang paling KANAN di postorder?\n    # Simpan index inorder nya\n    selesai = False\n    postorder_idx = len(postorder)-1 # mulai dari paling kanan, daripada dari 0\n    while (postorder_idx &gt;= 0) and (not selesai):\n        # lihat tiap elemen preorder DARI KANAN KE KIRI,\n        elemen_postorder = postorder[postorder_idx]\n        # dan untuk tiap elemen postorder, periksa satu-satu apakah sama dengan\n        # salah satu elemen inorder\n        inorder_idx = 0\n        while (inorder_idx &lt; len(inorder)) and (not selesai):\n            if inorder[inorder_idx] == elemen_postorder:\n                selesai = True\n            else:\n                inorder_idx += 1\n        postorder_idx -= 1\n\n    # 2. Buatlah node dengan data di index tersebut di inorder.\n    # Kalau belum ada root (karena LinkedBintree belum dibentuk sama sekali),\n    # buatlah objek LinkedBintree dengan rootnya adalah node tersebut\n    current_root = BintreeNode(inorder[inorder_idx])\n    if is_starting_node:\n        result = LinkedBintree()\n        result.root = current_root\n\n    # 3. Pisah inorder menjadi dua bagian,\n    # yaitu sebelah kiri dari elemen inorder_idx dan sebelah kanan darinya\n    inorder_left = inorder[:inorder_idx]\n    inorder_right = inorder[(inorder_idx+1):]\n\n    current_root.left = linkedbintree_from_postorder_inorder(\n        postorder, inorder_left, is_starting_node=False\n    )\n    current_root.right = linkedbintree_from_postorder_inorder(\n        postorder, inorder_right, is_starting_node=False\n    )\n\n    if is_starting_node:\n        return result\n    else:\n        return current_root\n\n\nhasil_post_in = linkedbintree_from_postorder_inorder(\n    postorder=[16, 90, 43, 89, 72, 35, 11, 54, 26],\n    inorder=[89, 90, 16, 43, 26, 54, 72, 11, 35]\n)\n\n\ndisplay(hasil_post_in.get_digraph_simple())\n\n\n\n\n\n\n\n\n\n\n\n\ndef linkedbintree_from_preorder_postorder(\n        preorder, postorder, is_starting_node=True\n):\n    \n    if (not is_starting_node):\n        if len(preorder) == 0 or len(postorder) == 0:\n            return None\n        if len(preorder) == 1:\n            return BintreeNode(preorder[0])\n        if len(postorder) == 1:\n            return BintreeNode(postorder[0])\n    \n    # 1. Buatlah node baru dengan datanya adalah preorder[0]\n    # (atau sama saja elemen terakhir dari postorder).\n    # Kalau belum ada root (karena LinkedBintree belum dibentuk sama sekali),\n    # buatlah objek LinkedBintree dengan rootnya adalah node tersebut\n    current_root = BintreeNode(preorder[0])\n    if is_starting_node:\n        result = LinkedBintree()\n        result.root = current_root\n    \n    # 2. Tentukan list postorder untuk left subtree dan untuk right subtree:\n    # 2a. Carilah letak preorder[1] di postorder, misal postorder_idx\n    # 2b. Belah postorder menjadi dua, dengan postorder_idx masuk ke kiri,\n    #     dan elemen terakhir postorder tidak masuk keduanya\n\n    postorder_idx = 0\n    while (postorder_idx &lt; len(postorder) and\n           postorder[postorder_idx] != preorder[1]):\n        postorder_idx += 1\n    \n    # 0 &lt;= indeks &lt; (postorder_idx+1)\n    postorder_left = postorder[ 0 : (postorder_idx+1) ]\n\n    # (postorder_idx+1) &lt;= indeks &lt; elemen terakhir (indeks -1)\n    postorder_right = postorder[ (postorder_idx+1) : -1 ]\n\n    # 3. Tentukan list preorder untuk left subtree dan untuk right subtree:\n    # 3a. Carilah letak postorder[-2] di preorder, misal preorder_idx\n    # 3b. Belah preorder menjadi dua, dengan preorder_idx masuk ke kanan,\n    #     dan elemen pertama preorder tidak masuk keduanya\n\n    preorder_idx = 0\n    while (preorder_idx &lt; len(preorder) and\n           preorder[preorder_idx] != postorder[-2]):\n        preorder_idx += 1\n    \n    # 1 &lt;= indeks &lt; preorder_idx\n    preorder_left = preorder[ 1 : preorder_idx ]\n\n    # preorder_idx &lt;= indeks\n    preorder_right = preorder[ preorder_idx : ]\n\n    print(\"preorder_left\", len(preorder_left))\n    print(\"preorder_right\", len(preorder_right))\n    print(\"postorder_left\", len(postorder_left))\n    print(\"postorder_right\", len(postorder_right))\n\n    # 4. Langkah rekursif: melakukan langkah yang sama di left subtree dan\n    # right subtree, hasilnya disambung ke current_root\n\n    current_root.left = linkedbintree_from_preorder_postorder(\n        preorder=preorder_left, postorder=postorder_left,\n        is_starting_node=False\n    )\n    current_root.right = linkedbintree_from_preorder_postorder(\n        preorder=preorder_right, postorder=postorder_right,\n        is_starting_node=False\n    )\n\n    if is_starting_node:\n        return result\n    else:\n        return current_root\n\n\ntest_pre_post = linkedbintree_from_preorder_postorder(\n    preorder=[\"F\", \"B\", \"A\", \"D\", \"C\", \"E\", \"G\", \"I\", \"H\"],\n    postorder=[\"A\", \"C\", \"E\", \"D\", \"B\", \"H\", \"I\", \"G\", \"F\"]\n)\n\npreorder_left 5\npreorder_right 3\npostorder_left 5\npostorder_right 3\npreorder_left 1\npreorder_right 3\npostorder_left 1\npostorder_right 3\npreorder_left 1\npreorder_right 1\npostorder_left 1\npostorder_right 1\npreorder_left 0\npreorder_right 2\npostorder_left 2\npostorder_right 0\n\n\n\ndisplay(test_pre_post.get_digraph_simple())"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul08.html#implementasi-binary-tree",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul08.html#implementasi-binary-tree",
    "title": "Modul 8 Struktur Data: Binary Tree, Binary Search Tree (BST)",
    "section": "",
    "text": "class ArrayBintree:\n    def __init__(self, dtype, height, emptydata=-9999):\n        self.dtype = dtype\n        self.height = height\n        self.emptydata = emptydata\n        self.array_size = 2**(height+1) - 1\n        self.array = np.empty(self.array_size, dtype=dtype)\n        for i in range(self.array_size):\n            self.array[i] = emptydata\n\n    def get_root(self):\n        root_data = self.array[0]\n        if root_data == self.emptydata:\n            return None\n        else:\n            return root_data\n\n    def set_root(self, newdata):\n        self.array[0] = newdata\n\n    def get_data(self, node_idx):\n        if node_idx &lt; self.array_size:\n            return self.array[node_idx]\n        else:\n            print(\"Error get_data: indeks di luar ukuran tree\")\n            return None\n\n    def set_data(self, node_idx, newdata):\n        if node_idx &lt; self.array_size:\n            self.array[node_idx] = newdata\n        else:\n            print(\"Error set_data: indeks di luar ukuran tree\")\n\n    def get_left_child_idx(self, node_idx):\n        left_idx = 2*node_idx + 1\n        if left_idx &lt; self.array_size:\n            return left_idx\n        else:\n            return -1\n\n    def get_left_child(self, node_idx):\n        left_idx = self.get_left_child_idx(node_idx)\n        if left_idx != -1:\n            data = self.array[left_idx]\n            if data != self.emptydata:\n                return data\n            else:\n                return None\n        else:\n            return None\n\n    def get_right_child_idx(self, node_idx):\n        right_idx = 2*node_idx + 2\n        if right_idx &lt; self.array_size:\n            return right_idx\n        else:\n            return -1\n\n    def get_right_child(self, node_idx):\n        right_idx = self.get_right_child_idx(node_idx)\n        if right_idx != -1:\n            data = self.array[right_idx]\n            if data != self.emptydata:\n                return data\n            else:\n                return None\n        else:\n            return None\n\n    def get_parent_idx(self, node_idx):\n        if node_idx == 0:\n            return -1\n        idx = int(np.floor( (node_idx - 1)/2 ))\n        return idx\n\n    # preorder: tengah, kiri, kanan\n    def get_preorder(self, current=0, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n\n        # tengah\n        current_data = self.array[current]\n        if current_data != self.emptydata:\n            result.append(current_data)\n\n        # kiri\n        left_idx = self.get_left_child_idx(current)\n        if left_idx != -1:\n            self.get_preorder(current=left_idx, result=result)\n\n        # kanan\n        right_idx = self.get_right_child_idx(current)\n        if right_idx != -1:\n            self.get_preorder(current=right_idx, result=result)\n\n        if is_starting_node:\n            return result\n\n    # inorder: kiri, tengah, kanan\n    def get_inorder(self, current=0, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n\n        # kiri\n        left_idx = self.get_left_child_idx(current)\n        if left_idx != -1:\n            self.get_inorder(current=left_idx, result=result)\n\n        # tengah\n        current_data = self.array[current]\n        if current_data != self.emptydata:\n            result.append(current_data)\n\n        # kanan\n        right_idx = self.get_right_child_idx(current)\n        if right_idx != -1:\n            self.get_inorder(current=right_idx, result=result)\n\n        if is_starting_node:\n            return result\n\n    # postorder: kiri, kanan, tengah\n    def get_postorder(self, current=0, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n\n        # kiri\n        left_idx = self.get_left_child_idx(current)\n        if left_idx != -1:\n            self.get_postorder(current=left_idx, result=result)\n\n        # kanan\n        right_idx = self.get_right_child_idx(current)\n        if right_idx != -1:\n            self.get_postorder(current=right_idx, result=result)\n\n        # tengah\n        current_data = self.array[current]\n        if current_data != self.emptydata:\n            result.append(current_data)\n\n        if is_starting_node:\n            return result\n\n    def get_digraph_simple(self):\n        digraph = gv.Digraph()\n        for idx in range(self.array_size):\n            data = self.array[idx]\n            if data != self.emptydata:\n                digraph.node(\"node\" + str(idx), label=str(data))\n                left_idx = self.get_left_child_idx(idx)\n                right_idx = self.get_right_child_idx(idx)\n                if left_idx != -1:\n                    digraph.edge(\"node\" + str(idx), \"node\" + str(left_idx))\n                    if self.array[left_idx] == self.emptydata:\n                        digraph.node(\"node\" + str(left_idx), label=\"NULL\", shape=\"none\")\n                if right_idx != -1:\n                    digraph.edge(\"node\" + str(idx), \"node\" + str(right_idx))\n                    if self.array[right_idx] == self.emptydata:\n                        digraph.node(\"node\" + str(right_idx), label=\"NULL\", shape=\"none\")\n        return digraph\n\n\narraybintree = ArrayBintree(int, 2)\n\n\nprint(arraybintree.array)\n\n[-9999 -9999 -9999 -9999 -9999 -9999 -9999]\n\n\n\narraybintree.set_root(10)\n\n\nprint(arraybintree.array)\n\n[   10 -9999 -9999 -9999 -9999 -9999 -9999]\n\n\n\ndisplay(arraybintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraybintree.set_data(\n    arraybintree.get_left_child_idx(0),\n    5\n)\n\n\nprint(arraybintree.array)\n\n[   10     5 -9999 -9999 -9999 -9999 -9999]\n\n\n\ndisplay(arraybintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraybintree.set_data(\n    arraybintree.get_right_child_idx(0),\n    19\n)\n\n\nprint(arraybintree.array)\n\n[   10     5    19 -9999 -9999 -9999 -9999]\n\n\n\ndisplay(arraybintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraybintree.set_data(\n    arraybintree.get_right_child_idx(arraybintree.get_left_child_idx(0)),\n    37\n)\n\n\nprint(arraybintree.array)\n\n[   10     5    19 -9999    37 -9999 -9999]\n\n\n\ndisplay(arraybintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraybintree.get_data(\n    arraybintree.get_right_child_idx(arraybintree.get_left_child_idx(0))\n)\n\n37\n\n\n\narraybintree.array[5] = 98\narraybintree.array[6] = 62\n\n\nprint(arraybintree.array)\n\n[   10     5    19 -9999    37    98    62]\n\n\n\ndisplay(arraybintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraybintree.array[3] = 25\n\n\nprint(arraybintree.array)\n\n[10  5 19 25 37 98 62]\n\n\n\ndisplay(arraybintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraybintree.get_preorder()\n\n[10, 5, 25, 37, 19, 98, 62]\n\n\n\narraybintree.get_inorder()\n\n[25, 5, 37, 10, 98, 19, 62]\n\n\n\narraybintree.get_postorder()\n\n[25, 37, 5, 98, 62, 19, 10]\n\n\n\n\n\n\nclass BintreeNode:\n    def __init__(self, data, left=None, right=None):\n        self.data = data\n        self.left = left\n        self.right = right\n\n\nclass LinkedBintree:\n    def __init__(self):\n        self.root = None\n\n    def is_empty(self):\n        if self.root == None:\n            return True\n        else:\n            return False\n\n    def get_root_data(self):\n        if self.is_empty():\n            print(\"Error get_root_data: tree sedang kosong\")\n            return None\n        else:\n            return self.root.data\n\n    def set_root_data(self, newdata):\n        if self.is_empty():\n            self.root = BintreeNode(newdata)\n        else:\n            self.root.data = newdata\n\n    # preorder: tengah, kiri, kanan\n    def get_preorder(self, current=None, result=None, get_addresses=False):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n            current = self.root\n\n        if current != None:\n            # tengah\n            if (not get_addresses):\n                result.append(current.data)\n            else:\n                result.append(current)\n\n            # kiri\n            if current.left != None:\n                self.get_preorder(current.left, result=result)\n            \n            # kanan\n            if current.right != None:\n                self.get_preorder(current.right, result=result)\n\n        if is_starting_node:\n            return result\n\n    # inorder: kiri, tengah, kanan\n    def get_inorder(self, current=None, result=None, get_addresses=False):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n            current = self.root\n\n        if current != None:\n            # kiri\n            if current.left != None:\n                self.get_inorder(current.left, result=result)\n            \n            # tengah\n            if (not get_addresses):\n                result.append(current.data)\n            else:\n                result.append(current)\n\n            # kanan\n            if current.right != None:\n                self.get_inorder(current.right, result=result)\n\n        if is_starting_node:\n            return result\n\n    # postorder: kiri, kanan, tengah\n    def get_postorder(self, current=None, result=None, get_addresses=False):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n            current = self.root\n\n        if current != None:\n            # kiri\n            if current.left != None:\n                self.get_postorder(current.left, result=result)\n            \n            # kanan\n            if current.right != None:\n                self.get_postorder(current.right, result=result)\n\n            # tengah\n            if (not get_addresses):\n                result.append(current.data)\n            else:\n                result.append(current)\n\n        if is_starting_node:\n            return result\n\n    # berdasarkan algoritma preorder traversal :D\n    def get_digraph_simple(self, current=None, node_name=None, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = gv.Digraph()\n            current = self.root\n            node_name = \"root\"\n        \n        if current != None:\n            # tengah\n            result.node(node_name, label=str(current.data))\n\n            # kiri\n            left_name = node_name + \"-&gt;left\"\n            result.edge(node_name, left_name)\n            self.get_digraph_simple(\n                current=current.left, node_name=left_name, result=result\n            )\n            \n            # kanan\n            right_name = node_name + \"-&gt;right\"\n            self.get_digraph_simple(\n                current=current.right, node_name=right_name, result=result\n            )\n            result.edge(node_name, right_name)\n        else:\n            result.node(node_name, label=\"NULL\", shape=\"none\")\n        \n        if is_starting_node:\n            return result\n\n\nlinkedbintree = LinkedBintree()\n\n\nprint(linkedbintree.root)\n\nNone\n\n\n\nlinkedbintree.root = BintreeNode(26)\n\n\nprint(linkedbintree.root)\n\n&lt;__main__.BintreeNode object at 0x10ccbd060&gt;\n\n\n\nprint(linkedbintree.root.data)\n\n26\n\n\n\nlinkedbintree.root.left = BintreeNode(89)\nlinkedbintree.root.right = BintreeNode(54)\n\n\ndisplay(linkedbintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbintree.root.left.right = BintreeNode(43)\n\n\ndisplay(linkedbintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nprint(linkedbintree.root.left.right.data)\n\n43\n\n\n\nlinkedbintree.root.right.right = BintreeNode(11)\nlinkedbintree.root.right.right.left = BintreeNode(72)\nlinkedbintree.root.right.right.right = BintreeNode(35)\n\n\ndisplay(linkedbintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbintree.root.left.right.left = BintreeNode(90)\nlinkedbintree.root.left.right.left.right = BintreeNode(16)\n\n\ndisplay(linkedbintree.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbintree.get_preorder()\n\n[26, 89, 43, 90, 16, 54, 11, 72, 35]\n\n\n\nlinkedbintree.get_inorder()\n\n[89, 90, 16, 43, 26, 54, 72, 11, 35]\n\n\n\nlinkedbintree.get_postorder()\n\n[16, 90, 43, 89, 72, 35, 11, 54, 26]"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul08.html#binary-search-tree-bst-dengan-pointer-linked-bst",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul08.html#binary-search-tree-bst-dengan-pointer-linked-bst",
    "title": "Modul 8 Struktur Data: Binary Tree, Binary Search Tree (BST)",
    "section": "",
    "text": "Binary Search Tree (BST) adalah binary tree dengan beberapa sifat dan fitur tambahan. Sehingga, untuk implementasi BST, kita cukup menambahkan beberapa method ke class binary tree yang sudah dibuat. Daripada mengetik ulang semua method yang sudah dibuat di class binary tree, kita bisa menerapkan salah satu prinsip OOP yaitu inheritance, agar langsung mewariskan semua fitur yang sudah dibuat di implementasi binary tree.\nKarena lebih fleksibel (tidak ada keterbatasan ukuran), kita akan membuat BST dengan pointer (juga disebut linked BST) saja, berarti meng-inherit dari class LinkedBintree.\n(Membuat BST dengan array juga memungkinkan, meng-inherit dari class ArrayBintree, tetapi akan ada beberapa pertimbangan tambahan, misalnya untuk memastikan posisi node yang di-insert tidak melebihi kapastias array.)\n\nclass LinkedBST(LinkedBintree):\n    def __init__(self):\n        # menggunakan __init__ dari parent class,\n        # melalui super() yaitu parent class\n        super().__init__()\n    \n    # semua method dari LinkedBintree otomatis sudah terdefinisi\n\n    # cari elemen di BST\n    def search(self, x):\n        temp = self.root\n        while (temp != None):\n            if x == temp.data:\n                return x\n            elif x &lt; temp.data:\n                temp = temp.left\n            else:\n                temp = temp.right\n        return None\n\n    # insertion\n    def insert(self, newdata):\n        if self.root == None:\n            self.root = BintreeNode(newdata)\n            return\n        temp = self.root\n        while (temp != None):\n            if newdata == temp.data:\n                print(\"Error insert: data sudah ada di BST, yaitu\", newdata)\n                return\n            elif newdata &lt; temp.data:\n                if temp.left == None:\n                    temp.left = BintreeNode(newdata)\n                    return\n                else:\n                    temp = temp.left\n            else: # newdata &gt; temp.data\n                if temp.right == None:\n                    temp.right = BintreeNode(newdata)\n                    return\n                else:\n                    temp = temp.right\n\n    # deletion\n    def delete(self, x, inorder_pred=False):\n        if self.is_empty():\n            print(\"Error: BST kosong\")\n            return\n        prev = self.root\n        turn = \"\"\n        if x &lt; prev.data:\n            if prev.left == None:\n                print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                return\n            else:\n                temp = prev.left\n                turn = \"left\"\n        elif x &gt; prev.data:\n            if prev.right == None:\n                print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                return\n            else:\n                temp = prev.right\n                turn = \"right\"\n        else:\n            temp = prev\n        \n        while (temp != None):\n            if temp.data == x:\n                break\n            elif x &lt; temp.data:\n                if temp.left == None:\n                    print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                    return\n                else:\n                    prev = temp\n                    temp = temp.left\n                    turn = \"left\"\n            else: # x &gt; temp.data\n                if temp.right == None:\n                    print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                    return\n                else:\n                    prev = temp\n                    temp = temp.right\n                    turn = \"right\"\n        \n        # kasus 0 children\n        if (temp.left == None) and (temp.right == None):\n            if turn == \"left\":\n                prev.left = None\n            elif turn == \"right\":\n                prev.right = None\n            del temp\n            return\n\n        # kasus 1 child, di kiri\n        elif (temp.left != None) and (temp.right == None):\n            if turn == \"left\":\n                prev.left = temp.left\n            elif turn == \"right\":\n                prev.right = temp.left\n            del temp\n            return\n        \n        # kasus 1 child, di kanan\n        elif (temp.left == None) and (temp.right != None):\n            if turn == \"left\":\n                prev.left = temp.right\n            elif turn == \"right\":\n                prev.right = temp.right\n            del temp\n            return\n        \n        # kasus 2 children\n        elif inorder_pred: # metode inorder predecessor (left subtree)\n            inorder_left = []\n            self.get_inorder(current=temp.left, result=inorder_left)\n            replacement = inorder_left[-1] # elemen terakhir\n            self.delete(replacement, inorder_pred=inorder_pred)\n            temp.data = replacement\n            return\n        else: # metode inorder successor (right subtree)\n            inorder_right = []\n            self.get_inorder(current=temp.right, result=inorder_right)\n            replacement = inorder_right[0]\n            self.delete(replacement, inorder_pred=inorder_pred)\n            temp.data = replacement\n            return\n\n\nlinkedbst = LinkedBST()\n\n\nlinkedbst.insert(10)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(27)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(5)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(8)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(8)\n\nError insert: data sudah ada di BST, yaitu 8\n\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(16)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(38)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(3)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.insert(9)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.get_preorder()\n\n[10, 5, 3, 8, 9, 27, 16, 38]\n\n\n\nlinkedbst.get_inorder()\n\n[3, 5, 8, 9, 10, 16, 27, 38]\n\n\n\nlinkedbst.get_postorder()\n\n[3, 9, 8, 5, 16, 38, 27, 10]\n\n\n\nlinkedbst.delete(50)\n\nError delete: tidak ditemukan data yang bernilai 50\n\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.delete(3)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.delete(8)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.delete(27)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.delete(10)\n\n\ndisplay(linkedbst.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedbst.delete(16, inorder_pred=True)\n\n\ndisplay(linkedbst.get_digraph_simple())"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul08.html#todo-pengayaan-linkedbintree-dari-preorder-inorder-danatau-postorder",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul08.html#todo-pengayaan-linkedbintree-dari-preorder-inorder-danatau-postorder",
    "title": "Modul 8 Struktur Data: Binary Tree, Binary Search Tree (BST)",
    "section": "",
    "text": "Kita akan membuat LinkedBintree saja, karena height dari tree yang akan dibentuk tidak bisa ditentukan sebelum tree selesai terbentuk, sedangkan pembuatan ArrayBintree melibatkan penentuan height di awal-awal sebelum tree dibentuk.\nJika diberikan preorder dengan inorder, atau postorder dengan inorder, maka hanya ada satu binary tree yang mungkin.\nNamun, apabila diberikan preorder dengan postorder, maka binary tree yang dibentuk belum tentu unik. Meskipun demikian, apabila ditambahkan syarat bahwa binary tree yang dibentuk harus bersifat complete, maka binary tree yang dibentuk menjadi unik.\nOleh karena itu, untuk kasus diberikan preorder dengan postorder, ada algoritma biasa (tanpa syarat tersebut) dan algoritma dengan syarat tersebut.\n\n\n\ndef linkedbintree_from_preorder_inorder(\n        preorder, inorder, is_starting_node=True\n    ):\n    \n    # Nanti di paling bawah tree kalau inorder sudah kosong,\n    # tidak perlu buat node lagi; langsung return None (NULL)\n    if len(inorder) == 0:\n        return None\n\n    # 1. Di antara semua elemen inorder, mana yang paling kiri di preorder?\n    # Simpan index inorder nya\n    selesai = False\n    preorder_idx = 0\n    while (preorder_idx &lt; len(preorder)) and (not selesai):\n        # lihat tiap elemen preorder dari kiri ke kanan,\n        elemen_preorder = preorder[preorder_idx]\n        # dan untuk tiap elemen preorder, periksa satu-satu apakah sama dengan\n        # salah satu elemen inorder\n        inorder_idx = 0\n        while (inorder_idx &lt; len(inorder)) and (not selesai):\n            if inorder[inorder_idx] == elemen_preorder:\n                selesai = True\n            else:\n                inorder_idx += 1\n        preorder_idx += 1\n\n    # 2. Buatlah node dengan data di index tersebut di inorder.\n    # Kalau belum ada root (karena LinkedBintree belum dibentuk sama sekali),\n    # buatlah objek LinkedBintree dengan rootnya adalah node tersebut\n    current_root = BintreeNode(inorder[inorder_idx])\n    if is_starting_node:\n        result = LinkedBintree()\n        result.root = current_root\n\n    # 3. Pisah inorder menjadi dua bagian,\n    # yaitu sebelah kiri dari elemen inorder_idx dan sebelah kanan darinya\n    inorder_left = inorder[:inorder_idx]\n    inorder_right = inorder[(inorder_idx+1):]\n\n    current_root.left = linkedbintree_from_preorder_inorder(\n        preorder, inorder_left, is_starting_node=False\n    )\n    current_root.right = linkedbintree_from_preorder_inorder(\n        preorder, inorder_right, is_starting_node=False\n    )\n\n    if is_starting_node:\n        return result\n    else:\n        return current_root\n\n\nhasil_pre_in = linkedbintree_from_preorder_inorder(\n    preorder=[26, 89, 43, 90, 16, 54, 11, 72, 35],\n    inorder=[89, 90, 16, 43, 26, 54, 72, 11, 35]\n)\n\n\ndisplay(hasil_pre_in.get_digraph_simple())\n\n\n\n\n\n\n\n\n\n\n\nAlgoritma ini hampir sama dengan algoritma membentuk binary tree dari preorder dan inorder. Bedanya, di algoritma ini, dicari elemen inorder yang paling kanan di postorder, daripada yang paling kiri di preorder.\n\ndef linkedbintree_from_postorder_inorder(\n        postorder, inorder, is_starting_node=True\n    ):\n    \n    # Nanti di paling bawah tree kalau inorder sudah kosong,\n    # tidak perlu buat node lagi; langsung return None (NULL)\n    if len(inorder) == 0:\n        return None\n\n    # 1. Di antara semua elemen inorder, mana yang paling KANAN di postorder?\n    # Simpan index inorder nya\n    selesai = False\n    postorder_idx = len(postorder)-1 # mulai dari paling kanan, daripada dari 0\n    while (postorder_idx &gt;= 0) and (not selesai):\n        # lihat tiap elemen preorder DARI KANAN KE KIRI,\n        elemen_postorder = postorder[postorder_idx]\n        # dan untuk tiap elemen postorder, periksa satu-satu apakah sama dengan\n        # salah satu elemen inorder\n        inorder_idx = 0\n        while (inorder_idx &lt; len(inorder)) and (not selesai):\n            if inorder[inorder_idx] == elemen_postorder:\n                selesai = True\n            else:\n                inorder_idx += 1\n        postorder_idx -= 1\n\n    # 2. Buatlah node dengan data di index tersebut di inorder.\n    # Kalau belum ada root (karena LinkedBintree belum dibentuk sama sekali),\n    # buatlah objek LinkedBintree dengan rootnya adalah node tersebut\n    current_root = BintreeNode(inorder[inorder_idx])\n    if is_starting_node:\n        result = LinkedBintree()\n        result.root = current_root\n\n    # 3. Pisah inorder menjadi dua bagian,\n    # yaitu sebelah kiri dari elemen inorder_idx dan sebelah kanan darinya\n    inorder_left = inorder[:inorder_idx]\n    inorder_right = inorder[(inorder_idx+1):]\n\n    current_root.left = linkedbintree_from_postorder_inorder(\n        postorder, inorder_left, is_starting_node=False\n    )\n    current_root.right = linkedbintree_from_postorder_inorder(\n        postorder, inorder_right, is_starting_node=False\n    )\n\n    if is_starting_node:\n        return result\n    else:\n        return current_root\n\n\nhasil_post_in = linkedbintree_from_postorder_inorder(\n    postorder=[16, 90, 43, 89, 72, 35, 11, 54, 26],\n    inorder=[89, 90, 16, 43, 26, 54, 72, 11, 35]\n)\n\n\ndisplay(hasil_post_in.get_digraph_simple())\n\n\n\n\n\n\n\n\n\n\n\n\ndef linkedbintree_from_preorder_postorder(\n        preorder, postorder, is_starting_node=True\n):\n    \n    if (not is_starting_node):\n        if len(preorder) == 0 or len(postorder) == 0:\n            return None\n        if len(preorder) == 1:\n            return BintreeNode(preorder[0])\n        if len(postorder) == 1:\n            return BintreeNode(postorder[0])\n    \n    # 1. Buatlah node baru dengan datanya adalah preorder[0]\n    # (atau sama saja elemen terakhir dari postorder).\n    # Kalau belum ada root (karena LinkedBintree belum dibentuk sama sekali),\n    # buatlah objek LinkedBintree dengan rootnya adalah node tersebut\n    current_root = BintreeNode(preorder[0])\n    if is_starting_node:\n        result = LinkedBintree()\n        result.root = current_root\n    \n    # 2. Tentukan list postorder untuk left subtree dan untuk right subtree:\n    # 2a. Carilah letak preorder[1] di postorder, misal postorder_idx\n    # 2b. Belah postorder menjadi dua, dengan postorder_idx masuk ke kiri,\n    #     dan elemen terakhir postorder tidak masuk keduanya\n\n    postorder_idx = 0\n    while (postorder_idx &lt; len(postorder) and\n           postorder[postorder_idx] != preorder[1]):\n        postorder_idx += 1\n    \n    # 0 &lt;= indeks &lt; (postorder_idx+1)\n    postorder_left = postorder[ 0 : (postorder_idx+1) ]\n\n    # (postorder_idx+1) &lt;= indeks &lt; elemen terakhir (indeks -1)\n    postorder_right = postorder[ (postorder_idx+1) : -1 ]\n\n    # 3. Tentukan list preorder untuk left subtree dan untuk right subtree:\n    # 3a. Carilah letak postorder[-2] di preorder, misal preorder_idx\n    # 3b. Belah preorder menjadi dua, dengan preorder_idx masuk ke kanan,\n    #     dan elemen pertama preorder tidak masuk keduanya\n\n    preorder_idx = 0\n    while (preorder_idx &lt; len(preorder) and\n           preorder[preorder_idx] != postorder[-2]):\n        preorder_idx += 1\n    \n    # 1 &lt;= indeks &lt; preorder_idx\n    preorder_left = preorder[ 1 : preorder_idx ]\n\n    # preorder_idx &lt;= indeks\n    preorder_right = preorder[ preorder_idx : ]\n\n    print(\"preorder_left\", len(preorder_left))\n    print(\"preorder_right\", len(preorder_right))\n    print(\"postorder_left\", len(postorder_left))\n    print(\"postorder_right\", len(postorder_right))\n\n    # 4. Langkah rekursif: melakukan langkah yang sama di left subtree dan\n    # right subtree, hasilnya disambung ke current_root\n\n    current_root.left = linkedbintree_from_preorder_postorder(\n        preorder=preorder_left, postorder=postorder_left,\n        is_starting_node=False\n    )\n    current_root.right = linkedbintree_from_preorder_postorder(\n        preorder=preorder_right, postorder=postorder_right,\n        is_starting_node=False\n    )\n\n    if is_starting_node:\n        return result\n    else:\n        return current_root\n\n\ntest_pre_post = linkedbintree_from_preorder_postorder(\n    preorder=[\"F\", \"B\", \"A\", \"D\", \"C\", \"E\", \"G\", \"I\", \"H\"],\n    postorder=[\"A\", \"C\", \"E\", \"D\", \"B\", \"H\", \"I\", \"G\", \"F\"]\n)\n\npreorder_left 5\npreorder_right 3\npostorder_left 5\npostorder_right 3\npreorder_left 1\npreorder_right 3\npostorder_left 1\npostorder_right 3\npreorder_left 1\npreorder_right 1\npostorder_left 1\npostorder_right 1\npreorder_left 0\npreorder_right 2\npostorder_left 2\npostorder_right 0\n\n\n\ndisplay(test_pre_post.get_digraph_simple())"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul06.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul06.html",
    "title": "Modul 6 Struktur Data: Stack dan urusan notasi prefix, infix, postfix",
    "section": "",
    "text": "Kembali ke Struktur Data (dengan Python)\nDi praktikum kali ini tentang stack, kita akan membahas implementasi stack (baik dengan array maupun dengan linked list) serta contoh penggunaannya. Selain itu, kita akan membahas tentang penggunaan stack ketika berurusan dengan notasi prefix, infix, dan postfix.\n\nimport numpy as np\nimport graphviz as gv\n\n\n\n\n\n\nclass ArrayStack:\n    def __init__(self, dtype, max):\n        self.dtype = dtype\n        self.max = max\n        self.array = np.empty(max, dtype=dtype)\n        self.top = -1\n    \n    def get_size(self):\n        return self.top + 1\n    \n    def get_capacity(self):\n        return self.max\n    \n    def get_dtype(self):\n        return self.dtype\n\n    def is_empty(self):\n        if self.get_size() &gt; 0:\n            return False\n        else:\n            return True\n    \n    def is_full(self):\n        if self.get_size() &gt;= self.get_capacity():\n            # if top+1 &gt;= max\n            # atau sama saja, if top &gt;= max-1\n            return True\n        else:\n            return False\n\n    def push(self, newdata):\n        if self.is_full():\n            print(\"Error push: stack sudah penuh.\")\n        else:\n            self.top += 1\n            self.array[self.top] = newdata\n    \n    def peek(self):\n        if self.is_empty():\n            print(\"Error peek: stack sedang kosong.\")\n            return None\n        else:\n            return self.array[self.top]\n    \n    def pop(self):\n        if self.is_empty():\n            print(\"Error pop: stack sudah kosong sebelumnya.\")\n            return None\n        else:\n            output = self.array[self.top]\n            self.top -= 1\n            return output\n\n    def print_stack(self):\n        i = self.top\n        while i &gt;= 0:\n            print(self.array[i])\n            i -= 1\n\n    # print array\n    def print_storage(self):\n        print(self.array)\n    \n    def get_digraph_stack(self):\n        new_digraph = gv.Digraph()\n        # gambar akan terdiri dari satu tabel saja, satu kolom,\n        # dan tiap baris adalah tiap elemen di stack\n\n        tabel_besar = \"&lt;\"\n        # pembuka tabel\n        tabel_besar += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n        # menambahkan tiap elemen sebagai baris tersendiri\n        i = self.top\n        if i &lt; 0:\n            tabel_besar += \"&lt;TR&gt;&lt;TD&gt;\"\n            tabel_besar += \"(Stack sedang kosong; tidak ada data sama sekali.)\"\n            tabel_besar += \"&lt;/TD&gt;&lt;/TR&gt;\"\n        while i &gt;= 0:\n            tabel_besar += \"&lt;TR&gt;&lt;TD&gt;\"\n            tabel_besar += str(self.array[i])\n            tabel_besar += \"&lt;/TD&gt;&lt;/TR&gt;\"\n            i -= 1\n        # penutup tabel\n        tabel_besar += \"&lt;/TABLE&gt;\"\n        tabel_besar += \"&gt;\"\n        new_digraph.node(\"ArrayStack\", shape=\"none\", label=tabel_besar)\n        return new_digraph\n\n    def get_digraph_storage(self):\n        # menggambar array\n        new_digraph = gv.Digraph()\n\n        # pembuka tabel\n        tabel_besar = \"&lt;\"\n        tabel_besar += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n        # tabel hanya terdiri dari satu baris\n        tabel_besar += \"&lt;TR&gt;\"\n        # satu elemen per kolom\n        for i in range(self.get_capacity()):\n            tabel_besar += \"&lt;TD&gt;\"\n            tabel_besar += str(self.array[i])\n            tabel_besar += \"&lt;/TD&gt;\"\n        # penutup baris\n        tabel_besar += \"&lt;/TR&gt;\"\n        # penutup tabel\n        tabel_besar += \"&lt;/TABLE&gt;\"\n        tabel_besar += \"&gt;\"\n        new_digraph.node(\"array\", shape=\"none\", label=tabel_besar)\n        return new_digraph\n\n\narraystack = ArrayStack(int, 5)\narraystack.push(5)\narraystack.push(80)\narraystack.push(100)\n\n\narraystack.print_stack()\n\n100\n80\n5\n\n\n\nprint(arraystack.get_capacity())\n\n5\n\n\n\narraystack.print_storage()\n\n[                  5                  80                 100\n 4622241330054037504 4625478292286210048]\n\n\n\nprint(arraystack.peek())\n\n100\n\n\n\narraystack.print_stack()\n\n100\n80\n5\n\n\n\nnilai = arraystack.pop()\nprint(nilai)\n\n100\n\n\n\narraystack.print_stack()\n\n80\n5\n\n\n\narraystack.print_storage()\n\n[                  5                  80                 100\n 4622241330054037504 4625478292286210048]\n\n\n\narraystack.push(-10)\narraystack.push(57)\n\n\narraystack.print_stack()\n\n57\n-10\n80\n5\n\n\n\narraystack.print_storage()\n\n[                  5                  80                 -10\n                  57 4625478292286210048]\n\n\n\ngraf1 = arraystack.get_digraph_stack()\n\n\ndisplay(graf1)\n\n\n\n\n\n\n\n\n\ngraf2 = arraystack.get_digraph_storage()\n\n\ndisplay(graf2)\n\n\n\n\n\n\n\n\n\narraystack.push(90)\n\n\narraystack.push(46)\n\nError push: stack sudah penuh.\n\n\n\narraystack.print_storage()\n\n[  5  80 -10  57  90]\n\n\n\nprint(arraystack.pop())\nprint(arraystack.pop())\nprint(arraystack.pop())\nprint(arraystack.pop())\nprint(arraystack.pop())\n\n90\n57\n-10\n80\n5\n\n\n\nprint(arraystack.pop())\n\nError pop: stack sudah kosong sebelumnya.\nNone\n\n\n\nprint(arraystack.get_size())\n\n0\n\n\n\narraystack.print_stack()\n\n\narraystack.print_storage()\n\n[  5  80 -10  57  90]\n\n\n\ndisplay(arraystack.get_digraph_stack())\n\n\n\n\n\n\n\n\n\n\n\n\nclass SLNode:\n    def __init__(self, data, next=None):\n        self.data = data\n        self.next = next\n\n\nclass SLStack:\n    def __init__(self):\n        # \"head\" ganti nama jadi top\n        self.top = None\n    \n    def is_empty(self):\n        if self.top == None:\n            return True\n        else:\n            return False\n    \n    def push(self, newdata):\n        newnode = SLNode(newdata)\n        newnode.next = self.top\n        self.top = newnode\n    \n    def peek(self):\n        if self.is_empty():\n            print(\"Error peek: stack sedang kosong.\")\n        else:\n            return self.top.data\n    \n    def pop(self):\n        if self.is_empty():\n            print(\"Error pop: stack sudah kosong sebelumnya.\")\n        else:\n            output = self.top.data\n            temp = self.top\n            self.top = self.top.next\n            del temp\n            return output\n    \n    def get_size(self):\n        temp = self.top\n        size = 0\n        while temp != None:\n            size += 1\n            temp = temp.next\n        return size\n\n    def print_stack(self):\n        temp = self.top\n        while temp != None:\n            print(temp.data)\n            temp = temp.next\n    \n    # print linked list\n    def print_storage(self):\n        print(\"top -&gt; \", end=\"\")\n        temp = self.top\n        while temp != None:\n            print(temp.data, end=\" -&gt; \")\n            temp = temp.next\n        print(\"None\")\n    \n    def get_digraph_stack(self):\n        new_digraph = gv.Digraph()\n        # gambar akan terdiri dari satu tabel saja, satu kolom,\n        # dan tiap baris adalah tiap elemen di stack\n        tabel_besar = \"\"\n        tabel_besar += \"&lt;\"\n        tabel_besar += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n        temp = self.top\n        if temp == None:\n            tabel_besar += \"&lt;TR&gt;&lt;TD&gt;\"\n            tabel_besar += \"(Stack sedang kosong; tidak ada data sama sekali.)\"\n            tabel_besar += \"&lt;/TD&gt;&lt;/TR&gt;\"\n        while temp != None:\n            tabel_besar += \"&lt;TR&gt;&lt;TD&gt;\"\n            tabel_besar += str(temp.data)\n            tabel_besar += \"&lt;/TD&gt;&lt;/TR&gt;\"\n            temp = temp.next\n        # penutup tabel\n        tabel_besar += \"&lt;/TABLE&gt;\"\n        tabel_besar += \"&gt;\"\n        new_digraph.node(\"SLStack\", shape=\"none\", label=tabel_besar)\n        return new_digraph\n\n    # copas dari modul linked list, tapi head ganti jadi top\n    def get_digraph_storage(self):\n        # Buat digraph baru yang sifatnya dari kiri ke kanan\n        new_digraph = gv.Digraph(graph_attr={\"rankdir\": \"LR\"})\n        \n        # Pointer untuk menunjuk ke tiap node, mulai dari node pertama\n        # (akan dilakukan traversal)\n        current = self.top\n\n        # Untuk menghitung node ke-sekian untuk nama node di Graphviz,\n        # sehingga top menunjuk ke node0, lalu node0 menunjuk ke node1, dst\n        counter = 0\n\n        # Memperoleh alamat yang sedang disimpan di top\n        # - asumsi awal: tidak ada alamat (None)\n        next_id = None\n        next_name = \"node0\" # ini nanti untuk nama node berikutnya di Graphviz\n        # - kalau ternyata ada alamat...\n        if current != None:\n            # maka simpan alamat tersebut\n            next_id = hex(id(current))\n            # kita buat lebih spesifik untuk node berikutnya, tunjuk ke port id\n            next_name = \"node0:id\"\n        \n        # Label (tabel) untuk pointer top\n        # - pembuka tabel\n        str_label = \"&lt;\"\n        str_label += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n        # - baris top\n        str_label += \"&lt;TR&gt;&lt;TD&gt;top&lt;/TD&gt;&lt;/TR&gt;\"\n        # - baris alamat (sekalian membuat port namanya \"contents\")\n        str_label += \"&lt;TR&gt;&lt;TD PORT=\\\"contents\\\"&gt;\" + str(next_id) + \"&lt;/TD&gt;&lt;/TR&gt;\"\n        # - penutup tabel\n        str_label += \"&lt;/TABLE&gt;\"\n        str_label += \"&gt;\"\n\n        # Membuat node top, membuat edge dari top ke node berikutnya\n        new_digraph.node(\"top\", shape=\"none\", label=str_label)\n        new_digraph.edge(\"top:contents\", next_name)\n        # dari port \"contents\" ke node berikutnya, yang namanya next_name\n        \n        # Selama node yang ditunjuk bukan None, buatlah node nya di Graphviz,\n        # lalu lanjut ke node selanjutnya (ini traversal)\n        while current != None:\n            # Alamat yang tersimpan pada current.next\n            # - asumsi awal: tidak ada alamat; current adalah node terakhir\n            next_id = None\n            # - kalau ternyata ada alamat...\n            if current.next != None:\n                # maka simpan alamat tersebut\n                next_id = hex(id(current.next))\n            \n            # Persiapan label (tabel) untuk node\n            # - pembuka tabel\n            str_label = \"&lt;\"\n            str_label += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n            # - baris tulisan \"data\", \"next\"\n            str_label += \"&lt;TR&gt;&lt;TD&gt;data&lt;/TD&gt;&lt;TD&gt;next&lt;/TD&gt;&lt;/TR&gt;\"\n            # - baris untuk isi data dan isi next\n            str_label += \"&lt;TR&gt;\"\n            str_label += \"&lt;TD&gt;\" + str(current.data) + \"&lt;/TD&gt;\"\n            str_label += \"&lt;TD PORT=\\\"next\\\"&gt;\" + str(next_id) + \"&lt;/TD&gt;\"\n            str_label += \"&lt;/TR&gt;\"\n            # - baris tulisan \"alamat node\", merentang dua kolom\n            str_label += \"&lt;TR&gt;&lt;TD COLSPAN=\\\"2\\\"&gt;alamat node&lt;/TD&gt;&lt;/TR&gt;\"\n            # - baris untuk isi alamat node, merentang dua kolom\n            str_label += \"&lt;TR&gt;\"\n            str_label += \"&lt;TD PORT=\\\"id\\\" COLSPAN=\\\"2\\\"&gt;\"\n            str_label += str(hex(id(current)))\n            str_label += \"&lt;/TD&gt;\"\n            str_label += \"&lt;/TR&gt;\"\n            # - penutup tabel\n            str_label += \"&lt;/TABLE&gt;\"\n            str_label += \"&gt;\"\n\n            # Membuat node baru di Graphviz dengan label (tabel) tersebut\n            new_digraph.node(\"node\" + str(counter), shape=\"none\", label = str_label)\n\n            # Menentukan nama dua port yang bakal disambung dengan edge,\n            # yaitu (node saat ini):next disambung ke node(berikutnya):id\n            # yaitu bagian \"next\" disambung ke bagian alamat di node berikutnya\n            nama_node_next = \"node\" + str(counter) + \":next\"\n            if current.next != None:\n                nama_alamat_node_berikutnya = \"node\" + str(counter+1) + \":id\"\n            # atau ke node(berikutnya) saja tanpa id kalau itu ternyata None,\n            # karena None tidak akan memiliki port id\n            else:\n                nama_alamat_node_berikutnya = \"node\" + str(counter+1)\n            \n            # Menyambung keduanya\n            new_digraph.edge(nama_node_next, nama_alamat_node_berikutnya)\n            \n            # Lanjut ke node selanjutnya\n            current = current.next\n            counter += 1\n        # Kalau sudah keluar loop, artinya current menunjuk ke None\n        # Berarti tinggal membuat \"node\" terakhir berisi tulisan None\n        # (karena sambungannya sudah dibuat di dalam loop, tinggal node nya)\n        new_digraph.node(\"node\" + str(counter), shape=\"none\", label=\"None\")\n\n        # Digraph sudah jadi\n        return new_digraph\n\n\nslstack = SLStack()\nslstack.print_storage()\n\ntop -&gt; None\n\n\n\nslstack.push(\"abc\")\nslstack.push(\"fg\")\nslstack.push(\"ijk\")\nslstack.push(\"pqrs\")\nslstack.push(\"xyz\")\n\n\nslstack.print_stack()\n\nxyz\npqrs\nijk\nfg\nabc\n\n\n\nslstack.print_storage()\n\ntop -&gt; xyz -&gt; pqrs -&gt; ijk -&gt; fg -&gt; abc -&gt; None\n\n\n\ndisplay(slstack.get_digraph_stack())\n\n\n\n\n\n\n\n\n\nprint(slstack.pop())\nprint(slstack.pop())\nprint(slstack.pop())\n\nxyz\npqrs\nijk\n\n\n\nslstack.print_stack()\n\nfg\nabc\n\n\n\nslstack.print_storage()\n\ntop -&gt; fg -&gt; abc -&gt; None\n\n\n\ndisplay(slstack.get_digraph_stack())\n\n\n\n\n\n\n\n\n\n\n\n\ndef reverse_array_arraystack(array_old):\n    array = array_old.copy()\n\n    # memeriksa tipe data dari elemen pertama\n    tipe_data = type(array[0])\n    # khusus array, bisa juga menggunakan array.dtype\n\n    arraystack = ArrayStack(tipe_data, len(array))\n    for i in range(len(array)):\n        arraystack.push(array[i])\n    for i in range(len(array)):\n        array[i] = arraystack.pop()\n    return array\n\n\nlist1 = [\"m\", \"a\", \"t\", \"e\", \"k\"]\nlist2 = reverse_array_arraystack(list1)\nprint(list2)\n\n['k', 'e', 't', 'a', 'm']\n\n\n\ndef reverse_array_slstack(array_old):\n    array = array_old.copy()\n    slstack = SLStack()\n    for i in range(len(array)):\n        slstack.push(array[i])\n    for i in range(len(array)):\n        array[i] = slstack.pop()\n    return array\n\n\narray1 = np.array([\"m\", \"a\", \"t\", \"e\", \"k\"])\narray2 = reverse_array_slstack(array1)\nprint(array2)\n\n['k' 'e' 't' 'a' 'm']\n\n\n\n\n\n\nNotasi prefix, infix, dan postfix adalah tiga jenis notasi (cara penulisan) untuk menuliskan operasi aritmetika seperti penjumlahan, perkalian, dan sebagainya.\nMisalnya, kita bisa menuliskan penjumlahan 3 + 5, di mana dua angka, 3 dan 5, dioperasikan oleh suatu “operator” yaitu + (plus). Perhatikan bahwa operator berada di tengah, di antara kedua angka. Penulisan seperti ini disebut notasi infix, dan inilah penulisan yang biasa kita kenal.\nAda juga cara penulisan di mana operator ditempatkan sebelum kedua angka, disebut notasi prefix, seperti berikut: + 3 5\nWalaupun terlihat agak aneh, kita bisa saja mendefinisikan fungsi seperti pseuducode berikut:\nfunction add(x, y)\n    return x+y\nendfunction\nKemudian penggunaannya adalah add(3, 5), secara tidak langsung menggunakan notasi prefix :)\nSelain prefix untuk di awal dan infix untuk di tengah, kita juga bisa menempatkan operator setelah kedua angka, disebut notasi postfix. Contohnya: 3 5 +\nNotasi postfix sebenarnya tidak terlalu asing, karena misalnya untuk menuliskan faktorial itu biasanya menggunakan tanda seru setelah angkanya, lagi-lagi secara tidak langsung menggunakan notasi postfix, seperti: 4!\nSalah satu keuntungan menggunakan notasi prefix maupun postfix adalah bisa menghilangkan kurung tanpa menyebabkan ambigu. Contohnya, dalam notasi infix kita bisa menuliskan 5 * (6 + 7) agar penjumlahan dilakukan terlebih dahulu. Sedangkan, notasi prefix maupun postfix dijamin tidak membutuhkan kurung:\n\nPrefix: * 5 + 6 7\nPostfix: 6 7 + 5 *\n\nStack bisa sangat membantu untuk mengubah antara notasi prefix, infix, dan postfix.\n\n\nSebelum membahas konversi antara notasi prefix, infix, dan postfix, kita perlu membahas sebentar mengenai “tokenisasi” (tokenization), yaitu proses “memecah” suatu string yang utuh menjadi “bagian-bagiannya”.\nMisalnya, kalau kita punya notasi infix dalam string \"3 + 5\", kita bisa melakukan tokenization untuk memecahnya menjadi [\"3\", \"+\", \"5\"].\nCara mudah untuk melakukan tokenisasi, bisa dengan sekedar menganggap tiap “bagian” atau tiap “token” terpisahkan oleh spasi, sehingga bisa di-split begitu saja:\n\ndef tokenize(string_utuh):\n    hasil = string_utuh.split(\" \") # string berisi satu spasi\n    return hasil\n\n\nprint(tokenize(\"3 + 5\"))\n\n['3', '+', '5']\n\n\nAgar cara mudah ini berhasil (terutama untuk notasi infix), bahkan antara kurung buka/tutup juga harus diberi spasi, ya!\n\nprint(tokenize(\"5 * ( 6 + 7 )\"))\n\n['5', '*', '(', '6', '+', '7', ')']\n\n\n\n\n\nSebelumnya, telah disebutkan bahwa salah satu keuntungan notasi prefix maupun postfix dibandingkan notasi infix adalah penulisan yang tidak ambigu tanpa diperlukannya kurung. Agar bisa mengubah notasi infix menjadi notasi prefix ataupun notasi postfix, tentunya kita harus bisa membaca notasi infix secara tidak ambigu. Artinya, kita harus kenal dengan aturan urutan pengoperasian.\nUrusan urutan pengoperasian terbagi menjadi dua:\n\nPrecedence, semacam tingkatan prioritas antara operasi yang berbeda, yang mana yang dilakukan duluan (apalagi kalau tidak ada tanda kurung)\nAssociativity, urutan pengoperasian antara dua operasi yang precedence nya sama, apakah dari kiri ke kanan atau kanan ke kiri\n\nMisalkan ada penulisan notasi infix: 9 + 8 * 7\nTentunya perkalian dilakukan terlebih dahulu, barulah penjumlahan. Artinya, perkalian memiliki higher precedence (atau precedence yang lebih tinggi) daripada penjumlahan; bisa juga dikatakan, penjumlahan memiliki lower precedence (atau precedence yang lebih rendah) daripada perkalian.\nSedangkan, misal ada penulisan notasi infix: 8 / 4 * 2 dan 8 * 4 / 2\nKeduanya dilakukan dari kiri ke kanan. Artinya:\n\nTidak ada prioritas yang lebih utama antara pembagian maupun perkalian, sehingga keduanya memiliki equal precedence (atau precedence yang sama).\nAssociativity dari pembagian maupun perkalian bersifat left-to-right.\n\nPrecedence dan associativity dari beberapa operator bisa didata:\n\n\n\nPrecedence\nOperator\nAssociativity\n\n\n\n\n3\n^\nright-to-left\n\n\n2\n* /\nleft-to-right\n\n\n1\n+ -\nleft-to-right\n\n\n\nPerhatikan:\n\nPerpangkatan bersifat right-to-left karena \\(a^{b^c} = a^{\\left(b^c\\right)}\\).\nPembagian maupun pengurangan bersifat left-to-right karena\n\\(a/b/c = \\left(a/b\\right)/c\\) dan\n\\(a-b-c = (a-b)-c\\).\nKebetulan, perkalian maupun penjumlahan memiliki sifat asosiatif, yaitu\n\\((a*b)*c = a*(b*c)\\)\n\\((a+b)+c = a+(b+c)\\)\nsehingga perkalian maupun penjumlahan sebenarnya bersifat left-to-right maupun right-to-left sekaligus, yaitu\n\\(a*b*c = (a*b)*c = a*(b*c)\\)\n\\(a+b+c = (a+b)+c = a+(b+c)\\)\nNamun, untuk mempermudah klasifikasi, kita bisa mengkategorikan perkalian dan penjumlahan bersifat left-to-right.\n\n\n\n\n\n\n\nSetelah tokenisasi, berikut langkah mengubah notasi infix menjadi postfix.\nSiapkan suatu stack kosong, serta tempat (misal string kosong) untuk menyimpan hasil infix. Lalu, scanning (melihat satu-per-satu) tiap token dari kiri ke kanan, dan ikuti ketentuan berikut:\n\nApabila token adalah operand/angka, langsung tambahkan ke hasil infix\nApabila stack kosong, atau apabila elemen teratas pada stack adalah kurung kiri, maka push token tersebut ke dalam stack\nApabila token adalah kurung kiri yaitu “(”, push ke dalam stack\nApabila token adalah kurung kanan yaitu “)”, lakukan while loop: lakukan pop pada stack, masukkan hasil pop tersebut ke hasil infix, hentikan while loop apabila hasil pop tersebut adalah kurung kiri.\nApabila token memiliki precedence yang lebih tinggi daripada elemen teratas pada stack, maka push token tersebut ke dalam stack.\nApabila token memiliki precedence yang lebih rendah daripada elemen teratas pada stack, lakukan langkah berikut: lakukan pop pada stack, lalu masukkan hasil pop tersebut ke hasil infix.\nApabila token memiliki precedence yang setara dengan elemen teratas pada stack, perhatikan associativity dari operator tersebut, lalu:\n\nApabila untuk operator tersebut bersifat left-to-right: lakukan pop pada stack, masukkan hasil pop ke hasil infix, lalu push token\nSedangkan apabila bersifat right-to-left: push token tersebut ke dalam stack\n\n\nSetelah suatu token teratasi, tentunya langsung lanjut melihat token berikutnya. Apabila semua token sudah teratasi sedangkan stack belum kosong, maka ulangi sampai stack kosong: lakukan pop, masukkan hasil pop ke hasil infix."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul06.html#implementasi-dan-contoh-penggunaan-stack",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul06.html#implementasi-dan-contoh-penggunaan-stack",
    "title": "Modul 6 Struktur Data: Stack dan urusan notasi prefix, infix, postfix",
    "section": "",
    "text": "class ArrayStack:\n    def __init__(self, dtype, max):\n        self.dtype = dtype\n        self.max = max\n        self.array = np.empty(max, dtype=dtype)\n        self.top = -1\n    \n    def get_size(self):\n        return self.top + 1\n    \n    def get_capacity(self):\n        return self.max\n    \n    def get_dtype(self):\n        return self.dtype\n\n    def is_empty(self):\n        if self.get_size() &gt; 0:\n            return False\n        else:\n            return True\n    \n    def is_full(self):\n        if self.get_size() &gt;= self.get_capacity():\n            # if top+1 &gt;= max\n            # atau sama saja, if top &gt;= max-1\n            return True\n        else:\n            return False\n\n    def push(self, newdata):\n        if self.is_full():\n            print(\"Error push: stack sudah penuh.\")\n        else:\n            self.top += 1\n            self.array[self.top] = newdata\n    \n    def peek(self):\n        if self.is_empty():\n            print(\"Error peek: stack sedang kosong.\")\n            return None\n        else:\n            return self.array[self.top]\n    \n    def pop(self):\n        if self.is_empty():\n            print(\"Error pop: stack sudah kosong sebelumnya.\")\n            return None\n        else:\n            output = self.array[self.top]\n            self.top -= 1\n            return output\n\n    def print_stack(self):\n        i = self.top\n        while i &gt;= 0:\n            print(self.array[i])\n            i -= 1\n\n    # print array\n    def print_storage(self):\n        print(self.array)\n    \n    def get_digraph_stack(self):\n        new_digraph = gv.Digraph()\n        # gambar akan terdiri dari satu tabel saja, satu kolom,\n        # dan tiap baris adalah tiap elemen di stack\n\n        tabel_besar = \"&lt;\"\n        # pembuka tabel\n        tabel_besar += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n        # menambahkan tiap elemen sebagai baris tersendiri\n        i = self.top\n        if i &lt; 0:\n            tabel_besar += \"&lt;TR&gt;&lt;TD&gt;\"\n            tabel_besar += \"(Stack sedang kosong; tidak ada data sama sekali.)\"\n            tabel_besar += \"&lt;/TD&gt;&lt;/TR&gt;\"\n        while i &gt;= 0:\n            tabel_besar += \"&lt;TR&gt;&lt;TD&gt;\"\n            tabel_besar += str(self.array[i])\n            tabel_besar += \"&lt;/TD&gt;&lt;/TR&gt;\"\n            i -= 1\n        # penutup tabel\n        tabel_besar += \"&lt;/TABLE&gt;\"\n        tabel_besar += \"&gt;\"\n        new_digraph.node(\"ArrayStack\", shape=\"none\", label=tabel_besar)\n        return new_digraph\n\n    def get_digraph_storage(self):\n        # menggambar array\n        new_digraph = gv.Digraph()\n\n        # pembuka tabel\n        tabel_besar = \"&lt;\"\n        tabel_besar += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n        # tabel hanya terdiri dari satu baris\n        tabel_besar += \"&lt;TR&gt;\"\n        # satu elemen per kolom\n        for i in range(self.get_capacity()):\n            tabel_besar += \"&lt;TD&gt;\"\n            tabel_besar += str(self.array[i])\n            tabel_besar += \"&lt;/TD&gt;\"\n        # penutup baris\n        tabel_besar += \"&lt;/TR&gt;\"\n        # penutup tabel\n        tabel_besar += \"&lt;/TABLE&gt;\"\n        tabel_besar += \"&gt;\"\n        new_digraph.node(\"array\", shape=\"none\", label=tabel_besar)\n        return new_digraph\n\n\narraystack = ArrayStack(int, 5)\narraystack.push(5)\narraystack.push(80)\narraystack.push(100)\n\n\narraystack.print_stack()\n\n100\n80\n5\n\n\n\nprint(arraystack.get_capacity())\n\n5\n\n\n\narraystack.print_storage()\n\n[                  5                  80                 100\n 4622241330054037504 4625478292286210048]\n\n\n\nprint(arraystack.peek())\n\n100\n\n\n\narraystack.print_stack()\n\n100\n80\n5\n\n\n\nnilai = arraystack.pop()\nprint(nilai)\n\n100\n\n\n\narraystack.print_stack()\n\n80\n5\n\n\n\narraystack.print_storage()\n\n[                  5                  80                 100\n 4622241330054037504 4625478292286210048]\n\n\n\narraystack.push(-10)\narraystack.push(57)\n\n\narraystack.print_stack()\n\n57\n-10\n80\n5\n\n\n\narraystack.print_storage()\n\n[                  5                  80                 -10\n                  57 4625478292286210048]\n\n\n\ngraf1 = arraystack.get_digraph_stack()\n\n\ndisplay(graf1)\n\n\n\n\n\n\n\n\n\ngraf2 = arraystack.get_digraph_storage()\n\n\ndisplay(graf2)\n\n\n\n\n\n\n\n\n\narraystack.push(90)\n\n\narraystack.push(46)\n\nError push: stack sudah penuh.\n\n\n\narraystack.print_storage()\n\n[  5  80 -10  57  90]\n\n\n\nprint(arraystack.pop())\nprint(arraystack.pop())\nprint(arraystack.pop())\nprint(arraystack.pop())\nprint(arraystack.pop())\n\n90\n57\n-10\n80\n5\n\n\n\nprint(arraystack.pop())\n\nError pop: stack sudah kosong sebelumnya.\nNone\n\n\n\nprint(arraystack.get_size())\n\n0\n\n\n\narraystack.print_stack()\n\n\narraystack.print_storage()\n\n[  5  80 -10  57  90]\n\n\n\ndisplay(arraystack.get_digraph_stack())\n\n\n\n\n\n\n\n\n\n\n\n\nclass SLNode:\n    def __init__(self, data, next=None):\n        self.data = data\n        self.next = next\n\n\nclass SLStack:\n    def __init__(self):\n        # \"head\" ganti nama jadi top\n        self.top = None\n    \n    def is_empty(self):\n        if self.top == None:\n            return True\n        else:\n            return False\n    \n    def push(self, newdata):\n        newnode = SLNode(newdata)\n        newnode.next = self.top\n        self.top = newnode\n    \n    def peek(self):\n        if self.is_empty():\n            print(\"Error peek: stack sedang kosong.\")\n        else:\n            return self.top.data\n    \n    def pop(self):\n        if self.is_empty():\n            print(\"Error pop: stack sudah kosong sebelumnya.\")\n        else:\n            output = self.top.data\n            temp = self.top\n            self.top = self.top.next\n            del temp\n            return output\n    \n    def get_size(self):\n        temp = self.top\n        size = 0\n        while temp != None:\n            size += 1\n            temp = temp.next\n        return size\n\n    def print_stack(self):\n        temp = self.top\n        while temp != None:\n            print(temp.data)\n            temp = temp.next\n    \n    # print linked list\n    def print_storage(self):\n        print(\"top -&gt; \", end=\"\")\n        temp = self.top\n        while temp != None:\n            print(temp.data, end=\" -&gt; \")\n            temp = temp.next\n        print(\"None\")\n    \n    def get_digraph_stack(self):\n        new_digraph = gv.Digraph()\n        # gambar akan terdiri dari satu tabel saja, satu kolom,\n        # dan tiap baris adalah tiap elemen di stack\n        tabel_besar = \"\"\n        tabel_besar += \"&lt;\"\n        tabel_besar += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n        temp = self.top\n        if temp == None:\n            tabel_besar += \"&lt;TR&gt;&lt;TD&gt;\"\n            tabel_besar += \"(Stack sedang kosong; tidak ada data sama sekali.)\"\n            tabel_besar += \"&lt;/TD&gt;&lt;/TR&gt;\"\n        while temp != None:\n            tabel_besar += \"&lt;TR&gt;&lt;TD&gt;\"\n            tabel_besar += str(temp.data)\n            tabel_besar += \"&lt;/TD&gt;&lt;/TR&gt;\"\n            temp = temp.next\n        # penutup tabel\n        tabel_besar += \"&lt;/TABLE&gt;\"\n        tabel_besar += \"&gt;\"\n        new_digraph.node(\"SLStack\", shape=\"none\", label=tabel_besar)\n        return new_digraph\n\n    # copas dari modul linked list, tapi head ganti jadi top\n    def get_digraph_storage(self):\n        # Buat digraph baru yang sifatnya dari kiri ke kanan\n        new_digraph = gv.Digraph(graph_attr={\"rankdir\": \"LR\"})\n        \n        # Pointer untuk menunjuk ke tiap node, mulai dari node pertama\n        # (akan dilakukan traversal)\n        current = self.top\n\n        # Untuk menghitung node ke-sekian untuk nama node di Graphviz,\n        # sehingga top menunjuk ke node0, lalu node0 menunjuk ke node1, dst\n        counter = 0\n\n        # Memperoleh alamat yang sedang disimpan di top\n        # - asumsi awal: tidak ada alamat (None)\n        next_id = None\n        next_name = \"node0\" # ini nanti untuk nama node berikutnya di Graphviz\n        # - kalau ternyata ada alamat...\n        if current != None:\n            # maka simpan alamat tersebut\n            next_id = hex(id(current))\n            # kita buat lebih spesifik untuk node berikutnya, tunjuk ke port id\n            next_name = \"node0:id\"\n        \n        # Label (tabel) untuk pointer top\n        # - pembuka tabel\n        str_label = \"&lt;\"\n        str_label += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n        # - baris top\n        str_label += \"&lt;TR&gt;&lt;TD&gt;top&lt;/TD&gt;&lt;/TR&gt;\"\n        # - baris alamat (sekalian membuat port namanya \"contents\")\n        str_label += \"&lt;TR&gt;&lt;TD PORT=\\\"contents\\\"&gt;\" + str(next_id) + \"&lt;/TD&gt;&lt;/TR&gt;\"\n        # - penutup tabel\n        str_label += \"&lt;/TABLE&gt;\"\n        str_label += \"&gt;\"\n\n        # Membuat node top, membuat edge dari top ke node berikutnya\n        new_digraph.node(\"top\", shape=\"none\", label=str_label)\n        new_digraph.edge(\"top:contents\", next_name)\n        # dari port \"contents\" ke node berikutnya, yang namanya next_name\n        \n        # Selama node yang ditunjuk bukan None, buatlah node nya di Graphviz,\n        # lalu lanjut ke node selanjutnya (ini traversal)\n        while current != None:\n            # Alamat yang tersimpan pada current.next\n            # - asumsi awal: tidak ada alamat; current adalah node terakhir\n            next_id = None\n            # - kalau ternyata ada alamat...\n            if current.next != None:\n                # maka simpan alamat tersebut\n                next_id = hex(id(current.next))\n            \n            # Persiapan label (tabel) untuk node\n            # - pembuka tabel\n            str_label = \"&lt;\"\n            str_label += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n            # - baris tulisan \"data\", \"next\"\n            str_label += \"&lt;TR&gt;&lt;TD&gt;data&lt;/TD&gt;&lt;TD&gt;next&lt;/TD&gt;&lt;/TR&gt;\"\n            # - baris untuk isi data dan isi next\n            str_label += \"&lt;TR&gt;\"\n            str_label += \"&lt;TD&gt;\" + str(current.data) + \"&lt;/TD&gt;\"\n            str_label += \"&lt;TD PORT=\\\"next\\\"&gt;\" + str(next_id) + \"&lt;/TD&gt;\"\n            str_label += \"&lt;/TR&gt;\"\n            # - baris tulisan \"alamat node\", merentang dua kolom\n            str_label += \"&lt;TR&gt;&lt;TD COLSPAN=\\\"2\\\"&gt;alamat node&lt;/TD&gt;&lt;/TR&gt;\"\n            # - baris untuk isi alamat node, merentang dua kolom\n            str_label += \"&lt;TR&gt;\"\n            str_label += \"&lt;TD PORT=\\\"id\\\" COLSPAN=\\\"2\\\"&gt;\"\n            str_label += str(hex(id(current)))\n            str_label += \"&lt;/TD&gt;\"\n            str_label += \"&lt;/TR&gt;\"\n            # - penutup tabel\n            str_label += \"&lt;/TABLE&gt;\"\n            str_label += \"&gt;\"\n\n            # Membuat node baru di Graphviz dengan label (tabel) tersebut\n            new_digraph.node(\"node\" + str(counter), shape=\"none\", label = str_label)\n\n            # Menentukan nama dua port yang bakal disambung dengan edge,\n            # yaitu (node saat ini):next disambung ke node(berikutnya):id\n            # yaitu bagian \"next\" disambung ke bagian alamat di node berikutnya\n            nama_node_next = \"node\" + str(counter) + \":next\"\n            if current.next != None:\n                nama_alamat_node_berikutnya = \"node\" + str(counter+1) + \":id\"\n            # atau ke node(berikutnya) saja tanpa id kalau itu ternyata None,\n            # karena None tidak akan memiliki port id\n            else:\n                nama_alamat_node_berikutnya = \"node\" + str(counter+1)\n            \n            # Menyambung keduanya\n            new_digraph.edge(nama_node_next, nama_alamat_node_berikutnya)\n            \n            # Lanjut ke node selanjutnya\n            current = current.next\n            counter += 1\n        # Kalau sudah keluar loop, artinya current menunjuk ke None\n        # Berarti tinggal membuat \"node\" terakhir berisi tulisan None\n        # (karena sambungannya sudah dibuat di dalam loop, tinggal node nya)\n        new_digraph.node(\"node\" + str(counter), shape=\"none\", label=\"None\")\n\n        # Digraph sudah jadi\n        return new_digraph\n\n\nslstack = SLStack()\nslstack.print_storage()\n\ntop -&gt; None\n\n\n\nslstack.push(\"abc\")\nslstack.push(\"fg\")\nslstack.push(\"ijk\")\nslstack.push(\"pqrs\")\nslstack.push(\"xyz\")\n\n\nslstack.print_stack()\n\nxyz\npqrs\nijk\nfg\nabc\n\n\n\nslstack.print_storage()\n\ntop -&gt; xyz -&gt; pqrs -&gt; ijk -&gt; fg -&gt; abc -&gt; None\n\n\n\ndisplay(slstack.get_digraph_stack())\n\n\n\n\n\n\n\n\n\nprint(slstack.pop())\nprint(slstack.pop())\nprint(slstack.pop())\n\nxyz\npqrs\nijk\n\n\n\nslstack.print_stack()\n\nfg\nabc\n\n\n\nslstack.print_storage()\n\ntop -&gt; fg -&gt; abc -&gt; None\n\n\n\ndisplay(slstack.get_digraph_stack())\n\n\n\n\n\n\n\n\n\n\n\n\ndef reverse_array_arraystack(array_old):\n    array = array_old.copy()\n\n    # memeriksa tipe data dari elemen pertama\n    tipe_data = type(array[0])\n    # khusus array, bisa juga menggunakan array.dtype\n\n    arraystack = ArrayStack(tipe_data, len(array))\n    for i in range(len(array)):\n        arraystack.push(array[i])\n    for i in range(len(array)):\n        array[i] = arraystack.pop()\n    return array\n\n\nlist1 = [\"m\", \"a\", \"t\", \"e\", \"k\"]\nlist2 = reverse_array_arraystack(list1)\nprint(list2)\n\n['k', 'e', 't', 'a', 'm']\n\n\n\ndef reverse_array_slstack(array_old):\n    array = array_old.copy()\n    slstack = SLStack()\n    for i in range(len(array)):\n        slstack.push(array[i])\n    for i in range(len(array)):\n        array[i] = slstack.pop()\n    return array\n\n\narray1 = np.array([\"m\", \"a\", \"t\", \"e\", \"k\"])\narray2 = reverse_array_slstack(array1)\nprint(array2)\n\n['k' 'e' 't' 'a' 'm']"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul06.html#todo-notasi-prefix-infix-dan-postfix",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul06.html#todo-notasi-prefix-infix-dan-postfix",
    "title": "Modul 6 Struktur Data: Stack dan urusan notasi prefix, infix, postfix",
    "section": "",
    "text": "Notasi prefix, infix, dan postfix adalah tiga jenis notasi (cara penulisan) untuk menuliskan operasi aritmetika seperti penjumlahan, perkalian, dan sebagainya.\nMisalnya, kita bisa menuliskan penjumlahan 3 + 5, di mana dua angka, 3 dan 5, dioperasikan oleh suatu “operator” yaitu + (plus). Perhatikan bahwa operator berada di tengah, di antara kedua angka. Penulisan seperti ini disebut notasi infix, dan inilah penulisan yang biasa kita kenal.\nAda juga cara penulisan di mana operator ditempatkan sebelum kedua angka, disebut notasi prefix, seperti berikut: + 3 5\nWalaupun terlihat agak aneh, kita bisa saja mendefinisikan fungsi seperti pseuducode berikut:\nfunction add(x, y)\n    return x+y\nendfunction\nKemudian penggunaannya adalah add(3, 5), secara tidak langsung menggunakan notasi prefix :)\nSelain prefix untuk di awal dan infix untuk di tengah, kita juga bisa menempatkan operator setelah kedua angka, disebut notasi postfix. Contohnya: 3 5 +\nNotasi postfix sebenarnya tidak terlalu asing, karena misalnya untuk menuliskan faktorial itu biasanya menggunakan tanda seru setelah angkanya, lagi-lagi secara tidak langsung menggunakan notasi postfix, seperti: 4!\nSalah satu keuntungan menggunakan notasi prefix maupun postfix adalah bisa menghilangkan kurung tanpa menyebabkan ambigu. Contohnya, dalam notasi infix kita bisa menuliskan 5 * (6 + 7) agar penjumlahan dilakukan terlebih dahulu. Sedangkan, notasi prefix maupun postfix dijamin tidak membutuhkan kurung:\n\nPrefix: * 5 + 6 7\nPostfix: 6 7 + 5 *\n\nStack bisa sangat membantu untuk mengubah antara notasi prefix, infix, dan postfix.\n\n\nSebelum membahas konversi antara notasi prefix, infix, dan postfix, kita perlu membahas sebentar mengenai “tokenisasi” (tokenization), yaitu proses “memecah” suatu string yang utuh menjadi “bagian-bagiannya”.\nMisalnya, kalau kita punya notasi infix dalam string \"3 + 5\", kita bisa melakukan tokenization untuk memecahnya menjadi [\"3\", \"+\", \"5\"].\nCara mudah untuk melakukan tokenisasi, bisa dengan sekedar menganggap tiap “bagian” atau tiap “token” terpisahkan oleh spasi, sehingga bisa di-split begitu saja:\n\ndef tokenize(string_utuh):\n    hasil = string_utuh.split(\" \") # string berisi satu spasi\n    return hasil\n\n\nprint(tokenize(\"3 + 5\"))\n\n['3', '+', '5']\n\n\nAgar cara mudah ini berhasil (terutama untuk notasi infix), bahkan antara kurung buka/tutup juga harus diberi spasi, ya!\n\nprint(tokenize(\"5 * ( 6 + 7 )\"))\n\n['5', '*', '(', '6', '+', '7', ')']\n\n\n\n\n\nSebelumnya, telah disebutkan bahwa salah satu keuntungan notasi prefix maupun postfix dibandingkan notasi infix adalah penulisan yang tidak ambigu tanpa diperlukannya kurung. Agar bisa mengubah notasi infix menjadi notasi prefix ataupun notasi postfix, tentunya kita harus bisa membaca notasi infix secara tidak ambigu. Artinya, kita harus kenal dengan aturan urutan pengoperasian.\nUrusan urutan pengoperasian terbagi menjadi dua:\n\nPrecedence, semacam tingkatan prioritas antara operasi yang berbeda, yang mana yang dilakukan duluan (apalagi kalau tidak ada tanda kurung)\nAssociativity, urutan pengoperasian antara dua operasi yang precedence nya sama, apakah dari kiri ke kanan atau kanan ke kiri\n\nMisalkan ada penulisan notasi infix: 9 + 8 * 7\nTentunya perkalian dilakukan terlebih dahulu, barulah penjumlahan. Artinya, perkalian memiliki higher precedence (atau precedence yang lebih tinggi) daripada penjumlahan; bisa juga dikatakan, penjumlahan memiliki lower precedence (atau precedence yang lebih rendah) daripada perkalian.\nSedangkan, misal ada penulisan notasi infix: 8 / 4 * 2 dan 8 * 4 / 2\nKeduanya dilakukan dari kiri ke kanan. Artinya:\n\nTidak ada prioritas yang lebih utama antara pembagian maupun perkalian, sehingga keduanya memiliki equal precedence (atau precedence yang sama).\nAssociativity dari pembagian maupun perkalian bersifat left-to-right.\n\nPrecedence dan associativity dari beberapa operator bisa didata:\n\n\n\nPrecedence\nOperator\nAssociativity\n\n\n\n\n3\n^\nright-to-left\n\n\n2\n* /\nleft-to-right\n\n\n1\n+ -\nleft-to-right\n\n\n\nPerhatikan:\n\nPerpangkatan bersifat right-to-left karena \\(a^{b^c} = a^{\\left(b^c\\right)}\\).\nPembagian maupun pengurangan bersifat left-to-right karena\n\\(a/b/c = \\left(a/b\\right)/c\\) dan\n\\(a-b-c = (a-b)-c\\).\nKebetulan, perkalian maupun penjumlahan memiliki sifat asosiatif, yaitu\n\\((a*b)*c = a*(b*c)\\)\n\\((a+b)+c = a+(b+c)\\)\nsehingga perkalian maupun penjumlahan sebenarnya bersifat left-to-right maupun right-to-left sekaligus, yaitu\n\\(a*b*c = (a*b)*c = a*(b*c)\\)\n\\(a+b+c = (a+b)+c = a+(b+c)\\)\nNamun, untuk mempermudah klasifikasi, kita bisa mengkategorikan perkalian dan penjumlahan bersifat left-to-right."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul06.html#todo-urusan-notasi-prefix-infix-dan-postfix-dengan-stack",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul06.html#todo-urusan-notasi-prefix-infix-dan-postfix-dengan-stack",
    "title": "Modul 6 Struktur Data: Stack dan urusan notasi prefix, infix, postfix",
    "section": "",
    "text": "Setelah tokenisasi, berikut langkah mengubah notasi infix menjadi postfix.\nSiapkan suatu stack kosong, serta tempat (misal string kosong) untuk menyimpan hasil infix. Lalu, scanning (melihat satu-per-satu) tiap token dari kiri ke kanan, dan ikuti ketentuan berikut:\n\nApabila token adalah operand/angka, langsung tambahkan ke hasil infix\nApabila stack kosong, atau apabila elemen teratas pada stack adalah kurung kiri, maka push token tersebut ke dalam stack\nApabila token adalah kurung kiri yaitu “(”, push ke dalam stack\nApabila token adalah kurung kanan yaitu “)”, lakukan while loop: lakukan pop pada stack, masukkan hasil pop tersebut ke hasil infix, hentikan while loop apabila hasil pop tersebut adalah kurung kiri.\nApabila token memiliki precedence yang lebih tinggi daripada elemen teratas pada stack, maka push token tersebut ke dalam stack.\nApabila token memiliki precedence yang lebih rendah daripada elemen teratas pada stack, lakukan langkah berikut: lakukan pop pada stack, lalu masukkan hasil pop tersebut ke hasil infix.\nApabila token memiliki precedence yang setara dengan elemen teratas pada stack, perhatikan associativity dari operator tersebut, lalu:\n\nApabila untuk operator tersebut bersifat left-to-right: lakukan pop pada stack, masukkan hasil pop ke hasil infix, lalu push token\nSedangkan apabila bersifat right-to-left: push token tersebut ke dalam stack\n\n\nSetelah suatu token teratasi, tentunya langsung lanjut melihat token berikutnya. Apabila semua token sudah teratasi sedangkan stack belum kosong, maka ulangi sampai stack kosong: lakukan pop, masukkan hasil pop ke hasil infix."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul04.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul04.html",
    "title": "Modul 4 Struktur Data: Array, Searching, Sorting",
    "section": "",
    "text": "Kembali ke Struktur Data (dengan Python)\nPada pertemuan ini, kita akan membahas tentang operasi pada array, termasuk melihat beberapa algoritma-algoritma searching dan sorting pada array.\n\n\nSebagian besar pembahasan di praktikum kali ini bisa menggunakan list biasa atau menggunakan array dari numpy, terutama materi searching dan sorting. Namun, untuk materi operasi pada array, kita akan menggunakan array dari numpy.\n\nimport numpy as np\n\n\n\nTraversal pada array adalah “mengunjungi” elemen array satu per satu, dari awal sampai akhir. Tujuannya bisa untuk print saja, atau untuk menjumlahkan, atau yang lain. Apapun tujuannya, kalau itu melibatkan mengunjungi elemen array satu per satu, maka itu termasuk traversal.\nKita bisa mendeklarasikan suatu array dengan ukurannya saja, kemudian mengisi elemennya satu-per-satu.\n\nA = np.empty(5)\n\n\nprint(A) # isinya masih garbage value\n\n[0.  0.5 1.  1.5 2. ]\n\n\n\nA[0] = 5\nA[1] = 20\nA[2] = -3\nA[3] = 7\nA[4] = -11\n\n\nprint(A)\n\n[  5.  20.  -3.   7. -11.]\n\n\nAlternatifnya, kita bisa langsung saja menentukan elemen array sejak awal dibuat.\n\nA = np.array([5, 20, -3, 7, -11])\nprint(A)\n\n[  5  20  -3   7 -11]\n\n\nBerikut beberapa contoh traversal pada array.\n\nfor i in range(0, len(A)):\n    print(A[i])\n\n5\n20\n-3\n7\n-11\n\n\n\nsum = 0\nfor i in range(0, len(A)):\n    sum += A[i]\nprint(sum)\n\n18\n\n\n\n\n\nArray memiliki ukuran yang tetap. Terkadang, ketika kita membuat array, belum tentu keseluruhan array itu langsung kita gunakan semua. Bisa jadi, di awal kita hanya menggunakan sebagian saja, namun nantinya akan kita gunakan seutuhnya. Sehingga, untuk mengelola data yang kita simpan di dalam array (sebagai struktur data), perlu ada mekanisme “memasukkan” dan “menghapus” data pada array.\n(Pembahasan “insertion” dan “deletion” pada array mungkin agak aneh, tetapi sangat masuk akal untuk berbagai struktur data yang akan kita pelajari ke depannya, sehingga kita bahas terlebih dahulu untuk array.\nMisalkan kita hanya mendeklarasikan suatu array. Belum ada data yang dimasukkan, sehingga kita bisa menyimpan variabel untuk “ukuran” array saat ini adalah nol.\n\nB = np.empty(5)\nB_size = 0\n\nSaat ini, array tersebut masih sepenuhnya berisi garbage value.\n\nprint(B)\n\n[13. 20.  3.  7. 11.]\n\n\nKita bisa memasukkan elemen, misalnya 13, seperti berikut.\n\n# insert 97\nB[B_size] = 97\n\n# update data \"ukuran\" array,\n# bertambah satu karena memasukkan satu elemen baru\nB_size += 1\n\nDengan begitu, array menjadi seperti ini:\n\nprint(B)\n\n[97. 20.  3.  7. 11.]\n\n\nPerhatikan nilai variabel “ukuran” yang kita simpan:\n\nprint(B_size)\n\n1\n\n\nSaat ini, baru satu elemen yang kita masukkan ke dalam array. Sehingga, semua elemen lainnya itu tidak kita anggap, karena masih berupa garbage value (data sampah).\n\n# insert -17\nB[B_size] = -17\nB_size += 1\n\n\nprint(B)\n\n[ 97. -17.   3.   7.  11.]\n\n\n\nprint(B_size)\n\n2\n\n\n\n# insert 43\nB[B_size] = 43\nB_size += 1\n\n\nprint(B)\n\n[ 97. -17.  43.   7.  11.]\n\n\n\nprint(B_size)\n\n3\n\n\n\n\n\nSelain memasukkan data, kita juga bisa menghapus data. Kalau kita hanya ingin menghapus elemen “terakhir” (di data kita yaitu 43), maka kita tinggal “melupakan” elemen tersebut (sehingga statusnya menjadi garbage value) dengan mengurangi variabel “ukuran”:\n\n# delete elemen \"terakhir\" (dari yang sudah kita isi)\nB_size = B_size - 1\n\n\nprint(B)\n\n[ 97. -17.  43.   7.  11.]\n\n\n\nprint(B_size)\n\n2\n\n\nMemang array nya tidak berubah sama sekali, tapi ini masalah mindset (hehe). Tadinya, kita mengakui bahwa array berisi tiga buah data yang kita simpan, tetapi sekarang kita menganggap hanya berisi dua buah data. Sehingga, data ketiga yang tadi kita anggap data, itu sekarang menjadi garbage value yang bukan tanggung jawab kita.\nMari kita coba insert beberapa elemen lagi.\n\n# insert 53, -98, 71\n\nB[B_size] = 53\nB_size += 1\n\nB[B_size] = -98\nB_size += 1\n\nB[B_size] = 71\nB_size += 1\n\n\nprint(B)\n\n[ 97. -17.  53. -98.  71.]\n\n\n\nprint(B_size)\n\n5\n\n\nSekarang array sudah penuh. Bagaimana kalau misalnya kita ingin menghapus elemen pada indeks 2 (yaitu 53)? Kita perlu menggeser elemen indeks 3 menjadi indeks 2, kemudian indeks 4 menjadi indeks 3, sehingga “ukuran” array menjadi berkurang satu (elemen terakhir menjadi garbage value).\n\n# delete elemen pada indeks 2\nfor i in range(2, len(B)-1):\n    B[i] = B[i+1]\nB_size = B_size - 1\n\n\nprint(B)\n\n[ 97. -17. -98.  71.  71.]\n\n\n\nprint(B_size)\n\n4\n\n\nJangan lupa, sekarang “ukuran” data kita hanya empat buah data, sehingga elemen terakhir di situ (yang kebetulan juga 71) adalah garbage value yang tidak kita anggap.\n\n\n\n\nAlgoritma searching, seperti namanya, adalah algoritma yang digunakan untuk mencari sesuatu dalam suatu list. Umumnya, algoritma semacam ini memiliki 2 input, yaitu suatu “key” atau elemen yang ingin dicari, dan suatu array atau list tempat pencarian key tersebut.\nTerdapat 2 algoritma umum untuk searching, yaitu:\n\nLinear Search\nBinary Search\n\n\n\nLinear search adalah algoritma searching di mana setiap elemen pada list dibandingkan satu per satu dengan key. Pada algoritma ini, kita akan mencoba untuk mencari keberadaan key pada list, serta index dari key tersebut (jika ada). Kalau key tidak ditemukan, kita bisa return -1 (memang sudah tradisi untuk menandakan ketiadaan elemen pada array, lagipula mustahil ada indeks -1 pada array).\n\ndef linear_search(arr, key):\n    for i in range(0, len(arr)):\n        if arr[i] == key:\n            return i\n\n    # sampai sini, berarti elemen tidak ditemukan\n    return -1\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nlinear_search(A, 8)\n\n5\n\n\n\n\n\nBinary search adalah algoritma searching dimana suatu list dicek apakah nilai tengahnya adalah key. Jika tidak, list dipecah dua dan searching dilanjut tergantung posisi key relatif dari nilai tengah tersebut (apakah lebih kecil atau lebih besar).\n\ndef binary_search(arr, key):\n    left_idx = 0\n    right_idx = len(A)\n    found = False\n    while (not found) and (left_idx &lt;= right_idx):\n        center_idx = int( (left_idx + right_idx) / 2 )\n        if arr[center_idx] == key:\n            return center_idx\n        elif arr[center_idx] &gt; key:\n            right_idx = center_idx - 1\n        else:\n            left_idx = center_idx + 1\n    # keluar loop berarti tidak ditemukan\n    return -1\n\n\nA = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\nbinary_search(A, 14)\n\n6\n\n\n\n\n\n\nTerdapat 5 algoritma umum dalam sorting yang akan dijelaskan, yaitu:\n\nBubble Sort\nInsertion Sort\nSelection Sort\nQuick Sort\nMerge Sort\n\n\n\nBubble sort adalah algoritma sorting yang cara kerjanya adalah dengan membandingkan elemen yang bersebelahan secara berurutan, lalu ditukar jika urutannya salah. Bubble sort melibatkan beberapa kali “pass”, yaitu beberapa kali melihat array dari awal sampai akhir.\nTentunya, bubble sort akan berhenti ketika array sudah terurut. Namun, bagaimana cara mengetahui apakah array sudah terurut? Salah satu caranya, di tiap pass, kita bisa menganggap array sudah terurut (ditandai dengan variabel boolean), lalu melakukan bubble sort, dan apabila ada elemen yang masih belum terurut, maka ketika ditukar, kita menandai array tersebut belum terurut. Sedangkan, apabila semua elemen sudah terurut (tidak terjadi pertukaran), variabel boolean tetap bernilai True, sehingga array sudah terurut dan bubble sort sudah selesai. Untuk itu, digunakan while loop.\n\ndef bubble_sort_while(A):\n    n = len(A)\n    # di awal, array belum terurut\n    selesai = False\n    while (not selesai):\n        # di awal pass, asumsi array sudah terurut\n        selesai = True\n        for i in range(0, n-1):\n            # jika ada elemen yang belum terurut (perlu ditukar),\n            if A[i] &gt; A[i+1]:\n                # tandai array belum terurut\n                selesai = False\n                # lalu tukar\n                A[i], A[i+1] = A[i+1], A[i]\n        # pass selesai\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nbubble_sort_while(A)\nprint(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\nSebenarnya, banyaknya pass tidak akan melebihi \\((n-1)\\). Sehingga, daripada menggunakan while loop dan menandai array, kita bisa menggunakan for loop saja, untuk pass ke-i.\n\ndef bubble_sort_for(A):\n    n = len(A)\n    # Lakukan pass sebanyak (n-1) kali, yaitu pass ke-i, i=0, 1, ..., (n-2)\n    for i in range(n-1):\n        # Iterasi untuk tiap elemen ke-j, j=0, 1, ..., (n-2)\n        for j in range(n-1):\n            # Apabila elemen ke-j ternyata lebih besar daripada yang setelahnya,\n            if A[j] &gt; A[j+1]:\n                # Maka tukar kedua elemen agar urutannya benar\n                A[j], A[j+1] = A[j+1], A[j]\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nbubble_sort_for(A)\nprint(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nCara kerja dari insertion sort adalah dengan membandingkan elemen baru dengan elemen sebelumnya dan ditempatkan di tempat yang sesuai. Insertion sort mulai dari indeks ke-1, yang mana elemen pada indeks tersebut dibandingkan dengan indeks sebelumnya. Jika posisinya tidak sesuai, maka elemen ditukar, dan seterusnya hingga posisinya sesuai. Lalu iterasi dilanjutkan dengan elemen indeks ke-2, hingga elemen telah diiterasi semua.\n\ndef insertion_sort(A):\n    n = len(A)\n    # Untuk tiap elemen di array... (kecuali elemen paling pertama, indeks 0)\n    for i in range(1, n):\n        j = i\n        # Selama elemen itu lebih kecil daripada elemen di sebelah kirinya,\n        # tukar (geser elemen itu ke sebelah kirinya) agar menjadi terurut\n        while A[j] &lt; A[j-1]:\n            A[j], A[j-1] = A[j-1], A[j]\n            j -= 1 # j berkurang karena bergeser ke kiri\n            # Kalau elemen sudah di ujung kiri array,\n            # udah ga ada elemen di sebelah kirinya lagi, jadi keluar aja\n            if j == 0:\n                break\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\ninsertion_sort(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nSelection sort melakukan sorting dengan memasukkan nilai minimum dari suatu list. Jika diberikan suatu list \\(A[0..(n-1)]\\), maka algoritma mencari nilai minimum dari \\(A[0..(n-1)]\\), lalu ditukar dengan elemen \\(A[0]\\). Selanjutnya algoritma mencari nilai minimum dari \\(A[1..(n-1)]\\), lalu ditukar dengan elemen \\(A[1]\\), dan seterusnya.\n\ndef selection_sort(A):\n    n = len(A)\n    # Untuk tiap elemen ke-i, akan ditukarkan dengan elemen minimum yang\n    # ada di sebelah kanannya\n    for i in range(n-1):\n        # Asumsi awal: elemen yang sedang dilihat (elemen ke-i) adalah minimum\n        min_idx = i\n        min_val = A[min_idx]\n\n        # Periksa masing-masing elemen selanjutnya...\n        for j in range(i+1, n):\n            # Kalau ternyata ketemu elemen yang lebih kecil lagi...\n            if A[j] &lt; min_val:\n                # ... maka itu menjadi minimum yang terbaru\n                min_val = A[j]\n                min_idx = j\n        # Ketika keluar for loop, sudah diperoleh elemen minimum sesungguhnya\n        # Tukar elemen minimum dengan elemen ke-i\n        A[i], A[min_idx] = A[min_idx], A[i]\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nselection_sort(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nMerge sort melakukan sort dengan memecah list menjadi dua secara rekursif. Lalu sorting dilakukan dengan melakukan merge pada hasil pecahan list. Merge adalah proses pada dua list yang menyatukan dua list terurut menjadi satu list terurut. Merge dilakukan hingga list utuh kembali.\n\ndef merge_sort(A):\n    n = len(A)\n    # Seandainya hanya berisi satu elemen, tidak perlu dilakukan apa-apa\n    if len(A) &gt; 1:\n        # indeks middle (elemen tengah)\n        m = int(n/2)\n        # Array A dipisah menjadi A1 (sebelah kiri) dan A2 (sebelah kanan)\n        A1 = A[:m]\n        A2 = A[m:]\n        # Lakukan merge sort pada keduanya\n        merge_sort(A1)\n        merge_sort(A2)\n\n        # Di bawah ini adalah proses penggabungan dari A1 dan A2 yang\n        # masing-masing sudah terurut\n\n        i = 0 # indeks untuk A1\n        j = 0 # indeks untuk A2\n        k = 0 # indeks untuk array/list baru yang nantinya sudah terurut\n\n        # Loop selama kedua array masih punya elemen yang\n        # belum dimasukkan ke array/list baru\n        while i &lt; len(A1) and j &lt; len(A2):\n            # Kalau ternyata elemen pada A1 yang lebih kecil...\n            if A1[i] &lt;= A2[j]:\n                # ... maka itulah yang dimasukkan ke array/list baru\n                A[k] = A1[i]\n                i += 1 # lanjut ke elemen berikutnya untuk A1\n            # Selain itu, berarti elemen pada A2 yang lebih kecil...\n            else:\n                # ... maka itulah yang dimasukkan\n                A[k] = A2[j]\n                j += 1 # lanjut ke elemen berikutnya untuk A2\n            # Ukuran array baru sudah bertambah satu\n            k += 1\n        # Keluar loop, berarti salah satu array sudah habis\n        # Ada dua kemungkinan, yaitu A1 yang belum habis, atau A2 yang belum.\n        # Sehingga keduanya perlu \"dihabiskan\"\n        \n        # Menghabiskan A1 kalau belum habis\n        while i &lt; len(A1):\n            A[k] = A1[i]\n            i += 1\n            k += 1\n        \n        # Menghabiskan A2 kalau belum habis\n        while j &lt; len(A2):\n            A[k] = A2[j]\n            j += 1\n            k += 1\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nmerge_sort(A)\nprint(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nSecara keseluruhan, algoritma quicksort (yang bersifat rekursif) terdiri dari langkah berikut:\n\nApabila array kosong atau terdiri dari satu elemen, sorting selesai. Selain itu, lanjut ke langkah berikut.\nPilih salah satu elemen di array sebagai “pivot” (Bebas, yang penting konsisten. Biasanya elemen pertama. Kemungkinan lain: elemen tengah, elemen terakhir, dsb)\nLakukan “partisi”, yaitu proses yang membuat kondisi array menjadi seperti berikut:\n\n-----------------------------------------------------------\n| semua elemen yang      | pivot | semua elemen yang      |\n| lebih kecil dari pivot |       | lebih besar dari pivot |\n-----------------------------------------------------------\n\nLakukan quicksort pada sebelah kiri pivot dan pada sebelah kanan pivot.\n\nUntuk proses “partisi”, ada dua cara utama untuk melakukannya (algoritma partisi), yaitu algoritma partisi Hoare dan algoritma partisi Lomuto.\n\n\n\ndef partition_hoare(A, left_idx, right_idx):\n    # Buat \"pointer\" low dan high (simpan indeksnya saja)\n    low_idx = left_idx\n    high_idx = right_idx\n\n    # Diasumsikan array sudah terpartisi dengan baik (padahal belom hehe),\n    # - tugas low adalah memeriksa dari kiri (apakah benar sudah dipartisi),\n    # - tugas high adalah memeriksa dari kanan.\n    # Sudah terpartisi artinya:\n    # - sebelah kiri pivot adalah yang lebih kecil dari pivot\n    # - sebelah kanan pivot adalah yang lebih besar dari pivot\n\n    # Pilih indeks pivot, bebas, misal elemen paling pertama (paling kiri)\n    pivot_idx = left_idx\n    pivot_val = A[pivot_idx]\n\n    # Loop selama low belum melewati high\n    # (syarat ini sangat penting, hingga diperiksa berkali-kali)\n    while low_idx &lt;= high_idx:\n\n        # low lanjut ke kanan hingga menemukan elemen yang posisinya salah,\n        # yaitu elemen yang nilainya lebih besar dari pivot\n        while (low_idx &lt;= high_idx) and not (A[low_idx] &gt; pivot_val):\n            low_idx += 1\n\n        # high lanjut ke kiri hingga menemukan elemen yang posisinya salah,\n        # yaitu elemen yang nilainya lebih kecil dari pivot\n        while (low_idx &lt;= high_idx) and not (A[high_idx] &lt; pivot_val):\n            high_idx -= 1\n\n        # low dan high sama-sama menunjuk pada elemen yang posisinya salah,\n        # keduanya akan menjadi benar kalau posisinya ditukar\n        if low_idx &lt;= high_idx:\n            A[low_idx], A[high_idx] = A[high_idx], A[low_idx]\n\n            # Apabila elemen pivot ternyata ikut ditukar,\n            # pastikan data posisinya (pivot_idx) di-update.\n            if pivot_idx == low_idx: # Apabila tadinya pivot di low,\n                pivot_idx = high_idx # maka sekarang pivot di high.\n            elif pivot_idx == high_idx: # Namun apabila tadinya pivot di high,\n                pivot_idx = low_idx # maka sekarang pivot di low.\n    \n    # Kalau sudah keluar loop, berarti low sudah melewati high;\n    # Sudah ketemu garis baginya, yaitu antara low dan high.\n    # Saat ini, sebelah kiri garis bagi sudah lebih kecil dari pivot,\n    # dan sebelah kanan garis bagi sudah lebih besar dari pivot.\n    # Sekarang kita tinggal menempatkan pivot pada garis bagi tersebut\n\n    # Tukar pivot dengan high kalau pivot di sebelah kiri high,\n    if pivot_idx &lt;= high_idx:\n        A[pivot_idx], A[high_idx] = A[high_idx], A[pivot_idx]\n        pivot_idx = high_idx\n    \n    # atau tukar pivot dengan low kalau pivot di sebelah kanan low\n    else:\n        A[pivot_idx], A[low_idx] = A[low_idx], A[pivot_idx]\n        pivot_idx = low_idx\n    \n    # Partisi sudah selesai, return posisi pivot\n    # supaya jadi tahu di mana garis baginya\n    return pivot_idx\n\n\ndef quicksort_hoare(A, left_idx=None, right_idx=None):\n    # Kalau left_idx dan right_idx tidak diinput, otomatis menjadi None\n    # dan kalau begitu, berarti sebenarnya quicksort mau dilakukan pada\n    # keseluruhan array, sehingga ujung kiri adalah indeks 0 dan\n    # ujung kanan adalah indeks terakhir (n-1 di mana n adalah panjang array)\n    if left_idx == None:\n        left_idx = 0\n    if right_idx == None:\n        right_idx = len(A) - 1\n    \n    # Ada if statement untuk memastikan ujung kiri dan ujung kanan masih wajar.\n    if left_idx &lt; right_idx:\n        pivot_idx = partition_hoare(A, left_idx, right_idx)\n        quicksort_hoare(A, left_idx, pivot_idx-1)\n        quicksort_hoare(A, pivot_idx+1, right_idx)\n    # Kalau sewaktu-waktu menjadi tidak wajar, berarti array kosong, berarti\n    # quicksort sudah selesai dan tidak perlu dilakukan apa-apa lagi\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nquicksort_hoare(A)\nprint(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\n\ndef partition_lomuto(A, left_idx, right_idx):\n    # Pilih elemen pivot, sepertinya untuk Lomuto harus elemen terakhir\n    pivot_idx = right_idx\n    pivot_val = A[pivot_idx]\n\n    # Asumsi awal: semua elemen lebih besar dari nilai pivot,\n    # sehingga \"separator\" atau \"garis pemisah\" ada di ujung kiri,\n    # bahkan di sebelah kiri elemen pertama\n    sep = left_idx - 1\n\n    # Periksa tiap elemen...\n    for j in range(left_idx, right_idx):\n        # Kalau ternyata ada elemen yang tidak lebih besar dari pivot...\n        if A[j] &lt;= pivot_val:\n            # Majukan garis pemisah...\n            sep = sep + 1\n            # Lalu tukar elemen itu (yang seharusnya di sebelah kiri pivot),\n            # agar menjadi di (sebelah kiri) garis pemisah\n            A[sep], A[j] = A[j], A[sep]\n            # Nantinya, pivot akan diletakkan di posisi indeks sep+1.\n            # Data indeks \"sep\" menunjuk pada indeks terakhir yang\n            # elemennya lebih kecil dari pivot.\n    \n    # Keluar for loop, sekarang semua elemen sudah diperiksa,\n    # indeks sep menunjuk pada elemen terakhir yang lebih kecil dari pivot.\n    # Maka, pivot bisa diletakkan di posisi sep+1.\n    # Tukar elemen pivot dengan elemen apapun yang sedang di sep+1.\n    A[sep+1], A[pivot_idx] = A[pivot_idx], A[sep+1]\n    # Sekarang, pivot ada di sep+1\n    pivot_idx = sep+1\n\n    # Partisi sudah selesai, return posisi pivot\n    # supaya jadi tahu di mana garis baginya\n    return pivot_idx\n\n\ndef quicksort_lomuto(A, left_idx=None, right_idx=None):\n    if left_idx == None:\n        left_idx = 0\n    if right_idx == None:\n        right_idx = len(A) - 1\n\n    if left_idx &lt; right_idx:\n        pivot_idx = partition_lomuto(A, left_idx, right_idx)\n        quicksort_lomuto(A, left_idx, pivot_idx - 1)\n        quicksort_lomuto(A, pivot_idx + 1, right_idx)\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nquicksort_lomuto(A)\nprint(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\nPerhatikan bahwa, meskipun algoritma partisi Hoare dan partisi Lomuto sangat berbeda, ketika di fungsi quicksort (quicksort_hoare dan quicksort_lomuto), kodenya sama, hanya berbeda di fungsi partisi yang digunakan."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul04.html#operasi-pada-array",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul04.html#operasi-pada-array",
    "title": "Modul 4 Struktur Data: Array, Searching, Sorting",
    "section": "",
    "text": "Sebagian besar pembahasan di praktikum kali ini bisa menggunakan list biasa atau menggunakan array dari numpy, terutama materi searching dan sorting. Namun, untuk materi operasi pada array, kita akan menggunakan array dari numpy.\n\nimport numpy as np\n\n\n\nTraversal pada array adalah “mengunjungi” elemen array satu per satu, dari awal sampai akhir. Tujuannya bisa untuk print saja, atau untuk menjumlahkan, atau yang lain. Apapun tujuannya, kalau itu melibatkan mengunjungi elemen array satu per satu, maka itu termasuk traversal.\nKita bisa mendeklarasikan suatu array dengan ukurannya saja, kemudian mengisi elemennya satu-per-satu.\n\nA = np.empty(5)\n\n\nprint(A) # isinya masih garbage value\n\n[0.  0.5 1.  1.5 2. ]\n\n\n\nA[0] = 5\nA[1] = 20\nA[2] = -3\nA[3] = 7\nA[4] = -11\n\n\nprint(A)\n\n[  5.  20.  -3.   7. -11.]\n\n\nAlternatifnya, kita bisa langsung saja menentukan elemen array sejak awal dibuat.\n\nA = np.array([5, 20, -3, 7, -11])\nprint(A)\n\n[  5  20  -3   7 -11]\n\n\nBerikut beberapa contoh traversal pada array.\n\nfor i in range(0, len(A)):\n    print(A[i])\n\n5\n20\n-3\n7\n-11\n\n\n\nsum = 0\nfor i in range(0, len(A)):\n    sum += A[i]\nprint(sum)\n\n18\n\n\n\n\n\nArray memiliki ukuran yang tetap. Terkadang, ketika kita membuat array, belum tentu keseluruhan array itu langsung kita gunakan semua. Bisa jadi, di awal kita hanya menggunakan sebagian saja, namun nantinya akan kita gunakan seutuhnya. Sehingga, untuk mengelola data yang kita simpan di dalam array (sebagai struktur data), perlu ada mekanisme “memasukkan” dan “menghapus” data pada array.\n(Pembahasan “insertion” dan “deletion” pada array mungkin agak aneh, tetapi sangat masuk akal untuk berbagai struktur data yang akan kita pelajari ke depannya, sehingga kita bahas terlebih dahulu untuk array.\nMisalkan kita hanya mendeklarasikan suatu array. Belum ada data yang dimasukkan, sehingga kita bisa menyimpan variabel untuk “ukuran” array saat ini adalah nol.\n\nB = np.empty(5)\nB_size = 0\n\nSaat ini, array tersebut masih sepenuhnya berisi garbage value.\n\nprint(B)\n\n[13. 20.  3.  7. 11.]\n\n\nKita bisa memasukkan elemen, misalnya 13, seperti berikut.\n\n# insert 97\nB[B_size] = 97\n\n# update data \"ukuran\" array,\n# bertambah satu karena memasukkan satu elemen baru\nB_size += 1\n\nDengan begitu, array menjadi seperti ini:\n\nprint(B)\n\n[97. 20.  3.  7. 11.]\n\n\nPerhatikan nilai variabel “ukuran” yang kita simpan:\n\nprint(B_size)\n\n1\n\n\nSaat ini, baru satu elemen yang kita masukkan ke dalam array. Sehingga, semua elemen lainnya itu tidak kita anggap, karena masih berupa garbage value (data sampah).\n\n# insert -17\nB[B_size] = -17\nB_size += 1\n\n\nprint(B)\n\n[ 97. -17.   3.   7.  11.]\n\n\n\nprint(B_size)\n\n2\n\n\n\n# insert 43\nB[B_size] = 43\nB_size += 1\n\n\nprint(B)\n\n[ 97. -17.  43.   7.  11.]\n\n\n\nprint(B_size)\n\n3\n\n\n\n\n\nSelain memasukkan data, kita juga bisa menghapus data. Kalau kita hanya ingin menghapus elemen “terakhir” (di data kita yaitu 43), maka kita tinggal “melupakan” elemen tersebut (sehingga statusnya menjadi garbage value) dengan mengurangi variabel “ukuran”:\n\n# delete elemen \"terakhir\" (dari yang sudah kita isi)\nB_size = B_size - 1\n\n\nprint(B)\n\n[ 97. -17.  43.   7.  11.]\n\n\n\nprint(B_size)\n\n2\n\n\nMemang array nya tidak berubah sama sekali, tapi ini masalah mindset (hehe). Tadinya, kita mengakui bahwa array berisi tiga buah data yang kita simpan, tetapi sekarang kita menganggap hanya berisi dua buah data. Sehingga, data ketiga yang tadi kita anggap data, itu sekarang menjadi garbage value yang bukan tanggung jawab kita.\nMari kita coba insert beberapa elemen lagi.\n\n# insert 53, -98, 71\n\nB[B_size] = 53\nB_size += 1\n\nB[B_size] = -98\nB_size += 1\n\nB[B_size] = 71\nB_size += 1\n\n\nprint(B)\n\n[ 97. -17.  53. -98.  71.]\n\n\n\nprint(B_size)\n\n5\n\n\nSekarang array sudah penuh. Bagaimana kalau misalnya kita ingin menghapus elemen pada indeks 2 (yaitu 53)? Kita perlu menggeser elemen indeks 3 menjadi indeks 2, kemudian indeks 4 menjadi indeks 3, sehingga “ukuran” array menjadi berkurang satu (elemen terakhir menjadi garbage value).\n\n# delete elemen pada indeks 2\nfor i in range(2, len(B)-1):\n    B[i] = B[i+1]\nB_size = B_size - 1\n\n\nprint(B)\n\n[ 97. -17. -98.  71.  71.]\n\n\n\nprint(B_size)\n\n4\n\n\nJangan lupa, sekarang “ukuran” data kita hanya empat buah data, sehingga elemen terakhir di situ (yang kebetulan juga 71) adalah garbage value yang tidak kita anggap."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul04.html#searching",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul04.html#searching",
    "title": "Modul 4 Struktur Data: Array, Searching, Sorting",
    "section": "",
    "text": "Algoritma searching, seperti namanya, adalah algoritma yang digunakan untuk mencari sesuatu dalam suatu list. Umumnya, algoritma semacam ini memiliki 2 input, yaitu suatu “key” atau elemen yang ingin dicari, dan suatu array atau list tempat pencarian key tersebut.\nTerdapat 2 algoritma umum untuk searching, yaitu:\n\nLinear Search\nBinary Search\n\n\n\nLinear search adalah algoritma searching di mana setiap elemen pada list dibandingkan satu per satu dengan key. Pada algoritma ini, kita akan mencoba untuk mencari keberadaan key pada list, serta index dari key tersebut (jika ada). Kalau key tidak ditemukan, kita bisa return -1 (memang sudah tradisi untuk menandakan ketiadaan elemen pada array, lagipula mustahil ada indeks -1 pada array).\n\ndef linear_search(arr, key):\n    for i in range(0, len(arr)):\n        if arr[i] == key:\n            return i\n\n    # sampai sini, berarti elemen tidak ditemukan\n    return -1\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nlinear_search(A, 8)\n\n5\n\n\n\n\n\nBinary search adalah algoritma searching dimana suatu list dicek apakah nilai tengahnya adalah key. Jika tidak, list dipecah dua dan searching dilanjut tergantung posisi key relatif dari nilai tengah tersebut (apakah lebih kecil atau lebih besar).\n\ndef binary_search(arr, key):\n    left_idx = 0\n    right_idx = len(A)\n    found = False\n    while (not found) and (left_idx &lt;= right_idx):\n        center_idx = int( (left_idx + right_idx) / 2 )\n        if arr[center_idx] == key:\n            return center_idx\n        elif arr[center_idx] &gt; key:\n            right_idx = center_idx - 1\n        else:\n            left_idx = center_idx + 1\n    # keluar loop berarti tidak ditemukan\n    return -1\n\n\nA = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\nbinary_search(A, 14)\n\n6"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul04.html#sorting",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul04.html#sorting",
    "title": "Modul 4 Struktur Data: Array, Searching, Sorting",
    "section": "",
    "text": "Terdapat 5 algoritma umum dalam sorting yang akan dijelaskan, yaitu:\n\nBubble Sort\nInsertion Sort\nSelection Sort\nQuick Sort\nMerge Sort\n\n\n\nBubble sort adalah algoritma sorting yang cara kerjanya adalah dengan membandingkan elemen yang bersebelahan secara berurutan, lalu ditukar jika urutannya salah. Bubble sort melibatkan beberapa kali “pass”, yaitu beberapa kali melihat array dari awal sampai akhir.\nTentunya, bubble sort akan berhenti ketika array sudah terurut. Namun, bagaimana cara mengetahui apakah array sudah terurut? Salah satu caranya, di tiap pass, kita bisa menganggap array sudah terurut (ditandai dengan variabel boolean), lalu melakukan bubble sort, dan apabila ada elemen yang masih belum terurut, maka ketika ditukar, kita menandai array tersebut belum terurut. Sedangkan, apabila semua elemen sudah terurut (tidak terjadi pertukaran), variabel boolean tetap bernilai True, sehingga array sudah terurut dan bubble sort sudah selesai. Untuk itu, digunakan while loop.\n\ndef bubble_sort_while(A):\n    n = len(A)\n    # di awal, array belum terurut\n    selesai = False\n    while (not selesai):\n        # di awal pass, asumsi array sudah terurut\n        selesai = True\n        for i in range(0, n-1):\n            # jika ada elemen yang belum terurut (perlu ditukar),\n            if A[i] &gt; A[i+1]:\n                # tandai array belum terurut\n                selesai = False\n                # lalu tukar\n                A[i], A[i+1] = A[i+1], A[i]\n        # pass selesai\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nbubble_sort_while(A)\nprint(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\nSebenarnya, banyaknya pass tidak akan melebihi \\((n-1)\\). Sehingga, daripada menggunakan while loop dan menandai array, kita bisa menggunakan for loop saja, untuk pass ke-i.\n\ndef bubble_sort_for(A):\n    n = len(A)\n    # Lakukan pass sebanyak (n-1) kali, yaitu pass ke-i, i=0, 1, ..., (n-2)\n    for i in range(n-1):\n        # Iterasi untuk tiap elemen ke-j, j=0, 1, ..., (n-2)\n        for j in range(n-1):\n            # Apabila elemen ke-j ternyata lebih besar daripada yang setelahnya,\n            if A[j] &gt; A[j+1]:\n                # Maka tukar kedua elemen agar urutannya benar\n                A[j], A[j+1] = A[j+1], A[j]\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nbubble_sort_for(A)\nprint(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nCara kerja dari insertion sort adalah dengan membandingkan elemen baru dengan elemen sebelumnya dan ditempatkan di tempat yang sesuai. Insertion sort mulai dari indeks ke-1, yang mana elemen pada indeks tersebut dibandingkan dengan indeks sebelumnya. Jika posisinya tidak sesuai, maka elemen ditukar, dan seterusnya hingga posisinya sesuai. Lalu iterasi dilanjutkan dengan elemen indeks ke-2, hingga elemen telah diiterasi semua.\n\ndef insertion_sort(A):\n    n = len(A)\n    # Untuk tiap elemen di array... (kecuali elemen paling pertama, indeks 0)\n    for i in range(1, n):\n        j = i\n        # Selama elemen itu lebih kecil daripada elemen di sebelah kirinya,\n        # tukar (geser elemen itu ke sebelah kirinya) agar menjadi terurut\n        while A[j] &lt; A[j-1]:\n            A[j], A[j-1] = A[j-1], A[j]\n            j -= 1 # j berkurang karena bergeser ke kiri\n            # Kalau elemen sudah di ujung kiri array,\n            # udah ga ada elemen di sebelah kirinya lagi, jadi keluar aja\n            if j == 0:\n                break\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\ninsertion_sort(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nSelection sort melakukan sorting dengan memasukkan nilai minimum dari suatu list. Jika diberikan suatu list \\(A[0..(n-1)]\\), maka algoritma mencari nilai minimum dari \\(A[0..(n-1)]\\), lalu ditukar dengan elemen \\(A[0]\\). Selanjutnya algoritma mencari nilai minimum dari \\(A[1..(n-1)]\\), lalu ditukar dengan elemen \\(A[1]\\), dan seterusnya.\n\ndef selection_sort(A):\n    n = len(A)\n    # Untuk tiap elemen ke-i, akan ditukarkan dengan elemen minimum yang\n    # ada di sebelah kanannya\n    for i in range(n-1):\n        # Asumsi awal: elemen yang sedang dilihat (elemen ke-i) adalah minimum\n        min_idx = i\n        min_val = A[min_idx]\n\n        # Periksa masing-masing elemen selanjutnya...\n        for j in range(i+1, n):\n            # Kalau ternyata ketemu elemen yang lebih kecil lagi...\n            if A[j] &lt; min_val:\n                # ... maka itu menjadi minimum yang terbaru\n                min_val = A[j]\n                min_idx = j\n        # Ketika keluar for loop, sudah diperoleh elemen minimum sesungguhnya\n        # Tukar elemen minimum dengan elemen ke-i\n        A[i], A[min_idx] = A[min_idx], A[i]\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nselection_sort(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nMerge sort melakukan sort dengan memecah list menjadi dua secara rekursif. Lalu sorting dilakukan dengan melakukan merge pada hasil pecahan list. Merge adalah proses pada dua list yang menyatukan dua list terurut menjadi satu list terurut. Merge dilakukan hingga list utuh kembali.\n\ndef merge_sort(A):\n    n = len(A)\n    # Seandainya hanya berisi satu elemen, tidak perlu dilakukan apa-apa\n    if len(A) &gt; 1:\n        # indeks middle (elemen tengah)\n        m = int(n/2)\n        # Array A dipisah menjadi A1 (sebelah kiri) dan A2 (sebelah kanan)\n        A1 = A[:m]\n        A2 = A[m:]\n        # Lakukan merge sort pada keduanya\n        merge_sort(A1)\n        merge_sort(A2)\n\n        # Di bawah ini adalah proses penggabungan dari A1 dan A2 yang\n        # masing-masing sudah terurut\n\n        i = 0 # indeks untuk A1\n        j = 0 # indeks untuk A2\n        k = 0 # indeks untuk array/list baru yang nantinya sudah terurut\n\n        # Loop selama kedua array masih punya elemen yang\n        # belum dimasukkan ke array/list baru\n        while i &lt; len(A1) and j &lt; len(A2):\n            # Kalau ternyata elemen pada A1 yang lebih kecil...\n            if A1[i] &lt;= A2[j]:\n                # ... maka itulah yang dimasukkan ke array/list baru\n                A[k] = A1[i]\n                i += 1 # lanjut ke elemen berikutnya untuk A1\n            # Selain itu, berarti elemen pada A2 yang lebih kecil...\n            else:\n                # ... maka itulah yang dimasukkan\n                A[k] = A2[j]\n                j += 1 # lanjut ke elemen berikutnya untuk A2\n            # Ukuran array baru sudah bertambah satu\n            k += 1\n        # Keluar loop, berarti salah satu array sudah habis\n        # Ada dua kemungkinan, yaitu A1 yang belum habis, atau A2 yang belum.\n        # Sehingga keduanya perlu \"dihabiskan\"\n        \n        # Menghabiskan A1 kalau belum habis\n        while i &lt; len(A1):\n            A[k] = A1[i]\n            i += 1\n            k += 1\n        \n        # Menghabiskan A2 kalau belum habis\n        while j &lt; len(A2):\n            A[k] = A2[j]\n            j += 1\n            k += 1\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nmerge_sort(A)\nprint(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nSecara keseluruhan, algoritma quicksort (yang bersifat rekursif) terdiri dari langkah berikut:\n\nApabila array kosong atau terdiri dari satu elemen, sorting selesai. Selain itu, lanjut ke langkah berikut.\nPilih salah satu elemen di array sebagai “pivot” (Bebas, yang penting konsisten. Biasanya elemen pertama. Kemungkinan lain: elemen tengah, elemen terakhir, dsb)\nLakukan “partisi”, yaitu proses yang membuat kondisi array menjadi seperti berikut:\n\n-----------------------------------------------------------\n| semua elemen yang      | pivot | semua elemen yang      |\n| lebih kecil dari pivot |       | lebih besar dari pivot |\n-----------------------------------------------------------\n\nLakukan quicksort pada sebelah kiri pivot dan pada sebelah kanan pivot.\n\nUntuk proses “partisi”, ada dua cara utama untuk melakukannya (algoritma partisi), yaitu algoritma partisi Hoare dan algoritma partisi Lomuto.\n\n\n\ndef partition_hoare(A, left_idx, right_idx):\n    # Buat \"pointer\" low dan high (simpan indeksnya saja)\n    low_idx = left_idx\n    high_idx = right_idx\n\n    # Diasumsikan array sudah terpartisi dengan baik (padahal belom hehe),\n    # - tugas low adalah memeriksa dari kiri (apakah benar sudah dipartisi),\n    # - tugas high adalah memeriksa dari kanan.\n    # Sudah terpartisi artinya:\n    # - sebelah kiri pivot adalah yang lebih kecil dari pivot\n    # - sebelah kanan pivot adalah yang lebih besar dari pivot\n\n    # Pilih indeks pivot, bebas, misal elemen paling pertama (paling kiri)\n    pivot_idx = left_idx\n    pivot_val = A[pivot_idx]\n\n    # Loop selama low belum melewati high\n    # (syarat ini sangat penting, hingga diperiksa berkali-kali)\n    while low_idx &lt;= high_idx:\n\n        # low lanjut ke kanan hingga menemukan elemen yang posisinya salah,\n        # yaitu elemen yang nilainya lebih besar dari pivot\n        while (low_idx &lt;= high_idx) and not (A[low_idx] &gt; pivot_val):\n            low_idx += 1\n\n        # high lanjut ke kiri hingga menemukan elemen yang posisinya salah,\n        # yaitu elemen yang nilainya lebih kecil dari pivot\n        while (low_idx &lt;= high_idx) and not (A[high_idx] &lt; pivot_val):\n            high_idx -= 1\n\n        # low dan high sama-sama menunjuk pada elemen yang posisinya salah,\n        # keduanya akan menjadi benar kalau posisinya ditukar\n        if low_idx &lt;= high_idx:\n            A[low_idx], A[high_idx] = A[high_idx], A[low_idx]\n\n            # Apabila elemen pivot ternyata ikut ditukar,\n            # pastikan data posisinya (pivot_idx) di-update.\n            if pivot_idx == low_idx: # Apabila tadinya pivot di low,\n                pivot_idx = high_idx # maka sekarang pivot di high.\n            elif pivot_idx == high_idx: # Namun apabila tadinya pivot di high,\n                pivot_idx = low_idx # maka sekarang pivot di low.\n    \n    # Kalau sudah keluar loop, berarti low sudah melewati high;\n    # Sudah ketemu garis baginya, yaitu antara low dan high.\n    # Saat ini, sebelah kiri garis bagi sudah lebih kecil dari pivot,\n    # dan sebelah kanan garis bagi sudah lebih besar dari pivot.\n    # Sekarang kita tinggal menempatkan pivot pada garis bagi tersebut\n\n    # Tukar pivot dengan high kalau pivot di sebelah kiri high,\n    if pivot_idx &lt;= high_idx:\n        A[pivot_idx], A[high_idx] = A[high_idx], A[pivot_idx]\n        pivot_idx = high_idx\n    \n    # atau tukar pivot dengan low kalau pivot di sebelah kanan low\n    else:\n        A[pivot_idx], A[low_idx] = A[low_idx], A[pivot_idx]\n        pivot_idx = low_idx\n    \n    # Partisi sudah selesai, return posisi pivot\n    # supaya jadi tahu di mana garis baginya\n    return pivot_idx\n\n\ndef quicksort_hoare(A, left_idx=None, right_idx=None):\n    # Kalau left_idx dan right_idx tidak diinput, otomatis menjadi None\n    # dan kalau begitu, berarti sebenarnya quicksort mau dilakukan pada\n    # keseluruhan array, sehingga ujung kiri adalah indeks 0 dan\n    # ujung kanan adalah indeks terakhir (n-1 di mana n adalah panjang array)\n    if left_idx == None:\n        left_idx = 0\n    if right_idx == None:\n        right_idx = len(A) - 1\n    \n    # Ada if statement untuk memastikan ujung kiri dan ujung kanan masih wajar.\n    if left_idx &lt; right_idx:\n        pivot_idx = partition_hoare(A, left_idx, right_idx)\n        quicksort_hoare(A, left_idx, pivot_idx-1)\n        quicksort_hoare(A, pivot_idx+1, right_idx)\n    # Kalau sewaktu-waktu menjadi tidak wajar, berarti array kosong, berarti\n    # quicksort sudah selesai dan tidak perlu dilakukan apa-apa lagi\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nquicksort_hoare(A)\nprint(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\n\ndef partition_lomuto(A, left_idx, right_idx):\n    # Pilih elemen pivot, sepertinya untuk Lomuto harus elemen terakhir\n    pivot_idx = right_idx\n    pivot_val = A[pivot_idx]\n\n    # Asumsi awal: semua elemen lebih besar dari nilai pivot,\n    # sehingga \"separator\" atau \"garis pemisah\" ada di ujung kiri,\n    # bahkan di sebelah kiri elemen pertama\n    sep = left_idx - 1\n\n    # Periksa tiap elemen...\n    for j in range(left_idx, right_idx):\n        # Kalau ternyata ada elemen yang tidak lebih besar dari pivot...\n        if A[j] &lt;= pivot_val:\n            # Majukan garis pemisah...\n            sep = sep + 1\n            # Lalu tukar elemen itu (yang seharusnya di sebelah kiri pivot),\n            # agar menjadi di (sebelah kiri) garis pemisah\n            A[sep], A[j] = A[j], A[sep]\n            # Nantinya, pivot akan diletakkan di posisi indeks sep+1.\n            # Data indeks \"sep\" menunjuk pada indeks terakhir yang\n            # elemennya lebih kecil dari pivot.\n    \n    # Keluar for loop, sekarang semua elemen sudah diperiksa,\n    # indeks sep menunjuk pada elemen terakhir yang lebih kecil dari pivot.\n    # Maka, pivot bisa diletakkan di posisi sep+1.\n    # Tukar elemen pivot dengan elemen apapun yang sedang di sep+1.\n    A[sep+1], A[pivot_idx] = A[pivot_idx], A[sep+1]\n    # Sekarang, pivot ada di sep+1\n    pivot_idx = sep+1\n\n    # Partisi sudah selesai, return posisi pivot\n    # supaya jadi tahu di mana garis baginya\n    return pivot_idx\n\n\ndef quicksort_lomuto(A, left_idx=None, right_idx=None):\n    if left_idx == None:\n        left_idx = 0\n    if right_idx == None:\n        right_idx = len(A) - 1\n\n    if left_idx &lt; right_idx:\n        pivot_idx = partition_lomuto(A, left_idx, right_idx)\n        quicksort_lomuto(A, left_idx, pivot_idx - 1)\n        quicksort_lomuto(A, pivot_idx + 1, right_idx)\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nquicksort_lomuto(A)\nprint(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\nPerhatikan bahwa, meskipun algoritma partisi Hoare dan partisi Lomuto sangat berbeda, ketika di fungsi quicksort (quicksort_hoare dan quicksort_lomuto), kodenya sama, hanya berbeda di fungsi partisi yang digunakan."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul02.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul02.html",
    "title": "Modul 2 Struktur Data: Pengantar OOP",
    "section": "",
    "text": "Kembali ke Struktur Data (dengan Python)\nPada praktikum kali ini, kita akan membahas tentang class, yang nantinya akan kita gunakan untuk membuat berbagai jenis struktur data. Sekaligus, kita juga akan membahas tentang object-oriented programming atau OOP (pemrograman berorientasi objek atau PBO), yaitu semacam “paradigma pemrograman” (gaya pemrograman) di mana kita sering berurusan dengan class.\nIntinya, hari ini kita akan membahas tentang class dan serba-serbi (filosofi) penggunaannya.\n\n\nDi pertemuan sebelumnya, ketika belajar tentang tipe data di Python, kita sering menjumpai nama tipe data disertai istilah class. Sebelum memahami apa itu class, kita bisa paham dulu tentang konsep “objek”.\nDi Python (dan banyak bahasa pemrograman lainnya yang “mendukung OOP”), sebuah “objek” adalah sesuatu yang bisa memiliki variabel-variabel tersendiri (disebut atribut) serta fungsi-fungsi tersendiri (disebut method) di bawah satu nama yang sama (yaitu objek tersebut).\nKemudian, sebuah class adalah semacam blueprint untuk membuat objek. Ketika kita ingin membuat objek, kita harus membuat definisi class nya terlebih dahulu sebagai blueprint untuk objek tersebut. Barulah, setelah definisi class nya ada, kita bisa membuat objek sebanyak-banyaknya dari class yang sama.\nSebagai blueprint untuk membuat objek, suatu definisi class mencakupi atribut serta method yang akan terdefinisi untuk objek yang akan dibuat. Artinya, semua objek yang dibuat dari class yang sama itu akan memiliki “struktur” yang sama, baik variabel-variabel maupun fungsi-fungsi yang terkandung di dalam tiap objek.\n(Itulah mengapa tipe data dianggap sebagai class di Python. Misalnya, untuk tipe data str, yaitu &lt;class 'str'&gt;, semua string di Python tentunya “memiliki sifat yang sama”, seperti bisa di-format dengan method .format)\nAgar lebih paham, mari kita coba membuat class pertama kita, yaitu class Orang, untuk menyimpan data orang yang terdiri dari nama dan umur. Kemudian, kita akan membuat beberapa objek, yaitu beberapa Orang, yang masing-masing bisa memiliki data nama dan umur tersendiri.\n\nclass Orang:\n    def __init__(self, nama, umur):\n        self.nama = nama\n        self.umur = umur\n\nPada definisi class Orang di atas, kita baru merancang atribut apa saja yang akan terkandung dalam objek, yaitu nama dan umur.\n\nPada baris pertama, kita menuliskan kata class untuk memulai suatu definisi class baru, diikuti dengan nama class nya (di sini namanya Orang).\nPada baris kedua, kita memulai definisi suatu method istimewa yang bernama __init__ yang dimulai dan diakhiri dengan dua garis bawah. Method yang satu ini harus selalu ada di tiap definisi class, dan istilahnya adalah constructor. Argumen yang masuk ke dalam method ini adalah self yang merujuk ke “diri sendiri” (objek yang bersangkutan), kemudian dua atribut yang bisa ditentukan ketika objek dibuat, yaitu nama dan umur\nDi dalam definisi __init__ di atas (baris ketiga dan keempat), nilai self.nama dan self.umur akan dipasangkan menjadi nama dan umur yang “masuk ke dalam method” (yaitu ditentukan ketika objek dibuat).\n\nKalau baru pertama kali lihat, mungkin syntax definisi class rasanya sangat aneh dan asing. Tidak masalah, itu normal. Ketiknya pelan-pelan saja. Kalau belum begitu paham, juga tidak masalah, ikuti saja. Perlahan, kita akan terus-menerus memberi tambahan ke definisi class Orang tersebut agar lebih paham.\nSemoga menjadi lebih jelas setelah melihat syntax pembuatan objek:\n\norang1 = Orang(\"Bisma\", 19)\norang2 = Orang(\"Vero\", 20)\n\nKemudian, kita bisa melihat atribut objek seperti berikut:\n\nprint(orang1.nama)\nprint(orang1.umur)\n\nBisma\n19\n\n\n\nprint(orang2.nama)\nprint(orang2.umur)\n\nVero\n20\n\n\nPerhatikan bahwa masing-masing atribut diakses melalui objek yang bersangkutan. Terlihat kegunaan objek sebagai penampung beberapa variabel (atribut) di bawah satu nama yang sama.\nSelain melihat, tentunya kita juga bisa melakukan assignment:\n\norang1.umur = 21\nprint(orang1.umur)\n\n21\n\n\nBahkan, kita bisa melakukan variasi assignment lainnya seperti biasa, misalnya +=\n\norang1.umur += 3\nprint(orang1.umur)\n\n24\n\n\nKalau dirasa perlu, kita dapat membuat fungsi yang akan menerima suatu objek Orang lalu akan mengubah data umur.`\n\ndef ulangtahun(orang):\n    orang.umur += 1\n\nSehingga, bisa digunakan seperti berikut:\n\nulangtahun(orang1)\nprint(orang1.umur)\n\n25\n\n\nPerhatikan bahwa objek di Python bersifat pass-by-reference! Artinya, apabila suatu objek dimasukkan ke dalam fungsi, kemudian dimodifikasi di dalam fungsi tersebut, maka modifikasi tersebut juga berdampak hingga di luar fungsi.\nDefinisi fungsi ulangtahun yang telah kita buat di atas sebenarnya bisa dimasukkan ke dalam definisi class Orang sebagai suatu method.\n\nclass Orang:\n    def __init__(self, nama, umur):\n        self.nama = nama\n        self.umur = umur\n    def ulangtahun(self):\n        self.umur += 1\n\nPerhatikan, ini adalah pendefinisian ulang! Ini adalah definisi baru untuk class Orang. Sedangkan, objek-objek yang sudah kita buat sebelumnya masih menganut definisi yang lama. Sehingga, setelah ini, kita harus membuat ulang objek agar mengikuti definisi class Orang yang baru.\nPerhatikan juga, ada sedikit perbedaan istilah pada fungsi ulangtahun: tadinya, objek yang masuk itu kita sebut orang, sekarang kita sebut self. Istilah self ini memang sudah menjadi kebiasaan di Python untuk merujuk ke diri sendiri, yaitu objek yang bersangkutan. Tiap definisi method selalu harus diawali dengan masuknya objek yang bersangkutan (yang biasa disebut self), sudah menjadi formalitas di Python.\nItulah mengapa, di definisi __init__ seolah-olah ada tiga variabel yang masuk yaitu self, nama, dan umur, meskipun yang diperlukan ketika membuat objeknya hanyalah nama dan umur.\nMari kita buat ulang orang1:\n\norang1 = Orang(\"Bisma\", 19)\n\nKita bisa melihat atributnya:\n\nprint(orang1.nama)\nprint(orang1.umur)\n\nBisma\n19\n\n\nKemudian, kita bisa menggunakan method ulangtahun yang telah kita buat, lalu melihat data umur terbaru:\n\norang1.ulangtahun()\nprint(orang1.umur)\n\n20\n\n\nPenggunaan method memang seperti itu, sangat mirip dengan mengakses atribut, bedanya adalah bahwa method berupa fungsi. Di sini, kita bisa melihat, baik atribut maupun method suatu objek itu sama-sama berada di bawah satu nama yang sama, yaitu objek yang bersangkutan (di sini, baik atribut umur maupun method ulangtahun diakses melalui orang1).\nKalau mau, kita bisa melakukannya lagi:\n\norang1.ulangtahun()\nprint(orang1.umur)\n\n21\n\n\nTentu saja, kegunaan class tidak sebatas itu. Bahkan, ada semacam “paradigma pemrograman” (gaya pemrograman) di mana kita sering berurusan dengan class, yang disebut OOP. Agar lebih paham juga tentang class dan kegunaannya, kita akan mempelajari dasar-dasar OOP, yang tercakup oleh empat pilar (tiang) OOP.\n\n\n\nEmpat pilar OOP adalah:\n\nEncapsulation (pembungkusan)\nAbstraction (abstraksi; kebalikan dari “mendetail”)\nInheritance (pewarisan sifat)\nPolymorphism (“banyak bentuk”)\n\nIstilah prinsip polymorphism memang sulit diterjemahkan. Kita akan membahas masing-masing keempat prinsip OOP tersebut.\n\n\nSejauh ini, kita sudah merasakan bagaimana variabel (atribut) dan fungsi (method) sama-sama berada di bawah satu nama yang sama, yaitu objek yang bersangkutan. Seolah-olah, atribut dan method tersebut dibungkus ke dalam objek tersebut. Inilah yang dinamakan prinsip encapsulation atau pembungkusan.\nNamun, ada juga konsep data hiding, di mana atribut objek sebaiknya diakses dan dimodifikasi melalui method saja. Method untuk memperoleh (mengakses) nilai atribut tertentu disebut getter, dan method untuk memasang nilai baru untuk atribut tertentu disebut setter.\nPrinsip data hiding seringkali dianggap bagian dari prinsip encapsulation (tetapi terkadang dianggap bagian dari abstraction yang akan kita bahas selanjutnya).\nKita akan mendefinisikan ulang class Orang agar memiliki getter dan setter untuk atribut umur.\n\nclass Orang:\n    def __init__(self, nama, umur):\n        self.nama = nama\n        self.umur = umur\n    def ulangtahun(self):\n        self.umur += 1\n    def get_umur(self):\n        return self.umur\n    def set_umur(self, baru):\n        self.umur = baru\n\nPerhatikan bahwa method get_umur melakukan return. Penggunaannya akan mirip dengan fungsi seperti biasanya. Kemudian, method set_umur akan menerima satu input di dalam kurungnya (sedangkan self hanya untuk formalitas).\nKita bisa membuat objek seperti biasa…\n\norang1 = Orang(\"Bisma\", 19)\n\nLalu kita bisa melihat umurnya seperti ini:\n\nprint(orang1.get_umur())\n\n19\n\n\nAtau bahkan kita bisa membuat variabel baru yang menyimpan umur yang diperoleh:\n\nberapa_tahun = orang1.get_umur()\nprint(berapa_tahun)\n\n19\n\n\nKemudian, kita bisa memasang nilai baru untuk atribut umur:\n\norang1.set_umur(30)\n\nLalu memperoleh kembali umur yang baru:\n\norang1.get_umur()\n\n30\n\n\nSebenarnya, tujuan getter dan setter adalah untuk berjaga-jaga agar tidak terjadi hal yang aneh. Misalnya, saat ini, kita masih bisa memasang umur menjadi negatif:\n\norang1.umur = -5\nprint(orang1.umur)\n\n-5\n\n\nKita dapat menambahkan if statement pada definisi method set_umur di definisi class Orang untuk mencegah umur dipasang menjadi negatif:\n\nclass Orang:\n    def __init__(self, nama, umur):\n        self.nama = nama\n        self.umur = umur\n    def ulangtahun(self):\n        self.umur += 1\n    def get_umur(self):\n        return self.umur\n    def set_umur(self, baru):\n        if baru &gt;= 0:\n            self.umur = baru\n        else:\n            print(\"error: umur tidak bisa negatif\")\n\nSehingga, setelah membuat objek, kita bisa mencoba:\n\norang1 = Orang(\"Bisma\", 19)\n\n\norang1.set_umur(-5)\n\nerror: umur tidak bisa negatif\n\n\nDengan begitu, data umur masih aman:\n\norang1.get_umur()\n\n19\n\n\nSedangkan, pemasangan umur menjadi bilangan yang tidak negatif tetap berjalan dengan lancar:\n\norang1.set_umur(25)\nprint(orang1.get_umur())\n\n25\n\n\nApakah kemudian kita masih bisa menuliskan misalnya orang1.umur = -5? Masih bisa, tetapi setidaknya, sekarang dengan adanya getter dan setter untuk atribut umur, kita bisa menjadikan kebiasaan agar selalu menggunakan get_umur dan set_umur ketika ingin berurusan dengan data umur, tidak lagi melalui self.umur, agar terjamin tidak akan terjadi keanehan seperti itu. Biasanya, istilahnya, atribut umur disebut private, karena diharapkan tidak bisa diakses dari luar secara langsung, hanya boleh melalui method.\nBahkan, kita dapat menggunakan getter dan setter di dalam definisi method lainnya. Contohnya, yang tadinya method ulangtahun didefinisikan sebagai self.umur += 1, kita bisa menggantikannya dengan get_umur dan set_umur:\n\nclass Orang:\n    def __init__(self, nama, umur):\n        self.nama = nama\n        self.umur = umur\n    def ulangtahun(self):\n        self.set_umur(self.get_umur() + 1)\n    def get_umur(self):\n        return self.umur\n    def set_umur(self, baru):\n        if baru &gt;= 0:\n            self.umur = baru\n        else:\n            print(\"error: umur tidak bisa negatif\")\n\nPada definisi baru di atas untuk method ulangtahun, konsepnya sebagai berikut:\n\nPeroleh umur saat ini dengan self.get_umur\nTambah satu\nHasil yang baru itu dijadikan umur yang baru menggunakan self.set_umur\n\nSaat ini, orang1 masih menggunakan definisi method ulangtahun yang lama. Mari kita buat objek baru dari definisi class Orang yang baru bernama orang3, agar bisa dibandingkan:\n\norang3 = Orang(\"Bisma\", 19)\norang1.set_umur(19) # kita samakan dulu umurnya\n\nKemudian, kita gunakan method ulangtahun pada keduanya:\n\norang1.ulangtahun()\norang3.ulangtahun()\n\nKita bisa melihat umur baru masing-masing:\n\nprint(orang1.get_umur())\nprint(orang3.get_umur())\n\n20\n20\n\n\nTernyata hasilnya sama. Artinya, kedua cara mendefinisikan method ulangtahun itu memberikan hasil yang sama.\nPerhatikan bahwa, dari segi penggunaan, untuk menambahkan satu ke data umur, kita tinggal memanggil method ulangtahun. Kita tidak perlu memikirkan internalnya seperti apa. Bahkan, kita bisa mengubah definisinya secara internal, tetapi cara penggunaannya dari luar tetap sama.\nSelain itu, untuk memasang data umur baru tanpa pusing, kita bisa langsung menggunakan set_umur. Bahkan, kita tidak perlu mengkhawatirkan kasus umur negatif; method tersebut bisa langsung menanganinya. Sehingga, kapanpun kita ingin memasang data umur yang baru, kita tidak perlu lagi membuat if statement untuk memastikan umurnya tidak negatif, karena sudah ditangani oleh set_umur.\nKedua contoh method di atas menggambarkan bagaimana method bisa sangat mempermudah proses pemrograman kita dengan objek. Prinsip abstraction menekankan penggunaan method dengan cara seperti itu agar kita tidak perlu terlalu memusingkan detailnya. Misalnya, kita tidak perlu memusingkan cara mendefinisikan method ulangtahun, dan kita tidak perlu memusingkan kasus umur negatif berkat adanya method set_umur, pokoknya tinggal pakai. Lagipula, maksudnya “abstraksi” adalah kebalikan dari “mendetail”.\nSelain tidak pusing, manfaat lain dari abstraction adalah, kapanpun kita mau, kita bisa memodifikasi definisi method di definisi class nya saja, tanpa harus mengubah kode yang menggunakan method tersebut.\nBayangkan apabila tidak ada method ulangtahun, sehingga kita menjadi harus mengubah self.umur += 1 menjadi self.set_umur(self.get_umur() + 1) di mana-mana. Betapa ribetnya.\n\n\n\nSebelum belajar tentang inheritance, mari kita buat satu method lagi yaitu perkenalan:\n\nclass Orang:\n    def __init__(self, nama, umur):\n        self.nama = nama\n        self.umur = umur\n    def ulangtahun(self):\n        self.set_umur(self.get_umur() + 1)\n    def get_umur(self):\n        return self.umur\n    def set_umur(self, baru):\n        if baru &gt;= 0:\n            self.umur = baru\n        else:\n            print(\"error: umur tidak bisa negatif\")\n    def perkenalan(self):\n        print(\"Halo, nama saya \" + self.nama + \" dan umur saya \" + str(self.umur) + \" tahun.\")\n\nSeperti biasa, kita bisa membuat objek:\n\norang1 = Orang(\"Bisma\", 19)\norang2 = Orang(\"Vero\", 20)\n\nKemudian, kita bisa memanggil method perkenalan\n\norang1.perkenalan()\norang2.perkenalan()\n\nHalo, nama saya Bisma dan umur saya 19 tahun.\nHalo, nama saya Vero dan umur saya 20 tahun.\n\n\nLalu, misalnya, kita ingin membuat class baru yaitu class Mahasiswa, yang akan memiliki atribut tambahan yaitu NPM.\nTentunya, mahasiswa adalah orang, sehingga kita harapkan bahwa semua yang bisa dilakukan oleh objek dari class Orang juga bisa dilakukan oleh objek dari class Mahasiswa.\nUntungnya, daripada harus copy-paste semua method yang ada di class Orang ke dalam definisi class Mahasiswa, kita tinggal memanfaatkan inheritance (pewarisan sifat), dengan syntax yang bisa dilihat di baris pertama di kode berikut:\n\nclass Mahasiswa(Orang):\n    def __init__(self, nama, umur, NPM):\n        self.nama = nama\n        self.umur = umur\n        self.NPM = NPM\n\nSesingkat itu! Kita tinggal menyediakan constructor __init__ yang baru yang lebih sesuai untuk class Mahasiswa, karena adanya atribut baru yaitu NPM. Semua method lainnya akan tetap dimiliki oleh objek dari class Mahasiswa karena sudah diwariskan dari class Orang, hanya dengan menuliskan class Mahasiswa(Orang) pada baris pertama definisi class Mahasiswa.\nclass yang asli (di sini class Orang) biasa disebut parent class, base class, atau superclass, sedangkan class yang mewariskan (di sini class Mahasiswa) biasa disebut child class, derived class, atau subclass.\nKemudian, pembuatan objek dari class Mahasiswa dilakukan seperti biasa (jangan lupa, kali ini ada tiga atribut):\n\nmhs1 = Mahasiswa(\"Bisma\", 19, 2106635581)\n\nSeperti biasa, kita bisa lihat isi atributnya satu per satu:\n\nprint(mhs1.nama)\nprint(mhs1.umur)\nprint(mhs1.NPM)\n\nBisma\n19\n2106635581\n\n\nSemua method yang dimiliki oleh objek Orang itu juga dimiliki oleh objek Mahasiswa. Misalnya, kita bisa menggunakan method ulangtahun dan get_umur:\n\nmhs1.ulangtahun()\nprint(mhs1.get_umur())\n\n20\n\n\nKita juga bisa melakukan perkenalan\n\nmhs1.perkenalan()\n\nHalo, nama saya Bisma dan umur saya 20 tahun.\n\n\nNamun, isi perkenalannya sama persis seperti objek Orang, bahkan tidak ada keterangan NPM. Bagaimana kalau kita mau mahasiswa melakukan perkenalan dengan NPM juga? Apakah kita bisa memodifikasi method ini khusus untuk class Mahasiswa? Jawabannya adalah bisa, berkat prinsip polymorphism.\n\n\n\nSetelah melakukan inheritance, seandainya ada method yang diwaris yang dirasa perlu diubah atau dibedakan dari parent class, kita tinggal mendefinisikan ulang method tersebut di dalam definisi child class yang bersangkutan.\nMisalnya, kita bisa mendefinisikan ulang method perkenalan di dalam definisi class Mahasiswa agar berbeda dengan perkenalan di class Orang:\n\nclass Mahasiswa(Orang):\n    def __init__(self, nama, umur, NPM):\n        self.nama = nama\n        self.umur = umur\n        self.NPM = NPM\n    def perkenalan(self):\n        print(\"Perkenalkan, saya \" + self.nama + \" dengan NPM \" + str(self.NPM) )\n\nKita sudah memiliki orang1 sebagai objek dari class Orang, sehingga bisa kita bandingkan dengan objek dari class Mahasiswa yang perlu kita buat ulang:\n\nmhs1 = Mahasiswa(\"Bisma\", 19, 2106635581)\n\nSekarang kita lakukan perkenalan untuk masing-masing:\n\norang1.perkenalan()\nmhs1.perkenalan()\n\nHalo, nama saya Bisma dan umur saya 19 tahun.\nPerkenalkan, saya Bisma dengan NPM 2106635581\n\n\nHasilnya berbeda, sesuai harapan. Namun, nama method nya tetap sama, yaitu perkenalan. Seolah-olah, method perkenalan ini adalah “method yang sama” tetapi “memiliki bentuk yang berbeda-beda”, yaitu berbeda antara di class Orang dengan class Mahasiswa.\nBahkan, kalau mau, kita bisa membuat child class yang baru lagi dari class Orang, dan mendefinisikan ulang atau “menimpa” lagi method perkenalan untuk child class tersebut. Sehingga, method perkenalan ini seperti memiliki banyak bentuk.\n“Banyak bentuk” itulah yang dimaksud dengan polymorphism. Kita bisa melakukan inheritance berkali-kali, kemudian “menimpa” suatu method pada child class dengan definisi yang berbeda daripada di parent class.\nPenerapan lain dari prinsip polymorphism adalah fitur yang bernama operator overloading, yang kebetulan dimiliki oleh Python dan sejumlah “bahasa OOP” lainnya (bahasa yang “mendukung OOP”, yaitu memiliki fitur class, inheritance dan sebagainya sesuai dengan empat pilar OOP).\n\n\n\n\nMisalnya kita membuat class Pecahan yang terdiri dari atribut pembilang dan penyebut:\n\nclass Pecahan:\n    def __init__(self, pembilang, penyebut):\n        self.pembilang = pembilang\n        self.penyebut = penyebut\n\nKita bisa membuat pecahan setengah seperti berikut:\n\nfrac1 = Pecahan(1, 2)\n\nKita bisa melihat isi atribut pembilang dan penyebut:\n\nprint(frac1.pembilang)\nprint(frac1.penyebut)\n\n1\n2\n\n\nMisalnya kita ada pecahan lain…\n\nfrac2 = Pecahan(3, 5)\n\n… alangkah indahnya kalau kita bisa menjumlahkannya begitu saja…\n\nfrac1 + frac2\n\nTypeError: unsupported operand type(s) for +: 'Pecahan' and 'Pecahan'\n\n\nTerjadi error, karena saat ini, operator + belum ada artinya untuk objek Pecahan.\nAkan tetapi, ada method istimewa yang bisa kita definisikan agar operator + menjadi terdefinisi, lho! Namanya adalah __add__.\nSecara matematis, penjumlahan pecahan bisa dituliskan seperti berikut:\n\\[\\frac{a}{b} + \\frac{c}{d} = \\frac{ad + bc}{bd}\\]\nSehingga, kita bisa mendefinisikan method __add__ sebagai berikut:\n\nclass Pecahan:\n    def __init__(self, pembilang, penyebut):\n        self.pembilang = pembilang\n        self.penyebut = penyebut\n    def __add__(self, pecahan2):\n        a = self.pembilang\n        b = self.penyebut\n        c = pecahan2.pembilang\n        d = pecahan2.penyebut\n        atas = a*d + b*c\n        bawah = b*d\n        hasil = Pecahan(atas, bawah)\n        return hasil\n\nLalu, kita bisa membuat ulang kedua pecahan yang tadi, mencoba menjumlahkannya, dan melihat data atribut pembilang dan penyebut di hasil jumlahannya:\n\nfrac1 = Pecahan(1, 2)\nfrac2 = Pecahan(3, 5)\n\n\nfrac3 = frac1 + frac2\nprint(frac3.pembilang)\nprint(frac3.penyebut)\n\n11\n10\n\n\nWow, keren! Hasilnya benar ya!\nSelain penjumlahan, kita bisa mendefinisikan banyak operator lainnya untuk class. Pendefinisian operator untuk class disebut operator overloading (“menimpa operator”), dan selalu melibatkan method istimewa atau magic methods (juga disebut dunder methods atau double underscore methods) yang sudah memiliki nama tertentu. Kebetulan, constructor yang dinamakan __init__ juga termasuk magic method.\nKalian bisa membaca lebih lanjut tentang operator overloading dan magic method lainnya di link berikut:\nhttps://www.geeksforgeeks.org/operator-overloading-in-python/"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul02.html#apa-itu-class-apa-itu-oop",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul02.html#apa-itu-class-apa-itu-oop",
    "title": "Modul 2 Struktur Data: Pengantar OOP",
    "section": "",
    "text": "Di pertemuan sebelumnya, ketika belajar tentang tipe data di Python, kita sering menjumpai nama tipe data disertai istilah class. Sebelum memahami apa itu class, kita bisa paham dulu tentang konsep “objek”.\nDi Python (dan banyak bahasa pemrograman lainnya yang “mendukung OOP”), sebuah “objek” adalah sesuatu yang bisa memiliki variabel-variabel tersendiri (disebut atribut) serta fungsi-fungsi tersendiri (disebut method) di bawah satu nama yang sama (yaitu objek tersebut).\nKemudian, sebuah class adalah semacam blueprint untuk membuat objek. Ketika kita ingin membuat objek, kita harus membuat definisi class nya terlebih dahulu sebagai blueprint untuk objek tersebut. Barulah, setelah definisi class nya ada, kita bisa membuat objek sebanyak-banyaknya dari class yang sama.\nSebagai blueprint untuk membuat objek, suatu definisi class mencakupi atribut serta method yang akan terdefinisi untuk objek yang akan dibuat. Artinya, semua objek yang dibuat dari class yang sama itu akan memiliki “struktur” yang sama, baik variabel-variabel maupun fungsi-fungsi yang terkandung di dalam tiap objek.\n(Itulah mengapa tipe data dianggap sebagai class di Python. Misalnya, untuk tipe data str, yaitu &lt;class 'str'&gt;, semua string di Python tentunya “memiliki sifat yang sama”, seperti bisa di-format dengan method .format)\nAgar lebih paham, mari kita coba membuat class pertama kita, yaitu class Orang, untuk menyimpan data orang yang terdiri dari nama dan umur. Kemudian, kita akan membuat beberapa objek, yaitu beberapa Orang, yang masing-masing bisa memiliki data nama dan umur tersendiri.\n\nclass Orang:\n    def __init__(self, nama, umur):\n        self.nama = nama\n        self.umur = umur\n\nPada definisi class Orang di atas, kita baru merancang atribut apa saja yang akan terkandung dalam objek, yaitu nama dan umur.\n\nPada baris pertama, kita menuliskan kata class untuk memulai suatu definisi class baru, diikuti dengan nama class nya (di sini namanya Orang).\nPada baris kedua, kita memulai definisi suatu method istimewa yang bernama __init__ yang dimulai dan diakhiri dengan dua garis bawah. Method yang satu ini harus selalu ada di tiap definisi class, dan istilahnya adalah constructor. Argumen yang masuk ke dalam method ini adalah self yang merujuk ke “diri sendiri” (objek yang bersangkutan), kemudian dua atribut yang bisa ditentukan ketika objek dibuat, yaitu nama dan umur\nDi dalam definisi __init__ di atas (baris ketiga dan keempat), nilai self.nama dan self.umur akan dipasangkan menjadi nama dan umur yang “masuk ke dalam method” (yaitu ditentukan ketika objek dibuat).\n\nKalau baru pertama kali lihat, mungkin syntax definisi class rasanya sangat aneh dan asing. Tidak masalah, itu normal. Ketiknya pelan-pelan saja. Kalau belum begitu paham, juga tidak masalah, ikuti saja. Perlahan, kita akan terus-menerus memberi tambahan ke definisi class Orang tersebut agar lebih paham.\nSemoga menjadi lebih jelas setelah melihat syntax pembuatan objek:\n\norang1 = Orang(\"Bisma\", 19)\norang2 = Orang(\"Vero\", 20)\n\nKemudian, kita bisa melihat atribut objek seperti berikut:\n\nprint(orang1.nama)\nprint(orang1.umur)\n\nBisma\n19\n\n\n\nprint(orang2.nama)\nprint(orang2.umur)\n\nVero\n20\n\n\nPerhatikan bahwa masing-masing atribut diakses melalui objek yang bersangkutan. Terlihat kegunaan objek sebagai penampung beberapa variabel (atribut) di bawah satu nama yang sama.\nSelain melihat, tentunya kita juga bisa melakukan assignment:\n\norang1.umur = 21\nprint(orang1.umur)\n\n21\n\n\nBahkan, kita bisa melakukan variasi assignment lainnya seperti biasa, misalnya +=\n\norang1.umur += 3\nprint(orang1.umur)\n\n24\n\n\nKalau dirasa perlu, kita dapat membuat fungsi yang akan menerima suatu objek Orang lalu akan mengubah data umur.`\n\ndef ulangtahun(orang):\n    orang.umur += 1\n\nSehingga, bisa digunakan seperti berikut:\n\nulangtahun(orang1)\nprint(orang1.umur)\n\n25\n\n\nPerhatikan bahwa objek di Python bersifat pass-by-reference! Artinya, apabila suatu objek dimasukkan ke dalam fungsi, kemudian dimodifikasi di dalam fungsi tersebut, maka modifikasi tersebut juga berdampak hingga di luar fungsi.\nDefinisi fungsi ulangtahun yang telah kita buat di atas sebenarnya bisa dimasukkan ke dalam definisi class Orang sebagai suatu method.\n\nclass Orang:\n    def __init__(self, nama, umur):\n        self.nama = nama\n        self.umur = umur\n    def ulangtahun(self):\n        self.umur += 1\n\nPerhatikan, ini adalah pendefinisian ulang! Ini adalah definisi baru untuk class Orang. Sedangkan, objek-objek yang sudah kita buat sebelumnya masih menganut definisi yang lama. Sehingga, setelah ini, kita harus membuat ulang objek agar mengikuti definisi class Orang yang baru.\nPerhatikan juga, ada sedikit perbedaan istilah pada fungsi ulangtahun: tadinya, objek yang masuk itu kita sebut orang, sekarang kita sebut self. Istilah self ini memang sudah menjadi kebiasaan di Python untuk merujuk ke diri sendiri, yaitu objek yang bersangkutan. Tiap definisi method selalu harus diawali dengan masuknya objek yang bersangkutan (yang biasa disebut self), sudah menjadi formalitas di Python.\nItulah mengapa, di definisi __init__ seolah-olah ada tiga variabel yang masuk yaitu self, nama, dan umur, meskipun yang diperlukan ketika membuat objeknya hanyalah nama dan umur.\nMari kita buat ulang orang1:\n\norang1 = Orang(\"Bisma\", 19)\n\nKita bisa melihat atributnya:\n\nprint(orang1.nama)\nprint(orang1.umur)\n\nBisma\n19\n\n\nKemudian, kita bisa menggunakan method ulangtahun yang telah kita buat, lalu melihat data umur terbaru:\n\norang1.ulangtahun()\nprint(orang1.umur)\n\n20\n\n\nPenggunaan method memang seperti itu, sangat mirip dengan mengakses atribut, bedanya adalah bahwa method berupa fungsi. Di sini, kita bisa melihat, baik atribut maupun method suatu objek itu sama-sama berada di bawah satu nama yang sama, yaitu objek yang bersangkutan (di sini, baik atribut umur maupun method ulangtahun diakses melalui orang1).\nKalau mau, kita bisa melakukannya lagi:\n\norang1.ulangtahun()\nprint(orang1.umur)\n\n21\n\n\nTentu saja, kegunaan class tidak sebatas itu. Bahkan, ada semacam “paradigma pemrograman” (gaya pemrograman) di mana kita sering berurusan dengan class, yang disebut OOP. Agar lebih paham juga tentang class dan kegunaannya, kita akan mempelajari dasar-dasar OOP, yang tercakup oleh empat pilar (tiang) OOP."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul02.html#empat-pilar-oop",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul02.html#empat-pilar-oop",
    "title": "Modul 2 Struktur Data: Pengantar OOP",
    "section": "",
    "text": "Empat pilar OOP adalah:\n\nEncapsulation (pembungkusan)\nAbstraction (abstraksi; kebalikan dari “mendetail”)\nInheritance (pewarisan sifat)\nPolymorphism (“banyak bentuk”)\n\nIstilah prinsip polymorphism memang sulit diterjemahkan. Kita akan membahas masing-masing keempat prinsip OOP tersebut.\n\n\nSejauh ini, kita sudah merasakan bagaimana variabel (atribut) dan fungsi (method) sama-sama berada di bawah satu nama yang sama, yaitu objek yang bersangkutan. Seolah-olah, atribut dan method tersebut dibungkus ke dalam objek tersebut. Inilah yang dinamakan prinsip encapsulation atau pembungkusan.\nNamun, ada juga konsep data hiding, di mana atribut objek sebaiknya diakses dan dimodifikasi melalui method saja. Method untuk memperoleh (mengakses) nilai atribut tertentu disebut getter, dan method untuk memasang nilai baru untuk atribut tertentu disebut setter.\nPrinsip data hiding seringkali dianggap bagian dari prinsip encapsulation (tetapi terkadang dianggap bagian dari abstraction yang akan kita bahas selanjutnya).\nKita akan mendefinisikan ulang class Orang agar memiliki getter dan setter untuk atribut umur.\n\nclass Orang:\n    def __init__(self, nama, umur):\n        self.nama = nama\n        self.umur = umur\n    def ulangtahun(self):\n        self.umur += 1\n    def get_umur(self):\n        return self.umur\n    def set_umur(self, baru):\n        self.umur = baru\n\nPerhatikan bahwa method get_umur melakukan return. Penggunaannya akan mirip dengan fungsi seperti biasanya. Kemudian, method set_umur akan menerima satu input di dalam kurungnya (sedangkan self hanya untuk formalitas).\nKita bisa membuat objek seperti biasa…\n\norang1 = Orang(\"Bisma\", 19)\n\nLalu kita bisa melihat umurnya seperti ini:\n\nprint(orang1.get_umur())\n\n19\n\n\nAtau bahkan kita bisa membuat variabel baru yang menyimpan umur yang diperoleh:\n\nberapa_tahun = orang1.get_umur()\nprint(berapa_tahun)\n\n19\n\n\nKemudian, kita bisa memasang nilai baru untuk atribut umur:\n\norang1.set_umur(30)\n\nLalu memperoleh kembali umur yang baru:\n\norang1.get_umur()\n\n30\n\n\nSebenarnya, tujuan getter dan setter adalah untuk berjaga-jaga agar tidak terjadi hal yang aneh. Misalnya, saat ini, kita masih bisa memasang umur menjadi negatif:\n\norang1.umur = -5\nprint(orang1.umur)\n\n-5\n\n\nKita dapat menambahkan if statement pada definisi method set_umur di definisi class Orang untuk mencegah umur dipasang menjadi negatif:\n\nclass Orang:\n    def __init__(self, nama, umur):\n        self.nama = nama\n        self.umur = umur\n    def ulangtahun(self):\n        self.umur += 1\n    def get_umur(self):\n        return self.umur\n    def set_umur(self, baru):\n        if baru &gt;= 0:\n            self.umur = baru\n        else:\n            print(\"error: umur tidak bisa negatif\")\n\nSehingga, setelah membuat objek, kita bisa mencoba:\n\norang1 = Orang(\"Bisma\", 19)\n\n\norang1.set_umur(-5)\n\nerror: umur tidak bisa negatif\n\n\nDengan begitu, data umur masih aman:\n\norang1.get_umur()\n\n19\n\n\nSedangkan, pemasangan umur menjadi bilangan yang tidak negatif tetap berjalan dengan lancar:\n\norang1.set_umur(25)\nprint(orang1.get_umur())\n\n25\n\n\nApakah kemudian kita masih bisa menuliskan misalnya orang1.umur = -5? Masih bisa, tetapi setidaknya, sekarang dengan adanya getter dan setter untuk atribut umur, kita bisa menjadikan kebiasaan agar selalu menggunakan get_umur dan set_umur ketika ingin berurusan dengan data umur, tidak lagi melalui self.umur, agar terjamin tidak akan terjadi keanehan seperti itu. Biasanya, istilahnya, atribut umur disebut private, karena diharapkan tidak bisa diakses dari luar secara langsung, hanya boleh melalui method.\nBahkan, kita dapat menggunakan getter dan setter di dalam definisi method lainnya. Contohnya, yang tadinya method ulangtahun didefinisikan sebagai self.umur += 1, kita bisa menggantikannya dengan get_umur dan set_umur:\n\nclass Orang:\n    def __init__(self, nama, umur):\n        self.nama = nama\n        self.umur = umur\n    def ulangtahun(self):\n        self.set_umur(self.get_umur() + 1)\n    def get_umur(self):\n        return self.umur\n    def set_umur(self, baru):\n        if baru &gt;= 0:\n            self.umur = baru\n        else:\n            print(\"error: umur tidak bisa negatif\")\n\nPada definisi baru di atas untuk method ulangtahun, konsepnya sebagai berikut:\n\nPeroleh umur saat ini dengan self.get_umur\nTambah satu\nHasil yang baru itu dijadikan umur yang baru menggunakan self.set_umur\n\nSaat ini, orang1 masih menggunakan definisi method ulangtahun yang lama. Mari kita buat objek baru dari definisi class Orang yang baru bernama orang3, agar bisa dibandingkan:\n\norang3 = Orang(\"Bisma\", 19)\norang1.set_umur(19) # kita samakan dulu umurnya\n\nKemudian, kita gunakan method ulangtahun pada keduanya:\n\norang1.ulangtahun()\norang3.ulangtahun()\n\nKita bisa melihat umur baru masing-masing:\n\nprint(orang1.get_umur())\nprint(orang3.get_umur())\n\n20\n20\n\n\nTernyata hasilnya sama. Artinya, kedua cara mendefinisikan method ulangtahun itu memberikan hasil yang sama.\nPerhatikan bahwa, dari segi penggunaan, untuk menambahkan satu ke data umur, kita tinggal memanggil method ulangtahun. Kita tidak perlu memikirkan internalnya seperti apa. Bahkan, kita bisa mengubah definisinya secara internal, tetapi cara penggunaannya dari luar tetap sama.\nSelain itu, untuk memasang data umur baru tanpa pusing, kita bisa langsung menggunakan set_umur. Bahkan, kita tidak perlu mengkhawatirkan kasus umur negatif; method tersebut bisa langsung menanganinya. Sehingga, kapanpun kita ingin memasang data umur yang baru, kita tidak perlu lagi membuat if statement untuk memastikan umurnya tidak negatif, karena sudah ditangani oleh set_umur.\nKedua contoh method di atas menggambarkan bagaimana method bisa sangat mempermudah proses pemrograman kita dengan objek. Prinsip abstraction menekankan penggunaan method dengan cara seperti itu agar kita tidak perlu terlalu memusingkan detailnya. Misalnya, kita tidak perlu memusingkan cara mendefinisikan method ulangtahun, dan kita tidak perlu memusingkan kasus umur negatif berkat adanya method set_umur, pokoknya tinggal pakai. Lagipula, maksudnya “abstraksi” adalah kebalikan dari “mendetail”.\nSelain tidak pusing, manfaat lain dari abstraction adalah, kapanpun kita mau, kita bisa memodifikasi definisi method di definisi class nya saja, tanpa harus mengubah kode yang menggunakan method tersebut.\nBayangkan apabila tidak ada method ulangtahun, sehingga kita menjadi harus mengubah self.umur += 1 menjadi self.set_umur(self.get_umur() + 1) di mana-mana. Betapa ribetnya.\n\n\n\nSebelum belajar tentang inheritance, mari kita buat satu method lagi yaitu perkenalan:\n\nclass Orang:\n    def __init__(self, nama, umur):\n        self.nama = nama\n        self.umur = umur\n    def ulangtahun(self):\n        self.set_umur(self.get_umur() + 1)\n    def get_umur(self):\n        return self.umur\n    def set_umur(self, baru):\n        if baru &gt;= 0:\n            self.umur = baru\n        else:\n            print(\"error: umur tidak bisa negatif\")\n    def perkenalan(self):\n        print(\"Halo, nama saya \" + self.nama + \" dan umur saya \" + str(self.umur) + \" tahun.\")\n\nSeperti biasa, kita bisa membuat objek:\n\norang1 = Orang(\"Bisma\", 19)\norang2 = Orang(\"Vero\", 20)\n\nKemudian, kita bisa memanggil method perkenalan\n\norang1.perkenalan()\norang2.perkenalan()\n\nHalo, nama saya Bisma dan umur saya 19 tahun.\nHalo, nama saya Vero dan umur saya 20 tahun.\n\n\nLalu, misalnya, kita ingin membuat class baru yaitu class Mahasiswa, yang akan memiliki atribut tambahan yaitu NPM.\nTentunya, mahasiswa adalah orang, sehingga kita harapkan bahwa semua yang bisa dilakukan oleh objek dari class Orang juga bisa dilakukan oleh objek dari class Mahasiswa.\nUntungnya, daripada harus copy-paste semua method yang ada di class Orang ke dalam definisi class Mahasiswa, kita tinggal memanfaatkan inheritance (pewarisan sifat), dengan syntax yang bisa dilihat di baris pertama di kode berikut:\n\nclass Mahasiswa(Orang):\n    def __init__(self, nama, umur, NPM):\n        self.nama = nama\n        self.umur = umur\n        self.NPM = NPM\n\nSesingkat itu! Kita tinggal menyediakan constructor __init__ yang baru yang lebih sesuai untuk class Mahasiswa, karena adanya atribut baru yaitu NPM. Semua method lainnya akan tetap dimiliki oleh objek dari class Mahasiswa karena sudah diwariskan dari class Orang, hanya dengan menuliskan class Mahasiswa(Orang) pada baris pertama definisi class Mahasiswa.\nclass yang asli (di sini class Orang) biasa disebut parent class, base class, atau superclass, sedangkan class yang mewariskan (di sini class Mahasiswa) biasa disebut child class, derived class, atau subclass.\nKemudian, pembuatan objek dari class Mahasiswa dilakukan seperti biasa (jangan lupa, kali ini ada tiga atribut):\n\nmhs1 = Mahasiswa(\"Bisma\", 19, 2106635581)\n\nSeperti biasa, kita bisa lihat isi atributnya satu per satu:\n\nprint(mhs1.nama)\nprint(mhs1.umur)\nprint(mhs1.NPM)\n\nBisma\n19\n2106635581\n\n\nSemua method yang dimiliki oleh objek Orang itu juga dimiliki oleh objek Mahasiswa. Misalnya, kita bisa menggunakan method ulangtahun dan get_umur:\n\nmhs1.ulangtahun()\nprint(mhs1.get_umur())\n\n20\n\n\nKita juga bisa melakukan perkenalan\n\nmhs1.perkenalan()\n\nHalo, nama saya Bisma dan umur saya 20 tahun.\n\n\nNamun, isi perkenalannya sama persis seperti objek Orang, bahkan tidak ada keterangan NPM. Bagaimana kalau kita mau mahasiswa melakukan perkenalan dengan NPM juga? Apakah kita bisa memodifikasi method ini khusus untuk class Mahasiswa? Jawabannya adalah bisa, berkat prinsip polymorphism.\n\n\n\nSetelah melakukan inheritance, seandainya ada method yang diwaris yang dirasa perlu diubah atau dibedakan dari parent class, kita tinggal mendefinisikan ulang method tersebut di dalam definisi child class yang bersangkutan.\nMisalnya, kita bisa mendefinisikan ulang method perkenalan di dalam definisi class Mahasiswa agar berbeda dengan perkenalan di class Orang:\n\nclass Mahasiswa(Orang):\n    def __init__(self, nama, umur, NPM):\n        self.nama = nama\n        self.umur = umur\n        self.NPM = NPM\n    def perkenalan(self):\n        print(\"Perkenalkan, saya \" + self.nama + \" dengan NPM \" + str(self.NPM) )\n\nKita sudah memiliki orang1 sebagai objek dari class Orang, sehingga bisa kita bandingkan dengan objek dari class Mahasiswa yang perlu kita buat ulang:\n\nmhs1 = Mahasiswa(\"Bisma\", 19, 2106635581)\n\nSekarang kita lakukan perkenalan untuk masing-masing:\n\norang1.perkenalan()\nmhs1.perkenalan()\n\nHalo, nama saya Bisma dan umur saya 19 tahun.\nPerkenalkan, saya Bisma dengan NPM 2106635581\n\n\nHasilnya berbeda, sesuai harapan. Namun, nama method nya tetap sama, yaitu perkenalan. Seolah-olah, method perkenalan ini adalah “method yang sama” tetapi “memiliki bentuk yang berbeda-beda”, yaitu berbeda antara di class Orang dengan class Mahasiswa.\nBahkan, kalau mau, kita bisa membuat child class yang baru lagi dari class Orang, dan mendefinisikan ulang atau “menimpa” lagi method perkenalan untuk child class tersebut. Sehingga, method perkenalan ini seperti memiliki banyak bentuk.\n“Banyak bentuk” itulah yang dimaksud dengan polymorphism. Kita bisa melakukan inheritance berkali-kali, kemudian “menimpa” suatu method pada child class dengan definisi yang berbeda daripada di parent class.\nPenerapan lain dari prinsip polymorphism adalah fitur yang bernama operator overloading, yang kebetulan dimiliki oleh Python dan sejumlah “bahasa OOP” lainnya (bahasa yang “mendukung OOP”, yaitu memiliki fitur class, inheritance dan sebagainya sesuai dengan empat pilar OOP)."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul02.html#operator-overloading",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul02.html#operator-overloading",
    "title": "Modul 2 Struktur Data: Pengantar OOP",
    "section": "",
    "text": "Misalnya kita membuat class Pecahan yang terdiri dari atribut pembilang dan penyebut:\n\nclass Pecahan:\n    def __init__(self, pembilang, penyebut):\n        self.pembilang = pembilang\n        self.penyebut = penyebut\n\nKita bisa membuat pecahan setengah seperti berikut:\n\nfrac1 = Pecahan(1, 2)\n\nKita bisa melihat isi atribut pembilang dan penyebut:\n\nprint(frac1.pembilang)\nprint(frac1.penyebut)\n\n1\n2\n\n\nMisalnya kita ada pecahan lain…\n\nfrac2 = Pecahan(3, 5)\n\n… alangkah indahnya kalau kita bisa menjumlahkannya begitu saja…\n\nfrac1 + frac2\n\nTypeError: unsupported operand type(s) for +: 'Pecahan' and 'Pecahan'\n\n\nTerjadi error, karena saat ini, operator + belum ada artinya untuk objek Pecahan.\nAkan tetapi, ada method istimewa yang bisa kita definisikan agar operator + menjadi terdefinisi, lho! Namanya adalah __add__.\nSecara matematis, penjumlahan pecahan bisa dituliskan seperti berikut:\n\\[\\frac{a}{b} + \\frac{c}{d} = \\frac{ad + bc}{bd}\\]\nSehingga, kita bisa mendefinisikan method __add__ sebagai berikut:\n\nclass Pecahan:\n    def __init__(self, pembilang, penyebut):\n        self.pembilang = pembilang\n        self.penyebut = penyebut\n    def __add__(self, pecahan2):\n        a = self.pembilang\n        b = self.penyebut\n        c = pecahan2.pembilang\n        d = pecahan2.penyebut\n        atas = a*d + b*c\n        bawah = b*d\n        hasil = Pecahan(atas, bawah)\n        return hasil\n\nLalu, kita bisa membuat ulang kedua pecahan yang tadi, mencoba menjumlahkannya, dan melihat data atribut pembilang dan penyebut di hasil jumlahannya:\n\nfrac1 = Pecahan(1, 2)\nfrac2 = Pecahan(3, 5)\n\n\nfrac3 = frac1 + frac2\nprint(frac3.pembilang)\nprint(frac3.penyebut)\n\n11\n10\n\n\nWow, keren! Hasilnya benar ya!\nSelain penjumlahan, kita bisa mendefinisikan banyak operator lainnya untuk class. Pendefinisian operator untuk class disebut operator overloading (“menimpa operator”), dan selalu melibatkan method istimewa atau magic methods (juga disebut dunder methods atau double underscore methods) yang sudah memiliki nama tertentu. Kebetulan, constructor yang dinamakan __init__ juga termasuk magic method.\nKalian bisa membaca lebih lanjut tentang operator overloading dan magic method lainnya di link berikut:\nhttps://www.geeksforgeeks.org/operator-overloading-in-python/"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/strukdat2023.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/strukdat2023.html",
    "title": "Praktikum Struktur Data 2023 Ganjil dengan Python (Kurikulum 2020)",
    "section": "",
    "text": "Kembali ke Praktikum\nPraktikum Struktur Data tahun 2023 semester ganjil ini akan dilaksanakan menggunakan bahasa pemrograman Python.\n\nModul per pertemuan dan tugas\n\nModul 1: Tipe Data di Python, 14-15 September 2023 (offline di Lab Departemen Matematika D.311)\nModul 2: Pengantar OOP, 21-22 September 2023 (online melalui Zoom)\nModul 3: I/O, CodeChef, 29 September 2023 (online melalui Zoom)\nModul 4: Array, Searching, Sorting, 5-6 Oktober 2023 (online melalui Zoom)\nModul 5: Graphviz, Linked List, 12-13 Oktober 2023 (online melalui Zoom)\nTugas 1: Array, Linked List, OOP\nDiberikan: Minggu, 22 Oktober 2023\nDeadline: Minggu, 5 November 2023, 23.59 WIB\nModul 6: Stack, 2-3 November 2023 (online melalui Zoom)\nModul 7: Queue, 9-10 November 2023 (online melalui Zoom)\nModul 8: Binary Tree, Binary Search Tree (BST), 16-17 November 2023 (online melalui Zoom)\nModul 9: Heap Tree, AVL/Balance Tree, 23-24 November 2023 (online melalui Zoom)\n\n(coming soon) Modul 9a: A-B Tree dan variasinya (B-Tree, 2-3 Tree, dsb)\n\nTugas 2: Stack, Queue, dan berbagai Binary Tree\nDiberikan: Sabtu, 25 November 2023\nDeadline: Sabtu, 9 Desember 2023, 23.59 WIB\nModul 10: Pengantar database dengan SQLite, 30 November–1 Desember 2023 (online melalui Zoom)\n\n\n\nRekaman praktikum\nSemua rekaman praktikum Struktur Data (yang dilaksanakan secara online melalui Zoom) disimpan di link berikut.\nhttps://bit.ly/RekamanPrakStrukdat2023Ganjil\nTiap kali ada praktikum, rekaman akan di-upload ke folder Google Drive tersebut beberapa hari kemudian.\nAntara praktikum kelas A dan kelas B, materinya sama saja; apabila untuk materi tertentu hanya ada rekaman untuk salah satu kelas, tonton saja yang ada, harusnya tidak masalah."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04a.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04a.html",
    "title": "Modul 4a (opsional): ASCII, Unicode, inttypes.h, dan manipulasi text file",
    "section": "",
    "text": "Kembali ke Struktur Data\n\nOutline\n\nTentang ASCII, char, dan int\nManipulasi text file berformat ASCII\nTentang stderr\ninttypes.h untuk tipe data bilangan bulat dengan berbagai ukuran\nTentang Unicode: UTF-32, UTF-8\nManipulasi text file berformat UTF-8\nHeader file untuk Modul 4a Praktikum: prakmodul4a.h dan prakmodul4a.c\n\n\n\nTentang ASCII, char, dan int\nblablabla chart table thingy\n\n\nManipulasi text file berformat ASCII\nhttps://stackoverflow.com/questions/4627330/difference-between-fprintf-printf-and-sprintf\nhttps://www.tutorialspoint.com/c_standard_library/c_function_fprintf.htm\nfopen, fprintf, fclose later fgets, sscanf\nhttps://www.guru99.com/c-file-input-output.html\nblabla\n\n\nTentang stderr\nhttps://stackoverflow.com/questions/12102332/when-should-i-use-perror-and-fprintfstderr\nblabla\n\n\ninttypes.h untuk tipe data bilangan bulat dengan berbagai ukuran\nblabla\n\n\nTentang Unicode: UTF-32, UTF-8\nblabla\n\n\nManipulasi text file berformat UTF-8\nhttps://stackoverflow.com/questions/21737906/how-to-read-write-utf8-text-files-in-c\nblabla\nhttps://www.youtube.com/watch?v=70b9ineDgLU\nhttps://gitlab.com/greggink/youtube_episode_understanding_text/-/blob/master/main.c\nblabla\n\n\nHeader file untuk Modul 4a Praktikum: prakmodul4a.h dan prakmodul4a.c\n\nprakmodul4a.hprakmodul4a.c\n\n\n// empty\n\n\n// empty"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "",
    "text": "Kembali ke Struktur Data"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#linear-search",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#linear-search",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Linear search",
    "text": "Linear search\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#binary-search",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#binary-search",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Binary search",
    "text": "Binary search\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#bubble-sort",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#bubble-sort",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Bubble sort",
    "text": "Bubble sort\nBubble sort adalah suatu algoritma sorting yang dilakukan berkali-kali sampai array sudah terurut dengan benar, di mana tiap elemen diperiksa dengan sebelahnya, kemudian ditukar apabila urutan di antara keduanya belum benar. Ketika melakukan bubble sort, kita bisa yakin bahwa array sudah terurut apabila sudah tidak terjadi pertukaran sama sekali ketika memeriksa kembali semua elemen array dari awal sampai akhir.\nDengan konsep di atas, kita bisa membuat fungsi bubble sort seperti berikut.\nvoid array_int_bubblesort1_asc(int arr[], size_t arr_length) {\n    bool terjadi_pertukaran = true; // asumsi array belum terurut\n\n    // ulangi selama masih terjadi pertukaran\n    while (terjadi_pertukaran) {\n        terjadi_pertukaran = false;\n        // asumsi tidak akan terjadi pertukaran,\n        // akan diubah menjadi true ketika terjadi pertukaran\n\n        // for loop untuk melihat tiap elemen dari awal sampai akhir\n        for (int i = 0; i &lt; (int)arr_length-1; i++) {\n            if (arr[i] &gt; arr[i+1]) { // apabila ada yang harus ditukar\n                // maka tukarlah\n                int temp = arr[i];\n                arr[i] = arr[i+1];\n                arr[i+1] = temp;\n\n                // terjadi pertukaran\n                terjadi_pertukaran = true;\n            }\n        }\n    }\n}\nPerhatikan bahwa fungsi di atas memiliki return type berupa void, yang artinya tidak ada yang di-return. Bahkan, elemen array langsung ditukar menggunakan array yang dimasukkan ke dalam fungsi. Di bahasa pemrograman C, ada sesuatu yang spesial tentang array sehingga array bisa langsung dimanipulasi dari dalam fungsi. Hal ini akan dibahas di pertemuan selanjutnya bersama pointer.\nIntinya, terima saja dulu, bahwa ketika array masuk sebagai input fungsi, maka apapun yang dilakukan pada array tersebut di dalam fungsinya akan benar-benar mengubah array yang sesungguhnya.\nDengan demikian, penggunaan fungsi di atas bisa seperti berikut:\n\n\nbubblesort1.c\n\n#include &lt;stdio.h&gt;\n#include \"prakmodul2.h\"\n\n// deklarasi fungsi\nvoid array_int_bubblesort1_asc(int arr[], size_t arr_length);\n// fungsi ini akan didefinisikan setelah definisi fungsi main\n\nint main () {\n    int array1[] = {10, 3, 8, 4, 5, 7, 9, 6};\n    size_t panjang1 = sizeof(array1)/sizeof(array1[0]);\n\n    printf(\"Sebelum bubble sort: \");\n    array_int_print(array1, panjang1);\n    printf(\"\\n\");\n\n    printf(\"Setelah bubble sort: \");\n    array_int_bubblesort1_asc(array1, panjang1);\n    array_int_print(array1, panjang1);\n\n    return 0;\n}\n\n// definisi fungsi\nvoid array_int_bubblesort1_asc(int arr[], size_t arr_length) {\n    bool terjadi_pertukaran = true; // asumsi array belum terurut\n\n    // ulangi selama masih terjadi pertukaran\n    while (terjadi_pertukaran) {\n        terjadi_pertukaran = false;\n        // asumsi tidak akan terjadi pertukaran,\n        // akan diubah menjadi true ketika terjadi pertukaran\n\n        // for loop untuk melihat tiap elemen dari awal sampai akhir\n        for (int i = 0; i &lt; (int)arr_length-1; i++) {\n            if (arr[i] &gt; arr[i+1]) { // apabila ada yang harus ditukar\n                // maka tukarlah\n                int temp = arr[i];\n                arr[i] = arr[i+1];\n                arr[i+1] = temp;\n\n                // terjadi pertukaran\n                terjadi_pertukaran = true;\n            }\n        }\n    }\n}\n\nPerhatikan bahwa… (basically lead to optimizing bubble sort, provide two other variations as per the wikipedia page)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#selection-sort",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#selection-sort",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Selection sort",
    "text": "Selection sort\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#insertion-sort",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#insertion-sort",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Insertion sort",
    "text": "Insertion sort\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#merge-sort",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#merge-sort",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Merge sort",
    "text": "Merge sort\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#quicksort-versi-hoare",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#quicksort-versi-hoare",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Quicksort versi Hoare",
    "text": "Quicksort versi Hoare\nTony Hoare menerbitkan paper tentang quicksort, yaitu algoritma sorting yang ia buat, pada tahun 1961, yang bisa dilihat di tautan (link) berikut.\n\nhttps://www.cs.ox.ac.uk/files/6226/H2006%20-%20Historic%20Quicksort.pdf\n(link alternatif) http://rabbit.eng.miami.edu/class/een511/quicksort.pdf\n\nSejak itu, sudah ada beberapa variasi quicksort, seperti versi Lomuto. Namun, inti sari dari algoritma quicksort secara umum adalah sebagai berikut:\n\nApabila array ternyata kosong atau hanya terdiri dari satu elemen, diamkan saja, tidak ada yang perlu disortir. Apabila terdiri dari 2+ elemen, lanjut ke langkah selanjutnya.\nPilih salah satu elemen pada array (boleh yang mana saja) sebagai elemen “pivot”. Jangan sampai lupa, baik nilainya maupun indeksnya/letaknya.\nLakukan “partisi”, yaitu pertukaran elemen seperlunya (bahkan elemen pivot boleh ikut ditukar dan dipindahkan) sedemikian sehingga, pada akhirnya,\n\nsemua elemen di sebelah kiri pivot pasti lebih kecil (atau sama dengan) pivot; dan\nsemua elemen di sebelah kanan pivot pasti lebih besar (atau sama dengan) pivot.\n\n“Partisi” yang dimaksud adalah bahwa, setelah proses partisi selesai, array seakan-akan telah terbagi (terpartisi) menjadi tiga bagian, yaitu (dari kiri ke kanan):\n\n“partisi kiri/bawah”, yaitu bagian di sebelah kiri pivot, terdiri dari semua elemen yang lebih kecil (atau sama dengan) pivot;\npivot itu sendiri; dan\n“partisi kanan/atas”, yaitu bagian di sebelah kanan pivot, terdiri dari semua elemen yang lebih besar (atau sama dengan) pivot.\n\nKemudian, memperhatikan letak pivot, lakukan quicksort pada semua elemen di sebelah kiri pivot (yaitu pada partisi kiri), dan lakukan quicksort pada semua elemen di sebelah kanan pivot (yaitu pada partisi kanan).\n\n(Menariknya, Tony Hoare tidak menggunakan istilah “pivot”. Beliau menggunakan istilah “bound” untuk “nilai pivot”, dan menuliskan “the element from which the bound was chosen” ketika bermaksud mengatakan “elemen pivot”.)\nTerlihat dari langkah terakhir, algoritma quicksort bersifat rekursif. Bagian tersulit dari quicksort adalah pada tahapan partisi. Tahapan inilah yang cara melakukannya bisa bervariasi (tidak seperti algoritma sorting lainnya yang cenderung begitu-begitu saja). Tidak hanya itu, bahkan cara memilih pivot bisa saja dengan memilih elemen pertama, elemen tengah, elemen terakhir, atau median dari ketiganya (“median-of-three”), ataupun variasi lainnya.\nDari paper aslinya, penjelasan Tony Hoare tentang cara melakukan partisi (menurut beliau) bisa dirangkum sebagai berikut:\n\nBuat dua “panah”, yaitu “panah bawah” (i) dan “panah atas” (j), di mana panah bawah menunjuk pada elemen pertama dan panah atas menunjuk pada elemen terakhir. (Secara pemrograman, simpan indeksnya saja.) Bisa dibayangkan, ada asumsi array sudah dipartisi, di mana panah bawah akan memastikan partisi kiri sudah benar, dan panah atas akan memastikan partisi kanan sudah benar.\nwhile loop: selama elemen yang ditunjuk oleh panah bawah itu masih lebih kecil atau sama dengan nilai pivot, (dan selama panah bawah belum melewati panah atas,) geser panah bawah satu langkah ke kanan. (Artinya, selama partisi kiri sudah benar, lanjut memeriksa elemen berikutnya yaitu ke kanan. Berhenti ketika ada yang lebih besar dari pivot, sehingga harusnya ada di partisi kanan; menunggu ditukar.)\nwhile loop: selama elemen yang ditunjuk oleh panah atas itu masih lebih besar atau sama dengan nilai pivot, (dan selama panah bawah belum melewati panah atas,) geser panah atas satu langkah ke kiri. (Artinya, selama partisi kanan sudah benar, lanjut memeriksa elemen berikutnya yaitu ke kiri. Berhenti ketika ada yang lebih kecil dari pivot, sehingga harusnya ada di partisi kiri; menunggu ditukar.)\nSampai sini, apabila panah bawah masih belum melewati panah atas, maka ada dua elemen yang menunggu ditukar, yaitu yang ditunjuk oleh panah bawah dan yang ditunjuk oleh panah atas. Maka tukarlah, lalu kembali ke langkah kedua.\nSampai sini, sudah tidak lagi kembali ke langkah kedua, sehingga panah bawah sudah melewati panah atas; sekarang panah atas ada di sebelah kiri dari panah bawah. Bayangkan, di antara dua panah tersebut, ada semacam garis pembagi: dari elemen pertama sampai panah atas adalah “partisi kiri”, sedangkan dari panah bawah sampai elemen terakhir adalah “partisi kanan”.\n\nApabila pivot jatuh pada partisi kiri (indeks pivot &lt;= panah atas), tukarkan elemen pada panah atas dengan elemen pivot. (Lalu, bayangkan bahwa partisi kiri sedikit diperkecil karena elemen pivot tidak boleh masuk ke kedua partisi.)\nSedangkan, apabila pivot berada pada partisi kanan (indeks pivot &gt;= panah bawah), tukarkan elemen pada panah bawah dengan elemen pivot. (Lalu, bayangkan bahwa partisi kanan sedikit diperkecil karena elemen pivot tidak boleh masuk ke kedua partisi.)\n\n(Dengan demikian, letak pivot sekarang berada di perbatasan antara partisi kiri dan partisi kanan.)\nKembalikan indeks letak pivot.\n\nCatatan: apabila, pada langkah keempat, ternyata antara panah bawah maupun panah atas sedang menunjuk ke elemen pivot, maka elemen pivot terlibat dalam pertukaran; jangan lupa mengubah indeks pivot menjadi posisi barunya setelah ditukar.\n(Sebenarnya, Tony Hoare menggunakan istilah lower pointer dan upper pointer untuk kedua panah. Namun, konsep pointer sebenarnya tidak diperlukan sama sekali, dan konsep yang beliau maksud juga bisa digambarkan dengan panah, yang letaknya berupa indeks array.)\nSebelum membuat kode untuk algoritma quicksort versi Tony Hoare, kita perlu membuat fungsi yang akan menentukan elemen pivot berdasarkan array, misalnya memanfaatkan indeks pertama dan/atau indeks terakhir. (Fungsi ini akan bisa diubah-ubah apabila ingin bereksperimen dengan metode pemilihan pivot.)\nint ChoosePivot_idx(int arr[], int low, int high) {\n    int choice_idx = low; // pilih elemen pertama saja lah~\n    return choice_idx;\n}\nBerikut ini, kita akan mencoba menerapkan quicksort versi Tony Hoare, sebelum nantinya mencoba dengan algoritma partisi menurut Lomuto.\nvoid HoarePartition(int arr[], int low, int high) {\n    return;\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#quicksort-versi-lomuto",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#quicksort-versi-lomuto",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Quicksort versi Lomuto",
    "text": "Quicksort versi Lomuto\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "",
    "text": "Kembali ke Struktur Data\nSelamat datang di praktikum Struktur Data!"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#hello-world---komponen-dasar-program-c",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#hello-world---komponen-dasar-program-c",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Hello world! - komponen dasar program C",
    "text": "Hello world! - komponen dasar program C\n\n\nhelloworld.c\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"Hello, world!\");\n    return 0;\n}\n\nProgram di atas melakukan… terdiri dari…\nCoba save di folder… kemudian pencet run (code runner)…\nBeberapa variasi…"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#kompilasi-compilation-dan-eksekusi-execution-atau-running",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#kompilasi-compilation-dan-eksekusi-execution-atau-running",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Kompilasi (compilation) dan eksekusi (execution atau running)",
    "text": "Kompilasi (compilation) dan eksekusi (execution atau running)\nPerhatikan folder di mana kode Anda tersimpan. Apakah ada file baru dengan nama yang sama seperti nama program, tetapi dengan file extension (akhiran) yang berbeda? Sebenarnya, file itulah yang dibuka oleh komputer Anda.\nTidak seperti Python yang bersifat interpreted, bahasa pemrograman C adalah bahasa pemrograman yang bersifat compiled. Artinya, ketika ingin menguji coba program C yang telah kita buat, ada dua tahapan:\n\nKompilasi (compilation), yaitu mengkonversi program C menjadi bahasa mesin (machine language, bahasa yang langsung bisa dipahami oleh prosesor di komputer Anda, yaitu komponen yang gunanya adalah menjalankan program). Proses kompilasi ini menghasilkan file baru.\nEksekusi (execution atau running), yaitu komputer (lebih tepatnya prosesor) langsung menjalankan program yang telah dikompilasi ke dalam bahasa mesin (yaitu file baru tersebut).\n\nSedangkan, pada bahasa pemrograman yang interpreted, ketika komputer menjalankan program, komputer melakukannya per baris; artinya, untuk tiap baris, komputer perlu memahaminya terlebih dahulu, kemudian melakukan perintah pada baris tersebut. Bolak-balik antara memahami dan melakukan perintah itu dilakukan per baris, dan selalu dilakukan tiap kali program dijalankan. Oleh karena itu, program yang dibuat dengan bahasa pemrograman interpreted seperti Python cenderung lebih pelan daripada yang dibuat dengan bahasa pemrograman compiled seperti C.\nProses kompilasi dilakukan oleh compiler. Compiler untuk bahasa pemrograman C yang paling terkenal adalah gcc (GNU Compiler Collection), yang bisa tersambung langsung dengan Visual Studio Code melalui extension seperti “C/C++” dan “Code Runner”. Dengan extension Code Runner, Anda tinggal menekan tombol run (▶) di sekitar ujung kanan atas aplikasi, lalu gcc akan langsung mengkompilasi program Anda.\nProses kompilasi menghasilkan suatu file yang bisa langsung dijalankan oleh komputer Anda. Untuk model dan merek proseor yang berbeda, bisa jadi ada variasi dalam file hasil compile tersebut, tergantung bahasa mesin yang dipahami oleh prosesor. Untungnya, gcc juga bisa mengkompilasi program ke dalam file format seperti .exe (aplikasi Windows), sehingga hanya bergantung sistem operasi (operating system).\nTiap kali Anda ingin menjalankan suatu program C, proses kompilasi selalu harus dilakukan terlebih dahulu sebelum eksekusi, tidak seperti bahasa pemrograman yang interpreted.\nFun fact: biasanya compiler tidak sekedar mengkompilasi, tetapi juga mencoba melakukan optimisasi (optimization), yaitu mempersingkat dan menyederhanakan program, menghemat semua penggunaan memori dan sebagainya agar program menjadi lebih kecil dan lebih cepat dijalankan tetapi tetap melakukan hal yang sama persis."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#output-selain-string-format-specifier",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#output-selain-string-format-specifier",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Output selain string: format specifier",
    "text": "Output selain string: format specifier\nTentu saja, kemampuan C bukan sekedar mengeluarkan output berupa string. Program C juga bisa mengeluarkan output berupa integer (bilangan bulat), dengan syntax (sintaks; cara penulisan) seperti berikut:\n\n\nhelloint.c\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"%d\", 98);\n    return 0;\n}\n\nPada contoh program helloint.c di atas, output yang dikeluarkan adalah suatu bilangan bulat yaitu 98. Adanya tulisan \"%d\" adalah bentuk string formatting, di mana huruf “d” melambangkan tipe data bilangan bulat dalam bentuk desimal (base 10). Artinya, bilangan bulat di sampingnya itu disisipkan ke dalam string, sehingga kita bisa melihat output berupa bilangan bulat tersebut.\nLambang seperti %d disebut format specifier.\nFun fact: huruf “f” dalam istilah printf artinya “formatted”.\nTentu saja, kita dapat menuliskan apapun sebelum dan sesudah format specifier %d tersebut:\n\n\nhelloint2.c\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"Anda memasukkan %d yaitu bilangan bulat\", 98);\n    return 0;\n}\n\nBilangan bulat tersebut akan disisipkan di dalam string, sesuai dengan posisi %d.\nBilangan bulat juga bisa negatif:\n\n\nhelloint3.c\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"Anda memasukkan %d yaitu bilangan bulat\", -5);\n    return 0;\n}\n\nSelain “d” yang berarti bilangan bulat, huruf “f” artinya float, atau floating-point number. Singkat cerita, tipe data float adalah bilangan yang bisa berupa desimal, sehingga tidak terbatas bilangan bulat saja. (Kalau penasaran detilnya dan mengapa namanya demikian, kalian bisa review kembali materi pertemuan pertama kuliah Metode Numerik, tentang floating-point arithmetic.) Kita dapat membuat program seperti berikut:\n\n\nhellofloat.c\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"%f\", 3.14);\n    return 0;\n}\n\ndan kita akan menerima output berupa float yang kita tuliskan, yaitu 3.14. Tentu saja, tipe data float juga bisa negatif:\n\n\nhellofloat2.c\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"%f\", -0.618);\n    return 0;\n}\n\nKita bisa menyisipkan lebih dari satu bilangan:\n\n\nhellonum.c\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"%d %f %f\", 98, -0.618, 3.14);\n    return 0;\n}\n\nPerhatikan bahwa tiap bilangan di dalam string di atas dipisah dengan spasi. Sehingga, pada output, tiap bilangan akan dipisah dengan spasi.\nPerhatikan apa yang terjadi kalau kita memisahkan proses print menjadi satu bilangan saja per printf:\n\n\nhellonum2.c\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"%d\", 98);\n    printf(\"%f\", -0.618);\n    printf(\"%f\", 3.14);\n\n    return 0;\n}\n\n(Catatan: return 0; tidak harus selalu menempel dengan baris-baris sebelumnya. Bahkan, tidak ada baris yang harus saling menempel.)\nTernyata, semua output tetap di baris yang sama. Bahkan, tidak ada spasi yang memisahkan (karena tidak kita tulis). Ada kode khusus untuk membuat baris baru (new line), yaitu \\n. Perhatikan:\n\n\nhellonum3.c\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"%d\\n\", 98);\n    printf(\"%f\\n\", -0.618);\n    printf(\"%f\", 3.14);\n\n    return 0;\n}\n\nTiap kali ada \\n, dikeluarkan “output” berupa baris baru. Sehingga, output selanjutnya akan mulai dari baris baru tersebut. Kalau mau, kita bisa memisahkan pembuatan baris baru, seperti berikut:\n\n\nhellonum4.c\n\n#include &lt;stdio.h&gt;\n\nint main() {\n  printf(\"%d\", 98);\n  printf(\"\\n\");\n  printf(\"%f\", -0.618);\n  printf(\"\\n\");\n  printf(\"%f\", 3.14);\n\n  return 0;\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#escape-sequence-untuk-string",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#escape-sequence-untuk-string",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Escape sequence untuk string",
    "text": "Escape sequence untuk string\n\\n adalah contoh escape sequence, yaitu kode khusus untuk mem-print hal-hal yang tidak bisa kita ketik begitu saja. Contoh lain, bagaimana caranya kita mem-print output \"Hello world\" dengan tanda kutip? Masalahnya, tanda kutip sudah digunakan untuk menandakan awal dan akhir string, sehingga tidak bisa kita ketik begitu saja. Solusinya, kita gunakan escape sequence lain yaitu \\\" seperti berikut.\n\n\nescapequote.c\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"Kita coba print \\\"Hello world!\\\" apakah berhasil?\");\n    return 0;\n}\n\nPerhatikan kalimat berikut.\n\nSejauh ini, kita sudah mempelajari \\n dan \\” yaitu dua contoh escape sequence.\n\nBagaimana caranya kita mem-print keseluruhan kalimat tersebut di C, misalnya tanpa membuat baris baru? Masalanhya ada pada tanda backslash \\ yang memang sudah menjadi ciri khas untuk escape sequence. Kita ingin menampilkan escape sequence tersebut tanpa mengaktifkannya. Solusinya, bahkan tanda backslash itu sendiri bisa “dinonaktifkan” dengan menuliskan \\\\ seperti berikut:\n\n\nescapebackslash.c\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"Sejauh ini, kita sudah mempelajari \\\\n dan \\\\\\\" yaitu dua contoh escape sequence.\");\n    return 0;\n}\n\nPerhatikan bahwa, untuk \\n, hanya diperlukan satu backslash agar bisa ditampilkan. Sedangkan, diperlukan dua backslash untuk menampilkan \\\". Seandainya hanya digunakan satu backslash, yaitu mengetik \\\\\", maka output nya akan menjadi seperti berikut,\n\nSejauh ini, kita sudah mempelajari \\n dan \\\n\nkarena, melihat \\\\\", tanda kutip tersebut dianggap sebagai penutup string. Anggapan tersebut bisa kita nonaktifkan menggunakan backslash juga (yang ditambahkan tepat sebelum tanda kutip tersebut), sehingga kita ketik \\\\\\\".\nAda banyak escape sequence lainnya yang tidak dibahas di sini (bisa dicari di Google)."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#comment",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#comment",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Comment",
    "text": "Comment\nDalam pemrograman, comment adalah semacam catatan yang tidak diperhatikan oleh komputer sama sekali; gunanya hanya untuk memudahkan manusia memahami kode. Pada bahasa pemrograman C, ada dua jenis comment, yaitu:\n\nsingle-line (satu baris), yang diawali dengan // dan bisa dituliskan di mana saja. Penggunaan // pada C sama persis dengan penggunaan # pada Python.\nmulti-line (banyak baris), yang diawali dengan /* dan diakhiri dengan */, dan juga bisa ditempatkan di mana saja. Penggunaan ini bahkan lebih fleksibel daripada \"\"\" di Python.\n\nPerhatikan program berikut.\n\n\nhellocomment.c\n\n#include &lt;stdio.h&gt;\n\n// comment tidak harus di dalam main()\n\nint main() {\n    // ini comment\n    printf(\"Hello world!\\n\");\n    /* ini\n    juga\n    comment */\n\n    /*\n    bisa\n    seperti\n    ini\n    */\n\n    printf(\"%d adalah bilangan bulat.\\n\", 22);\n    printf(/* penyusup */ \"%f\\n\", /* tes */ -273.15);\n}\n\nSesuai kegunaannya, semua comment diabaikan oleh C; kode tetap diijalankan seolah-olah tidak ada comment sama sekali."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#variabel-dan-tipe-data-bilangan",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#variabel-dan-tipe-data-bilangan",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Variabel dan tipe data bilangan",
    "text": "Variabel dan tipe data bilangan\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#operasi-dasar",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#operasi-dasar",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Operasi dasar",
    "text": "Operasi dasar\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#konstanta",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#konstanta",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Konstanta",
    "text": "Konstanta\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#ukuran-data-dengan-sizeof-dan-size_t",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#ukuran-data-dengan-sizeof-dan-size_t",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Ukuran data dengan sizeof dan size_t",
    "text": "Ukuran data dengan sizeof dan size_t\nnitip https://stackoverflow.com/questions/19732319/difference-between-size-t-and-unsigned-int\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#format-specifier-lainnya",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#format-specifier-lainnya",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Format specifier lainnya",
    "text": "Format specifier lainnya\nSebelumnya, kita sudah menggunakan beberapa format specifier seperti %d, %f, dan %lf. Format specifier lainnya bisa dilihat di link berikut:\nhttps://www.tutorialspoint.com/format-specifiers-in-c"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#if-else",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#if-else",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "if, else",
    "text": "if, else\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#tipe-data-boolean",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#tipe-data-boolean",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Tipe data boolean",
    "text": "Tipe data boolean\n\nPengartian data sebagai nilai kebenaran di bahasa pemrograman C\n\n\nData\nDiartikan sebagai\n\n\n\n\n0 (nol), NULL, \\0\nFalse (salah)\n\n\napapun data lainnya\nTrue (benar)\n\n\n\nAda juga istilah falsy value dan truthy value untuk mengkategorikan jenis data yang diartikan sebagai False dan yang diartikan sebagai True. Dalam hal ini, nol, NULL, dan \\0 adalah falsy values, dan semua data lainnya adalah truthy values.\n(Kita akan berjumpa dengan NULL dan \\0 di sesi praktikum yang akan datang.)\nPerlu diingat, klasifikasi antara data yang termasuk falsy values dan yang termasuk truthy values bisa berbeda-beda antara beberapa bahasa pemrograman. Oleh karena itu, ada semacam “standar” untuk data boolean di bahasa pemrgoraman C, di mana didefinisikan variabel false=0 dan true=1. Untuk menggunakan kedua variabel ini, kita perlu #include &lt;stdbool.h&gt;, yang juga akan memperkenalkan tipe data baru, yaitu bool, sebagai tipe data boolean. (Sudah menjadi standar untuk melakukan include tersebut daripada mendefinisikan kedua variabel secara manual.)\n(kode include stdbool)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#switch-case-dan-enum",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#switch-case-dan-enum",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "switch case dan enum",
    "text": "switch case dan enum\nblabla\n(contoh switch case)\nSayangnya, bagian case hanya bisa menggunakan bilangan bulat dan huruf. Untungnya, bahasa pemrograman C memiliki fitur enum (dibaca “inam”) atau enumeration yang bisa digunakan untuk membuat tipe data baru yang sebenarnya merupakan bilangan bulat tetapi bisa dituliskan sebagai semacam variabel. Dengan demikian, kita seolah-olah bisa menggunakan switch case dengan variabel yang tidak terlihat seperti bilangan bulat, atau setidaknya kita bisa mendefinisikan beberapa bilangan bulat sekaligus yang merupakan bilangan bulat untuk digunakan dengan switch case.\nContohnya, kita bisa membuat enum untuk tipe data baru bernama “Hari” seperti berikut.\nenum Hari = {\n    Senin, Selasa, Rabu, Kamis, Jumat, Sabtu, Minggu\n}\nKemudian, enum bisa digunakan dengan switch case, karena Senin, Selasa, Rabu, Kamis, Jumat, Sabtu, dan Minggu sudah menjadi semacam variabel konstanta yang mengandung bilangan bulat yang berbeda-beda (dan berurut).\n\n\nenumhari.c\n\n#include &lt;stdio.h&gt;\n\nenum Hari = {\n    Senin, Selasa, Rabu, Kamis, Jumat, Sabtu, Minggu\n}\n\nint main() {\n    enum Hari sekarang = Rabu;\n\n    switch (sekarang) {\n        case Senin:\n        case Rabu:\n        case Kamis:\n            puts(\"Toko buka\");\n            printf(\"Urutan: %d\\n\", sekarang);\n            break;\n        case Selasa:\n        case Jumat:\n        case Sabtu:\n        case Minggu:\n            puts(\"Toko tutup\");\n            printf(\"Urutan: %d\\n\", sekarang);\n            break;\n        default:\n            puts(\"Hari tidak jelas\");\n            printf(\"Urutan: %d\\n\", sekarang);\n    }\n\n    return 0;\n}\n\nTentu saja, kegunaan enum tidak sebatas switch case. Meskipun cukup jarang dijumpai, enum bisa digunakan dalam kondisi apapun yang mengharuskan penggunaan bilangan bulat. Selain itu, dengan sifat enum yang selalu memasang nilai bilangan bulat secara terurut, enum bisa digunakan ketika ada variabel (atau ingin membuat tipe data baru) yang diharapkan hanya memiliki beberapa kemungkinan nilai (misalnya enum Hari di atas hanya memiliki 7 kemungkinan nilai), apalagi ketika urutan itu penting (walaupun tidak masalah juga menggunakan enum ketika urutan tidak penting).\nBahkan, kalau mau, kita bisa memasang nilai bilangan bulat tertentu untuk beberapa “konstanta” di dalam suatu enum, dan “konstanta” berikutnya akan selalu lebih besar daripada yang sebelumnya.\nenum KategoriUsia {\n    batita, balita=4, anak, remaja=13, dewasa=19, quarterlifecrisis, lansia=60\n};\nKita bisa melihat semua nilai yang dipasang:\n\n\nenumusia.c\n\n#include &lt;stdio.h&gt;\n\nenum KategoriUsia {\n    batita, balita=4, anak, remaja=13, dewasa=19, quarterlifecrisis, lansia=60\n};\n\nint main() {\n    printf(\n        \"%d %d %d %d %d %d %d\",\n        batita, balita, anak, remaja, dewasa, quarterlifecrisis, lansia\n    );\n    // output: 0 4 5 13 19 20 60\n\n    return 0;\n}\n\nKita juga bisa memaksakan agar beberapa “konstanta” memiliki nilai yang sama atau bahkan lebih rendah:\nenum Warna {\n    merah=100, putih=100, ungu=0, hijau, kuning, kelabu=1, biru\n};\nKarena enum merupakan bilangan bulat, kita bahkan bisa membandingkan apakah suatu bilangan bulat (ataupun suatu enum) itu sama dengan, lebih besar dari, atau lebih kecil dari suatu “konstanta” dalam enum.\n\n\nenumwarna.c\n\n#include &lt;stdio.h&gt;\n\nenum Warna {\n    merah=100, putih=100, ungu=0, hijau, kuning, kelabu=1, biru\n};\n\nint main() {\n    printf(\n        \"%d %d %d %d %d %d %d\",\n        merah, putih, ungu, hijau, kuning, kelabu, biru\n    );\n    // output: 100 100 0 1 2 1 \n    \n    if (merah==putih) {\n        puts(\"Merah dan putih setara\");\n    } else {\n        puts(\"Merah dan putih tidak setara\");\n    }\n\n    enum Warna warna_saya = biru;\n    if (warna_saya &lt; hijau) {\n        puts(\"warna_saya &lt; hijau\");\n    } else {\n        puts(\"warna_saya &gt;= hijau\");\n    }\n\n    return 0;\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#while-loop",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#while-loop",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "while loop",
    "text": "while loop\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#for-loop",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#for-loop",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "for loop",
    "text": "for loop\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#do-while-loop",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#do-while-loop",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "do while loop",
    "text": "do while loop\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html",
    "title": "Praktikum Struktur Data 2023 Ganjil dengan C",
    "section": "",
    "text": "Kembali ke Praktikum"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html#part-1-sebelum-uts",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html#part-1-sebelum-uts",
    "title": "Praktikum Struktur Data 2023 Ganjil dengan C",
    "section": "Part 1: Sebelum UTS",
    "text": "Part 1: Sebelum UTS\nPsst… UTS Struktur Data itu “jenis” soalnya sama seperti ujian Alprog: ada beberapa soal pilihan ganda serta satu/dua soal esai berupa menulis pseudocode. Kalau kalian lancar di praktikum, mungkin UTS kalian akan lancar jaya~ aamiin.\n\nModul 0: Instalasi dan konfigurasi software\nModul 1: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika\nModul 2: Array, fungsi, struct, dan proses kompilasi\nModul 3: Operasi array, algoritma searching dan sorting\nModul 4: Pointer, memori, CodeChef, input dan manipulasi string\n\nModul 4a (opsional): ASCII, Unicode, inttypes.h, dan manipulasi text file\nModul 4b (opsional): membuat command-line interface (CLI) dengan argv\n\nModul 5: Linked-list dengan struct dan pointer\n\nModul 5a (opsional): Pengenalan graphviz dan visualisasi berbagai jenis linked-list"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html#part-2-setelah-uts",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html#part-2-setelah-uts",
    "title": "Praktikum Struktur Data 2023 Ganjil dengan C",
    "section": "Part 2: Setelah UTS",
    "text": "Part 2: Setelah UTS\nSemangat terus ya! Setelah mempelajari dasar-dasar bahasa pemrograman C, hingga array dan linked list, kalian akan mempelajari struktur data yang lebih kompleks, yang sebenarnya memanfaatkan konsep array maupun linked list.\n\nModul 6: Stack (tumpukan)\n\nModul 6a (opsional): notasi prefix, infix, dan postfix\n\nModul 7: Queue (antrian)\nModul 8: Binary Tree, Binary Search Tree (BST), dan N-ary Tree\n\nModul 8a (opsional): DFS (depth-first search) dan BFS (breadth-first search) untuk tree\nModul 8b (opsional): Visualisasi sembarang binary tree dengan graphviz\nModul 8c (opsional): Visualisasi sembarang N-ary tree dengan graphviz\n\nModul 9: “Balance Tree” (AVL), Max Heap, Min Heap, dan B-Tree\n\nModul 9a (opsional): Konversi antara bentuk array (BFS) dan bentuk pointer untuk sembarang binary tree, termasuk heap\nModul 9b (opsional): Visualisasi B-Tree dengan graphviz\n\nModul 10: Pengantar database (basis data) dengan SQLite"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html#part-3-pengayaan-python",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html#part-3-pengayaan-python",
    "title": "Praktikum Struktur Data 2023 Ganjil dengan C",
    "section": "Part 3 (pengayaan): Python",
    "text": "Part 3 (pengayaan): Python\nMeskipun semua materi pada bagian ini bersifat pengayaan dan tidak akan dibahas di sesi praktikum, ada baiknya tetap dibaca untuk sekadar menambah wawasan. (Apabila Anda nekat berniat menggunakan bahasa pemrograman Python untuk proyek akhir Struktur Data, semoga materi pengayaan ini membantu.)\n\nModul 11: Struktur data yang khas Python\nModul 12: Pengantar OOP dengan class di Python, pengganti struct di C\nModul 13: I/O dan text file di Python\nModul 14: Visualisasi tree (pohon) dengan graphviz di Python"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul9.html#fashion_mnist-load",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul9.html#fashion_mnist-load",
    "title": "Modul 9 Praktikum Sains Data",
    "section": "Fashion_MNIST load",
    "text": "Fashion_MNIST load\n\nfrom keras.datasets import fashion_mnist\n\n\n(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n\n\nprint(\"X_train_full: \", X_train_full.shape)\nprint(\"y_train_full: \", y_train_full.shape)\nprint(\"X_test: \", X_test.shape)\nprint(\"y_test: \", y_test.shape)\n\nX_train_full:  (60000, 28, 28)\ny_train_full:  (60000,)\nX_test:  (10000, 28, 28)\ny_test:  (10000,)\n\n\n\nclass_mnist = [\"T_shirt/Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n\n\nsample = 0\nimage = X_train_full[sample]\n\n\nplt.imshow(image, cmap = 'binary')\nplt.show()\n\n\n\n\n\n\n\n\n\nprint(f\"kelas untuk gambar indeks ke-{sample}: {class_mnist[y_train_full[sample]]}\")\n\nkelas untuk gambar indeks ke-0: Ankle Boot\n\n\n\nX_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n\ny_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n\n#model yg kemaren, bisa diskip\n\n#model.add(keras.layers.Flatten(input_shape = [28, 28])) #mengubah input menjadi 1D array\n#model.add(keras.layers.Dense(300, activation = 'relu')) #hidden layer 1 dgn 300 neuron dan activation Relu\n#model.add(keras.layers.Dense(100, activation = 'relu')) #hidden layer 2 dgn 100 neuron dan activation Relu\n#model = keras.models.Sequential()\n#model.add(keras.layers.Dense(10, activation = 'softmax')) #hidden layer 1 dgn 300 neuron dan activation Relu"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul9.html#membangun-model",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul9.html#membangun-model",
    "title": "Modul 9 Praktikum Sains Data",
    "section": "Membangun Model",
    "text": "Membangun Model\n\ndef build_model(hp):\n    model = keras.models.Sequential()\n    model.add(keras.layers.Flatten(input_shape = [28, 28])) #input layer\n\n    hp_layers = hp.Choice('layer', [2,3]) #banyak hidden layer 2 atau 3\n    hp_neurons = hp.Int('neuron', min_value = 100, max_value=300, step = 100) #banyak neuron disetiap layer 100, 20\n\n    for layer in range(hp_layers):\n        model.add(keras.layers.Dense(hp_neurons, activation = 'relu')) #hidden layer\n    model.add(keras.layers.Dense(10, activation = 'softmax')) #output layer\n    \n    optimizer = tf.keras.optimizers.Adam()\n    model.compile(loss = 'sparse_categorical_crossentropy', #model compile\n                  optimizer = optimizer,\n                  metrics = ['accuracy'])\n\n    return model\n\n\n#hyperband tuner\ntuner = kt.Hyperband(build_model,\n                     objective = 'val_accuracy',\n                     max_epochs = 10,\n                     directory = 'my_dir',\n                     project_name = 'my_tuner')\n\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n\n\n\n#early stopping\nstop_early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n                                              patience = 5)\n\n\n#proses pencarian hyperparameter terbaik\ntuner.search(X_train, y_train,\n             epochs = 50,\n             validation_data = [X_valid, y_valid],\n             callbacks = [stop_early])\n\nTrial 6 Complete [00h 00m 24s]\nval_accuracy: 0.8704000115394592\n\nBest val_accuracy So Far: 0.8781999945640564\nTotal elapsed time: 00h 02m 02s\n\n\n\nbest_hps = tuner.get_best_hyperparameters()[0]\nprint(\"best number of layers: \", best_hps.get('layer'))\nprint(\"best number of neurons: \", best_hps.get('neuron'))\n\nbest number of layers:  3\nbest number of neurons:  300\n\n\n\n#model terbaik\nmodel = tuner.hypermodel.build(best_hps)\n\n#training dengan model terbaik\nmodel.fit(X_train, y_train, \n          epochs = 10,\n          validation_data = [X_valid, y_valid])\n\nEpoch 1/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 18s 9ms/step - accuracy: 0.7711 - loss: 0.6256 - val_accuracy: 0.8666 - val_loss: 0.3779\nEpoch 2/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 16s 7ms/step - accuracy: 0.8598 - loss: 0.3748 - val_accuracy: 0.8778 - val_loss: 0.3538\nEpoch 3/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 21s 7ms/step - accuracy: 0.8772 - loss: 0.3309 - val_accuracy: 0.8848 - val_loss: 0.3173\nEpoch 4/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 12s 7ms/step - accuracy: 0.8830 - loss: 0.3109 - val_accuracy: 0.8868 - val_loss: 0.3139\nEpoch 5/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 12s 7ms/step - accuracy: 0.8886 - loss: 0.2921 - val_accuracy: 0.8796 - val_loss: 0.3163\nEpoch 6/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 20s 7ms/step - accuracy: 0.8994 - loss: 0.2675 - val_accuracy: 0.8876 - val_loss: 0.3087\nEpoch 7/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 13s 7ms/step - accuracy: 0.9024 - loss: 0.2577 - val_accuracy: 0.8906 - val_loss: 0.3070\nEpoch 8/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 21s 8ms/step - accuracy: 0.9091 - loss: 0.2461 - val_accuracy: 0.8940 - val_loss: 0.3076\nEpoch 9/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 20s 7ms/step - accuracy: 0.9084 - loss: 0.2404 - val_accuracy: 0.8760 - val_loss: 0.3599\nEpoch 10/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 12s 7ms/step - accuracy: 0.9142 - loss: 0.2274 - val_accuracy: 0.8848 - val_loss: 0.3167\n\n\n&lt;keras.src.callbacks.history.History at 0x27418daa690&gt;"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul9.html#memprediksi-dengan-model",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul9.html#memprediksi-dengan-model",
    "title": "Modul 9 Praktikum Sains Data",
    "section": "Memprediksi dengan model",
    "text": "Memprediksi dengan model\n\nmodel.evaluate(X_test, y_test)\n\n313/313 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.8652 - loss: 45.0263\n\n\n[45.98220443725586, 0.8651000261306763]\n\n\n\nX_new = X_test[:4]\ny_proba = model.predict(X_new)\ny_proba\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 136ms/step\n\n\narray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)\n\n\n\ny_p = np.array([np.argmax(i) for i in y_proba]) #mendapatka kelas\nprint(y_p)\nprint(np.array(class_mnist)[y_p])\n\n[9 2 1 1]\n['Ankle Boot' 'Pullover' 'Trouser' 'Trouser']"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul7.html",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul7.html",
    "title": "Modul 7 Praktikum Sains Data",
    "section": "",
    "text": "Pendahuluan Artificial Neural Network dan Deep learning : - Forward Propagation - Activation Function"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul7.html#outline",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul7.html#outline",
    "title": "Modul 7 Praktikum Sains Data",
    "section": "",
    "text": "Pendahuluan Artificial Neural Network dan Deep learning : - Forward Propagation - Activation Function"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul7.html#forward-propagation",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul7.html#forward-propagation",
    "title": "Modul 7 Praktikum Sains Data",
    "section": "Forward Propagation",
    "text": "Forward Propagation\n\nGambar diatas adalah contoh Artificial Neural Network sederhana dengan metode Forward Propagation. Sesuai namanya, metode tersebut memiliki alur maju dalam menghitung dan menyimpan variabel pada neural network. Yaitu dari input, hidden layer, hingga ke output.\nPada praktikum kali ini kita akan membahas konsep dasar dari Deep Learning.\n\n#import modul\nimport numpy as np\n\n\n#implementasi forward propagation untuk artificial neural network (ann) pada gambar di atas\n\n#input data dalam bentuk array\ninput_data = ([2, 3])\n#masukkan weights pada masing masing node\nweights = {'node_0': np.array([1,1]), 'node_1': np.array([-1,1]), 'output':np.array([2,-1])}\n#lakukan \"dot product\" pada weights dan input\nnode_0_val = (input_data*weights['node_0']).sum()\nnode_1_val = (input_data*weights['node_1']).sum()\n\n\n#menentukan nilai node pada hidden layer\nhidden_layer_values = np.array([node_0_val,node_1_val])\nprint(hidden_layer_values)\n\n[5 1]\n\n\n\n#output\noutput = (hidden_layer_values*weights['output']).sum()\nprint(output)\n\n9"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul7.html#activation-function",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul7.html#activation-function",
    "title": "Modul 7 Praktikum Sains Data",
    "section": "Activation Function",
    "text": "Activation Function\n\nTanh\n\n#contoh penggunaan activation function, tanh\ninput_data2 = np.array([-1,2])\nweights2 = {'node_0':np.array([3,3]),'node_1':np.array([1,5]),'output':np.array([2,-1])}\nnode_0_input = (input_data2*weights2['node_0']).sum()\nnode_0_output = np.tanh(node_0_input)\n\nnode_1_input = (input_data2*weights2['node_1']).sum()\nnode_1_output = np.tanh(node_1_input)\n\nhidden_layer_outputs = np.array([node_0_output,node_1_output])\nprint(hidden_layer_outputs)\n\n[0.99505475 0.99999997]\n\n\n\noutput = (hidden_layer_outputs * weights2['output']).sum()\nprint(output)\n\n0.99010953783342\n\n\n\n\nReLu\n\n#definisikan activation fuction ReLu\ndef relu (input):\n output = max(input,0)\n return output\n\n#contoh penggunaan activation function, relu\ninput_data2 = np.array([-1,2])\nweights2 = {'node_0':np.array([3,3]),'node_1':np.array([1,5]),'output':np.array([2,-1])}\nnode_0_input = (input_data2*weights2['node_0']).sum()\nnode_0_output_relu = relu(node_0_input)\n\nnode_1_input = (input_data2*weights2['node_1']).sum()\nnode_1_output_relu = relu(node_1_input)\n\nhidden_layer_outputs_relu = np.array([node_0_output_relu,node_1_output_relu])\noutput_relu = (hidden_layer_outputs_relu * weights2['output']).sum()\nprint(hidden_layer_outputs_relu)\nprint(output_relu)\n\n[3 9]\n-3\n\n\n\n#contoh dengan beberapa input, dapat menggunakan loop\ninput_data3 = [np.array([3,5]),np.array([1,-1]),np.array([8,4])]\nweights3 = {'node_0': np.array([2,4]), 'node_1':np.array([4,-5]), 'output':np.array([2,7])}\n\n\ndef network_pred(input_data_row,weights3):\n node_0_input = (input_data_row*weights3['node_0']).sum()\n node_0_output = relu(node_0_input)\n \n node_1_input = (input_data_row*weights3['node_1']).sum()\n node_1_output = relu(node_0_input)\n \n hidden_layer_outputs = np.array([node_0_output,node_1_output])\n \n input_output = (hidden_layer_outputs*weights['output']).sum()\n model_output = relu(input_output)\n \n return (model_output)\n\nresults = []\nfor input_data_row in input_data3:\n results.append(network_pred(input_data_row,weights3))\n \nprint(results)\n\n[26, 0, 32]"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#data",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#data",
    "title": "Modul 5 Praktikum Sains Data",
    "section": "Data",
    "text": "Data\nPada module kali ini, akan digunakan data csv teleCust1000t (teleCust1000t.csv) yang bisa didownload dari: - Kaggle\n\n #membaca dataset\ndf = pd.read_csv('./teleCust1000t.csv')\ndf.head()\n\n\n\n\n\n\n\n\nregion\ntenure\nage\nmarital\naddress\nincome\ned\nemploy\nretire\ngender\nreside\ncustcat\n\n\n\n\n0\n2\n13\n44\n1\n9\n64.0\n4\n5\n0.0\n0\n2\n1\n\n\n1\n3\n11\n33\n1\n7\n136.0\n5\n5\n0.0\n0\n6\n4\n\n\n2\n3\n68\n52\n1\n24\n116.0\n1\n29\n0.0\n1\n2\n3\n\n\n3\n2\n33\n33\n0\n12\n33.0\n2\n0\n0.0\n1\n1\n1\n\n\n4\n2\n23\n30\n1\n9\n30.0\n1\n2\n0.0\n0\n4\n3\n\n\n\n\n\n\n\n\n#menghitung jumlah anggota tiap kelas\ndf['custcat'].value_counts()\n\ncustcat\n3    281\n1    266\n4    236\n2    217\nName: count, dtype: int64\n\n\n\n #melihat sebaran income dengan histogram\ndf.hist(column='income')\n\narray([[&lt;Axes: title={'center': 'income'}&gt;]], dtype=object)\n\n\n\n\n\n\n\n\n\n\n#melihat 4 row pertama\nX = df[['region', 'tenure', 'age', 'marital', 'address', 'income', 'ed', 'employ', 'retire','gender', 'reside']].values\nX[0:4]\n\narray([[  2.,  13.,  44.,   1.,   9.,  64.,   4.,   5.,   0.,   0.,   2.],\n       [  3.,  11.,  33.,   1.,   7., 136.,   5.,   5.,   0.,   0.,   6.],\n       [  3.,  68.,  52.,   1.,  24., 116.,   1.,  29.,   0.,   1.,   2.],\n       [  2.,  33.,  33.,   0.,  12.,  33.,   2.,   0.,   0.,   1.,   1.]])\n\n\n\n#melihat kelas dari 4 row pertama\nY = df[['custcat']].values\nY[0:4]\n\narray([[1],\n       [4],\n       [3],\n       [1]], dtype=int64)"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#preprocessing",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#preprocessing",
    "title": "Modul 5 Praktikum Sains Data",
    "section": "Preprocessing",
    "text": "Preprocessing\n\nfrom sklearn import preprocessing\n\n\n#normalize data\nX = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\nX[0:4]\n\narray([[-0.02696767, -1.055125  ,  0.18450456,  1.0100505 , -0.25303431,\n        -0.12650641,  1.0877526 , -0.5941226 , -0.22207644, -1.03459817,\n        -0.23065004],\n       [ 1.19883553, -1.14880563, -0.69181243,  1.0100505 , -0.4514148 ,\n         0.54644972,  1.9062271 , -0.5941226 , -0.22207644, -1.03459817,\n         2.55666158],\n       [ 1.19883553,  1.52109247,  0.82182601,  1.0100505 ,  1.23481934,\n         0.35951747, -1.36767088,  1.78752803, -0.22207644,  0.96655883,\n        -0.23065004],\n       [-0.02696767, -0.11831864, -0.69181243, -0.9900495 ,  0.04453642,\n        -0.41625141, -0.54919639, -1.09029981, -0.22207644,  0.96655883,\n        -0.92747794]])"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#train-test-split",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#train-test-split",
    "title": "Modul 5 Praktikum Sains Data",
    "section": "Train test split",
    "text": "Train test split\n\n#train test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 4)\n\n\nprint(X_train.shape)\nprint(Y_train.shape)\nprint(X_test.shape)\nprint(Y_test.shape)\n\n(800, 11)\n(800, 1)\n(200, 11)\n(200, 1)"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#membuat-model",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#membuat-model",
    "title": "Modul 5 Praktikum Sains Data",
    "section": "Membuat model",
    "text": "Membuat model\n\n#membuat model dengan k = 4\nfrom sklearn.neighbors import KNeighborsClassifier\nk = 4\nneighbor = KNeighborsClassifier(n_neighbors = k).fit(X_train, Y_train)\n\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#prediksi",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#prediksi",
    "title": "Modul 5 Praktikum Sains Data",
    "section": "Prediksi",
    "text": "Prediksi\n\n#hasil prediksi\nypredict = neighbor.predict(X_test)\nypredict[0:5]\n\narray([1, 1, 3, 2, 4], dtype=int64)\n\n\n\n#kelas sebenarnya\nY_test[0:5]\n\narray([[4],\n       [1],\n       [1],\n       [2],\n       [4]], dtype=int64)"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#evaluasi-model",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#evaluasi-model",
    "title": "Modul 5 Praktikum Sains Data",
    "section": "Evaluasi Model",
    "text": "Evaluasi Model\n\n#menghitung akurasi\nfrom sklearn import metrics\nmetrics.accuracy_score(Y_test,ypredict)\n\n0.32"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#membuat-model-dengan-k-lainnya",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#membuat-model-dengan-k-lainnya",
    "title": "Modul 5 Praktikum Sains Data",
    "section": "Membuat model dengan k lainnya",
    "text": "Membuat model dengan k lainnya\n\n#membuat model dengan k = 6\nk = 6\nneighbor_6 = KNeighborsClassifier(n_neighbors = k).fit(X_train, Y_train)\n\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\n\n\n\n#hasil prediksi\nypredict6 = neighbor_6.predict(X_test)\nypredict6[0:5]\n\narray([3, 3, 3, 4, 4], dtype=int64)\n\n\n\n#kelas sebenarnya\nY_test[0:5]\n\narray([[4],\n       [1],\n       [1],\n       [2],\n       [4]], dtype=int64)\n\n\n\n#akurasi\nmetrics.accuracy_score(Y_test,ypredict6)\n\n0.31"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#mencari-k-terbaik",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul5.html#mencari-k-terbaik",
    "title": "Modul 5 Praktikum Sains Data",
    "section": "Mencari k terbaik",
    "text": "Mencari k terbaik\nKinerja model K-NN sangat bergantung pada jumlah k yang dipilih. Kita dapat menentukan k terbaik dengan menggunakan loop.\n\n#mencari k terbaik diantara 1&lt;=k&lt;=10\nnk = 10\n\nmean_acc= np.zeros((nk))\nstd_acc = np.zeros((nk))\n\nfor n in range(1,nk+1):\n neighbor_k = KNeighborsClassifier(n_neighbors= n).fit(X_train,Y_train)\n ypredict = neighbor_k.predict(X_test)\n mean_acc[n-1] = metrics.accuracy_score(Y_test, ypredict)\n std_acc[n-1]= np.std(ypredict==Y_test)/np.sqrt(ypredict.shape[0])\n\nmean_acc\n\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\n\n\narray([0.3  , 0.29 , 0.315, 0.32 , 0.315, 0.31 , 0.335, 0.325, 0.34 ,\n       0.33 ])\n\n\n\n#plot akurasi dari beberapa k\nplt.plot(range(1,nk+1),mean_acc,'g')\nplt.fill_between(range(1,nk+1),mean_acc-1*std_acc,mean_acc+1*std_acc,alpha = 0.10)\nplt.fill_between(range(1,nk+1),mean_acc-3*std_acc,mean_acc+3*std_acc,alpha = 0.10, color = \"red\")\nplt.legend(('Accuracy', '+-1xstd', '+-3xstd'))\nplt.ylabel('Accuracy')\nplt.xlabel('Jumlah neighbor')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#k terbaik beserta hasilnya\nprint(\"akurasi terbaik model adalah\", mean_acc.max(), \"dengan jumlah k=\", mean_acc.argmax()+1)\n\nakurasi terbaik model adalah 0.34 dengan jumlah k= 9"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul3.html",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul3.html",
    "title": "MODUL 3 PRAKTIKUM SAINS DATA",
    "section": "",
    "text": "Regresi Logistik\n\n\n\n\nPada modul sebelumnya regresi linear memprediksi suatu nilai yang bersifat numerik (kontinu, masalah regresi).\nRegresi Logistik menggunakan konsep regresi untuk memprediksi suatu nilai yang bersifat kategorik (diskrit, masalah klasifikasi).\nRegresi Logistik memberikan output berupa probabilitas suatu item termasuk kelas tertentu, menggunakan fungsi sigmoid sebagai berikut: \\[ h_\\theta (x) = \\sigma(\\theta^T X) = \\frac {e^{(\\theta _0 + \\theta _1 x_1 + \\theta _2 x_2 + ...)}} {1 + e^{(\\theta _0 + \\theta _1 x_1 + \\theta _2 x_2 + ...)}}\\]\nProbabilitas suatu kelas = \\(P(Y = 1|X) = \\sigma(\\theta^T X)= \\frac {e^{\\theta^T X}}{1 + e^{\\theta^T X}}\\)\n\nSuatu item akan diklasifikasikan berdasarkan probabilitas tertinggi yang diperoleh antara dua kelas.\nTujuan dari algoritma Regresi Logistik adalah untuk mencari terbaik sehingga model membuat prediksi yang cukup tepat dari kelas kelasyang ada.\n\n#jika belum ada, insall dulu package scikit learn\n!pip install scikit-learn\n\nRequirement already satisfied: scikit-learn in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.1.post1)\nRequirement already satisfied: numpy&lt;2.0,&gt;=1.19.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy&gt;=1.6.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.12.0)\nRequirement already satisfied: joblib&gt;=1.2.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.3.2)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.3.0)\n\n\n\n[notice] A new release of pip is available: 23.2.1 -&gt; 24.0\n[notice] To update, run: python.exe -m pip install --upgrade pip\n\n\n\n\n\n#import modul modul yang diperlukan\nimport pandas as pd\nimport pylab as pl\nimport numpy as np\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\n\n\nPada module kali ini, akan digunakan data csv Churn Data (ChurnData.csv) yang bisa didownload dari:\n\nGoogle Drive\n\n\n#memuat data frame dari Churn_data.csv\nchurn_df = pd.read_csv(\".\\ChurnData.csv\")\nchurn_df.head()\n\n&lt;&gt;:2: SyntaxWarning: invalid escape sequence '\\C'\n&lt;&gt;:2: SyntaxWarning: invalid escape sequence '\\C'\nC:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_12160\\3974188785.py:2: SyntaxWarning: invalid escape sequence '\\C'\n  churn_df = pd.read_csv(\".\\ChurnData.csv\")\n\n\n\n\n\n\n\n\n\ntenure\nage\naddress\nincome\ned\nemploy\nequip\ncallcard\nwireless\nlongmon\n...\npager\ninternet\ncallwait\nconfer\nebill\nloglong\nlogtoll\nlninc\ncustcat\nchurn\n\n\n\n\n0\n11.0\n33.0\n7.0\n136.0\n5.0\n5.0\n0.0\n1.0\n1.0\n4.40\n...\n1.0\n0.0\n1.0\n1.0\n0.0\n1.482\n3.033\n4.913\n4.0\n1.0\n\n\n1\n33.0\n33.0\n12.0\n33.0\n2.0\n0.0\n0.0\n0.0\n0.0\n9.45\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n2.246\n3.240\n3.497\n1.0\n1.0\n\n\n2\n23.0\n30.0\n9.0\n30.0\n1.0\n2.0\n0.0\n0.0\n0.0\n6.30\n...\n0.0\n0.0\n0.0\n1.0\n0.0\n1.841\n3.240\n3.401\n3.0\n0.0\n\n\n3\n38.0\n35.0\n5.0\n76.0\n2.0\n10.0\n1.0\n1.0\n1.0\n6.05\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n1.800\n3.807\n4.331\n4.0\n0.0\n\n\n4\n7.0\n35.0\n14.0\n80.0\n2.0\n15.0\n0.0\n1.0\n0.0\n7.10\n...\n0.0\n0.0\n1.0\n1.0\n0.0\n1.960\n3.091\n4.382\n3.0\n0.0\n\n\n\n\n5 rows × 28 columns\n\n\n\n\n\n\n\n#ambil beberapa feature/kolom yang diduga berpengaruh terhadap churn\nchurn_df = churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip', 'callcard', 'wireless','churn']]\nchurn_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 200 entries, 0 to 199\nData columns (total 10 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   tenure    200 non-null    float64\n 1   age       200 non-null    float64\n 2   address   200 non-null    float64\n 3   income    200 non-null    float64\n 4   ed        200 non-null    float64\n 5   employ    200 non-null    float64\n 6   equip     200 non-null    float64\n 7   callcard  200 non-null    float64\n 8   wireless  200 non-null    float64\n 9   churn     200 non-null    float64\ndtypes: float64(10)\nmemory usage: 15.8 KB\n\n\n\n#ubah tipe value pada target (kolom churn) dari df tersebut menjadi integer\nchurn_df['churn'] = churn_df['churn'].astype('int')\nchurn_df.head()\nchurn_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 200 entries, 0 to 199\nData columns (total 10 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   tenure    200 non-null    float64\n 1   age       200 non-null    float64\n 2   address   200 non-null    float64\n 3   income    200 non-null    float64\n 4   ed        200 non-null    float64\n 5   employ    200 non-null    float64\n 6   equip     200 non-null    float64\n 7   callcard  200 non-null    float64\n 8   wireless  200 non-null    float64\n 9   churn     200 non-null    int32  \ndtypes: float64(9), int32(1)\nmemory usage: 15.0 KB\n\n\n\nchurn_df.shape\n\n(200, 10)\n\n\n\n#ubah value dari feature/kolom data frame menjadi array 2D untuk selanjutnya kita olah, set sebagai x\nX = np.asarray(churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\nX[0:5]\n\narray([[ 11.,  33.,   7., 136.,   5.,   5.,   0.],\n       [ 33.,  33.,  12.,  33.,   2.,   0.,   0.],\n       [ 23.,  30.,   9.,  30.,   1.,   2.,   0.],\n       [ 38.,  35.,   5.,  76.,   2.,  10.,   1.],\n       [  7.,  35.,  14.,  80.,   2.,  15.,   0.]])\n\n\n\n#ubah value dari feature/kolom data frame menjadi array 2D untuk selanjutnya kita olah, set sebagai Y\nY = np.asarray(churn_df['churn'])\nY[0:5]\n\narray([1, 1, 0, 0, 0])\n\n\n\n#import preprocessing\nfrom sklearn import preprocessing\nX = preprocessing.StandardScaler().fit(X).transform(X) #normalisasi data\nX[0:5]\n\narray([[-1.13518441, -0.62595491, -0.4588971 ,  0.4751423 ,  1.6961288 ,\n        -0.58477841, -0.85972695],\n       [-0.11604313, -0.62595491,  0.03454064, -0.32886061, -0.6433592 ,\n        -1.14437497, -0.85972695],\n       [-0.57928917, -0.85594447, -0.261522  , -0.35227817, -1.42318853,\n        -0.92053635, -0.85972695],\n       [ 0.11557989, -0.47262854, -0.65627219,  0.00679109, -0.6433592 ,\n        -0.02518185,  1.16316   ],\n       [-1.32048283, -0.47262854,  0.23191574,  0.03801451, -0.6433592 ,\n         0.53441472, -0.85972695]])\n\n\n\n\n\n\n#pisah data menjadi data latih dan data uji dengan perbandingan 8:2\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 4)\nprint('Train set: ', X_train.shape, Y_train.shape)\nprint('Test set: ', X_test.shape, Y_test.shape)\n\nTrain set:  (160, 7) (160,)\nTest set:  (40, 7) (40,)\n\n\n\n\n\n\n#membuat model, gunakan LogisticRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\n#buat model regresi logistik, beri nama LR\n#ada beberapa macam solver, contoh : newton-cg,lbfgs,liblinear,sag,saga\nLR = LogisticRegression(C = 0.01, solver='liblinear').fit(X_train, Y_train)\nLR\n\nLogisticRegression(C=0.01, solver='liblinear')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LogisticRegression?Documentation for LogisticRegressioniFittedLogisticRegression(C=0.01, solver='liblinear') \n\n\n\n\n\n\n#prediksikan nilai y berdasarkan x pada data uji\nyhat = LR.predict(X_test)\n#hasil prediksi\nyhat\n\narray([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])\n\n\n\n#memprediksi probabilitas dari entri data frame (per baris)\nyhat_prob = LR.predict_proba(X_test)\nyhat_prob #sebelah kiri terhadap kelas 0, kanan terhadap kelas 1\n\narray([[0.54132919, 0.45867081],\n       [0.60593357, 0.39406643],\n       [0.56277713, 0.43722287],\n       [0.63432489, 0.36567511],\n       [0.56431839, 0.43568161],\n       [0.55386646, 0.44613354],\n       [0.52237207, 0.47762793],\n       [0.60514349, 0.39485651],\n       [0.41069572, 0.58930428],\n       [0.6333873 , 0.3666127 ],\n       [0.58068791, 0.41931209],\n       [0.62768628, 0.37231372],\n       [0.47559883, 0.52440117],\n       [0.4267593 , 0.5732407 ],\n       [0.66172417, 0.33827583],\n       [0.55092315, 0.44907685],\n       [0.51749946, 0.48250054],\n       [0.485743  , 0.514257  ],\n       [0.49011451, 0.50988549],\n       [0.52423349, 0.47576651],\n       [0.61619519, 0.38380481],\n       [0.52696302, 0.47303698],\n       [0.63957168, 0.36042832],\n       [0.52205164, 0.47794836],\n       [0.50572852, 0.49427148],\n       [0.70706202, 0.29293798],\n       [0.55266286, 0.44733714],\n       [0.52271594, 0.47728406],\n       [0.51638863, 0.48361137],\n       [0.71331391, 0.28668609],\n       [0.67862111, 0.32137889],\n       [0.50896403, 0.49103597],\n       [0.42348082, 0.57651918],\n       [0.71495838, 0.28504162],\n       [0.59711064, 0.40288936],\n       [0.63808839, 0.36191161],\n       [0.39957895, 0.60042105],\n       [0.52127638, 0.47872362],\n       [0.65975464, 0.34024536],\n       [0.5114172 , 0.4885828 ]])\n\n\n\n\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\n# code untuk membuat visualiasi confusion matrix\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n  \"\"\"\n  This function prints and plots the confusion matrix.\n  Normalization can be applied by setting `normalize=True`.\n  \"\"\"\n  if normalize:\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    print(\"Normalized confusion matrix\")\n  else:\n    print('Confusion matrix, without normalization')\n\n  print(cm)\n\n  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n  plt.title(title)\n  plt.colorbar()\n  tick_marks = np.arange(len(classes))\n  plt.xticks(tick_marks, classes, rotation=45)\n  plt.yticks(tick_marks, classes)\n\n  fmt = '.2f' if normalize else 'd'\n  thresh = cm.max() / 2.\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, format(cm[i, j], fmt),\n             horizontalalignment=\"center\",\n             color=\"white\" if cm[i, j] &gt; thresh else \"black\")\n  \n  plt.tight_layout()\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label')\n\n  print(confusion_matrix(Y_test, yhat, labels=[1,0]))\n\n\n#confusion matrix\ncnf = confusion_matrix(Y_test, yhat, labels=[1,0])\nplt.figure()\nplot_confusion_matrix(cnf,classes=['churn =1', 'churn=0'],normalize = False, title='Confusion matrix')\n\nConfusion matrix, without normalization\n[[ 6  9]\n [ 1 24]]\n[[ 6  9]\n [ 1 24]]\n\n\n\n\n\n\n\n\n\n\nprint (classification_report(Y_test, yhat))\n# Precission = TP/(TP+FP)\n# recall = TP/(TP+FN)\n\n              precision    recall  f1-score   support\n\n           0       0.73      0.96      0.83        25\n           1       0.86      0.40      0.55        15\n\n    accuracy                           0.75        40\n   macro avg       0.79      0.68      0.69        40\nweighted avg       0.78      0.75      0.72        40\n\n\n\n\n#log loss\nfrom sklearn.metrics import log_loss\nlog_loss(Y_test,yhat_prob)\n\n0.6017092478101185\n\n\n\n#jaccard score\nfrom sklearn.metrics import jaccard_score\njaccard_score(Y_test, yhat,pos_label=0)\n\n0.7058823529411765"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul3.html#regresi-logistik",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul3.html#regresi-logistik",
    "title": "MODUL 3 PRAKTIKUM SAINS DATA",
    "section": "",
    "text": "Pada modul sebelumnya regresi linear memprediksi suatu nilai yang bersifat numerik (kontinu, masalah regresi).\nRegresi Logistik menggunakan konsep regresi untuk memprediksi suatu nilai yang bersifat kategorik (diskrit, masalah klasifikasi).\nRegresi Logistik memberikan output berupa probabilitas suatu item termasuk kelas tertentu, menggunakan fungsi sigmoid sebagai berikut: \\[ h_\\theta (x) = \\sigma(\\theta^T X) = \\frac {e^{(\\theta _0 + \\theta _1 x_1 + \\theta _2 x_2 + ...)}} {1 + e^{(\\theta _0 + \\theta _1 x_1 + \\theta _2 x_2 + ...)}}\\]\nProbabilitas suatu kelas = \\(P(Y = 1|X) = \\sigma(\\theta^T X)= \\frac {e^{\\theta^T X}}{1 + e^{\\theta^T X}}\\)\n\nSuatu item akan diklasifikasikan berdasarkan probabilitas tertinggi yang diperoleh antara dua kelas.\nTujuan dari algoritma Regresi Logistik adalah untuk mencari terbaik sehingga model membuat prediksi yang cukup tepat dari kelas kelasyang ada.\n\n#jika belum ada, insall dulu package scikit learn\n!pip install scikit-learn\n\nRequirement already satisfied: scikit-learn in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.1.post1)\nRequirement already satisfied: numpy&lt;2.0,&gt;=1.19.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy&gt;=1.6.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.12.0)\nRequirement already satisfied: joblib&gt;=1.2.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.3.2)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.3.0)\n\n\n\n[notice] A new release of pip is available: 23.2.1 -&gt; 24.0\n[notice] To update, run: python.exe -m pip install --upgrade pip\n\n\n\n\n\n#import modul modul yang diperlukan\nimport pandas as pd\nimport pylab as pl\nimport numpy as np\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\n\n\nPada module kali ini, akan digunakan data csv Churn Data (ChurnData.csv) yang bisa didownload dari:\n\nGoogle Drive\n\n\n#memuat data frame dari Churn_data.csv\nchurn_df = pd.read_csv(\".\\ChurnData.csv\")\nchurn_df.head()\n\n&lt;&gt;:2: SyntaxWarning: invalid escape sequence '\\C'\n&lt;&gt;:2: SyntaxWarning: invalid escape sequence '\\C'\nC:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_12160\\3974188785.py:2: SyntaxWarning: invalid escape sequence '\\C'\n  churn_df = pd.read_csv(\".\\ChurnData.csv\")\n\n\n\n\n\n\n\n\n\ntenure\nage\naddress\nincome\ned\nemploy\nequip\ncallcard\nwireless\nlongmon\n...\npager\ninternet\ncallwait\nconfer\nebill\nloglong\nlogtoll\nlninc\ncustcat\nchurn\n\n\n\n\n0\n11.0\n33.0\n7.0\n136.0\n5.0\n5.0\n0.0\n1.0\n1.0\n4.40\n...\n1.0\n0.0\n1.0\n1.0\n0.0\n1.482\n3.033\n4.913\n4.0\n1.0\n\n\n1\n33.0\n33.0\n12.0\n33.0\n2.0\n0.0\n0.0\n0.0\n0.0\n9.45\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n2.246\n3.240\n3.497\n1.0\n1.0\n\n\n2\n23.0\n30.0\n9.0\n30.0\n1.0\n2.0\n0.0\n0.0\n0.0\n6.30\n...\n0.0\n0.0\n0.0\n1.0\n0.0\n1.841\n3.240\n3.401\n3.0\n0.0\n\n\n3\n38.0\n35.0\n5.0\n76.0\n2.0\n10.0\n1.0\n1.0\n1.0\n6.05\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n1.800\n3.807\n4.331\n4.0\n0.0\n\n\n4\n7.0\n35.0\n14.0\n80.0\n2.0\n15.0\n0.0\n1.0\n0.0\n7.10\n...\n0.0\n0.0\n1.0\n1.0\n0.0\n1.960\n3.091\n4.382\n3.0\n0.0\n\n\n\n\n5 rows × 28 columns\n\n\n\n\n\n\n\n#ambil beberapa feature/kolom yang diduga berpengaruh terhadap churn\nchurn_df = churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip', 'callcard', 'wireless','churn']]\nchurn_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 200 entries, 0 to 199\nData columns (total 10 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   tenure    200 non-null    float64\n 1   age       200 non-null    float64\n 2   address   200 non-null    float64\n 3   income    200 non-null    float64\n 4   ed        200 non-null    float64\n 5   employ    200 non-null    float64\n 6   equip     200 non-null    float64\n 7   callcard  200 non-null    float64\n 8   wireless  200 non-null    float64\n 9   churn     200 non-null    float64\ndtypes: float64(10)\nmemory usage: 15.8 KB\n\n\n\n#ubah tipe value pada target (kolom churn) dari df tersebut menjadi integer\nchurn_df['churn'] = churn_df['churn'].astype('int')\nchurn_df.head()\nchurn_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 200 entries, 0 to 199\nData columns (total 10 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   tenure    200 non-null    float64\n 1   age       200 non-null    float64\n 2   address   200 non-null    float64\n 3   income    200 non-null    float64\n 4   ed        200 non-null    float64\n 5   employ    200 non-null    float64\n 6   equip     200 non-null    float64\n 7   callcard  200 non-null    float64\n 8   wireless  200 non-null    float64\n 9   churn     200 non-null    int32  \ndtypes: float64(9), int32(1)\nmemory usage: 15.0 KB\n\n\n\nchurn_df.shape\n\n(200, 10)\n\n\n\n#ubah value dari feature/kolom data frame menjadi array 2D untuk selanjutnya kita olah, set sebagai x\nX = np.asarray(churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\nX[0:5]\n\narray([[ 11.,  33.,   7., 136.,   5.,   5.,   0.],\n       [ 33.,  33.,  12.,  33.,   2.,   0.,   0.],\n       [ 23.,  30.,   9.,  30.,   1.,   2.,   0.],\n       [ 38.,  35.,   5.,  76.,   2.,  10.,   1.],\n       [  7.,  35.,  14.,  80.,   2.,  15.,   0.]])\n\n\n\n#ubah value dari feature/kolom data frame menjadi array 2D untuk selanjutnya kita olah, set sebagai Y\nY = np.asarray(churn_df['churn'])\nY[0:5]\n\narray([1, 1, 0, 0, 0])\n\n\n\n#import preprocessing\nfrom sklearn import preprocessing\nX = preprocessing.StandardScaler().fit(X).transform(X) #normalisasi data\nX[0:5]\n\narray([[-1.13518441, -0.62595491, -0.4588971 ,  0.4751423 ,  1.6961288 ,\n        -0.58477841, -0.85972695],\n       [-0.11604313, -0.62595491,  0.03454064, -0.32886061, -0.6433592 ,\n        -1.14437497, -0.85972695],\n       [-0.57928917, -0.85594447, -0.261522  , -0.35227817, -1.42318853,\n        -0.92053635, -0.85972695],\n       [ 0.11557989, -0.47262854, -0.65627219,  0.00679109, -0.6433592 ,\n        -0.02518185,  1.16316   ],\n       [-1.32048283, -0.47262854,  0.23191574,  0.03801451, -0.6433592 ,\n         0.53441472, -0.85972695]])\n\n\n\n\n\n\n#pisah data menjadi data latih dan data uji dengan perbandingan 8:2\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 4)\nprint('Train set: ', X_train.shape, Y_train.shape)\nprint('Test set: ', X_test.shape, Y_test.shape)\n\nTrain set:  (160, 7) (160,)\nTest set:  (40, 7) (40,)\n\n\n\n\n\n\n#membuat model, gunakan LogisticRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\n#buat model regresi logistik, beri nama LR\n#ada beberapa macam solver, contoh : newton-cg,lbfgs,liblinear,sag,saga\nLR = LogisticRegression(C = 0.01, solver='liblinear').fit(X_train, Y_train)\nLR\n\nLogisticRegression(C=0.01, solver='liblinear')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LogisticRegression?Documentation for LogisticRegressioniFittedLogisticRegression(C=0.01, solver='liblinear') \n\n\n\n\n\n\n#prediksikan nilai y berdasarkan x pada data uji\nyhat = LR.predict(X_test)\n#hasil prediksi\nyhat\n\narray([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])\n\n\n\n#memprediksi probabilitas dari entri data frame (per baris)\nyhat_prob = LR.predict_proba(X_test)\nyhat_prob #sebelah kiri terhadap kelas 0, kanan terhadap kelas 1\n\narray([[0.54132919, 0.45867081],\n       [0.60593357, 0.39406643],\n       [0.56277713, 0.43722287],\n       [0.63432489, 0.36567511],\n       [0.56431839, 0.43568161],\n       [0.55386646, 0.44613354],\n       [0.52237207, 0.47762793],\n       [0.60514349, 0.39485651],\n       [0.41069572, 0.58930428],\n       [0.6333873 , 0.3666127 ],\n       [0.58068791, 0.41931209],\n       [0.62768628, 0.37231372],\n       [0.47559883, 0.52440117],\n       [0.4267593 , 0.5732407 ],\n       [0.66172417, 0.33827583],\n       [0.55092315, 0.44907685],\n       [0.51749946, 0.48250054],\n       [0.485743  , 0.514257  ],\n       [0.49011451, 0.50988549],\n       [0.52423349, 0.47576651],\n       [0.61619519, 0.38380481],\n       [0.52696302, 0.47303698],\n       [0.63957168, 0.36042832],\n       [0.52205164, 0.47794836],\n       [0.50572852, 0.49427148],\n       [0.70706202, 0.29293798],\n       [0.55266286, 0.44733714],\n       [0.52271594, 0.47728406],\n       [0.51638863, 0.48361137],\n       [0.71331391, 0.28668609],\n       [0.67862111, 0.32137889],\n       [0.50896403, 0.49103597],\n       [0.42348082, 0.57651918],\n       [0.71495838, 0.28504162],\n       [0.59711064, 0.40288936],\n       [0.63808839, 0.36191161],\n       [0.39957895, 0.60042105],\n       [0.52127638, 0.47872362],\n       [0.65975464, 0.34024536],\n       [0.5114172 , 0.4885828 ]])\n\n\n\n\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\n# code untuk membuat visualiasi confusion matrix\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n  \"\"\"\n  This function prints and plots the confusion matrix.\n  Normalization can be applied by setting `normalize=True`.\n  \"\"\"\n  if normalize:\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    print(\"Normalized confusion matrix\")\n  else:\n    print('Confusion matrix, without normalization')\n\n  print(cm)\n\n  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n  plt.title(title)\n  plt.colorbar()\n  tick_marks = np.arange(len(classes))\n  plt.xticks(tick_marks, classes, rotation=45)\n  plt.yticks(tick_marks, classes)\n\n  fmt = '.2f' if normalize else 'd'\n  thresh = cm.max() / 2.\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, format(cm[i, j], fmt),\n             horizontalalignment=\"center\",\n             color=\"white\" if cm[i, j] &gt; thresh else \"black\")\n  \n  plt.tight_layout()\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label')\n\n  print(confusion_matrix(Y_test, yhat, labels=[1,0]))\n\n\n#confusion matrix\ncnf = confusion_matrix(Y_test, yhat, labels=[1,0])\nplt.figure()\nplot_confusion_matrix(cnf,classes=['churn =1', 'churn=0'],normalize = False, title='Confusion matrix')\n\nConfusion matrix, without normalization\n[[ 6  9]\n [ 1 24]]\n[[ 6  9]\n [ 1 24]]\n\n\n\n\n\n\n\n\n\n\nprint (classification_report(Y_test, yhat))\n# Precission = TP/(TP+FP)\n# recall = TP/(TP+FN)\n\n              precision    recall  f1-score   support\n\n           0       0.73      0.96      0.83        25\n           1       0.86      0.40      0.55        15\n\n    accuracy                           0.75        40\n   macro avg       0.79      0.68      0.69        40\nweighted avg       0.78      0.75      0.72        40\n\n\n\n\n#log loss\nfrom sklearn.metrics import log_loss\nlog_loss(Y_test,yhat_prob)\n\n0.6017092478101185\n\n\n\n#jaccard score\nfrom sklearn.metrics import jaccard_score\njaccard_score(Y_test, yhat,pos_label=0)\n\n0.7058823529411765"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul06.html",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul06.html",
    "title": "Modul 6 | Tree (2)",
    "section": "",
    "text": "Kembali ke Struktur Data\n\n\nB-Tree adalah struktur data berbentuk tree di mana tiap node memiliki lebih dari satu key, dan tiap key tersebut mempunyai child-nya sendiri. B-Tree mempunyai sifat meminimalkan height dari tree yang terbeentuk, karena biasanya B-Tree digunakan untuk mengurangi akses antar disk.\n\nclass BTreeNode:\n    def __init__(self, leaf=False):\n        self.leaf = leaf\n        self.keys = []\n        self.child = []\n\n\nclass BTree:\n    def __init__(self, m):\n        self.root = BTreeNode(True)\n        self.m = m\n    \n    # Insert node\n    def insert(self, k):\n        root = self.root\n        if len(root.keys) == self.m - 1:\n            temp = BTreeNode()\n            self.root = temp\n            temp.child.insert(0, root)\n            self.split(temp, 0)\n            self.__ins__(temp, k)\n        else:\n            self.__ins__(root, k)\n    \n    # Insert nonfull\n    def __ins__(self, x, k):\n        i = len(x.keys) - 1\n        if x.leaf:\n            x.keys.append((None, None))\n            while i &gt;= 0 and k[0] &lt; x.keys[i][0]:\n                x.keys[i + 1] = x.keys[i]\n                i -= 1\n            x.keys[i + 1] = k\n        else:\n            while i &gt;= 0 and k[0] &lt; x.keys[i][0]:\n                i -= 1\n            i += 1\n            if len(x.child[i].keys) == self.m:\n                self.split(x, i)\n                if k[0] &gt; x.keys[i][0]:\n                    i += 1\n            self.__ins__(x.child[i], k)\n        \n    # Split the child\n    def split(self, x, i):\n        t = self.m // 2\n        y = x.child[i]\n        z = BTreeNode(y.leaf)\n        x.child.insert(i + 1, z)\n        x.keys.insert(i, y.keys[t - 1])\n        z.keys = y.keys[t: self.m]\n        y.keys = y.keys[0: t - 1]\n        if not y.leaf:\n            z.child = y.child[t: self.m]\n            y.child = y.child[0: t - 1]\n        \n    # Print the tree\n    def print_tree(self, x, l=0):\n        print(\"Level \", l, \" \", len(x.keys), end=\":\")\n        for i in x.keys:\n            print(i[1], end=\" \")\n        print()\n        l += 1\n        if len(x.child) &gt; 0:\n            for i in x.child:\n                self.print_tree(i, l)\n\n\nB = BTree(5)\nfor i in range(1, 11):\n    B.insert((i, 2*i))\n\nB.print_tree(B.root)\n\nLevel  0   3:4 8 12 \nLevel  1   1:2 \nLevel  1   1:6 \nLevel  1   1:10 \nLevel  1   4:14 16 18 20 \n\n\n\n\n\nHeap adalah salah satu struktur data tree di mana nilai dari child lebih kecil dari parent (untuk max-heap). Bentuk dari heap adalah almost complete binary tree, dan dalam implementasinya, heap dibuat sedemikian rupa sehingga dapat menggunakan array.\n\n# Max-Heap data structure in Python\n\ndef heapify(arr, n, i):\n    largest = i\n    l = 2 * i + 1\n    r = 2 * i + 2\n\n    if l &lt; n and arr[i] &lt; arr[l]:\n        largest = l\n    \n    if r &lt; n and arr[largest] &lt; arr[r]:\n        largest = r\n    \n    if largest != i:\n        arr[i], arr[largest] = arr[largest], arr[i]\n        heapify(arr, n, largest)\n\ndef insert(array, newNum):\n    size = len(array)\n    if size == 0:\n        array.append(newNum)\n    else:\n        array.append(newNum)\n        for i in range((size//2)-1, -1, -1):\n            heapify(array, size, i)\n\ndef delete(array, num):\n    size = len(array)\n    i = 0\n    for i in range(0, size):\n        if num == array[i]:\n            break\n    array[i], array[size-1] = array[size-1], array[i]\n\n    array.remove(num)\n\n    for i in range((len(array)//2)-1, -1, -1):\n        heapify(array, len(array), i)\n\n\nA = [10, 42, 11, 35, 22]\nB = []\nfor i in A:\n    insert(B, i)\nprint(B)\n\n[42, 35, 11, 10, 22]"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul06.html#b-tree",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul06.html#b-tree",
    "title": "Modul 6 | Tree (2)",
    "section": "",
    "text": "B-Tree adalah struktur data berbentuk tree di mana tiap node memiliki lebih dari satu key, dan tiap key tersebut mempunyai child-nya sendiri. B-Tree mempunyai sifat meminimalkan height dari tree yang terbeentuk, karena biasanya B-Tree digunakan untuk mengurangi akses antar disk.\n\nclass BTreeNode:\n    def __init__(self, leaf=False):\n        self.leaf = leaf\n        self.keys = []\n        self.child = []\n\n\nclass BTree:\n    def __init__(self, m):\n        self.root = BTreeNode(True)\n        self.m = m\n    \n    # Insert node\n    def insert(self, k):\n        root = self.root\n        if len(root.keys) == self.m - 1:\n            temp = BTreeNode()\n            self.root = temp\n            temp.child.insert(0, root)\n            self.split(temp, 0)\n            self.__ins__(temp, k)\n        else:\n            self.__ins__(root, k)\n    \n    # Insert nonfull\n    def __ins__(self, x, k):\n        i = len(x.keys) - 1\n        if x.leaf:\n            x.keys.append((None, None))\n            while i &gt;= 0 and k[0] &lt; x.keys[i][0]:\n                x.keys[i + 1] = x.keys[i]\n                i -= 1\n            x.keys[i + 1] = k\n        else:\n            while i &gt;= 0 and k[0] &lt; x.keys[i][0]:\n                i -= 1\n            i += 1\n            if len(x.child[i].keys) == self.m:\n                self.split(x, i)\n                if k[0] &gt; x.keys[i][0]:\n                    i += 1\n            self.__ins__(x.child[i], k)\n        \n    # Split the child\n    def split(self, x, i):\n        t = self.m // 2\n        y = x.child[i]\n        z = BTreeNode(y.leaf)\n        x.child.insert(i + 1, z)\n        x.keys.insert(i, y.keys[t - 1])\n        z.keys = y.keys[t: self.m]\n        y.keys = y.keys[0: t - 1]\n        if not y.leaf:\n            z.child = y.child[t: self.m]\n            y.child = y.child[0: t - 1]\n        \n    # Print the tree\n    def print_tree(self, x, l=0):\n        print(\"Level \", l, \" \", len(x.keys), end=\":\")\n        for i in x.keys:\n            print(i[1], end=\" \")\n        print()\n        l += 1\n        if len(x.child) &gt; 0:\n            for i in x.child:\n                self.print_tree(i, l)\n\n\nB = BTree(5)\nfor i in range(1, 11):\n    B.insert((i, 2*i))\n\nB.print_tree(B.root)\n\nLevel  0   3:4 8 12 \nLevel  1   1:2 \nLevel  1   1:6 \nLevel  1   1:10 \nLevel  1   4:14 16 18 20"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul06.html#heap",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul06.html#heap",
    "title": "Modul 6 | Tree (2)",
    "section": "",
    "text": "Heap adalah salah satu struktur data tree di mana nilai dari child lebih kecil dari parent (untuk max-heap). Bentuk dari heap adalah almost complete binary tree, dan dalam implementasinya, heap dibuat sedemikian rupa sehingga dapat menggunakan array.\n\n# Max-Heap data structure in Python\n\ndef heapify(arr, n, i):\n    largest = i\n    l = 2 * i + 1\n    r = 2 * i + 2\n\n    if l &lt; n and arr[i] &lt; arr[l]:\n        largest = l\n    \n    if r &lt; n and arr[largest] &lt; arr[r]:\n        largest = r\n    \n    if largest != i:\n        arr[i], arr[largest] = arr[largest], arr[i]\n        heapify(arr, n, largest)\n\ndef insert(array, newNum):\n    size = len(array)\n    if size == 0:\n        array.append(newNum)\n    else:\n        array.append(newNum)\n        for i in range((size//2)-1, -1, -1):\n            heapify(array, size, i)\n\ndef delete(array, num):\n    size = len(array)\n    i = 0\n    for i in range(0, size):\n        if num == array[i]:\n            break\n    array[i], array[size-1] = array[size-1], array[i]\n\n    array.remove(num)\n\n    for i in range((len(array)//2)-1, -1, -1):\n        heapify(array, len(array), i)\n\n\nA = [10, 42, 11, 35, 22]\nB = []\nfor i in A:\n    insert(B, i)\nprint(B)\n\n[42, 35, 11, 10, 22]"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul04.html",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul04.html",
    "title": "Modul 4 | Linked List, Stack, dan Queue",
    "section": "",
    "text": "Kembali ke Struktur Data\n\n\nLinked list terdiri dari node, di mana tiap node berisi kurang lebih 2 value, yaitu data dan pointer ke node lain.\nPertama akan dibuat node terlebih dahulu menggunakan class.\n\nclass Node:\n    def __init__(self, data, next):\n        self.data = data\n        self.next = \"None\"\n\nSelanjutnya akan dibuat class untuk linked list.\n\nclass LL:\n    def __init__(self):\n        self.head = \"None\"\n        self.size = 0\n    \n    def __iter__(self):\n        temp = self.head\n        while temp != \"None\":\n            yield temp.data\n            temp = temp.next\n\n    def is_empty(self):\n        return self.size == 0\n    \n    def len(self):\n        return self.size\n    \n    def ins_front(self, data):\n        new = Node(data, \"None\")\n        new.next = self.head\n        self.head = new\n        self.size += 1\n    \n    def ins_end(self, data):\n        new = Node(data, \"None\")\n        temp = self.head\n        while temp.next != \"None\":\n            temp = temp.next\n        temp.next = new\n        self.size += 1\n    \n    def del_front(self):\n        if self.is_empty():\n            print(\"List is already empty\")\n            return\n        self.head = self.head.next\n        self.size -= 1\n    \n    def del_end(self):\n        if self.is_empty():\n            print(\"List is already empty\")\n            return\n        temp = self.head\n        while temp.next.next != \"None\":\n            temp = temp.next\n        temp.next = \"None\"\n        self.size -= 1\n    \n    def print_all(self):\n        temp = self.head\n        while temp != \"None\":\n            print(temp.data, end = \" -&gt; \")\n            temp = temp.next\n\n\ntest = LL()\ntest.ins_front(5)\ntest.ins_front(15)\ntest.ins_front(25)\ntest.ins_front(35)\ntest.ins_front(45)\n\n\ntest.print_all()\n\n45 -&gt; 35 -&gt; 25 -&gt; 15 -&gt; 5 -&gt; \n\n\n\nfor i in test:\n    print(i)\n\n45\n35\n25\n15\n5\n\n\n\n\n\nStack menganut paham LIFO, jadi yang terakhir dimasukin, kalo ada perintah keluar, yang itu yang keluar.\nDi Python, implementasi stack pake array udah agak redundant karena banyaknya method buat array, jadi sekarang dikasih implementasinya buat linked list yang udah kita bikin tadi.\n\nclass Stack:\n    def __init__(self):\n        self.head = \"None\"\n        self.size = 0\n    \n    def is_empty(self):\n        return self.size == 0\n    \n    def len(self):\n        return self.size\n    \n    def push(self, data):\n        new = Node(data, \"None\")\n        new.next = self.head\n        self.head = new\n        self.size += 1\n    \n    def pop(self):\n        if self.is_empty():\n            print(\"Stack is already empty\")\n            return\n        self.head = self.head.next\n        self.size -= 1\n    \n    def top(self):\n        if self.is_empty():\n            print(\"Stack is empty.\")\n            return\n        return self.head.data\n\n    def print(self):\n        temp = self.head\n        while temp != \"None\":\n            print(temp.data)\n            temp = temp.next\n\n\ntest = Stack()\ntest.top()\n\nStack is empty.\n\n\n\ntest.push(5)\ntest.push(80)\ntest.push(100)\ntest.print()\n\n100\n80\n5\n\n\n\ntest.pop()\n\n\ntest.print()\n\n80\n5\n\n\n\ntest.len()\n\n2\n\n\n\n\n\nBerbeda dengan stack, queue menganut paham FIFO (First In First Out). Berarti, yang masuk pertama, bakal keluar pertama.\n\nclass Queue:\n    def __init__(self):\n        self.head = \"None\"\n        self.size = 0\n    \n    def is_empty(self):\n        return self.size == 0\n    \n    def len(self):\n        return self.size\n\n    def ins_end(self, data):\n        new = Node(data, \"None\")\n        temp = self.head\n        while temp.next != \"None\":\n            temp = temp.next\n        temp.next = new\n        self.size += 1\n    \n    def del_front(self):\n        if self.is_empty():\n            print(\"Queue is already empty\")\n            return\n        self.head = self.head.next\n        self.size -= 1\n    \n    def print_all(self):\n        temp = self.head\n        while temp != \"None\":\n            print(temp.data, end = \" -&gt; \")\n            temp = temp.next"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul04.html#linked-list",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul04.html#linked-list",
    "title": "Modul 4 | Linked List, Stack, dan Queue",
    "section": "",
    "text": "Linked list terdiri dari node, di mana tiap node berisi kurang lebih 2 value, yaitu data dan pointer ke node lain.\nPertama akan dibuat node terlebih dahulu menggunakan class.\n\nclass Node:\n    def __init__(self, data, next):\n        self.data = data\n        self.next = \"None\"\n\nSelanjutnya akan dibuat class untuk linked list.\n\nclass LL:\n    def __init__(self):\n        self.head = \"None\"\n        self.size = 0\n    \n    def __iter__(self):\n        temp = self.head\n        while temp != \"None\":\n            yield temp.data\n            temp = temp.next\n\n    def is_empty(self):\n        return self.size == 0\n    \n    def len(self):\n        return self.size\n    \n    def ins_front(self, data):\n        new = Node(data, \"None\")\n        new.next = self.head\n        self.head = new\n        self.size += 1\n    \n    def ins_end(self, data):\n        new = Node(data, \"None\")\n        temp = self.head\n        while temp.next != \"None\":\n            temp = temp.next\n        temp.next = new\n        self.size += 1\n    \n    def del_front(self):\n        if self.is_empty():\n            print(\"List is already empty\")\n            return\n        self.head = self.head.next\n        self.size -= 1\n    \n    def del_end(self):\n        if self.is_empty():\n            print(\"List is already empty\")\n            return\n        temp = self.head\n        while temp.next.next != \"None\":\n            temp = temp.next\n        temp.next = \"None\"\n        self.size -= 1\n    \n    def print_all(self):\n        temp = self.head\n        while temp != \"None\":\n            print(temp.data, end = \" -&gt; \")\n            temp = temp.next\n\n\ntest = LL()\ntest.ins_front(5)\ntest.ins_front(15)\ntest.ins_front(25)\ntest.ins_front(35)\ntest.ins_front(45)\n\n\ntest.print_all()\n\n45 -&gt; 35 -&gt; 25 -&gt; 15 -&gt; 5 -&gt; \n\n\n\nfor i in test:\n    print(i)\n\n45\n35\n25\n15\n5"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul04.html#stack",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul04.html#stack",
    "title": "Modul 4 | Linked List, Stack, dan Queue",
    "section": "",
    "text": "Stack menganut paham LIFO, jadi yang terakhir dimasukin, kalo ada perintah keluar, yang itu yang keluar.\nDi Python, implementasi stack pake array udah agak redundant karena banyaknya method buat array, jadi sekarang dikasih implementasinya buat linked list yang udah kita bikin tadi.\n\nclass Stack:\n    def __init__(self):\n        self.head = \"None\"\n        self.size = 0\n    \n    def is_empty(self):\n        return self.size == 0\n    \n    def len(self):\n        return self.size\n    \n    def push(self, data):\n        new = Node(data, \"None\")\n        new.next = self.head\n        self.head = new\n        self.size += 1\n    \n    def pop(self):\n        if self.is_empty():\n            print(\"Stack is already empty\")\n            return\n        self.head = self.head.next\n        self.size -= 1\n    \n    def top(self):\n        if self.is_empty():\n            print(\"Stack is empty.\")\n            return\n        return self.head.data\n\n    def print(self):\n        temp = self.head\n        while temp != \"None\":\n            print(temp.data)\n            temp = temp.next\n\n\ntest = Stack()\ntest.top()\n\nStack is empty.\n\n\n\ntest.push(5)\ntest.push(80)\ntest.push(100)\ntest.print()\n\n100\n80\n5\n\n\n\ntest.pop()\n\n\ntest.print()\n\n80\n5\n\n\n\ntest.len()\n\n2"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul04.html#queue",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul04.html#queue",
    "title": "Modul 4 | Linked List, Stack, dan Queue",
    "section": "",
    "text": "Berbeda dengan stack, queue menganut paham FIFO (First In First Out). Berarti, yang masuk pertama, bakal keluar pertama.\n\nclass Queue:\n    def __init__(self):\n        self.head = \"None\"\n        self.size = 0\n    \n    def is_empty(self):\n        return self.size == 0\n    \n    def len(self):\n        return self.size\n\n    def ins_end(self, data):\n        new = Node(data, \"None\")\n        temp = self.head\n        while temp.next != \"None\":\n            temp = temp.next\n        temp.next = new\n        self.size += 1\n    \n    def del_front(self):\n        if self.is_empty():\n            print(\"Queue is already empty\")\n            return\n        self.head = self.head.next\n        self.size -= 1\n    \n    def print_all(self):\n        temp = self.head\n        while temp != \"None\":\n            print(temp.data, end = \" -&gt; \")\n            temp = temp.next"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul02.html",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul02.html",
    "title": "Modul 2 | Searching dan Sorting",
    "section": "",
    "text": "Kembali ke Struktur Data\nSelamat datang di pertemuan kedua praktikum StrukDat. Pada pertemuan kedua kita akan melihat beberapa algoritma-algoritma searching dan sorting.\nOUTLINE:\n\nLinear Search\nBinary Search\nBubble Sort\nInsertion Sort\nSelection Sort\nQuick Sort\nMerge Sort\n\n\n\nAlgoritma searching, seperti namanya, adalah algoritma yang digunakan untu kmencari sesuatu dalam suatu list. Umumnya, algoritma semacam ini memiliki 2 input, yang suatu key yang ingin dicari, dan suatu list tempat pencarian key tersebut.\nTerdapat 2 algoritma umum untuk searching, yaitu:\n\nLinear Search\nBinary Search\n\n\n\nLinear search adalah algoritma searching dimana setiap elemen pada list dibandingkan satu persatu dengan key. Pada algoritma ini, kita akan mencoba untuk mencari keberadaan key pada list, serta index dari key tersebut (jika ada).\n\ndef linear_search(lis, key):\n    for i in range(len(lis)):\n        if lis[i] == key:\n            print(\"Key ditemukan.\")\n            print(\"Index =\", i)\n            return lis[i]\n    else:\n        print(\"Key tidak ditemukan.\")\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nlinear_search(A, 8)\n\nKey ditemukan.\nIndex = 5\n\n\n8\n\n\n\n\n\nBinary search adalah algoritma searching dimana suatu list dicek apakah nilai tengahnya adalah key. Jika tidak, list dipecah dua dan searching dilanjut tergantung posisi key relatif dari nilai tengah tsb (apakah lebih kecil atau lebih besar).\n\ndef binary_search(A, key):\n    le = 0\n    ri = len(A)\n    while True:\n        ctr = (le + ri) // 2\n        if key == A[ctr]:\n            print('Key ditemukan.')\n            print('Index =', ctr)\n            return A[ctr]\n        elif key &lt; A[ctr]:\n            ri = ctr-1\n        else:\n            le = ctr+1\n\n\nA = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\nbinary_search(A, 14)\n\nKey ditemukan.\nIndex = 6\n\n\n14\n\n\n\n\n\n\nTerdapat 5 algoritma umum dalam sorting yang akan dijelaskan, yaitu:\n\nBubble Sort\nInsertion Sort\nSelection Sort\nQuick Sort\nMerge Sort\n\n\n\nBubble sort adalah algoritma sorting yang cara kerjanya adalah dengan membandingkan elemen yang bersebelahan secara berurutan, lalu ditukar jika urutannya salah.\n\ndef bubble_sort(A):\n    n = len(A)\n    for i in range(n-1):\n        for j in range(n-1):\n            if A[j] &gt; A[j+1]:\n                A[j], A[j+1] = A[j+1], A[j]\n    return A\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nbubble_sort(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nCara kerja dari insertion sort adalah dengan membandingkan elemen baru dengan elemen sebelumnya dan ditempatkan di tempat yang sesuai. Insertion sort mulai dari indeks ke-1, yang mana elemen pada indeks tersebut dibandingkan dengan indeks sebelumnya. Jika posisinya tidak sesuai, maka elemen ditukar, dan seterusnya hingga posisinya sesuai. Lalu iterasi dilanjutkan dengan elemen indeks ke-2, hingga elemen telah diiterasi semua.\n\ndef insertion_sort(A):\n    n = len(A)\n    for i in range(1, n):\n        j = i\n        while A[j] &lt; A[j-1]:\n            A[j], A[j-1] = A[j-1], A[j]\n            j -= 1\n            if j == 0:\n                break\n    return A\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\ninsertion_sort(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nSelection sort melakukan sorting dengan memasukkan nilai minimum dari suatu list. Jika diberikan suatu list \\(A[0..(n-1)]\\), maka algoritma mencari nilai minimum dari \\(A[0..(n-1)]\\), lalu ditukar dengan elemen \\(A[0]\\). Selanjutnya algoritma mencari nilai minimum dari \\(A[1..(n-1)]\\), lalu ditukar dengan elemen \\(A[1]\\), dan seterusnya.\n\ndef selection_sort(A):\n    n = len(A)\n    for i in range(n-1):\n        min = A[i]\n        mindx = i\n        for j in range(i+1, n):\n            if A[j] &lt; min:\n                min = A[j]\n                mindx = j\n        A[i], A[mindx] = A[mindx], A[i]\n    return A\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nselection_sort(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nUntuk melakukan sorting dengan quicksort pada list \\(A[0..(n-1)]\\), algoritma mengambil satu elemen untuk dijadikan pivot (dalam hal ini, elemen pertama pada list). Lalu dibuat dua sub-list, yang pertama berisi elemen yang nilainya lebih kecil dari pivot, dan yang kedua berisi elemen yang nilainya lebih besar dari pivot. Lalu pivot diletakkan di antara kedua sub-list. Selanjutnya, langkah pivoting dan seterusnya diulang pada tiap sub-list, hingga sub-list menjadi tersisa 1 elemen. Selanjutnya, sub-list terakhir tersebut digabungkan hingga membentuk list utuh kembali.\n\ndef partition(A, p, r):\n    x = A[r]\n    i = p - 1\n    for j in range(p, r):\n        if A[j] &lt;= x:\n            i = i + 1\n            A[i], A[j] = A[j], A[i]\n    A[i+1], A[r] = A[r], A[i+1]\n    return i+1\n\n\ndef quicksort(A, p=0, r=len(A)-1):\n    if p &lt; r:\n        q = partition(A, p, r)\n        quicksort(A, p, q-1)\n        quicksort(A, q+1, r)\n    return A\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nquicksort(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nMerge sort melakukan sort dengan memecah list menjadi dua secara rekursif. Lalu sorting dilakukan dengan melakukan merge pada hasil pecahan list. Merge adalah proses pada dua list yang menyatukan dua list terurut menjadi satu list terurut. Merge dilakukan hingga list utuh kembali.\n\ndef merge_sort(A):\n    n = len(A)\n    if len(A) &gt; 1:\n        m = n//2\n        A1 = A[:m]\n        A2 = A[m:]\n        merge_sort(A1)\n        merge_sort(A2)\n        i = j = k = 0\n        while i &lt; len(A1) and j &lt; len(A2):\n            if A1[i] &lt;= A2[j]:\n                A[k] = A1[i]\n                i += 1\n            else:\n                A[k] = A2[j]\n                j += 1\n            k += 1\n\n        # Checking if any element was left\n        while i &lt; len(A1):\n            A[k] = A1[i]\n            i += 1\n            k += 1\n        \n        while j &lt; len(A2):\n            A[k] = A2[j]\n            j += 1\n            k += 1\n    return A\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nmerge_sort(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul02.html#searching",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul02.html#searching",
    "title": "Modul 2 | Searching dan Sorting",
    "section": "",
    "text": "Algoritma searching, seperti namanya, adalah algoritma yang digunakan untu kmencari sesuatu dalam suatu list. Umumnya, algoritma semacam ini memiliki 2 input, yang suatu key yang ingin dicari, dan suatu list tempat pencarian key tersebut.\nTerdapat 2 algoritma umum untuk searching, yaitu:\n\nLinear Search\nBinary Search\n\n\n\nLinear search adalah algoritma searching dimana setiap elemen pada list dibandingkan satu persatu dengan key. Pada algoritma ini, kita akan mencoba untuk mencari keberadaan key pada list, serta index dari key tersebut (jika ada).\n\ndef linear_search(lis, key):\n    for i in range(len(lis)):\n        if lis[i] == key:\n            print(\"Key ditemukan.\")\n            print(\"Index =\", i)\n            return lis[i]\n    else:\n        print(\"Key tidak ditemukan.\")\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nlinear_search(A, 8)\n\nKey ditemukan.\nIndex = 5\n\n\n8\n\n\n\n\n\nBinary search adalah algoritma searching dimana suatu list dicek apakah nilai tengahnya adalah key. Jika tidak, list dipecah dua dan searching dilanjut tergantung posisi key relatif dari nilai tengah tsb (apakah lebih kecil atau lebih besar).\n\ndef binary_search(A, key):\n    le = 0\n    ri = len(A)\n    while True:\n        ctr = (le + ri) // 2\n        if key == A[ctr]:\n            print('Key ditemukan.')\n            print('Index =', ctr)\n            return A[ctr]\n        elif key &lt; A[ctr]:\n            ri = ctr-1\n        else:\n            le = ctr+1\n\n\nA = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\nbinary_search(A, 14)\n\nKey ditemukan.\nIndex = 6\n\n\n14"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul02.html#sorting",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul02.html#sorting",
    "title": "Modul 2 | Searching dan Sorting",
    "section": "",
    "text": "Terdapat 5 algoritma umum dalam sorting yang akan dijelaskan, yaitu:\n\nBubble Sort\nInsertion Sort\nSelection Sort\nQuick Sort\nMerge Sort\n\n\n\nBubble sort adalah algoritma sorting yang cara kerjanya adalah dengan membandingkan elemen yang bersebelahan secara berurutan, lalu ditukar jika urutannya salah.\n\ndef bubble_sort(A):\n    n = len(A)\n    for i in range(n-1):\n        for j in range(n-1):\n            if A[j] &gt; A[j+1]:\n                A[j], A[j+1] = A[j+1], A[j]\n    return A\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nbubble_sort(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nCara kerja dari insertion sort adalah dengan membandingkan elemen baru dengan elemen sebelumnya dan ditempatkan di tempat yang sesuai. Insertion sort mulai dari indeks ke-1, yang mana elemen pada indeks tersebut dibandingkan dengan indeks sebelumnya. Jika posisinya tidak sesuai, maka elemen ditukar, dan seterusnya hingga posisinya sesuai. Lalu iterasi dilanjutkan dengan elemen indeks ke-2, hingga elemen telah diiterasi semua.\n\ndef insertion_sort(A):\n    n = len(A)\n    for i in range(1, n):\n        j = i\n        while A[j] &lt; A[j-1]:\n            A[j], A[j-1] = A[j-1], A[j]\n            j -= 1\n            if j == 0:\n                break\n    return A\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\ninsertion_sort(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nSelection sort melakukan sorting dengan memasukkan nilai minimum dari suatu list. Jika diberikan suatu list \\(A[0..(n-1)]\\), maka algoritma mencari nilai minimum dari \\(A[0..(n-1)]\\), lalu ditukar dengan elemen \\(A[0]\\). Selanjutnya algoritma mencari nilai minimum dari \\(A[1..(n-1)]\\), lalu ditukar dengan elemen \\(A[1]\\), dan seterusnya.\n\ndef selection_sort(A):\n    n = len(A)\n    for i in range(n-1):\n        min = A[i]\n        mindx = i\n        for j in range(i+1, n):\n            if A[j] &lt; min:\n                min = A[j]\n                mindx = j\n        A[i], A[mindx] = A[mindx], A[i]\n    return A\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nselection_sort(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nUntuk melakukan sorting dengan quicksort pada list \\(A[0..(n-1)]\\), algoritma mengambil satu elemen untuk dijadikan pivot (dalam hal ini, elemen pertama pada list). Lalu dibuat dua sub-list, yang pertama berisi elemen yang nilainya lebih kecil dari pivot, dan yang kedua berisi elemen yang nilainya lebih besar dari pivot. Lalu pivot diletakkan di antara kedua sub-list. Selanjutnya, langkah pivoting dan seterusnya diulang pada tiap sub-list, hingga sub-list menjadi tersisa 1 elemen. Selanjutnya, sub-list terakhir tersebut digabungkan hingga membentuk list utuh kembali.\n\ndef partition(A, p, r):\n    x = A[r]\n    i = p - 1\n    for j in range(p, r):\n        if A[j] &lt;= x:\n            i = i + 1\n            A[i], A[j] = A[j], A[i]\n    A[i+1], A[r] = A[r], A[i+1]\n    return i+1\n\n\ndef quicksort(A, p=0, r=len(A)-1):\n    if p &lt; r:\n        q = partition(A, p, r)\n        quicksort(A, p, q-1)\n        quicksort(A, q+1, r)\n    return A\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nquicksort(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\n\n\nMerge sort melakukan sort dengan memecah list menjadi dua secara rekursif. Lalu sorting dilakukan dengan melakukan merge pada hasil pecahan list. Merge adalah proses pada dua list yang menyatukan dua list terurut menjadi satu list terurut. Merge dilakukan hingga list utuh kembali.\n\ndef merge_sort(A):\n    n = len(A)\n    if len(A) &gt; 1:\n        m = n//2\n        A1 = A[:m]\n        A2 = A[m:]\n        merge_sort(A1)\n        merge_sort(A2)\n        i = j = k = 0\n        while i &lt; len(A1) and j &lt; len(A2):\n            if A1[i] &lt;= A2[j]:\n                A[k] = A1[i]\n                i += 1\n            else:\n                A[k] = A2[j]\n                j += 1\n            k += 1\n\n        # Checking if any element was left\n        while i &lt; len(A1):\n            A[k] = A1[i]\n            i += 1\n            k += 1\n        \n        while j &lt; len(A2):\n            A[k] = A2[j]\n            j += 1\n            k += 1\n    return A\n\n\nA = [1, 5, 2, 3, 4, 8, 7, 6, 10, 9]\nmerge_sort(A)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/strukdat2022.html",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/strukdat2022.html",
    "title": "Praktikum Struktur Data 2022 Ganjil (Kurikulum 2020)",
    "section": "",
    "text": "Kembali ke Praktikum\n\nModul\n\nModul 1 | Tipe Data di Python\nModul 2 | Searching dan Sorting\nModul 3 | Pengenalan class\nModul 4 | Linked List, Stack, dan Queue\nModul 5 | Tree (1)\nModul 6 | Tree (2)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Langsung pencet Praktikum aja yaa!\nThis is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "semuahalaman/about.html",
    "href": "semuahalaman/about.html",
    "title": "About",
    "section": "",
    "text": "Langsung pencet Praktikum aja yaa!\nAbout this site"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html",
    "title": "Modul 1 | Tipe Data di Python",
    "section": "",
    "text": "Kembali ke Struktur Data\nSelamat dataing di praktikum pertama StrukDat. Pada pertemuan pertama akan di-review lagi beberapa materi AlProg dengan beberapa tambahan. Kita juga akan memperkenalkan kelas objek baru, yaitu dict.\n\n\nPada AlProg, ada beberapa jenis tipe data yang kalian pelajari, yaitu:\n\nNumerik: int, float, complex\nTeks: string\nList, Tuple\n\n\n\n\n\n# Tipe Data Integer\na1 = 5\na2 = -180\n\n# Mengecek tipe data menggunakan syntax type\nprint(type(a1))\nprint(type(a2))\n\n&lt;class 'int'&gt;\n&lt;class 'int'&gt;\n\n\n\n# Tipe data float\nb1 = 2.54\nb2 = -3.141592\nb3 = float('inf') # memasukkan infinity sebagai float\n\n# Mengecek tipe data\nprint(type(b1))\nprint(type(b2))\nprint(type(b3))\n\n&lt;class 'float'&gt;\n&lt;class 'float'&gt;\n&lt;class 'float'&gt;\n\n\n\n# Operasi pada numerik\nprint(a1 + a2)\nprint(b1 * b2)\nprint(a1 ** b1)\nprint(abs(b2))\n\n# Jika int bertemu float, maka tipe datanya akan menjadi float,\n# walaupun float nya sebenarnya bulat\nprint(type(a1 ** b1))\n\n-175\n-7.979643680000001\n59.618879710940476\n3.141592\n&lt;class 'float'&gt;\n\n\n\n\n\n\n# Tipe Data String\nc1 = 'string biasa'\nc2 = '''string\nsampe\nbawah'''\n\n# Mengecek Tipe Data\nprint(type(c1))\nprint(type(c2))\n\n&lt;class 'str'&gt;\n&lt;class 'str'&gt;\n\n\nPada string dapat dilakukan penggabungan (s + s), penggandaan (s * n), slicing (s[a:b]), cari panjang (len), maksimum-minimum (max-min di sini diliat dari urutannya di ASCII), dll. Method bisa lebih banyak lagi\n\nprint('ayam' + 'geprek')\nprint(5 * 'es jeruk') # dia ga nambahin whitespace yaa\n\nayamgeprek\nes jerukes jerukes jerukes jerukes jeruk\n\n\n\n\n\nKetiganya dapat digunakan untuk menyimpan banyak item sekaligus. Karena list sudah dijelaskan, akan dijelaskan mengenai tuple dan set\n\n# Membuat tuple\nt1 = (2, 3)\nt2 = (4, 'abc')\nt3 = tuple('kacang')\n\nprint(t3)\n\n('k', 'a', 'c', 'a', 'n', 'g')\n\n\nTuple dapat dianggap sebagai list yang isinya tidak bisa diganti, ditambah, ataupun dihapus. Namun masih berlaku operasi list yang tidak termasuk editing. Kelebihan tuple adalah bisa menjadi key untuk dict (akan dijelaskan kemudian)\n\n# Membuat set\ns1 = {'ayam', 'bebek', 'ayam', 'kuda'}\ns2 = set(list('kacang'))\n\nprint(s1)\nprint(s2)\n\n{'bebek', 'kuda', 'ayam'}\n{'k', 'g', 'c', 'a', 'n'}\n\n\nSet dianggap sebagai list yang tidak mempunyai urutan, sehingga tidak ada indexing dan slicing. Kelebihan utamanya adalah set hanya bisa mempunyai elemen yang unik (tidak bisa ada elemen yang sama di set). Hal ini berguna jika kalian mempunyai list yang kalian ingin hilangkan dobel-dobelnya (efek sampingnya, indeksnya jadi hilang sehingga bisa saja isinya tak beraturan).\nBeberapa operator himpunan matematika juga ada di set, seperti subset, superset, disjoint, union, intersection, dll.\n\ns3 = set('matematika')\ns4 = set('statistika')\ns5 = set('aktuaria')\n\nprint(s3)\nprint(s4)\nprint(s5)\n\n{'t', 'm', 'e', 'i', 'k', 'a'}\n{'t', 'i', 'k', 'a', 's'}\n{'t', 'k', 'r', 'i', 'a', 'u'}\n\n\n\nprint(s3 & s4) # Irisan\nprint(s3 | s4) # Gabungan\n\n{'t', 'a', 'i', 'k'}\n{'t', 'm', 'e', 'k', 'i', 'a', 's'}\n\n\n\n\n\nTerkadang kita membangun list menggunakan for loop, dan for loop tersebut bisa saja memakan beberapa line dari kode kalian. Dengan list comprehension, kita dapat membangun list tersebut hanya menggunakan 1 line dan bisa saja kode kita menjadi lebih enak untuk dibaca.\nSebagai contoh, kita ingin membuat list yang berisi nilai dari \\(2^x\\):\n\nexpo = []\nfor i in range(6):\n    expo.append(2**i)\n\nprint(expo)\n\n[1, 2, 4, 8, 16, 32]\n\n\nJika menggunakan list comprehension, akan menjadi seperti ini:\n\nexpo = [2 ** i for i in range(6)]\n\nprint(expo)\n\n[1, 2, 4, 8, 16, 32]\n\n\nList comprehension dibuat dengan membuat list yang berisi suatu ekspresi lalu diikuti dengan for, dan jika diinginkan, bisa ditambah lagi for atau if. Hasilnya akan membuat seolah kita menjalankan for loop untuk membuat list tersebut, namun hanya menggunakan satu line.\nSeperti disinggung sebelumnya, list comprehension dapat menggunakan lebih dari satu variabel pada ekspresinya. Hal ini ekivalen dengan jika kita menggunakan nested for loop untuk membuat list tersebut.\nSebagai contoh:\n\ncrossprod = [(x, y) for x in [1, 3, 5] for y in [2, 4, 6]]\nprint(crossprod)\n\n[(1, 2), (1, 4), (1, 6), (3, 2), (3, 4), (3, 6), (5, 2), (5, 4), (5, 6)]\n\n\nPotongan kode di atas ekivalen dengan:\n\ncrossprod = []\nfor x in [1, 3, 5]:\n    for y in [2, 4, 6]:\n        crossprod.append((x, y))\n\nprint(crossprod)\n\n[(1, 2), (1, 4), (1, 6), (3, 2), (3, 4), (3, 6), (5, 2), (5, 4), (5, 6)]\n\n\nIngat bahwa urutan pembacaan setiap ekspresi for dan if pada list comprehension adalah dari kiri ke kanan.\nList comprehension pun juga bisa di-nesting.\n\nmat = [[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]]\n\nmattr = [[ro[i] for ro in mat] for i in range(len(mat))]\nprint(mattr)\n\n[[1, 4, 7], [2, 5, 8], [3, 6, 9]]\n\n\n\n\n\nDictionary dapat dianggap sebagai set yang tiap elemennya memiliki 2 jenis nilai, yaitu key dan value. Strukturnya adalah {key1:value1, key2:value2, ....}.\n\n# Membuat dictionary\nd1 = {'a': 1, 'b': 2, 'c': 3}\nd2 = {'kopi': 6000, 'teh': 5000, 'susu': 7000}\n\nTidak seperti list yang diindeks menggunakan suatu range bilangan, dictionary diindeks meenggunakan key. Tipe data dari value boleh bebas, namun untuk key harus yang immutable (agak oversimplification tapi artinya tidak bisa diubah), sehingga tuple juga berguna untuk menjadi key dari dictionary\n\nd3 = {(2, 3): 6, (3, 4): 12}\nprint(d3)\n\n{(2, 3): 6, (3, 4): 12}\n\n\nUntuk memanggil suatu value, panggil layaknya list, namun indeksnya menggunakan key\n\nprint(d3[(3, 4)])\n\n12\n\n\nUntuk meneambah suatu pasangan key:value baru, cukup menggunakan d[key] = value, dan akan masuk ke dict tersebut.\n\nd3[(3, 5)] = 15\nprint(d3)\n\n{(2, 3): 6, (3, 4): 12, (3, 5): 15}\n\n\nJika ingin menghapus elemen pada dict, dapat menggunakan del\n\ndel d3[(2, 3)]\nprint(d3)\n\n{(3, 4): 12, (3, 5): 15}"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html#review-tipe-data",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html#review-tipe-data",
    "title": "Modul 1 | Tipe Data di Python",
    "section": "",
    "text": "Pada AlProg, ada beberapa jenis tipe data yang kalian pelajari, yaitu:\n\nNumerik: int, float, complex\nTeks: string\nList, Tuple"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html#tipe-numerik",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html#tipe-numerik",
    "title": "Modul 1 | Tipe Data di Python",
    "section": "",
    "text": "# Tipe Data Integer\na1 = 5\na2 = -180\n\n# Mengecek tipe data menggunakan syntax type\nprint(type(a1))\nprint(type(a2))\n\n&lt;class 'int'&gt;\n&lt;class 'int'&gt;\n\n\n\n# Tipe data float\nb1 = 2.54\nb2 = -3.141592\nb3 = float('inf') # memasukkan infinity sebagai float\n\n# Mengecek tipe data\nprint(type(b1))\nprint(type(b2))\nprint(type(b3))\n\n&lt;class 'float'&gt;\n&lt;class 'float'&gt;\n&lt;class 'float'&gt;\n\n\n\n# Operasi pada numerik\nprint(a1 + a2)\nprint(b1 * b2)\nprint(a1 ** b1)\nprint(abs(b2))\n\n# Jika int bertemu float, maka tipe datanya akan menjadi float,\n# walaupun float nya sebenarnya bulat\nprint(type(a1 ** b1))\n\n-175\n-7.979643680000001\n59.618879710940476\n3.141592\n&lt;class 'float'&gt;"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html#tipe-teks",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html#tipe-teks",
    "title": "Modul 1 | Tipe Data di Python",
    "section": "",
    "text": "# Tipe Data String\nc1 = 'string biasa'\nc2 = '''string\nsampe\nbawah'''\n\n# Mengecek Tipe Data\nprint(type(c1))\nprint(type(c2))\n\n&lt;class 'str'&gt;\n&lt;class 'str'&gt;\n\n\nPada string dapat dilakukan penggabungan (s + s), penggandaan (s * n), slicing (s[a:b]), cari panjang (len), maksimum-minimum (max-min di sini diliat dari urutannya di ASCII), dll. Method bisa lebih banyak lagi\n\nprint('ayam' + 'geprek')\nprint(5 * 'es jeruk') # dia ga nambahin whitespace yaa\n\nayamgeprek\nes jerukes jerukes jerukes jerukes jeruk"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html#list-tuple-dan-set",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html#list-tuple-dan-set",
    "title": "Modul 1 | Tipe Data di Python",
    "section": "",
    "text": "Ketiganya dapat digunakan untuk menyimpan banyak item sekaligus. Karena list sudah dijelaskan, akan dijelaskan mengenai tuple dan set\n\n# Membuat tuple\nt1 = (2, 3)\nt2 = (4, 'abc')\nt3 = tuple('kacang')\n\nprint(t3)\n\n('k', 'a', 'c', 'a', 'n', 'g')\n\n\nTuple dapat dianggap sebagai list yang isinya tidak bisa diganti, ditambah, ataupun dihapus. Namun masih berlaku operasi list yang tidak termasuk editing. Kelebihan tuple adalah bisa menjadi key untuk dict (akan dijelaskan kemudian)\n\n# Membuat set\ns1 = {'ayam', 'bebek', 'ayam', 'kuda'}\ns2 = set(list('kacang'))\n\nprint(s1)\nprint(s2)\n\n{'bebek', 'kuda', 'ayam'}\n{'k', 'g', 'c', 'a', 'n'}\n\n\nSet dianggap sebagai list yang tidak mempunyai urutan, sehingga tidak ada indexing dan slicing. Kelebihan utamanya adalah set hanya bisa mempunyai elemen yang unik (tidak bisa ada elemen yang sama di set). Hal ini berguna jika kalian mempunyai list yang kalian ingin hilangkan dobel-dobelnya (efek sampingnya, indeksnya jadi hilang sehingga bisa saja isinya tak beraturan).\nBeberapa operator himpunan matematika juga ada di set, seperti subset, superset, disjoint, union, intersection, dll.\n\ns3 = set('matematika')\ns4 = set('statistika')\ns5 = set('aktuaria')\n\nprint(s3)\nprint(s4)\nprint(s5)\n\n{'t', 'm', 'e', 'i', 'k', 'a'}\n{'t', 'i', 'k', 'a', 's'}\n{'t', 'k', 'r', 'i', 'a', 'u'}\n\n\n\nprint(s3 & s4) # Irisan\nprint(s3 | s4) # Gabungan\n\n{'t', 'a', 'i', 'k'}\n{'t', 'm', 'e', 'k', 'i', 'a', 's'}"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html#list-comprehension",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html#list-comprehension",
    "title": "Modul 1 | Tipe Data di Python",
    "section": "",
    "text": "Terkadang kita membangun list menggunakan for loop, dan for loop tersebut bisa saja memakan beberapa line dari kode kalian. Dengan list comprehension, kita dapat membangun list tersebut hanya menggunakan 1 line dan bisa saja kode kita menjadi lebih enak untuk dibaca.\nSebagai contoh, kita ingin membuat list yang berisi nilai dari \\(2^x\\):\n\nexpo = []\nfor i in range(6):\n    expo.append(2**i)\n\nprint(expo)\n\n[1, 2, 4, 8, 16, 32]\n\n\nJika menggunakan list comprehension, akan menjadi seperti ini:\n\nexpo = [2 ** i for i in range(6)]\n\nprint(expo)\n\n[1, 2, 4, 8, 16, 32]\n\n\nList comprehension dibuat dengan membuat list yang berisi suatu ekspresi lalu diikuti dengan for, dan jika diinginkan, bisa ditambah lagi for atau if. Hasilnya akan membuat seolah kita menjalankan for loop untuk membuat list tersebut, namun hanya menggunakan satu line.\nSeperti disinggung sebelumnya, list comprehension dapat menggunakan lebih dari satu variabel pada ekspresinya. Hal ini ekivalen dengan jika kita menggunakan nested for loop untuk membuat list tersebut.\nSebagai contoh:\n\ncrossprod = [(x, y) for x in [1, 3, 5] for y in [2, 4, 6]]\nprint(crossprod)\n\n[(1, 2), (1, 4), (1, 6), (3, 2), (3, 4), (3, 6), (5, 2), (5, 4), (5, 6)]\n\n\nPotongan kode di atas ekivalen dengan:\n\ncrossprod = []\nfor x in [1, 3, 5]:\n    for y in [2, 4, 6]:\n        crossprod.append((x, y))\n\nprint(crossprod)\n\n[(1, 2), (1, 4), (1, 6), (3, 2), (3, 4), (3, 6), (5, 2), (5, 4), (5, 6)]\n\n\nIngat bahwa urutan pembacaan setiap ekspresi for dan if pada list comprehension adalah dari kiri ke kanan.\nList comprehension pun juga bisa di-nesting.\n\nmat = [[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]]\n\nmattr = [[ro[i] for ro in mat] for i in range(len(mat))]\nprint(mattr)\n\n[[1, 4, 7], [2, 5, 8], [3, 6, 9]]"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html#dictionary",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html#dictionary",
    "title": "Modul 1 | Tipe Data di Python",
    "section": "",
    "text": "Dictionary dapat dianggap sebagai set yang tiap elemennya memiliki 2 jenis nilai, yaitu key dan value. Strukturnya adalah {key1:value1, key2:value2, ....}.\n\n# Membuat dictionary\nd1 = {'a': 1, 'b': 2, 'c': 3}\nd2 = {'kopi': 6000, 'teh': 5000, 'susu': 7000}\n\nTidak seperti list yang diindeks menggunakan suatu range bilangan, dictionary diindeks meenggunakan key. Tipe data dari value boleh bebas, namun untuk key harus yang immutable (agak oversimplification tapi artinya tidak bisa diubah), sehingga tuple juga berguna untuk menjadi key dari dictionary\n\nd3 = {(2, 3): 6, (3, 4): 12}\nprint(d3)\n\n{(2, 3): 6, (3, 4): 12}\n\n\nUntuk memanggil suatu value, panggil layaknya list, namun indeksnya menggunakan key\n\nprint(d3[(3, 4)])\n\n12\n\n\nUntuk meneambah suatu pasangan key:value baru, cukup menggunakan d[key] = value, dan akan masuk ke dict tersebut.\n\nd3[(3, 5)] = 15\nprint(d3)\n\n{(2, 3): 6, (3, 4): 12, (3, 5): 15}\n\n\nJika ingin menghapus elemen pada dict, dapat menggunakan del\n\ndel d3[(2, 3)]\nprint(d3)\n\n{(3, 4): 12, (3, 5): 15}"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html",
    "title": "Modul 3 | Pengenalan class",
    "section": "",
    "text": "Kembali ke Struktur Data\nPada praktikum kali ini, kita akan membahas tentang class, yang nantinya akan kita gunakan untuk membuat berbagai jenis struktur data.\n\n\nClass dapat digambarkan sebagai pabrik dari suatu objek. Dengan kata lain, class mengandung blueprint yang menggambarkan cara membuat objek tersebut. Setiap objek (atau instansi) akan mempunyai atribut dan method. Atribut adalah variabel yang menggambarkan karakteristik dari objek tersebut, dan method adalah fungsi yang dapat dilakukan oleh objek tersebut.\nSyntax untuk membuat class pada Python adalah:\nclass ClassName:\n    &lt;statement&gt;\n    &lt;statement&gt;\n    .\n    .\n    .\n    &lt;statement&gt;\nSebagai contoh, kita akan membuat suatu class kosong menggunakan syntax pass.\n\nclass MyClass:\n    pass\n\nPada contoh di atas, MyClass adalah nama dari class, dan pass adalah salah satu statement pada class tersebut. Untuk membuat suatu instansi dari class yang telah kita buat, mirip seperti memanggil fungsi:\n\nobj_1 = MyClass()\nprint(obj_1)\nobj_2 = MyClass()\nprint(obj_2)\n\n&lt;__main__.MyClass object at 0x1058f6cb0&gt;\n&lt;__main__.MyClass object at 0x1057cebc0&gt;\n\n\nKedua variabel tersebut adalah instansi dari MyClass yang telah kita buat. Kode hex di akhir print adalah address dari instansi tersebut pada memori.\nSekarang kita akan mendefinisikan variabel pada kelas MyClass:\n\nclass MyClass:\n    var = 9\n\nUntuk memanggil variabel tersebut, kita panggil instansi yang telah dibuat, diikuti dengan titik, lalu nama variabel tersebut\n\nobj_1 = MyClass()\nprint(obj_1.var)\n\nobj_2 = MyClass()\nprint(obj_2.var)\n\n9\n9\n\n\n\n\n\nSuatu fungsi yang didefinisikan pada class disebut method. Suatu method dari instansi membutuhkan instansi tersebut agar bisa dipanggil. Dalam membuat method, parameter pertama selalu self. self adalah parameter dari instansi yang dibuat.\n\nclass MyClass:\n    var = 9\n\n    def firstM(self):\n        print('hello, World')\n\n\nobj = MyClass()\nprint(obj.var)\nobj.firstM()\n\n9\nhello, World\n\n\n\n\n\nEnkapsulasi adalah salah satu teknik fundamental pada OOP. Enkapsulasi memberikan mekanisme dalam me-restrict akses ke beberapa komponen dari objek. Aksesnya biasanya diambil dari metode yang umumnya disebut getters and setters.\n\nclass MyClass:\n    def setAge(self, num):\n        self.age = num\n    \n    def getAge(self):\n        return self.age\n\n\nkobo = MyClass()\nkobo.setAge(20)\nprint(kobo.getAge())\n\n20\n\n\n\n\n\n__init__, sesuai namanya, adala inisialisasi dari suatu class. __init__ akan dipanggil langsung setela suatu instansi dibuat. __init__ juga terkadang disebut sebagai konstruktor.\nBanyak class yang lebih baik membuat objek yang sudah mempunyai suatu initial state. Di sinilah __init__ digunakan:\n\nclass MyClass:\n    def __init__(self, aaa, bbb):\n        self.a = aaa\n        self.b = bbb\n\nUntuk memanggil konstruktor __init__ nya, kita berikan parameter yang sesuai saat membuat instansi baru (dalam contoh di atas berarti aaa dan bbb).\n\nx = MyClass(4.5, 3)\nprint(x.a, x.b)\n\n4.5 3\n\n\n\n\n\nAtribut yang didefinisikan pada class akan disebut sebagai atribut class, dan atribut yang didefinisikan pada fungsi, atau atribut yang didefinisikan untuk instansi akan disebut ‘atribut instansi’. Saat pendefinisian, atribut ini tidak menggunakan prefix self, karena merupakan atribut dari suatu class dan bukan atribut dari suatu instansi.\nAtribut class dapat diakses oleh class itu sendiri (class attribute) ataupun oleh suatu instansi (instance attribute). Dengan kata lain, suatu instansi dapat mengakses atribut instansi sekaligus atribut kelas.\n\nclass myclass:\n    age = 21\n\n\nmyclass.age\n\n21\n\n\n\nx = myclass()\nx.age\n\n21\n\n\nAtribut class dapat ditimpa pada instansi\n\nclass myclass:\n    classy = 'Class Attrib'\n\n\ndd = myclass()\nprint(dd.classy)\n\nClass Attrib\n\n\n\n\n\nPada magian ini, akan dijelaskan bagaimana data class berhubungan dengan data instansi. Kita dapat menyimpan suatu data baik pada class maupun pada instansi. Ketika kita membuat suatu class, kita menentukan apaka suatu data lebih cocok disimpan di instansi atau di kelas.\nSuatu instansi dapat mengakses data class yang membuatnya. Ketika kita membuat banyak instansi, maka instansi-instansi tersebut dapat mengakses atribut instansinya masing-masing, serta mengakses data class keseluruhan. Maka, data class adalah data yang dapat diakses semua instansi yang dimuat di class tersebut.\n\nclass InstanceCounter:\n    count = 0  # Atribut class, dapat diakses oleh semua instansi\n\n    def __init__(self, val):\n        self.val = val\n        InstanceCounter.count += 1 # Menambahkan value dari atribut class\n    \n    def set_val(self, newval):\n        self.val = newval\n    \n    def get_val(self):\n        return self.val\n\n    def get_count(self):\n        return InstanceCounter.count\n\n\na = InstanceCounter(9)\nb = InstanceCounter(18)\nc = InstanceCounter(27)\n\nfor obj in (a, b, c):\n    print('val of obj: %s' % (obj.get_val())) # Nilai inisialisasi (9, 18, 27)\n    print('count: %s' % (obj.get_count())) # Nilai dari variabel count (akan selalu 3)\n\nval of obj: 9\ncount: 3\nval of obj: 18\ncount: 3\nval of obj: 27\ncount: 3\n\n\n\n\n\nSalah satu keuntungan dari OOP adalah kemampuannya untuk me-reuse sesuatu. Salah satu mekanismenya adalah inheritance. Inheritance adalah mekanisme yang membuat para programmer dapat membuat suatu class dasar, lalu diperluas ke class yang lebih specific. Dengan kata lain, kita dapat membuat class di dalam class.\nMenggunakan inheritance ini, kita dapat menggunakan data pada class dasar, lalu ditambah data yang spesifik pada class spesifik.\nDalam terminologi OOP, ketika suatu class X memperluas class Y, maka Y disebut sebagai superclass/parent class/base class, dan X disebut sebagai subclass/child class/derived class.\nSyntax dari derived class ini adalah:\nclass BaseClass:\n    &lt;body&gt;\nclass DerivedClass(BaseClass):\n    &lt;body&gt;\nInstansi pada derived class dapat mengakses atribut pada base class:\n\nclass Date:\n    def get_date(self):\n        return '11-10-2022'\n\nclass Time(Date):\n    def get_time(self):\n        return '08:30'\n\n\ndt = Date()\nprint('Data dari class Date: ', dt.get_date())\ntm = Time()\nprint('Data dari class Time: ', tm.get_time())\n\n# Memanggil get date dari instansi Time\nprint('Data dari class Date, dipanggil dari class Time: ', tm.get_date())\n\nData dari class Date:  11-10-2022\nData dari class Time:  08:30\nData dari class Date, dipanggil dari class Time:  11-10-2022\n\n\nHierarki untuk lookup atribut dari suatu instansi:\n\nInstansi\nClass\nParent class yang mem-parent-kan class sebelumnya\n\nSebagai contoh, kita akan membuat beberapa class.\n\nPokemon: Kelas yang berisi Pokemon (ceritanya)\nFlying: Subclass dari Pokemon\nGround: Subclass dari Pokemon\n\nKonstruktor dari subclass akan selalu memanggil konstruktor parent class nya terlebi dahulu, lalu meng-assign attribut untuk subclass tersebut.\n\nclass Pokemon:\n\n    def __init__(self, name):\n        self.name = name\n    def faint(self):\n        print('%s fainted.' % (self.name))\n\nclass Flying(Pokemon):\n    def SkyAttack(self):\n        print('%s used Sky Attack' % (self.name))\n\nclass Ground(Pokemon):\n    def Eartquake(self):\n        print('%s used Earthquake' % (self.name))\n\n\nf = Flying('Moltres')\ng = Ground('Diglett')\n\n# Akses class sendiri\nf.SkyAttack()\ng.Eartquake()\n\n# Akses parent class\nf.faint()\ng.faint()\n\nMoltres used Sky Attack\nDiglett used Earthquake\nMoltres fainted.\nDiglett fainted.\n\n\n\n# Error karena tidak bisa mengakses class\nf.Eartquake\n\nAttributeError: 'Flying' object has no attribute 'Eartquake'"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html#class",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html#class",
    "title": "Modul 3 | Pengenalan class",
    "section": "",
    "text": "Class dapat digambarkan sebagai pabrik dari suatu objek. Dengan kata lain, class mengandung blueprint yang menggambarkan cara membuat objek tersebut. Setiap objek (atau instansi) akan mempunyai atribut dan method. Atribut adalah variabel yang menggambarkan karakteristik dari objek tersebut, dan method adalah fungsi yang dapat dilakukan oleh objek tersebut.\nSyntax untuk membuat class pada Python adalah:\nclass ClassName:\n    &lt;statement&gt;\n    &lt;statement&gt;\n    .\n    .\n    .\n    &lt;statement&gt;\nSebagai contoh, kita akan membuat suatu class kosong menggunakan syntax pass.\n\nclass MyClass:\n    pass\n\nPada contoh di atas, MyClass adalah nama dari class, dan pass adalah salah satu statement pada class tersebut. Untuk membuat suatu instansi dari class yang telah kita buat, mirip seperti memanggil fungsi:\n\nobj_1 = MyClass()\nprint(obj_1)\nobj_2 = MyClass()\nprint(obj_2)\n\n&lt;__main__.MyClass object at 0x1058f6cb0&gt;\n&lt;__main__.MyClass object at 0x1057cebc0&gt;\n\n\nKedua variabel tersebut adalah instansi dari MyClass yang telah kita buat. Kode hex di akhir print adalah address dari instansi tersebut pada memori.\nSekarang kita akan mendefinisikan variabel pada kelas MyClass:\n\nclass MyClass:\n    var = 9\n\nUntuk memanggil variabel tersebut, kita panggil instansi yang telah dibuat, diikuti dengan titik, lalu nama variabel tersebut\n\nobj_1 = MyClass()\nprint(obj_1.var)\n\nobj_2 = MyClass()\nprint(obj_2.var)\n\n9\n9"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html#method-instansi",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html#method-instansi",
    "title": "Modul 3 | Pengenalan class",
    "section": "",
    "text": "Suatu fungsi yang didefinisikan pada class disebut method. Suatu method dari instansi membutuhkan instansi tersebut agar bisa dipanggil. Dalam membuat method, parameter pertama selalu self. self adalah parameter dari instansi yang dibuat.\n\nclass MyClass:\n    var = 9\n\n    def firstM(self):\n        print('hello, World')\n\n\nobj = MyClass()\nprint(obj.var)\nobj.firstM()\n\n9\nhello, World"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html#enkapsulasi",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html#enkapsulasi",
    "title": "Modul 3 | Pengenalan class",
    "section": "",
    "text": "Enkapsulasi adalah salah satu teknik fundamental pada OOP. Enkapsulasi memberikan mekanisme dalam me-restrict akses ke beberapa komponen dari objek. Aksesnya biasanya diambil dari metode yang umumnya disebut getters and setters.\n\nclass MyClass:\n    def setAge(self, num):\n        self.age = num\n    \n    def getAge(self):\n        return self.age\n\n\nkobo = MyClass()\nkobo.setAge(20)\nprint(kobo.getAge())\n\n20"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html#init__",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html#init__",
    "title": "Modul 3 | Pengenalan class",
    "section": "",
    "text": "__init__, sesuai namanya, adala inisialisasi dari suatu class. __init__ akan dipanggil langsung setela suatu instansi dibuat. __init__ juga terkadang disebut sebagai konstruktor.\nBanyak class yang lebih baik membuat objek yang sudah mempunyai suatu initial state. Di sinilah __init__ digunakan:\n\nclass MyClass:\n    def __init__(self, aaa, bbb):\n        self.a = aaa\n        self.b = bbb\n\nUntuk memanggil konstruktor __init__ nya, kita berikan parameter yang sesuai saat membuat instansi baru (dalam contoh di atas berarti aaa dan bbb).\n\nx = MyClass(4.5, 3)\nprint(x.a, x.b)\n\n4.5 3"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html#atribut-class",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html#atribut-class",
    "title": "Modul 3 | Pengenalan class",
    "section": "",
    "text": "Atribut yang didefinisikan pada class akan disebut sebagai atribut class, dan atribut yang didefinisikan pada fungsi, atau atribut yang didefinisikan untuk instansi akan disebut ‘atribut instansi’. Saat pendefinisian, atribut ini tidak menggunakan prefix self, karena merupakan atribut dari suatu class dan bukan atribut dari suatu instansi.\nAtribut class dapat diakses oleh class itu sendiri (class attribute) ataupun oleh suatu instansi (instance attribute). Dengan kata lain, suatu instansi dapat mengakses atribut instansi sekaligus atribut kelas.\n\nclass myclass:\n    age = 21\n\n\nmyclass.age\n\n21\n\n\n\nx = myclass()\nx.age\n\n21\n\n\nAtribut class dapat ditimpa pada instansi\n\nclass myclass:\n    classy = 'Class Attrib'\n\n\ndd = myclass()\nprint(dd.classy)\n\nClass Attrib"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html#data-class-dan-data-instansi",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html#data-class-dan-data-instansi",
    "title": "Modul 3 | Pengenalan class",
    "section": "",
    "text": "Pada magian ini, akan dijelaskan bagaimana data class berhubungan dengan data instansi. Kita dapat menyimpan suatu data baik pada class maupun pada instansi. Ketika kita membuat suatu class, kita menentukan apaka suatu data lebih cocok disimpan di instansi atau di kelas.\nSuatu instansi dapat mengakses data class yang membuatnya. Ketika kita membuat banyak instansi, maka instansi-instansi tersebut dapat mengakses atribut instansinya masing-masing, serta mengakses data class keseluruhan. Maka, data class adalah data yang dapat diakses semua instansi yang dimuat di class tersebut.\n\nclass InstanceCounter:\n    count = 0  # Atribut class, dapat diakses oleh semua instansi\n\n    def __init__(self, val):\n        self.val = val\n        InstanceCounter.count += 1 # Menambahkan value dari atribut class\n    \n    def set_val(self, newval):\n        self.val = newval\n    \n    def get_val(self):\n        return self.val\n\n    def get_count(self):\n        return InstanceCounter.count\n\n\na = InstanceCounter(9)\nb = InstanceCounter(18)\nc = InstanceCounter(27)\n\nfor obj in (a, b, c):\n    print('val of obj: %s' % (obj.get_val())) # Nilai inisialisasi (9, 18, 27)\n    print('count: %s' % (obj.get_count())) # Nilai dari variabel count (akan selalu 3)\n\nval of obj: 9\ncount: 3\nval of obj: 18\ncount: 3\nval of obj: 27\ncount: 3"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html#inheritance",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul03.html#inheritance",
    "title": "Modul 3 | Pengenalan class",
    "section": "",
    "text": "Salah satu keuntungan dari OOP adalah kemampuannya untuk me-reuse sesuatu. Salah satu mekanismenya adalah inheritance. Inheritance adalah mekanisme yang membuat para programmer dapat membuat suatu class dasar, lalu diperluas ke class yang lebih specific. Dengan kata lain, kita dapat membuat class di dalam class.\nMenggunakan inheritance ini, kita dapat menggunakan data pada class dasar, lalu ditambah data yang spesifik pada class spesifik.\nDalam terminologi OOP, ketika suatu class X memperluas class Y, maka Y disebut sebagai superclass/parent class/base class, dan X disebut sebagai subclass/child class/derived class.\nSyntax dari derived class ini adalah:\nclass BaseClass:\n    &lt;body&gt;\nclass DerivedClass(BaseClass):\n    &lt;body&gt;\nInstansi pada derived class dapat mengakses atribut pada base class:\n\nclass Date:\n    def get_date(self):\n        return '11-10-2022'\n\nclass Time(Date):\n    def get_time(self):\n        return '08:30'\n\n\ndt = Date()\nprint('Data dari class Date: ', dt.get_date())\ntm = Time()\nprint('Data dari class Time: ', tm.get_time())\n\n# Memanggil get date dari instansi Time\nprint('Data dari class Date, dipanggil dari class Time: ', tm.get_date())\n\nData dari class Date:  11-10-2022\nData dari class Time:  08:30\nData dari class Date, dipanggil dari class Time:  11-10-2022\n\n\nHierarki untuk lookup atribut dari suatu instansi:\n\nInstansi\nClass\nParent class yang mem-parent-kan class sebelumnya\n\nSebagai contoh, kita akan membuat beberapa class.\n\nPokemon: Kelas yang berisi Pokemon (ceritanya)\nFlying: Subclass dari Pokemon\nGround: Subclass dari Pokemon\n\nKonstruktor dari subclass akan selalu memanggil konstruktor parent class nya terlebi dahulu, lalu meng-assign attribut untuk subclass tersebut.\n\nclass Pokemon:\n\n    def __init__(self, name):\n        self.name = name\n    def faint(self):\n        print('%s fainted.' % (self.name))\n\nclass Flying(Pokemon):\n    def SkyAttack(self):\n        print('%s used Sky Attack' % (self.name))\n\nclass Ground(Pokemon):\n    def Eartquake(self):\n        print('%s used Earthquake' % (self.name))\n\n\nf = Flying('Moltres')\ng = Ground('Diglett')\n\n# Akses class sendiri\nf.SkyAttack()\ng.Eartquake()\n\n# Akses parent class\nf.faint()\ng.faint()\n\nMoltres used Sky Attack\nDiglett used Earthquake\nMoltres fainted.\nDiglett fainted.\n\n\n\n# Error karena tidak bisa mengakses class\nf.Eartquake\n\nAttributeError: 'Flying' object has no attribute 'Eartquake'"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul05.html",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul05.html",
    "title": "Modul 5 | Tree (1)",
    "section": "",
    "text": "Kembali ke Struktur Data\nTree adalah struktur data yang jenisnya hierarki. Tree terdiri dari sebuah node yang terhubung dengan node lain tanpa membuat suatu cycle. Hubungan antar node pada tree adalah berupa parent dan child. Satu node bisa menjadi parent dari banyak child, namun, setiap child hanya mempunyai satu parent. Pada praktikum kali ini, akan dibuat dua jenis tree, yaitu binary tree dan binary search tree.\n\n\nBinary tree adalah tree yang tiap parent hanya memiliki maksimum dua child. Umumnya, kedua child tersebut dinamakan left child dan right child.\nDalam pendefinisian binary tree yang akan kita buat, tree akan dibentuk menggunakan dict, dan node-nya adalah elemen dari dict tersebut, dengan key-nya melambangkan suatu node, dan value-nya terdiri dari 3 nilai, yaitu parent, left child, dan right child\nPertama, akan dibuat class dengan __init__ terlebih dahulu, yang akan mengkonstruksi binary tree kosong.\n\nclass BinaryTree:\n    def __init__(self):\n        self.tree = {}\n        self.root = None\n\n\n    def is_empty(self):\n        return self.root is None\n\n    def is_root(self, val):\n        return self.root == val\n\n    def parent(self, val):\n        return self.tree[val][0]\n\n    def left_child(self, val):\n        return self.tree[val][1]\n\n    def right_child(self, val):\n        return self.tree[val][2]\n\n    def is_leaf(self, val):\n        return self.tree[val][1:3] == [None, None]\n\n    def sibling(self, val):\n        par = self.tree[val][0]\n        if self.left_child(par) == val:\n            return self.right_child(par)\n        return self.left_child(par)\n\n\n    def add(self, par, val, pos):\n        if self.is_empty():\n            self.tree[val] = [None, None, None]\n            self.root = val\n            return\n        if val in self.tree:\n            print('Element already exists.')\n            return\n        if par not in self.tree:\n            print('Parent doesn\\'t exist')\n            return\n        if pos == 'l':\n            self.tree[par][1] = val\n        if pos == 'r':\n            self.tree[par][2] = val\n        self.tree[val] = [par, None, None]\n\n\n    def rem(self, val):\n        if val not in self.tree:\n            print('Element doesn\\'t exist')\n            return\n        if not self.is_leaf(val):\n            print('Element has a child. Pick a leaf node instead.')\n            return\n        par = self.tree[val][0]\n        for i in range(1, 3):\n            if self.tree[par][i] == val:\n                self.tree[par][i] = None\n        del self.tree[val]\n        if val == self.root:\n            self.root = None\n\n\n    def preorder(self, root, lis = []):\n        lis.append(root)\n        lchild = self.left_child(root)\n        if lchild != None:\n            self.preorder(lchild)\n        rchild = self.right_child(root)\n        if rchild != None:\n            self.preorder(rchild)\n        return lis\n    \n    def inorder(self, root, lis = []):\n        lchild = self.left_child(root)\n        if lchild != None:\n            self.inorder(lchild)\n        lis.append(root)\n        rchild = self.right_child(root)\n        if rchild != None:\n            self.inorder(rchild)\n        return lis\n    \n    def postorder(self, root, lis = []):\n        lchild = self.left_child(root)\n        if lchild != None:\n            self.postorder(lchild)\n        rchild = self.right_child(root)\n        if rchild != None:\n            self.postorder(rchild)\n        lis.append(root)\n        return lis\n\nMaka pada akhirnya kita akan mendapatkan class utuh berikut:\n\nclass BinaryTree:\n    def __init__(self):\n        self.tree = {}\n        self.root = None\n\n    def is_empty(self):\n        return self.root is None\n\n    def is_root(self, val):\n        return self.root == val\n\n    def parent(self, val):\n        return self.tree[val][0]\n\n    def left_child(self, val):\n        return self.tree[val][1]\n\n    def right_child(self, val):\n        return self.tree[val][2]\n\n    def is_leaf(self, val):\n        return self.tree[val][1:3] == [None, None]\n\n    def sibling(self, val):\n        par = self.tree[val][0]\n        if self.left_child(par) == val:\n            return self.right_child(par)\n        return self.left_child(par)\n    \n    def add(self, par, val, pos):\n        if self.is_empty():\n            self.tree[val] = [None, None, None]\n            self.root = val\n            return\n        if val in self.tree:\n            print('Element already exists.')\n            return\n        if par not in self.tree:\n            print('Parent doesn\\'t exist')\n            return\n        if pos == 'l':\n            self.tree[par][1] = val\n        if pos == 'r':\n            self.tree[par][2] = val\n        self.tree[val] = [par, None, None]\n    \n    def rem(self, val):\n        if val not in self.tree:\n            print('Element doesn\\'t exist')\n            return\n        if not self.is_leaf(val):\n            print('Element has a child. Pick a leaf node instead.')\n            return\n        par = self.tree[val][0]\n        for i in range(1, 3):\n            if self.tree[par][i] == val:\n                self.tree[par][i] = None\n        del self.tree[val]\n        if val == self.root:\n            self.root = None\n    \n    def preorder(self, root, lis = []):\n        lis.append(root)\n        lchild = self.left_child(root)\n        if lchild != None:\n            self.preorder(lchild)\n        rchild = self.right_child(root)\n        if rchild != None:\n            self.preorder(rchild)\n        return lis\n    \n    def inorder(self, root, lis = []):\n        lchild = self.left_child(root)\n        if lchild != None:\n            self.inorder(lchild)\n        lis.append(root)\n        rchild = self.right_child(root)\n        if rchild != None:\n            self.inorder(rchild)\n        return lis\n    \n    def postorder(self, root, lis = []):\n        lchild = self.left_child(root)\n        if lchild != None:\n            self.postorder(lchild)\n        rchild = self.right_child(root)\n        if rchild != None:\n            self.postorder(rchild)\n        lis.append(root)\n        return lis\n\nSekarang akan kita coba.\n\nT = BinaryTree()\n\n\nT.add(None, 12, None) # karena root, maka yang dibaca hanya value tengah\nT.add(12, 15, 'l')\nT.add(12, 18, 'r')\nT.add(14, 21, 'l') # akan meng-print pesan kesalahan karena 14 tidak ada di tree.\n\nParent doesn't exist\n\n\n\nprint(T.tree)\n\n{12: [None, 15, 18], 15: [12, None, None], 18: [12, None, None]}\n\n\n\nT.rem(12) # Tidak bisa karena bukan leaf node\n\nElement has a child. Pick a leaf node instead.\n\n\n\nT.rem(15)\nprint(T.tree)\n\n{12: [None, None, 18], 18: [12, None, None]}\n\n\n\nT.add(12, 15, 'l')\nT.add(15, 21, 'l')\nT.add(15, 24, 'r')\nT.add(18, 27, 'l')\nprint(T.tree)\n\n{12: [None, 15, 18], 18: [12, 27, None], 15: [12, 21, 24], 21: [15, None, None], 24: [15, None, None], 27: [18, None, None]}\n\n\n\nprint(T.is_root(12))\nprint(T.is_root(24))\n\nTrue\nFalse\n\n\n\nprint(T.sibling(12)) # Root tidak punya sibling\n\nKeyError: None\n\n\n\nprint(T.tree)\n\n{12: [None, 15, 18], 18: [12, 27, None], 15: [12, 21, 24], 21: [15, None, None], 24: [15, None, None], 27: [18, None, None]}\n\n\n\nprint(T.preorder(T.root)) # hasil print: 12, 15, 21, 24, 18, 27\nprint(T.inorder(T.root)) # hasil print: 21, 15, 24, 12, 18, 27\nprint(T.postorder(T.root)) # hasil print: 21, 24, 15, 27, 18, 12\n\n[12, 15, 21, 24, 18, 27]\n[21, 15, 24, 12, 27, 18]\n[21, 24, 15, 27, 18, 12]\n\n\n\n\n\nBinary search tree adalah binary tree yang nilai left child-nya lebih kecil dari parent-nya, dan nilai right child-nya lebih besar dari parent-nya. Umumnya, binary search tree dibuat dari suatu list angka.\nBerikut adalah class yang digunakan untuk membuat binary search tree. Karena hasil dari binary search tree sejatinya adalah binary tree, maka kita akan meng-inherit yang telah kita buat sebelumnya, namun dengan mengubah __init__ nya agar dapat langsung membuat binary tree saat __init__\n\nclass BinarySearchTree(BinaryTree):\n    def __init__(self, lis):\n        self.tree = {}\n        self.root = None\n        self.add(None, lis[0], None)\n        for i in range(1, len(lis)):\n            root = self.root\n            while True:\n                if lis[i] &lt; root:\n                    if self.left_child(root) is None:\n                        self.add(root, lis[i], 'l')\n                        break\n                    else:\n                        root = self.left_child(root)\n                else:\n                    if self.right_child(root) is None:\n                        self.add(root, lis[i], 'r')\n                        break\n                    else:\n                        root = self.right_child(root)\n\nSesuai namanya, binary search tree digunakan untuk binary search. Berikut algoritma binary search menggunakan binary search tree.\n\ndef search(self, val):\n    root = self.root\n    while True:\n        if val &lt; root:\n            if self.left_child(root) is None:\n                print('Element is not in the tree')\n                return\n            else:\n                root = self.left_child(root)\n        elif val &gt; root:\n            if self.right_child(root) is None:\n                print('Element is not in the tree')\n                return\n            else:\n                root = self.right_child(root)\n        else:\n            return val\n\nMaka, hasil akhir class-nya adalah sebagai berikut:\n\nclass BinarySearchTree(BinaryTree):\n    def __init__(self, lis):\n        self.tree = {}\n        self.root = None\n        self.add(None, lis[0], None)\n        for i in range(1, len(lis)):\n            root = self.root\n            while True:\n                if lis[i] &lt; root:\n                    if self.left_child(root) is None:\n                        self.add(root, lis[i], 'l')\n                        break\n                    else:\n                        root = self.left_child(root)\n                else:\n                    if self.right_child(root) is None:\n                        self.add(root, lis[i], 'r')\n                        break\n                    else:\n                        root = self.right_child(root)\n\n    def search(self, val):\n        root = self.root\n        while True:\n            if val &lt; root:\n                if self.left_child(root) is None:\n                    print('Element is not in the tree')\n                    return\n                else:\n                    root = self.left_child(root)\n            elif val &gt; root:\n                if self.right_child(root) is None:\n                    print('Element is not in the tree')\n                    return\n                else:\n                    root = self.right_child(root)\n            else:\n                return val\n\nSekarang akan kita coba membuat binary search tree.\n\nC = BinarySearchTree([23, 10, 12, 5, 4, 91, 18, 2, 28])\n\nKarena BinarySearchTree meng-inherit dari BinaryTree, kita dapat menggunakan method yang ada pada BinryTree di BinarySearchTree\n\nprint(C.tree)\n\n{23: [None, 10, 91], 10: [23, 5, 12], 12: [10, None, 18], 5: [10, 4, None], 4: [5, 2, None], 91: [23, 28, None], 18: [12, None, None], 2: [4, None, None], 28: [91, None, None]}\n\n\n\nC.is_root(23)\n\nTrue\n\n\n\nC.is_leaf(18)\n\nTrue\n\n\nSekarang akan kita coba searching.\n\nC.search(18)\n\n18\n\n\n\nC.search(15) # tidak ada di binary search tree\n\nElement is not in the tree"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul05.html#binary-tree",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul05.html#binary-tree",
    "title": "Modul 5 | Tree (1)",
    "section": "",
    "text": "Binary tree adalah tree yang tiap parent hanya memiliki maksimum dua child. Umumnya, kedua child tersebut dinamakan left child dan right child.\nDalam pendefinisian binary tree yang akan kita buat, tree akan dibentuk menggunakan dict, dan node-nya adalah elemen dari dict tersebut, dengan key-nya melambangkan suatu node, dan value-nya terdiri dari 3 nilai, yaitu parent, left child, dan right child\nPertama, akan dibuat class dengan __init__ terlebih dahulu, yang akan mengkonstruksi binary tree kosong.\n\nclass BinaryTree:\n    def __init__(self):\n        self.tree = {}\n        self.root = None\n\n\n    def is_empty(self):\n        return self.root is None\n\n    def is_root(self, val):\n        return self.root == val\n\n    def parent(self, val):\n        return self.tree[val][0]\n\n    def left_child(self, val):\n        return self.tree[val][1]\n\n    def right_child(self, val):\n        return self.tree[val][2]\n\n    def is_leaf(self, val):\n        return self.tree[val][1:3] == [None, None]\n\n    def sibling(self, val):\n        par = self.tree[val][0]\n        if self.left_child(par) == val:\n            return self.right_child(par)\n        return self.left_child(par)\n\n\n    def add(self, par, val, pos):\n        if self.is_empty():\n            self.tree[val] = [None, None, None]\n            self.root = val\n            return\n        if val in self.tree:\n            print('Element already exists.')\n            return\n        if par not in self.tree:\n            print('Parent doesn\\'t exist')\n            return\n        if pos == 'l':\n            self.tree[par][1] = val\n        if pos == 'r':\n            self.tree[par][2] = val\n        self.tree[val] = [par, None, None]\n\n\n    def rem(self, val):\n        if val not in self.tree:\n            print('Element doesn\\'t exist')\n            return\n        if not self.is_leaf(val):\n            print('Element has a child. Pick a leaf node instead.')\n            return\n        par = self.tree[val][0]\n        for i in range(1, 3):\n            if self.tree[par][i] == val:\n                self.tree[par][i] = None\n        del self.tree[val]\n        if val == self.root:\n            self.root = None\n\n\n    def preorder(self, root, lis = []):\n        lis.append(root)\n        lchild = self.left_child(root)\n        if lchild != None:\n            self.preorder(lchild)\n        rchild = self.right_child(root)\n        if rchild != None:\n            self.preorder(rchild)\n        return lis\n    \n    def inorder(self, root, lis = []):\n        lchild = self.left_child(root)\n        if lchild != None:\n            self.inorder(lchild)\n        lis.append(root)\n        rchild = self.right_child(root)\n        if rchild != None:\n            self.inorder(rchild)\n        return lis\n    \n    def postorder(self, root, lis = []):\n        lchild = self.left_child(root)\n        if lchild != None:\n            self.postorder(lchild)\n        rchild = self.right_child(root)\n        if rchild != None:\n            self.postorder(rchild)\n        lis.append(root)\n        return lis\n\nMaka pada akhirnya kita akan mendapatkan class utuh berikut:\n\nclass BinaryTree:\n    def __init__(self):\n        self.tree = {}\n        self.root = None\n\n    def is_empty(self):\n        return self.root is None\n\n    def is_root(self, val):\n        return self.root == val\n\n    def parent(self, val):\n        return self.tree[val][0]\n\n    def left_child(self, val):\n        return self.tree[val][1]\n\n    def right_child(self, val):\n        return self.tree[val][2]\n\n    def is_leaf(self, val):\n        return self.tree[val][1:3] == [None, None]\n\n    def sibling(self, val):\n        par = self.tree[val][0]\n        if self.left_child(par) == val:\n            return self.right_child(par)\n        return self.left_child(par)\n    \n    def add(self, par, val, pos):\n        if self.is_empty():\n            self.tree[val] = [None, None, None]\n            self.root = val\n            return\n        if val in self.tree:\n            print('Element already exists.')\n            return\n        if par not in self.tree:\n            print('Parent doesn\\'t exist')\n            return\n        if pos == 'l':\n            self.tree[par][1] = val\n        if pos == 'r':\n            self.tree[par][2] = val\n        self.tree[val] = [par, None, None]\n    \n    def rem(self, val):\n        if val not in self.tree:\n            print('Element doesn\\'t exist')\n            return\n        if not self.is_leaf(val):\n            print('Element has a child. Pick a leaf node instead.')\n            return\n        par = self.tree[val][0]\n        for i in range(1, 3):\n            if self.tree[par][i] == val:\n                self.tree[par][i] = None\n        del self.tree[val]\n        if val == self.root:\n            self.root = None\n    \n    def preorder(self, root, lis = []):\n        lis.append(root)\n        lchild = self.left_child(root)\n        if lchild != None:\n            self.preorder(lchild)\n        rchild = self.right_child(root)\n        if rchild != None:\n            self.preorder(rchild)\n        return lis\n    \n    def inorder(self, root, lis = []):\n        lchild = self.left_child(root)\n        if lchild != None:\n            self.inorder(lchild)\n        lis.append(root)\n        rchild = self.right_child(root)\n        if rchild != None:\n            self.inorder(rchild)\n        return lis\n    \n    def postorder(self, root, lis = []):\n        lchild = self.left_child(root)\n        if lchild != None:\n            self.postorder(lchild)\n        rchild = self.right_child(root)\n        if rchild != None:\n            self.postorder(rchild)\n        lis.append(root)\n        return lis\n\nSekarang akan kita coba.\n\nT = BinaryTree()\n\n\nT.add(None, 12, None) # karena root, maka yang dibaca hanya value tengah\nT.add(12, 15, 'l')\nT.add(12, 18, 'r')\nT.add(14, 21, 'l') # akan meng-print pesan kesalahan karena 14 tidak ada di tree.\n\nParent doesn't exist\n\n\n\nprint(T.tree)\n\n{12: [None, 15, 18], 15: [12, None, None], 18: [12, None, None]}\n\n\n\nT.rem(12) # Tidak bisa karena bukan leaf node\n\nElement has a child. Pick a leaf node instead.\n\n\n\nT.rem(15)\nprint(T.tree)\n\n{12: [None, None, 18], 18: [12, None, None]}\n\n\n\nT.add(12, 15, 'l')\nT.add(15, 21, 'l')\nT.add(15, 24, 'r')\nT.add(18, 27, 'l')\nprint(T.tree)\n\n{12: [None, 15, 18], 18: [12, 27, None], 15: [12, 21, 24], 21: [15, None, None], 24: [15, None, None], 27: [18, None, None]}\n\n\n\nprint(T.is_root(12))\nprint(T.is_root(24))\n\nTrue\nFalse\n\n\n\nprint(T.sibling(12)) # Root tidak punya sibling\n\nKeyError: None\n\n\n\nprint(T.tree)\n\n{12: [None, 15, 18], 18: [12, 27, None], 15: [12, 21, 24], 21: [15, None, None], 24: [15, None, None], 27: [18, None, None]}\n\n\n\nprint(T.preorder(T.root)) # hasil print: 12, 15, 21, 24, 18, 27\nprint(T.inorder(T.root)) # hasil print: 21, 15, 24, 12, 18, 27\nprint(T.postorder(T.root)) # hasil print: 21, 24, 15, 27, 18, 12\n\n[12, 15, 21, 24, 18, 27]\n[21, 15, 24, 12, 27, 18]\n[21, 24, 15, 27, 18, 12]"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul05.html#binary-search-tree",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul05.html#binary-search-tree",
    "title": "Modul 5 | Tree (1)",
    "section": "",
    "text": "Binary search tree adalah binary tree yang nilai left child-nya lebih kecil dari parent-nya, dan nilai right child-nya lebih besar dari parent-nya. Umumnya, binary search tree dibuat dari suatu list angka.\nBerikut adalah class yang digunakan untuk membuat binary search tree. Karena hasil dari binary search tree sejatinya adalah binary tree, maka kita akan meng-inherit yang telah kita buat sebelumnya, namun dengan mengubah __init__ nya agar dapat langsung membuat binary tree saat __init__\n\nclass BinarySearchTree(BinaryTree):\n    def __init__(self, lis):\n        self.tree = {}\n        self.root = None\n        self.add(None, lis[0], None)\n        for i in range(1, len(lis)):\n            root = self.root\n            while True:\n                if lis[i] &lt; root:\n                    if self.left_child(root) is None:\n                        self.add(root, lis[i], 'l')\n                        break\n                    else:\n                        root = self.left_child(root)\n                else:\n                    if self.right_child(root) is None:\n                        self.add(root, lis[i], 'r')\n                        break\n                    else:\n                        root = self.right_child(root)\n\nSesuai namanya, binary search tree digunakan untuk binary search. Berikut algoritma binary search menggunakan binary search tree.\n\ndef search(self, val):\n    root = self.root\n    while True:\n        if val &lt; root:\n            if self.left_child(root) is None:\n                print('Element is not in the tree')\n                return\n            else:\n                root = self.left_child(root)\n        elif val &gt; root:\n            if self.right_child(root) is None:\n                print('Element is not in the tree')\n                return\n            else:\n                root = self.right_child(root)\n        else:\n            return val\n\nMaka, hasil akhir class-nya adalah sebagai berikut:\n\nclass BinarySearchTree(BinaryTree):\n    def __init__(self, lis):\n        self.tree = {}\n        self.root = None\n        self.add(None, lis[0], None)\n        for i in range(1, len(lis)):\n            root = self.root\n            while True:\n                if lis[i] &lt; root:\n                    if self.left_child(root) is None:\n                        self.add(root, lis[i], 'l')\n                        break\n                    else:\n                        root = self.left_child(root)\n                else:\n                    if self.right_child(root) is None:\n                        self.add(root, lis[i], 'r')\n                        break\n                    else:\n                        root = self.right_child(root)\n\n    def search(self, val):\n        root = self.root\n        while True:\n            if val &lt; root:\n                if self.left_child(root) is None:\n                    print('Element is not in the tree')\n                    return\n                else:\n                    root = self.left_child(root)\n            elif val &gt; root:\n                if self.right_child(root) is None:\n                    print('Element is not in the tree')\n                    return\n                else:\n                    root = self.right_child(root)\n            else:\n                return val\n\nSekarang akan kita coba membuat binary search tree.\n\nC = BinarySearchTree([23, 10, 12, 5, 4, 91, 18, 2, 28])\n\nKarena BinarySearchTree meng-inherit dari BinaryTree, kita dapat menggunakan method yang ada pada BinryTree di BinarySearchTree\n\nprint(C.tree)\n\n{23: [None, 10, 91], 10: [23, 5, 12], 12: [10, None, 18], 5: [10, 4, None], 4: [5, 2, None], 91: [23, 28, None], 18: [12, None, None], 2: [4, None, None], 28: [91, None, None]}\n\n\n\nC.is_root(23)\n\nTrue\n\n\n\nC.is_leaf(18)\n\nTrue\n\n\nSekarang akan kita coba searching.\n\nC.search(18)\n\n18\n\n\n\nC.search(15) # tidak ada di binary search tree\n\nElement is not in the tree"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul2.html",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul2.html",
    "title": "MODUL 2 PRAKTIKUM SAINS DATA",
    "section": "",
    "text": "Kembali ke Sains Data\n\n\n\nRegresi Linier Sederhana\nRegresi Linier Berganda"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#import-module",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#import-module",
    "title": "MODUL 2 PRAKTIKUM SAINS DATA",
    "section": "Import Module",
    "text": "Import Module\n\n#import module dan package yang diperlukan\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport pylab as pl\nimport numpy as np\n%matplotlib inline"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#import-data",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#import-data",
    "title": "MODUL 2 PRAKTIKUM SAINS DATA",
    "section": "Import Data",
    "text": "Import Data\nPada module kali ini, akan digunakan data csv Fuel Consumption of CO2 (FuelConsumptionCo2.csv) yang bisa didownload dari:\n\nKaggle\n\n\ndf = pd.read_csv('/content/FuelConsumptionCo2.csv')\n\n\n#lihat cuplikan data dari dataframe\ndf.head()\n\n\n  \n    \n\n\n\n\n\n\nMODELYEAR\nMAKE\nMODEL\nVEHICLECLASS\nENGINESIZE\nCYLINDERS\nTRANSMISSION\nFUELTYPE\nFUELCONSUMPTION_CITY\nFUELCONSUMPTION_HWY\nFUELCONSUMPTION_COMB\nFUELCONSUMPTION_COMB_MPG\nCO2EMISSIONS\n\n\n\n\n0\n2014\nACURA\nILX\nCOMPACT\n2.0\n4\nAS5\nZ\n9.9\n6.7\n8.5\n33\n196\n\n\n1\n2014\nACURA\nILX\nCOMPACT\n2.4\n4\nM6\nZ\n11.2\n7.7\n9.6\n29\n221\n\n\n2\n2014\nACURA\nILX HYBRID\nCOMPACT\n1.5\n4\nAV7\nZ\n6.0\n5.8\n5.9\n48\n136\n\n\n3\n2014\nACURA\nMDX 4WD\nSUV - SMALL\n3.5\n6\nAS6\nZ\n12.7\n9.1\n11.1\n25\n255\n\n\n4\n2014\nACURA\nRDX AWD\nSUV - SMALL\n3.5\n6\nAS6\nZ\n12.1\n8.7\n10.6\n27\n244\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nKali ini kita akan membuat model regresi linear untuk memprediksi nilai dari CO2EMISSION"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#eksplorasi-data",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#eksplorasi-data",
    "title": "MODUL 2 PRAKTIKUM SAINS DATA",
    "section": "Eksplorasi Data",
    "text": "Eksplorasi Data\nStatistik deskriptif dari data frame\n\ndf.describe()\n\n\n  \n    \n\n\n\n\n\n\nMODELYEAR\nENGINESIZE\nCYLINDERS\nFUELCONSUMPTION_CITY\nFUELCONSUMPTION_HWY\nFUELCONSUMPTION_COMB\nFUELCONSUMPTION_COMB_MPG\nCO2EMISSIONS\n\n\n\n\ncount\n1067.0\n1067.000000\n1067.000000\n1067.000000\n1067.000000\n1067.000000\n1067.000000\n1067.000000\n\n\nmean\n2014.0\n3.346298\n5.794752\n13.296532\n9.474602\n11.580881\n26.441425\n256.228679\n\n\nstd\n0.0\n1.415895\n1.797447\n4.101253\n2.794510\n3.485595\n7.468702\n63.372304\n\n\nmin\n2014.0\n1.000000\n3.000000\n4.600000\n4.900000\n4.700000\n11.000000\n108.000000\n\n\n25%\n2014.0\n2.000000\n4.000000\n10.250000\n7.500000\n9.000000\n21.000000\n207.000000\n\n\n50%\n2014.0\n3.400000\n6.000000\n12.600000\n8.800000\n10.900000\n26.000000\n251.000000\n\n\n75%\n2014.0\n4.300000\n8.000000\n15.550000\n10.850000\n13.350000\n31.000000\n294.000000\n\n\nmax\n2014.0\n8.400000\n12.000000\n30.200000\n20.500000\n25.800000\n60.000000\n488.000000\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nKita dapat memilih beberapa feature/kolom yang kita duga berpengaruh terhadap nilai dari CO2EMISSION\n\n #definisikan dataframe baru bernama cdf\ncdf = df[['ENGINESIZE', 'CYLINDERS', 'FUELCONSUMPTION_COMB', 'CO2EMISSIONS']]\ncdf.head(9)\n\n\n  \n    \n\n\n\n\n\n\nENGINESIZE\nCYLINDERS\nFUELCONSUMPTION_COMB\nCO2EMISSIONS\n\n\n\n\n0\n2.0\n4\n8.5\n196\n\n\n1\n2.4\n4\n9.6\n221\n\n\n2\n1.5\n4\n5.9\n136\n\n\n3\n3.5\n6\n11.1\n255\n\n\n4\n3.5\n6\n10.6\n244\n\n\n5\n3.5\n6\n10.0\n230\n\n\n6\n3.5\n6\n10.1\n232\n\n\n7\n3.7\n6\n11.1\n255\n\n\n8\n3.7\n6\n11.6\n267\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nMari visualisasikan sebaran datanya menggunakan histogram\n\n#membuat histogram\nviz = cdf[['CYLINDERS', 'ENGINESIZE', 'CO2EMISSIONS', 'FUELCONSUMPTION_COMB']]\nviz.hist()\nplt.show()\n\n\n\n\n\n\n\n\nSelanjutnya, kita akan melihat hubungan antara ketiga kolom/feature dengan CO2Emission menggunakan scatter plot.\n\n#scatter plot untuk fuelconsumption_comb\nplt.scatter(cdf.FUELCONSUMPTION_COMB, cdf.CO2EMISSIONS, color = 'blue')\nplt.xlabel(\"FUELCONSUMPTION_COMB\")\nplt.ylabel(\"Emission\")\nplt.show()\n\n\n\n\n\n\n\n\n\n#scatter plot untuk enginesize\nplt.scatter(cdf.ENGINESIZE, cdf.CO2EMISSIONS, color = 'blue')\nplt.xlabel(\"Engine Size\")\nplt.ylabel(\"Emission\")\nplt.show()\n\n\n\n\n\n\n\n\n\n #scatter plot untuk cylinders\nplt.scatter(cdf.CYLINDERS, cdf.CO2EMISSIONS, color = 'red')\nplt.xlabel(\"Cylinders\")\nplt.ylabel(\"Emission\")\nplt.show()\n\n\n\n\n\n\n\n\n\ndari ketiga visualisasi diatas, scatter plot Engine Size dan Fuel Consumption terlihat menarik untuk diteliti lebih jauh. Langkah selanjutnya kita akan membuat model untuk memprediksi Emisi CO2 (CO2 Emission) berdasarkan Ukuran Mesin (Engine Size) dan model untuk memprediksi Emisi CO2 (CO2 Emission) berdasarkan Konsumsi Bahan Bakar (Fuel Consumption)"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#train-test-set",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#train-test-set",
    "title": "MODUL 2 PRAKTIKUM SAINS DATA",
    "section": "Train-Test Set",
    "text": "Train-Test Set\nPertama tama, kita bagi data yang kita punya sebagai data latih (untuk melatih model) dan data uji (untuk menguji model).\nData uji diperlukan agar kita dapat melihat akurasi dari model yang telah dibuat.\nData latih dan data uji harus bersifat saling lepas (tidak memiliki irisan) agar memberikan gambaran peforma model terhadap data baru\n\n#memisahkan data train dan test dengan perbandingan 8:2\nmsk = np.random.rand(len(df)) &lt; 0.8\ntrain = cdf[msk]\ntest = cdf[~msk]"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#regresi-linear-sederhana-engine-size-vs.-co2-emissions",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#regresi-linear-sederhana-engine-size-vs.-co2-emissions",
    "title": "MODUL 2 PRAKTIKUM SAINS DATA",
    "section": "Regresi Linear Sederhana (Engine Size vs. CO2 Emissions)",
    "text": "Regresi Linear Sederhana (Engine Size vs. CO2 Emissions)\n\n #scatter plot dari data latih\nplt.scatter(train.ENGINESIZE, train.CO2EMISSIONS, color = 'blue')\nplt.xlabel(\"Engine Size\")\nplt.ylabel(\"Emission\")\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#membuat-model",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#membuat-model",
    "title": "MODUL 2 PRAKTIKUM SAINS DATA",
    "section": "Membuat model",
    "text": "Membuat model\nUntuk membuat model, kita akan menggunakan LinearRegression dari package sklearn\n\n#import package sklearn dan modul linear_model\nfrom sklearn import linear_model\n#definisikan model regresi linier dengan nama 'regr'\nregr = linear_model.LinearRegression()\n#definisikan fitur/kolom yang akan di-fit kedalam model\ntrain_x = np.asanyarray(train[['ENGINESIZE']])\ntrain_y = np.asanyarray(train[['CO2EMISSIONS']])\n#fit data training ke model regr\nregr.fit(train_x, train_y)\n#output koefisien dan intersepnya\nprint('Coefficients: ', regr.coef_)\nprint('y-Intercept: ', regr.intercept_)\n\nCoefficients:  [[38.54948831]]\ny-Intercept:  [126.65891652]\n\n\nsehingga diperoleh fungsi: \\(y = 38.549x+126.658\\)\nSelanjutnya, kita dapat visualisasikan fungsi diatas beserta scatter plot dari data latih.\n\nplt.scatter(train.ENGINESIZE, train.CO2EMISSIONS, color = 'blue')\n#visualisasi fungsi yang diperoleh\nplt.plot(train_x, regr.coef_[0][0]*train_x + regr.intercept_[0], '-r')\nplt.xlabel(\"Engine Size\")\nplt.ylabel(\"Emission\")\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#evaluasi-model",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#evaluasi-model",
    "title": "MODUL 2 PRAKTIKUM SAINS DATA",
    "section": "Evaluasi Model",
    "text": "Evaluasi Model\nTahap terakhir adalah membandingkan nilai aktual (nilai y yang ada pada data test) dengan nilai prediksi (nilai y setelah x test disubstitusikan ke fungsi yang telah diperoleh) Selisih nilai aktual dan prediksi disebut error.\nBeberapa metriks/ukuran yang dapat digunakan utk evaluasi model: - Mean Absolute Error: Mean dari mutlak dari error. Paling mudah dipahami, sebab berupa kesalahan rata-rata. - Mean Squared Error (MSE): Rata-rata dari error kuadrat. Lebih populer daripada MAE karena fokusnya lebih diarahkan pada kesalahan besar. Ini karena suku kuadrat secara eksponensial meningkatkan kesalahan yang lebih besar dibandingkan dengan kesalahan yang lebih kecil. - Root Mean Squared Error (RMSE): akar dari MSE. - R-square (R-2) : metrik populer untuk mengukur kinerja model regresi. Mewakili seberapa dekat titik data dengan garis regresi yang dipasang. Semakin tinggi nilai R-2, semakin baik model tersebut sesuai dengan data. Skor terbaik adalah 1.0 dan bisa juga bernilai negatif.\n\n#gunakan package sklearn.metrics utk melihat evaluasi model\nfrom sklearn.metrics import r2_score\ntest_x = np.asanyarray(test[['ENGINESIZE']])\ntest_y = np.asanyarray(test[['CO2EMISSIONS']])\ntest_y_ = regr.predict(test_x)\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_ - test_y)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_ - test_y) ** 2))\nprint(\"R2-score: %.2f\" % r2_score(test_y, test_y_))\n\nMean absolute error: 24.75\nResidual sum of squares (MSE): 1133.59\nR2-score: 0.76"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#regression-fuel-consumption-vs.-co2-emission",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#regression-fuel-consumption-vs.-co2-emission",
    "title": "MODUL 2 PRAKTIKUM SAINS DATA",
    "section": "Regression (Fuel Consumption vs. CO2 Emission)",
    "text": "Regression (Fuel Consumption vs. CO2 Emission)\n\nplt.scatter(train.FUELCONSUMPTION_COMB, train.CO2EMISSIONS, color = 'red')\nplt.xlabel(\"Fuel Consumption\")\nplt.ylabel(\"Emission\")\nplt.show()\n\n\n\n\n\n\n\n\n\nregr = linear_model.LinearRegression()\ntrain_x = np.asanyarray(train[['FUELCONSUMPTION_COMB']])\ntrain_y = np.asanyarray(train[['CO2EMISSIONS']])\nregr.fit(train_x, train_y)\nprint('Coefficients: ', regr.coef_)\nprint('y-Intercept: ', regr.intercept_)\n\nCoefficients:  [[15.99115452]]\ny-Intercept:  [71.06166585]\n\n\nsehingga diperoleh fungsi: \\(y = 15.991x+71.061\\)\n\nplt.scatter(train.FUELCONSUMPTION_COMB, train.CO2EMISSIONS, color = 'red')\nplt.plot(train_x, regr.coef_[0][0]*train_x + regr.intercept_[0], '-k')\nplt.xlabel(\"Fuel Consumption\")\nplt.ylabel(\"Emission\")\nplt.show()\n\n\n\n\n\n\n\n\n\ntest_x = np.asanyarray(test[['FUELCONSUMPTION_COMB']])\ntest_y = np.asanyarray(test[['CO2EMISSIONS']])\ntest_y_ = regr.predict(test_x)\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_ - test_y)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_ - test_y) ** 2))\nprint(\"R2-score: %.2f\" % r2_score(test_y, test_y_))\n\nMean absolute error: 21.10\nResidual sum of squares (MSE): 849.92\nR2-score: 0.82\n\n\n\nBerdasarkan perbandingan MAE, MSE dan R2-scorenya dapat disimpulkan bahwa model regresi linier Fuel Consumption vs. CO2 Emission lebih baik dari model regresi linier Engine Size vs. CO2 Emission."
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#traintest-set",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#traintest-set",
    "title": "MODUL 2 PRAKTIKUM SAINS DATA",
    "section": "Train/Test Set",
    "text": "Train/Test Set\n\n#memisah data uji dan data latih dgn perbandingan 8:2\nmsk = np.random.rand(len(df)) &lt; 0.8\ntrain = cdf[msk]\ntest = cdf[~msk]\n\n\n#membuat model\nregr = linear_model.LinearRegression()\n#perhatikan pada x, dipilih beberapa feature/kolom sebagai variabel bebasnya. kali ini akan dibuat model\n#berdasarkan ukuran mesin, banyak tabung, dan konsumsi bahan bakar\nx = np.asanyarray(train[['ENGINESIZE', 'CYLINDERS', 'FUELCONSUMPTION_COMB']])\ny = np.asanyarray(train[['CO2EMISSIONS']])\nregr.fit(x, y)\nprint('Coefficients: ', regr.coef_)\nprint('Intercept: ', regr.intercept_)\n\nCoefficients:  [[10.77193129  7.70821711  9.51766547]]\nIntercept:  [64.90866441]\n\n\n\\(y=10.771x_1 + 7.708x_2 + 9.517x_3 + 64.908\\)"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#evaluasi-model-1",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#evaluasi-model-1",
    "title": "MODUL 2 PRAKTIKUM SAINS DATA",
    "section": "Evaluasi Model",
    "text": "Evaluasi Model\nExplained Variance: Misal ŷ adalah prediksi, y adalah nilai aktual, dan Var adalah Varians (kuadrat dari standar deviasi).\n\\(\\text{explainedVariance} (y,ŷ) = 1-\\frac{\\text{Var }y-ŷ}{\\text{Var }y}\\)\nSkor terbaik adalah 1. Semakin rendah berarti kinerja model lebih buruk.\nResidual Sum of Square (RSS): Sum dari error kuadrat. Semakin tinggi nialinya, maka kinerja model lebih buruk.\n\n#evaluasi fungsi diatas\nx = np.asanyarray(test[['ENGINESIZE', 'CYLINDERS', 'FUELCONSUMPTION_COMB']])\ny = np.asanyarray(test[['CO2EMISSIONS']])\ny_hat = regr.predict(test[['ENGINESIZE', 'CYLINDERS', 'FUELCONSUMPTION_COMB']])\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat - y) ** 2))\nprint(\"Variance score: %.2f\" % regr.score(x, y))\n\nResidual sum of squares: 462.42\nVariance score: 0.88\n\n\n/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n  warnings.warn("
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#membuat-model-pembanding",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul2.html#membuat-model-pembanding",
    "title": "MODUL 2 PRAKTIKUM SAINS DATA",
    "section": "Membuat Model Pembanding",
    "text": "Membuat Model Pembanding\n‘FUELCONSUMPTION_COMB’ digantikan dengan ‘FUELCONSUMPTION_CITY’, ‘FUELCONSUMPTION_HWY’\n\nregr = linear_model.LinearRegression()\n#perhatikan pada x, dipilih beberapa feature/kolom sebagai variabel bebasnya. kali ini akan dibuat model\n#berdasarkan ukuran mesin, banyak tabung, konsumsi bahan bakar dalam kota dan konsumsi bahan bakar luar kota\nx = np.asanyarray(train[['ENGINESIZE', 'CYLINDERS', 'FUELCONSUMPTION_CITY', 'FUELCONSUMPTION_HWY']])\ny = np.asanyarray(train[['CO2EMISSIONS']])\nregr.fit(x, y)\nprint('Coefficients: ', regr.coef_)\nprint('Intercept: ', regr.intercept_)\n\nCoefficients:  [[10.89417412  7.24796498  6.44569745  2.65762343]]\nIntercept:  [66.53100166]\n\n\n\\(y=10.894x_1 + 7.247x_2 + 6.445x_3 + 2.657x_4 + 66.531\\)\n\n#evaluasi model diatas\nx = np.asanyarray(test[['ENGINESIZE', 'CYLINDERS', 'FUELCONSUMPTION_CITY', 'FUELCONSUMPTION_HWY']])\ny = np.asanyarray(test[['CO2EMISSIONS']])\ny_hat = regr.predict(test[['ENGINESIZE', 'CYLINDERS', 'FUELCONSUMPTION_CITY', 'FUELCONSUMPTION_HWY']])\nprint(\"Residual sum of squares: %.2f\" % np.mean((y_hat - y) ** 2))\nprint(\"Variance score: %.2f\" % regr.score(x, y))\n\nResidual sum of squares: 465.14\nVariance score: 0.88\n\n\n/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n  warnings.warn(\n\n\n\nBerdasarkan Residual sum of square (RSS) dari kedua model, terlihat bahwa model regresi \\[y=10.894x_1 + 7.247x_2 + 6.445x_3 + 2.657x_4 + 66.531\\] memiliki performa sedikit lebih baik dibandingkan dengan model regresi \\[y=10.771x_1 + 7.708x_2 + 9.517x_3 + 64.908\\]"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul4.html",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul4.html",
    "title": "Modul 4 Praktikum Sains Data",
    "section": "",
    "text": "Review Evaluation Metrics pada Klasifikasi\nDecission Tree\nSVM\n\n\n\n\n\nJaccard Index\n\nMengukur akurasi dari model menggunakan irisan dari hasil prediksi dengan value sebenarnya. \\[J(y, \\hat{y}) = \\frac{|y \\cap \\hat{y}|}{|y|+|\\hat{y}|-|y \\cap \\hat{y}|}\\]\n\\(y=\\) actual label\n\\(\\hat{y}=\\) predicted label\nContoh:\n\\(y = [0,0,0,0,0,1,1,1,1,1]\\)\n\\(\\hat{y} = [1,1,0,0,0,1,1,1,1,1]\\)\n\\(|y| = 10\\)\n\\(|\\hat{y}| = 10\\)\n\\(|\\hat{y}|-|y \\cap \\hat{y}| = 8\\)\n\\(J(y, \\hat{y}) = \\frac{|y \\cap \\hat{y}|}{|y|+|\\hat{y}|-|y \\cap \\hat{y}|} = \\frac{8}{10+10-8} = 0.66\\)\n\nRentang Jaccard index antara 0 hingga 1\nSemakin tinggi Jaccard Index, peforma model semakin baik\n\n\nConfusion Matrix, F1 Score\n\nTN / True Negative: kasus negatif, dengan hasil prediksi negatif\nTP / True Positive: kasus positif, dengan hasil prediksi positif\nFN / False Negative: kasus positif, dengan hasil prediksi negatif\nFP / False Positive: kasus negatif, dengan hasil prediksi positif\n\n\\[Precision = \\frac{TP}{(TP+FP)}\\]\n\\[Recall = \\frac{TN}{(TP+FN)}\\]\n\\[F1 \\text{ } Score = \\frac{2 . (Recall.Precision)}{(Recall+Precision)}\\]\nCara mengukur performa menggunakan F-1 score dengan mengambil rata rata F1-score dari masing masing label.\nContoh, label 0 memiliki F1-score 0.72 dan label 1 memiliki F1-score 0.50.\nMaka, F1-score dari model tersebut adalah 0.61\n\nRentang F1-score berkisar di antara 0 hingga 1\nSemakin tinggi F1-score, maka peforma model tersebut makin baik\n\n\nLog loss\n\nTerkadang, output dari suatu model klasifikasi berbentuk probabilitas dari suatu item memiliki label tertentu. (Contohnya pada logistic regression minggu lalu)\nKita dapat menghitung untuk masing-masing item: \\[(y. \\log(\\hat{y}) + (1-y). \\log(1-\\hat{y}))\\]\nKemudian, kita dapat menghitung rata rata dari tiap item tersebut \\[Logloss = -\\frac{1}{n} \\Sigma (y. \\log(\\hat{y}) + (1-y). \\log(1-\\hat{y}))\\]\n\\(y=\\) actual label\n\\(\\hat{y}=\\) predicted probability\nContoh:\n\n\nRentang logloss berkisar di antara 0 hingga 1\nSemakin rendah logloss, maka peforma model tersebut makin baik\n\n\n\n\nSeperti namanya, pohon keputusan, konsepnya bentuknya pohon, bercabang.\nBiasanya digunakan sebagai simple binary classifier.\n\n\nMencari fitur apa yg membuat suatu item memiliki label tertentu\nEntropy = tolak ukur seberapa random data di fitur tsb, entropy 0 artinya simpul (fitur) tsb berpengaruh terhadap klasifikasi, entropy 0 itu baik \\[-P(A).\\log(P(A)) - P(B).\\log(P(B))\\]\nInformation gain : informasi yang dapat meningkatkan kejelasan dari percabangan. \\(\\newline\\) InfoGain = Entropybefore - weightedentropyafter\nPohon yg lebih baik adalah yang memiliki infogain lebih tinggi\n\nKali ini, kita akan mengklasifikasi resep obat yang cocok dari penyakit yang sama untuk fitur-fitur yang berbeda (Umur, Jenis Kelamin,Tekanan Darah, Kolestrol)\n\n\n\n#import modul dan package\nimport numpy as np\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\n\n\n\n\nPada module kali ini, akan digunakan data csv drug200 (drug200.csv) yang bisa didownload dari:\n\nKaggle\n\n\n#muat dataset\nmy_data = pd.read_csv(r\".\\drug200.csv\")\nmy_data.head()\n\n\n\n\n\n\n\n\nAge\nSex\nBP\nCholesterol\nNa_to_K\nDrug\n\n\n\n\n0\n23\nF\nHIGH\nHIGH\n25.355\ndrugY\n\n\n1\n47\nM\nLOW\nHIGH\n13.093\ndrugC\n\n\n2\n47\nM\nLOW\nHIGH\n10.114\ndrugC\n\n\n3\n28\nF\nNORMAL\nHIGH\n7.798\ndrugX\n\n\n4\n61\nF\nLOW\nHIGH\n18.043\ndrugY\n\n\n\n\n\n\n\n\nmy_data.shape\n\n(200, 6)\n\n\n\n#melihat ada brp value berbeda pada feature/kolom Drug\nmy_data[\"Drug\"].unique()\n\narray(['drugY', 'drugC', 'drugX', 'drugA', 'drugB'], dtype=object)\n\n\n\n#feature/kolom pada dataframe\nmy_data.columns\n\nIndex(['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug'], dtype='object')\n\n\n\n#melihat value per baris\nX = my_data[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']].values\nX[0:5]\n\narray([[23, 'F', 'HIGH', 'HIGH', 25.355],\n       [47, 'M', 'LOW', 'HIGH', 13.093],\n       [47, 'M', 'LOW', 'HIGH', 10.114],\n       [28, 'F', 'NORMAL', 'HIGH', 7.798],\n       [61, 'F', 'LOW', 'HIGH', 18.043]], dtype=object)\n\n\n\n\n\nPada bagian ini, kita akan mengubah value kategorik menjadi data numerik\n\nfrom sklearn import preprocessing\nle_sex = preprocessing.LabelEncoder()\nle_sex.fit(['F', 'M'])\nX[:, 1] = le_sex.transform(X[:, 1]) #sex di kolom kedua df, indexnya 1\nX[0:5]\n\narray([[23, 0, 'HIGH', 'HIGH', 25.355],\n       [47, 1, 'LOW', 'HIGH', 13.093],\n       [47, 1, 'LOW', 'HIGH', 10.114],\n       [28, 0, 'NORMAL', 'HIGH', 7.798],\n       [61, 0, 'LOW', 'HIGH', 18.043]], dtype=object)\n\n\n\nle_bp = preprocessing.LabelEncoder()\nle_bp.fit(['LOW', 'NORMAL', 'HIGH'])\nX[:, 2] = le_bp.transform(X[:, 2]) #sex di kolom ketiga df, indexnya 2\nle_chol = preprocessing.LabelEncoder()\nle_chol.fit(['NORMAL', 'HIGH'])\nX[:, 3] = le_chol.transform(X[:, 3]) #sex di kolom keempat df, indexnya 3\nX[0:5]\n\narray([[23, 0, 0, 0, 25.355],\n       [47, 1, 1, 0, 13.093],\n       [47, 1, 1, 0, 10.114],\n       [28, 0, 2, 0, 7.798],\n       [61, 0, 1, 0, 18.043]], dtype=object)\n\n\n\ny = my_data['Drug']\ny[0:5]\n\n0    drugY\n1    drugC\n2    drugC\n3    drugX\n4    drugY\nName: Drug, dtype: object\n\n\n\n\n\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n\n\nprint(X_train.shape)\nprint(y_train.shape)\n\n(140, 5)\n(140,)\n\n\n\nprint(X_test.shape)\nprint(y_test.shape)\n\n(60, 5)\n(60,)\n\n\n\n\n\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n\ndrugtree = DecisionTreeClassifier(criterion = 'entropy', max_depth = 4)\n\n\ndrugtree.fit(X_train, y_train)\n\nDecisionTreeClassifier(criterion='entropy', max_depth=4)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFittedDecisionTreeClassifier(criterion='entropy', max_depth=4) \n\n\n\npredTree = drugtree.predict(X_test)\npredTree\n\narray(['drugC', 'drugY', 'drugX', 'drugY', 'drugX', 'drugX', 'drugY',\n       'drugX', 'drugY', 'drugX', 'drugY', 'drugC', 'drugC', 'drugY',\n       'drugB', 'drugX', 'drugA', 'drugY', 'drugY', 'drugC', 'drugX',\n       'drugC', 'drugX', 'drugY', 'drugY', 'drugB', 'drugB', 'drugC',\n       'drugY', 'drugY', 'drugY', 'drugY', 'drugC', 'drugY', 'drugY',\n       'drugY', 'drugY', 'drugY', 'drugA', 'drugX', 'drugY', 'drugY',\n       'drugY', 'drugB', 'drugY', 'drugY', 'drugA', 'drugA', 'drugX',\n       'drugX', 'drugY', 'drugY', 'drugY', 'drugY', 'drugX', 'drugX',\n       'drugX', 'drugA', 'drugY', 'drugA'], dtype=object)\n\n\n\n#bandingkan nilai y pada data uji dengan hasil prediksi\ncomparison = {\"y_test\" : y_test,\n              \"Predicted\": predTree}\ncomp = pd.DataFrame(comparison)\ncomp\n\n\n\n\n\n\n\n\ny_test\nPredicted\n\n\n\n\n10\ndrugC\ndrugC\n\n\n90\ndrugY\ndrugY\n\n\n132\ndrugX\ndrugX\n\n\n23\ndrugY\ndrugY\n\n\n145\ndrugX\ndrugX\n\n\n34\ndrugX\ndrugX\n\n\n154\ndrugY\ndrugY\n\n\n37\ndrugX\ndrugX\n\n\n49\ndrugY\ndrugY\n\n\n58\ndrugX\ndrugX\n\n\n123\ndrugY\ndrugY\n\n\n47\ndrugC\ndrugC\n\n\n195\ndrugC\ndrugC\n\n\n121\ndrugY\ndrugY\n\n\n108\ndrugB\ndrugB\n\n\n135\ndrugX\ndrugX\n\n\n61\ndrugA\ndrugA\n\n\n24\ndrugY\ndrugY\n\n\n157\ndrugY\ndrugY\n\n\n84\ndrugC\ndrugC\n\n\n181\ndrugX\ndrugX\n\n\n102\ndrugC\ndrugC\n\n\n45\ndrugX\ndrugX\n\n\n19\ndrugY\ndrugY\n\n\n125\ndrugY\ndrugY\n\n\n142\ndrugB\ndrugB\n\n\n41\ndrugB\ndrugB\n\n\n2\ndrugC\ndrugC\n\n\n166\ndrugY\ndrugY\n\n\n94\ndrugY\ndrugY\n\n\n28\ndrugY\ndrugY\n\n\n9\ndrugY\ndrugY\n\n\n193\ndrugC\ndrugC\n\n\n74\ndrugY\ndrugY\n\n\n164\ndrugY\ndrugY\n\n\n91\ndrugY\ndrugY\n\n\n115\ndrugY\ndrugY\n\n\n88\ndrugY\ndrugY\n\n\n36\ndrugA\ndrugA\n\n\n160\ndrugX\ndrugX\n\n\n172\ndrugY\ndrugY\n\n\n48\ndrugY\ndrugY\n\n\n22\ndrugY\ndrugY\n\n\n136\ndrugB\ndrugB\n\n\n62\ndrugY\ndrugY\n\n\n165\ndrugY\ndrugY\n\n\n140\ndrugA\ndrugA\n\n\n100\ndrugA\ndrugA\n\n\n81\ndrugX\ndrugX\n\n\n159\ndrugX\ndrugX\n\n\n75\ndrugY\ndrugY\n\n\n0\ndrugY\ndrugY\n\n\n29\ndrugY\ndrugY\n\n\n12\ndrugY\ndrugY\n\n\n63\ndrugX\ndrugX\n\n\n182\ndrugX\ndrugX\n\n\n105\ndrugX\ndrugX\n\n\n176\ndrugA\ndrugA\n\n\n33\ndrugY\ndrugY\n\n\n174\ndrugA\ndrugA\n\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.metrics import accuracy_score\nprint(\"Accuracy : \", accuracy_score(y_test, predTree))\n\nAccuracy :  1.0\n\n\n\n\n\n\nfrom sklearn import tree\n\n\nfeatureNames = my_data.columns[0:5]\n\ngraph = tree.plot_tree(drugtree,\n                       feature_names=featureNames,\n                       class_names=np.unique(y_train),\n                       filled=True)\n\n\n\n\n\n\n\n\n\n\n\n\nSVM adalah algoritma supervised learning utk klasifikasi dengan cara menemukan separator berupa hyperplane (biasanya utk binary classification)\n\nPetakan fitur (kolom, bentuk awalnya 1d) ke ruang dimensi yg lebih tinggi (contohnya 3D) menggunakan fungsi kernel (linear, Radial Basis Function, polinom, sigmoid, dsb)\nTemukan separatornya (utk di ruang 3d biasanya bentuknya bidang)\n\n\nHyperplane yg baik adalah yg memiliki margin lebih besar (jarak ke support vector)\n\n\n\n\nSVM\n\n\nKali ini, kita akan melakukan klasifikasi sebuah cell apakah cell tersebut jinak atau ganas (berpotensi kanker)\n\n#install dulu package bila belum memiliki sklearn\n!pip install scikit-learn==0.23.1\n\n\n\n\n#import modul yang diperlukan\nimport pandas as pd\nimport pylab as pl\nimport numpy as np\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\n\n\nPada module kali ini, akan digunakan data csv cell samples (cell_samples.csv) yang bisa didownload dari:\n\nKaggle\n\n\n#memuat dataframe\ncell_df=pd.read_csv(r\".\\cell_samples.csv\")\n\n\ncell_df.head()\n\n\n\n\n\n\n\n\nID\nClump\nUnifSize\nUnifShape\nMargAdh\nSingEpiSize\nBareNuc\nBlandChrom\nNormNucl\nMit\nClass\n\n\n\n\n0\n1000025\n5\n1\n1\n1\n2\n1\n3\n1\n1\n2\n\n\n1\n1002945\n5\n4\n4\n5\n7\n10\n3\n2\n1\n2\n\n\n2\n1015425\n3\n1\n1\n1\n2\n2\n3\n1\n1\n2\n\n\n3\n1016277\n6\n8\n8\n1\n3\n4\n3\n7\n1\n2\n\n\n4\n1017023\n4\n1\n1\n3\n2\n1\n3\n1\n1\n2\n\n\n\n\n\n\n\n\n#melihat sebaran datanya menggunakan scatterplot\nax = cell_df[cell_df['Class']==4][0:50].plot(kind='scatter', x='Clump', y = 'UnifSize', color = 'Blue',\n                                             label = 'ganas')\ncell_df[cell_df['Class']==2][0:50].plot(kind='scatter', x='Clump', y = 'UnifSize', color = 'Yellow', \n                                        label ='jinak',ax=ax)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n#cek type dari masing2 feature/kolom\ncell_df.dtypes\n\nID              int64\nClump           int64\nUnifSize        int64\nUnifShape       int64\nMargAdh         int64\nSingEpiSize     int64\nBareNuc        object\nBlandChrom      int64\nNormNucl        int64\nMit             int64\nClass           int64\ndtype: object\n\n\n\ncell_df = cell_df[pd.to_numeric(cell_df['BareNuc'],errors=\"coerce\").notnull()] #mengatasi value yg error menjadi NaN\ncell_df['BareNuc']=cell_df['BareNuc'].astype('int') #mengubah type menjadi integer\ncell_df.dtypes\n\nID             int64\nClump          int64\nUnifSize       int64\nUnifShape      int64\nMargAdh        int64\nSingEpiSize    int64\nBareNuc        int32\nBlandChrom     int64\nNormNucl       int64\nMit            int64\nClass          int64\ndtype: object\n\n\n\n\n\n\n#set X\nfeature_df = cell_df[['Clump', 'UnifSize','UnifShape','MargAdh','SingEpiSize','BareNuc','BlandChrom','NormNucl','Mit']].values\nX = np.asarray(feature_df)\nX[0:5]\n\narray([[ 5,  1,  1,  1,  2,  1,  3,  1,  1],\n       [ 5,  4,  4,  5,  7, 10,  3,  2,  1],\n       [ 3,  1,  1,  1,  2,  2,  3,  1,  1],\n       [ 6,  8,  8,  1,  3,  4,  3,  7,  1],\n       [ 4,  1,  1,  3,  2,  1,  3,  1,  1]], dtype=int64)\n\n\n\n#set Y\ncell_df['Class'] = cell_df['Class'].astype('int')\ny=np.asarray(cell_df['Class'])\ny[0:5]\n\narray([2, 2, 2, 2, 2])\n\n\n\n#train-test split\ntrain_x,test_x,train_y,test_y=train_test_split(X,y, test_size=0.2,random_state=4)\nprint('Train set:', train_x.shape,train_y.shape)\nprint('Train set:', test_x.shape,test_y.shape)\n\nTrain set: (546, 9) (546,)\nTrain set: (137, 9) (137,)\n\n\n\n\n\n\n#membuat model\nfrom sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit(train_x,train_y)\n\nSVC()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVC?Documentation for SVCiFittedSVC() \n\n\n\n#Prediksi\nyhat = clf.predict(test_x)\nyhat[0:5]\n\narray([2, 4, 2, 4, 2])\n\n\n\n\n\n\n#jaccard score\nfrom sklearn.metrics import jaccard_score\njaccard_score(test_y,yhat,pos_label=2)\n\n0.9444444444444444\n\n\n\n#f1-score\nfrom sklearn.metrics import f1_score\nf1_score(test_y,yhat,pos_label=2)\n\n0.9714285714285714\n\n\n\n#visualisasi confusion matrix\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n  \"\"\"\n  This function prints and plots the confusion matrix.\n  Normalization can be applied by setting `normalize=True`.\n  \"\"\"\n  if normalize:\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    print(\"Normalized confusion matrix\")\n  else:\n    print('Confusion matrix, without normalization')\n \n  print(cm)\n\n  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n  plt.title(title)\n  plt.colorbar()\n  tick_marks = np.arange(len(classes))\n  plt.xticks(tick_marks, classes, rotation=45)\n  plt.yticks(tick_marks, classes)\n  \n  fmt = '.2f' if normalize else 'd'\n  thresh = cm.max() / 2.\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, format(cm[i, j], fmt),\n             horizontalalignment=\"center\",\n             color=\"white\" if cm[i, j] &gt; thresh else \"black\")\n  plt.tight_layout()\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label')\nprint(confusion_matrix(test_y, yhat, labels=[2,4]))\n\n[[85  5]\n [ 0 47]]\n\n\n\n#confusion matrix\ncnf_matrix =confusion_matrix(test_y, yhat, labels=[2,4])\nplt.figure()\nplot_confusion_matrix(cnf_matrix,classes=['Jinak=2', 'Ganas=4'],normalize = False, title='Confusion matrix')\n\nConfusion matrix, without normalization\n[[85  5]\n [ 0 47]]"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul4.html#evaluation-metrics",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul4.html#evaluation-metrics",
    "title": "Modul 4 Praktikum Sains Data",
    "section": "",
    "text": "Jaccard Index\n\nMengukur akurasi dari model menggunakan irisan dari hasil prediksi dengan value sebenarnya. \\[J(y, \\hat{y}) = \\frac{|y \\cap \\hat{y}|}{|y|+|\\hat{y}|-|y \\cap \\hat{y}|}\\]\n\\(y=\\) actual label\n\\(\\hat{y}=\\) predicted label\nContoh:\n\\(y = [0,0,0,0,0,1,1,1,1,1]\\)\n\\(\\hat{y} = [1,1,0,0,0,1,1,1,1,1]\\)\n\\(|y| = 10\\)\n\\(|\\hat{y}| = 10\\)\n\\(|\\hat{y}|-|y \\cap \\hat{y}| = 8\\)\n\\(J(y, \\hat{y}) = \\frac{|y \\cap \\hat{y}|}{|y|+|\\hat{y}|-|y \\cap \\hat{y}|} = \\frac{8}{10+10-8} = 0.66\\)\n\nRentang Jaccard index antara 0 hingga 1\nSemakin tinggi Jaccard Index, peforma model semakin baik\n\n\nConfusion Matrix, F1 Score\n\nTN / True Negative: kasus negatif, dengan hasil prediksi negatif\nTP / True Positive: kasus positif, dengan hasil prediksi positif\nFN / False Negative: kasus positif, dengan hasil prediksi negatif\nFP / False Positive: kasus negatif, dengan hasil prediksi positif\n\n\\[Precision = \\frac{TP}{(TP+FP)}\\]\n\\[Recall = \\frac{TN}{(TP+FN)}\\]\n\\[F1 \\text{ } Score = \\frac{2 . (Recall.Precision)}{(Recall+Precision)}\\]\nCara mengukur performa menggunakan F-1 score dengan mengambil rata rata F1-score dari masing masing label.\nContoh, label 0 memiliki F1-score 0.72 dan label 1 memiliki F1-score 0.50.\nMaka, F1-score dari model tersebut adalah 0.61\n\nRentang F1-score berkisar di antara 0 hingga 1\nSemakin tinggi F1-score, maka peforma model tersebut makin baik\n\n\nLog loss\n\nTerkadang, output dari suatu model klasifikasi berbentuk probabilitas dari suatu item memiliki label tertentu. (Contohnya pada logistic regression minggu lalu)\nKita dapat menghitung untuk masing-masing item: \\[(y. \\log(\\hat{y}) + (1-y). \\log(1-\\hat{y}))\\]\nKemudian, kita dapat menghitung rata rata dari tiap item tersebut \\[Logloss = -\\frac{1}{n} \\Sigma (y. \\log(\\hat{y}) + (1-y). \\log(1-\\hat{y}))\\]\n\\(y=\\) actual label\n\\(\\hat{y}=\\) predicted probability\nContoh:\n\n\nRentang logloss berkisar di antara 0 hingga 1\nSemakin rendah logloss, maka peforma model tersebut makin baik"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul4.html#decision-tree",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul4.html#decision-tree",
    "title": "Modul 4 Praktikum Sains Data",
    "section": "",
    "text": "Seperti namanya, pohon keputusan, konsepnya bentuknya pohon, bercabang.\nBiasanya digunakan sebagai simple binary classifier.\n\n\nMencari fitur apa yg membuat suatu item memiliki label tertentu\nEntropy = tolak ukur seberapa random data di fitur tsb, entropy 0 artinya simpul (fitur) tsb berpengaruh terhadap klasifikasi, entropy 0 itu baik \\[-P(A).\\log(P(A)) - P(B).\\log(P(B))\\]\nInformation gain : informasi yang dapat meningkatkan kejelasan dari percabangan. \\(\\newline\\) InfoGain = Entropybefore - weightedentropyafter\nPohon yg lebih baik adalah yang memiliki infogain lebih tinggi\n\nKali ini, kita akan mengklasifikasi resep obat yang cocok dari penyakit yang sama untuk fitur-fitur yang berbeda (Umur, Jenis Kelamin,Tekanan Darah, Kolestrol)\n\n\n\n#import modul dan package\nimport numpy as np\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\n\n\n\n\nPada module kali ini, akan digunakan data csv drug200 (drug200.csv) yang bisa didownload dari:\n\nKaggle\n\n\n#muat dataset\nmy_data = pd.read_csv(r\".\\drug200.csv\")\nmy_data.head()\n\n\n\n\n\n\n\n\nAge\nSex\nBP\nCholesterol\nNa_to_K\nDrug\n\n\n\n\n0\n23\nF\nHIGH\nHIGH\n25.355\ndrugY\n\n\n1\n47\nM\nLOW\nHIGH\n13.093\ndrugC\n\n\n2\n47\nM\nLOW\nHIGH\n10.114\ndrugC\n\n\n3\n28\nF\nNORMAL\nHIGH\n7.798\ndrugX\n\n\n4\n61\nF\nLOW\nHIGH\n18.043\ndrugY\n\n\n\n\n\n\n\n\nmy_data.shape\n\n(200, 6)\n\n\n\n#melihat ada brp value berbeda pada feature/kolom Drug\nmy_data[\"Drug\"].unique()\n\narray(['drugY', 'drugC', 'drugX', 'drugA', 'drugB'], dtype=object)\n\n\n\n#feature/kolom pada dataframe\nmy_data.columns\n\nIndex(['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug'], dtype='object')\n\n\n\n#melihat value per baris\nX = my_data[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']].values\nX[0:5]\n\narray([[23, 'F', 'HIGH', 'HIGH', 25.355],\n       [47, 'M', 'LOW', 'HIGH', 13.093],\n       [47, 'M', 'LOW', 'HIGH', 10.114],\n       [28, 'F', 'NORMAL', 'HIGH', 7.798],\n       [61, 'F', 'LOW', 'HIGH', 18.043]], dtype=object)\n\n\n\n\n\nPada bagian ini, kita akan mengubah value kategorik menjadi data numerik\n\nfrom sklearn import preprocessing\nle_sex = preprocessing.LabelEncoder()\nle_sex.fit(['F', 'M'])\nX[:, 1] = le_sex.transform(X[:, 1]) #sex di kolom kedua df, indexnya 1\nX[0:5]\n\narray([[23, 0, 'HIGH', 'HIGH', 25.355],\n       [47, 1, 'LOW', 'HIGH', 13.093],\n       [47, 1, 'LOW', 'HIGH', 10.114],\n       [28, 0, 'NORMAL', 'HIGH', 7.798],\n       [61, 0, 'LOW', 'HIGH', 18.043]], dtype=object)\n\n\n\nle_bp = preprocessing.LabelEncoder()\nle_bp.fit(['LOW', 'NORMAL', 'HIGH'])\nX[:, 2] = le_bp.transform(X[:, 2]) #sex di kolom ketiga df, indexnya 2\nle_chol = preprocessing.LabelEncoder()\nle_chol.fit(['NORMAL', 'HIGH'])\nX[:, 3] = le_chol.transform(X[:, 3]) #sex di kolom keempat df, indexnya 3\nX[0:5]\n\narray([[23, 0, 0, 0, 25.355],\n       [47, 1, 1, 0, 13.093],\n       [47, 1, 1, 0, 10.114],\n       [28, 0, 2, 0, 7.798],\n       [61, 0, 1, 0, 18.043]], dtype=object)\n\n\n\ny = my_data['Drug']\ny[0:5]\n\n0    drugY\n1    drugC\n2    drugC\n3    drugX\n4    drugY\nName: Drug, dtype: object\n\n\n\n\n\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n\n\nprint(X_train.shape)\nprint(y_train.shape)\n\n(140, 5)\n(140,)\n\n\n\nprint(X_test.shape)\nprint(y_test.shape)\n\n(60, 5)\n(60,)\n\n\n\n\n\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n\ndrugtree = DecisionTreeClassifier(criterion = 'entropy', max_depth = 4)\n\n\ndrugtree.fit(X_train, y_train)\n\nDecisionTreeClassifier(criterion='entropy', max_depth=4)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFittedDecisionTreeClassifier(criterion='entropy', max_depth=4) \n\n\n\npredTree = drugtree.predict(X_test)\npredTree\n\narray(['drugC', 'drugY', 'drugX', 'drugY', 'drugX', 'drugX', 'drugY',\n       'drugX', 'drugY', 'drugX', 'drugY', 'drugC', 'drugC', 'drugY',\n       'drugB', 'drugX', 'drugA', 'drugY', 'drugY', 'drugC', 'drugX',\n       'drugC', 'drugX', 'drugY', 'drugY', 'drugB', 'drugB', 'drugC',\n       'drugY', 'drugY', 'drugY', 'drugY', 'drugC', 'drugY', 'drugY',\n       'drugY', 'drugY', 'drugY', 'drugA', 'drugX', 'drugY', 'drugY',\n       'drugY', 'drugB', 'drugY', 'drugY', 'drugA', 'drugA', 'drugX',\n       'drugX', 'drugY', 'drugY', 'drugY', 'drugY', 'drugX', 'drugX',\n       'drugX', 'drugA', 'drugY', 'drugA'], dtype=object)\n\n\n\n#bandingkan nilai y pada data uji dengan hasil prediksi\ncomparison = {\"y_test\" : y_test,\n              \"Predicted\": predTree}\ncomp = pd.DataFrame(comparison)\ncomp\n\n\n\n\n\n\n\n\ny_test\nPredicted\n\n\n\n\n10\ndrugC\ndrugC\n\n\n90\ndrugY\ndrugY\n\n\n132\ndrugX\ndrugX\n\n\n23\ndrugY\ndrugY\n\n\n145\ndrugX\ndrugX\n\n\n34\ndrugX\ndrugX\n\n\n154\ndrugY\ndrugY\n\n\n37\ndrugX\ndrugX\n\n\n49\ndrugY\ndrugY\n\n\n58\ndrugX\ndrugX\n\n\n123\ndrugY\ndrugY\n\n\n47\ndrugC\ndrugC\n\n\n195\ndrugC\ndrugC\n\n\n121\ndrugY\ndrugY\n\n\n108\ndrugB\ndrugB\n\n\n135\ndrugX\ndrugX\n\n\n61\ndrugA\ndrugA\n\n\n24\ndrugY\ndrugY\n\n\n157\ndrugY\ndrugY\n\n\n84\ndrugC\ndrugC\n\n\n181\ndrugX\ndrugX\n\n\n102\ndrugC\ndrugC\n\n\n45\ndrugX\ndrugX\n\n\n19\ndrugY\ndrugY\n\n\n125\ndrugY\ndrugY\n\n\n142\ndrugB\ndrugB\n\n\n41\ndrugB\ndrugB\n\n\n2\ndrugC\ndrugC\n\n\n166\ndrugY\ndrugY\n\n\n94\ndrugY\ndrugY\n\n\n28\ndrugY\ndrugY\n\n\n9\ndrugY\ndrugY\n\n\n193\ndrugC\ndrugC\n\n\n74\ndrugY\ndrugY\n\n\n164\ndrugY\ndrugY\n\n\n91\ndrugY\ndrugY\n\n\n115\ndrugY\ndrugY\n\n\n88\ndrugY\ndrugY\n\n\n36\ndrugA\ndrugA\n\n\n160\ndrugX\ndrugX\n\n\n172\ndrugY\ndrugY\n\n\n48\ndrugY\ndrugY\n\n\n22\ndrugY\ndrugY\n\n\n136\ndrugB\ndrugB\n\n\n62\ndrugY\ndrugY\n\n\n165\ndrugY\ndrugY\n\n\n140\ndrugA\ndrugA\n\n\n100\ndrugA\ndrugA\n\n\n81\ndrugX\ndrugX\n\n\n159\ndrugX\ndrugX\n\n\n75\ndrugY\ndrugY\n\n\n0\ndrugY\ndrugY\n\n\n29\ndrugY\ndrugY\n\n\n12\ndrugY\ndrugY\n\n\n63\ndrugX\ndrugX\n\n\n182\ndrugX\ndrugX\n\n\n105\ndrugX\ndrugX\n\n\n176\ndrugA\ndrugA\n\n\n33\ndrugY\ndrugY\n\n\n174\ndrugA\ndrugA\n\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.metrics import accuracy_score\nprint(\"Accuracy : \", accuracy_score(y_test, predTree))\n\nAccuracy :  1.0\n\n\n\n\n\n\nfrom sklearn import tree\n\n\nfeatureNames = my_data.columns[0:5]\n\ngraph = tree.plot_tree(drugtree,\n                       feature_names=featureNames,\n                       class_names=np.unique(y_train),\n                       filled=True)"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul4.html#support-vector-machine",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul4.html#support-vector-machine",
    "title": "Modul 4 Praktikum Sains Data",
    "section": "",
    "text": "SVM adalah algoritma supervised learning utk klasifikasi dengan cara menemukan separator berupa hyperplane (biasanya utk binary classification)\n\nPetakan fitur (kolom, bentuk awalnya 1d) ke ruang dimensi yg lebih tinggi (contohnya 3D) menggunakan fungsi kernel (linear, Radial Basis Function, polinom, sigmoid, dsb)\nTemukan separatornya (utk di ruang 3d biasanya bentuknya bidang)\n\n\nHyperplane yg baik adalah yg memiliki margin lebih besar (jarak ke support vector)\n\n\n\n\nSVM\n\n\nKali ini, kita akan melakukan klasifikasi sebuah cell apakah cell tersebut jinak atau ganas (berpotensi kanker)\n\n#install dulu package bila belum memiliki sklearn\n!pip install scikit-learn==0.23.1\n\n\n\n\n#import modul yang diperlukan\nimport pandas as pd\nimport pylab as pl\nimport numpy as np\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\n\n\nPada module kali ini, akan digunakan data csv cell samples (cell_samples.csv) yang bisa didownload dari:\n\nKaggle\n\n\n#memuat dataframe\ncell_df=pd.read_csv(r\".\\cell_samples.csv\")\n\n\ncell_df.head()\n\n\n\n\n\n\n\n\nID\nClump\nUnifSize\nUnifShape\nMargAdh\nSingEpiSize\nBareNuc\nBlandChrom\nNormNucl\nMit\nClass\n\n\n\n\n0\n1000025\n5\n1\n1\n1\n2\n1\n3\n1\n1\n2\n\n\n1\n1002945\n5\n4\n4\n5\n7\n10\n3\n2\n1\n2\n\n\n2\n1015425\n3\n1\n1\n1\n2\n2\n3\n1\n1\n2\n\n\n3\n1016277\n6\n8\n8\n1\n3\n4\n3\n7\n1\n2\n\n\n4\n1017023\n4\n1\n1\n3\n2\n1\n3\n1\n1\n2\n\n\n\n\n\n\n\n\n#melihat sebaran datanya menggunakan scatterplot\nax = cell_df[cell_df['Class']==4][0:50].plot(kind='scatter', x='Clump', y = 'UnifSize', color = 'Blue',\n                                             label = 'ganas')\ncell_df[cell_df['Class']==2][0:50].plot(kind='scatter', x='Clump', y = 'UnifSize', color = 'Yellow', \n                                        label ='jinak',ax=ax)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n#cek type dari masing2 feature/kolom\ncell_df.dtypes\n\nID              int64\nClump           int64\nUnifSize        int64\nUnifShape       int64\nMargAdh         int64\nSingEpiSize     int64\nBareNuc        object\nBlandChrom      int64\nNormNucl        int64\nMit             int64\nClass           int64\ndtype: object\n\n\n\ncell_df = cell_df[pd.to_numeric(cell_df['BareNuc'],errors=\"coerce\").notnull()] #mengatasi value yg error menjadi NaN\ncell_df['BareNuc']=cell_df['BareNuc'].astype('int') #mengubah type menjadi integer\ncell_df.dtypes\n\nID             int64\nClump          int64\nUnifSize       int64\nUnifShape      int64\nMargAdh        int64\nSingEpiSize    int64\nBareNuc        int32\nBlandChrom     int64\nNormNucl       int64\nMit            int64\nClass          int64\ndtype: object\n\n\n\n\n\n\n#set X\nfeature_df = cell_df[['Clump', 'UnifSize','UnifShape','MargAdh','SingEpiSize','BareNuc','BlandChrom','NormNucl','Mit']].values\nX = np.asarray(feature_df)\nX[0:5]\n\narray([[ 5,  1,  1,  1,  2,  1,  3,  1,  1],\n       [ 5,  4,  4,  5,  7, 10,  3,  2,  1],\n       [ 3,  1,  1,  1,  2,  2,  3,  1,  1],\n       [ 6,  8,  8,  1,  3,  4,  3,  7,  1],\n       [ 4,  1,  1,  3,  2,  1,  3,  1,  1]], dtype=int64)\n\n\n\n#set Y\ncell_df['Class'] = cell_df['Class'].astype('int')\ny=np.asarray(cell_df['Class'])\ny[0:5]\n\narray([2, 2, 2, 2, 2])\n\n\n\n#train-test split\ntrain_x,test_x,train_y,test_y=train_test_split(X,y, test_size=0.2,random_state=4)\nprint('Train set:', train_x.shape,train_y.shape)\nprint('Train set:', test_x.shape,test_y.shape)\n\nTrain set: (546, 9) (546,)\nTrain set: (137, 9) (137,)\n\n\n\n\n\n\n#membuat model\nfrom sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit(train_x,train_y)\n\nSVC()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVC?Documentation for SVCiFittedSVC() \n\n\n\n#Prediksi\nyhat = clf.predict(test_x)\nyhat[0:5]\n\narray([2, 4, 2, 4, 2])\n\n\n\n\n\n\n#jaccard score\nfrom sklearn.metrics import jaccard_score\njaccard_score(test_y,yhat,pos_label=2)\n\n0.9444444444444444\n\n\n\n#f1-score\nfrom sklearn.metrics import f1_score\nf1_score(test_y,yhat,pos_label=2)\n\n0.9714285714285714\n\n\n\n#visualisasi confusion matrix\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n  \"\"\"\n  This function prints and plots the confusion matrix.\n  Normalization can be applied by setting `normalize=True`.\n  \"\"\"\n  if normalize:\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    print(\"Normalized confusion matrix\")\n  else:\n    print('Confusion matrix, without normalization')\n \n  print(cm)\n\n  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n  plt.title(title)\n  plt.colorbar()\n  tick_marks = np.arange(len(classes))\n  plt.xticks(tick_marks, classes, rotation=45)\n  plt.yticks(tick_marks, classes)\n  \n  fmt = '.2f' if normalize else 'd'\n  thresh = cm.max() / 2.\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, format(cm[i, j], fmt),\n             horizontalalignment=\"center\",\n             color=\"white\" if cm[i, j] &gt; thresh else \"black\")\n  plt.tight_layout()\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label')\nprint(confusion_matrix(test_y, yhat, labels=[2,4]))\n\n[[85  5]\n [ 0 47]]\n\n\n\n#confusion matrix\ncnf_matrix =confusion_matrix(test_y, yhat, labels=[2,4])\nplt.figure()\nplot_confusion_matrix(cnf_matrix,classes=['Jinak=2', 'Ganas=4'],normalize = False, title='Confusion matrix')\n\nConfusion matrix, without normalization\n[[85  5]\n [ 0 47]]"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul6.html",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul6.html",
    "title": "Modul 6 Praktikum Sains Data",
    "section": "",
    "text": "Clustering\nK-Means"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul6.html#outline",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul6.html#outline",
    "title": "Modul 6 Praktikum Sains Data",
    "section": "",
    "text": "Clustering\nK-Means"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul6.html#k-means-clustering-menggunakan-dataset-random",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul6.html#k-means-clustering-menggunakan-dataset-random",
    "title": "Modul 6 Praktikum Sains Data",
    "section": "1. K-means Clustering menggunakan dataset random",
    "text": "1. K-means Clustering menggunakan dataset random\nContoh K-Means clustering menggunakan data random.\n\n#import modul yang diperlukan\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\n%matplotlib inline\n\n\nData\n\n#data\nnp.random.seed(0)\n\n\n#membuat sample, dengan centroid sebagai berikut\nX, y = make_blobs(n_samples= 5000, centers = [[4,4],[-2,-1],[2,-3],[1,1]], cluster_std=0.9)\n\n\n#menggambar plot dari sample\nplt.scatter(X[:,0], X[:,1],marker='.')\n\n\n\n\n\n\n\n\n\n\nMembuat model\n\n#buat model k-means, jumlah cluster 4, algoritma akan diulang sebanyak 12 kali\nk_means = KMeans(init=\"k-means++\", n_clusters = 4, n_init =12)\n\n\n#fitting x ke model\nk_means.fit(X)\n\nKMeans(n_clusters=4, n_init=12)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  KMeans?Documentation for KMeansiFittedKMeans(n_clusters=4, n_init=12) \n\n\n\n\nOutput hasil clustering\n\n#hasil clustering pada data\nk_means_labels = k_means.labels_\nk_means_labels\n\narray([0, 3, 3, ..., 1, 0, 0])\n\n\n\n#centroid dari 4 cluster setelah menggunakan model k-means\nk_means_cluster_centers = k_means.cluster_centers_\nk_means_cluster_centers\n\narray([[-2.03743147, -0.99782524],\n       [ 3.97334234,  3.98758687],\n       [ 0.96900523,  0.98370298],\n       [ 1.99741008, -3.01666822]])\n\n\n\n#plot hasil clustering\nfig = plt.figure(figsize=(6,4))\ncolors = plt.cm.Spectral(np.linspace(0,1, len(set(k_means_labels))))\nax= fig.add_subplot(1,1,1)\nfor k, col in zip(range(len([[4,4],[-2,-1],[2,-3],[1,1]])), colors) :\n my_members = (k_means_labels==k)\n cluster_center = k_means_cluster_centers[k]\n ax.plot(X[my_members,0], X[my_members,1], 'w', markerfacecolor=col,marker='.')\n ax.plot(cluster_center[0],cluster_center[1],'o',markerfacecolor=col,markeredgecolor='k',markersize=\n6)\nax.set_title('KMeans Clustering')\n#hilangkan sumbu\nax.set_xticks(())\nax.set_yticks(())\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul6.html#clustering-menggunakan-dataset-csv",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul6.html#clustering-menggunakan-dataset-csv",
    "title": "Modul 6 Praktikum Sains Data",
    "section": "2. Clustering menggunakan dataset (csv)",
    "text": "2. Clustering menggunakan dataset (csv)\nPada contoh ini, akan dilakukan clustering menggunakan dataset nasabah bank (Cust_Segmentation.csv). - Kaggle\nNasabah tersebut akan dikelompokkan menjadi 3 cluster.\n\n#import modul dan membaca dataset\nimport pandas as pd\ncust_df = pd.read_csv(r'./Cust_Segmentation.csv')\n\n\nData\n\n#cuplikan dataset\ncust_df.head()\n\n\n\n\n\n\n\n\nCustomer Id\nAge\nEdu\nYears Employed\nIncome\nCard Debt\nOther Debt\nDefaulted\nAddress\nDebtIncomeRatio\n\n\n\n\n0\n1\n41\n2\n6\n19\n0.124\n1.073\n0.0\nNBA001\n6.3\n\n\n1\n2\n47\n1\n26\n100\n4.582\n8.218\n0.0\nNBA021\n12.8\n\n\n2\n3\n33\n2\n10\n57\n6.111\n5.802\n1.0\nNBA013\n20.9\n\n\n3\n4\n29\n2\n4\n19\n0.681\n0.516\n0.0\nNBA009\n6.3\n\n\n4\n5\n47\n1\n31\n253\n9.308\n8.908\n0.0\nNBA008\n7.2\n\n\n\n\n\n\n\n\n#periksa tipe data dari masing masing kolom pada dataset\ncust_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 850 entries, 0 to 849\nData columns (total 10 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   Customer Id      850 non-null    int64  \n 1   Age              850 non-null    int64  \n 2   Edu              850 non-null    int64  \n 3   Years Employed   850 non-null    int64  \n 4   Income           850 non-null    int64  \n 5   Card Debt        850 non-null    float64\n 6   Other Debt       850 non-null    float64\n 7   Defaulted        700 non-null    float64\n 8   Address          850 non-null    object \n 9   DebtIncomeRatio  850 non-null    float64\ndtypes: float64(4), int64(5), object(1)\nmemory usage: 66.5+ KB\n\n\n\n\nPreprocessing data\n\n#buat semua data menjadi numerik\ncust_df2 = cust_df.drop('Address',axis=1)\ncust_df2.head()\n\n\n\n\n\n\n\n\nCustomer Id\nAge\nEdu\nYears Employed\nIncome\nCard Debt\nOther Debt\nDefaulted\nDebtIncomeRatio\n\n\n\n\n0\n1\n41\n2\n6\n19\n0.124\n1.073\n0.0\n6.3\n\n\n1\n2\n47\n1\n26\n100\n4.582\n8.218\n0.0\n12.8\n\n\n2\n3\n33\n2\n10\n57\n6.111\n5.802\n1.0\n20.9\n\n\n3\n4\n29\n2\n4\n19\n0.681\n0.516\n0.0\n6.3\n\n\n4\n5\n47\n1\n31\n253\n9.308\n8.908\n0.0\n7.2\n\n\n\n\n\n\n\n\ncust_df2.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 850 entries, 0 to 849\nData columns (total 9 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   Customer Id      850 non-null    int64  \n 1   Age              850 non-null    int64  \n 2   Edu              850 non-null    int64  \n 3   Years Employed   850 non-null    int64  \n 4   Income           850 non-null    int64  \n 5   Card Debt        850 non-null    float64\n 6   Other Debt       850 non-null    float64\n 7   Defaulted        700 non-null    float64\n 8   DebtIncomeRatio  850 non-null    float64\ndtypes: float64(4), int64(5)\nmemory usage: 59.9 KB\n\n\n\n#scaling value yang terdapat pada dataset agar error tidak besar\nfrom sklearn.preprocessing import StandardScaler\nX = cust_df2.values[:,1:]\nX = np.nan_to_num(X)\nClus_dataSet= StandardScaler().fit_transform(X)\nClus_dataSet\n\narray([[ 0.74291541,  0.31212243, -0.37878978, ..., -0.59048916,\n        -0.52379654, -0.57652509],\n       [ 1.48949049, -0.76634938,  2.5737211 , ...,  1.51296181,\n        -0.52379654,  0.39138677],\n       [-0.25251804,  0.31212243,  0.2117124 , ...,  0.80170393,\n         1.90913822,  1.59755385],\n       ...,\n       [-1.24795149,  2.46906604, -1.26454304, ...,  0.03863257,\n         1.90913822,  3.45892281],\n       [-0.37694723, -0.76634938,  0.50696349, ..., -0.70147601,\n        -0.52379654, -1.08281745],\n       [ 2.1116364 , -0.76634938,  1.09746566, ...,  0.16463355,\n        -0.52379654, -0.2340332 ]])\n\n\n\n\nMembuat model\n\n#modelling\nclusterNum = 3\nk_means_cust = KMeans(init = 'k-means++', n_clusters= clusterNum, n_init = 12) \n#3 cluster, dengan running algoritma sebanyak 12 kali\n\nk_means_cust.fit(X)\n\n#hasil clustering\nlabels_cust = k_means_cust.labels_\nprint(labels_cust)\n\n[2 0 2 2 1 0 2 0 2 0 0 2 2 2 2 2 2 2 0 2 2 2 2 0 0 0 2 2 0 2 0 2 2 2 2 2 2\n 2 2 0 2 0 2 1 2 0 2 2 2 0 0 2 2 0 0 2 2 2 0 2 0 2 0 0 2 2 0 2 2 2 0 0 0 2\n 2 2 2 2 0 2 0 0 1 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 0 2\n 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2 2 2 0 2 2 2 2 2 2 2 0 2 0 2\n 2 2 2 2 2 2 0 2 0 0 2 0 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 2 2 2 0 2\n 2 2 2 2 0 2 2 0 2 0 2 2 0 1 2 0 2 2 2 2 2 2 1 0 2 2 2 2 0 2 2 0 0 2 0 2 0\n 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 1 0 2 2 2 2 2 2 2 0 2 2 2 2\n 2 2 0 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 0 2 0 2 0 0 2 2 2 2 2 2\n 2 2 2 0 0 0 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 0 2 0 0 2\n 2 2 2 2 0 2 2 2 2 2 2 0 2 2 0 2 2 0 2 2 2 2 2 0 2 2 2 1 2 2 2 0 2 0 0 0 2\n 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2\n 2 0 2 2 0 2 2 2 2 0 2 2 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 1\n 2 2 2 2 2 2 0 2 2 2 1 2 2 2 2 0 2 1 2 2 2 2 0 2 0 0 0 2 2 0 0 2 2 2 2 2 2\n 2 0 2 2 2 2 0 2 2 2 0 2 0 2 2 2 0 2 2 2 2 0 0 2 2 2 2 0 2 2 2 2 0 2 2 2 2\n 2 0 0 2 2 2 2 2 2 2 2 2 2 2 1 0 2 2 2 2 2 2 0 2 2 2 2 0 2 2 0 2 2 1 2 1 2\n 2 1 2 2 2 2 2 2 2 2 2 0 2 0 2 2 1 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 2 0\n 2 2 2 2 2 2 0 2 2 2 2 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0\n 0 2 2 0 2 0 2 2 0 2 0 2 2 1 2 0 2 0 2 2 2 2 2 0 0 2 2 2 2 0 2 2 2 0 0 2 2\n 0 2 2 2 0 2 1 2 2 0 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2 0 2 2 0 2 2 2 2 2 2\n 2 2 0 2 2 0 2 0 2 0 0 2 2 2 0 2 0 2 2 2 2 2 0 2 2 2 2 0 0 2 2 0 0 2 2 2 2\n 2 0 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 2 0 2 0 0 2 2 0 2 2 2 2 2 0 0\n 2 2 2 2 2 2 2 0 2 2 2 2 2 2 1 0 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0]\n\n\n\n#menambahkan kolom hasil clustering pada dataset\ncust_df2['Clus_km'] = labels_cust\ncust_df2.head(5)\n\n\n\n\n\n\n\n\nCustomer Id\nAge\nEdu\nYears Employed\nIncome\nCard Debt\nOther Debt\nDefaulted\nDebtIncomeRatio\nClus_km\n\n\n\n\n0\n1\n41\n2\n6\n19\n0.124\n1.073\n0.0\n6.3\n2\n\n\n1\n2\n47\n1\n26\n100\n4.582\n8.218\n0.0\n12.8\n0\n\n\n2\n3\n33\n2\n10\n57\n6.111\n5.802\n1.0\n20.9\n2\n\n\n3\n4\n29\n2\n4\n19\n0.681\n0.516\n0.0\n6.3\n2\n\n\n4\n5\n47\n1\n31\n253\n9.308\n8.908\n0.0\n7.2\n1\n\n\n\n\n\n\n\n\n#melihat rata rata per cluster\ncust_df2.groupby('Clus_km').mean()\n\n\n\n\n\n\n\n\nCustomer Id\nAge\nEdu\nYears Employed\nIncome\nCard Debt\nOther Debt\nDefaulted\nDebtIncomeRatio\n\n\nClus_km\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n402.295082\n41.333333\n1.956284\n15.256831\n83.928962\n3.103639\n5.765279\n0.171233\n10.724590\n\n\n1\n410.166667\n45.388889\n2.666667\n19.555556\n227.166667\n5.678444\n10.907167\n0.285714\n7.322222\n\n\n2\n432.468413\n32.964561\n1.614792\n6.374422\n31.164869\n1.032541\n2.104133\n0.285185\n10.094761\n\n\n\n\n\n\n\n\n#plot hasil clustering berdasarkan age dan income\narea = np.pi * (X[:, 1])**2\nplt.scatter(X[:,0],X[:,3],s = area, c = labels_cust.astype(float), alpha=0.5)\nplt.xlabel('Age',fontsize=18)\nplt.ylabel('Income',fontsize = 16)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nKesimpulan\nDari datset diatas, kita dapat membuat 3 cluster, dengan segmentasi sebagai berikut:\n\nKuning : dewasa muda, pendapatan rendah\nUngu: dewasa menengah, pendapatan kelas menengah\nHijau: dewasa tua, pendapatan tinggi"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul8.html",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul8.html",
    "title": "Modul 8 Praktikum Sains Data",
    "section": "",
    "text": "pip install tensorflow\n\nRequirement already satisfied: tensorflow in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.16.1)\nRequirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.16.1)\nRequirement already satisfied: absl-py&gt;=1.0.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (2.1.0)\nRequirement already satisfied: astunparse&gt;=1.6.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers&gt;=23.5.26 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,&gt;=0.2.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta&gt;=0.1.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (0.2.0)\nRequirement already satisfied: h5py&gt;=3.10.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (3.11.0)\nRequirement already satisfied: libclang&gt;=13.0.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (0.3.2)\nRequirement already satisfied: opt-einsum&gt;=2.3.2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (3.3.0)\nRequirement already satisfied: packaging in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (23.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,&lt;5.0.0dev,&gt;=3.20.3 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (4.25.3)\nRequirement already satisfied: requests&lt;3,&gt;=2.21.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (2.31.0)\nRequirement already satisfied: setuptools in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (69.5.1)\nRequirement already satisfied: six&gt;=1.12.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (1.16.0)\nRequirement already satisfied: termcolor&gt;=1.1.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions&gt;=3.6.6 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (4.11.0)\nRequirement already satisfied: wrapt&gt;=1.11.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (1.16.0)\nRequirement already satisfied: grpcio&lt;2.0,&gt;=1.24.3 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (1.62.2)\nRequirement already satisfied: tensorboard&lt;2.17,&gt;=2.16 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (2.16.2)\nRequirement already satisfied: keras&gt;=3.0.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (3.3.3)\nRequirement already satisfied: numpy&lt;2.0.0,&gt;=1.26.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1-&gt;tensorflow) (1.26.4)\nRequirement already satisfied: wheel&lt;1.0,&gt;=0.23.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse&gt;=1.6.0-&gt;tensorflow-intel==2.16.1-&gt;tensorflow) (0.43.0)\nRequirement already satisfied: rich in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras&gt;=3.0.0-&gt;tensorflow-intel==2.16.1-&gt;tensorflow) (13.7.1)\nRequirement already satisfied: namex in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras&gt;=3.0.0-&gt;tensorflow-intel==2.16.1-&gt;tensorflow) (0.0.8)\nRequirement already satisfied: optree in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras&gt;=3.0.0-&gt;tensorflow-intel==2.16.1-&gt;tensorflow) (0.11.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorflow-intel==2.16.1-&gt;tensorflow) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorflow-intel==2.16.1-&gt;tensorflow) (3.6)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorflow-intel==2.16.1-&gt;tensorflow) (2.1.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorflow-intel==2.16.1-&gt;tensorflow) (2023.11.17)\nRequirement already satisfied: markdown&gt;=2.6.8 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard&lt;2.17,&gt;=2.16-&gt;tensorflow-intel==2.16.1-&gt;tensorflow) (3.6)\nRequirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard&lt;2.17,&gt;=2.16-&gt;tensorflow-intel==2.16.1-&gt;tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug&gt;=1.0.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard&lt;2.17,&gt;=2.16-&gt;tensorflow-intel==2.16.1-&gt;tensorflow) (3.0.2)\nRequirement already satisfied: MarkupSafe&gt;=2.1.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug&gt;=1.0.1-&gt;tensorboard&lt;2.17,&gt;=2.16-&gt;tensorflow-intel==2.16.1-&gt;tensorflow) (2.1.4)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich-&gt;keras&gt;=3.0.0-&gt;tensorflow-intel==2.16.1-&gt;tensorflow) (3.0.0)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich-&gt;keras&gt;=3.0.0-&gt;tensorflow-intel==2.16.1-&gt;tensorflow) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;keras&gt;=3.0.0-&gt;tensorflow-intel==2.16.1-&gt;tensorflow) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n[notice] A new release of pip is available: 23.2.1 -&gt; 24.0\n[notice] To update, run: python.exe -m pip install --upgrade pip"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul8.html#membuat-model",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul8.html#membuat-model",
    "title": "Modul 8 Praktikum Sains Data",
    "section": "Membuat Model",
    "text": "Membuat Model\nLangkah-langkah dalam membangun model:\n\nSpesifikasi arsitekturnya\nCompile\nFit\nPrediksi\n\n\n#Data dibagi menjadi data train, test, dan validasi\n#Data validasi diambil dari 5000 data pertama dari data train full\n#Lalu diskalakan dari 0 - 1\n\nX_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\ny_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n\n\nprint(\"X_train: \", X_train.shape)\nprint(\"y_train: \", y_train.shape)\nprint(\"X_valid: \", X_valid.shape)\nprint(\"y_valid: \", y_valid.shape)\nprint(\"X_test: \", X_test.shape)\nprint(\"y_test: \", y_test.shape)\n\nX_train:  (55000, 28, 28)\ny_train:  (55000,)\nX_valid:  (5000, 28, 28)\ny_valid:  (5000,)\nX_test:  (10000, 28, 28)\ny_test:  (10000,)\n\n\n\nmodel = keras.models.Sequential()\nmodel.add(keras.layers.Flatten(input_shape = [28, 28])) #mengubah input menjadi 1D array\nmodel.add(keras.layers.Dense(300, activation = 'relu')) #hidden layer dgn 300 neuron dan activation ReLu\nmodel.add(keras.layers.Dense(100, activation = 'relu')) #hidden layer dgn 100 neuron dan activation ReLu\nmodel.add(keras.layers.Dense(10, activation = 'softmax')) #output layer dgn 10 neuron dan activation softmax\n\nc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n\n\n\nmodel.summary()\n\nModel: \"sequential\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten (Flatten)               │ (None, 784)            │             0 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (Dense)                   │ (None, 300)            │       235,500 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (Dense)                 │ (None, 100)            │        30,100 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (Dense)                 │ (None, 10)             │         1,010 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n\n\n\n Total params: 266,610 (1.02 MB)\n\n\n\n Trainable params: 266,610 (1.02 MB)\n\n\n\n Non-trainable params: 0 (0.00 B)"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/modul8.html#loss-function",
    "href": "semuahalaman/modulprak/2022/genap/saindat/modul8.html#loss-function",
    "title": "Modul 8 Praktikum Sains Data",
    "section": "Loss Function",
    "text": "Loss Function\nNilai akumulasi error dari seluruh data prediksi\nContoh: - MSE (Mean Squared Error) pada masalah Regresi - Sparse_Categorical_Entropy pada masalah klasifikasi pada 2 atau lebih label kelas\nDigunakan untuk mengukur performa model\n\nmodel.compile(loss = 'sparse_categorical_crossentropy',\n              optimizer = 'sgd', #stocastic gradient descent\n              metrics = ['accuracy'])\n\n\n#fit the model\nhistory = model.fit(X_train, y_train, epochs = 10,\n                    validation_data = (X_valid, y_valid))\n\nEpoch 1/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 9s 5ms/step - accuracy: 0.6836 - loss: 0.9952 - val_accuracy: 0.8294 - val_loss: 0.5058\nEpoch 2/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 6s 4ms/step - accuracy: 0.8253 - loss: 0.5001 - val_accuracy: 0.8390 - val_loss: 0.4606\nEpoch 3/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 6s 3ms/step - accuracy: 0.8429 - loss: 0.4473 - val_accuracy: 0.8582 - val_loss: 0.4038\nEpoch 4/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 6s 3ms/step - accuracy: 0.8537 - loss: 0.4158 - val_accuracy: 0.8640 - val_loss: 0.3900\nEpoch 5/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 11s 3ms/step - accuracy: 0.8573 - loss: 0.4013 - val_accuracy: 0.8708 - val_loss: 0.3719\nEpoch 6/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 6s 3ms/step - accuracy: 0.8674 - loss: 0.3779 - val_accuracy: 0.8702 - val_loss: 0.3795\nEpoch 7/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - accuracy: 0.8701 - loss: 0.3676 - val_accuracy: 0.8644 - val_loss: 0.3773\nEpoch 8/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 6s 4ms/step - accuracy: 0.8756 - loss: 0.3541 - val_accuracy: 0.8766 - val_loss: 0.3541\nEpoch 9/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 7s 4ms/step - accuracy: 0.8759 - loss: 0.3435 - val_accuracy: 0.8704 - val_loss: 0.3550\nEpoch 10/10\n1719/1719 ━━━━━━━━━━━━━━━━━━━━ 11s 4ms/step - accuracy: 0.8818 - loss: 0.3361 - val_accuracy: 0.8700 - val_loss: 0.3585"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/genap/saindat/saindat2022genap.html",
    "href": "semuahalaman/modulprak/2022/genap/saindat/saindat2022genap.html",
    "title": "Praktikum Saindat (Sains Data) 2022 Genap (Kurikulum 2020)",
    "section": "",
    "text": "Kembali ke Praktikum\nIni adalah versi website (yang baru dibuat setelah semester ini berakhir) dari modul yang ada di link berikut: https://drive.google.com/open?id=1x2SR_L3pWH0W8Z0IUbL1ifBOcMSkWVYe\n\nTimeline\n\nModul 1 (belum tersedia)\nModul 2: Regresi Linier Sederhana dan Berganda\nModul 3: Regresi Logistik\nModul 4: Evaluation Metrics, Decision Tree, dan SVM\nModul 5: K-Nearest Neighbor\nModul 6: Clustering dan K-Means\nModul 7: Pendahuluan Artificial Neural Network (ANN)\nModul 8: Deep Learning Model untuk Klasifikasi Fashion MNIST\nModul 9: Hyperparameter Tuning"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "",
    "text": "Kembali ke Struktur Data\nUntuk praktikum Struktur Data, kita akan menggunakan bahasa pemrograman C, sehingga perlu diinstal beberapa software, terutama gcc dan aplikasi Visual Studio Code. Apabila Anda tidak bersedia menginstal software tersebut di laptop, Anda tetap dapat menggunakan Sololearn Compiler Playground atau situs serupa. Kebetulan, aplikasi Sololearn juga tersedia untuk smartphone (Android, iOS).\nSelain itu, di praktikum terakhir, kita juga akan mulai membahas database dan SQL menggunakan SQLite, termasuk aplikasi DB Viewer (database viewer) untuk SQLite, sehingga keduanya perlu diinstal juga.\nAda juga graphviz (opsional) apabila Anda berniat ingin membuat visualisasi untuk berbagai struktur data, terutama berbagai jenis tree."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-gcc",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-gcc",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Instalasi gcc",
    "text": "Instalasi gcc\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-dan-konfigurasi-visual-studio-code",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-dan-konfigurasi-visual-studio-code",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Instalasi dan konfigurasi Visual Studio Code",
    "text": "Instalasi dan konfigurasi Visual Studio Code\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-sqlite",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-sqlite",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Instalasi SQLite",
    "text": "Instalasi SQLite\nhttps://www.sqlite.org/download.html\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-db-browser-for-sqlite-db4s",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-db-browser-for-sqlite-db4s",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Instalasi DB Browser for SQLite (DB4S)",
    "text": "Instalasi DB Browser for SQLite (DB4S)\n\nWindows: dari installer\nStorage yang dibutuhkan: perkiraan 50-70 MB\n\nBuka situs https://sqlitebrowser.org/dl/, scroll ke bagian “Windows”, lalu pencet tulisan “DB Browser for SQLite - Standard installer for 64-bit Windows” untuk men-download/mengunduh installer untuk DB Browser for SQLite.\nSetelah proses download selesai, buka installer nya. Ikuti saja. Secara keseluruhan, Anda tinggal menekan Next berkali-kali sampai proses instalasi selesai. Apabila ada persetujuan seperti EULA (End-User License Agreement), setujui saja (centang). Namun, akan ada bagian Shortcuts, di mana Anda bisa mencentang semua pilihan untuk DB Browser (SQLite). Abaikan “SQLCipher” (tidak perlu dicentang).\nSetelah menekan Next beberapa kali, akan ada semacam proses loading, yang artinya proses instalasi sedang berjalan. Tunggu saja selama perkiraan 1 (satu) menit.\nNantinya, apabila proses instalasi sudah selesai, tombol Next akan berubah menjadi Finish, maka tekan Finish. Anda boleh menghapus installer nya.\n\n\n\nmacOS: dari file DMG\nStorage yang dibutuhkan: perkiraan 50-70 MB\n\nTentukan apakah laptop Anda memiliki prosesor Intel atau Apple Silicon. Di ujung kiri atas layar laptop Anda, tekan tombol Apple (), lalu “About This Mac”. Setelah itu, akan muncul beberapa informasi tentang MacBook Anda, termasuk keterangan prosesor atau chip, apakah Apple M1/M2 (Apple Silicon) atau Intel.\nBuka situs https://sqlitebrowser.org/dl/, scroll ke bagian “macOS”, lalu pencet tulisan “DB Browser for SQLite” yang sesuai dengan prosesor laptop Anda (antara Intel atau Apple Silicon) untuk men-download/mengunduh installer DB Browser for SQLite, yang berupa file DMG.\nSetelah proses download selesai, buka file DMG tersebut. Apabila muncul peringatan bahwa aplikasi tidak dikenal, tidak masalah, pencet Open saja.\nAkan muncul gambar/icon aplikasinya, dengan tulisan “DB Browser for SQLite”, serta folder Applications di sampingnya (dan ada panah di antaranya). Tarik gambar aplikasinya ke folder Applications tersebut, sesuai panah. Sebenarnya, ini adalah proses copy-paste agar aplikasinya menjadi tersedia di laptop Anda. Tunggu saja selama perkiraan 1 (satu) menit.\nProses instalasi sudah selesai dan aplikasi DB Browser untuk SQLite sudah bisa dibuka melalui folder Applications. Apabila, di Desktop, muncul semacam file Disk Image dengan tulisan DB Browser atau semacamnya, klik kanan lalu Eject saja. Anda boleh menghapus file DMG nya."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-graphviz",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-graphviz",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Instalasi graphviz",
    "text": "Instalasi graphviz\n\nWindows: dari installer\nhttps://graphviz.gitlab.io/download/\nblabla\n\n\nmacOS: dari source code\nStorage yang dibutuhkan: perkiraan 200-500 MB\n\nBuka situs https://graphviz.gitlab.io/download/source/, scroll ke bagian “Stable Releases”, lalu unduh/download versi yang terbaru (teratas), dengan menekan tulisan biru yang berakhiran “gz” (bukan yang sha256).\nSetelah proses download selesai, akan muncul file yang berakhiran .tar.gz. Itulah file yang telah diunduh. Klik file tersebut dua kali, seolah-olah ingin membuka suatu aplikasi. (Proses ini bernama extraction/unzipping. Daripada klik dua kali, Anda juga bisa klik kanan lalu “Extract”.) Kemudian, akan muncul folder baru dengan nama yang sama, tetapi tanpa akhiran .tar.gz, kira-kira bernama “graphviz-(versi)”, yang selanjutnya akan kita sebut “folder graphviz”.\nKlik kanan pada folder graphviz tersebut, lalu pencet “New Terminal at Folder”. Akan muncul Terimnal, yaitu semacam cmd atau command prompt untuk macOS.\nKetik ./configure, lalu tekan enter. Akan muncul banyak tulisan yang terus membanjiri Terminal. Tunggu saja selama perkiraan 3 (tiga) menit, sampai banjir berhenti. (Tentu saja, sambil menunggu, Anda boleh sambil melakukan hal lain, menggunakan aplikasi lain dan sebagainya, selama tidak menutup Terminal.)\nLalu, ketik make, tekan enter. Akan muncul banyak tulisan yang terus membanjiri Terminal lagi, tetapi kali ini lebih lama. Tunggu saja selama perkiraan 10 (sepuluh) menit, sampai banjir berhenti.\nTerakhir, ketik make install, dan tekan enter. Akan muncul banyak tulisan yang membanjiri Terminal lagi, tetapi tidak lama. Tunggu saja selama perkiraan 1 (satu) menit.\nSetelah banjir berhenti, proses instalasi sudah selesai dan Anda boleh menutup Terminal.\n\nSetelah instalasi selesai, Anda bisa membuka aplikasi Terminal (ada di folder Applications, lalu masuk folder Utilities) kapan saja, di mana saja, lalu menggunakan command dot untuk menggunakan graphviz. Contohnya, Anda bisa mengetik dot -V untuk memeriksa versi graphviz yang telah terinstal, atau mengetik dot -? untuk melihat daftar command yang ada."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#konfigurasi-visual-studio-code-untuk-graphviz",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#konfigurasi-visual-studio-code-untuk-graphviz",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Konfigurasi Visual Studio Code untuk graphviz",
    "text": "Konfigurasi Visual Studio Code untuk graphviz\nInstal extension berikut ini agar lebih mudah melihat gambar yang dihasilkan oleh bahasa Graphviz DOT:\nName: Graphviz Interactive Preview Id: tintinweb.graphviz-interactive-preview Description: Graphviz (dot) Interactive Preview Version: 0.3.5 Publisher: tintinweb VS Marketplace Link: https://marketplace.visualstudio.com/items?itemName=tintinweb.graphviz-interactive-preview\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#sololearn-compiler-playground",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#sololearn-compiler-playground",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Sololearn Compiler Playground",
    "text": "Sololearn Compiler Playground\nhttps://www.sololearn.com/compiler-playground/"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#graphviz-online",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#graphviz-online",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Graphviz Online",
    "text": "Graphviz Online\nhttps://dreampuf.github.io/GraphvizOnline/"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "",
    "text": "Kembali ke Struktur Data"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#array",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#array",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "Array",
    "text": "Array\nblabla\n(jangan lupa ukuran array dengan sizeof)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#char-huruf-putchar-dan-getchar",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#char-huruf-putchar-dan-getchar",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "char (huruf), putchar, dan getchar",
    "text": "char (huruf), putchar, dan getchar\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#string-puts-fgets-strlen-dan-strcmpstrncmp",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#string-puts-fgets-strlen-dan-strcmpstrncmp",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "string, puts, fgets, strlen, dan strcmp/strncmp",
    "text": "string, puts, fgets, strlen, dan strcmp/strncmp\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#menampilkan-semua-elemen-pada-array",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#menampilkan-semua-elemen-pada-array",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "Menampilkan semua elemen pada array",
    "text": "Menampilkan semua elemen pada array\nUntuk menampilkan semua elemen yang ada di dalam suatu array, kita perlu melakukan iterasi pada tiap elemen di array, lalu menggunakan printf pada tiap iterasi. Agar mengetahui batasan for loop, kita perlu mengetahui panjang array. Kita bisa membuat fungsi yang mem-print satu per satu elemen suatu array sampai panjang array tersebut.\nvoid array_int_print(int arr[], int arr_length) {\n    for (int i = 0; i &lt; arr_length; i++) {\n        printf(\"%d \", arr[i]);\n    }\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#mendalami-proses-kompilasi-program",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#mendalami-proses-kompilasi-program",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "Mendalami proses kompilasi program",
    "text": "Mendalami proses kompilasi program\n(diagram, empat langkah, caranya satu-satu di gcc)\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#preprocessor-directive-dan-header-file-.h",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#preprocessor-directive-dan-header-file-.h",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "Preprocessor directive dan header file (.h)",
    "text": "Preprocessor directive dan header file (.h)\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#build-system-make-kompilasi-otomatis-dengan-makefile",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#build-system-make-kompilasi-otomatis-dengan-makefile",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "Build system make: kompilasi otomatis dengan Makefile",
    "text": "Build system make: kompilasi otomatis dengan Makefile\nSumber referensi yang digunakan untuk materi pada bagian ini:\n\nHow to Create a Simple Makefile - Introduction to Makefiles\nhttps://www.youtube.com/watch?v=_r7i5X0rXJk\nMakefiles: 95% of what you need to know\nhttps://www.youtube.com/watch?v=DtGrdB8wQ_8\nhttps://github.com/gwu-cs-os/evening_os_hour/tree/master/f19/10.2-makefiles\n\nContoh Makefile 1 (tanpa variabel):\n# this is a comment\n\n## general format:\n\n# target: its dependencies\n#   command to build target from its dependencies\n\n## ^ tab character\n\n# if you only type \"make\",\n# it's going to execute the top most command,\n# which, in here, happens to be \"all\"\nall: helloworld\n\nhelloworld: helloworld.o dothing.o\n    gcc helloworld.o dothing.o -o helloworld\n\nhelloworld.o: helloworld.c\n    gcc -c helloworld.c\n\ndothing.o: dothing.c\n    gcc -c dothing.c\n\nclean:\n    rm helloworld *.o\n\ncleano:\n    rm *.o\nContoh Makefile 2 (dengan variabel):\n# this is a comment\n\n# === VARIABLES ===\n\n## general format:\n\n# VARNAME=word1 word2 word3\n# no space before NOR after the equal sign!\n# make sure NOT A SINGLE LINE ends with a trailing space!!\n# the variables will later be accessed with $(VARNAME)\n\n##\n\nCOMPILER=gcc\n\nCFILES=helloworld.c dothing.c\nOBJFILES=helloworld.o dothing.o\nBINARYNAME=helloworld\n\n# === COMMANDS ===\n\n## general format:\n\n# target: dependency\n#   command\n\n## ^ tab character\n\n# $@ refers to the target\n# $^ refers to the dependency\n\n# if you only type \"make\",\n# it's going to execute the top most command,\n# which, in here, happens to be \"all\"\nall: $(BINARYNAME)\n\n$(BINARYNAME): $(OBJFILES)\n    $(COMPILER) $(OBJFILES) -o $(BINARYNAME)\n\n%.o: %.c\n    $(COMPILER) -c $^ -o $@\n\nclean:\n    rm $(BINARYNAME) $(OBJFILES)\n\ncleano:\n    rm $(OBJFILES)\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#referensi-tambahan-cmake",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#referensi-tambahan-cmake",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "Referensi tambahan: CMake",
    "text": "Referensi tambahan: CMake\nKita telah belajar cara membuat Makefile secara manual dan menggunakannya. Sejauh ini, Makefile yang kita buat melibatkan beberapa variabel yang perlu kita setting secara manual. Untuk program dan proyek skala kecil seperti di mata kuliah Struktur Data, itu tidak masalah.\nSebenarnya, sudah ada software untuk membuat Makefile secara otomatis, yaitu CMake. Bahkan, CMake bisa menghasilkan Makefile untuk berbagai sistem operasi yang memiliki berbagai macam ketergantungan yang berbeda-beda. Namun, cara penggunaannya bisa agak sulit, sehingga tidak kami ajarkan di praktikum untuk menghemat waktu. Anda bisa membaca lebih lanjut tentang CMake di internet, seperti di link berikut:\nhttps://earthly.dev/blog/cmake-vs-make-diff/"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#faq-seputar-pembuatan-aplikasi-cli-gui-installer",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#faq-seputar-pembuatan-aplikasi-cli-gui-installer",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "FAQ seputar pembuatan aplikasi: CLI, GUI, installer",
    "text": "FAQ seputar pembuatan aplikasi: CLI, GUI, installer\nSampai sini, kita sudah bisa mengkompilasi program C ke dalam bentuk executable, hingga menggabungkan beberapa file yang berbeda dengan bantuan header file. Bahkan, kita sudah mempelajari penggunaan build system seperti make agar proses kompilasi bisa dilakukan secara otomatis.\nSejauh ini, semua program yang kita buat melibatkan command line (juga disebut command prompt atau terminal), karena perlu menampilkan output dan menerima input. Bisa dikatakan, tampilan seperti itu adalah semacam “perantara”, atau istilahnya “antarmuka” (interface), agar kita bisa “berkomunikasi” dengan program atau aplikasi tersebut. Antarmuka seperti itu disebut command-line interface (CLI).\n(Sebenarnya, istilah “command-line interface” umumnya digunakan untuk program yang sudah dirancang agar bisa merespon dengan baik terhadap berbagai macam input. Bahkan, daripada hanya mengetik ./namaprogram, kita bisa langsung memberi input di sebelah nama programnya, misalnya ./namaprogram input1 input2. Cara membuat fitur seperti ini di bahasa pemrograman C dibahas di Modul opsional 4b.)\n\n\n\n\n\n\nApakah ada program tanpa antarmuka?\n\n\n\nIya, ada, tidak mustahil. Mungkin terdengar aneh, program yang tidak memberikan output di command line maupun menerima input, dan terdengar tidak berguna. Biasanya, program seperti itu melakukan beberapa hal (seperti urusan membuat, mengubah, maupun menghapus file, yang dibahas di Modul opsional 4a) yang sudah ditentukan dan sudah dibuat kodenya sehingga tidak perlu menerima informasi tambahan apapun (sehingga tidak memerlukan input), dan tidak perlu memberikan informasi apapun (sehingga tidak memberikan output).\nNamun, program seperti itu jarang ada, dan biasanya dibuat untuk kepentingan pribadi saja.\n\n\nMungkin dalam kehidupan sehari-hari, kalian lebih terbiasa dengan aplikasi yang memiliki semacam tampilan dengan tombol-tombol yang bisa ditekan dan sebagainya. Tampilan atau antarmuka seperti itu disebut graphical user interface (GUI).\nBeberapa aplikasi memiliki CLI, seperti aplikasi atau program yang kita buat selama praktikum. Beberapa aplikasi memiliki GUI, seperti aplikasi yang biasa kalian gunakan di kehidupan sehari-hari. Beberapa aplikasi memiliki CLI dan GUI (biasanya kita bisa memilih di antara keduanya), dan ada juga aplikasi yang tidak memiliki keduanya (sudah dibahas di atas).\nBerikut adalah beberapa pertanyaan umum seputar pembuatan aplikasi serta jawabannya.\n\nSaya ingin program saya memiliki GUI, bagaimana caranya?\n\nUntuk itu, Anda perlu menginstal “library” (kumpulan kode yang dibuat oleh orang lain) yang diperuntukkan untuk membuat GUI, contohnya GTK. Pada umumnya, library memiliki “dokumentasi” (penjelasan tentang cara penggunaannya), sehingga Anda bisa mempelajari cara menggunakan library tersebut untuk membuat GUI. Tiap library menyediakan fungsi-fungsi yang bisa digunakan, yang bisa “diaktifkan” menggunakan #include, sebagaimana kita mengaktifkan fitur printf dengan #include &lt;stdio.h&gt;.\nLibrary untuk GUI, seperti GTK, memiliki fungsi-fungsi tersendiri untuk merancang GUI. Bahkan, dua library dengan kegunaan yang sama (misalnya sama-sama untuk membuat GUI) bisa memiliki fungsi-fungsi yang berbeda, hinggga cara penggunaan yang jauh berbeda, dan masing-masing memiliki kelebihan dan kekurangan tersendiri.\nSelama praktikum Struktur Data, tidak ada pembahasan tentang cara membuat GUI. Namun, kita akan menggunakan library seperti SQLite untuk kegunaan lainnya (cara menginstal ada di Modul 0).\n\nDi macOS, setelah kompilasi, hasilnya adalah suatu executable atau program yang bisa dijalankan, tetapi tampaknya tidak seperti aplikasi yang biasa saya gunakan. (Sedangkan, di Windows, hasil kompilasi sudah berupa file .exe seperti aplikasi yang biasa digunakan.) Mengapa demikian?\n\nYup betul, memang ada sedikit perbedaan antara Windows dan macOS dalam hal ini. Aplikasi yang biasa digunakan di macOS (dan bisa diinstal dari App Store) berupa file .app (juga disebut app bundle), sedangkan hasil kompilasi gcc berupa executable file yang… tidak memiliki akhiran/extension. Namun, app bundle bisa dibuat secara manual, karena sebenarnya app bundle adalah semacam file .zip yang isinya terdiri dari beberapa folder, dan di dalamnya terdiri dari executable juga.\nBerikut video yang membahas cara membuat app bundle secara manual.\n“How to create an app bundle with dynamically linked libraries on macOS”\nhttps://www.youtube.com/watch?v=ny1Na1oOsb8\n\nBagaimana cara membuat installer?\n\n\n\n\n\n\n\nTL;DR / ringkasan\n\n\n\n\n\nPelajari dulu cara menggunakan CMake, lalu ikuti petunjuk di link berikut:\nhttps://cmake.org/cmake/help/book/mastering-cmake/chapter/Packaging%20With%20CPack.html\n\n\n\nBisa dikatakan, sebenarnya Makefile sudah termasuk semacam installer. Bahkan, beberapa program di macOS (dan Linux) lazim diinstal menggunakan command ./configure lalu make lalu make install, yang memanfaatkan Makefile. Ini sering ditemukan di proyek open source yang ada di GitHub misalnya.\nNamun, installer yang sering dijumpai bisa berupa\n\n.exe atau .msi di Windows\n.pkg di macOS\n\n(File .dmg atau DMG lebih sering ditemukan di macOS daripada .pkg, tetapi DMG sebenarnya hanyalah sejenis .zip yang dikhususkan untuk penyimpanan aplikasi. Meskipun demikian, isi suatu DMG bisa berupa .app maupun .pkg, sehingga DMG juga terkadang disebut installer.)\nSeperti pembuatan GUI, pembuatan installer sudah di luar cakupan praktikum Struktur Data. Salah satu cara membuat installer adalah melalui CMake, dengan salah satu fiturnya yang bernama CPack, yang bisa membuat berbagai jenis installer seperti .exe, .pkg, dan .dmg. Anda bisa mempelajarinya lebih lanjut di link berikut:\nhttps://cmake.org/cmake/help/book/mastering-cmake/chapter/Packaging%20With%20CPack.html"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "",
    "text": "Kembali ke Struktur Data"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pass-by-value-vs.-pass-by-reference",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pass-by-value-vs.-pass-by-reference",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Pass by value vs. pass by reference",
    "text": "Pass by value vs. pass by reference\nDengan adanya pointer, bahkan kita bisa memasukkan alamat ke dalam fungsi, sehingga fungsi tersebut akan memanipulasi data yang ada pada alamat tersebut. Contohnya, perhatikan kedua fungsi “addfive” berikut yang menambahkan lima ke sembarangan bilangan bulat.\nint addfive_notinplace(int number) {\n    int result = number + 5;\n    return result;\n}\n\nvoid addfive_inplace(int * numberptr) {\n    int result = *numberptr + 5;\n    *numberptr = result;\n}\nPerhatikan bahwa ada dua variasi, yaitu “in-place” dan “not-in-place” (juga disebut out-of-place). Berikut beberapa perbedaannya:\n\nInput yang diterima oleh versi “not-in-place” akan berupa nilai bilangan bulat seperti biasanya, tetapi input yang diterima oleh versi “in-place” akan berupa alamat (jangan lupa, pointer menyimpan alamat).\nVersi “in-place” memanfaatkan pointer sehingga bisa langsung mengakses data yang sesungguhnya, sedangkan versi “not-in-place” tidak memanfaatkan pointer sama sekali.\nVersi “in-place” langsung memanipulasi (mengubah) data yang ada pada alamat di pointer yang diberikan. Sedangkan, versi “not-in-place” mengembalikan hasil perhitungan, tanpa memodifikasi data aslinya.\nVersi “not-in-place” mengembalikan hasil berupa int. Sedangkan, versi “in-place” tidak mengembalikan apa-apa, sehingga ditulis return type berupa void (ketiadaan, tidak ada tipe datanya, karena memang tidak ada data yang dikembalikan).\n\nKedua fungsi tersebut bisa digunakan seperti pada kode berikut.\n\n\naddfive.c\n\n#include &lt;stdio.h&gt;\n\nint addfive_notinplace(int number) {\n    int result = number + 5;\n    return result;\n}\n\nvoid addfive_inplace(int * numberptr) {\n    int result = *numberptr + 5;\n    *numberptr = result;\n}\n\nint main () {\n    int a = 27;\n    int b = 27;\n\n    // Perhatikan perbedaan penggunaannya:\n\n    a = addfive_notinplace(a);\n    // - nilainya langsung dimasukkan ke dalam fungsi\n    // - fungsinya mengembalikan hasil untuk memperbarui nilai a\n\n    addfive_inplace(&b);\n    // - yang diberikan adalah alamatnya, sehingga digunakan tanda &\n    // - nilai b akan langsung diubah di tempat, tanpa mengembalikan nilai\n\n    // Hasil berikut ini pasti akan sama\n    printf(\"Hasil a adalah: %d\\n\", a);\n    printf(\"Hasil b adalah: %d\\n\", b);\n\n    return 0;\n}\n\nKetika kita memberikan alamat ke dalam fungsi, istilahnya adalah pass by reference, yaitu memasukkan variabel melalui reference atau alamatnya. Sedangkan, ketika kita langsung memasukkan nilai ke dalam fungsi (seperti yang sudah kita kenal sebelumnya), istilahnya adalah pass by value.\nSeandainya kita mencoba membuat versi “in-place” tanpa memanfaatkan pointer (sehingga tidak menggunakan alamat), pasti akan gagal. Perhatikan kode berikut.\n\n\naddfivefail.c\n\n#include &lt;stdio.h&gt;\n\nvoid addfive_fail(int number) {\n    int result = number + 5;\n    number = result;\n}\n\nint main() {\n    int c = 27;\n\n    // Coba aja...\n    addfive_fail(c);\n\n    printf(\"Hasil c adalah: %d\\n\", c);\n    // Ternyata tidak berubah\n\n    return 0;\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#fungsi-swap_int-untuk-menukar-dua-integer",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#fungsi-swap_int-untuk-menukar-dua-integer",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Fungsi swap_int untuk menukar dua integer",
    "text": "Fungsi swap_int untuk menukar dua integer\nSeperti pada contoh di atas, salah satu keunggulan pointer adalah bisa memberi akses langsung ke data aslinya dari dalam fungsi. Tentu saja, suatu fungsi bisa menerima input berupa lebih dari satu pointer (lebih tepatnya, lebih dari satu alamat). Bahkan, kita bisa membuat fungsi swap_int yang menerima dua alamat dari dua variabel yang sama-sama berupa int, lalu menukar nilai aslinya dari dalam fungsi. Dengan demikian, daripada harus seringkali manual membuat variabel temp untuk menukar dua nilai, kita bisa membuat kodenya sekali saja di dalam fungsi swap_int, sehingga untuk ke depannya tinggal menggunakan fungsi swap_int.\nvoid swap_int(int * ptr1, int * ptr2) {\n    int temp = *ptr1;\n    *ptr1 = *ptr2;\n    *ptr2 = temp;\n}\nFungsi swap_int demikian menjadi suatu fungsi in-place. Berikut contoh penggunaannya:\n\n\nswapint.c\n\n#include &lt;stdio.h&gt;\n\nvoid swap_int(int * ptr1, int * ptr2) {\n    int temp = *ptr1;\n    *ptr1 = *ptr2;\n    *ptr2 = temp;\n}\n\nint main() {\n    int x = 15;\n    int y = 9;\n\n    swap_int(&x, &y);\n    // Fungsi yang bersifat in-place memang umumnya digunakan seperti itu\n\n    printf(\"Nilai x baru: %d\\n\", x);\n    printf(\"Nilai y baru: %d\\n\", y);\n\n    return 0;\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#array-adalah-pointer-ke-elemen-pertama",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#array-adalah-pointer-ke-elemen-pertama",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Array adalah pointer ke elemen pertama",
    "text": "Array adalah pointer ke elemen pertama\n(write some code to assign an array to another array apparently, even though then you are actually assigning a pointer to another pointer. For example assign a string to another string, or to a char pointer. Then try to access from the second pointer, and even modify from the second pointer, then check the new value from the first pointer)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pointer-arithmetic-penjumlahanpengurangan-pointer",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pointer-arithmetic-penjumlahanpengurangan-pointer",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Pointer arithmetic: penjumlahan/pengurangan pointer",
    "text": "Pointer arithmetic: penjumlahan/pengurangan pointer\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#typecasting-untuk-pointer-mengubah-tipe-data-yang-ditunjuk",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#typecasting-untuk-pointer-mengubah-tipe-data-yang-ditunjuk",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Typecasting untuk pointer: mengubah tipe data yang ditunjuk",
    "text": "Typecasting untuk pointer: mengubah tipe data yang ditunjuk\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#char-pointer-sebagai-pointer-satuan-satu-byte",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#char-pointer-sebagai-pointer-satuan-satu-byte",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "char pointer sebagai “pointer satuan” (satu byte)",
    "text": "char pointer sebagai “pointer satuan” (satu byte)\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#penggunaan-memori-sementara-malloc-dan-free",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#penggunaan-memori-sementara-malloc-dan-free",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Penggunaan memori sementara: malloc dan free",
    "text": "Penggunaan memori sementara: malloc dan free\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#variasi-malloc-calloc-realloc",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#variasi-malloc-calloc-realloc",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Variasi malloc: calloc, realloc",
    "text": "Variasi malloc: calloc, realloc\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pengenalan-segmentation-fault",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pengenalan-segmentation-fault",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Pengenalan segmentation fault",
    "text": "Pengenalan segmentation fault\nSegmentation fault (sering juga disebut segfault atau SIGSEGV) adalah error yang menandakan adanya masalah pada alokasi memori dinamis, seperti:\n\nmalloc?\nfreeing the nonexistent or the already freed\n\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#memset-untuk-menyeragamkan-sejumlah-byte",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#memset-untuk-menyeragamkan-sejumlah-byte",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "memset untuk “menyeragamkan” sejumlah byte",
    "text": "memset untuk “menyeragamkan” sejumlah byte\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#memcpy-untuk-menduplikasi",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#memcpy-untuk-menduplikasi",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "memcpy untuk menduplikasi",
    "text": "memcpy untuk menduplikasi\n(termasuk duplikasi struct! :D)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pointer-ke-struct",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pointer-ke-struct",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Pointer ke struct",
    "text": "Pointer ke struct\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#notasi--",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#notasi--",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Notasi ->",
    "text": "Notasi -&gt;\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pointer-di-dalam-struct",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pointer-di-dalam-struct",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Pointer di dalam struct",
    "text": "Pointer di dalam struct\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#automatic-memory-allocation-vs.-dynamic-memory-allocation",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#automatic-memory-allocation-vs.-dynamic-memory-allocation",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Automatic memory allocation vs. dynamic memory allocation",
    "text": "Automatic memory allocation vs. dynamic memory allocation\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#function-yang-mengembalikan-pointer",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#function-yang-mengembalikan-pointer",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Function yang mengembalikan pointer",
    "text": "Function yang mengembalikan pointer\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#function-pointer-pointer-ke-fungsi",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#function-pointer-pointer-ke-fungsi",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Function pointer: pointer ke fungsi",
    "text": "Function pointer: pointer ke fungsi\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#menerima-input-buffer-fgets-dan-sscanf",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#menerima-input-buffer-fgets-dan-sscanf",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Menerima input: buffer, fgets, dan sscanf",
    "text": "Menerima input: buffer, fgets, dan sscanf\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#menyimpan-formatted-string-snprintf",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#menyimpan-formatted-string-snprintf",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Menyimpan formatted string: snprintf",
    "text": "Menyimpan formatted string: snprintf\nblabla (the main use of snprintf is indeed to store a formatted string instead of printing it with printf, so it’s like printf but to a string instead of to the console/stdin)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#snprintf-untuk-copy-dan-penggabungan-string",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#snprintf-untuk-copy-dan-penggabungan-string",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "snprintf untuk copy dan penggabungan string",
    "text": "snprintf untuk copy dan penggabungan string\nSelain untuk menyimpan formatted string, snprintf ternyata juga bisa digunakan untuk meng-copy sebuah string maupun menggabungkan dua string.\n(blablabla, sebenarnya juga bisa dilakukan dengan memcpy? iya kah? blablabla)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pengenalan-codechef",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pengenalan-codechef",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Pengenalan CodeChef",
    "text": "Pengenalan CodeChef\nCodeChef adalah blablabla\nNanti kalian akan menggunakan CodeChef untuk proyek, mencari soal, blablabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#problem-1-number-mirror-start01",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#problem-1-number-mirror-start01",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Problem 1: “Number Mirror” (START01)",
    "text": "Problem 1: “Number Mirror” (START01)\nlink soal: https://www.codechef.com/problems/START01\nContoh penyelesaian:\n\n\nstart01.c\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    const size_t BUFFER_SIZE = 1000;\n    char buffer[BUFFER_SIZE];\n    \n    int number;\n    \n    fgets(buffer, BUFFER_SIZE, stdin);\n    sscanf(buffer, \"%d\", &number);\n    \n    printf(\"%d\", number);\n    \n    return 0;\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#problem-2-add-two-numbers-flow001",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#problem-2-add-two-numbers-flow001",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Problem 2: “Add Two Numbers” (FLOW001)",
    "text": "Problem 2: “Add Two Numbers” (FLOW001)\nlink: https://www.codechef.com/problems/FLOW001\nContoh penyelesaian:\n\n\nflow001.c\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    const size_t BUFFER_SIZE = 1000;\n    char buffer[BUFFER_SIZE];\n    \n    int T;\n    fgets(buffer, BUFFER_SIZE, stdin);\n    sscanf(buffer, \"%d\", &T);\n    \n    int a, b, result;\n    for (int i = 0; i &lt; T; i++) {\n        fgets(buffer, BUFFER_SIZE, stdin);\n        sscanf(buffer, \"%d %d\", &a, &b);\n        result = a + b;\n        printf(\"%d\\n\", result);\n    }\n    \n    return 0;\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04b.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04b.html",
    "title": "Modul 4b (opsional): membuat command-line interface (CLI) dengan argv",
    "section": "",
    "text": "Kembali ke Struktur Data\n\nOutline\n\nPengenalan argc dan argv di fungsi main\nargv sebagai array of string\nContoh program echoall: menampilkan kembali tiap input\nContoh program sumall: menjumlahkan semua bilangan yang diberikan\nContoh program bacatxt: menampilkan isi suatu text file\n\n\n\nPengenalan argc dan argv di fungsi main\nblabla\n\n\nargv sebagai array of string\nblabla\n\n\nContoh program echoall: menampilkan kembali tiap input\nblabla\n\n\nContoh program sumall: menjumlahkan semua bilangan yang diberikan\nblabla\n\n\nContoh program bacatxt: menampilkan isi suatu text file\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html",
    "title": "Modul 1 Struktur Data: Tipe Data di Python",
    "section": "",
    "text": "Kembali ke Struktur Data (dengan Python)\nSelamat datang di praktikum Struktur Data! Sesuai nama mata kuliahnya, kita akan mempelajari cara mengimplementasikan (membuat) berbagai jenis struktur data dengan bahasa pemrograman Python. Nantinya, berbagai struktur data akan dibentuk “di atas” struktur data array dan yang namanya linked list, tetapi yang lebih mendasar lagi daripada keduanya adalah tipe data.\nDi pertemuan pertama ini, kita akan membahas tentang berbagai tipe data yang ada di Python, baik yang sudah kita kenal di mata kuliah Algoritma dan Pemrograman (pasti tersedia di semua bahasa pemrograman) maupun beberapa tipe data khusus yang ada di Python tetapi belum tentu ada di bahasa pemrograman lain. Tujuannya agar kalian lebih mahir dan lebih mudah ketika menggunakan Python untuk menyelesaikan berbagai masalah dalam kehidupan sehari-hari :D\nKita juga akan membahas tentang array dari numpy di Python (bisa disebut static homogeneous array atau biasa disebut array saja), dan bedanya dengan list di Python (dynamic heterogeneous array).\n\n\nPada AlProg, ada beberapa jenis tipe data yang kalian pelajari, yaitu:\n\nNumerik: int, float\nTeks: string\nList\n\n\n\n\n# Tipe Data Integer\na1 = 5\na2 = -180\n\n# Melihat isinya\nprint(a1)\nprint(a2)\n\n5\n-180\n\n\n\n# Mengecek tipe data menggunakan syntax type\nprint(type(a1))\nprint(type(a2))\n\n&lt;class 'int'&gt;\n&lt;class 'int'&gt;\n\n\nMenurut output yang diperoleh, variabel a1 dan a2 saat ini berupa bilangan bulat atau integer. Python punya “kode” atau nama tersendiri untuk tiap tipe data. Untuk bilangan bulat, namanya adalah int. Nama ini sudah ketetapan dari sananya; kapanpun kita berurusan dengan bilangan bulat di Python, sebutannya selalu int.\nKebetulan, Python juga menyebut istilah class. Kita akan belajar lebih lanjut tentang class di pertemuan berikutnya. Untuk sekarang ini, terima saja dulu ya: kurang lebih, maksud dari istilah class adalah tipe data. Jadi intinya, Python memberi tahu bahwa tipe data nya adalah int.\nHasil jumlahan bilangan bulat pasti juga bilangan bulat.\n\na3 = a1 + a2\nprint(a3)\nprint(type(a3))\n\n-175\n&lt;class 'int'&gt;\n\n\nSelanjutnya, kita bahas tentang float atau floating-point number. Intinya ya koma-komaan atau bilangan rasional. Kenapa disebut “floating-point”, itu karena menurut komputer, titik nya itu bisa dengan mudah dipindah-pindah. Barangkali pernah dibahas dulu di awal kuliah Metode Numerik. Tapi detil itu tidak penting, intinya terima saja, namanya float\n\n# Tipe data float\nb1 = 2.54\nb2 = -3.141592\nb3 = float('inf') # memasukkan infinity sebagai float\n\n# Melihat isinya\nprint(b1)\nprint(b2)\nprint(b3)\n\n# Mengecek tipe data\nprint(type(b1))\nprint(type(b2))\nprint(type(b3))\n\n2.54\n-3.141592\ninf\n&lt;class 'float'&gt;\n&lt;class 'float'&gt;\n&lt;class 'float'&gt;\n\n\nfloat(\"inf\") atau float('inf') yang melambangkan tak hingga ini gunanya untuk perbandingan, barangkali sewaktu-waktu kalian membutuhkan suatu bilangan yang selalu lebih besar daripada semua bilangan lain.\n\n# apapun itu, pasti lebih kecil daripada b3 yaitu tak hingga\nif (b1 &lt; b3):\n    print(\"lebih kecil\")\nelse:\n    print(\"lebih besar\")\n\nlebih kecil\n\n\nAda juga float(\"-inf\") atau float('-inf') yang melambangkan negatif tak hingga, yang selalu lebih kecil daripada semua bilangan lain.\n\nb4 = float(\"-inf\")\nif (-123456789 &gt; b4):\n    print(\"masih lebih besar dari -inf\")\nelse:\n    print(\"lebih kecil dari -inf\")\n\nmasih lebih besar dari -inf\n\n\n\n# Operasi dengan int dan float\nprint(b1 * b2)\nprint(a1 ** b1)\nprint(abs(b2))\n\n-7.979643680000001\n59.618879710940476\n3.141592\n\n\n\n# Jika int bertemu float, maka tipe datanya akan menjadi float,\n# walaupun float nya sebenarnya bulat\nprint(type(a1 ** b1))\n\n&lt;class 'float'&gt;\n\n\n\nprint(10.0 / 2)\nprint(type(10.0 / 2))\n\n5.0\n&lt;class 'float'&gt;\n\n\n\n\n\nUntuk menyimpan teks atau “tulisan” di Python, kita gunakan tipe data string, yang menurut Python sebutannya str. Penulisannya bisa menggunakan tanda petik ' atau tanda kutip \" itu sama saja, sama-sama string, yang penting konsisten.\n\n# Tipe Data String\nc1 = \"string biasa\"\nc2 = 'string lagi'\n\n# Print isinya\nprint(c1)\nprint(c2)\n\nstring biasa\nstring lagi\n\n\n\n# Mengecek Tipe Data\nprint(type(c1))\nprint(type(c2))\n\n&lt;class 'str'&gt;\n&lt;class 'str'&gt;\n\n\nApabila tanda petik atau tanda kutip itu diketik tiga kali berturut-turut, string nya bisa berbaris-baris (disebut multiline string).\n\nc3 = '''string\nsampe\nbawah'''\n\nprint(c3)\nprint(type(c3))\n\nstring\nsampe\nbawah\n&lt;class 'str'&gt;\n\n\nSebenarnya, secara internal, baris baru atau newline itu berupa “huruf” atau karakter tersendiri. Ada cara penulisan khusus, yaitu \\n untuk newline character. Dengan demikian, kita bisa mengadakan baris baru tanpa menekan tombol Enter.\n\nc4 = \"Selamat\\nsore\\nsemuanya\"\nprint(c4)\nprint(type(c4))\n\nSelamat\nsore\nsemuanya\n&lt;class 'str'&gt;\n\n\nCara penulisan khusus seperti \\n itu disebut escape character. Maksudnya, yang tadinya berupa huruf “n” itu diawali garis miring \\ sehingga maknanya berubah.\nPada string dapat dilakukan penggabungan (s + s), penggandaan (s * n), slicing (s[a:b]), cari panjang (len), maksimum-minimum (max-min di sini diliat dari urutannya di ASCII), dll.\n\nprint('ayam' + 'geprek')\n\nayamgeprek\n\n\n\nprint('ayam' + ' ' + 'geprek')\n\nayam geprek\n\n\n\n# Penjumlahan berulang adalah perkalian :)\nprint('es jeruk' * 5)\n\nes jerukes jerukes jerukes jerukes jeruk\n\n\n\nprint('es jeruk, ' * 5)\n\nes jeruk, es jeruk, es jeruk, es jeruk, es jeruk, \n\n\n\n\n\n\nKetiganya dapat digunakan untuk menyimpan banyak item sekaligus.\n\n# Membuat list\nlist1 = [10, -1, 13.7]\nlist2 = [\"apel\", \"pisang\", \"mangga\"]\nlist3 = [-75, \"kartu\", True]\nlist4 = list(\"rumput\")\n\nprint(list1)\nprint(list2)\nprint(list3)\nprint(list4)\n\n[10, -1, 13.7]\n['apel', 'pisang', 'mangga']\n[-75, 'kartu', True]\n['r', 'u', 'm', 'p', 'u', 't']\n\n\nPerhatikan bahwa kita dapat menyimpan berbagai tipe data yang berbeda-beda di dalam list yang sama. Kita juga dapat memodifikasi list:\n\nnilai = [100, 75, 30, 60]\nnilai[2] = 55\n\nprint(nilai)\n\n[100, 75, 55, 60]\n\n\nBahkan, kita dapat dengan mudah menambahkan elemen di belakang list:\n\nwarna = [\"merah\", \"hijau\", \"biru\"]\nwarna.append(\"kuning\")\nwarna.append(\"putih\")\nwarna.append(\"hitam\")\n\nprint(warna)\n\n['merah', 'hijau', 'biru', 'kuning', 'putih', 'hitam']\n\n\nKita dapat memperoleh panjangnya (banyaknya elemen; isinya ada berapa) menggunakan len seperti berikut\n\nprint(len(warna))\n\n6\n\n\nSelanjutnya, mari kita coba membuat tuple.\n\n# Membuat tuple\nt1 = (2, 3)\nt2 = (4, 'abc')\nt3 = tuple('kacang')\n\nprint(t1)\nprint(t2)\nprint(t3)\n\n(2, 3)\n(4, 'abc')\n('k', 'a', 'c', 'a', 'n', 'g')\n\n\n\nprint(type(t1))\nprint(type(t2))\nprint(type(t3))\n\n&lt;class 'tuple'&gt;\n&lt;class 'tuple'&gt;\n&lt;class 'tuple'&gt;\n\n\nTuple dapat dianggap sebagai list yang isinya tidak bisa diganti, ditambah, ataupun dihapus. Namun masih berlaku operasi list yang tidak termasuk editing. Kelebihan tuple adalah bisa menjadi key untuk dict (akan dijelaskan kemudian)\n\n# Kalau mencoba edit tuple, pasti error\nt2[1] = 'xyz'\n\nTypeError: 'tuple' object does not support item assignment\n\n\nKata error nya sih, ga ada fitur assignment. Ini memang disengaja, tuple itu dimaksudkan sebagai list yang tidak bisa diubah.\nBarangkali sewaktu-waktu kalian perlu menyimpan data yang sudah pasti tidak berubah. Kalian bisa menggunakan tuple untuk berjaga-jaga, takutnya kalian ga sengaja mengubah datanya, nah itu akan error agar kalian ingat bahwa tidak bisa diubah.\nKemudian, mari kita mencoba membuat set atau himpunan. Penulisannya menggunakan kurung kurawal. Konsep set atau himpunan di Python ini diharapkan sama seperti himpunan yang kalian pelajari di mata kuliah Logika dan Himpunan (LDH).\n\n# Membuat set\ns1 = {'ayam', 'bebek', 'ayam', 'kuda'}\ns2 = set(list('kacang'))\n\nprint(s1)\nprint(s2)\n\n{'ayam', 'bebek', 'kuda'}\n{'a', 'g', 'k', 'n', 'c'}\n\n\nBisa jadi, hasil di atas itu agak berbeda dengan hasil kalian, karena memang agak random, urutan elemen di himpunan itu benar-benar tidak diperhatikan di Python.\nSet bisa dianggap sebagai list yang tidak mempunyai urutan, sehingga tidak ada indexing dan slicing. Kelebihan utamanya adalah set hanya bisa mempunyai elemen yang unik (tidak bisa ada elemen yang sama di set). Hal ini berguna jika kalian mempunyai list yang kalian ingin hilangkan dobel-dobelnya (efek sampingnya, indeksnya jadi hilang sehingga bisa saja isinya tak beraturan).\nAtau bisa jadi, mungkin kalian memang memerlukan konsep himpunan dari LDH itu di dalam Python, seperti memeriksa apakah suatu elemen ada atau tidak ada di himpunan.\n\nif ('ayam' in s1):\n    print(\"ada ayam\")\nelse:\n    print(\"ayam habis\")\n\nada ayam\n\n\nBeberapa operator himpunan matematika juga ada di set, seperti subset, superset, disjoint, union, intersection, dll.\n\ns3 = set('matematika')\ns4 = set('statistika')\ns5 = set('aktuaria')\n\nprint(s3)\nprint(s4)\nprint(s5)\n\n{'a', 'm', 'k', 't', 'e', 'i'}\n{'a', 's', 'k', 't', 'i'}\n{'a', 'k', 'u', 't', 'i', 'r'}\n\n\n\nprint(s3 & s4) # irisan/intersection\n\n{'a', 'i', 't', 'k'}\n\n\n\nprint(s3 | s4) # gabungan/union\n\n{'a', 'm', 's', 'k', 't', 'e', 'i'}\n\n\n\n# subset\nprint(s4 &lt;= s5)\nprint( {3, 4} &lt;= {1, 2, 3, 4, 5} )\n\nFalse\nTrue\n\n\n\n# superset\nprint(s4 &gt;= s3)\nprint( {3, 4, 5, 6, 7, 8} &gt;= {7, 4} )\n\nFalse\nTrue\n\n\n\n\n\nIstilah set/list/tuple comprehension itu konsepnya sama saja, mungkin kita bahas di set/himpunan dulu yaa.\nMisalnya kalian punya himpunan ini:\n\\(B = \\{ 1, 2, 3, 4, 5 \\}\\)\n\nB = {1, 2, 3, 4, 5}\nprint(B)\nprint(type(B))\n\n{1, 2, 3, 4, 5}\n&lt;class 'set'&gt;\n\n\nTerus misalnya kalian ingin membangun himpunan baru (seperti di LDH) seperti berikut:\n\\(C = \\{ 2x : x \\in B \\}\\)\nMenariknya, di Python, kalian tinggal mengetik seperti ini:\n\nC = {2*x for x in B}\nprint(C)\n\n{2, 4, 6, 8, 10}\n\n\nBahkan kita juga bisa menambahkan syarat tambahan, misalnya:\n\\(D = \\{ 2x : x \\in B, x &lt; 3 \\}\\)\n\nD = {2*x for x in B if x &lt; 3}\nprint(D)\n\n{2, 4}\n\n\nJangan lupa, himpunan itu tidak memperhatikan urutan (di sini kebetulan aja lagi berurut, tumben). Untungnya, penulisan set comprehension ini juga berlaku sama persis di list maupun tuple, sehingga ada istilah list comprehension dan tuple comprehension kalau dilakukan di list maupun tuple.\nWalaupun fitur ini mungkin hanya ada di Python, set/list/tuple comprehension ini bisa sangat mempersingkat kode kita. Terkadang kita membangun list menggunakan for loop, dan for loop tersebut bisa saja memakan beberapa line. Dengan list comprehension, kita dapat membangun list tersebut hanya menggunakan 1 line dan kode kita menjadi lebih enak untuk dibaca.\nSebagai contoh, misal kita ingin membuat list yang berisi nilai dari \\(2^x\\):\n\nexpo = []\nfor i in range(6):\n    expo.append(2**i)\n\nprint(expo)\n\n[1, 2, 4, 8, 16, 32]\n\n\nJika menggunakan list comprehension, akan menjadi seperti ini:\n\nexpo = [2 ** i for i in range(6)]\n\nprint(expo)\n\n[1, 2, 4, 8, 16, 32]\n\n\nList comprehension dibuat dengan membuat list yang berisi suatu ekspresi lalu diikuti dengan for, dan jika diinginkan, bisa ditambah lagi for atau if. Hasilnya seolah-olah kita menjalankan for loop untuk membuat list tersebut, namun hanya menggunakan satu baris kode.\nList comprehension dapat menggunakan lebih dari satu variabel pada ekspresinya. Hal ini ekivalen dengan menggunakan nested for loop untuk membuat list tersebut.\nContohnya, ada konsep cartesian product dari dua himpunan, yaitu memasangkan tiap elemen pertama dengan tiap elemen kedua, seperti berikut:\n\\(\\{ 1, 2 \\} \\times \\{ a, b, c \\} = \\{ (1, a), (1, b), (1, c), (2, a), (2, b), (2, c) \\}\\)\nDi Python, kita bisa menggunakan list comprehension untuk membuat list hasil cartesian product dengan mudah, yaitu dengan dua for:\n\ncartesian_prod = [(x, y) for x in [1, 2] for y in ['a', 'b', 'c']]\nprint(cartesian_prod)\n\n[(1, 'a'), (1, 'b'), (1, 'c'), (2, 'a'), (2, 'b'), (2, 'c')]\n\n\n(Tentu saja, daripada menggunakan list, kita bisa menggunakan set atau bahkan tuple.)\nPotongan kode di atas ekivalen dengan:\n\ncartesian_prod = []\nfor x in [1, 2]:\n    for y in ['a', 'b', 'c']:\n        cartesian_prod.append((x, y))\n\nprint(cartesian_prod)\n\n[(1, 'a'), (1, 'b'), (1, 'c'), (2, 'a'), (2, 'b'), (2, 'c')]\n\n\nIngat bahwa urutan pembacaan setiap ekspresi for dan if pada list comprehension adalah dari kiri ke kanan.\nList comprehension pun juga bisa di-nesting.\n\nmat = [[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]]\n\nmat_transpos = [[baris[j] for baris in mat] for j in range(len(mat))]\nprint(mat_transpos)\n\n[[1, 4, 7], [2, 5, 8], [3, 6, 9]]\n\n\n\n\n\nDictionary ini secara harfiah memang artinya “kamus” ya. Di dalam kamus, ada kata dan ada definisi, sebagai pasangan, di mana kita memiliki kata dan kita mencari definisi.\nDi Python, dictionary seperti semacam “perumuman” dari konsep pasangan kata-definisi untuk kamus, di mana “kata” disebut “key” atau kunci dan “definisi” menjadi “value” atau nilai atau data yang sedang dicari berdasarkan key nya.\nKita juga bisa memandang dictionary sebagai list yang indeksnya tidak harus berupa bilangan bulat (tetapi, seperti set, tidak ada urutan).\nStrukturnya adalah {key1:value1, key2:value2, ....}.\nDictionary dalam hal ini juga terkadang disebut associative array.\n\n# Membuat dictionary\nd1 = {'a': 1, 'b': 2, 'c': 3}\nd2 = {'kopi': 6000, 'teh': 5000, 'susu': 7000}\n\nprint(d1)\nprint(d2)\nprint(type(d1))\nprint(type(d2))\n\n{'a': 1, 'b': 2, 'c': 3}\n{'kopi': 6000, 'teh': 5000, 'susu': 7000}\n&lt;class 'dict'&gt;\n&lt;class 'dict'&gt;\n\n\nTidak seperti list yang diindeks menggunakan suatu range bilangan, dictionary diindeks menggunakan key. Jadi, untuk memanggil suatu value, panggil layaknya list, namun indeksnya menggunakan key\n\nprint(d2['kopi'])\n\n6000\n\n\nTipe data dari value boleh bebas, namun untuk key itu harus yang immutable (kurang lebih artinya tidak bisa diubah). Seandainya kita coba membuat dictionary dengan key berupa tipe data yang mutable (bisa diubah) seperti list, akan error:\n\nd3 = { [2, 3]: 6, [3, 4]: 12 }\nprint(d3)\n\nTypeError: unhashable type: 'list'\n\n\nSehingga, kita harus menggunakan tuple:\n\nd3 = {(2, 3): 6, (3, 4): 12}\nprint(d3)\n\n{(2, 3): 6, (3, 4): 12}\n\n\n\nprint(d3[(3, 4)])\n\n12\n\n\nUntuk menambah suatu pasangan key:value baru, cukup menggunakan d[key] = value, dan akan masuk ke dict tersebut.\n\nd3[(3, 5)] = 15\nprint(d3)\n\n{(2, 3): 6, (3, 4): 12, (3, 5): 15}\n\n\nJika ingin menghapus elemen pada dict, dapat menggunakan del\n\ndel d3[(2, 3)]\nprint(d3)\n\n{(3, 4): 12, (3, 5): 15}\n\n\n\n\n\nSebenarnya, list yang ada di Python itu sedikit berbeda dengan array (larik) yang biasa dibahas di Alprog. Suatu array:\n\nharus statis, yaitu ukurannya tidak dapat berubah;\nharus homogen, yaitu tipe datanya harus sama semua.\n\nDi Python, kita bisa menggunakan array melalui numpy. Mari kita coba, import numpy dulu:\n\nimport numpy as np\n\nAda “cara cepat” untuk membuat array yang berisi nol semua atau berisi satu semua, yaitu dengan numpy.zeros dan numpy.ones:\n\narray1 = np.zeros(5)\narray2 = np.ones(3)\n\nprint(array1)\nprint(array2)\nprint(type(array1))\nprint(type(array2))\n\n[0. 0. 0. 0. 0.]\n[1. 1. 1.]\n&lt;class 'numpy.ndarray'&gt;\n&lt;class 'numpy.ndarray'&gt;\n\n\nMaksud dari istilah ndarray adalah n-dimensional array atau array yang dimensinya bisa berupa bilangan asli apapun.\nApabila kita memasukkan tuple, kita bisa membuat array dengan dimensi yang lebih tinggi.\n\n# Memasukkan tuple (3, 2) untuk ukuran 3 x 2\narray3 = np.ones((3, 2))\nprint(array3)\n\n[[1. 1.]\n [1. 1.]\n [1. 1.]]\n\n\n\narray1[3] = -15\nprint(array1)\n\n[  0.   0.   0. -15.   0.]\n\n\n\narray1.append(7)\n\nAttributeError: 'numpy.ndarray' object has no attribute 'append'\n\n\nMungkin di beberapa referensi pemrograman yang membahas array, ada istilah deklarasi dan inisialisasi. Deklarasi itu sekedar menyatakan bahwa array akan memiliki ukuran sekian, sedangkan inisialisasi adalah memasang nilai awal.\nDengan numpy, kita bisa menggunakan numpy.empty(ukuran) untuk deklarasi saja, atau numpy.array(list_isinya) untuk sekaligus memasang nilai awal.\nMisalnya, kita coba deklarasi + inisialisasi sekaligus:\n\narray4 = np.array([10, -5, 2, 17])\nprint(array4)\n\n[10 -5  2 17]\n\n\nPerhatikan bahwa array4 yang sudah kita buat ini berisi bilangan bulat semua. Setelah membuat array tersebut, ukurannya sudah tetap dan tipe datanya juga sudah tetap (dan harus seragam).\nSeandainya kita mencoba memasang float ke array bilangan bulat, akan dipaksakan menjadi bilangan bulat:\n\narray4[3] = 3.14\nprint(array4)\n\n[10 -5  2  3]\n\n\nSeandainya mencoba memasang str ke array bilangan bulat, Python menyerah dan menjadi error:\n\narray4[3] = \"string\"\nprint(array4)\n\nValueError: invalid literal for int() with base 10: 'string'\n\n\nBagaimana kalau kita ingin membuat array float meskipun data kita kebetulan bilangan bulat semua? Salah satu caranya adalah menambahkan .0 ke salah satu elemennya:\n\narray5 = np.array([10.0, -5, 2, 17])\nprint(array5)\n\n[10. -5.  2. 17.]\n\n\nDengan demikian, kita bisa memasang float:\n\narray5[3] = 3.14\nprint(array5)\n\n[10.   -5.    2.    3.14]\n\n\nCara lain adalah dengan memberitahu numpy, melalui dtype yaitu tipe data yang kita tentukan. Perhatikan, untuk dtype, di sini kita menggunakan nama yang dikenal oleh Python. Misalnya, float untuk koma-komaan dan int untuk bilangan bulat.\n\narray6 = np.array([10, -5, 2, 17], dtype=float)\nprint(array6)\n\n[10. -5.  2. 17.]\n\n\nKita bahkan bisa membuat array berisi string yaitu str\n\narray7 = np.array(['p', 'r', 'a', 'k'], dtype=str)\nprint(array7)\n\n['p' 'r' 'a' 'k']\n\n\nNamun, ingat bahwa array bersifat fixed size. Bahkan, di sini kita sudah terlanjur membuat array berisi 4 string dan masing-masing satu huruf. Maka, array ini sudah terlanjur hanya bisa menampung 4 string dengan masing-masing string hanya sebesar satu karakter.\n\narray7[3] = \"praktikum\"\nprint(array7)\n\n['p' 'r' 'a' 'p']\n\n\nTerakhir, tentang deklarasi menggunakan numpy.empty. Kalau kita hanya melakukan deklarasi, kita hanya menyatakan ukurannya, tanpa memberitahu isinya apa. Dengan demikian, komputer kita akan mencari memori yang sedang tidak digunakan, lalu langsung menggunakannya untuk array baru kita. Kemungkinan besar, memori yang sudah ditemukan itu tadinya bekas data lain yang sudah terhapus.\nCara menggunakan numpy.empty serupa dengan numpy.ones atau numpy.zeros:\n\narray8 = np.empty(8)\nprint(array8)\n\n[3.10503618e+231 1.49457044e-154 3.95252517e-323 0.00000000e+000\n 0.00000000e+000 0.00000000e+000 3.10503618e+231 3.10503618e+231]\n\n\nLho, muncul angka-angka ga jelas. Mungkin di kalian akan berbeda. Inilah bekas dari data yang sudah terhapus.\nTahukah kalian, ketika kalian menghapus file, sebenarnya data itu belum tentu benar-benar terhapus? Datanya hanya diberi tanda “terhapus”, bukan benar-benar dihilangkan. Data bekas seperti itu disebut garbage value.\nBiasanya, ketika kita membuat file baru, barulah komputer mencari memori yang “kosong”, yaitu berisi garbage value, kemudian komputer menimpa data yang baru di atas data yang lama (garbage value) tersebut.\nTentu saja, array hasil deklarasi ini kemudian bisa dipasang nilainya satu-per-satu (assignment):\n\n# bisa manual tiap indeks\narray8[0] = -17.6\narray8[1] = 24.3\n\n# bisa juga dengan for loop\nfor i in range(2, len(array8)): # dari i=2 sampai i=7\n    array8[i] = 5*i/4\n\nprint(array8)\n\n[-17.6   24.3    2.5    3.75   5.     6.25   7.5    8.75]\n\n\nKebetulan, hasil numpy.empty berisi float, sehingga tipe data array nya otomatis menjadi float. Namun, tentu saja, kita bisa menentukan dtype yang kita inginkan (begitu juga untuk numpy.ones dan numpy.zeros, sama seperti numpy.array).\nContohnya, dengan dtype=str kita mendapatkan array yang tiap elemennya berupa string yang hanya bisa menampung satu karakter (secara teori juga disebut tipe data karakter atau char):\n\narray9 = np.empty(4, dtype=str)\nprint(array9)\n\narray9[2] = \"coba\"\nprint(array9)\n\n['' '' '' '']\n['' '' 'c' '']\n\n\nUntuk string dengan panjang maksimum \\(n\\) karakter, gunakan dtype='&lt;Un' atau dtype=\"&lt;Un\". Misalnya, dtype='&lt;U3' atau dtype=\"&lt;U3\" untuk tiga karakter:\n\narray10 = np.empty(5, dtype=\"&lt;U3\")\nprint(array10)\n\narray10[2] = \"percobaan\"\nprint(array10)\n\n['' '' '' '' '']\n['' '' 'per' '' '']\n\n\nUntuk bilangan bulat, seperti biasa, gunakan dtype=int\n\narray11 = np.empty(11, dtype=int)\nprint(array11)\n\n[8070450532247928832 1152930267120700532                   6\n                   0                   0 3832119515839358315\n 3271410370466756915 3762814858193679157 4120005537702227256\n 3977580307635332705 8386112019188900194]\n\n\nSangat random ya! Lagi-lagi, isi dari hasil numpy.empty sangat mungkin berbeda-beda untuk tiap komputer dan di tiap saat. Intinya, kita hanya meminta array dengan ukuran tertentu, tanpa menentukan isinya (tidak seperti numpy.ones dan numpy.zeros yang isinya sudah pasti, atau numpy.array di mana kita manual menentukan isinya), sehingga isinya bisa berupa apa saja. Begitulah jadinya, jika array hanya dideklarasi tanpa ditentukan isinya.\nPada prakteknya, deklarasi array selalu diikuti dengan menentukan isinya, seperti dengan assignment atau contoh for loop di atas (atau kalau mau, kita bisa saja menggunakan numpy.ones, numpy.zeros, atau bahkan numpy.array agar tidak pusing).\n\n\n\nSekian praktikum Struktur Data minggu ini. Di pertemuan selanjutnya, kita akan belajar tentang class, di mana kita seolah-olah bisa membuat tipe data sendiri lho! Selain itu, fitur class ini akan sering kita gunakan untuk membuat berbagai struktur data ke depannya. Sekalian, kita akan membahas juga tentang object-oriented programming atau biasa disingkat OOP (atau dalam bahasa Indonesia: pemrograman berorientasi objek, biasa disingkat PBO), yaitu semacam “paradigma pemrograman” atau “gaya pemrograman” di mana kita sering berurusan dengan class. Sampai jumpa!"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html#review-tipe-data",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html#review-tipe-data",
    "title": "Modul 1 Struktur Data: Tipe Data di Python",
    "section": "",
    "text": "Pada AlProg, ada beberapa jenis tipe data yang kalian pelajari, yaitu:\n\nNumerik: int, float\nTeks: string\nList\n\n\n\n\n# Tipe Data Integer\na1 = 5\na2 = -180\n\n# Melihat isinya\nprint(a1)\nprint(a2)\n\n5\n-180\n\n\n\n# Mengecek tipe data menggunakan syntax type\nprint(type(a1))\nprint(type(a2))\n\n&lt;class 'int'&gt;\n&lt;class 'int'&gt;\n\n\nMenurut output yang diperoleh, variabel a1 dan a2 saat ini berupa bilangan bulat atau integer. Python punya “kode” atau nama tersendiri untuk tiap tipe data. Untuk bilangan bulat, namanya adalah int. Nama ini sudah ketetapan dari sananya; kapanpun kita berurusan dengan bilangan bulat di Python, sebutannya selalu int.\nKebetulan, Python juga menyebut istilah class. Kita akan belajar lebih lanjut tentang class di pertemuan berikutnya. Untuk sekarang ini, terima saja dulu ya: kurang lebih, maksud dari istilah class adalah tipe data. Jadi intinya, Python memberi tahu bahwa tipe data nya adalah int.\nHasil jumlahan bilangan bulat pasti juga bilangan bulat.\n\na3 = a1 + a2\nprint(a3)\nprint(type(a3))\n\n-175\n&lt;class 'int'&gt;\n\n\nSelanjutnya, kita bahas tentang float atau floating-point number. Intinya ya koma-komaan atau bilangan rasional. Kenapa disebut “floating-point”, itu karena menurut komputer, titik nya itu bisa dengan mudah dipindah-pindah. Barangkali pernah dibahas dulu di awal kuliah Metode Numerik. Tapi detil itu tidak penting, intinya terima saja, namanya float\n\n# Tipe data float\nb1 = 2.54\nb2 = -3.141592\nb3 = float('inf') # memasukkan infinity sebagai float\n\n# Melihat isinya\nprint(b1)\nprint(b2)\nprint(b3)\n\n# Mengecek tipe data\nprint(type(b1))\nprint(type(b2))\nprint(type(b3))\n\n2.54\n-3.141592\ninf\n&lt;class 'float'&gt;\n&lt;class 'float'&gt;\n&lt;class 'float'&gt;\n\n\nfloat(\"inf\") atau float('inf') yang melambangkan tak hingga ini gunanya untuk perbandingan, barangkali sewaktu-waktu kalian membutuhkan suatu bilangan yang selalu lebih besar daripada semua bilangan lain.\n\n# apapun itu, pasti lebih kecil daripada b3 yaitu tak hingga\nif (b1 &lt; b3):\n    print(\"lebih kecil\")\nelse:\n    print(\"lebih besar\")\n\nlebih kecil\n\n\nAda juga float(\"-inf\") atau float('-inf') yang melambangkan negatif tak hingga, yang selalu lebih kecil daripada semua bilangan lain.\n\nb4 = float(\"-inf\")\nif (-123456789 &gt; b4):\n    print(\"masih lebih besar dari -inf\")\nelse:\n    print(\"lebih kecil dari -inf\")\n\nmasih lebih besar dari -inf\n\n\n\n# Operasi dengan int dan float\nprint(b1 * b2)\nprint(a1 ** b1)\nprint(abs(b2))\n\n-7.979643680000001\n59.618879710940476\n3.141592\n\n\n\n# Jika int bertemu float, maka tipe datanya akan menjadi float,\n# walaupun float nya sebenarnya bulat\nprint(type(a1 ** b1))\n\n&lt;class 'float'&gt;\n\n\n\nprint(10.0 / 2)\nprint(type(10.0 / 2))\n\n5.0\n&lt;class 'float'&gt;\n\n\n\n\n\nUntuk menyimpan teks atau “tulisan” di Python, kita gunakan tipe data string, yang menurut Python sebutannya str. Penulisannya bisa menggunakan tanda petik ' atau tanda kutip \" itu sama saja, sama-sama string, yang penting konsisten.\n\n# Tipe Data String\nc1 = \"string biasa\"\nc2 = 'string lagi'\n\n# Print isinya\nprint(c1)\nprint(c2)\n\nstring biasa\nstring lagi\n\n\n\n# Mengecek Tipe Data\nprint(type(c1))\nprint(type(c2))\n\n&lt;class 'str'&gt;\n&lt;class 'str'&gt;\n\n\nApabila tanda petik atau tanda kutip itu diketik tiga kali berturut-turut, string nya bisa berbaris-baris (disebut multiline string).\n\nc3 = '''string\nsampe\nbawah'''\n\nprint(c3)\nprint(type(c3))\n\nstring\nsampe\nbawah\n&lt;class 'str'&gt;\n\n\nSebenarnya, secara internal, baris baru atau newline itu berupa “huruf” atau karakter tersendiri. Ada cara penulisan khusus, yaitu \\n untuk newline character. Dengan demikian, kita bisa mengadakan baris baru tanpa menekan tombol Enter.\n\nc4 = \"Selamat\\nsore\\nsemuanya\"\nprint(c4)\nprint(type(c4))\n\nSelamat\nsore\nsemuanya\n&lt;class 'str'&gt;\n\n\nCara penulisan khusus seperti \\n itu disebut escape character. Maksudnya, yang tadinya berupa huruf “n” itu diawali garis miring \\ sehingga maknanya berubah.\nPada string dapat dilakukan penggabungan (s + s), penggandaan (s * n), slicing (s[a:b]), cari panjang (len), maksimum-minimum (max-min di sini diliat dari urutannya di ASCII), dll.\n\nprint('ayam' + 'geprek')\n\nayamgeprek\n\n\n\nprint('ayam' + ' ' + 'geprek')\n\nayam geprek\n\n\n\n# Penjumlahan berulang adalah perkalian :)\nprint('es jeruk' * 5)\n\nes jerukes jerukes jerukes jerukes jeruk\n\n\n\nprint('es jeruk, ' * 5)\n\nes jeruk, es jeruk, es jeruk, es jeruk, es jeruk,"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html#list-tuple-dan-set",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html#list-tuple-dan-set",
    "title": "Modul 1 Struktur Data: Tipe Data di Python",
    "section": "",
    "text": "Ketiganya dapat digunakan untuk menyimpan banyak item sekaligus.\n\n# Membuat list\nlist1 = [10, -1, 13.7]\nlist2 = [\"apel\", \"pisang\", \"mangga\"]\nlist3 = [-75, \"kartu\", True]\nlist4 = list(\"rumput\")\n\nprint(list1)\nprint(list2)\nprint(list3)\nprint(list4)\n\n[10, -1, 13.7]\n['apel', 'pisang', 'mangga']\n[-75, 'kartu', True]\n['r', 'u', 'm', 'p', 'u', 't']\n\n\nPerhatikan bahwa kita dapat menyimpan berbagai tipe data yang berbeda-beda di dalam list yang sama. Kita juga dapat memodifikasi list:\n\nnilai = [100, 75, 30, 60]\nnilai[2] = 55\n\nprint(nilai)\n\n[100, 75, 55, 60]\n\n\nBahkan, kita dapat dengan mudah menambahkan elemen di belakang list:\n\nwarna = [\"merah\", \"hijau\", \"biru\"]\nwarna.append(\"kuning\")\nwarna.append(\"putih\")\nwarna.append(\"hitam\")\n\nprint(warna)\n\n['merah', 'hijau', 'biru', 'kuning', 'putih', 'hitam']\n\n\nKita dapat memperoleh panjangnya (banyaknya elemen; isinya ada berapa) menggunakan len seperti berikut\n\nprint(len(warna))\n\n6\n\n\nSelanjutnya, mari kita coba membuat tuple.\n\n# Membuat tuple\nt1 = (2, 3)\nt2 = (4, 'abc')\nt3 = tuple('kacang')\n\nprint(t1)\nprint(t2)\nprint(t3)\n\n(2, 3)\n(4, 'abc')\n('k', 'a', 'c', 'a', 'n', 'g')\n\n\n\nprint(type(t1))\nprint(type(t2))\nprint(type(t3))\n\n&lt;class 'tuple'&gt;\n&lt;class 'tuple'&gt;\n&lt;class 'tuple'&gt;\n\n\nTuple dapat dianggap sebagai list yang isinya tidak bisa diganti, ditambah, ataupun dihapus. Namun masih berlaku operasi list yang tidak termasuk editing. Kelebihan tuple adalah bisa menjadi key untuk dict (akan dijelaskan kemudian)\n\n# Kalau mencoba edit tuple, pasti error\nt2[1] = 'xyz'\n\nTypeError: 'tuple' object does not support item assignment\n\n\nKata error nya sih, ga ada fitur assignment. Ini memang disengaja, tuple itu dimaksudkan sebagai list yang tidak bisa diubah.\nBarangkali sewaktu-waktu kalian perlu menyimpan data yang sudah pasti tidak berubah. Kalian bisa menggunakan tuple untuk berjaga-jaga, takutnya kalian ga sengaja mengubah datanya, nah itu akan error agar kalian ingat bahwa tidak bisa diubah.\nKemudian, mari kita mencoba membuat set atau himpunan. Penulisannya menggunakan kurung kurawal. Konsep set atau himpunan di Python ini diharapkan sama seperti himpunan yang kalian pelajari di mata kuliah Logika dan Himpunan (LDH).\n\n# Membuat set\ns1 = {'ayam', 'bebek', 'ayam', 'kuda'}\ns2 = set(list('kacang'))\n\nprint(s1)\nprint(s2)\n\n{'ayam', 'bebek', 'kuda'}\n{'a', 'g', 'k', 'n', 'c'}\n\n\nBisa jadi, hasil di atas itu agak berbeda dengan hasil kalian, karena memang agak random, urutan elemen di himpunan itu benar-benar tidak diperhatikan di Python.\nSet bisa dianggap sebagai list yang tidak mempunyai urutan, sehingga tidak ada indexing dan slicing. Kelebihan utamanya adalah set hanya bisa mempunyai elemen yang unik (tidak bisa ada elemen yang sama di set). Hal ini berguna jika kalian mempunyai list yang kalian ingin hilangkan dobel-dobelnya (efek sampingnya, indeksnya jadi hilang sehingga bisa saja isinya tak beraturan).\nAtau bisa jadi, mungkin kalian memang memerlukan konsep himpunan dari LDH itu di dalam Python, seperti memeriksa apakah suatu elemen ada atau tidak ada di himpunan.\n\nif ('ayam' in s1):\n    print(\"ada ayam\")\nelse:\n    print(\"ayam habis\")\n\nada ayam\n\n\nBeberapa operator himpunan matematika juga ada di set, seperti subset, superset, disjoint, union, intersection, dll.\n\ns3 = set('matematika')\ns4 = set('statistika')\ns5 = set('aktuaria')\n\nprint(s3)\nprint(s4)\nprint(s5)\n\n{'a', 'm', 'k', 't', 'e', 'i'}\n{'a', 's', 'k', 't', 'i'}\n{'a', 'k', 'u', 't', 'i', 'r'}\n\n\n\nprint(s3 & s4) # irisan/intersection\n\n{'a', 'i', 't', 'k'}\n\n\n\nprint(s3 | s4) # gabungan/union\n\n{'a', 'm', 's', 'k', 't', 'e', 'i'}\n\n\n\n# subset\nprint(s4 &lt;= s5)\nprint( {3, 4} &lt;= {1, 2, 3, 4, 5} )\n\nFalse\nTrue\n\n\n\n# superset\nprint(s4 &gt;= s3)\nprint( {3, 4, 5, 6, 7, 8} &gt;= {7, 4} )\n\nFalse\nTrue"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html#setlisttuple-comprehension",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html#setlisttuple-comprehension",
    "title": "Modul 1 Struktur Data: Tipe Data di Python",
    "section": "",
    "text": "Istilah set/list/tuple comprehension itu konsepnya sama saja, mungkin kita bahas di set/himpunan dulu yaa.\nMisalnya kalian punya himpunan ini:\n\\(B = \\{ 1, 2, 3, 4, 5 \\}\\)\n\nB = {1, 2, 3, 4, 5}\nprint(B)\nprint(type(B))\n\n{1, 2, 3, 4, 5}\n&lt;class 'set'&gt;\n\n\nTerus misalnya kalian ingin membangun himpunan baru (seperti di LDH) seperti berikut:\n\\(C = \\{ 2x : x \\in B \\}\\)\nMenariknya, di Python, kalian tinggal mengetik seperti ini:\n\nC = {2*x for x in B}\nprint(C)\n\n{2, 4, 6, 8, 10}\n\n\nBahkan kita juga bisa menambahkan syarat tambahan, misalnya:\n\\(D = \\{ 2x : x \\in B, x &lt; 3 \\}\\)\n\nD = {2*x for x in B if x &lt; 3}\nprint(D)\n\n{2, 4}\n\n\nJangan lupa, himpunan itu tidak memperhatikan urutan (di sini kebetulan aja lagi berurut, tumben). Untungnya, penulisan set comprehension ini juga berlaku sama persis di list maupun tuple, sehingga ada istilah list comprehension dan tuple comprehension kalau dilakukan di list maupun tuple.\nWalaupun fitur ini mungkin hanya ada di Python, set/list/tuple comprehension ini bisa sangat mempersingkat kode kita. Terkadang kita membangun list menggunakan for loop, dan for loop tersebut bisa saja memakan beberapa line. Dengan list comprehension, kita dapat membangun list tersebut hanya menggunakan 1 line dan kode kita menjadi lebih enak untuk dibaca.\nSebagai contoh, misal kita ingin membuat list yang berisi nilai dari \\(2^x\\):\n\nexpo = []\nfor i in range(6):\n    expo.append(2**i)\n\nprint(expo)\n\n[1, 2, 4, 8, 16, 32]\n\n\nJika menggunakan list comprehension, akan menjadi seperti ini:\n\nexpo = [2 ** i for i in range(6)]\n\nprint(expo)\n\n[1, 2, 4, 8, 16, 32]\n\n\nList comprehension dibuat dengan membuat list yang berisi suatu ekspresi lalu diikuti dengan for, dan jika diinginkan, bisa ditambah lagi for atau if. Hasilnya seolah-olah kita menjalankan for loop untuk membuat list tersebut, namun hanya menggunakan satu baris kode.\nList comprehension dapat menggunakan lebih dari satu variabel pada ekspresinya. Hal ini ekivalen dengan menggunakan nested for loop untuk membuat list tersebut.\nContohnya, ada konsep cartesian product dari dua himpunan, yaitu memasangkan tiap elemen pertama dengan tiap elemen kedua, seperti berikut:\n\\(\\{ 1, 2 \\} \\times \\{ a, b, c \\} = \\{ (1, a), (1, b), (1, c), (2, a), (2, b), (2, c) \\}\\)\nDi Python, kita bisa menggunakan list comprehension untuk membuat list hasil cartesian product dengan mudah, yaitu dengan dua for:\n\ncartesian_prod = [(x, y) for x in [1, 2] for y in ['a', 'b', 'c']]\nprint(cartesian_prod)\n\n[(1, 'a'), (1, 'b'), (1, 'c'), (2, 'a'), (2, 'b'), (2, 'c')]\n\n\n(Tentu saja, daripada menggunakan list, kita bisa menggunakan set atau bahkan tuple.)\nPotongan kode di atas ekivalen dengan:\n\ncartesian_prod = []\nfor x in [1, 2]:\n    for y in ['a', 'b', 'c']:\n        cartesian_prod.append((x, y))\n\nprint(cartesian_prod)\n\n[(1, 'a'), (1, 'b'), (1, 'c'), (2, 'a'), (2, 'b'), (2, 'c')]\n\n\nIngat bahwa urutan pembacaan setiap ekspresi for dan if pada list comprehension adalah dari kiri ke kanan.\nList comprehension pun juga bisa di-nesting.\n\nmat = [[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]]\n\nmat_transpos = [[baris[j] for baris in mat] for j in range(len(mat))]\nprint(mat_transpos)\n\n[[1, 4, 7], [2, 5, 8], [3, 6, 9]]"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html#dictionary",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html#dictionary",
    "title": "Modul 1 Struktur Data: Tipe Data di Python",
    "section": "",
    "text": "Dictionary ini secara harfiah memang artinya “kamus” ya. Di dalam kamus, ada kata dan ada definisi, sebagai pasangan, di mana kita memiliki kata dan kita mencari definisi.\nDi Python, dictionary seperti semacam “perumuman” dari konsep pasangan kata-definisi untuk kamus, di mana “kata” disebut “key” atau kunci dan “definisi” menjadi “value” atau nilai atau data yang sedang dicari berdasarkan key nya.\nKita juga bisa memandang dictionary sebagai list yang indeksnya tidak harus berupa bilangan bulat (tetapi, seperti set, tidak ada urutan).\nStrukturnya adalah {key1:value1, key2:value2, ....}.\nDictionary dalam hal ini juga terkadang disebut associative array.\n\n# Membuat dictionary\nd1 = {'a': 1, 'b': 2, 'c': 3}\nd2 = {'kopi': 6000, 'teh': 5000, 'susu': 7000}\n\nprint(d1)\nprint(d2)\nprint(type(d1))\nprint(type(d2))\n\n{'a': 1, 'b': 2, 'c': 3}\n{'kopi': 6000, 'teh': 5000, 'susu': 7000}\n&lt;class 'dict'&gt;\n&lt;class 'dict'&gt;\n\n\nTidak seperti list yang diindeks menggunakan suatu range bilangan, dictionary diindeks menggunakan key. Jadi, untuk memanggil suatu value, panggil layaknya list, namun indeksnya menggunakan key\n\nprint(d2['kopi'])\n\n6000\n\n\nTipe data dari value boleh bebas, namun untuk key itu harus yang immutable (kurang lebih artinya tidak bisa diubah). Seandainya kita coba membuat dictionary dengan key berupa tipe data yang mutable (bisa diubah) seperti list, akan error:\n\nd3 = { [2, 3]: 6, [3, 4]: 12 }\nprint(d3)\n\nTypeError: unhashable type: 'list'\n\n\nSehingga, kita harus menggunakan tuple:\n\nd3 = {(2, 3): 6, (3, 4): 12}\nprint(d3)\n\n{(2, 3): 6, (3, 4): 12}\n\n\n\nprint(d3[(3, 4)])\n\n12\n\n\nUntuk menambah suatu pasangan key:value baru, cukup menggunakan d[key] = value, dan akan masuk ke dict tersebut.\n\nd3[(3, 5)] = 15\nprint(d3)\n\n{(2, 3): 6, (3, 4): 12, (3, 5): 15}\n\n\nJika ingin menghapus elemen pada dict, dapat menggunakan del\n\ndel d3[(2, 3)]\nprint(d3)\n\n{(3, 4): 12, (3, 5): 15}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html#bagaimana-dengan-array",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html#bagaimana-dengan-array",
    "title": "Modul 1 Struktur Data: Tipe Data di Python",
    "section": "",
    "text": "Sebenarnya, list yang ada di Python itu sedikit berbeda dengan array (larik) yang biasa dibahas di Alprog. Suatu array:\n\nharus statis, yaitu ukurannya tidak dapat berubah;\nharus homogen, yaitu tipe datanya harus sama semua.\n\nDi Python, kita bisa menggunakan array melalui numpy. Mari kita coba, import numpy dulu:\n\nimport numpy as np\n\nAda “cara cepat” untuk membuat array yang berisi nol semua atau berisi satu semua, yaitu dengan numpy.zeros dan numpy.ones:\n\narray1 = np.zeros(5)\narray2 = np.ones(3)\n\nprint(array1)\nprint(array2)\nprint(type(array1))\nprint(type(array2))\n\n[0. 0. 0. 0. 0.]\n[1. 1. 1.]\n&lt;class 'numpy.ndarray'&gt;\n&lt;class 'numpy.ndarray'&gt;\n\n\nMaksud dari istilah ndarray adalah n-dimensional array atau array yang dimensinya bisa berupa bilangan asli apapun.\nApabila kita memasukkan tuple, kita bisa membuat array dengan dimensi yang lebih tinggi.\n\n# Memasukkan tuple (3, 2) untuk ukuran 3 x 2\narray3 = np.ones((3, 2))\nprint(array3)\n\n[[1. 1.]\n [1. 1.]\n [1. 1.]]\n\n\n\narray1[3] = -15\nprint(array1)\n\n[  0.   0.   0. -15.   0.]\n\n\n\narray1.append(7)\n\nAttributeError: 'numpy.ndarray' object has no attribute 'append'\n\n\nMungkin di beberapa referensi pemrograman yang membahas array, ada istilah deklarasi dan inisialisasi. Deklarasi itu sekedar menyatakan bahwa array akan memiliki ukuran sekian, sedangkan inisialisasi adalah memasang nilai awal.\nDengan numpy, kita bisa menggunakan numpy.empty(ukuran) untuk deklarasi saja, atau numpy.array(list_isinya) untuk sekaligus memasang nilai awal.\nMisalnya, kita coba deklarasi + inisialisasi sekaligus:\n\narray4 = np.array([10, -5, 2, 17])\nprint(array4)\n\n[10 -5  2 17]\n\n\nPerhatikan bahwa array4 yang sudah kita buat ini berisi bilangan bulat semua. Setelah membuat array tersebut, ukurannya sudah tetap dan tipe datanya juga sudah tetap (dan harus seragam).\nSeandainya kita mencoba memasang float ke array bilangan bulat, akan dipaksakan menjadi bilangan bulat:\n\narray4[3] = 3.14\nprint(array4)\n\n[10 -5  2  3]\n\n\nSeandainya mencoba memasang str ke array bilangan bulat, Python menyerah dan menjadi error:\n\narray4[3] = \"string\"\nprint(array4)\n\nValueError: invalid literal for int() with base 10: 'string'\n\n\nBagaimana kalau kita ingin membuat array float meskipun data kita kebetulan bilangan bulat semua? Salah satu caranya adalah menambahkan .0 ke salah satu elemennya:\n\narray5 = np.array([10.0, -5, 2, 17])\nprint(array5)\n\n[10. -5.  2. 17.]\n\n\nDengan demikian, kita bisa memasang float:\n\narray5[3] = 3.14\nprint(array5)\n\n[10.   -5.    2.    3.14]\n\n\nCara lain adalah dengan memberitahu numpy, melalui dtype yaitu tipe data yang kita tentukan. Perhatikan, untuk dtype, di sini kita menggunakan nama yang dikenal oleh Python. Misalnya, float untuk koma-komaan dan int untuk bilangan bulat.\n\narray6 = np.array([10, -5, 2, 17], dtype=float)\nprint(array6)\n\n[10. -5.  2. 17.]\n\n\nKita bahkan bisa membuat array berisi string yaitu str\n\narray7 = np.array(['p', 'r', 'a', 'k'], dtype=str)\nprint(array7)\n\n['p' 'r' 'a' 'k']\n\n\nNamun, ingat bahwa array bersifat fixed size. Bahkan, di sini kita sudah terlanjur membuat array berisi 4 string dan masing-masing satu huruf. Maka, array ini sudah terlanjur hanya bisa menampung 4 string dengan masing-masing string hanya sebesar satu karakter.\n\narray7[3] = \"praktikum\"\nprint(array7)\n\n['p' 'r' 'a' 'p']\n\n\nTerakhir, tentang deklarasi menggunakan numpy.empty. Kalau kita hanya melakukan deklarasi, kita hanya menyatakan ukurannya, tanpa memberitahu isinya apa. Dengan demikian, komputer kita akan mencari memori yang sedang tidak digunakan, lalu langsung menggunakannya untuk array baru kita. Kemungkinan besar, memori yang sudah ditemukan itu tadinya bekas data lain yang sudah terhapus.\nCara menggunakan numpy.empty serupa dengan numpy.ones atau numpy.zeros:\n\narray8 = np.empty(8)\nprint(array8)\n\n[3.10503618e+231 1.49457044e-154 3.95252517e-323 0.00000000e+000\n 0.00000000e+000 0.00000000e+000 3.10503618e+231 3.10503618e+231]\n\n\nLho, muncul angka-angka ga jelas. Mungkin di kalian akan berbeda. Inilah bekas dari data yang sudah terhapus.\nTahukah kalian, ketika kalian menghapus file, sebenarnya data itu belum tentu benar-benar terhapus? Datanya hanya diberi tanda “terhapus”, bukan benar-benar dihilangkan. Data bekas seperti itu disebut garbage value.\nBiasanya, ketika kita membuat file baru, barulah komputer mencari memori yang “kosong”, yaitu berisi garbage value, kemudian komputer menimpa data yang baru di atas data yang lama (garbage value) tersebut.\nTentu saja, array hasil deklarasi ini kemudian bisa dipasang nilainya satu-per-satu (assignment):\n\n# bisa manual tiap indeks\narray8[0] = -17.6\narray8[1] = 24.3\n\n# bisa juga dengan for loop\nfor i in range(2, len(array8)): # dari i=2 sampai i=7\n    array8[i] = 5*i/4\n\nprint(array8)\n\n[-17.6   24.3    2.5    3.75   5.     6.25   7.5    8.75]\n\n\nKebetulan, hasil numpy.empty berisi float, sehingga tipe data array nya otomatis menjadi float. Namun, tentu saja, kita bisa menentukan dtype yang kita inginkan (begitu juga untuk numpy.ones dan numpy.zeros, sama seperti numpy.array).\nContohnya, dengan dtype=str kita mendapatkan array yang tiap elemennya berupa string yang hanya bisa menampung satu karakter (secara teori juga disebut tipe data karakter atau char):\n\narray9 = np.empty(4, dtype=str)\nprint(array9)\n\narray9[2] = \"coba\"\nprint(array9)\n\n['' '' '' '']\n['' '' 'c' '']\n\n\nUntuk string dengan panjang maksimum \\(n\\) karakter, gunakan dtype='&lt;Un' atau dtype=\"&lt;Un\". Misalnya, dtype='&lt;U3' atau dtype=\"&lt;U3\" untuk tiga karakter:\n\narray10 = np.empty(5, dtype=\"&lt;U3\")\nprint(array10)\n\narray10[2] = \"percobaan\"\nprint(array10)\n\n['' '' '' '' '']\n['' '' 'per' '' '']\n\n\nUntuk bilangan bulat, seperti biasa, gunakan dtype=int\n\narray11 = np.empty(11, dtype=int)\nprint(array11)\n\n[8070450532247928832 1152930267120700532                   6\n                   0                   0 3832119515839358315\n 3271410370466756915 3762814858193679157 4120005537702227256\n 3977580307635332705 8386112019188900194]\n\n\nSangat random ya! Lagi-lagi, isi dari hasil numpy.empty sangat mungkin berbeda-beda untuk tiap komputer dan di tiap saat. Intinya, kita hanya meminta array dengan ukuran tertentu, tanpa menentukan isinya (tidak seperti numpy.ones dan numpy.zeros yang isinya sudah pasti, atau numpy.array di mana kita manual menentukan isinya), sehingga isinya bisa berupa apa saja. Begitulah jadinya, jika array hanya dideklarasi tanpa ditentukan isinya.\nPada prakteknya, deklarasi array selalu diikuti dengan menentukan isinya, seperti dengan assignment atau contoh for loop di atas (atau kalau mau, kita bisa saja menggunakan numpy.ones, numpy.zeros, atau bahkan numpy.array agar tidak pusing)."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html#selanjutnya-bahas-apa",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html#selanjutnya-bahas-apa",
    "title": "Modul 1 Struktur Data: Tipe Data di Python",
    "section": "",
    "text": "Sekian praktikum Struktur Data minggu ini. Di pertemuan selanjutnya, kita akan belajar tentang class, di mana kita seolah-olah bisa membuat tipe data sendiri lho! Selain itu, fitur class ini akan sering kita gunakan untuk membuat berbagai struktur data ke depannya. Sekalian, kita akan membahas juga tentang object-oriented programming atau biasa disingkat OOP (atau dalam bahasa Indonesia: pemrograman berorientasi objek, biasa disingkat PBO), yaitu semacam “paradigma pemrograman” atau “gaya pemrograman” di mana kita sering berurusan dengan class. Sampai jumpa!"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul03.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul03.html",
    "title": "Modul 3 Struktur Data: I/O, CodeChef",
    "section": "",
    "text": "Kembali ke Struktur Data (dengan Python)\nDi praktikum kali ini, kita akan belajar tentang I/O (input/output), yaitu cara berurusan dengan input dan output di Python. Bukan hanya sekadar print dan input, tetapi juga cara berurusan dengan text file.\nSelain itu, kita akan belajar tentang Graphviz, yang bisa kita gunakan untuk membuat berbagai gambar “graf”, dan bisa digunakan untuk menggambar berbagai jenis struktur data nantinya. Pembahasan tentang Graphviz ditunda ke praktikum yang akan datang.\nTerakhir, untuk melatih dan mendalami urusan input/output, kita akan berkenalan dengan CodeChef (https://www.codechef.com/), suatu situs “competitive programming”. Kesannya seolah-olah untuk persiapan lomba, tetapi maksudnya situs tersebut punya “bank soal”, lebih tepatnya di link berikut (jangan lupa membuat akun terlebih dahulu):\n\nhttps://www.codechef.com/practice (sudah dikategorikan tetapi banyak soal yang berbayar)\nhttps://www.codechef.com/practice-old (lebih lengkap, bisa searching, dan gratis semua)\n\nAda banyak latihan soal yang bisa kita coba untuk melatih kemampuan pemrograman kita. Siapa tahu, kalian akan mengambil soal dari situ dan menyesuaikan untuk proyek akhir Struktur Data :)\n\n\n\n\nKegunaan utama print adalah untuk menampilkan string (str).\n\nprint(\"Hello, world!\")\n\nHello, world!\n\n\n\nteks1 = \"Selamat sore!\"\nprint(teks1)\n\nSelamat sore!\n\n\nKita bisa menampilkan beberapa string sekaligus di dalam satu print, memisakan tiap string dengan koma.\n\nprint(\"Saya\", \"sudah\", \"makan\", \"siang\")\n\nSaya sudah makan siang\n\n\nSebenarnya, kita bisa menggunakan print untuk menampilkan tipe data apapun.\n\nangka = -45\nharga = 10.6\nprint(angka)\nprint(harga)\n\n-45\n10.6\n\n\nSehingga, kita bisa menuliskan seperti ini:\n\nprint(\"Suhu:\", angka)\n\nSuhu: -45\n\n\nKalau mau, kita juga bisa menyiapkan suatu string yang utuh terlebih dahulu (mengubah tipe data lain menjadi string dengan str), baru menampilkan string yang utuh tersebut:\n\nstring_utuh = \"Suhu: \" + str(angka)\nprint(string_utuh)\n\nSuhu: -45\n\n\nApabila kita print suatu list begitu saja, maka akan ditampilkan sebagai list.\n\nbeberapa_buah = [\"pisang\", 42, -5.1, \"apel\", \"jeruk\"]\nprint(beberapa_buah)\n\n['pisang', 42, -5.1, 'apel', 'jeruk']\n\n\nNamun, kita bisa saja menggunakan for loop untuk menampilkan tiap elemen.\n\nfor elemen in beberapa_buah:\n    print(elemen)\n\npisang\n42\n-5.1\napel\njeruk\n\n\nBegitu juga untuk set (tentu saja urutannya tidak menentu):\n\nbeberapa_warna = {\"merah\", \"hijau\", \"biru\", \"kuning\"}\nprint(beberapa_warna)\n\n{'merah', 'biru', 'kuning', 'hijau'}\n\n\n\nfor warna in beberapa_warna:\n    print(warna)\n\nmerah\nbiru\nkuning\nhijau\n\n\nUntuk suatu dict, kita bisa menampilkan dict seutuhnya:\n\nharga_toko = {\"kopi\": 6000, \"teh\": 5000, \"susu\": 7000}\nprint(harga_toko)\n\n{'kopi': 6000, 'teh': 5000, 'susu': 7000}\n\n\nKita bisa memperoleh set yang berisi key nya saja dengan dict.keys(), baru menampilkan set tersebut:\n\nyang_dijual = set(harga_toko.keys())\nprint(yang_dijual)\n\n{'kopi', 'teh', 'susu'}\n\n\nSerupa, kita bisa memperoleh set yang berisi value nya saja menggunakan dict.values():\n\nsemua_harga = set(harga_toko.values())\nprint(semua_harga)\n\n{6000, 7000, 5000}\n\n\nKalau mau, kita bisa melakukan for loop untuk tiap key:\n\nfor key in harga_toko.keys():\n    print(key, harga_toko[key])\n\nkopi 6000\nteh 5000\nsusu 7000\n\n\nBahkan, kita bisa melakukan for loop untuk tiap key dan value sekaligus, dengan dict.items():\n\nfor key, value in harga_toko.items():\n    print(key, \"harganya\", value)\n\nkopi harganya 6000\nteh harganya 5000\nsusu harganya 7000\n\n\nUmumnya, tiap kali kita menggunakan print, baris baru selalu ditambahkan secara otomatis, sehingga print yang selanjutnya akan ditampilkan di baris berikutnya. Sebenarnya, hal ini bisa diatur dengan setting end= seperti berikut:\n\nprint(\"Hari\", end=\"\\n\")\nprint(\"ini\", end=\"\\n\")\nprint(\"Jum'at\", end=\"\\n\")\n\nHari\nini\nJum'at\n\n\nend= bisa berupa apa saja:\n\nprint(\"Hari\", end=\"|\")\nprint(\"ini\", end=\"|\")\nprint(\"Jum'at\", end=\"|\")\n\nHari|ini|Jum'at|\n\n\nBahkan, kita bisa mengkosongkan end= (membuatnya menjadi string kosong atau \"\" atau '') apabila kita mengharapkan tidak ada “pemisah” antara tiap output:\n\nprint(\"Hari\", end=\"\")\nprint(\"ini\", end=\"\")\nprint(\"Jum'at\", end=\"\")\n\nHariiniJum'at\n\n\n\n\n\nMneggunakan input, kita bisa menerima masukkan data berupa string.\n\nnama = input()\nprint(\"Halo\", nama)\n\nHalo Bisma\n\n\nKita bisa menggunakan prompt berupa string dalam input, yaitu semacam “pertanyaan” agar jelas data apa yang diperlukan.\n\nnama = input(\"Masukkan nama: \")\nprint(\"Halo\", nama)\n\nMasukkan nama: Bisma\nHalo Bisma\n\n\nApabila input yang kita inginkan adalah selain string, kita harus mengakali. Contohnya, bisa saja kita langsung mengkonversi string yang masuk menjadi tipe data lain:\n\numur = int(input(\"Masukkan umur: \"))\nprint(\"Tahun depan, Anda akan berumur\", umur+1, \"tahun\")\n\nMasukkan umur: 19\nTahun depan, Anda akan berumur 20 tahun\n\n\nBahkan menjadi list juga bisa, menggunakan split untuk memecah suatu string menjadi beberapa bagian (dalam suatu list) berdasarkan suatu pemisah (di sini ,):\n\nbeberapa_angka = input(\"Masukkan beberapa angka: \").split(\",\")\nprint(\"Input yang masuk:\", beberapa_angka)\nsum = 0\nfor angka in beberapa_angka:\n    sum += float(angka)\nprint(\"Totalnya adalah\", sum)\n\nMasukkan beberapa angka: -10, 5.6, 3, -7, 82\nInput yang masuk: ['-10', ' 5.6', ' 3', ' -7', ' 82']\nTotalnya adalah 73.6\n\n\n\n\n\nDi Python, kita bisa membuka, mengedit, dan menutup text file, yaitu file yang berakhiran .txt\nKetika membuka suatu text file, ada beberapa pilihan “mode”:\n\nr: read-only, jika kita hanya ingin membaca isinya. Kalau file nya tidak ada, error.\na: append-only, jika kita hanya ingin menambahkan isi di akhir text file (sehingga tidak bisa melihat isi yang sudah ada). Kalau file nya belum ada, akan dibuat.\nw: write-only, jika kita hanya ingin menulis (tanpa bisa membaca isi yang sudah ada) dan menimpa apapun tulisan yang sudah ada. Kalau file nya belum ada, akan dibuat.\nr+: read and write. Kalau file nya tidak ada, error.\na+: append and read. Kalau file nya belum ada, akan dibuat.\nw+: write and read. Kalau file nya belum ada, akan dibuat.\n\nUntuk fitur yang paling lengkap (tetapi bisa berbahaya apabila kita tidak berhati-hati), bisa digunakan mode w+.\nKita bisa membuka suatu file dengan open. Dengan begitu, kita akan memperoleh suatu objek file. Objek ini memiliki beberapa atribut seperti .mode, dan beberapa method seperti:\n\n.write() untuk menulis\n.read() untuk membaca (memperoleh isinya sebagai string)\n.seek() agar “cursor” lompat ke posisi tertentu (misalnya .seek(0) untuk kembali ke awal file)\n.close() untuk menutup file setelah selesai digunakan\n\n(Apabila kita ingin mengubah mode, kita bisa melakukan .close() terlebih dahulu, baru open lagi dengan mode yang baru.)\nDi kode di bawah ini, kita akan membuka suatu file, menuliskan Hello, world! di dalamnya, lalu menutup file nya.\n\nteks = open(\"test.txt\", 'w+')\nteks.write(\"Hello, world!\")\nteks.close()\n\nSetelah running kode di atas, coba cek folder kalian yang menyimpan file .ipynb yang sedang kalian gunakan. Harusnya, ada file baru yang muncul bernama test.txt dan isinya Hello, world!\n\nDi Jupyter Notebook, kalian bisa kembali ke tab yang terbuka di browser kalian di mana kalian tadinya sudah membuat new notebook. Coba double-click test.txt\nDi Google Colaboratory, kalian bisa menekan tombol folder yang ada di sebelah kiri. Coba download test.txt lalu buka isinya\n\nMari kita coba gunakan .write() untuk menuliskan sesuatu di dalamnya, lalu .seek(0) untuk kembali ke awal file, kemudian .read() untuk membaca isinya (mulai dari awal file sesuai yang ditentukan oleh .seek())\n\nteks = open(\"test.txt\", 'w+')\nteks.write(\"Selamat pagi\")\nteks.seek(0)\nprint(teks.read())\nteks.close()\n\nSelamat pagi\n\n\nSetelah running kode di atas, kalau mau, silakan dibuka kembali.\n\nMenggunakan Jupyter Notebook: kalau tadinya sudah dibuka, ditutup dulu, baru dibuka lagi.\nMenggunakan Google Colaboratory: tunggu sebentar, download lagi, lalu buka isinya.\n\nPasti ada isinya, yaitu tulisan Selamat pagi\nTulisan Selamat pagi yang tadi tertimpa, karena kita menggunakan mode w, bukan a.\nSebenarnya, kalaupun tidak diperiksa isinya, kita bisa yakin bahwa isinya sudah berubah sesuai yang kita inginkan, karena kita sudah melihat isi yang baru dengan .read()\nMari kita coba menuliskan hal lain.\n\nteks = open(\"test.txt\", 'w+')\nteks.write(\"Selamat siang\")\nteks.seek(0)\nprint(teks.read())\nteks.close()\n\nSelamat siang\n\n\nKalau kita buka kembali, sekarang tulisannya adalah Selamat siang\nAda cara penulisan lain agar Python akan menutup file secara otomatis, yaitu menggunakan yang namanya context manager atau with statement. Syntax nya sebagai berikut:\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat sore\")\n    teks.seek(0)\n    print(teks.read())\n\nSelamat sore\n\n\nYang tadinya kita tulis teks = open(\"test.txt\", 'w+'), sekarang kita tulis dengan with ... as ... dengan titik dua di akhir. Lalu, semua hal yang mau kita lakukan dengan file tersebut (yang di sini sekarang namanya teks) itu kita lakukan di dalam with statement tersebut, dengan indentasi, seperti dalam for loop misalnya.\nBegitu keluar dari with statement, file akan ditutup secara otomatis. Dengan demikian, kita tidak perlu lagi melakukan .close()\nAnyway, boleh diperiksa lagi file nya, sekarang tulisannya menjadi Selamat sore\nKalau mau, kita bisa saja melakukan .write() berkali-kali untuk menambahkan tulisan berbaris-baris:\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\")\n    teks.write(\"Selamat siang\")\n    teks.write(\"Selamat sore\")\n    teks.write(\"Selamat malam\")\n    teks.seek(0)\n    print(teks.read())\n\nSelamat pagiSelamat siangSelamat soreSelamat malam\n\n\nOops, jangan lupa tambahkan \\n di akhir, ya!\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n    teks.seek(0)\n    print(teks.read())\n\nSelamat pagi\nSelamat siang\nSelamat sore\nSelamat malam\n\n\nKalau iseng, kita bisa melakukan misalnya teks.seek(21) untuk melompat 21 karakter dari awal file, sebelum melakukan .read():\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n    teks.seek(21)\n    print(teks.read())\n\nsiang\nSelamat sore\nSelamat malam\n\n\nDengan demikian, .read() hanya akan membaca tulisan yang ada mulai dari posisi ke-21 tersebut.\nKalau mau, kita bisa saja hanya membaca beberapa karakter, misalnya hanya 5 karakter:\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n    teks.seek(21)\n    print(teks.read(5))\n\nsiang\n\n\nKita bahkan bisa .seek() lagi setelah .read(), lalu .read() lagi, .seek() lagi, dan seterusnya sesuka hati.\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n    teks.seek(21)\n    print(teks.read(5))\n    teks.seek(48)\n    print(teks.read(5))\n    teks.seek(35)\n    print(teks.read(4))\n\nsiang\nmalam\nsore\n\n\nSetelah melakukan read, sebenarnya cursor akan ikut maju! Seandainya kita melakukan read dua kali berturut-turut, perhatikan:\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n    teks.seek(21)\n    print(teks.read(5), end=\"\")\n    print(teks.read(7), end=\"\")\n\nsiang\nSelama\n\n\nDi sini, kita menggunakan end=\"\" agar print tidak menambahkan baris baru. Lho, tapi ada baris baru? Baris baru itu sebenarnya dari file itu sendiri :)\nPerhatikan juga bahwa baris baru \\n itu terhitung sebagai satu karakter dengan sendirinya, sehingga yang tadinya kita mau membaca Selamat (7 karakter) itu malah hanya menjadi Selama (6 karakter), karena jatah satu karakter sudah digunakan untuk baris baru.\nSeandainya kita tidak menggunakan .seek() sama sekali, maka setelah selesai .write(), cursor akan terletak di akhir file (karena tadinya sudah selesai menulis sampai situ) sehingga .read() tidak akan memberikan output apapun:\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n    print(teks.read())\n\n\n\n\nKita bisa melihat posisi cursor saat ini dengan .tell()\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n    print(teks.tell())\n\n53\n\n\nWow, jauh ya! Tidak heran, tidak ada lagi yang perlu dibaca.\nKalau misalnya kita muak dengan .seek(), kita bisa saja menutup file setelah menulis, barulah kemudian membuka file lagi untuk melihat isinya. Kita bisa melakukan itu dengan dua kali with statement. (Ada baiknya kita menggunakan mode yang sesuai, misalnya w saja untuk menulis saja, lalu r saja untuk membaca saja.)\n\nwith open(\"test.txt\", 'w') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n\nwith open(\"test.txt\", 'r') as teks:\n    print(teks.read())\n\nSelamat pagi\nSelamat siang\nSelamat sore\nSelamat malam\n\n\nKok bisa? Karena, setelah file ditutup, ketika dibuka lagi, cursor akan kembali ke posisi awal. Sehingga, kita tidak perlu menggunakan .seek() untuk meminta agar kembali ke posisi awal. Lihat saja:\n\nwith open(\"test.txt\", 'w') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n\nwith open(\"test.txt\", 'r') as teks:\n    print(teks.tell()) # output 0 karena berada di awal file\n    print(teks.read())\n\n0\nSelamat pagi\nSelamat siang\nSelamat sore\nSelamat malam\n\n\nSelain .read() beberapa karakter, kita juga bisa membaca satu baris (yaitu berhenti di baris baru) menggunakan .readline()\n\nwith open(\"test.txt\", 'w') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n\nwith open(\"test.txt\", 'r') as teks:\n    print(teks.readline(), end=\"\")\n\nSelamat pagi\n\n\nKalau kita lakukan berkali-kali, akan terbaca beberapa baris:\n\nwith open(\"test.txt\", 'w') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n\nwith open(\"test.txt\", 'r') as teks:\n    print(teks.readline(), end=\"\")\n    print(teks.readline(), end=\"\")\n    print(teks.readline(), end=\"\")\n\nSelamat pagi\nSelamat siang\nSelamat sore\n\n\nBahkan, kita bisa menggunakan for loop untuk mengiterasi pada tiap baris:\n\nwith open(\"test.txt\", 'w') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n\nwith open(\"test.txt\", 'r') as teks:\n    for baris in teks:\n        print(baris, end=\"\")\n\nSelamat pagi\nSelamat siang\nSelamat sore\nSelamat malam\n\n\nKita juga bisa memperoleh suatu list yang terdiri dari tiap baris, menggunakan .readlines():\n\nwith open(\"test.txt\", 'w') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n\nwith open(\"test.txt\", 'r') as teks:\n    semua_baris = teks.readlines()\n\nprint(semua_baris)\n\n['Selamat pagi\\n', 'Selamat siang\\n', 'Selamat sore\\n', 'Selamat malam']\n\n\nBagaimana kalau kita coba mode a? Kita coba .tell() juga di awal mode a agar bisa melihat posisi cursor kita membuka file dalam mode a:\n\nwith open(\"test.txt\", 'w') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n\nwith open(\"test.txt\", 'a') as teks:\n    print(teks.tell())\n    teks.write(\"Selamat sore\\n\")\n\nwith open(\"test.txt\", 'r') as teks:\n    semua_baris = teks.readlines()\n\nprint(semua_baris)\n\n27\n['Selamat pagi\\n', 'Selamat siang\\n', 'Selamat sore\\n']\n\n\nTernyata, ketika membuka file dengan mode a, cursor langsung diposisikan di akhir file, sehingga kita bisa langsung menulis untuk menambahkan sesuatu di akhir file.\nTerakhir, kita akan mencoba untuk meng-copy suatu text file, dengan cara membuat text file baru dan mengisi isinya dari text file yang lama. Caranya:\n\nBuka file yang lama dengan mode r, simpan semua isinya dalam suatu variabel, tutup\nBuka file yang baru dengan mode w, isi dengan variabel tersebut, tutup\n\nSetelah itu, kita bisa membuka lagi file yang baru dengan mode r hanya untuk melihat isinya, memastikan sama :)\n\n# Memperoleh isi file yang lama\nwith open(\"test.txt\", 'r') as file_lama:\n    isi_lama = file_lama.read()\n\nprint(\"Isi file yang lama: \")\nprint(isi_lama, end=\"\")\n\n# Menuliskan ke file yang baru\nwith open(\"testcopy.txt\", 'w') as file_baru:\n    file_baru.write(isi_lama)\n\n# Memperoleh isi file yang baru, mau liat aja\nwith open(\"testcopy.txt\", 'r') as file_baru:\n    isi_baru = file_baru.read()\n\nprint(\"Isi file yang baru:\")\nprint(isi_baru, end=\"\")\n\nIsi file yang lama: \nSelamat pagi\nSelamat siang\nSelamat sore\nIsi file yang baru:\nSelamat pagi\nSelamat siang\nSelamat sore\n\n\nBerhasil ya!\n\n\n\n\nKita akan latihan beberapa soal pemrograman di CodeChef. Sebenarnya, yang ditekankan di sini adalah latihan cara menerima input dan memberikan output sesuai permintaan soal di CodeChef, agar kalian sudah paham nantinya ketika mencari soal di CodeChef untuk proyek akhir Struktur Data.\nPertama-tama, silakan buat akun terlebih dahulu di https://www.codechef.com/\nLalu, silakan coba menyelesaikan soal-soal berikut:\n\nhttps://www.codechef.com/problems/START01\nhttps://www.codechef.com/problems/FLOW001\n(tidak jadi dibahas) https://www.codechef.com/problems/GDTURN\n\n\n\n\n\n\n\nJawaban no. 1\n\n\n\n\n\nN = input()\nprint(N)\n\n\n\n\n\n\n\n\n\nJawaban no. 2\n\n\n\n\n\nT = int(input())\nfor i in range(T):\n    baris = input().split(\" \")\n    A = int(baris[0])\n    B = int(baris[1])\n    hasil = A + B\n    print(hasil)\n\n\n\n\n\n\nSebelum bisa menggunakan Graphviz, perlu di-install terlebih dahulu.\nDi Google Colaboratory, kalian tinggal mengetik:\npip install graphviz\nSedangkan, apabila menggunakan Anaconda, buka Anaconda Prompt atau Command Prompt (cmd) lalu ketik:\nconda install graphviz\nTunggu instalasi selesai, barulah buka Jupyter Notebook dan ketik\npip install graphviz\nKemudian, kita bisa import:\n\nimport graphviz as gv\n\n(tunggu praktikum yang akan datang yaa)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul03.html#io-inputoutput",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul03.html#io-inputoutput",
    "title": "Modul 3 Struktur Data: I/O, CodeChef",
    "section": "",
    "text": "Kegunaan utama print adalah untuk menampilkan string (str).\n\nprint(\"Hello, world!\")\n\nHello, world!\n\n\n\nteks1 = \"Selamat sore!\"\nprint(teks1)\n\nSelamat sore!\n\n\nKita bisa menampilkan beberapa string sekaligus di dalam satu print, memisakan tiap string dengan koma.\n\nprint(\"Saya\", \"sudah\", \"makan\", \"siang\")\n\nSaya sudah makan siang\n\n\nSebenarnya, kita bisa menggunakan print untuk menampilkan tipe data apapun.\n\nangka = -45\nharga = 10.6\nprint(angka)\nprint(harga)\n\n-45\n10.6\n\n\nSehingga, kita bisa menuliskan seperti ini:\n\nprint(\"Suhu:\", angka)\n\nSuhu: -45\n\n\nKalau mau, kita juga bisa menyiapkan suatu string yang utuh terlebih dahulu (mengubah tipe data lain menjadi string dengan str), baru menampilkan string yang utuh tersebut:\n\nstring_utuh = \"Suhu: \" + str(angka)\nprint(string_utuh)\n\nSuhu: -45\n\n\nApabila kita print suatu list begitu saja, maka akan ditampilkan sebagai list.\n\nbeberapa_buah = [\"pisang\", 42, -5.1, \"apel\", \"jeruk\"]\nprint(beberapa_buah)\n\n['pisang', 42, -5.1, 'apel', 'jeruk']\n\n\nNamun, kita bisa saja menggunakan for loop untuk menampilkan tiap elemen.\n\nfor elemen in beberapa_buah:\n    print(elemen)\n\npisang\n42\n-5.1\napel\njeruk\n\n\nBegitu juga untuk set (tentu saja urutannya tidak menentu):\n\nbeberapa_warna = {\"merah\", \"hijau\", \"biru\", \"kuning\"}\nprint(beberapa_warna)\n\n{'merah', 'biru', 'kuning', 'hijau'}\n\n\n\nfor warna in beberapa_warna:\n    print(warna)\n\nmerah\nbiru\nkuning\nhijau\n\n\nUntuk suatu dict, kita bisa menampilkan dict seutuhnya:\n\nharga_toko = {\"kopi\": 6000, \"teh\": 5000, \"susu\": 7000}\nprint(harga_toko)\n\n{'kopi': 6000, 'teh': 5000, 'susu': 7000}\n\n\nKita bisa memperoleh set yang berisi key nya saja dengan dict.keys(), baru menampilkan set tersebut:\n\nyang_dijual = set(harga_toko.keys())\nprint(yang_dijual)\n\n{'kopi', 'teh', 'susu'}\n\n\nSerupa, kita bisa memperoleh set yang berisi value nya saja menggunakan dict.values():\n\nsemua_harga = set(harga_toko.values())\nprint(semua_harga)\n\n{6000, 7000, 5000}\n\n\nKalau mau, kita bisa melakukan for loop untuk tiap key:\n\nfor key in harga_toko.keys():\n    print(key, harga_toko[key])\n\nkopi 6000\nteh 5000\nsusu 7000\n\n\nBahkan, kita bisa melakukan for loop untuk tiap key dan value sekaligus, dengan dict.items():\n\nfor key, value in harga_toko.items():\n    print(key, \"harganya\", value)\n\nkopi harganya 6000\nteh harganya 5000\nsusu harganya 7000\n\n\nUmumnya, tiap kali kita menggunakan print, baris baru selalu ditambahkan secara otomatis, sehingga print yang selanjutnya akan ditampilkan di baris berikutnya. Sebenarnya, hal ini bisa diatur dengan setting end= seperti berikut:\n\nprint(\"Hari\", end=\"\\n\")\nprint(\"ini\", end=\"\\n\")\nprint(\"Jum'at\", end=\"\\n\")\n\nHari\nini\nJum'at\n\n\nend= bisa berupa apa saja:\n\nprint(\"Hari\", end=\"|\")\nprint(\"ini\", end=\"|\")\nprint(\"Jum'at\", end=\"|\")\n\nHari|ini|Jum'at|\n\n\nBahkan, kita bisa mengkosongkan end= (membuatnya menjadi string kosong atau \"\" atau '') apabila kita mengharapkan tidak ada “pemisah” antara tiap output:\n\nprint(\"Hari\", end=\"\")\nprint(\"ini\", end=\"\")\nprint(\"Jum'at\", end=\"\")\n\nHariiniJum'at\n\n\n\n\n\nMneggunakan input, kita bisa menerima masukkan data berupa string.\n\nnama = input()\nprint(\"Halo\", nama)\n\nHalo Bisma\n\n\nKita bisa menggunakan prompt berupa string dalam input, yaitu semacam “pertanyaan” agar jelas data apa yang diperlukan.\n\nnama = input(\"Masukkan nama: \")\nprint(\"Halo\", nama)\n\nMasukkan nama: Bisma\nHalo Bisma\n\n\nApabila input yang kita inginkan adalah selain string, kita harus mengakali. Contohnya, bisa saja kita langsung mengkonversi string yang masuk menjadi tipe data lain:\n\numur = int(input(\"Masukkan umur: \"))\nprint(\"Tahun depan, Anda akan berumur\", umur+1, \"tahun\")\n\nMasukkan umur: 19\nTahun depan, Anda akan berumur 20 tahun\n\n\nBahkan menjadi list juga bisa, menggunakan split untuk memecah suatu string menjadi beberapa bagian (dalam suatu list) berdasarkan suatu pemisah (di sini ,):\n\nbeberapa_angka = input(\"Masukkan beberapa angka: \").split(\",\")\nprint(\"Input yang masuk:\", beberapa_angka)\nsum = 0\nfor angka in beberapa_angka:\n    sum += float(angka)\nprint(\"Totalnya adalah\", sum)\n\nMasukkan beberapa angka: -10, 5.6, 3, -7, 82\nInput yang masuk: ['-10', ' 5.6', ' 3', ' -7', ' 82']\nTotalnya adalah 73.6\n\n\n\n\n\nDi Python, kita bisa membuka, mengedit, dan menutup text file, yaitu file yang berakhiran .txt\nKetika membuka suatu text file, ada beberapa pilihan “mode”:\n\nr: read-only, jika kita hanya ingin membaca isinya. Kalau file nya tidak ada, error.\na: append-only, jika kita hanya ingin menambahkan isi di akhir text file (sehingga tidak bisa melihat isi yang sudah ada). Kalau file nya belum ada, akan dibuat.\nw: write-only, jika kita hanya ingin menulis (tanpa bisa membaca isi yang sudah ada) dan menimpa apapun tulisan yang sudah ada. Kalau file nya belum ada, akan dibuat.\nr+: read and write. Kalau file nya tidak ada, error.\na+: append and read. Kalau file nya belum ada, akan dibuat.\nw+: write and read. Kalau file nya belum ada, akan dibuat.\n\nUntuk fitur yang paling lengkap (tetapi bisa berbahaya apabila kita tidak berhati-hati), bisa digunakan mode w+.\nKita bisa membuka suatu file dengan open. Dengan begitu, kita akan memperoleh suatu objek file. Objek ini memiliki beberapa atribut seperti .mode, dan beberapa method seperti:\n\n.write() untuk menulis\n.read() untuk membaca (memperoleh isinya sebagai string)\n.seek() agar “cursor” lompat ke posisi tertentu (misalnya .seek(0) untuk kembali ke awal file)\n.close() untuk menutup file setelah selesai digunakan\n\n(Apabila kita ingin mengubah mode, kita bisa melakukan .close() terlebih dahulu, baru open lagi dengan mode yang baru.)\nDi kode di bawah ini, kita akan membuka suatu file, menuliskan Hello, world! di dalamnya, lalu menutup file nya.\n\nteks = open(\"test.txt\", 'w+')\nteks.write(\"Hello, world!\")\nteks.close()\n\nSetelah running kode di atas, coba cek folder kalian yang menyimpan file .ipynb yang sedang kalian gunakan. Harusnya, ada file baru yang muncul bernama test.txt dan isinya Hello, world!\n\nDi Jupyter Notebook, kalian bisa kembali ke tab yang terbuka di browser kalian di mana kalian tadinya sudah membuat new notebook. Coba double-click test.txt\nDi Google Colaboratory, kalian bisa menekan tombol folder yang ada di sebelah kiri. Coba download test.txt lalu buka isinya\n\nMari kita coba gunakan .write() untuk menuliskan sesuatu di dalamnya, lalu .seek(0) untuk kembali ke awal file, kemudian .read() untuk membaca isinya (mulai dari awal file sesuai yang ditentukan oleh .seek())\n\nteks = open(\"test.txt\", 'w+')\nteks.write(\"Selamat pagi\")\nteks.seek(0)\nprint(teks.read())\nteks.close()\n\nSelamat pagi\n\n\nSetelah running kode di atas, kalau mau, silakan dibuka kembali.\n\nMenggunakan Jupyter Notebook: kalau tadinya sudah dibuka, ditutup dulu, baru dibuka lagi.\nMenggunakan Google Colaboratory: tunggu sebentar, download lagi, lalu buka isinya.\n\nPasti ada isinya, yaitu tulisan Selamat pagi\nTulisan Selamat pagi yang tadi tertimpa, karena kita menggunakan mode w, bukan a.\nSebenarnya, kalaupun tidak diperiksa isinya, kita bisa yakin bahwa isinya sudah berubah sesuai yang kita inginkan, karena kita sudah melihat isi yang baru dengan .read()\nMari kita coba menuliskan hal lain.\n\nteks = open(\"test.txt\", 'w+')\nteks.write(\"Selamat siang\")\nteks.seek(0)\nprint(teks.read())\nteks.close()\n\nSelamat siang\n\n\nKalau kita buka kembali, sekarang tulisannya adalah Selamat siang\nAda cara penulisan lain agar Python akan menutup file secara otomatis, yaitu menggunakan yang namanya context manager atau with statement. Syntax nya sebagai berikut:\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat sore\")\n    teks.seek(0)\n    print(teks.read())\n\nSelamat sore\n\n\nYang tadinya kita tulis teks = open(\"test.txt\", 'w+'), sekarang kita tulis dengan with ... as ... dengan titik dua di akhir. Lalu, semua hal yang mau kita lakukan dengan file tersebut (yang di sini sekarang namanya teks) itu kita lakukan di dalam with statement tersebut, dengan indentasi, seperti dalam for loop misalnya.\nBegitu keluar dari with statement, file akan ditutup secara otomatis. Dengan demikian, kita tidak perlu lagi melakukan .close()\nAnyway, boleh diperiksa lagi file nya, sekarang tulisannya menjadi Selamat sore\nKalau mau, kita bisa saja melakukan .write() berkali-kali untuk menambahkan tulisan berbaris-baris:\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\")\n    teks.write(\"Selamat siang\")\n    teks.write(\"Selamat sore\")\n    teks.write(\"Selamat malam\")\n    teks.seek(0)\n    print(teks.read())\n\nSelamat pagiSelamat siangSelamat soreSelamat malam\n\n\nOops, jangan lupa tambahkan \\n di akhir, ya!\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n    teks.seek(0)\n    print(teks.read())\n\nSelamat pagi\nSelamat siang\nSelamat sore\nSelamat malam\n\n\nKalau iseng, kita bisa melakukan misalnya teks.seek(21) untuk melompat 21 karakter dari awal file, sebelum melakukan .read():\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n    teks.seek(21)\n    print(teks.read())\n\nsiang\nSelamat sore\nSelamat malam\n\n\nDengan demikian, .read() hanya akan membaca tulisan yang ada mulai dari posisi ke-21 tersebut.\nKalau mau, kita bisa saja hanya membaca beberapa karakter, misalnya hanya 5 karakter:\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n    teks.seek(21)\n    print(teks.read(5))\n\nsiang\n\n\nKita bahkan bisa .seek() lagi setelah .read(), lalu .read() lagi, .seek() lagi, dan seterusnya sesuka hati.\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n    teks.seek(21)\n    print(teks.read(5))\n    teks.seek(48)\n    print(teks.read(5))\n    teks.seek(35)\n    print(teks.read(4))\n\nsiang\nmalam\nsore\n\n\nSetelah melakukan read, sebenarnya cursor akan ikut maju! Seandainya kita melakukan read dua kali berturut-turut, perhatikan:\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n    teks.seek(21)\n    print(teks.read(5), end=\"\")\n    print(teks.read(7), end=\"\")\n\nsiang\nSelama\n\n\nDi sini, kita menggunakan end=\"\" agar print tidak menambahkan baris baru. Lho, tapi ada baris baru? Baris baru itu sebenarnya dari file itu sendiri :)\nPerhatikan juga bahwa baris baru \\n itu terhitung sebagai satu karakter dengan sendirinya, sehingga yang tadinya kita mau membaca Selamat (7 karakter) itu malah hanya menjadi Selama (6 karakter), karena jatah satu karakter sudah digunakan untuk baris baru.\nSeandainya kita tidak menggunakan .seek() sama sekali, maka setelah selesai .write(), cursor akan terletak di akhir file (karena tadinya sudah selesai menulis sampai situ) sehingga .read() tidak akan memberikan output apapun:\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n    print(teks.read())\n\n\n\n\nKita bisa melihat posisi cursor saat ini dengan .tell()\n\nwith open(\"test.txt\", 'w+') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n    print(teks.tell())\n\n53\n\n\nWow, jauh ya! Tidak heran, tidak ada lagi yang perlu dibaca.\nKalau misalnya kita muak dengan .seek(), kita bisa saja menutup file setelah menulis, barulah kemudian membuka file lagi untuk melihat isinya. Kita bisa melakukan itu dengan dua kali with statement. (Ada baiknya kita menggunakan mode yang sesuai, misalnya w saja untuk menulis saja, lalu r saja untuk membaca saja.)\n\nwith open(\"test.txt\", 'w') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n\nwith open(\"test.txt\", 'r') as teks:\n    print(teks.read())\n\nSelamat pagi\nSelamat siang\nSelamat sore\nSelamat malam\n\n\nKok bisa? Karena, setelah file ditutup, ketika dibuka lagi, cursor akan kembali ke posisi awal. Sehingga, kita tidak perlu menggunakan .seek() untuk meminta agar kembali ke posisi awal. Lihat saja:\n\nwith open(\"test.txt\", 'w') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n\nwith open(\"test.txt\", 'r') as teks:\n    print(teks.tell()) # output 0 karena berada di awal file\n    print(teks.read())\n\n0\nSelamat pagi\nSelamat siang\nSelamat sore\nSelamat malam\n\n\nSelain .read() beberapa karakter, kita juga bisa membaca satu baris (yaitu berhenti di baris baru) menggunakan .readline()\n\nwith open(\"test.txt\", 'w') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n\nwith open(\"test.txt\", 'r') as teks:\n    print(teks.readline(), end=\"\")\n\nSelamat pagi\n\n\nKalau kita lakukan berkali-kali, akan terbaca beberapa baris:\n\nwith open(\"test.txt\", 'w') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n\nwith open(\"test.txt\", 'r') as teks:\n    print(teks.readline(), end=\"\")\n    print(teks.readline(), end=\"\")\n    print(teks.readline(), end=\"\")\n\nSelamat pagi\nSelamat siang\nSelamat sore\n\n\nBahkan, kita bisa menggunakan for loop untuk mengiterasi pada tiap baris:\n\nwith open(\"test.txt\", 'w') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n\nwith open(\"test.txt\", 'r') as teks:\n    for baris in teks:\n        print(baris, end=\"\")\n\nSelamat pagi\nSelamat siang\nSelamat sore\nSelamat malam\n\n\nKita juga bisa memperoleh suatu list yang terdiri dari tiap baris, menggunakan .readlines():\n\nwith open(\"test.txt\", 'w') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n    teks.write(\"Selamat sore\\n\")\n    teks.write(\"Selamat malam\")\n\nwith open(\"test.txt\", 'r') as teks:\n    semua_baris = teks.readlines()\n\nprint(semua_baris)\n\n['Selamat pagi\\n', 'Selamat siang\\n', 'Selamat sore\\n', 'Selamat malam']\n\n\nBagaimana kalau kita coba mode a? Kita coba .tell() juga di awal mode a agar bisa melihat posisi cursor kita membuka file dalam mode a:\n\nwith open(\"test.txt\", 'w') as teks:\n    teks.write(\"Selamat pagi\\n\")\n    teks.write(\"Selamat siang\\n\")\n\nwith open(\"test.txt\", 'a') as teks:\n    print(teks.tell())\n    teks.write(\"Selamat sore\\n\")\n\nwith open(\"test.txt\", 'r') as teks:\n    semua_baris = teks.readlines()\n\nprint(semua_baris)\n\n27\n['Selamat pagi\\n', 'Selamat siang\\n', 'Selamat sore\\n']\n\n\nTernyata, ketika membuka file dengan mode a, cursor langsung diposisikan di akhir file, sehingga kita bisa langsung menulis untuk menambahkan sesuatu di akhir file.\nTerakhir, kita akan mencoba untuk meng-copy suatu text file, dengan cara membuat text file baru dan mengisi isinya dari text file yang lama. Caranya:\n\nBuka file yang lama dengan mode r, simpan semua isinya dalam suatu variabel, tutup\nBuka file yang baru dengan mode w, isi dengan variabel tersebut, tutup\n\nSetelah itu, kita bisa membuka lagi file yang baru dengan mode r hanya untuk melihat isinya, memastikan sama :)\n\n# Memperoleh isi file yang lama\nwith open(\"test.txt\", 'r') as file_lama:\n    isi_lama = file_lama.read()\n\nprint(\"Isi file yang lama: \")\nprint(isi_lama, end=\"\")\n\n# Menuliskan ke file yang baru\nwith open(\"testcopy.txt\", 'w') as file_baru:\n    file_baru.write(isi_lama)\n\n# Memperoleh isi file yang baru, mau liat aja\nwith open(\"testcopy.txt\", 'r') as file_baru:\n    isi_baru = file_baru.read()\n\nprint(\"Isi file yang baru:\")\nprint(isi_baru, end=\"\")\n\nIsi file yang lama: \nSelamat pagi\nSelamat siang\nSelamat sore\nIsi file yang baru:\nSelamat pagi\nSelamat siang\nSelamat sore\n\n\nBerhasil ya!"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul03.html#codechef",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul03.html#codechef",
    "title": "Modul 3 Struktur Data: I/O, CodeChef",
    "section": "",
    "text": "Kita akan latihan beberapa soal pemrograman di CodeChef. Sebenarnya, yang ditekankan di sini adalah latihan cara menerima input dan memberikan output sesuai permintaan soal di CodeChef, agar kalian sudah paham nantinya ketika mencari soal di CodeChef untuk proyek akhir Struktur Data.\nPertama-tama, silakan buat akun terlebih dahulu di https://www.codechef.com/\nLalu, silakan coba menyelesaikan soal-soal berikut:\n\nhttps://www.codechef.com/problems/START01\nhttps://www.codechef.com/problems/FLOW001\n(tidak jadi dibahas) https://www.codechef.com/problems/GDTURN\n\n\n\n\n\n\n\nJawaban no. 1\n\n\n\n\n\nN = input()\nprint(N)\n\n\n\n\n\n\n\n\n\nJawaban no. 2\n\n\n\n\n\nT = int(input())\nfor i in range(T):\n    baris = input().split(\" \")\n    A = int(baris[0])\n    B = int(baris[1])\n    hasil = A + B\n    print(hasil)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul03.html#ditunda-ke-praktikum-yang-akan-datang-graphviz",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul03.html#ditunda-ke-praktikum-yang-akan-datang-graphviz",
    "title": "Modul 3 Struktur Data: I/O, CodeChef",
    "section": "",
    "text": "Sebelum bisa menggunakan Graphviz, perlu di-install terlebih dahulu.\nDi Google Colaboratory, kalian tinggal mengetik:\npip install graphviz\nSedangkan, apabila menggunakan Anaconda, buka Anaconda Prompt atau Command Prompt (cmd) lalu ketik:\nconda install graphviz\nTunggu instalasi selesai, barulah buka Jupyter Notebook dan ketik\npip install graphviz\nKemudian, kita bisa import:\n\nimport graphviz as gv\n\n(tunggu praktikum yang akan datang yaa)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul05.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul05.html",
    "title": "Modul 5 Struktur Data: Graphviz, Linked List",
    "section": "",
    "text": "Kembali ke Struktur Data (dengan Python)\nPada praktikum kali ini, kita akan membahas mengenai linked list, serta cara memvisualisasikannya menggunakan yang namanya Graphviz.\nSebelum mengikuti praktikum ini, ada baiknya kalian me-review kembali modul berikut:\n\nModul 2: Pengantar OOP\n\nUntuk apa? Kita akan menyusun struktur data linked list menggunakan class :) semoga kalian sudah cukup paham tentang class yaa. Kalau belum pun, semoga kalian akan lebih paham setelah praktikum kali ini :D\n\n\nGraphviz adalah semacam software yang bisa membuat visualisasi “graf” yang bagus. Mungkin di antara kalian belum semuanya kenal dengan graf, itu tidak masalah. Kurang lebih, suatu graf adalah kumpulan bulet-bulet (disebut simpul, node, atau vertex) yang disambung oleh “busur” (juga disebut arc atau edge), di mana tiap edge bisa berupa garis biasa atau berupa panah.\nBerikut contoh graf yang digambar dengan Graphviz:\n\n\n\n\n\n\n\ngraf G\n\n\n\nA\n\nA\n\n\n\nB\n\nB\n\n\n\nA-&gt;B\n\n\n\n\n\nC\n\nC\n\n\n\nA-&gt;C\n\n\n\n\n\nB-&gt;A\n\n\n\n\n\nF\n\nF\n\n\n\nB-&gt;F\n\n\n\n\nE\n\nE\n\n\n\nC-&gt;E\n\n\n\n\n\n\nD\n\nD\n\n\n\nD-&gt;C\n\n\n\n\nD-&gt;D\n\n\n\n\n\nD-&gt;E\n\n\n  tes\n\n\n\nE-&gt;F\n\n\n\n\n\nGHI\n\nGHI\n\n\n\nGHI-&gt;F\n\n\nqwerty\n\n\n\n\n\n\n\n\nLho, di mata kuliah Struktur Data kan ga ada graf. Untuk apa kita pelajari Graphviz?\nDengan Graphviz, kita bisa membuat visualisasi untuk berbagai struktur data nantinya, termasuk linked list hari ini. Kita bisa meminta Graphviz untuk membuat bentuk node yang tidak sederhana, termasuk bentuk node yang kita kenal di linked list, kemudian membuat edge yang berupa panah, sehingga kita benar-benar bisa menggambarkan suatu linked list :)\n\n\nSebelum bisa menggunakan Graphviz, perlu di-install terlebih dahulu.\nDi Google Colaboratory, kalian tinggal mengetik:\npip install graphviz\nSedangkan, apabila menggunakan Jupyter Notebook melalui Anaconda, buka Anaconda Prompt lalu ketik:\nconda install graphviz\nTunggu instalasi selesai, barulah buka Jupyter Notebook dan ketik\npip install graphviz\nNote:\n\nApabila Anda menggunakan Jupyter Notebook tetapi tidak melalui Anaconda, langkah conda install graphviz bisa digantikan dengan menginstal Graphviz dari https://graphviz.gitlab.io/download/\nUntuk penulisan pip, ada kemungkinan kalian perlu mengetik !pip dengan tanda seru di awal. Biasanya tidak perlu, tapi kalau menjadi error, boleh dicoba dengan tanda seru.\n\n\n\n\nSetelah instalasi selesai, kita bisa import:\n\nimport graphviz as gv\n\nDengan Graphviz, ada dua jenis gambar graf yang bisa kita buat:\n\nDigraph (graf berarah, yaitu tiap edge bisa berupa panah maupun garis biasa)\nGraph (graf sederhana, yaitu tiap edge hanya bisa berupa garis biasa, bukan panah)\n\nKarena Digraph lebih banyak fiturnya, kita akan membuat Digraph saja.\nSebagai contoh sederhana, kita bisa membuat Digraph yang terdiri dari dua node yaitu A dan B, dengan edge berupa panah yang menghubungkan A ke B. Kita buat objek Digraph terlebih dahulu:\n\ngraf1 = gv.Digraph()\n\nKemudian, kita bisa menambahkan node A dan B sebagai berikut:\n\ngraf1.node(\"A\")\ngraf1.node(\"B\")\n\nSelanjutnya, kita bisa membuat/menambahkan suatu edge dari A ke B, seperti berikut:\n\ngraf1.edge(\"A\", \"B\")\n\nSekarang kita bisa lihat grafnya:\n\ndisplay(graf1)\n\n\n\n\n\n\n\n\nNote: apabila fungsi display tidak dikenal, silakan import:\nfrom IPython.display import display\nSebenarnya, kita bisa saja menambahkan edge baru tanpa membuat node terlebih dahulu. Contohnya, menambahkan edge dari A ke C (suatu node baru):\n\ngraf1.edge(\"A\", \"C\")\n\nKita bisa lihat lagi:\n\ndisplay(graf1)\n\n\n\n\n\n\n\n\nBahkan, kita bisa membuat ulang graf di atas dengan cara seperti berikut:\n\ngraf2 = gv.Digraph()\ngraf2.edge(\"A\", \"B\")\ngraf2.edge(\"A\", \"C\")\n\n\ndisplay(graf2)\n\n\n\n\n\n\n\n\nMenariknya, kita bisa saja membuat panah yang menunjuk ke dirinya sendiri.\n\ngraf3 = gv.Digraph()\ngraf3.edge(\"A\", \"B\")\ngraf3.edge(\"B\", \"B\")\n\n\ndisplay(graf3)\n\n\n\n\n\n\n\n\nKita juga bisa membuat dua panah berlawanan arah di antara dua node seperti berikut:\n\ngraf4 = gv.Digraph()\ngraf4.edge(\"A\", \"B\")\ngraf4.edge(\"B\", \"A\")\n\n\ndisplay(graf4)\n\n\n\n\n\n\n\n\nMembuat satu panah yang dua arah juga bisa, dengan menentukan dir atau direction dari edge tersebut menjadi \"both\" seperti berikut:\n\ngraf5 = gv.Digraph()\ngraf5.edge(\"A\", \"B\", dir=\"both\")\n\n\ndisplay(graf5)\n\n\n\n\n\n\n\n\nDaripada panah, kita juga bisa membuat edge berupa garis biasa, dengan dir=\"none\" (bukan None ya!)\n\ngraf6 = gv.Digraph()\ngraf6.edge(\"A\", \"B\", dir=\"none\")\n\n\ndisplay(graf6)\n\n\n\n\n\n\n\n\nSejauh ini, grafnya selalu cenderung “dari atas ke bawah”. Daripada seperti itu, kita bisa mengubahnya menjadi kiri ke kanan untuk keseluruhan graf. Caranya, kita memasang graph_attr atau atribut graf, berbentuk dict, dan di dalamnya kita buat \"rankdir\": \"LR\" (left-right) seperti di bawah ini.\nSetelah objek Digraph dibuat, barulah tiap edge yang kita tambahkan akan dari kiri ke kanan.\n\ngraf7 = gv.Digraph(graph_attr={\"rankdir\": \"LR\"})\ngraf7.edge(\"A\", \"B\")\n\n\ndisplay(graf7)\n\n\n\n\n\n\n\n\nSelain node diberi nama, edge juga bisa diberi keterangan, lho! Caranya, pasang nilai label ketika membuat edge baru:\n\ngraf8 = gv.Digraph(graph_attr={\"rankdir\": \"LR\"})\ngraf8.edge(\"A\", \"B\", label=\"test\")\n\n\ndisplay(graf8)\n\n\n\n\n\n\n\n\nSebenarnya, di dalam suatu node, ada yang namanya name (atau ID) dan ada juga yang disebut label.\n\nlabel adalah tulisan yang tampil di gambar pada node tersebut\nname atau ID adalah sebutan yang dikenal oleh Graphviz ketika misalnya ingin membuat edge\n\nSelama ini, yang kita tentukan adalah name. Kebetulan, khusus node, apabila label tidak ditentukan, maka otomatis akan diambil dari name.\nBerikut ini, kita bisa coba menentukan name dan label sekaligus ketika membuat node:\n\ngraf9 = gv.Digraph()\ngraf9.node(\"matkul1\", label=\"Alprog\")\ngraf9.node(\"matkul2\", label=\"Strukdat\")\ngraf9.edge(\"matkul1\", \"matkul2\")\n\n\ndisplay(graf9)\n\n\n\n\n\n\n\n\nPerlu dicatat, apabila kita menambahkan edge sekaligus membuat node baru, kita tidak bisa memasang label untuk node baru tersebut.\nSehingga, apabila kalian ingin membuat node dengan label tertentu, yang nantinya akan disambung ke node lain dengan edge, maka sebaiknya node baru tersebut dibuat dengan .node() terlebih dahulu, barulah name nya digunakan ketika membuat .edge()\nSelain itu, bahkan graf itu sendiri juga bisa memiliki nama, yang ditentukan ketika membuat objek grafnya.\n\ngraf10 = gv.Digraph(\"Nama graf\")\ngraf10.edge(\"A\", \"B\")\ngraf10.edge(\"B\", \"C\")\n\n\ndisplay(graf10)\n\n\n\n\n\n\n\n\nCoba letakkan mouse kalian pada gambarnya selama beberapa detik. Akan muncul tulisan “Nama graf”. (Kalau tidak muncul, coba klik kanan dulu, pencet “Open image in New Tab” atau semacamnya.)\nApabila kalian ingin menentukan misalnya rankdir, tuliskan setelah nama grafnya.\n\ngraf11 = gv.Digraph(\"Graf ke kanan\", graph_attr={\"rankdir\": \"LR\"})\ngraf11.edge(\"A\", \"B\")\ngraf11.edge(\"B\", \"C\")\n\n\ndisplay(graf11)\n\n\n\n\n\n\n\n\n\n\n\nSebenarnya, Graphviz melibatkan yang namanya bahasa DOT (dibaca “dot”), yaitu semacam “bahasa komputer” untuk mendeskripsikan graf, yang kemudian diolah oleh Graphviz menjadi gambar.\n(Sebenarnya, bahasa DOT mudah dipahami dan bisa kalian pelajari sendiri kalo iseng :D)\nTiap kali kita membuat graf baru dengan Graphviz melalui Python ini, Graphviz selalu menyusun bahasa DOT terlebih dahulu, baru mengolah bahasa DOT tersebut menjadi gambar.\nKita bisa melihat bahasa DOT untuk tiap graf melalui atribut .source seperti berikut:\n\nprint(graf11.source)\n\ndigraph \"Graf ke kanan\" {\n    graph [rankdir=LR]\n    A -&gt; B\n    B -&gt; C\n}\n\n\n\nKemudian, kita bisa memasukkan bahasa DOT tersebut ke dalam semacam software yang bisa mengolah bahasa DOT menjadi gambar. Contohnya adalah link berikut:\nhttps://dreampuf.github.io/GraphvizOnline/\nSebaliknya, dari bahasa DOT, Graphviz juga bisa membuat objek Digraph misalnya, menggunakan graphviz.Source() seperti berikut:\n\ngraf12 = gv.Source(\"\"\"\ndigraph \"Graf ke kanan\" {\n    graph [rankdir=LR]\n    A -&gt; B\n    B -&gt; C\n}\n\"\"\")\n\n\ndisplay(graf12)\n\n\n\n\n\n\n\n\nSelain import seperti itu, baik bahasa DOT maupun gambar yang dibuat oleh Graphviz bisa di-export dengan menetapkan .format terlebih dahulu (misalnya “svg” atau “png”), lalu menggunakan .render() sebagai berikut:\n\ngraf11.format = \"svg\"\ngraf11.render()\n\n'Graf ke kanan.gv.svg'\n\n\nSeperti di Modul 3 kemarin ketika membahas I/O, ada file baru yang muncul.\n\nApabila menggunakan Google Colaboratory, silakan tekan tombol folder di sebelah kiri.\nApabila menggunakan Jupyter Notebook, silakan periksa folder yang di dalamnya ada file .ipynb yang sedang kalian gunakan.\n\nAkan muncul dua file baru, yaitu:\n\nGraf ke kanan.gv\nGraf ke kanan.gv.svg\n\nFile pertama adalah file .gv (Graphviz) yang mengandung bahasa DOT yang disusun sebelum diolah menjadi gambar. File kedua adalah file gambar yang diolah, dalam format sesuai dengan yang kita tentukan.\nKita bisa membaca isi Graf ke kanan.gv sebagaimana kita membaca isi text file:\n\nwith open(\"Graf ke kanan.gv\", \"r\") as isi:\n    print(isi.read())\n\ndigraph \"Graf ke kanan\" {\n    graph [rankdir=LR]\n    A -&gt; B\n    B -&gt; C\n}\n\n\n\nSelain itu, perhatikan bahwa nama file nya sesuai dengan nama graf yang kita tentukan ketika membuat objek graf11 tadi. Kalau lupa, kita bisa memeriksa nama graf melalui atribut .nama\n\nprint(graf11.name)\n\nGraf ke kanan\n\n\nDengan atribut itu pula, kita bisa mengubah nama grafnya:\n\ngraf11.name = \"Nama baru\"\n\nSehingga, ketika misalnya Graphviz menyusun bahasa DOT, akan digunakan nama yang baru:\n\nprint(graf11.source)\n\ndigraph \"Nama baru\" {\n    graph [rankdir=LR]\n    A -&gt; B\n    B -&gt; C\n}\n\n\n\n\n\n\nIngat atribut label yang bisa dipasang ketika membuat suatu node? Sebenarnya, kita bisa memanfaatkan atribut tersebut untuk membuat bentuk node sesuka hati kita, lho! Terutama, kita bisa membuat node dengan bentuk seperti tabel.\nPenulisan label seperti tabel ini mirip seperti struktur bahasa HTML, sehingga disebut HTML-like labels.\nPerhatikan syntax (penulisan) berikut.\n\ngraf13 = gv.Digraph()\ngraf13.node(\"A\", shape=\"none\", label=\"\"\"&lt;\n&lt;TABLE&gt;\n    &lt;TR&gt;\n        &lt;TD&gt;P&lt;/TD&gt;\n        &lt;TD&gt;Q&lt;/TD&gt;\n    &lt;/TR&gt;\n    &lt;TR&gt;\n        &lt;TD&gt;R&lt;/TD&gt;\n        &lt;TD&gt;S&lt;/TD&gt;\n    &lt;/TR&gt;\n&lt;/TABLE&gt;\n&gt;\"\"\")\n\ngraf13.node(\"B\") # node biasa\ngraf13.edge(\"A\", \"B\")\n\n\ndisplay(graf13)\n\n\n\n\n\n\n\n\nPerhatikan,\n\nKetika membuat node yang ingin berbentuk tabel, ditambahkan atribut shape=\"none\" (bukan None) di samping menulis label nya.\nlabel berupa long string, sehingga diawali dan diakhiri dengan tiga tanda kutip.\nKarakter pertama dari long string tersebut haruslah &lt; dan karakter terakhir haruslah &gt;\nKemudian, penulisan tabel diawali dengan penulisan &lt;TABLE&gt;, kemudian &lt;TR&gt; (table row) untuk tiap baris, lalu &lt;TD&gt; (table data) untuk tiap sel. Masing-masing selalu ditutup dengan &lt;/TD&gt;, &lt;/TR&gt;, dan &lt;/TABLE&gt;, bagaikan keberadaan endif, endfor, endwhile dan sebagainya di pseudocode.\n\nAgar lebih bagus, di bagian &lt;TABLE&gt; kita bisa menambahkan:\nBORDER=\"0\" CELLBORDER=\"1\" CELLSPACING=\"0\"\nSeperti berikut:\n\ngraf14 = gv.Digraph()\ngraf14.node(\"A\", shape=\"none\", label=\"\"\"&lt;\n&lt;TABLE BORDER=\"0\" CELLBORDER=\"1\" CELLSPACING=\"0\"&gt;\n    &lt;TR&gt;\n        &lt;TD&gt;P&lt;/TD&gt;\n        &lt;TD&gt;Q&lt;/TD&gt;\n    &lt;/TR&gt;\n    &lt;TR&gt;\n        &lt;TD&gt;R&lt;/TD&gt;\n        &lt;TD&gt;S&lt;/TD&gt;\n    &lt;/TR&gt;\n&lt;/TABLE&gt;\n&gt;\"\"\")\n\ngraf14.node(\"B\")\ngraf14.edge(\"A\", \"B\")\n\n\ndisplay(graf14)\n\n\n\n\n\n\n\n\nBagaimana kalau misalnya kita ingin panahnya seperti “berasal” dari sel tertentu? Caranya, kita bisa membuat yang namanya port, misalnya di sel R, kemudian edge yang dibuat akan kita sambung dari port tersebut, seperti berikut:\n\ngraf15 = gv.Digraph()\ngraf15.node(\"A\", shape=\"none\", label=\"\"\"&lt;\n&lt;TABLE BORDER=\"0\" CELLBORDER=\"1\" CELLSPACING=\"0\"&gt;\n    &lt;TR&gt;\n        &lt;TD&gt;P&lt;/TD&gt;\n        &lt;TD&gt;Q&lt;/TD&gt;\n    &lt;/TR&gt;\n    &lt;TR&gt;\n        &lt;TD PORT=\"port1\"&gt;R&lt;/TD&gt;\n        &lt;TD&gt;S&lt;/TD&gt;\n    &lt;/TR&gt;\n&lt;/TABLE&gt;\n&gt;\"\"\")\n\ngraf15.node(\"B\")\ngraf15.edge(\"A:port1\", \"B\")\n\n\ndisplay(graf15)\n\n\n\n\n\n\n\n\nKalau di Microsoft Excel atau Google Sheets, kita bisa melakukan merge beberapa sel, entah secara horizontal atau vertikal atau bahkan dua-duanya. Ketika menyusun HTML-like labels, kita bisa menggunakan COLSPAN (merentang beberapa kolom) dan ROWSPAN (merentang beberapa baris) untuk membuat efek seperti di-merge.\n\ngraf16 = gv.Digraph()\ngraf16.node(\"A\", shape=\"none\", label=\"\"\"&lt;\n&lt;TABLE BORDER=\"0\" CELLBORDER=\"1\" CELLSPACING=\"0\"&gt;\n    &lt;TR&gt;\n        &lt;TD ROWSPAN=\"2\"&gt;P&lt;/TD&gt;\n        &lt;TD COLSPAN=\"2\"&gt;Q&lt;/TD&gt;\n    &lt;/TR&gt;\n    &lt;TR&gt;\n        &lt;TD&gt;R&lt;/TD&gt;\n        &lt;TD&gt;S&lt;/TD&gt;\n    &lt;/TR&gt;\n&lt;/TABLE&gt;\n&gt;\"\"\")\n\ngraf16.node(\"B\")\ngraf16.edge(\"A\", \"B\")\n\n\ndisplay(graf16)\n\n\n\n\n\n\n\n\n\n\n\n\nSingly-linked list (seringkali disebut linked list saja) adalah semacam “rantai” dari node, di mana tiap node berisi 2 nilai, yaitu data dan next (yaitu pointer ke node lain). Node yang paling pertama itu ditunjuk oleh suatu pointer bernama head, yang menjadi awal dari linked list.\n(Terkadang, pointer next ditulis LINK. Artinya dan kegunaannya sama.)\nPertama-tama, kita buat struktur node terlebih dahulu menggunakan class. (Apabila pointer next tidak menunjuk ke apapun, biasanya ditulis NULL atau di sini None.)\nBiasanya, di kuliah, disebutnya class Node atau Node saja. Namun, berhubung modul ini akan membahas doubly-linked list dengan struktur yang agak berbeda, maka node untuk singly-linked list akan kita sebut SLNode (singly-linked node) agar berbeda.\n\nclass SLNode:\n    def __init__(self, data, next=None):\n        self.data = data\n        self.next = next\n\nKita bisa bermain-main dengan node ini sebagaimana yang dibahas di kuliah. Misalnya, kita buat node baru yang menyimpan data 15:\n\np = SLNode(15)\n\nSaat ini, node tersebut ditunjuk oleh pointer yang di sini kita sebut p. Secara tidak langsung, kita telah membuat linked list dengan head nya adalah p.\nKita bisa mengakses data yang disimpan di data dan juga alamat yang tersimpan di next:\n\nprint(p.data)\n\n15\n\n\n\nprint(p.next)\n\nNone\n\n\nSaat ini, node yang ditunjuk oleh p itu belum menunjuk ke manapun, sehingga p.next masih bernilai None.\nKita bisa melihat alamat dari node itu sendiri menggunakan id:\n\nprint(id(p))\n\n4404463888\n\n\nAlamat ini akan selalu berbeda tiap kali kita membuat node baru, dan di antara dua komputer kemungkinan besar juga berbeda. Memang wajar apabila alamat yang kalian dapatkan itu berbeda dengan yang tertera di modul.\nNamun, alamat biasanya ditampilkan dalam bentuk heksadesimal (base-16), sedangkan yang kita dapatkan dengan id masih berupa bilangan bulat desimal (base-10). Kita bisa menggunakan hex untuk mengubah base-10 menjadi base-16:\n\nprint(hex(id(p)))\n\n0x10686c910\n\n\nAwalan 0x itu hanya penanda bahwa bilangannya berupa heksadesimal.\nSelanjutnya, kita bisa membuat node baru di p.next, yaitu yang ditunjuk oleh p, sebagai berikut:\n\np.next = SLNode(28)\n\nSehingga, data 28 itu bisa diakses dari p seperti berikut:\n\nprint(p.next.data)\n\n28\n\n\nSedangkan, setelah node berisi 15 dan node berisi 28, belum ada node lagi, sehingga:\n\nprint(p.next.next)\n\nNone\n\n\nMari kita buat node baru lagi setelah node berisi 28:\n\np.next.next = SLNode(-3)\n\nSehingga, kita bisa mengakses data masing-masing node dari p:\n\nprint(p.data)\nprint(p.next.data)\nprint(p.next.next.data)\n\n15\n28\n-3\n\n\nKita bisa juga membuat pointer baru yang menunjuk ke node yang sudah ada. Misalnya, kita bisa membuat pointer bernama q yang menunjuk ke node yang berisi 28, seperti berikut:\n\nq = p.next\n\nSehingga, p.next.next bisa diakses dengan q.next:\n\nprint(p.next.next.data)\nprint(q.next.data)\n\n-3\n-3\n\n\nBahkan, kita bisa mengubah data -3 menjadi yang lain melalui q, dan itu akan berubah juga jika diakses melalui p:\n\nq.next.data = -63\nprint(q.next.data)\nprint(p.next.next.data)\n\n-63\n-63\n\n\nKok bisa? Karena, sesuai yang sudah kita tetapkan, q menunjuk ke node yang sama dengan p.next. Kita bisa periksa alamatnya:\n\nprint(hex(id(q)))\nprint(hex(id(p.next)))\n\n0x10686d780\n0x10686d780\n\n\nSehingga alamat dari node yang ditunjuk oleh q.next akan sama dengan yang ditunjuk oleh p.next.next:\n\nprint(hex(id(q.next)))\nprint(hex(id(p.next.next)))\n\n0x10686d000\n0x10686d000\n\n\nSejauh ini, kita sudah bermain dengan node dan membuat linked list secara manual. Sebenarnya, kita juga bisa membuat suatu class untuk suatu linked list secara keseluruhan. Di dalam class itu, kita bisa membuat atribut (variabel) yang menyimpan head, serta berbagai method (fungsi) untuk algoritma-algoritma operasi dasar yang kita pelajari di kuliah, seperti insert node di awal/akhir dan delete node di awal/akhir. Dengan begitu, kita bisa menggunakan linked list dengan lebih nyaman.\nKita akan menyebutnya class SLList (singly-linked list).\n\nclass SLList:\n    def __init__(self):\n        self.head = None\n\n    def is_empty(self):\n        if self.head == None:\n            return True\n        else:\n            return False\n\n    # Traversal, hanya untuk menghitung banyaknya node di linked list\n    def get_size(self):\n        count = 0\n        current = self.head\n        while current != None:\n            count += 1\n            current = current.next\n        return count\n\n    # Traversal, print masing-masing data node dari awal sampai akhir\n    def print_all(self):\n        print(\"head -&gt; \", end=\"\")\n        temp = self.head\n        while temp != None:\n            print(temp.data, end = \" -&gt; \")\n            temp = temp.next\n        print(\"None\")\n    \n    # Traversal, semacam linear search, cari letak node dengan data tertentu\n    def get_pos(self, x):\n        pos = -1\n        current = self.head\n        while current != None:\n            pos += 1\n            if current.data == x:\n                return pos\n            current = current.next\n        return -1\n    \n    def ins_front(self, newdata):\n        newnode = SLNode(newdata)\n        newnode.next = self.head\n        self.head = newnode\n    \n    def ins_end(self, newdata):\n        newnode = SLNode(newdata)\n        if self.is_empty():\n            self.head = newnode\n        else:\n            temp = self.head\n            while temp.next != None:\n                temp = temp.next\n            \n            # sekarang temp sudah di node terakhir\n            temp.next = newnode\n    \n    def ins_pos(self, newdata, pos):\n        if pos == 0:\n            self.ins_front(newdata)\n        else:\n            current_pos = 0\n            current = self.head\n            while (current != None) and (current_pos != pos-1):\n                current = current.next\n                current_pos += 1\n            # Keluar loop, bisa karena current == None atau current_pos == pos-1\n            # Kalau karena current_pos == pos-1, bisa insert\n            if (current_pos == pos-1):\n                newnode = SLNode(newdata)\n                temp = current.next\n                current.next = newnode\n                newnode.next = temp\n            # Tapi kalau karena current == None,\n            # berarti posisi yang diminta melampaui panjang linked list\n            else:\n                print(\"Error: posisi melebihi panjang linked list\")\n    \n    def del_front(self):\n        if self.is_empty():\n            print(\"Error: linked list sudah kosong\")\n        else:\n            temp = self.head.next\n            del self.head\n            self.head = temp\n    \n    def del_end(self):\n        if self.is_empty():\n            print(\"Error: linked list sudah kosong\")\n        else:\n            temp = self.head\n            while temp.next.next != None:\n                temp = temp.next\n            \n            # sekarang temp ada di node sebelum terakhir\n            del temp.next\n            temp.next = None\n    \n    # Mirip ins_pos, hanya berbeda di bagian current_pos == pos-1\n    def del_pos(self, pos):\n        if pos == 0:\n            self.del_front()\n        else:\n            current_pos = 0\n            current = self.head\n            while (current != None) and (current_pos != pos-1):\n                current = current.next\n                current_pos += 1\n            # Keluar loop, bisa karena current == None atau current_pos == pos-1\n            # Kalau karena current_pos == pos-1, maka bisa dihapus selama \n            # current.next yang mau dihapus itu memang ada\n            if (current_pos == pos-1) and (current.next != None):\n                temp = current.next.next\n                del current.next\n                current.next = temp\n            # Tapi kalau karena current == None, atau current.next tidak ada,\n            # berarti posisi yang diminta melampaui panjang linked list\n            else:\n                print(\"Error: posisi melebihi panjang linked list\")\n\n    # Menghapus semua node di linked list\n    def del_all(self):\n        while (not self.is_empty()):\n            self.del_front()\n\n    # Method untuk memperoleh digraph yang menggambarkan linked list nya :D\n    def get_digraph(self):\n        # Buat digraph baru yang sifatnya dari kiri ke kanan\n        new_digraph = gv.Digraph(graph_attr={\"rankdir\": \"LR\"})\n        \n        # Pointer untuk menunjuk ke tiap node, mulai dari node pertama\n        # (akan dilakukan traversal)\n        current = self.head\n\n        # Untuk menghitung node ke-sekian untuk nama node di Graphviz,\n        # sehingga head menunjuk ke node0, lalu node0 menunjuk ke node1, dst\n        counter = 0\n\n        # Memperoleh alamat yang sedang disimpan di head\n        # - asumsi awal: tidak ada alamat (None)\n        next_id = None\n        next_name = \"node0\" # ini nanti untuk nama node berikutnya di Graphviz\n        # - kalau ternyata ada alamat...\n        if current != None:\n            # maka simpan alamat tersebut\n            next_id = hex(id(current))\n            # kita buat lebih spesifik untuk node berikutnya, tunjuk ke port id\n            next_name = \"node0:id\"\n        \n        # Label (tabel) untuk pointer head\n        # - pembuka tabel\n        str_label = \"&lt;\"\n        str_label += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n        # - baris head\n        str_label += \"&lt;TR&gt;&lt;TD&gt;head&lt;/TD&gt;&lt;/TR&gt;\"\n        # - baris alamat (sekalian membuat port namanya \"contents\")\n        str_label += \"&lt;TR&gt;&lt;TD PORT=\\\"contents\\\"&gt;\" + str(next_id) + \"&lt;/TD&gt;&lt;/TR&gt;\"\n        # - penutup tabel\n        str_label += \"&lt;/TABLE&gt;\"\n        str_label += \"&gt;\"\n\n        # Membuat node head, membuat edge dari head ke node berikutnya\n        new_digraph.node(\"head\", shape=\"none\", label=str_label)\n        new_digraph.edge(\"head:contents\", next_name)\n        # dari port \"contents\" ke node berikutnya, yang namanya next_name\n        \n        # Selama node yang ditunjuk bukan None, buatlah node nya di Graphviz,\n        # lalu lanjut ke node selanjutnya (ini traversal)\n        while current != None:\n            # Alamat yang tersimpan pada current.next\n            # - asumsi awal: tidak ada alamat; current adalah node terakhir\n            next_id = None\n            # - kalau ternyata ada alamat...\n            if current.next != None:\n                # maka simpan alamat tersebut\n                next_id = hex(id(current.next))\n            \n            # Persiapan label (tabel) untuk node\n            # - pembuka tabel\n            str_label = \"&lt;\"\n            str_label += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n            # - baris tulisan \"data\", \"next\"\n            str_label += \"&lt;TR&gt;&lt;TD&gt;data&lt;/TD&gt;&lt;TD&gt;next&lt;/TD&gt;&lt;/TR&gt;\"\n            # - baris untuk isi data dan isi next\n            str_label += \"&lt;TR&gt;\"\n            str_label += \"&lt;TD&gt;\" + str(current.data) + \"&lt;/TD&gt;\"\n            str_label += \"&lt;TD PORT=\\\"next\\\"&gt;\" + str(next_id) + \"&lt;/TD&gt;\"\n            str_label += \"&lt;/TR&gt;\"\n            # - baris tulisan \"alamat node\", merentang dua kolom\n            str_label += \"&lt;TR&gt;&lt;TD COLSPAN=\\\"2\\\"&gt;alamat node&lt;/TD&gt;&lt;/TR&gt;\"\n            # - baris untuk isi alamat node, merentang dua kolom\n            str_label += \"&lt;TR&gt;\"\n            str_label += \"&lt;TD PORT=\\\"id\\\" COLSPAN=\\\"2\\\"&gt;\"\n            str_label += str(hex(id(current)))\n            str_label += \"&lt;/TD&gt;\"\n            str_label += \"&lt;/TR&gt;\"\n            # - penutup tabel\n            str_label += \"&lt;/TABLE&gt;\"\n            str_label += \"&gt;\"\n\n            # Membuat node baru di Graphviz dengan label (tabel) tersebut\n            new_digraph.node(\"node\" + str(counter), shape=\"none\", label = str_label)\n\n            # Menentukan nama dua port yang bakal disambung dengan edge,\n            # yaitu (node saat ini):next disambung ke node(berikutnya):id\n            # yaitu bagian \"next\" disambung ke bagian alamat di node berikutnya\n            nama_node_next = \"node\" + str(counter) + \":next\"\n            if current.next != None:\n                nama_alamat_node_berikutnya = \"node\" + str(counter+1) + \":id\"\n            # atau ke node(berikutnya) saja tanpa id kalau itu ternyata None,\n            # karena None tidak akan memiliki port id\n            else:\n                nama_alamat_node_berikutnya = \"node\" + str(counter+1)\n            \n            # Menyambung keduanya\n            new_digraph.edge(nama_node_next, nama_alamat_node_berikutnya)\n            \n            # Lanjut ke node selanjutnya\n            current = current.next\n            counter += 1\n        # Kalau sudah keluar loop, artinya current menunjuk ke None\n        # Berarti tinggal membuat \"node\" terakhir berisi tulisan None\n        # (karena sambungannya sudah dibuat di dalam loop, tinggal node nya)\n        new_digraph.node(\"node\" + str(counter), shape=\"none\", label=\"None\")\n\n        # Digraph sudah jadi\n        return new_digraph\n\n\ntest = SLList()\ntest.ins_front(5)\ntest.ins_front(15)\ntest.ins_front(25)\ntest.ins_front(35)\n\n\ntest.print_all()\n\nhead -&gt; 35 -&gt; 25 -&gt; 15 -&gt; 5 -&gt; None\n\n\n\nprint(test.get_pos(15))\n\n2\n\n\n\nprint(test.get_pos(39))\n\n-1\n\n\n\ntest.ins_end(100)\n\n\ntest.print_all()\n\nhead -&gt; 35 -&gt; 25 -&gt; 15 -&gt; 5 -&gt; 100 -&gt; None\n\n\n\ntest.del_front()\ntest.del_front()\n\n\ntest.print_all()\n\nhead -&gt; 15 -&gt; 5 -&gt; 100 -&gt; None\n\n\n\ntest.del_pos(3)\n\nError: posisi melebihi panjang linked list\n\n\n\ntest.del_pos(2)\n\n\ntest.print_all()\n\nhead -&gt; 15 -&gt; 5 -&gt; None\n\n\n\ntest.ins_pos(-42, 7)\n\nError: posisi melebihi panjang linked list\n\n\n\ntest.ins_pos(76, 1)\n\n\ntest.print_all()\n\nhead -&gt; 15 -&gt; 76 -&gt; 5 -&gt; None\n\n\n\ngambar = test.get_digraph()\n\n\ndisplay(gambar)\n\n\n\n\n\n\n\n\n\n\n\n\nclass DLNode:\n    def __init__(self, data, next=None, prev=None):\n        self.data = data\n        self.next = next\n        self.prev = prev\n\n\nclass DLList:\n    def __init__(self):\n        self.head = None\n        self.tail = None\n    \n    # Masih sama persis dengan singly linked list\n    def is_empty(self):\n        if self.head == None:\n            return True\n        else:\n            return False\n    \n    # Traversal, hanya untuk menghitung banyaknya node di linked list\n    # Masih sama persis dengan singly linked list\n    def get_size(self):\n        count = 0\n        current = self.head\n        while current != None:\n            count += 1\n            current = current.next\n        return count\n\n    # Traversal, print masing-masing data node dari awal sampai akhir\n    def print_all(self):\n        print(\"head -&gt; \", end=\"\")\n        temp = self.head\n        while (temp != None) and (temp.next != None):\n            print(temp.data, end = \" &lt;-&gt; \")\n            temp = temp.next\n        # Khusus node terakhir:\n        if (temp != None) and (temp.next == None):\n            print(temp.data, end = \" &lt;- \")\n        print(\"tail\")\n    \n    def ins_front(self, newdata):\n        newnode = DLNode(newdata)\n        newnode.next = self.head\n        if self.head != None:\n            self.head.prev = newnode\n        self.head = newnode\n        if self.tail == None: # jika tadinya doubly linked list kosong,\n            # maka newnode menjadi node pertama, ditunjuk oleh head dan tail\n            self.tail = newnode\n\n    # Berbeda dengan singly linked list, tinggal insert di tail;\n    # tidak perlu traversal\n    def ins_end(self, newdata):\n        newnode = DLNode(newdata)\n        newnode.prev = self.tail\n        if self.tail != None:\n            self.tail.next = newnode\n        self.tail = newnode\n        if self.head == None: # jika tadinya doubly linked list kosong,\n            # maka newnode menjadi node pertama, ditunjuk oleh head dan tail\n            self.head = newnode\n    \n    def ins_pos(self, newdata, pos):\n        if pos == 0:\n            self.ins_front(newdata)\n            return\n        n = self.get_size()\n        if pos == n:\n            self.ins_end(newdata)\n        elif pos &gt; n:\n            print(\"Error: posisi melebihi panjang linked list\")\n        else:\n            current_pos = 0\n            current = self.head\n            while (current_pos != pos-1):\n                current = current.next\n                current_pos += 1\n            # Keluar loop berarti current_pos == pos-1\n            newnode = DLNode(newdata)\n            newnode.prev = current\n            newnode.next = current.next\n            current.next = newnode\n            # Sudah pasti newnode.next != None,\n            # karena kasus pos == n sudah ditangani\n            newnode.next.prev = newnode\n    \n    def del_front(self):\n        if self.is_empty():\n            print(\"Error: linked list sudah kosong\")\n        else:\n            temp = self.head.next\n            del self.head\n            self.head = temp\n            if temp != None:\n                temp.prev = None\n            else: # jika temp == None, maka self.head == None,\n                # berarti sekarang doubly linkd list kosong,\n                # sehingga tail juga menunjuk ke None\n                self.tail = None\n    \n    def del_end(self):\n        if self.is_empty():\n            print(\"Error: linked list sudah kosong\")\n        else:\n            temp = self.tail.prev\n            del self.tail\n            self.tail = temp\n            if temp != None:\n                temp.next = None\n            else: # jika temp == None, maka self.tail == None,\n                # berarti sekarang doubly linkd list kosong,\n                # sehingga head juga menunjuk ke None\n                self.head = None\n    \n    def del_pos(self, pos):\n        if pos == 0:\n            self.del_front()\n            return\n        n = self.get_size()\n        if pos == n-1:\n            self.del_end()\n        elif pos &gt; n-1:\n            print(\"Error: posisi melebihi panjang linked list\")\n        else:\n            current_pos = 0\n            current = self.head\n            while (current_pos != pos-1):\n                current = current.next\n                current_pos += 1\n            temp = current.next.next\n            del current.next\n            current.next = temp\n            # Sudah pasti temp != None,\n            # karena kasus pos == (n-1) sudah ditangani\n            temp.prev = current\n    \n    # Method untuk memperoleh digraph yang menggambarkan linked list nya :D\n    def get_digraph(self):\n        # Buat digraph baru yang sifatnya dari kiri ke kanan\n        new_digraph = gv.Digraph(graph_attr={\"rankdir\": \"LR\"})\n        \n        # Pointer untuk menunjuk ke tiap node, mulai dari node pertama\n        # (akan dilakukan traversal)\n        current = self.head\n\n        # Untuk menghitung node ke-sekian untuk nama node di Graphviz,\n        # sehingga head menunjuk ke node0, lalu node0 menunjuk ke node1, dst\n        counter = 0\n\n        # Memperoleh alamat yang sedang disimpan di head\n        # - asumsi awal: tidak ada alamat (None)\n        next_id = None\n        next_name = \"node0\" # ini nanti untuk nama node berikutnya di Graphviz\n        # - kalau ternyata ada alamat...\n        if current != None:\n            # maka simpan alamat tersebut\n            next_id = hex(id(current))\n            # kita buat lebih spesifik untuk node berikutnya, tunjuk ke port id\n            next_name = \"node0:id\"\n        \n        # Label (tabel) untuk pointer head\n        # - pembuka tabel\n        str_label = \"&lt;\"\n        str_label += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n        # - baris head\n        str_label += \"&lt;TR&gt;&lt;TD&gt;head&lt;/TD&gt;&lt;/TR&gt;\"\n        # - baris alamat (sekalian membuat port namanya \"contents\")\n        str_label += \"&lt;TR&gt;&lt;TD PORT=\\\"contents\\\"&gt;\" + str(next_id) + \"&lt;/TD&gt;&lt;/TR&gt;\"\n        # - penutup tabel\n        str_label += \"&lt;/TABLE&gt;\"\n        str_label += \"&gt;\"\n\n        # Membuat node head, membuat edge dari head ke node berikutnya\n        new_digraph.node(\"head\", shape=\"none\", label=str_label)\n        new_digraph.edge(\"head:contents\", next_name)\n        # dari port \"contents\" ke node berikutnya, yang namanya next_name\n        \n        # Selama node yang ditunjuk bukan None, buatlah node nya di Graphviz,\n        # lalu lanjut ke node selanjutnya (ini traversal)\n        while current != None:\n            # Alamat yang tersimpan pada current.next\n            # - asumsi awal: tidak ada alamat; current adalah node terakhir\n            next_id = None\n            # - kalau ternyata ada alamat...\n            if current.next != None:\n                # maka simpan alamat tersebut\n                next_id = hex(id(current.next))\n\n            # serupa untuk prev\n            prev_id = None\n            if current.prev != None:\n                prev_id = hex(id(current.prev))\n            \n            # Persiapan label (tabel) untuk node\n            # - pembuka tabel\n            str_label = \"&lt;\"\n            str_label += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n            # - baris tulisan \"prev\", \"data\", \"next\"\n            str_label += \"&lt;TR&gt;&lt;TD&gt;prev&lt;/TD&gt;&lt;TD&gt;data&lt;/TD&gt;&lt;TD&gt;next&lt;/TD&gt;&lt;/TR&gt;\"\n            # - baris untuk isi prev, isi data, dan isi next\n            str_label += \"&lt;TR&gt;\"\n            str_label += \"&lt;TD PORT=\\\"prev\\\"&gt;\" + str(prev_id) + \"&lt;/TD&gt;\"\n            str_label += \"&lt;TD&gt;\" + str(current.data) + \"&lt;/TD&gt;\"\n            str_label += \"&lt;TD PORT=\\\"next\\\"&gt;\" + str(next_id) + \"&lt;/TD&gt;\"\n            str_label += \"&lt;/TR&gt;\"\n            # - baris tulisan \"alamat node\", merentang dua kolom\n            str_label += \"&lt;TR&gt;&lt;TD COLSPAN=\\\"3\\\"&gt;alamat node&lt;/TD&gt;&lt;/TR&gt;\"\n            # - baris untuk isi alamat node, merentang dua kolom\n            str_label += \"&lt;TR&gt;\"\n            str_label += \"&lt;TD PORT=\\\"id\\\" COLSPAN=\\\"3\\\"&gt;\"\n            str_label += str(hex(id(current)))\n            str_label += \"&lt;/TD&gt;\"\n            str_label += \"&lt;/TR&gt;\"\n            # - penutup tabel\n            str_label += \"&lt;/TABLE&gt;\"\n            str_label += \"&gt;\"\n\n            # Membuat node baru di Graphviz dengan label (tabel) tersebut\n            new_digraph.node(\"node\" + str(counter), shape=\"none\", label = str_label)\n\n            # Menentukan nama dua port yang bakal disambung dengan edge,\n            # yaitu (node saat ini):next disambung ke node(berikutnya):id\n            # yaitu bagian \"next\" disambung ke bagian alamat di node berikutnya\n            nama_node_next = \"node\" + str(counter) + \":next\"\n\n            # tambahan untuk doubly linked list\n            nama_node_prev = \"node\" + str(counter) + \":prev\"\n\n            if current.next != None:\n                nama_alamat_node_berikutnya = \"node\" + str(counter+1) + \":id\"\n            # atau ke node(berikutnya) saja tanpa id kalau itu ternyata None,\n            # karena None tidak akan memiliki port id\n            else:\n                nama_alamat_node_berikutnya = \"node\" + str(counter+1)\n            \n            # Menyambung keduanya\n            new_digraph.edge(nama_node_next, nama_alamat_node_berikutnya)\n\n            # tambahan untuk doubly linked list\n            if current.prev != None:\n                nama_alamat_node_sebelumnya = \"node\" + str(counter-1) + \":id\"\n            else:\n                nama_alamat_node_sebelumnya = \"node\" + str(counter-1)\n            if current == self.head:\n                new_digraph.node(\"node-1\", shape=\"none\", label=\"None\")\n            new_digraph.edge(nama_node_prev, nama_alamat_node_sebelumnya)\n            \n            # Lanjut ke node selanjutnya\n            current = current.next\n            counter += 1\n        # Kalau sudah keluar loop, artinya current menunjuk ke None\n        # Berarti tinggal membuat \"node\" terakhir berisi tulisan None\n        # (karena sambungannya sudah dibuat di dalam loop, tinggal node nya)\n        new_digraph.node(\"node\" + str(counter), shape=\"none\", label=\"None\")\n\n        # Tambah pointer tail\n        # - asumsi awal: tidak ada alamat (None)\n        tail_id = None\n        tail_name = \"node\" + str(counter-1) # ini nanti untuk nama node tail\n        # - kalau ternyata ada alamat...\n        if self.tail != None:\n            # maka simpan alamat tersebut\n            tail_id = hex(id(self.tail))\n            # kita buat lebih spesifik untuk node berikutnya, tunjuk ke port id\n            tail_name += \":id\"\n        \n        # Label (tabel) untuk pointer tail\n        # - pembuka tabel\n        str_label = \"&lt;\"\n        str_label += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n        # - baris head\n        str_label += \"&lt;TR&gt;&lt;TD&gt;tail&lt;/TD&gt;&lt;/TR&gt;\"\n        # - baris alamat (sekalian membuat port namanya \"contents\")\n        str_label += \"&lt;TR&gt;&lt;TD PORT=\\\"contents\\\"&gt;\" + str(tail_id) + \"&lt;/TD&gt;&lt;/TR&gt;\"\n        # - penutup tabel\n        str_label += \"&lt;/TABLE&gt;\"\n        str_label += \"&gt;\"\n\n        # Membuat node tail, membuat edge dari tail ke node nya\n        new_digraph.node(\"tail\", shape=\"none\", label=str_label)\n        new_digraph.edge(\"tail:contents\", tail_name)\n        # dari port \"contents\" ke node yang ditunjuk tail, namanya tail_name\n\n        # Digraph sudah jadi\n        return new_digraph\n\n\ntestDL = DLList()\ntestDL.ins_front(5)\ntestDL.ins_front(15)\ntestDL.ins_front(25)\ntestDL.ins_front(35)\n\n\ntestDL.print_all()\n\nhead -&gt; 35 &lt;-&gt; 25 &lt;-&gt; 15 &lt;-&gt; 5 &lt;- tail\n\n\n\ngambarDL = testDL.get_digraph()\n\n\ndisplay(gambarDL)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul05.html#graphviz",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul05.html#graphviz",
    "title": "Modul 5 Struktur Data: Graphviz, Linked List",
    "section": "",
    "text": "Graphviz adalah semacam software yang bisa membuat visualisasi “graf” yang bagus. Mungkin di antara kalian belum semuanya kenal dengan graf, itu tidak masalah. Kurang lebih, suatu graf adalah kumpulan bulet-bulet (disebut simpul, node, atau vertex) yang disambung oleh “busur” (juga disebut arc atau edge), di mana tiap edge bisa berupa garis biasa atau berupa panah.\nBerikut contoh graf yang digambar dengan Graphviz:\n\n\n\n\n\n\n\ngraf G\n\n\n\nA\n\nA\n\n\n\nB\n\nB\n\n\n\nA-&gt;B\n\n\n\n\n\nC\n\nC\n\n\n\nA-&gt;C\n\n\n\n\n\nB-&gt;A\n\n\n\n\n\nF\n\nF\n\n\n\nB-&gt;F\n\n\n\n\nE\n\nE\n\n\n\nC-&gt;E\n\n\n\n\n\n\nD\n\nD\n\n\n\nD-&gt;C\n\n\n\n\nD-&gt;D\n\n\n\n\n\nD-&gt;E\n\n\n  tes\n\n\n\nE-&gt;F\n\n\n\n\n\nGHI\n\nGHI\n\n\n\nGHI-&gt;F\n\n\nqwerty\n\n\n\n\n\n\n\n\nLho, di mata kuliah Struktur Data kan ga ada graf. Untuk apa kita pelajari Graphviz?\nDengan Graphviz, kita bisa membuat visualisasi untuk berbagai struktur data nantinya, termasuk linked list hari ini. Kita bisa meminta Graphviz untuk membuat bentuk node yang tidak sederhana, termasuk bentuk node yang kita kenal di linked list, kemudian membuat edge yang berupa panah, sehingga kita benar-benar bisa menggambarkan suatu linked list :)\n\n\nSebelum bisa menggunakan Graphviz, perlu di-install terlebih dahulu.\nDi Google Colaboratory, kalian tinggal mengetik:\npip install graphviz\nSedangkan, apabila menggunakan Jupyter Notebook melalui Anaconda, buka Anaconda Prompt lalu ketik:\nconda install graphviz\nTunggu instalasi selesai, barulah buka Jupyter Notebook dan ketik\npip install graphviz\nNote:\n\nApabila Anda menggunakan Jupyter Notebook tetapi tidak melalui Anaconda, langkah conda install graphviz bisa digantikan dengan menginstal Graphviz dari https://graphviz.gitlab.io/download/\nUntuk penulisan pip, ada kemungkinan kalian perlu mengetik !pip dengan tanda seru di awal. Biasanya tidak perlu, tapi kalau menjadi error, boleh dicoba dengan tanda seru.\n\n\n\n\nSetelah instalasi selesai, kita bisa import:\n\nimport graphviz as gv\n\nDengan Graphviz, ada dua jenis gambar graf yang bisa kita buat:\n\nDigraph (graf berarah, yaitu tiap edge bisa berupa panah maupun garis biasa)\nGraph (graf sederhana, yaitu tiap edge hanya bisa berupa garis biasa, bukan panah)\n\nKarena Digraph lebih banyak fiturnya, kita akan membuat Digraph saja.\nSebagai contoh sederhana, kita bisa membuat Digraph yang terdiri dari dua node yaitu A dan B, dengan edge berupa panah yang menghubungkan A ke B. Kita buat objek Digraph terlebih dahulu:\n\ngraf1 = gv.Digraph()\n\nKemudian, kita bisa menambahkan node A dan B sebagai berikut:\n\ngraf1.node(\"A\")\ngraf1.node(\"B\")\n\nSelanjutnya, kita bisa membuat/menambahkan suatu edge dari A ke B, seperti berikut:\n\ngraf1.edge(\"A\", \"B\")\n\nSekarang kita bisa lihat grafnya:\n\ndisplay(graf1)\n\n\n\n\n\n\n\n\nNote: apabila fungsi display tidak dikenal, silakan import:\nfrom IPython.display import display\nSebenarnya, kita bisa saja menambahkan edge baru tanpa membuat node terlebih dahulu. Contohnya, menambahkan edge dari A ke C (suatu node baru):\n\ngraf1.edge(\"A\", \"C\")\n\nKita bisa lihat lagi:\n\ndisplay(graf1)\n\n\n\n\n\n\n\n\nBahkan, kita bisa membuat ulang graf di atas dengan cara seperti berikut:\n\ngraf2 = gv.Digraph()\ngraf2.edge(\"A\", \"B\")\ngraf2.edge(\"A\", \"C\")\n\n\ndisplay(graf2)\n\n\n\n\n\n\n\n\nMenariknya, kita bisa saja membuat panah yang menunjuk ke dirinya sendiri.\n\ngraf3 = gv.Digraph()\ngraf3.edge(\"A\", \"B\")\ngraf3.edge(\"B\", \"B\")\n\n\ndisplay(graf3)\n\n\n\n\n\n\n\n\nKita juga bisa membuat dua panah berlawanan arah di antara dua node seperti berikut:\n\ngraf4 = gv.Digraph()\ngraf4.edge(\"A\", \"B\")\ngraf4.edge(\"B\", \"A\")\n\n\ndisplay(graf4)\n\n\n\n\n\n\n\n\nMembuat satu panah yang dua arah juga bisa, dengan menentukan dir atau direction dari edge tersebut menjadi \"both\" seperti berikut:\n\ngraf5 = gv.Digraph()\ngraf5.edge(\"A\", \"B\", dir=\"both\")\n\n\ndisplay(graf5)\n\n\n\n\n\n\n\n\nDaripada panah, kita juga bisa membuat edge berupa garis biasa, dengan dir=\"none\" (bukan None ya!)\n\ngraf6 = gv.Digraph()\ngraf6.edge(\"A\", \"B\", dir=\"none\")\n\n\ndisplay(graf6)\n\n\n\n\n\n\n\n\nSejauh ini, grafnya selalu cenderung “dari atas ke bawah”. Daripada seperti itu, kita bisa mengubahnya menjadi kiri ke kanan untuk keseluruhan graf. Caranya, kita memasang graph_attr atau atribut graf, berbentuk dict, dan di dalamnya kita buat \"rankdir\": \"LR\" (left-right) seperti di bawah ini.\nSetelah objek Digraph dibuat, barulah tiap edge yang kita tambahkan akan dari kiri ke kanan.\n\ngraf7 = gv.Digraph(graph_attr={\"rankdir\": \"LR\"})\ngraf7.edge(\"A\", \"B\")\n\n\ndisplay(graf7)\n\n\n\n\n\n\n\n\nSelain node diberi nama, edge juga bisa diberi keterangan, lho! Caranya, pasang nilai label ketika membuat edge baru:\n\ngraf8 = gv.Digraph(graph_attr={\"rankdir\": \"LR\"})\ngraf8.edge(\"A\", \"B\", label=\"test\")\n\n\ndisplay(graf8)\n\n\n\n\n\n\n\n\nSebenarnya, di dalam suatu node, ada yang namanya name (atau ID) dan ada juga yang disebut label.\n\nlabel adalah tulisan yang tampil di gambar pada node tersebut\nname atau ID adalah sebutan yang dikenal oleh Graphviz ketika misalnya ingin membuat edge\n\nSelama ini, yang kita tentukan adalah name. Kebetulan, khusus node, apabila label tidak ditentukan, maka otomatis akan diambil dari name.\nBerikut ini, kita bisa coba menentukan name dan label sekaligus ketika membuat node:\n\ngraf9 = gv.Digraph()\ngraf9.node(\"matkul1\", label=\"Alprog\")\ngraf9.node(\"matkul2\", label=\"Strukdat\")\ngraf9.edge(\"matkul1\", \"matkul2\")\n\n\ndisplay(graf9)\n\n\n\n\n\n\n\n\nPerlu dicatat, apabila kita menambahkan edge sekaligus membuat node baru, kita tidak bisa memasang label untuk node baru tersebut.\nSehingga, apabila kalian ingin membuat node dengan label tertentu, yang nantinya akan disambung ke node lain dengan edge, maka sebaiknya node baru tersebut dibuat dengan .node() terlebih dahulu, barulah name nya digunakan ketika membuat .edge()\nSelain itu, bahkan graf itu sendiri juga bisa memiliki nama, yang ditentukan ketika membuat objek grafnya.\n\ngraf10 = gv.Digraph(\"Nama graf\")\ngraf10.edge(\"A\", \"B\")\ngraf10.edge(\"B\", \"C\")\n\n\ndisplay(graf10)\n\n\n\n\n\n\n\n\nCoba letakkan mouse kalian pada gambarnya selama beberapa detik. Akan muncul tulisan “Nama graf”. (Kalau tidak muncul, coba klik kanan dulu, pencet “Open image in New Tab” atau semacamnya.)\nApabila kalian ingin menentukan misalnya rankdir, tuliskan setelah nama grafnya.\n\ngraf11 = gv.Digraph(\"Graf ke kanan\", graph_attr={\"rankdir\": \"LR\"})\ngraf11.edge(\"A\", \"B\")\ngraf11.edge(\"B\", \"C\")\n\n\ndisplay(graf11)\n\n\n\n\n\n\n\n\n\n\n\nSebenarnya, Graphviz melibatkan yang namanya bahasa DOT (dibaca “dot”), yaitu semacam “bahasa komputer” untuk mendeskripsikan graf, yang kemudian diolah oleh Graphviz menjadi gambar.\n(Sebenarnya, bahasa DOT mudah dipahami dan bisa kalian pelajari sendiri kalo iseng :D)\nTiap kali kita membuat graf baru dengan Graphviz melalui Python ini, Graphviz selalu menyusun bahasa DOT terlebih dahulu, baru mengolah bahasa DOT tersebut menjadi gambar.\nKita bisa melihat bahasa DOT untuk tiap graf melalui atribut .source seperti berikut:\n\nprint(graf11.source)\n\ndigraph \"Graf ke kanan\" {\n    graph [rankdir=LR]\n    A -&gt; B\n    B -&gt; C\n}\n\n\n\nKemudian, kita bisa memasukkan bahasa DOT tersebut ke dalam semacam software yang bisa mengolah bahasa DOT menjadi gambar. Contohnya adalah link berikut:\nhttps://dreampuf.github.io/GraphvizOnline/\nSebaliknya, dari bahasa DOT, Graphviz juga bisa membuat objek Digraph misalnya, menggunakan graphviz.Source() seperti berikut:\n\ngraf12 = gv.Source(\"\"\"\ndigraph \"Graf ke kanan\" {\n    graph [rankdir=LR]\n    A -&gt; B\n    B -&gt; C\n}\n\"\"\")\n\n\ndisplay(graf12)\n\n\n\n\n\n\n\n\nSelain import seperti itu, baik bahasa DOT maupun gambar yang dibuat oleh Graphviz bisa di-export dengan menetapkan .format terlebih dahulu (misalnya “svg” atau “png”), lalu menggunakan .render() sebagai berikut:\n\ngraf11.format = \"svg\"\ngraf11.render()\n\n'Graf ke kanan.gv.svg'\n\n\nSeperti di Modul 3 kemarin ketika membahas I/O, ada file baru yang muncul.\n\nApabila menggunakan Google Colaboratory, silakan tekan tombol folder di sebelah kiri.\nApabila menggunakan Jupyter Notebook, silakan periksa folder yang di dalamnya ada file .ipynb yang sedang kalian gunakan.\n\nAkan muncul dua file baru, yaitu:\n\nGraf ke kanan.gv\nGraf ke kanan.gv.svg\n\nFile pertama adalah file .gv (Graphviz) yang mengandung bahasa DOT yang disusun sebelum diolah menjadi gambar. File kedua adalah file gambar yang diolah, dalam format sesuai dengan yang kita tentukan.\nKita bisa membaca isi Graf ke kanan.gv sebagaimana kita membaca isi text file:\n\nwith open(\"Graf ke kanan.gv\", \"r\") as isi:\n    print(isi.read())\n\ndigraph \"Graf ke kanan\" {\n    graph [rankdir=LR]\n    A -&gt; B\n    B -&gt; C\n}\n\n\n\nSelain itu, perhatikan bahwa nama file nya sesuai dengan nama graf yang kita tentukan ketika membuat objek graf11 tadi. Kalau lupa, kita bisa memeriksa nama graf melalui atribut .nama\n\nprint(graf11.name)\n\nGraf ke kanan\n\n\nDengan atribut itu pula, kita bisa mengubah nama grafnya:\n\ngraf11.name = \"Nama baru\"\n\nSehingga, ketika misalnya Graphviz menyusun bahasa DOT, akan digunakan nama yang baru:\n\nprint(graf11.source)\n\ndigraph \"Nama baru\" {\n    graph [rankdir=LR]\n    A -&gt; B\n    B -&gt; C\n}\n\n\n\n\n\n\nIngat atribut label yang bisa dipasang ketika membuat suatu node? Sebenarnya, kita bisa memanfaatkan atribut tersebut untuk membuat bentuk node sesuka hati kita, lho! Terutama, kita bisa membuat node dengan bentuk seperti tabel.\nPenulisan label seperti tabel ini mirip seperti struktur bahasa HTML, sehingga disebut HTML-like labels.\nPerhatikan syntax (penulisan) berikut.\n\ngraf13 = gv.Digraph()\ngraf13.node(\"A\", shape=\"none\", label=\"\"\"&lt;\n&lt;TABLE&gt;\n    &lt;TR&gt;\n        &lt;TD&gt;P&lt;/TD&gt;\n        &lt;TD&gt;Q&lt;/TD&gt;\n    &lt;/TR&gt;\n    &lt;TR&gt;\n        &lt;TD&gt;R&lt;/TD&gt;\n        &lt;TD&gt;S&lt;/TD&gt;\n    &lt;/TR&gt;\n&lt;/TABLE&gt;\n&gt;\"\"\")\n\ngraf13.node(\"B\") # node biasa\ngraf13.edge(\"A\", \"B\")\n\n\ndisplay(graf13)\n\n\n\n\n\n\n\n\nPerhatikan,\n\nKetika membuat node yang ingin berbentuk tabel, ditambahkan atribut shape=\"none\" (bukan None) di samping menulis label nya.\nlabel berupa long string, sehingga diawali dan diakhiri dengan tiga tanda kutip.\nKarakter pertama dari long string tersebut haruslah &lt; dan karakter terakhir haruslah &gt;\nKemudian, penulisan tabel diawali dengan penulisan &lt;TABLE&gt;, kemudian &lt;TR&gt; (table row) untuk tiap baris, lalu &lt;TD&gt; (table data) untuk tiap sel. Masing-masing selalu ditutup dengan &lt;/TD&gt;, &lt;/TR&gt;, dan &lt;/TABLE&gt;, bagaikan keberadaan endif, endfor, endwhile dan sebagainya di pseudocode.\n\nAgar lebih bagus, di bagian &lt;TABLE&gt; kita bisa menambahkan:\nBORDER=\"0\" CELLBORDER=\"1\" CELLSPACING=\"0\"\nSeperti berikut:\n\ngraf14 = gv.Digraph()\ngraf14.node(\"A\", shape=\"none\", label=\"\"\"&lt;\n&lt;TABLE BORDER=\"0\" CELLBORDER=\"1\" CELLSPACING=\"0\"&gt;\n    &lt;TR&gt;\n        &lt;TD&gt;P&lt;/TD&gt;\n        &lt;TD&gt;Q&lt;/TD&gt;\n    &lt;/TR&gt;\n    &lt;TR&gt;\n        &lt;TD&gt;R&lt;/TD&gt;\n        &lt;TD&gt;S&lt;/TD&gt;\n    &lt;/TR&gt;\n&lt;/TABLE&gt;\n&gt;\"\"\")\n\ngraf14.node(\"B\")\ngraf14.edge(\"A\", \"B\")\n\n\ndisplay(graf14)\n\n\n\n\n\n\n\n\nBagaimana kalau misalnya kita ingin panahnya seperti “berasal” dari sel tertentu? Caranya, kita bisa membuat yang namanya port, misalnya di sel R, kemudian edge yang dibuat akan kita sambung dari port tersebut, seperti berikut:\n\ngraf15 = gv.Digraph()\ngraf15.node(\"A\", shape=\"none\", label=\"\"\"&lt;\n&lt;TABLE BORDER=\"0\" CELLBORDER=\"1\" CELLSPACING=\"0\"&gt;\n    &lt;TR&gt;\n        &lt;TD&gt;P&lt;/TD&gt;\n        &lt;TD&gt;Q&lt;/TD&gt;\n    &lt;/TR&gt;\n    &lt;TR&gt;\n        &lt;TD PORT=\"port1\"&gt;R&lt;/TD&gt;\n        &lt;TD&gt;S&lt;/TD&gt;\n    &lt;/TR&gt;\n&lt;/TABLE&gt;\n&gt;\"\"\")\n\ngraf15.node(\"B\")\ngraf15.edge(\"A:port1\", \"B\")\n\n\ndisplay(graf15)\n\n\n\n\n\n\n\n\nKalau di Microsoft Excel atau Google Sheets, kita bisa melakukan merge beberapa sel, entah secara horizontal atau vertikal atau bahkan dua-duanya. Ketika menyusun HTML-like labels, kita bisa menggunakan COLSPAN (merentang beberapa kolom) dan ROWSPAN (merentang beberapa baris) untuk membuat efek seperti di-merge.\n\ngraf16 = gv.Digraph()\ngraf16.node(\"A\", shape=\"none\", label=\"\"\"&lt;\n&lt;TABLE BORDER=\"0\" CELLBORDER=\"1\" CELLSPACING=\"0\"&gt;\n    &lt;TR&gt;\n        &lt;TD ROWSPAN=\"2\"&gt;P&lt;/TD&gt;\n        &lt;TD COLSPAN=\"2\"&gt;Q&lt;/TD&gt;\n    &lt;/TR&gt;\n    &lt;TR&gt;\n        &lt;TD&gt;R&lt;/TD&gt;\n        &lt;TD&gt;S&lt;/TD&gt;\n    &lt;/TR&gt;\n&lt;/TABLE&gt;\n&gt;\"\"\")\n\ngraf16.node(\"B\")\ngraf16.edge(\"A\", \"B\")\n\n\ndisplay(graf16)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul05.html#singly-linked-list",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul05.html#singly-linked-list",
    "title": "Modul 5 Struktur Data: Graphviz, Linked List",
    "section": "",
    "text": "Singly-linked list (seringkali disebut linked list saja) adalah semacam “rantai” dari node, di mana tiap node berisi 2 nilai, yaitu data dan next (yaitu pointer ke node lain). Node yang paling pertama itu ditunjuk oleh suatu pointer bernama head, yang menjadi awal dari linked list.\n(Terkadang, pointer next ditulis LINK. Artinya dan kegunaannya sama.)\nPertama-tama, kita buat struktur node terlebih dahulu menggunakan class. (Apabila pointer next tidak menunjuk ke apapun, biasanya ditulis NULL atau di sini None.)\nBiasanya, di kuliah, disebutnya class Node atau Node saja. Namun, berhubung modul ini akan membahas doubly-linked list dengan struktur yang agak berbeda, maka node untuk singly-linked list akan kita sebut SLNode (singly-linked node) agar berbeda.\n\nclass SLNode:\n    def __init__(self, data, next=None):\n        self.data = data\n        self.next = next\n\nKita bisa bermain-main dengan node ini sebagaimana yang dibahas di kuliah. Misalnya, kita buat node baru yang menyimpan data 15:\n\np = SLNode(15)\n\nSaat ini, node tersebut ditunjuk oleh pointer yang di sini kita sebut p. Secara tidak langsung, kita telah membuat linked list dengan head nya adalah p.\nKita bisa mengakses data yang disimpan di data dan juga alamat yang tersimpan di next:\n\nprint(p.data)\n\n15\n\n\n\nprint(p.next)\n\nNone\n\n\nSaat ini, node yang ditunjuk oleh p itu belum menunjuk ke manapun, sehingga p.next masih bernilai None.\nKita bisa melihat alamat dari node itu sendiri menggunakan id:\n\nprint(id(p))\n\n4404463888\n\n\nAlamat ini akan selalu berbeda tiap kali kita membuat node baru, dan di antara dua komputer kemungkinan besar juga berbeda. Memang wajar apabila alamat yang kalian dapatkan itu berbeda dengan yang tertera di modul.\nNamun, alamat biasanya ditampilkan dalam bentuk heksadesimal (base-16), sedangkan yang kita dapatkan dengan id masih berupa bilangan bulat desimal (base-10). Kita bisa menggunakan hex untuk mengubah base-10 menjadi base-16:\n\nprint(hex(id(p)))\n\n0x10686c910\n\n\nAwalan 0x itu hanya penanda bahwa bilangannya berupa heksadesimal.\nSelanjutnya, kita bisa membuat node baru di p.next, yaitu yang ditunjuk oleh p, sebagai berikut:\n\np.next = SLNode(28)\n\nSehingga, data 28 itu bisa diakses dari p seperti berikut:\n\nprint(p.next.data)\n\n28\n\n\nSedangkan, setelah node berisi 15 dan node berisi 28, belum ada node lagi, sehingga:\n\nprint(p.next.next)\n\nNone\n\n\nMari kita buat node baru lagi setelah node berisi 28:\n\np.next.next = SLNode(-3)\n\nSehingga, kita bisa mengakses data masing-masing node dari p:\n\nprint(p.data)\nprint(p.next.data)\nprint(p.next.next.data)\n\n15\n28\n-3\n\n\nKita bisa juga membuat pointer baru yang menunjuk ke node yang sudah ada. Misalnya, kita bisa membuat pointer bernama q yang menunjuk ke node yang berisi 28, seperti berikut:\n\nq = p.next\n\nSehingga, p.next.next bisa diakses dengan q.next:\n\nprint(p.next.next.data)\nprint(q.next.data)\n\n-3\n-3\n\n\nBahkan, kita bisa mengubah data -3 menjadi yang lain melalui q, dan itu akan berubah juga jika diakses melalui p:\n\nq.next.data = -63\nprint(q.next.data)\nprint(p.next.next.data)\n\n-63\n-63\n\n\nKok bisa? Karena, sesuai yang sudah kita tetapkan, q menunjuk ke node yang sama dengan p.next. Kita bisa periksa alamatnya:\n\nprint(hex(id(q)))\nprint(hex(id(p.next)))\n\n0x10686d780\n0x10686d780\n\n\nSehingga alamat dari node yang ditunjuk oleh q.next akan sama dengan yang ditunjuk oleh p.next.next:\n\nprint(hex(id(q.next)))\nprint(hex(id(p.next.next)))\n\n0x10686d000\n0x10686d000\n\n\nSejauh ini, kita sudah bermain dengan node dan membuat linked list secara manual. Sebenarnya, kita juga bisa membuat suatu class untuk suatu linked list secara keseluruhan. Di dalam class itu, kita bisa membuat atribut (variabel) yang menyimpan head, serta berbagai method (fungsi) untuk algoritma-algoritma operasi dasar yang kita pelajari di kuliah, seperti insert node di awal/akhir dan delete node di awal/akhir. Dengan begitu, kita bisa menggunakan linked list dengan lebih nyaman.\nKita akan menyebutnya class SLList (singly-linked list).\n\nclass SLList:\n    def __init__(self):\n        self.head = None\n\n    def is_empty(self):\n        if self.head == None:\n            return True\n        else:\n            return False\n\n    # Traversal, hanya untuk menghitung banyaknya node di linked list\n    def get_size(self):\n        count = 0\n        current = self.head\n        while current != None:\n            count += 1\n            current = current.next\n        return count\n\n    # Traversal, print masing-masing data node dari awal sampai akhir\n    def print_all(self):\n        print(\"head -&gt; \", end=\"\")\n        temp = self.head\n        while temp != None:\n            print(temp.data, end = \" -&gt; \")\n            temp = temp.next\n        print(\"None\")\n    \n    # Traversal, semacam linear search, cari letak node dengan data tertentu\n    def get_pos(self, x):\n        pos = -1\n        current = self.head\n        while current != None:\n            pos += 1\n            if current.data == x:\n                return pos\n            current = current.next\n        return -1\n    \n    def ins_front(self, newdata):\n        newnode = SLNode(newdata)\n        newnode.next = self.head\n        self.head = newnode\n    \n    def ins_end(self, newdata):\n        newnode = SLNode(newdata)\n        if self.is_empty():\n            self.head = newnode\n        else:\n            temp = self.head\n            while temp.next != None:\n                temp = temp.next\n            \n            # sekarang temp sudah di node terakhir\n            temp.next = newnode\n    \n    def ins_pos(self, newdata, pos):\n        if pos == 0:\n            self.ins_front(newdata)\n        else:\n            current_pos = 0\n            current = self.head\n            while (current != None) and (current_pos != pos-1):\n                current = current.next\n                current_pos += 1\n            # Keluar loop, bisa karena current == None atau current_pos == pos-1\n            # Kalau karena current_pos == pos-1, bisa insert\n            if (current_pos == pos-1):\n                newnode = SLNode(newdata)\n                temp = current.next\n                current.next = newnode\n                newnode.next = temp\n            # Tapi kalau karena current == None,\n            # berarti posisi yang diminta melampaui panjang linked list\n            else:\n                print(\"Error: posisi melebihi panjang linked list\")\n    \n    def del_front(self):\n        if self.is_empty():\n            print(\"Error: linked list sudah kosong\")\n        else:\n            temp = self.head.next\n            del self.head\n            self.head = temp\n    \n    def del_end(self):\n        if self.is_empty():\n            print(\"Error: linked list sudah kosong\")\n        else:\n            temp = self.head\n            while temp.next.next != None:\n                temp = temp.next\n            \n            # sekarang temp ada di node sebelum terakhir\n            del temp.next\n            temp.next = None\n    \n    # Mirip ins_pos, hanya berbeda di bagian current_pos == pos-1\n    def del_pos(self, pos):\n        if pos == 0:\n            self.del_front()\n        else:\n            current_pos = 0\n            current = self.head\n            while (current != None) and (current_pos != pos-1):\n                current = current.next\n                current_pos += 1\n            # Keluar loop, bisa karena current == None atau current_pos == pos-1\n            # Kalau karena current_pos == pos-1, maka bisa dihapus selama \n            # current.next yang mau dihapus itu memang ada\n            if (current_pos == pos-1) and (current.next != None):\n                temp = current.next.next\n                del current.next\n                current.next = temp\n            # Tapi kalau karena current == None, atau current.next tidak ada,\n            # berarti posisi yang diminta melampaui panjang linked list\n            else:\n                print(\"Error: posisi melebihi panjang linked list\")\n\n    # Menghapus semua node di linked list\n    def del_all(self):\n        while (not self.is_empty()):\n            self.del_front()\n\n    # Method untuk memperoleh digraph yang menggambarkan linked list nya :D\n    def get_digraph(self):\n        # Buat digraph baru yang sifatnya dari kiri ke kanan\n        new_digraph = gv.Digraph(graph_attr={\"rankdir\": \"LR\"})\n        \n        # Pointer untuk menunjuk ke tiap node, mulai dari node pertama\n        # (akan dilakukan traversal)\n        current = self.head\n\n        # Untuk menghitung node ke-sekian untuk nama node di Graphviz,\n        # sehingga head menunjuk ke node0, lalu node0 menunjuk ke node1, dst\n        counter = 0\n\n        # Memperoleh alamat yang sedang disimpan di head\n        # - asumsi awal: tidak ada alamat (None)\n        next_id = None\n        next_name = \"node0\" # ini nanti untuk nama node berikutnya di Graphviz\n        # - kalau ternyata ada alamat...\n        if current != None:\n            # maka simpan alamat tersebut\n            next_id = hex(id(current))\n            # kita buat lebih spesifik untuk node berikutnya, tunjuk ke port id\n            next_name = \"node0:id\"\n        \n        # Label (tabel) untuk pointer head\n        # - pembuka tabel\n        str_label = \"&lt;\"\n        str_label += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n        # - baris head\n        str_label += \"&lt;TR&gt;&lt;TD&gt;head&lt;/TD&gt;&lt;/TR&gt;\"\n        # - baris alamat (sekalian membuat port namanya \"contents\")\n        str_label += \"&lt;TR&gt;&lt;TD PORT=\\\"contents\\\"&gt;\" + str(next_id) + \"&lt;/TD&gt;&lt;/TR&gt;\"\n        # - penutup tabel\n        str_label += \"&lt;/TABLE&gt;\"\n        str_label += \"&gt;\"\n\n        # Membuat node head, membuat edge dari head ke node berikutnya\n        new_digraph.node(\"head\", shape=\"none\", label=str_label)\n        new_digraph.edge(\"head:contents\", next_name)\n        # dari port \"contents\" ke node berikutnya, yang namanya next_name\n        \n        # Selama node yang ditunjuk bukan None, buatlah node nya di Graphviz,\n        # lalu lanjut ke node selanjutnya (ini traversal)\n        while current != None:\n            # Alamat yang tersimpan pada current.next\n            # - asumsi awal: tidak ada alamat; current adalah node terakhir\n            next_id = None\n            # - kalau ternyata ada alamat...\n            if current.next != None:\n                # maka simpan alamat tersebut\n                next_id = hex(id(current.next))\n            \n            # Persiapan label (tabel) untuk node\n            # - pembuka tabel\n            str_label = \"&lt;\"\n            str_label += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n            # - baris tulisan \"data\", \"next\"\n            str_label += \"&lt;TR&gt;&lt;TD&gt;data&lt;/TD&gt;&lt;TD&gt;next&lt;/TD&gt;&lt;/TR&gt;\"\n            # - baris untuk isi data dan isi next\n            str_label += \"&lt;TR&gt;\"\n            str_label += \"&lt;TD&gt;\" + str(current.data) + \"&lt;/TD&gt;\"\n            str_label += \"&lt;TD PORT=\\\"next\\\"&gt;\" + str(next_id) + \"&lt;/TD&gt;\"\n            str_label += \"&lt;/TR&gt;\"\n            # - baris tulisan \"alamat node\", merentang dua kolom\n            str_label += \"&lt;TR&gt;&lt;TD COLSPAN=\\\"2\\\"&gt;alamat node&lt;/TD&gt;&lt;/TR&gt;\"\n            # - baris untuk isi alamat node, merentang dua kolom\n            str_label += \"&lt;TR&gt;\"\n            str_label += \"&lt;TD PORT=\\\"id\\\" COLSPAN=\\\"2\\\"&gt;\"\n            str_label += str(hex(id(current)))\n            str_label += \"&lt;/TD&gt;\"\n            str_label += \"&lt;/TR&gt;\"\n            # - penutup tabel\n            str_label += \"&lt;/TABLE&gt;\"\n            str_label += \"&gt;\"\n\n            # Membuat node baru di Graphviz dengan label (tabel) tersebut\n            new_digraph.node(\"node\" + str(counter), shape=\"none\", label = str_label)\n\n            # Menentukan nama dua port yang bakal disambung dengan edge,\n            # yaitu (node saat ini):next disambung ke node(berikutnya):id\n            # yaitu bagian \"next\" disambung ke bagian alamat di node berikutnya\n            nama_node_next = \"node\" + str(counter) + \":next\"\n            if current.next != None:\n                nama_alamat_node_berikutnya = \"node\" + str(counter+1) + \":id\"\n            # atau ke node(berikutnya) saja tanpa id kalau itu ternyata None,\n            # karena None tidak akan memiliki port id\n            else:\n                nama_alamat_node_berikutnya = \"node\" + str(counter+1)\n            \n            # Menyambung keduanya\n            new_digraph.edge(nama_node_next, nama_alamat_node_berikutnya)\n            \n            # Lanjut ke node selanjutnya\n            current = current.next\n            counter += 1\n        # Kalau sudah keluar loop, artinya current menunjuk ke None\n        # Berarti tinggal membuat \"node\" terakhir berisi tulisan None\n        # (karena sambungannya sudah dibuat di dalam loop, tinggal node nya)\n        new_digraph.node(\"node\" + str(counter), shape=\"none\", label=\"None\")\n\n        # Digraph sudah jadi\n        return new_digraph\n\n\ntest = SLList()\ntest.ins_front(5)\ntest.ins_front(15)\ntest.ins_front(25)\ntest.ins_front(35)\n\n\ntest.print_all()\n\nhead -&gt; 35 -&gt; 25 -&gt; 15 -&gt; 5 -&gt; None\n\n\n\nprint(test.get_pos(15))\n\n2\n\n\n\nprint(test.get_pos(39))\n\n-1\n\n\n\ntest.ins_end(100)\n\n\ntest.print_all()\n\nhead -&gt; 35 -&gt; 25 -&gt; 15 -&gt; 5 -&gt; 100 -&gt; None\n\n\n\ntest.del_front()\ntest.del_front()\n\n\ntest.print_all()\n\nhead -&gt; 15 -&gt; 5 -&gt; 100 -&gt; None\n\n\n\ntest.del_pos(3)\n\nError: posisi melebihi panjang linked list\n\n\n\ntest.del_pos(2)\n\n\ntest.print_all()\n\nhead -&gt; 15 -&gt; 5 -&gt; None\n\n\n\ntest.ins_pos(-42, 7)\n\nError: posisi melebihi panjang linked list\n\n\n\ntest.ins_pos(76, 1)\n\n\ntest.print_all()\n\nhead -&gt; 15 -&gt; 76 -&gt; 5 -&gt; None\n\n\n\ngambar = test.get_digraph()\n\n\ndisplay(gambar)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul05.html#doubly-linked-list",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul05.html#doubly-linked-list",
    "title": "Modul 5 Struktur Data: Graphviz, Linked List",
    "section": "",
    "text": "class DLNode:\n    def __init__(self, data, next=None, prev=None):\n        self.data = data\n        self.next = next\n        self.prev = prev\n\n\nclass DLList:\n    def __init__(self):\n        self.head = None\n        self.tail = None\n    \n    # Masih sama persis dengan singly linked list\n    def is_empty(self):\n        if self.head == None:\n            return True\n        else:\n            return False\n    \n    # Traversal, hanya untuk menghitung banyaknya node di linked list\n    # Masih sama persis dengan singly linked list\n    def get_size(self):\n        count = 0\n        current = self.head\n        while current != None:\n            count += 1\n            current = current.next\n        return count\n\n    # Traversal, print masing-masing data node dari awal sampai akhir\n    def print_all(self):\n        print(\"head -&gt; \", end=\"\")\n        temp = self.head\n        while (temp != None) and (temp.next != None):\n            print(temp.data, end = \" &lt;-&gt; \")\n            temp = temp.next\n        # Khusus node terakhir:\n        if (temp != None) and (temp.next == None):\n            print(temp.data, end = \" &lt;- \")\n        print(\"tail\")\n    \n    def ins_front(self, newdata):\n        newnode = DLNode(newdata)\n        newnode.next = self.head\n        if self.head != None:\n            self.head.prev = newnode\n        self.head = newnode\n        if self.tail == None: # jika tadinya doubly linked list kosong,\n            # maka newnode menjadi node pertama, ditunjuk oleh head dan tail\n            self.tail = newnode\n\n    # Berbeda dengan singly linked list, tinggal insert di tail;\n    # tidak perlu traversal\n    def ins_end(self, newdata):\n        newnode = DLNode(newdata)\n        newnode.prev = self.tail\n        if self.tail != None:\n            self.tail.next = newnode\n        self.tail = newnode\n        if self.head == None: # jika tadinya doubly linked list kosong,\n            # maka newnode menjadi node pertama, ditunjuk oleh head dan tail\n            self.head = newnode\n    \n    def ins_pos(self, newdata, pos):\n        if pos == 0:\n            self.ins_front(newdata)\n            return\n        n = self.get_size()\n        if pos == n:\n            self.ins_end(newdata)\n        elif pos &gt; n:\n            print(\"Error: posisi melebihi panjang linked list\")\n        else:\n            current_pos = 0\n            current = self.head\n            while (current_pos != pos-1):\n                current = current.next\n                current_pos += 1\n            # Keluar loop berarti current_pos == pos-1\n            newnode = DLNode(newdata)\n            newnode.prev = current\n            newnode.next = current.next\n            current.next = newnode\n            # Sudah pasti newnode.next != None,\n            # karena kasus pos == n sudah ditangani\n            newnode.next.prev = newnode\n    \n    def del_front(self):\n        if self.is_empty():\n            print(\"Error: linked list sudah kosong\")\n        else:\n            temp = self.head.next\n            del self.head\n            self.head = temp\n            if temp != None:\n                temp.prev = None\n            else: # jika temp == None, maka self.head == None,\n                # berarti sekarang doubly linkd list kosong,\n                # sehingga tail juga menunjuk ke None\n                self.tail = None\n    \n    def del_end(self):\n        if self.is_empty():\n            print(\"Error: linked list sudah kosong\")\n        else:\n            temp = self.tail.prev\n            del self.tail\n            self.tail = temp\n            if temp != None:\n                temp.next = None\n            else: # jika temp == None, maka self.tail == None,\n                # berarti sekarang doubly linkd list kosong,\n                # sehingga head juga menunjuk ke None\n                self.head = None\n    \n    def del_pos(self, pos):\n        if pos == 0:\n            self.del_front()\n            return\n        n = self.get_size()\n        if pos == n-1:\n            self.del_end()\n        elif pos &gt; n-1:\n            print(\"Error: posisi melebihi panjang linked list\")\n        else:\n            current_pos = 0\n            current = self.head\n            while (current_pos != pos-1):\n                current = current.next\n                current_pos += 1\n            temp = current.next.next\n            del current.next\n            current.next = temp\n            # Sudah pasti temp != None,\n            # karena kasus pos == (n-1) sudah ditangani\n            temp.prev = current\n    \n    # Method untuk memperoleh digraph yang menggambarkan linked list nya :D\n    def get_digraph(self):\n        # Buat digraph baru yang sifatnya dari kiri ke kanan\n        new_digraph = gv.Digraph(graph_attr={\"rankdir\": \"LR\"})\n        \n        # Pointer untuk menunjuk ke tiap node, mulai dari node pertama\n        # (akan dilakukan traversal)\n        current = self.head\n\n        # Untuk menghitung node ke-sekian untuk nama node di Graphviz,\n        # sehingga head menunjuk ke node0, lalu node0 menunjuk ke node1, dst\n        counter = 0\n\n        # Memperoleh alamat yang sedang disimpan di head\n        # - asumsi awal: tidak ada alamat (None)\n        next_id = None\n        next_name = \"node0\" # ini nanti untuk nama node berikutnya di Graphviz\n        # - kalau ternyata ada alamat...\n        if current != None:\n            # maka simpan alamat tersebut\n            next_id = hex(id(current))\n            # kita buat lebih spesifik untuk node berikutnya, tunjuk ke port id\n            next_name = \"node0:id\"\n        \n        # Label (tabel) untuk pointer head\n        # - pembuka tabel\n        str_label = \"&lt;\"\n        str_label += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n        # - baris head\n        str_label += \"&lt;TR&gt;&lt;TD&gt;head&lt;/TD&gt;&lt;/TR&gt;\"\n        # - baris alamat (sekalian membuat port namanya \"contents\")\n        str_label += \"&lt;TR&gt;&lt;TD PORT=\\\"contents\\\"&gt;\" + str(next_id) + \"&lt;/TD&gt;&lt;/TR&gt;\"\n        # - penutup tabel\n        str_label += \"&lt;/TABLE&gt;\"\n        str_label += \"&gt;\"\n\n        # Membuat node head, membuat edge dari head ke node berikutnya\n        new_digraph.node(\"head\", shape=\"none\", label=str_label)\n        new_digraph.edge(\"head:contents\", next_name)\n        # dari port \"contents\" ke node berikutnya, yang namanya next_name\n        \n        # Selama node yang ditunjuk bukan None, buatlah node nya di Graphviz,\n        # lalu lanjut ke node selanjutnya (ini traversal)\n        while current != None:\n            # Alamat yang tersimpan pada current.next\n            # - asumsi awal: tidak ada alamat; current adalah node terakhir\n            next_id = None\n            # - kalau ternyata ada alamat...\n            if current.next != None:\n                # maka simpan alamat tersebut\n                next_id = hex(id(current.next))\n\n            # serupa untuk prev\n            prev_id = None\n            if current.prev != None:\n                prev_id = hex(id(current.prev))\n            \n            # Persiapan label (tabel) untuk node\n            # - pembuka tabel\n            str_label = \"&lt;\"\n            str_label += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n            # - baris tulisan \"prev\", \"data\", \"next\"\n            str_label += \"&lt;TR&gt;&lt;TD&gt;prev&lt;/TD&gt;&lt;TD&gt;data&lt;/TD&gt;&lt;TD&gt;next&lt;/TD&gt;&lt;/TR&gt;\"\n            # - baris untuk isi prev, isi data, dan isi next\n            str_label += \"&lt;TR&gt;\"\n            str_label += \"&lt;TD PORT=\\\"prev\\\"&gt;\" + str(prev_id) + \"&lt;/TD&gt;\"\n            str_label += \"&lt;TD&gt;\" + str(current.data) + \"&lt;/TD&gt;\"\n            str_label += \"&lt;TD PORT=\\\"next\\\"&gt;\" + str(next_id) + \"&lt;/TD&gt;\"\n            str_label += \"&lt;/TR&gt;\"\n            # - baris tulisan \"alamat node\", merentang dua kolom\n            str_label += \"&lt;TR&gt;&lt;TD COLSPAN=\\\"3\\\"&gt;alamat node&lt;/TD&gt;&lt;/TR&gt;\"\n            # - baris untuk isi alamat node, merentang dua kolom\n            str_label += \"&lt;TR&gt;\"\n            str_label += \"&lt;TD PORT=\\\"id\\\" COLSPAN=\\\"3\\\"&gt;\"\n            str_label += str(hex(id(current)))\n            str_label += \"&lt;/TD&gt;\"\n            str_label += \"&lt;/TR&gt;\"\n            # - penutup tabel\n            str_label += \"&lt;/TABLE&gt;\"\n            str_label += \"&gt;\"\n\n            # Membuat node baru di Graphviz dengan label (tabel) tersebut\n            new_digraph.node(\"node\" + str(counter), shape=\"none\", label = str_label)\n\n            # Menentukan nama dua port yang bakal disambung dengan edge,\n            # yaitu (node saat ini):next disambung ke node(berikutnya):id\n            # yaitu bagian \"next\" disambung ke bagian alamat di node berikutnya\n            nama_node_next = \"node\" + str(counter) + \":next\"\n\n            # tambahan untuk doubly linked list\n            nama_node_prev = \"node\" + str(counter) + \":prev\"\n\n            if current.next != None:\n                nama_alamat_node_berikutnya = \"node\" + str(counter+1) + \":id\"\n            # atau ke node(berikutnya) saja tanpa id kalau itu ternyata None,\n            # karena None tidak akan memiliki port id\n            else:\n                nama_alamat_node_berikutnya = \"node\" + str(counter+1)\n            \n            # Menyambung keduanya\n            new_digraph.edge(nama_node_next, nama_alamat_node_berikutnya)\n\n            # tambahan untuk doubly linked list\n            if current.prev != None:\n                nama_alamat_node_sebelumnya = \"node\" + str(counter-1) + \":id\"\n            else:\n                nama_alamat_node_sebelumnya = \"node\" + str(counter-1)\n            if current == self.head:\n                new_digraph.node(\"node-1\", shape=\"none\", label=\"None\")\n            new_digraph.edge(nama_node_prev, nama_alamat_node_sebelumnya)\n            \n            # Lanjut ke node selanjutnya\n            current = current.next\n            counter += 1\n        # Kalau sudah keluar loop, artinya current menunjuk ke None\n        # Berarti tinggal membuat \"node\" terakhir berisi tulisan None\n        # (karena sambungannya sudah dibuat di dalam loop, tinggal node nya)\n        new_digraph.node(\"node\" + str(counter), shape=\"none\", label=\"None\")\n\n        # Tambah pointer tail\n        # - asumsi awal: tidak ada alamat (None)\n        tail_id = None\n        tail_name = \"node\" + str(counter-1) # ini nanti untuk nama node tail\n        # - kalau ternyata ada alamat...\n        if self.tail != None:\n            # maka simpan alamat tersebut\n            tail_id = hex(id(self.tail))\n            # kita buat lebih spesifik untuk node berikutnya, tunjuk ke port id\n            tail_name += \":id\"\n        \n        # Label (tabel) untuk pointer tail\n        # - pembuka tabel\n        str_label = \"&lt;\"\n        str_label += \"&lt;TABLE BORDER=\\\"0\\\" CELLBORDER=\\\"1\\\" CELLSPACING=\\\"0\\\"&gt;\"\n        # - baris head\n        str_label += \"&lt;TR&gt;&lt;TD&gt;tail&lt;/TD&gt;&lt;/TR&gt;\"\n        # - baris alamat (sekalian membuat port namanya \"contents\")\n        str_label += \"&lt;TR&gt;&lt;TD PORT=\\\"contents\\\"&gt;\" + str(tail_id) + \"&lt;/TD&gt;&lt;/TR&gt;\"\n        # - penutup tabel\n        str_label += \"&lt;/TABLE&gt;\"\n        str_label += \"&gt;\"\n\n        # Membuat node tail, membuat edge dari tail ke node nya\n        new_digraph.node(\"tail\", shape=\"none\", label=str_label)\n        new_digraph.edge(\"tail:contents\", tail_name)\n        # dari port \"contents\" ke node yang ditunjuk tail, namanya tail_name\n\n        # Digraph sudah jadi\n        return new_digraph\n\n\ntestDL = DLList()\ntestDL.ins_front(5)\ntestDL.ins_front(15)\ntestDL.ins_front(25)\ntestDL.ins_front(35)\n\n\ntestDL.print_all()\n\nhead -&gt; 35 &lt;-&gt; 25 &lt;-&gt; 15 &lt;-&gt; 5 &lt;- tail\n\n\n\ngambarDL = testDL.get_digraph()\n\n\ndisplay(gambarDL)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul07.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul07.html",
    "title": "Modul 7 Struktur Data: Queue dan berbagai implementasinya",
    "section": "",
    "text": "Kembali ke Struktur Data (dengan Python)\nDi praktikum kali ini, kita akan membahas tentang struktur data queue serta berbagai “implementasi”nya dalam Python (yaitu berbagai cara membuat struktur data queue di Python), baik menggunakan array maupun linked list.\nQueue itu sendiri adalah suatu struktur data dengan dua ujung, di mana data bisa dimasukkan dari salah satu ujung tertentu (yang disebut rear) dan data bisa dikeluarkan dari ujung yang satunya lagi (yang disebut front). Queue dikatakan menganut prinsip FIFO (First In First Out), karena data yang pertama masuk akan menjadi data yang pertama keluar.\nKita akan menggunakan array dari numpy, sehingga perlu melakukan import:\n\nimport numpy as np\n\n\n\n\nclass ArrayLinQueue:\n    def __init__(self, dtype, array_max):\n        self.dtype = dtype\n        self.array_max = array_max\n        self.array = np.empty(array_max, dtype=dtype)\n        self.front = -1\n        self.rear = -1\n    \n    def get_size(self):\n        size = (self.rear - self.front) + 1\n        return size\n\n    def get_capacity_array(self):\n        return self.array_max\n\n    def get_capacity_queue(self):\n        if self.front == -1:\n            capacity_queue = self.array_max\n        else:\n            capacity_queue = self.array_max - self.front\n        return capacity_queue\n    \n    def is_empty(self):\n        if self.front == -1:\n            return True\n        else:\n            return False\n    \n    def is_full(self):\n        if self.rear == self.array_max - 1:\n            return True\n        else:\n            return False\n    \n    def enqueue(self, newdata):\n        if self.is_full():\n            print(\"Error enqueue: queue sudah penuh sebelumnya\")\n        elif self.front == -1:\n            self.front += 1\n            self.rear += 1\n            self.array[self.rear] = newdata\n        else:\n            self.rear += 1\n            self.array[self.rear] = newdata\n    \n    def peek(self):\n        if self.is_empty():\n            print(\"Error peek: queue sedang kosong\")\n        else:\n            return self.array[self.front]\n    \n    def dequeue(self):\n        if self.is_empty():\n            print(\"Error dequeue: queue sudah kosong sebelumnya\")\n            return None\n        elif (self.get_size() == 1):\n            # Jika di queue hanya ada satu elemen, dan ingin di-dequeue,\n            # maka queue akan kosong setelah itu\n            output = self.array[self.front]\n            self.front = -1\n            self.rear = -1\n            return output\n        else:\n            output = self.array[self.front]\n            self.front += 1\n            return output\n    \n    def print_storage(self):\n        print(self.array)\n\n    def print_queue(self):\n        print(\"front : \", end=\"\")\n        if self.is_empty():\n            print(\"(tidak ada data) : rear\")\n        else:\n            for i in range(self.front, self.rear): # i = front, ..., rear-1\n                print(self.array[i], end=\" | \")\n            print(self.array[self.rear], end=\"\") # untuk i = rear\n            print(\" : rear\")\n\n\narraylinqueue = ArrayLinQueue(int, 5)\n\n\narraylinqueue.print_queue()\n\nfront : (tidak ada data) : rear\n\n\n\narraylinqueue.print_storage()\n\n[                  0 4602678819172646912 4607182418800017408\n 4609434218613702656 4611686018427387904]\n\n\n\narraylinqueue.enqueue(-18)\narraylinqueue.enqueue(67)\narraylinqueue.enqueue(32)\n\n\narraylinqueue.print_queue()\n\nfront : -18 | 67 | 32 : rear\n\n\n\narraylinqueue.print_storage()\n\n[                -18                  67                  32\n 4609434218613702656 4611686018427387904]\n\n\n\nprint(arraylinqueue.front)\nprint(arraylinqueue.rear)\n\n0\n2\n\n\n\narraylinqueue.enqueue(-29)\n\n\narraylinqueue.print_queue()\n\nfront : -18 | 67 | 32 | -29 : rear\n\n\n\narraylinqueue.print_storage()\n\n[                -18                  67                  32\n                 -29 4611686018427387904]\n\n\n\nprint(arraylinqueue.front)\nprint(arraylinqueue.rear)\n\n0\n3\n\n\n\nprint(arraylinqueue.peek())\n\n-18\n\n\n\narraylinqueue.print_queue()\n\nfront : -18 | 67 | 32 | -29 : rear\n\n\n\nnilai = arraylinqueue.dequeue()\nprint(nilai)\n\n-18\n\n\n\narraylinqueue.print_queue()\n\nfront : 67 | 32 | -29 : rear\n\n\n\narraylinqueue.print_storage()\n\n[                -18                  67                  32\n                 -29 4611686018427387904]\n\n\n\nprint(arraylinqueue.front)\nprint(arraylinqueue.rear)\n\n1\n3\n\n\n\nprint(arraylinqueue.dequeue())\n\n67\n\n\n\narraylinqueue.print_queue()\n\nfront : 32 | -29 : rear\n\n\n\nprint(arraylinqueue.dequeue())\nprint(arraylinqueue.dequeue())\n\n32\n-29\n\n\n\narraylinqueue.print_queue()\n\nfront : (tidak ada data) : rear\n\n\n\nprint(arraylinqueue.front)\nprint(arraylinqueue.rear)\n\n-1\n-1\n\n\n\nprint(arraylinqueue.dequeue())\n\nError dequeue: queue sudah kosong sebelumnya\nNone\n\n\n\narraylinqueue.enqueue(-25)\narraylinqueue.enqueue(13)\narraylinqueue.enqueue(48)\narraylinqueue.enqueue(-87)\narraylinqueue.enqueue(38)\n\n\narraylinqueue.print_queue()\n\nfront : -25 | 13 | 48 | -87 | 38 : rear\n\n\n\narraylinqueue.print_storage()\n\n[-25  13  48 -87  38]\n\n\n\nprint(arraylinqueue.is_full())\n\nTrue\n\n\n\nprint(arraylinqueue.front)\nprint(arraylinqueue.rear)\n\n0\n4\n\n\n\narraylinqueue.enqueue(-53)\n\nError enqueue: queue sudah penuh sebelumnya\n\n\n\nprint(arraylinqueue.dequeue())\nprint(arraylinqueue.dequeue())\n\n-25\n13\n\n\n\narraylinqueue.print_queue()\n\nfront : 48 | -87 | 38 : rear\n\n\n\narraylinqueue.print_storage()\n\n[-25  13  48 -87  38]\n\n\n\nprint(arraylinqueue.front)\nprint(arraylinqueue.rear)\n\n2\n4\n\n\n\narraylinqueue.enqueue(-53)\n\nError enqueue: queue sudah penuh sebelumnya\n\n\n\n\n\n\nclass ArrayCircQueue:\n    def __init__(self, dtype, max):\n        self.dtype = dtype\n        self.max = max\n        self.array = np.empty(max, dtype=dtype)\n        self.front = -1\n        self.rear = -1\n    \n    def is_empty(self):\n        if self.front == -1:\n            return True\n        else:\n            return False\n    \n    def is_full(self):\n        if self.front == (self.rear + 1) % self.max:\n            return True\n        else:\n            return False\n\n    def get_size(self):\n        if self.is_empty():\n            size = 0\n        elif self.front &lt;= self.rear:\n            size = (self.rear - self.front) + 1\n        else:\n            size = self.max - (self.front - self.rear - 1)\n        return size\n\n    def get_capacity(self):\n        return self.max\n    \n    def enqueue(self, newdata):\n        if self.is_full():\n            print(\"Error enqueue: queue sudah penuh sebelumnya\")\n        elif self.front == -1:\n            self.front += 1\n            self.rear += 1\n            self.array[self.rear] = newdata\n        else:\n            self.rear = (self.rear + 1) % self.max # hanya berbeda di sini\n            self.array[self.rear] = newdata\n    \n    # Masih sama persis\n    def peek(self):\n        if self.is_empty():\n            print(\"Error peek: queue sedang kosong\")\n        else:\n            return self.array[self.front]\n    \n    def dequeue(self):\n        if self.is_empty():\n            print(\"Error dequeue: queue sudah kosong sebelumnya\")\n            return None\n        elif (self.get_size() == 1):\n            # Jika di queue hanya ada satu elemen, dan ingin di-dequeue,\n            # maka queue akan kosong setelah itu\n            output = self.array[self.front]\n            self.front = -1\n            self.rear = -1\n            return output\n        else:\n            output = self.array[self.front]\n            self.front = (self.front + 1) % self.max # hanya berbeda di sini\n            return output\n    \n    def print_storage(self):\n        print(self.array)\n\n    def print_queue(self):\n        print(\"front : \", end=\"\")\n        if self.is_empty():\n            print(\"(tidak ada data) : rear\")\n        else:\n            # i = front, ..., rear-1 (kurang lebih begitu)\n            i = self.front\n            while i != self.rear:\n                print(self.array[i], end=\" | \")\n                i = (i + 1) % self.max\n            # untuk i = rear\n            print(self.array[self.rear], end=\"\") \n            print(\" : rear\")\n\n\narraycircqueue = ArrayCircQueue(int, 5)\narraycircqueue.print_queue()\n\nfront : (tidak ada data) : rear\n\n\n\narraycircqueue.print_storage()\n\n[4607182418800017408 4613374868287651840 4618441417868443648\n 4622241330054037504 4625478292286210048]\n\n\n\narraycircqueue.enqueue(65)\narraycircqueue.enqueue(-11)\narraycircqueue.enqueue(43)\n\n\narraycircqueue.print_queue()\n\nfront : 65 | -11 | 43 : rear\n\n\n\narraycircqueue.print_storage()\n\n[                 65                 -11                  43\n 4622241330054037504 4625478292286210048]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n0\n2\n\n\n\narraycircqueue.enqueue(97)\narraycircqueue.enqueue(-12)\n\n\narraycircqueue.print_queue()\n\nfront : 65 | -11 | 43 | 97 | -12 : rear\n\n\n\narraycircqueue.enqueue(41)\n\nError enqueue: queue sudah penuh sebelumnya\n\n\n\narraycircqueue.print_storage()\n\n[ 65 -11  43  97 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n0\n4\n\n\n\nprint(arraycircqueue.peek())\n\n65\n\n\n\narraycircqueue.print_queue()\n\nfront : 65 | -11 | 43 | 97 | -12 : rear\n\n\n\nprint(arraycircqueue.dequeue())\n\n65\n\n\n\narraycircqueue.print_queue()\n\nfront : -11 | 43 | 97 | -12 : rear\n\n\n\narraycircqueue.print_storage()\n\n[ 65 -11  43  97 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n1\n4\n\n\n\nprint(arraycircqueue.dequeue())\nprint(arraycircqueue.dequeue())\n\n-11\n43\n\n\n\narraycircqueue.print_queue()\n\nfront : 97 | -12 : rear\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n3\n4\n\n\n\narraycircqueue.print_storage()\n\n[ 65 -11  43  97 -12]\n\n\n\narraycircqueue.enqueue(-74)\n\n\narraycircqueue.print_queue()\n\nfront : 97 | -12 | -74 : rear\n\n\n\narraycircqueue.print_storage()\n\n[-74 -11  43  97 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n3\n0\n\n\n\narraycircqueue.enqueue(19)\n\n\narraycircqueue.print_queue()\n\nfront : 97 | -12 | -74 | 19 : rear\n\n\n\narraycircqueue.print_storage()\n\n[-74  19  43  97 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n3\n1\n\n\n\narraycircqueue.enqueue(85)\n\n\narraycircqueue.print_queue()\n\nfront : 97 | -12 | -74 | 19 | 85 : rear\n\n\n\narraycircqueue.print_storage()\n\n[-74  19  85  97 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n3\n2\n\n\n\narraycircqueue.enqueue(-31)\n\nError enqueue: queue sudah penuh sebelumnya\n\n\n\nprint(arraycircqueue.dequeue())\n\n97\n\n\n\narraycircqueue.print_queue()\n\nfront : -12 | -74 | 19 | 85 : rear\n\n\n\narraycircqueue.print_storage()\n\n[-74  19  85  97 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n4\n2\n\n\n\nprint(arraycircqueue.dequeue())\n\n-12\n\n\n\narraycircqueue.print_queue()\n\nfront : -74 | 19 | 85 : rear\n\n\n\narraycircqueue.print_storage()\n\n[-74  19  85  97 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n0\n2\n\n\n\narraycircqueue.enqueue(27)\n\n\narraycircqueue.print_queue()\n\nfront : -74 | 19 | 85 | 27 : rear\n\n\n\narraycircqueue.print_storage()\n\n[-74  19  85  27 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n0\n3\n\n\n\nprint(arraycircqueue.dequeue())\n\n-74\n\n\n\narraycircqueue.print_queue()\n\nfront : 19 | 85 | 27 : rear\n\n\n\narraycircqueue.print_storage()\n\n[-74  19  85  27 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n1\n3\n\n\n\n\n\n\nclass SLNode:\n    def __init__(self, data, next=None):\n        self.data = data\n        self.next = next\n\n\nclass SLLinQueue:\n    def __init__(self):\n        # head=front, tail=rear\n        self.front = None\n        self.rear = None\n    \n    def is_empty(self):\n        if self.front == None:\n            return True\n        else:\n            return False\n    \n    def get_size(self):\n        size = 0\n        temp = self.front\n        while (temp != None):\n            size += 1\n            temp = temp.next\n        return size\n\n    # insert di akhir linked list\n    def enqueue(self, newdata):\n        newnode = SLNode(newdata)\n        if self.is_empty():\n            self.front = newnode\n            self.rear = newnode\n        else:\n            self.rear.next = newnode\n            self.rear = newnode\n    \n    def peek(self):\n        if self.is_empty():\n            print(\"Error peek: queue sedang kosong\")\n            return None\n        else:\n            return self.front.data\n\n    # hapus di awal linked list\n    def dequeue(self):\n        if self.is_empty():\n            print(\"Error dequeue: queue sudah kosong sebelumnya\")\n            return None\n        else:\n            output = self.front.data\n            temp = self.front\n            self.front = self.front.next\n            del temp\n            return output\n    \n    def print_queue(self):\n        print(\"front : \", end=\"\")\n        if self.is_empty():\n            print(\"(tidak ada data) : rear\")\n        else:\n            temp = self.front\n            while temp != None:\n                if temp.next != None:\n                    print(temp.data, end = \" | \")\n                else:\n                    print(temp.data, end=\"\")\n                temp = temp.next\n            print(\" : rear\")\n\n    def print_storage(self):\n        print(\"front -&gt; \", end=\"\")\n        if self.is_empty():\n            print(\"None &lt;- rear\")\n        else:\n            temp = self.front\n            while temp != None:\n                if temp.next != None:\n                    print(temp.data, end = \" -&gt; \")\n                else:\n                    print(temp.data, end = \" &lt;- \")\n                temp = temp.next\n            print(\"rear\")\n\n\nsllinqueue = SLLinQueue()\nsllinqueue.print_queue()\nsllinqueue.print_storage()\n\nfront : (tidak ada data) : rear\nfront -&gt; None &lt;- rear\n\n\n\nsllinqueue.enqueue(10)\nsllinqueue.print_queue()\nsllinqueue.print_storage()\n\nfront : 10 : rear\nfront -&gt; 10 &lt;- rear\n\n\n\nsllinqueue.enqueue(98)\nsllinqueue.print_queue()\nsllinqueue.print_storage()\n\nfront : 10 | 98 : rear\nfront -&gt; 10 -&gt; 98 &lt;- rear\n\n\n\nsllinqueue.enqueue(-43)\nsllinqueue.print_queue()\nsllinqueue.print_storage()\n\nfront : 10 | 98 | -43 : rear\nfront -&gt; 10 -&gt; 98 -&gt; -43 &lt;- rear\n\n\n\nprint(sllinqueue.peek())\n\n10\n\n\n\nsllinqueue.print_queue()\nsllinqueue.print_storage()\n\nfront : 10 | 98 | -43 : rear\nfront -&gt; 10 -&gt; 98 -&gt; -43 &lt;- rear\n\n\n\nprint(sllinqueue.dequeue())\n\n10\n\n\n\nsllinqueue.print_queue()\nsllinqueue.print_storage()\n\nfront : 98 | -43 : rear\nfront -&gt; 98 -&gt; -43 &lt;- rear\n\n\n\n\n\n\nclass SLCircQueue:\n    def __init__(self):\n        # head=front, tail=rear\n        self.front = None\n        self.rear = None\n    \n    def is_empty(self):\n        if self.front == None:\n            return True\n        else:\n            return False\n    \n    def get_size(self):\n        size = 0\n        temp = self.front\n        if temp == None:\n            return size\n        else:\n            size += 1\n            temp = temp.next\n        while (temp != self.front):\n            size += 1\n            temp = temp.next\n        return size\n\n    def enqueue(self, newdata):\n        newnode = SLNode(newdata)\n        if self.is_empty():\n            self.front = newnode\n            self.rear = newnode\n            newnode.next = newnode\n        else:\n            self.rear.next = newnode\n            self.rear = newnode\n            newnode.next = self.front\n    \n    # masih sama persis\n    def peek(self):\n        if self.is_empty():\n            print(\"Error peek: queue sedang kosong\")\n            return None\n        else:\n            return self.front.data\n\n    def dequeue(self):\n        if self.is_empty():\n            print(\"Error dequeue: queue sudah kosong sebelumnya\")\n            return None\n        elif (self.front == self.rear): # sama saja self.get_size() == 1\n            output = self.front.data\n            del self.front\n            self.front = None\n            self.rear = None\n            return output\n        else:\n            output = self.front.data\n            temp = self.front\n            self.front = self.front.next\n            del temp\n            self.rear.next = self.front\n            return output\n    \n    def print_queue(self):\n        print(\"front : \", end=\"\")\n        if self.is_empty():\n            print(\"(tidak ada data) : rear\")\n        else:\n            temp = self.front\n            while temp.next != self.front:\n                print(temp.data, end = \" | \")\n                temp = temp.next\n            print(temp.data, end=\"\")\n            print(\" : rear\")\n\n    def print_storage(self):\n        print(\"front -&gt; \", end=\"\")\n        if self.is_empty():\n            print(\"None (&lt;- rear)\")\n        else:\n            temp = self.front\n            while temp.next != self.front:\n                print(temp.data, end = \" -&gt; \")\n                temp = temp.next\n            print(temp.data, end = \"\")\n            print(\" (&lt;- rear) -&gt; front\")\n\n\nslcircqueue = SLCircQueue()\nslcircqueue.print_queue()\nslcircqueue.print_storage()\n\nfront : (tidak ada data) : rear\nfront -&gt; None (&lt;- rear)\n\n\n\nslcircqueue.enqueue(-91)\nslcircqueue.print_queue()\nslcircqueue.print_storage()\n\nfront : -91 : rear\nfront -&gt; -91 (&lt;- rear) -&gt; front\n\n\n\nslcircqueue.enqueue(14)\nslcircqueue.print_queue()\nslcircqueue.print_storage()\n\nfront : -91 | 14 : rear\nfront -&gt; -91 -&gt; 14 (&lt;- rear) -&gt; front\n\n\n\nslcircqueue.enqueue(30)\nslcircqueue.print_queue()\nslcircqueue.print_storage()\n\nfront : -91 | 14 | 30 : rear\nfront -&gt; -91 -&gt; 14 -&gt; 30 (&lt;- rear) -&gt; front\n\n\n\nslcircqueue.peek()\n\n-91\n\n\n\nslcircqueue.print_queue()\nslcircqueue.print_storage()\n\nfront : -91 | 14 | 30 : rear\nfront -&gt; -91 -&gt; 14 -&gt; 30 (&lt;- rear) -&gt; front\n\n\n\nprint(slcircqueue.dequeue())\n\n-91\n\n\n\nslcircqueue.print_queue()\nslcircqueue.print_storage()\n\nfront : 14 | 30 : rear\nfront -&gt; 14 -&gt; 30 (&lt;- rear) -&gt; front"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul07.html#implementasi-linear-queue-dengan-array",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul07.html#implementasi-linear-queue-dengan-array",
    "title": "Modul 7 Struktur Data: Queue dan berbagai implementasinya",
    "section": "",
    "text": "class ArrayLinQueue:\n    def __init__(self, dtype, array_max):\n        self.dtype = dtype\n        self.array_max = array_max\n        self.array = np.empty(array_max, dtype=dtype)\n        self.front = -1\n        self.rear = -1\n    \n    def get_size(self):\n        size = (self.rear - self.front) + 1\n        return size\n\n    def get_capacity_array(self):\n        return self.array_max\n\n    def get_capacity_queue(self):\n        if self.front == -1:\n            capacity_queue = self.array_max\n        else:\n            capacity_queue = self.array_max - self.front\n        return capacity_queue\n    \n    def is_empty(self):\n        if self.front == -1:\n            return True\n        else:\n            return False\n    \n    def is_full(self):\n        if self.rear == self.array_max - 1:\n            return True\n        else:\n            return False\n    \n    def enqueue(self, newdata):\n        if self.is_full():\n            print(\"Error enqueue: queue sudah penuh sebelumnya\")\n        elif self.front == -1:\n            self.front += 1\n            self.rear += 1\n            self.array[self.rear] = newdata\n        else:\n            self.rear += 1\n            self.array[self.rear] = newdata\n    \n    def peek(self):\n        if self.is_empty():\n            print(\"Error peek: queue sedang kosong\")\n        else:\n            return self.array[self.front]\n    \n    def dequeue(self):\n        if self.is_empty():\n            print(\"Error dequeue: queue sudah kosong sebelumnya\")\n            return None\n        elif (self.get_size() == 1):\n            # Jika di queue hanya ada satu elemen, dan ingin di-dequeue,\n            # maka queue akan kosong setelah itu\n            output = self.array[self.front]\n            self.front = -1\n            self.rear = -1\n            return output\n        else:\n            output = self.array[self.front]\n            self.front += 1\n            return output\n    \n    def print_storage(self):\n        print(self.array)\n\n    def print_queue(self):\n        print(\"front : \", end=\"\")\n        if self.is_empty():\n            print(\"(tidak ada data) : rear\")\n        else:\n            for i in range(self.front, self.rear): # i = front, ..., rear-1\n                print(self.array[i], end=\" | \")\n            print(self.array[self.rear], end=\"\") # untuk i = rear\n            print(\" : rear\")\n\n\narraylinqueue = ArrayLinQueue(int, 5)\n\n\narraylinqueue.print_queue()\n\nfront : (tidak ada data) : rear\n\n\n\narraylinqueue.print_storage()\n\n[                  0 4602678819172646912 4607182418800017408\n 4609434218613702656 4611686018427387904]\n\n\n\narraylinqueue.enqueue(-18)\narraylinqueue.enqueue(67)\narraylinqueue.enqueue(32)\n\n\narraylinqueue.print_queue()\n\nfront : -18 | 67 | 32 : rear\n\n\n\narraylinqueue.print_storage()\n\n[                -18                  67                  32\n 4609434218613702656 4611686018427387904]\n\n\n\nprint(arraylinqueue.front)\nprint(arraylinqueue.rear)\n\n0\n2\n\n\n\narraylinqueue.enqueue(-29)\n\n\narraylinqueue.print_queue()\n\nfront : -18 | 67 | 32 | -29 : rear\n\n\n\narraylinqueue.print_storage()\n\n[                -18                  67                  32\n                 -29 4611686018427387904]\n\n\n\nprint(arraylinqueue.front)\nprint(arraylinqueue.rear)\n\n0\n3\n\n\n\nprint(arraylinqueue.peek())\n\n-18\n\n\n\narraylinqueue.print_queue()\n\nfront : -18 | 67 | 32 | -29 : rear\n\n\n\nnilai = arraylinqueue.dequeue()\nprint(nilai)\n\n-18\n\n\n\narraylinqueue.print_queue()\n\nfront : 67 | 32 | -29 : rear\n\n\n\narraylinqueue.print_storage()\n\n[                -18                  67                  32\n                 -29 4611686018427387904]\n\n\n\nprint(arraylinqueue.front)\nprint(arraylinqueue.rear)\n\n1\n3\n\n\n\nprint(arraylinqueue.dequeue())\n\n67\n\n\n\narraylinqueue.print_queue()\n\nfront : 32 | -29 : rear\n\n\n\nprint(arraylinqueue.dequeue())\nprint(arraylinqueue.dequeue())\n\n32\n-29\n\n\n\narraylinqueue.print_queue()\n\nfront : (tidak ada data) : rear\n\n\n\nprint(arraylinqueue.front)\nprint(arraylinqueue.rear)\n\n-1\n-1\n\n\n\nprint(arraylinqueue.dequeue())\n\nError dequeue: queue sudah kosong sebelumnya\nNone\n\n\n\narraylinqueue.enqueue(-25)\narraylinqueue.enqueue(13)\narraylinqueue.enqueue(48)\narraylinqueue.enqueue(-87)\narraylinqueue.enqueue(38)\n\n\narraylinqueue.print_queue()\n\nfront : -25 | 13 | 48 | -87 | 38 : rear\n\n\n\narraylinqueue.print_storage()\n\n[-25  13  48 -87  38]\n\n\n\nprint(arraylinqueue.is_full())\n\nTrue\n\n\n\nprint(arraylinqueue.front)\nprint(arraylinqueue.rear)\n\n0\n4\n\n\n\narraylinqueue.enqueue(-53)\n\nError enqueue: queue sudah penuh sebelumnya\n\n\n\nprint(arraylinqueue.dequeue())\nprint(arraylinqueue.dequeue())\n\n-25\n13\n\n\n\narraylinqueue.print_queue()\n\nfront : 48 | -87 | 38 : rear\n\n\n\narraylinqueue.print_storage()\n\n[-25  13  48 -87  38]\n\n\n\nprint(arraylinqueue.front)\nprint(arraylinqueue.rear)\n\n2\n4\n\n\n\narraylinqueue.enqueue(-53)\n\nError enqueue: queue sudah penuh sebelumnya"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul07.html#implementasi-circular-queue-dengan-array",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul07.html#implementasi-circular-queue-dengan-array",
    "title": "Modul 7 Struktur Data: Queue dan berbagai implementasinya",
    "section": "",
    "text": "class ArrayCircQueue:\n    def __init__(self, dtype, max):\n        self.dtype = dtype\n        self.max = max\n        self.array = np.empty(max, dtype=dtype)\n        self.front = -1\n        self.rear = -1\n    \n    def is_empty(self):\n        if self.front == -1:\n            return True\n        else:\n            return False\n    \n    def is_full(self):\n        if self.front == (self.rear + 1) % self.max:\n            return True\n        else:\n            return False\n\n    def get_size(self):\n        if self.is_empty():\n            size = 0\n        elif self.front &lt;= self.rear:\n            size = (self.rear - self.front) + 1\n        else:\n            size = self.max - (self.front - self.rear - 1)\n        return size\n\n    def get_capacity(self):\n        return self.max\n    \n    def enqueue(self, newdata):\n        if self.is_full():\n            print(\"Error enqueue: queue sudah penuh sebelumnya\")\n        elif self.front == -1:\n            self.front += 1\n            self.rear += 1\n            self.array[self.rear] = newdata\n        else:\n            self.rear = (self.rear + 1) % self.max # hanya berbeda di sini\n            self.array[self.rear] = newdata\n    \n    # Masih sama persis\n    def peek(self):\n        if self.is_empty():\n            print(\"Error peek: queue sedang kosong\")\n        else:\n            return self.array[self.front]\n    \n    def dequeue(self):\n        if self.is_empty():\n            print(\"Error dequeue: queue sudah kosong sebelumnya\")\n            return None\n        elif (self.get_size() == 1):\n            # Jika di queue hanya ada satu elemen, dan ingin di-dequeue,\n            # maka queue akan kosong setelah itu\n            output = self.array[self.front]\n            self.front = -1\n            self.rear = -1\n            return output\n        else:\n            output = self.array[self.front]\n            self.front = (self.front + 1) % self.max # hanya berbeda di sini\n            return output\n    \n    def print_storage(self):\n        print(self.array)\n\n    def print_queue(self):\n        print(\"front : \", end=\"\")\n        if self.is_empty():\n            print(\"(tidak ada data) : rear\")\n        else:\n            # i = front, ..., rear-1 (kurang lebih begitu)\n            i = self.front\n            while i != self.rear:\n                print(self.array[i], end=\" | \")\n                i = (i + 1) % self.max\n            # untuk i = rear\n            print(self.array[self.rear], end=\"\") \n            print(\" : rear\")\n\n\narraycircqueue = ArrayCircQueue(int, 5)\narraycircqueue.print_queue()\n\nfront : (tidak ada data) : rear\n\n\n\narraycircqueue.print_storage()\n\n[4607182418800017408 4613374868287651840 4618441417868443648\n 4622241330054037504 4625478292286210048]\n\n\n\narraycircqueue.enqueue(65)\narraycircqueue.enqueue(-11)\narraycircqueue.enqueue(43)\n\n\narraycircqueue.print_queue()\n\nfront : 65 | -11 | 43 : rear\n\n\n\narraycircqueue.print_storage()\n\n[                 65                 -11                  43\n 4622241330054037504 4625478292286210048]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n0\n2\n\n\n\narraycircqueue.enqueue(97)\narraycircqueue.enqueue(-12)\n\n\narraycircqueue.print_queue()\n\nfront : 65 | -11 | 43 | 97 | -12 : rear\n\n\n\narraycircqueue.enqueue(41)\n\nError enqueue: queue sudah penuh sebelumnya\n\n\n\narraycircqueue.print_storage()\n\n[ 65 -11  43  97 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n0\n4\n\n\n\nprint(arraycircqueue.peek())\n\n65\n\n\n\narraycircqueue.print_queue()\n\nfront : 65 | -11 | 43 | 97 | -12 : rear\n\n\n\nprint(arraycircqueue.dequeue())\n\n65\n\n\n\narraycircqueue.print_queue()\n\nfront : -11 | 43 | 97 | -12 : rear\n\n\n\narraycircqueue.print_storage()\n\n[ 65 -11  43  97 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n1\n4\n\n\n\nprint(arraycircqueue.dequeue())\nprint(arraycircqueue.dequeue())\n\n-11\n43\n\n\n\narraycircqueue.print_queue()\n\nfront : 97 | -12 : rear\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n3\n4\n\n\n\narraycircqueue.print_storage()\n\n[ 65 -11  43  97 -12]\n\n\n\narraycircqueue.enqueue(-74)\n\n\narraycircqueue.print_queue()\n\nfront : 97 | -12 | -74 : rear\n\n\n\narraycircqueue.print_storage()\n\n[-74 -11  43  97 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n3\n0\n\n\n\narraycircqueue.enqueue(19)\n\n\narraycircqueue.print_queue()\n\nfront : 97 | -12 | -74 | 19 : rear\n\n\n\narraycircqueue.print_storage()\n\n[-74  19  43  97 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n3\n1\n\n\n\narraycircqueue.enqueue(85)\n\n\narraycircqueue.print_queue()\n\nfront : 97 | -12 | -74 | 19 | 85 : rear\n\n\n\narraycircqueue.print_storage()\n\n[-74  19  85  97 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n3\n2\n\n\n\narraycircqueue.enqueue(-31)\n\nError enqueue: queue sudah penuh sebelumnya\n\n\n\nprint(arraycircqueue.dequeue())\n\n97\n\n\n\narraycircqueue.print_queue()\n\nfront : -12 | -74 | 19 | 85 : rear\n\n\n\narraycircqueue.print_storage()\n\n[-74  19  85  97 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n4\n2\n\n\n\nprint(arraycircqueue.dequeue())\n\n-12\n\n\n\narraycircqueue.print_queue()\n\nfront : -74 | 19 | 85 : rear\n\n\n\narraycircqueue.print_storage()\n\n[-74  19  85  97 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n0\n2\n\n\n\narraycircqueue.enqueue(27)\n\n\narraycircqueue.print_queue()\n\nfront : -74 | 19 | 85 | 27 : rear\n\n\n\narraycircqueue.print_storage()\n\n[-74  19  85  27 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n0\n3\n\n\n\nprint(arraycircqueue.dequeue())\n\n-74\n\n\n\narraycircqueue.print_queue()\n\nfront : 19 | 85 | 27 : rear\n\n\n\narraycircqueue.print_storage()\n\n[-74  19  85  27 -12]\n\n\n\nprint(arraycircqueue.front)\nprint(arraycircqueue.rear)\n\n1\n3"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul07.html#implementasi-linear-queue-dengan-linked-list",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul07.html#implementasi-linear-queue-dengan-linked-list",
    "title": "Modul 7 Struktur Data: Queue dan berbagai implementasinya",
    "section": "",
    "text": "class SLNode:\n    def __init__(self, data, next=None):\n        self.data = data\n        self.next = next\n\n\nclass SLLinQueue:\n    def __init__(self):\n        # head=front, tail=rear\n        self.front = None\n        self.rear = None\n    \n    def is_empty(self):\n        if self.front == None:\n            return True\n        else:\n            return False\n    \n    def get_size(self):\n        size = 0\n        temp = self.front\n        while (temp != None):\n            size += 1\n            temp = temp.next\n        return size\n\n    # insert di akhir linked list\n    def enqueue(self, newdata):\n        newnode = SLNode(newdata)\n        if self.is_empty():\n            self.front = newnode\n            self.rear = newnode\n        else:\n            self.rear.next = newnode\n            self.rear = newnode\n    \n    def peek(self):\n        if self.is_empty():\n            print(\"Error peek: queue sedang kosong\")\n            return None\n        else:\n            return self.front.data\n\n    # hapus di awal linked list\n    def dequeue(self):\n        if self.is_empty():\n            print(\"Error dequeue: queue sudah kosong sebelumnya\")\n            return None\n        else:\n            output = self.front.data\n            temp = self.front\n            self.front = self.front.next\n            del temp\n            return output\n    \n    def print_queue(self):\n        print(\"front : \", end=\"\")\n        if self.is_empty():\n            print(\"(tidak ada data) : rear\")\n        else:\n            temp = self.front\n            while temp != None:\n                if temp.next != None:\n                    print(temp.data, end = \" | \")\n                else:\n                    print(temp.data, end=\"\")\n                temp = temp.next\n            print(\" : rear\")\n\n    def print_storage(self):\n        print(\"front -&gt; \", end=\"\")\n        if self.is_empty():\n            print(\"None &lt;- rear\")\n        else:\n            temp = self.front\n            while temp != None:\n                if temp.next != None:\n                    print(temp.data, end = \" -&gt; \")\n                else:\n                    print(temp.data, end = \" &lt;- \")\n                temp = temp.next\n            print(\"rear\")\n\n\nsllinqueue = SLLinQueue()\nsllinqueue.print_queue()\nsllinqueue.print_storage()\n\nfront : (tidak ada data) : rear\nfront -&gt; None &lt;- rear\n\n\n\nsllinqueue.enqueue(10)\nsllinqueue.print_queue()\nsllinqueue.print_storage()\n\nfront : 10 : rear\nfront -&gt; 10 &lt;- rear\n\n\n\nsllinqueue.enqueue(98)\nsllinqueue.print_queue()\nsllinqueue.print_storage()\n\nfront : 10 | 98 : rear\nfront -&gt; 10 -&gt; 98 &lt;- rear\n\n\n\nsllinqueue.enqueue(-43)\nsllinqueue.print_queue()\nsllinqueue.print_storage()\n\nfront : 10 | 98 | -43 : rear\nfront -&gt; 10 -&gt; 98 -&gt; -43 &lt;- rear\n\n\n\nprint(sllinqueue.peek())\n\n10\n\n\n\nsllinqueue.print_queue()\nsllinqueue.print_storage()\n\nfront : 10 | 98 | -43 : rear\nfront -&gt; 10 -&gt; 98 -&gt; -43 &lt;- rear\n\n\n\nprint(sllinqueue.dequeue())\n\n10\n\n\n\nsllinqueue.print_queue()\nsllinqueue.print_storage()\n\nfront : 98 | -43 : rear\nfront -&gt; 98 -&gt; -43 &lt;- rear"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul07.html#implementasi-circular-queue-dengan-circular-linked-list",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul07.html#implementasi-circular-queue-dengan-circular-linked-list",
    "title": "Modul 7 Struktur Data: Queue dan berbagai implementasinya",
    "section": "",
    "text": "class SLCircQueue:\n    def __init__(self):\n        # head=front, tail=rear\n        self.front = None\n        self.rear = None\n    \n    def is_empty(self):\n        if self.front == None:\n            return True\n        else:\n            return False\n    \n    def get_size(self):\n        size = 0\n        temp = self.front\n        if temp == None:\n            return size\n        else:\n            size += 1\n            temp = temp.next\n        while (temp != self.front):\n            size += 1\n            temp = temp.next\n        return size\n\n    def enqueue(self, newdata):\n        newnode = SLNode(newdata)\n        if self.is_empty():\n            self.front = newnode\n            self.rear = newnode\n            newnode.next = newnode\n        else:\n            self.rear.next = newnode\n            self.rear = newnode\n            newnode.next = self.front\n    \n    # masih sama persis\n    def peek(self):\n        if self.is_empty():\n            print(\"Error peek: queue sedang kosong\")\n            return None\n        else:\n            return self.front.data\n\n    def dequeue(self):\n        if self.is_empty():\n            print(\"Error dequeue: queue sudah kosong sebelumnya\")\n            return None\n        elif (self.front == self.rear): # sama saja self.get_size() == 1\n            output = self.front.data\n            del self.front\n            self.front = None\n            self.rear = None\n            return output\n        else:\n            output = self.front.data\n            temp = self.front\n            self.front = self.front.next\n            del temp\n            self.rear.next = self.front\n            return output\n    \n    def print_queue(self):\n        print(\"front : \", end=\"\")\n        if self.is_empty():\n            print(\"(tidak ada data) : rear\")\n        else:\n            temp = self.front\n            while temp.next != self.front:\n                print(temp.data, end = \" | \")\n                temp = temp.next\n            print(temp.data, end=\"\")\n            print(\" : rear\")\n\n    def print_storage(self):\n        print(\"front -&gt; \", end=\"\")\n        if self.is_empty():\n            print(\"None (&lt;- rear)\")\n        else:\n            temp = self.front\n            while temp.next != self.front:\n                print(temp.data, end = \" -&gt; \")\n                temp = temp.next\n            print(temp.data, end = \"\")\n            print(\" (&lt;- rear) -&gt; front\")\n\n\nslcircqueue = SLCircQueue()\nslcircqueue.print_queue()\nslcircqueue.print_storage()\n\nfront : (tidak ada data) : rear\nfront -&gt; None (&lt;- rear)\n\n\n\nslcircqueue.enqueue(-91)\nslcircqueue.print_queue()\nslcircqueue.print_storage()\n\nfront : -91 : rear\nfront -&gt; -91 (&lt;- rear) -&gt; front\n\n\n\nslcircqueue.enqueue(14)\nslcircqueue.print_queue()\nslcircqueue.print_storage()\n\nfront : -91 | 14 : rear\nfront -&gt; -91 -&gt; 14 (&lt;- rear) -&gt; front\n\n\n\nslcircqueue.enqueue(30)\nslcircqueue.print_queue()\nslcircqueue.print_storage()\n\nfront : -91 | 14 | 30 : rear\nfront -&gt; -91 -&gt; 14 -&gt; 30 (&lt;- rear) -&gt; front\n\n\n\nslcircqueue.peek()\n\n-91\n\n\n\nslcircqueue.print_queue()\nslcircqueue.print_storage()\n\nfront : -91 | 14 | 30 : rear\nfront -&gt; -91 -&gt; 14 -&gt; 30 (&lt;- rear) -&gt; front\n\n\n\nprint(slcircqueue.dequeue())\n\n-91\n\n\n\nslcircqueue.print_queue()\nslcircqueue.print_storage()\n\nfront : 14 | 30 : rear\nfront -&gt; 14 -&gt; 30 (&lt;- rear) -&gt; front"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09.html",
    "title": "Modul 9 Struktur Data: Heap Tree, AVL/Balance Tree",
    "section": "",
    "text": "Kembali ke Struktur Data (dengan Python)\nSeperti biasa, kita perlu numpy untuk fitur array dan perlu graphviz untuk visualisasi:\n\nimport numpy as np\nimport graphviz as gv\n\nKali ini, kita juga memerlukan kode dari modul sebelumnya, terlampir di bagian Lampiran di akhir modul ini.\n\n\nHeap tree adalah sejenis binary tree dengan beberapa sifat tambahan tertentu. Heap tree terbagi lagi menjadi dua jenis, yaitu max heap dan min heap.\n\nMax heap adalah binary tree dengan sifat tambahan berikut:\n\nmerupakan tree yang complete (terkadang disebut almost complete), yaitu tiap level (kecuali level terakhir) harus terisi penuh, sedangkan pengisian node di level terakhir harus dari paling kiri.\n(Max Heap Property) Untuk tiap node, nilai data yang tersimpan di node tersebut harus lebih besar daripada (atau sama dengan) nilai data yang tersimpan di tiap child nya.\n\nDengan demikian, pada max heap, data dengan nilai terbesar ada di root.\nMin heap adalah binary tree dengan sifat tambahan berikut:\n\nmerupakan tree yang complete (terkadang disebut almost complete)\n(Min Heap Property) Untuk tiap node, nilai data yang tersimpan di node tersebut harus lebih kecil daripada (atau sama dengan) nilai data yang tersimpan di tiap child nya.\n\nDengan demikian, pada min heap, data dengan nilai terkecil ada di root.\n\nBeberapa hal lain tentang heap tree:\n\nKetika membahas deletion, yang dihapus sudah pasti root, dan nilai yang dihapus juga di-return (seperti operasi pop di stack).\nInsertion selalu dilakukan di level paling dalam, tepat di sebelah kanan dari node yang sudah ada (agar tree tetap beersifat complete).\n\nSelama berurusan dengan heap tree, ada (sekumpulan) operasi bernama heapify, yang tujuannya adalah memastikan bahwa heap tree memang memenuhi sifat max/min heap property. Beberapa variasi heapify adalah:\n\nbottom-up: dimulai dari suatu leaf node yang ditentukan, periksa dengan parentnya. Kemudian, periksa parent tersebut dengan parent dari parent tersebut. Terus ke atas hingga mencapai root.\ntop-down: dimulai dari root,\n\nuntuk max heap: periksa dengan yang terbesar di antara semua child nya. Kemudian, periksa child tersebut dengan yang terbesar di antara semua child nya. Terus ke bawah, berhenti ketika sudah mencapai suatu leaf node.\nuntuk min heap: periksa dengan yang terkecil di antara semua child nya. Kemudian, periksa child tersebut dengan yang terkecil di antara semua child nya. Terus ke bawah, berhenti ketika sudah mencapai suatu leaf node.\n\nheapify all: periksa tiap node dengan parentnya, dimulai dari level terdalam, dimulai dari node paling kanan. Lanjut ke tiap node yang ada di sebelah kirinya, hingga level tersebut sudah diperiksa semua. Kemudian, lanjut ke level di atasnya, dimulai dari node yang paling kanan. Lanjut terus hingga mencapai root.\n\nPada heap tree, operasi insertion selalu diikuti dengan heapify yang bottom-up, dan operasi deletion selalu diikuti dengan heapify yang top-down.\nApabila diberikan sembarang binary tree, di antara ketiga variasi di atas, hanya heapify all yang menjamin binary tree berubah menjadi heap tree. Namun, apabila diberikan sembarang heap tree, operasi insertion dan deletion yang dilakukan (masing-masing diikuti heapify yang bottom-up atau top-down) akan tetap menjaga sifatnya sebagai heap tree, meskipun tidak dilakukan heapify all sama sekali.\nKalau ingin mengubah sembarang binary tree menjadi heap tree, kami menyediakan method bernama completify untuk membuat binary tree tersebut menjadi complete, yang kemudian bisa diikuti dengan penggunaan heapify all.\nKita akan mengimplementasikan heap tree dengan array. Karena heap tree adalah sejenis binary tree, kita bisa membuat class ArrayMaxHeap dan class ArrayMinHeap yang sama-sama meng-inherit dari class ArrayBintree dari Modul 8.\n\n\n\nclass ArrayMaxHeap(ArrayBintree):\n    def __init__(self, dtype, height, emptydata=-9999):\n        # menggunakan __init__ dari ArrayBintree,\n        # melalui super() yaitu parent class\n        super().__init__(dtype, height, emptydata)\n\n        # atribut tambahan: banyaknya node yang sudah ada\n        self.n_nodes = 0\n    \n    # semua method dari ArrayBintree otomatis sudah terdefinisi\n\n    # Memeriksa apakah dua nilai (parent, child) memenuhi max heap property\n    def is_correct_parent_child_data(self, parent_data, child_data):\n        if (parent_data &gt;= child_data):\n            return True\n        else:\n            return False\n\n    # Membuat binary tree menjadi complete (atau almost complete)\n    # Idenya, tiap elemen yang bukan \"data kosong\" harus didempetkan ke kiri\n    def completify(self):\n        # Sangat mirip dengan insertion sort, hanya saja syaratnya yang beda\n        for i in range(self.array_size): # i = 0, 1, 2, ..., n-1\n            for j in range(i, 0, -1): # j = i, i-1, ..., 2, 1\n                if ((self.array[j] != self.emptydata)\n                    and (self.array[j-1] == self.emptydata)):\n                    self.array[j-1] = self.array[j]\n                    self.array[j] = self.emptydata\n        # Setelah selesai, tentukan nilai n_nodes\n        i = 0\n        while (i &lt; self.array_size) and (self.array[i] != self.emptydata):\n            i += 1\n        self.n_nodes = i\n\n    # Pastikan, dari leaf tertentu ke atas, bahwa heap tree memang memenuhi\n    # heap property\n    def heapify_bottomup(self, child_idx):\n        if child_idx &gt; 0:\n            parent_idx = self.get_parent_idx(child_idx)\n            if not (self.is_correct_parent_child_data(\n                self.array[parent_idx], self.array[child_idx]\n                )): # Jika tidak memenuhi heap property, tukar\n                temp = self.array[parent_idx]\n                self.array[parent_idx] = self.array[child_idx]\n                self.array[child_idx] = temp\n            # heapify parent nya\n            self.heapify_bottomup(parent_idx)\n\n    def insert(self, newdata):\n        if self.n_nodes == self.array_size:\n            print(\"Error insert: array heap sudah penuh\")\n        else:\n            self.array[self.n_nodes] = newdata\n            self.heapify_bottomup(self.n_nodes)\n            self.n_nodes += 1\n    \n    # Pastikan, dari atas ke bawah, bahwa heap tree memang memenuhi\n    # heap property\n    def heapify_topdown(self, parent_idx=None):\n        # Awalnya mulai dari root\n        if parent_idx == None:\n            parent_idx = 0\n        \n        # Menentukan yang mana antara left child atau right child yang\n        # lebih layak menjadi parent\n        left_idx = self.get_left_child_idx(parent_idx)\n        right_idx = self.get_right_child_idx(parent_idx)\n\n        if ((left_idx != -1) and (right_idx != -1)\n            and (self.array[left_idx] != self.emptydata)\n            and (self.array[right_idx] != self.emptydata)):\n            # Kasus dua child, mana yang lebih layak jadi parent?\n            # (memperhatikan heap property)\n            if self.is_correct_parent_child_data(\n                self.array[left_idx], self.array[right_idx]\n                ): # Jika left child lebih layak, pilih itu\n                child_idx = left_idx\n            else:\n                child_idx = right_idx\n        elif (left_idx != -1) and (self.array[left_idx] != self.emptydata):\n            # Hanya satu child yaitu yang kiri, pilih saja\n            child_idx = left_idx\n        elif (right_idx != -1) and (self.array[right_idx] != self.emptydata):\n            # Hanya satu child yaitu yang kanan, pilih saja\n            child_idx = right_idx\n        else: # tidak punya child; top down selesai\n            return\n\n        # Kalau child yang dipilih bahkan lebih layak daripada parent sekarang,\n        # tukar agar heap property menjadi terpenuhi\n        if self.is_correct_parent_child_data(\n            self.array[child_idx], self.array[parent_idx]\n            ):\n            temp = self.array[child_idx]\n            self.array[child_idx] = self.array[parent_idx]\n            self.array[parent_idx] = temp\n        \n        # Lanjutkan heapify pada child tersebut\n        self.heapify_topdown(child_idx)\n    \n    # Mengintip apa yang ada di root\n    def peek(self):\n        nilai = self.get_root()\n        if nilai == self.emptydata:\n            print(\"Error peek: heap tree sedang kosong\")\n            return None\n        else:\n            return nilai\n\n    # Delete root\n    def delete(self):\n        # 1. Peroleh nilai root untuk di-return\n        nilai_root = self.get_root()\n\n        # Kalau ternyata sudah kosong sebelumnya, tidak ada yang bisa dihapus\n        if nilai_root == self.emptydata:\n            print(\"Error delete: heap tree sudah kosong sebelumnya\")\n            return None\n        # Kalau tidak kosong, lanjut\n\n        # 2. Ganti nilai di root dengan elemen ter-kanan di array\n        self.set_root(self.array[self.n_nodes-1])\n\n        # 3. \"Hapus\" elemen ter-kanan tersebut\n        self.array[self.n_nodes-1] = self.emptydata\n        self.n_nodes -= 1\n\n        # 4. Lakukan heapify dari root ke bawah\n        self.heapify_topdown()\n\n        # 5. return nilai yang baru saja dihapus\n        return nilai_root\n\n    # Heapify untuk semua node\n    def heapify_all(self):\n        # Periksa dari node ter-kanan hingga node ter-kiri (kecuali root)\n        for child_idx in range(self.n_nodes, 0, -1): # i = n, n-1, ..., 2, 1\n            parent_idx = self.get_parent_idx(child_idx)\n            # Jika heap property tidak terpenuhi, tukar\n            if not (self.is_correct_parent_child_data(\n                self.array[parent_idx], self.array[child_idx]\n                )):\n                temp = self.array[parent_idx]\n                self.array[parent_idx] = self.array[child_idx]\n                self.array[child_idx] = temp\n\nMengubah suatu binary tree (representasi array) menjadi heap tree\n\nbintree1 = ArrayMaxHeap(int, 3)\n\n\nlist1 = [15, 22, 14, 75, -9999, 67, -9999, 32]\nfor i in range(len(list1)):\n    bintree1.array[i] = list1[i]\n\n\nprint(bintree1.array)\n\n[   15    22    14    75 -9999    67 -9999    32 -9999 -9999 -9999 -9999\n -9999 -9999 -9999]\n\n\n\ndisplay(bintree1.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nbintree1.completify()\n\n\nprint(bintree1.array)\n\n[   15    22    14    75    67    32 -9999 -9999 -9999 -9999 -9999 -9999\n -9999 -9999 -9999]\n\n\n\ndisplay(bintree1.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nbintree1.array[4]\n\n67\n\n\n\nbintree1.heapify_bottomup(4)\n\n\ndisplay(bintree1.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nbintree1.heapify_topdown()\n\n\ndisplay(bintree1.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nprint(bintree1.array)\n\n[   67    75    14    15    22    32 -9999 -9999 -9999 -9999 -9999 -9999\n -9999 -9999 -9999]\n\n\n\nbintree1.array[5]\n\n32\n\n\n\nbintree1.heapify_bottomup(5)\n\n\ndisplay(bintree1.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nbintree1.heapify_all()\n\n\ndisplay(bintree1.get_digraph_simple())\n\n\n\n\n\n\n\n\nMembangun max heap baru dari awal\n\narraymaxheap = ArrayMaxHeap(int, 4)\n\n\narraymaxheap.insert(50)\n\n\ndisplay(arraymaxheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraymaxheap.insert(40)\n\n\ndisplay(arraymaxheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraymaxheap.insert(70)\n\n\ndisplay(arraymaxheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraymaxheap.insert(45)\n\n\ndisplay(arraymaxheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraymaxheap.insert(60)\n\n\ndisplay(arraymaxheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraymaxheap.delete()\n\n70\n\n\n\ndisplay(arraymaxheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraymaxheap.delete()\n\n60\n\n\n\ndisplay(arraymaxheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\n\n\nDibandingkan dengan implementasi max heap di atas, hanya dua hal yang perlu diubah untuk memperoleh implementasi min heap:\n\nUbah nama class dari ArrayMaxHeap menjadi ArrayMinHeap\nModifikasi deinisi fungsi is_correct_parent_child_data di bagian (parent_data &gt;= child_data) menjadi (parent_data &lt;= child_data) (agar menggunakan min heap property daripada max heap property)\n\n\nclass ArrayMinHeap(ArrayBintree):\n    def __init__(self, dtype, height, emptydata=-9999):\n        # menggunakan __init__ dari ArrayBintree,\n        # melalui super() yaitu parent class\n        super().__init__(dtype, height, emptydata)\n\n        # atribut tambahan: banyaknya node yang sudah ada\n        self.n_nodes = 0\n    \n    # semua method dari ArrayBintree otomatis sudah terdefinisi\n\n    # Memeriksa apakah dua nilai (parent, child) memenuhi min heap property\n    def is_correct_parent_child_data(self, parent_data, child_data):\n        if (parent_data &lt;= child_data):\n            return True\n        else:\n            return False\n\n    # Membuat binary tree menjadi complete (atau almost complete)\n    # Idenya, tiap elemen yang bukan \"data kosong\" harus didempetkan ke kiri\n    def completify(self):\n        # Sangat mirip dengan insertion sort, hanya saja syaratnya yang beda\n        for i in range(self.array_size): # i = 0, 1, 2, ..., n-1\n            for j in range(i, 0, -1): # j = i, i-1, ..., 2, 1\n                if ((self.array[j] != self.emptydata)\n                    and (self.array[j-1] == self.emptydata)):\n                    self.array[j-1] = self.array[j]\n                    self.array[j] = self.emptydata\n        # Setelah selesai, tentukan nilai n_nodes\n        i = 0\n        while (i &lt; self.array_size) and (self.array[i] != self.emptydata):\n            i += 1\n        self.n_nodes = i\n\n    # Pastikan, dari leaf tertentu ke atas, bahwa heap tree memang memenuhi\n    # heap property\n    def heapify_bottomup(self, child_idx):\n        if child_idx &gt; 0:\n            parent_idx = self.get_parent_idx(child_idx)\n            if not (self.is_correct_parent_child_data(\n                self.array[parent_idx], self.array[child_idx]\n                )): # Jika tidak memenuhi heap property, tukar\n                temp = self.array[parent_idx]\n                self.array[parent_idx] = self.array[child_idx]\n                self.array[child_idx] = temp\n            # heapify parent nya\n            self.heapify_bottomup(parent_idx)\n\n    def insert(self, newdata):\n        if self.n_nodes == self.array_size:\n            print(\"Error insert: array heap sudah penuh\")\n        else:\n            self.array[self.n_nodes] = newdata\n            self.heapify_bottomup(self.n_nodes)\n            self.n_nodes += 1\n    \n    # Pastikan, dari atas ke bawah, bahwa heap tree memang memenuhi\n    # heap property\n    def heapify_topdown(self, parent_idx=None):\n        # Awalnya mulai dari root\n        if parent_idx == None:\n            parent_idx = 0\n        \n        # Menentukan yang mana antara left child atau right child yang\n        # lebih layak menjadi parent\n        left_idx = self.get_left_child_idx(parent_idx)\n        right_idx = self.get_right_child_idx(parent_idx)\n\n        if ((left_idx != -1) and (right_idx != -1)\n            and (self.array[left_idx] != self.emptydata)\n            and (self.array[right_idx] != self.emptydata)):\n            # Kasus dua child, mana yang lebih layak jadi parent?\n            # (memperhatikan heap property)\n            if self.is_correct_parent_child_data(\n                self.array[left_idx], self.array[right_idx]\n                ): # Jika left child lebih layak, pilih itu\n                child_idx = left_idx\n            else:\n                child_idx = right_idx\n        elif (left_idx != -1) and (self.array[left_idx] != self.emptydata):\n            # Hanya satu child yaitu yang kiri, pilih saja\n            child_idx = left_idx\n        elif (right_idx != -1) and (self.array[right_idx] != self.emptydata):\n            # Hanya satu child yaitu yang kanan, pilih saja\n            child_idx = right_idx\n        else: # tidak punya child; top down selesai\n            return\n\n        # Kalau child yang dipilih bahkan lebih layak daripada parent sekarang,\n        # tukar agar heap property menjadi terpenuhi\n        if self.is_correct_parent_child_data(\n            self.array[child_idx], self.array[parent_idx]\n            ):\n            temp = self.array[child_idx]\n            self.array[child_idx] = self.array[parent_idx]\n            self.array[parent_idx] = temp\n        \n        # Lanjutkan heapify pada child tersebut\n        self.heapify_topdown(child_idx)\n    \n    # Mengintip apa yang ada di root\n    def peek(self):\n        nilai = self.get_root()\n        if nilai == self.emptydata:\n            print(\"Error peek: heap tree sedang kosong\")\n            return None\n        else:\n            return nilai\n\n    # Delete root\n    def delete(self):\n        # 1. Peroleh nilai root untuk di-return\n        nilai_root = self.get_root()\n\n        # Kalau ternyata sudah kosong sebelumnya, tidak ada yang bisa dihapus\n        if nilai_root == self.emptydata:\n            print(\"Error delete: heap tree sudah kosong sebelumnya\")\n            return None\n        # Kalau tidak kosong, lanjut\n\n        # 2. Ganti nilai di root dengan elemen ter-kanan di array\n        self.set_root(self.array[self.n_nodes-1])\n\n        # 3. \"Hapus\" elemen ter-kanan tersebut\n        self.array[self.n_nodes-1] = self.emptydata\n        self.n_nodes -= 1\n\n        # 4. Lakukan heapify dari root ke bawah\n        self.heapify_topdown()\n\n        # 5. return nilai yang baru saja dihapus\n        return nilai_root\n\n    # Heapify untuk semua node\n    def heapify_all(self):\n        # Periksa dari node ter-kanan hingga node ter-kiri (kecuali root)\n        for child_idx in range(self.n_nodes, 0, -1): # i = n, n-1, ..., 2, 1\n            parent_idx = self.get_parent_idx(child_idx)\n            # Jika heap property tidak terpenuhi, tukar\n            if not (self.is_correct_parent_child_data(\n                self.array[parent_idx], self.array[child_idx]\n                )):\n                temp = self.array[parent_idx]\n                self.array[parent_idx] = self.array[child_idx]\n                self.array[child_idx] = temp\n\n\narrayminheap = ArrayMinHeap(int, 3)\n\n\narrayminheap.insert(78)\n\n\ndisplay(arrayminheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narrayminheap.insert(43)\n\n\ndisplay(arrayminheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narrayminheap.insert(21)\n\n\ndisplay(arrayminheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narrayminheap.insert(39)\n\n\ndisplay(arrayminheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narrayminheap.insert(15)\n\n\ndisplay(arrayminheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narrayminheap.delete()\n\n15\n\n\n\ndisplay(arrayminheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narrayminheap.delete()\n\n21\n\n\n\ndisplay(arrayminheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\n\n\n\nSuatu AVL tree, terkadang juga disebut balance tree, adalah semacam binary search tree (BST) dengan pertimbangan tambahan ketika insertion maupun deletion, yaitu dilakukan yang namanya re-balancing agar pohon tidak terlalu “berat sebelah”. Re-balancing di AVL tree dilakukan dengan yang namanya “rotasi” (rotation) terhadap node tertentu, bisa ke kiri (left rotation) ataupun ke kanan (right rotation).\nKapan dilakukannya re-balancing, tergantung suatu ukuran yang disebut balance factor, yang dimiliki oleh tiap node, dan dihitung sebagai selisih antara height dari left subtree dengan height dari right subtree. Balance factor diharapkan tidak kurang dari -1 dan tidak lebih dari 1; kalau aturan ini dilanggar (misalnya ketika insertion maupun deletion), barulah dilakukan re-balancing dengan rotation yang sesuai agar semua balance factor kembali mematuhi aturan tersebut.\nPada AVL tree, ketika ada pelanggaran nilai balance factor, ada empat kemungkinan kasus: LL, LR, RL, dan RR, di mana L artinya left dan R artinya right. Di antara empat kasus tersebut, tindakan re-balancing yang dilakukan bisa berupa satu ataupun dua rotasi, dan tiap rotasi bisa berupa rotasi kiri atau rotasi kanan, tergantung kasusnya.\nFun fact: AVL adalah singkatan dari dua penemunya, Georgy Maximovich Adelson-Velsky dan Evgenii Mikhailovich Landis.\nKarena AVL tree adalah modifikasi dari binary search tree (BST), di bawah ini, diimplementasikan class LinkedAVL yang meng-inherit dari class LinkedBST dari Modul 8.\n\n\n\nclass LinkedAVL(LinkedBST):\n    def __init__(self):\n        # menggunakan __init__ dari LinkedBST,\n        # melalui super() yaitu parent class\n        super().__init__()\n\n    def get_node_height(self, node):\n        if node == None:\n            return -1\n        left_height = self.get_node_height(node.left)\n        right_height = self.get_node_height(node.right)\n        node_height = 1 + max(left_height, right_height)\n        return node_height\n\n    def get_tree_height(self):\n        return self.get_node_height(self.root)\n\n    def get_balance_factor(self, node):\n        if node == None:\n            return 0\n        left_height = self.get_node_height(node.left)\n        right_height = self.get_node_height(node.right)\n        balance_factor = left_height - right_height\n        return balance_factor\n\n    def left_rotate(self, x):\n        #  x\n        #   \\\n        #    y\n        #   / \\\n        #  S   z\n        y = x.right\n        S = y.left # left subtree dari y\n\n        # rotate\n        y.left = x\n        x.right = S\n        #   y\n        #  / \\\n        # x   z\n        #  \\\n        #   S\n\n        # root baru\n        return y\n\n    def right_rotate(self, x):\n        #     x\n        #    /\n        #   y\n        #  / \\\n        # z   S\n        y = x.left\n        S = y.right # right subtree dari y\n\n        # rotate\n        y.right = x\n        x.left = S\n        #   y\n        #  / \\\n        # z   x\n        #    /\n        #   S\n\n        # root baru\n        return y\n\n    # Kali ini insert harus secara rekursif\n    # agar bisa sekaligus melakukan re-balancing secara bottom-up\n    def insert(self, newdata):\n        if self.search(newdata) == None: # jika data belum ada, boleh insert\n            self.root = self.insert_rec(newdata, current=self.root)\n        else:\n            print(\"Error insert: data sudah ada di AVL tree, yaitu\", newdata)\n    def insert_rec(self, newdata, current):\n        if current == None:\n            return BintreeNode(newdata)\n        elif newdata &lt; current.data:\n            current.left = self.insert_rec(newdata, current=current.left)\n        else: # newdata &gt; temp.data\n            current.right = self.insert_rec(newdata, current=current.right)\n        \n        cur_BF = self.get_balance_factor(current)\n        left_BF = self.get_balance_factor(current.left)\n        right_BF = self.get_balance_factor(current.right)\n\n        # re-balancing, bagi kasus tergantung balance factor\n        if (cur_BF &gt; 1 and left_BF &gt; 0): # kasus LL\n            #        current\n            #       /\n            #   left\n            #  /\n            # n\n\n            # solusi: right rotate current\n            return self.right_rotate(current)\n            #   left\n            #  /    \\\n            # n      current\n        \n        elif (cur_BF &gt; 1 and left_BF &lt;= 0): # kasus LR\n            #      current\n            #     /\n            # left\n            #     \\\n            #      n\n            #       \\\n            #        S\n\n            # S: subtree\n            \n            # solusi\n            # step 1: left rotate left child\n            current.left = self.left_rotate(current.left)\n            #        current\n            #       /\n            #      n\n            #     / \\\n            # left   S\n\n            # step 2: right rotate current\n            return self.right_rotate(current)\n            #      n\n            #     / \\\n            # left   current\n            #       /\n            #      S\n\n        elif (cur_BF &lt; -1 and right_BF &lt;= 0): # kasus RR\n            # current\n            #        \\\n            #         right\n            #        /     \\\n            #       S       n\n\n            # S: subtree\n\n            # solusi: left rotate current\n            return self.left_rotate(current)\n            #         right\n            #        /     \\\n            # current       n\n            #              /\n            #             S\n\n        elif (cur_BF &lt; -1 and right_BF &gt; 0): # kasus RL\n            # current\n            #        \\\n            #         right\n            #        /\n            #       n\n            #      /\n            #     S\n\n            # S: subtree\n\n            # solusi\n            # step 1: right rotate right child\n            current.right = self.right_rotate(current.right)\n            # current\n            #        \\\n            #         n\n            #        / \\\n            #       S   right\n\n            # step 2: left rotate current\n            return self.right_rotate(current)\n            #         n\n            #        / \\\n            # current   right\n            #          /\n            #         S\n\n        return current\n\n    # Deletion juga secara rekursif\n    # agar sekaligus melakukan re-balancing secara bottom-up\n    def delete(self, x, inorder_pred=False):\n        if self.search(x) != None:\n            self.root = self.delete_rec(x, current=self.root,\n                                        inorder_pred=inorder_pred)\n        else:\n            print(\"Error delete: tidak ditemukan data\", x)\n    def delete_rec(self, x, current, inorder_pred=False):\n        if current == None:\n            return current\n        elif x &lt; current.data:\n            current.left = self.delete_rec(x, current=current.left,\n                                           inorder_pred=inorder_pred)\n        elif x &gt; current.data:\n            current.right = self.delete_rec(x, current=current.right,\n                                            inorder_pred=inorder_pred)\n        # untuk elif/else berikut ini, x == current.data, sehingga dihapus\n        elif current.left == None: # hanya satu child (kanan)\n            temp = current.right\n            del current\n            return temp\n        elif current.right == None: # hanya satu child (kiri)\n            temp = current.left\n            del current\n            return temp\n\n        # dua child\n        elif inorder_pred: # metode inorder predecessor\n            inorder_left = []\n            self.get_inorder(current=current.left, result=inorder_left)\n            inorder_pred_val = inorder_left[-1]\n\n            current.data = inorder_pred_val\n            current.left = self.delete_rec(\n                inorder_pred_val, current=current.left,\n                inorder_pred=inorder_pred\n            )\n        else: # metode inorder succcessor\n            inorder_right = []\n            self.get_inorder(current=current.right, result=inorder_right)\n            inorder_succ_val = inorder_right[0]\n\n            current.data = inorder_succ_val\n            current.right = self.delete_rec(\n                inorder_succ_val, current=current.right,\n                inorder_pred=inorder_pred\n            )\n        \n        cur_BF = self.get_balance_factor(current)\n        left_BF = self.get_balance_factor(current.left)\n        right_BF = self.get_balance_factor(current.right)\n\n        # re-balancing, bagi kasus tergantung balance factor\n        if (cur_BF &gt; 1 and left_BF &gt; 0): # kasus LL\n            # solusi: right rotate current\n            return self.right_rotate(current)\n        elif (cur_BF &gt; 1 and left_BF &lt;= 0): # kasus LR\n            # step 1: left rotate left child\n            current.left = self.left_rotate(current.left)\n            # step 2: right rotate current\n            return self.right_rotate(current)\n        elif (cur_BF &lt; -1 and right_BF &lt;= 0): # kasus RR\n            # solusi: left rotate current\n            return self.left_rotate(current)\n        elif (cur_BF &lt; -1 and right_BF &gt; 0): # kasus RL\n            # step 1: right rotate right child\n            current.right = self.right_rotate(current.right)\n            # step 2: left rotate current\n            return self.right_rotate(current)\n\n        return current\n\n\nlinkedavl = LinkedAVL()\n\n\nlinkedavl.insert(2)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.insert(1)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.insert(5)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.insert(3)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.insert(7)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.insert(10)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.delete(7)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.delete(2)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.delete(5)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass ArrayBintree:\n    def __init__(self, dtype, height, emptydata=-9999):\n        self.dtype = dtype\n        self.height = height\n        self.emptydata = emptydata\n        self.array_size = 2**(height+1) - 1\n        self.array = np.empty(self.array_size, dtype=dtype)\n        for i in range(self.array_size):\n            self.array[i] = emptydata\n\n    def get_root(self):\n        root_data = self.array[0]\n        if root_data == self.emptydata:\n            return None\n        else:\n            return root_data\n\n    def set_root(self, newdata):\n        self.array[0] = newdata\n\n    def get_data(self, node_idx):\n        if node_idx &lt; self.array_size:\n            return self.array[node_idx]\n        else:\n            print(\"Error get_data: indeks di luar ukuran tree\")\n            return None\n\n    def set_data(self, node_idx, newdata):\n        if node_idx &lt; self.array_size:\n            self.array[node_idx] = newdata\n        else:\n            print(\"Error set_data: indeks di luar ukuran tree\")\n\n    def get_left_child_idx(self, node_idx):\n        left_idx = 2*node_idx + 1\n        if left_idx &lt; self.array_size:\n            return left_idx\n        else:\n            return -1\n\n    def get_left_child(self, node_idx):\n        left_idx = self.get_left_child_idx(node_idx)\n        if left_idx != -1:\n            data = self.array[left_idx]\n            if data != self.emptydata:\n                return data\n            else:\n                return None\n        else:\n            return None\n\n    def get_right_child_idx(self, node_idx):\n        right_idx = 2*node_idx + 2\n        if right_idx &lt; self.array_size:\n            return right_idx\n        else:\n            return -1\n\n    def get_right_child(self, node_idx):\n        right_idx = self.get_right_child_idx(node_idx)\n        if right_idx != -1:\n            data = self.array[right_idx]\n            if data != self.emptydata:\n                return data\n            else:\n                return None\n        else:\n            return None\n\n    def get_parent_idx(self, node_idx):\n        if node_idx == 0:\n            return -1\n        idx = int(np.floor( (node_idx - 1)/2 ))\n        return idx\n\n    # preorder: tengah, kiri, kanan\n    def get_preorder(self, current=0, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n\n        # tengah\n        current_data = self.array[current]\n        if current_data != self.emptydata:\n            result.append(current_data)\n\n        # kiri\n        left_idx = self.get_left_child_idx(current)\n        if left_idx != -1:\n            self.get_preorder(current=left_idx, result=result)\n\n        # kanan\n        right_idx = self.get_right_child_idx(current)\n        if right_idx != -1:\n            self.get_preorder(current=right_idx, result=result)\n\n        if is_starting_node:\n            return result\n\n    # inorder: kiri, tengah, kanan\n    def get_inorder(self, current=0, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n\n        # kiri\n        left_idx = self.get_left_child_idx(current)\n        if left_idx != -1:\n            self.get_inorder(current=left_idx, result=result)\n\n        # tengah\n        current_data = self.array[current]\n        if current_data != self.emptydata:\n            result.append(current_data)\n\n        # kanan\n        right_idx = self.get_right_child_idx(current)\n        if right_idx != -1:\n            self.get_inorder(current=right_idx, result=result)\n\n        if is_starting_node:\n            return result\n\n    # postorder: kiri, kanan, tengah\n    def get_postorder(self, current=0, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n\n        # kiri\n        left_idx = self.get_left_child_idx(current)\n        if left_idx != -1:\n            self.get_postorder(current=left_idx, result=result)\n\n        # kanan\n        right_idx = self.get_right_child_idx(current)\n        if right_idx != -1:\n            self.get_postorder(current=right_idx, result=result)\n\n        # tengah\n        current_data = self.array[current]\n        if current_data != self.emptydata:\n            result.append(current_data)\n\n        if is_starting_node:\n            return result\n\n    def get_digraph_simple(self):\n        digraph = gv.Digraph()\n        for idx in range(self.array_size):\n            data = self.array[idx]\n            if data != self.emptydata:\n                digraph.node(\"node\" + str(idx), label=str(data))\n                left_idx = self.get_left_child_idx(idx)\n                right_idx = self.get_right_child_idx(idx)\n                if left_idx != -1:\n                    digraph.edge(\"node\" + str(idx), \"node\" + str(left_idx))\n                    if self.array[left_idx] == self.emptydata:\n                        digraph.node(\"node\" + str(left_idx), label=\"NULL\", shape=\"none\")\n                if right_idx != -1:\n                    digraph.edge(\"node\" + str(idx), \"node\" + str(right_idx))\n                    if self.array[right_idx] == self.emptydata:\n                        digraph.node(\"node\" + str(right_idx), label=\"NULL\", shape=\"none\")\n        return digraph\n\n\n\n\n\nclass BintreeNode:\n    def __init__(self, data, left=None, right=None):\n        self.data = data\n        self.left = left\n        self.right = right\n\n\nclass LinkedBintree:\n    def __init__(self):\n        self.root = None\n\n    def is_empty(self):\n        if self.root == None:\n            return True\n        else:\n            return False\n\n    def get_root_data(self):\n        if self.is_empty():\n            print(\"Error get_root_data: tree sedang kosong\")\n            return None\n        else:\n            return self.root.data\n\n    def set_root_data(self, newdata):\n        if self.is_empty():\n            self.root = BintreeNode(newdata)\n        else:\n            self.root.data = newdata\n\n    # preorder: tengah, kiri, kanan\n    def get_preorder(self, current=None, result=None, get_addresses=False):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n            current = self.root\n\n        if current != None:\n            # tengah\n            if (not get_addresses):\n                result.append(current.data)\n            else:\n                result.append(current)\n\n            # kiri\n            if current.left != None:\n                self.get_preorder(current.left, result=result)\n            \n            # kanan\n            if current.right != None:\n                self.get_preorder(current.right, result=result)\n\n        if is_starting_node:\n            return result\n\n    # inorder: kiri, tengah, kanan\n    def get_inorder(self, current=None, result=None, get_addresses=False):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n            current = self.root\n\n        if current != None:\n            # kiri\n            if current.left != None:\n                self.get_inorder(current.left, result=result)\n            \n            # tengah\n            if (not get_addresses):\n                result.append(current.data)\n            else:\n                result.append(current)\n\n            # kanan\n            if current.right != None:\n                self.get_inorder(current.right, result=result)\n\n        if is_starting_node:\n            return result\n\n    # postorder: kiri, kanan, tengah\n    def get_postorder(self, current=None, result=None, get_addresses=False):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n            current = self.root\n\n        if current != None:\n            # kiri\n            if current.left != None:\n                self.get_postorder(current.left, result=result)\n            \n            # kanan\n            if current.right != None:\n                self.get_postorder(current.right, result=result)\n\n            # tengah\n            if (not get_addresses):\n                result.append(current.data)\n            else:\n                result.append(current)\n\n        if is_starting_node:\n            return result\n\n    # berdasarkan algoritma preorder traversal :D\n    def get_digraph_simple(self, current=None, node_name=None, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = gv.Digraph()\n            current = self.root\n            node_name = \"root\"\n        \n        if current != None:\n            # tengah\n            result.node(node_name, label=str(current.data))\n\n            # kiri\n            left_name = node_name + \"-&gt;left\"\n            result.edge(node_name, left_name)\n            self.get_digraph_simple(\n                current=current.left, node_name=left_name, result=result\n            )\n            \n            # kanan\n            right_name = node_name + \"-&gt;right\"\n            self.get_digraph_simple(\n                current=current.right, node_name=right_name, result=result\n            )\n            result.edge(node_name, right_name)\n        else:\n            result.node(node_name, label=\"NULL\", shape=\"none\")\n        \n        if is_starting_node:\n            return result\n\n\nclass LinkedBST(LinkedBintree):\n    def __init__(self):\n        # menggunakan __init__ dari parent class,\n        # melalui super() yaitu parent class\n        super().__init__()\n    \n    # semua method dari LinkedBintree otomatis sudah terdefinisi\n\n    # cari elemen di BST\n    def search(self, x):\n        temp = self.root\n        while (temp != None):\n            if x == temp.data:\n                return x\n            elif x &lt; temp.data:\n                temp = temp.left\n            else:\n                temp = temp.right\n        return None\n\n    # insertion\n    def insert(self, newdata):\n        if self.root == None:\n            self.root = BintreeNode(newdata)\n            return\n        temp = self.root\n        while (temp != None):\n            if newdata == temp.data:\n                print(\"Error insert: data sudah ada di BST, yaitu\", newdata)\n                return\n            elif newdata &lt; temp.data:\n                if temp.left == None:\n                    temp.left = BintreeNode(newdata)\n                    return\n                else:\n                    temp = temp.left\n            else: # newdata &gt; temp.data\n                if temp.right == None:\n                    temp.right = BintreeNode(newdata)\n                    return\n                else:\n                    temp = temp.right\n\n    # deletion\n    def delete(self, x, inorder_pred=False):\n        if self.is_empty():\n            print(\"Error: BST kosong\")\n            return\n        prev = self.root\n        turn = \"\"\n        if x &lt; prev.data:\n            if prev.left == None:\n                print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                return\n            else:\n                temp = prev.left\n                turn = \"left\"\n        elif x &gt; prev.data:\n            if prev.right == None:\n                print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                return\n            else:\n                temp = prev.right\n                turn = \"right\"\n        else:\n            temp = prev\n        \n        while (temp != None):\n            if temp.data == x:\n                break\n            elif x &lt; temp.data:\n                if temp.left == None:\n                    print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                    return\n                else:\n                    prev = temp\n                    temp = temp.left\n                    turn = \"left\"\n            else: # x &gt; temp.data\n                if temp.right == None:\n                    print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                    return\n                else:\n                    prev = temp\n                    temp = temp.right\n                    turn = \"right\"\n        \n        # kasus 0 children\n        if (temp.left == None) and (temp.right == None):\n            if turn == \"left\":\n                prev.left = None\n            elif turn == \"right\":\n                prev.right = None\n            del temp\n            return\n\n        # kasus 1 child, di kiri\n        elif (temp.left != None) and (temp.right == None):\n            if turn == \"left\":\n                prev.left = temp.left\n            elif turn == \"right\":\n                prev.right = temp.left\n            del temp\n            return\n        \n        # kasus 1 child, di kanan\n        elif (temp.left == None) and (temp.right != None):\n            if turn == \"left\":\n                prev.left = temp.right\n            elif turn == \"right\":\n                prev.right = temp.right\n            del temp\n            return\n        \n        # kasus 2 children\n        elif inorder_pred: # metode inorder predecessor (left subtree)\n            inorder_left = []\n            self.get_inorder(current=temp.left, result=inorder_left)\n            replacement = inorder_left[-1] # elemen terakhir\n            self.delete(replacement, inorder_pred=inorder_pred)\n            temp.data = replacement\n            return\n        else: # metode inorder successor (right subtree)\n            inorder_right = []\n            self.get_inorder(current=temp.right, result=inorder_right)\n            replacement = inorder_right[0]\n            self.delete(replacement, inorder_pred=inorder_pred)\n            temp.data = replacement\n            return"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09.html#implementasi-heap-tree-dengan-array",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09.html#implementasi-heap-tree-dengan-array",
    "title": "Modul 9 Struktur Data: Heap Tree, AVL/Balance Tree",
    "section": "",
    "text": "Heap tree adalah sejenis binary tree dengan beberapa sifat tambahan tertentu. Heap tree terbagi lagi menjadi dua jenis, yaitu max heap dan min heap.\n\nMax heap adalah binary tree dengan sifat tambahan berikut:\n\nmerupakan tree yang complete (terkadang disebut almost complete), yaitu tiap level (kecuali level terakhir) harus terisi penuh, sedangkan pengisian node di level terakhir harus dari paling kiri.\n(Max Heap Property) Untuk tiap node, nilai data yang tersimpan di node tersebut harus lebih besar daripada (atau sama dengan) nilai data yang tersimpan di tiap child nya.\n\nDengan demikian, pada max heap, data dengan nilai terbesar ada di root.\nMin heap adalah binary tree dengan sifat tambahan berikut:\n\nmerupakan tree yang complete (terkadang disebut almost complete)\n(Min Heap Property) Untuk tiap node, nilai data yang tersimpan di node tersebut harus lebih kecil daripada (atau sama dengan) nilai data yang tersimpan di tiap child nya.\n\nDengan demikian, pada min heap, data dengan nilai terkecil ada di root.\n\nBeberapa hal lain tentang heap tree:\n\nKetika membahas deletion, yang dihapus sudah pasti root, dan nilai yang dihapus juga di-return (seperti operasi pop di stack).\nInsertion selalu dilakukan di level paling dalam, tepat di sebelah kanan dari node yang sudah ada (agar tree tetap beersifat complete).\n\nSelama berurusan dengan heap tree, ada (sekumpulan) operasi bernama heapify, yang tujuannya adalah memastikan bahwa heap tree memang memenuhi sifat max/min heap property. Beberapa variasi heapify adalah:\n\nbottom-up: dimulai dari suatu leaf node yang ditentukan, periksa dengan parentnya. Kemudian, periksa parent tersebut dengan parent dari parent tersebut. Terus ke atas hingga mencapai root.\ntop-down: dimulai dari root,\n\nuntuk max heap: periksa dengan yang terbesar di antara semua child nya. Kemudian, periksa child tersebut dengan yang terbesar di antara semua child nya. Terus ke bawah, berhenti ketika sudah mencapai suatu leaf node.\nuntuk min heap: periksa dengan yang terkecil di antara semua child nya. Kemudian, periksa child tersebut dengan yang terkecil di antara semua child nya. Terus ke bawah, berhenti ketika sudah mencapai suatu leaf node.\n\nheapify all: periksa tiap node dengan parentnya, dimulai dari level terdalam, dimulai dari node paling kanan. Lanjut ke tiap node yang ada di sebelah kirinya, hingga level tersebut sudah diperiksa semua. Kemudian, lanjut ke level di atasnya, dimulai dari node yang paling kanan. Lanjut terus hingga mencapai root.\n\nPada heap tree, operasi insertion selalu diikuti dengan heapify yang bottom-up, dan operasi deletion selalu diikuti dengan heapify yang top-down.\nApabila diberikan sembarang binary tree, di antara ketiga variasi di atas, hanya heapify all yang menjamin binary tree berubah menjadi heap tree. Namun, apabila diberikan sembarang heap tree, operasi insertion dan deletion yang dilakukan (masing-masing diikuti heapify yang bottom-up atau top-down) akan tetap menjaga sifatnya sebagai heap tree, meskipun tidak dilakukan heapify all sama sekali.\nKalau ingin mengubah sembarang binary tree menjadi heap tree, kami menyediakan method bernama completify untuk membuat binary tree tersebut menjadi complete, yang kemudian bisa diikuti dengan penggunaan heapify all.\nKita akan mengimplementasikan heap tree dengan array. Karena heap tree adalah sejenis binary tree, kita bisa membuat class ArrayMaxHeap dan class ArrayMinHeap yang sama-sama meng-inherit dari class ArrayBintree dari Modul 8.\n\n\n\nclass ArrayMaxHeap(ArrayBintree):\n    def __init__(self, dtype, height, emptydata=-9999):\n        # menggunakan __init__ dari ArrayBintree,\n        # melalui super() yaitu parent class\n        super().__init__(dtype, height, emptydata)\n\n        # atribut tambahan: banyaknya node yang sudah ada\n        self.n_nodes = 0\n    \n    # semua method dari ArrayBintree otomatis sudah terdefinisi\n\n    # Memeriksa apakah dua nilai (parent, child) memenuhi max heap property\n    def is_correct_parent_child_data(self, parent_data, child_data):\n        if (parent_data &gt;= child_data):\n            return True\n        else:\n            return False\n\n    # Membuat binary tree menjadi complete (atau almost complete)\n    # Idenya, tiap elemen yang bukan \"data kosong\" harus didempetkan ke kiri\n    def completify(self):\n        # Sangat mirip dengan insertion sort, hanya saja syaratnya yang beda\n        for i in range(self.array_size): # i = 0, 1, 2, ..., n-1\n            for j in range(i, 0, -1): # j = i, i-1, ..., 2, 1\n                if ((self.array[j] != self.emptydata)\n                    and (self.array[j-1] == self.emptydata)):\n                    self.array[j-1] = self.array[j]\n                    self.array[j] = self.emptydata\n        # Setelah selesai, tentukan nilai n_nodes\n        i = 0\n        while (i &lt; self.array_size) and (self.array[i] != self.emptydata):\n            i += 1\n        self.n_nodes = i\n\n    # Pastikan, dari leaf tertentu ke atas, bahwa heap tree memang memenuhi\n    # heap property\n    def heapify_bottomup(self, child_idx):\n        if child_idx &gt; 0:\n            parent_idx = self.get_parent_idx(child_idx)\n            if not (self.is_correct_parent_child_data(\n                self.array[parent_idx], self.array[child_idx]\n                )): # Jika tidak memenuhi heap property, tukar\n                temp = self.array[parent_idx]\n                self.array[parent_idx] = self.array[child_idx]\n                self.array[child_idx] = temp\n            # heapify parent nya\n            self.heapify_bottomup(parent_idx)\n\n    def insert(self, newdata):\n        if self.n_nodes == self.array_size:\n            print(\"Error insert: array heap sudah penuh\")\n        else:\n            self.array[self.n_nodes] = newdata\n            self.heapify_bottomup(self.n_nodes)\n            self.n_nodes += 1\n    \n    # Pastikan, dari atas ke bawah, bahwa heap tree memang memenuhi\n    # heap property\n    def heapify_topdown(self, parent_idx=None):\n        # Awalnya mulai dari root\n        if parent_idx == None:\n            parent_idx = 0\n        \n        # Menentukan yang mana antara left child atau right child yang\n        # lebih layak menjadi parent\n        left_idx = self.get_left_child_idx(parent_idx)\n        right_idx = self.get_right_child_idx(parent_idx)\n\n        if ((left_idx != -1) and (right_idx != -1)\n            and (self.array[left_idx] != self.emptydata)\n            and (self.array[right_idx] != self.emptydata)):\n            # Kasus dua child, mana yang lebih layak jadi parent?\n            # (memperhatikan heap property)\n            if self.is_correct_parent_child_data(\n                self.array[left_idx], self.array[right_idx]\n                ): # Jika left child lebih layak, pilih itu\n                child_idx = left_idx\n            else:\n                child_idx = right_idx\n        elif (left_idx != -1) and (self.array[left_idx] != self.emptydata):\n            # Hanya satu child yaitu yang kiri, pilih saja\n            child_idx = left_idx\n        elif (right_idx != -1) and (self.array[right_idx] != self.emptydata):\n            # Hanya satu child yaitu yang kanan, pilih saja\n            child_idx = right_idx\n        else: # tidak punya child; top down selesai\n            return\n\n        # Kalau child yang dipilih bahkan lebih layak daripada parent sekarang,\n        # tukar agar heap property menjadi terpenuhi\n        if self.is_correct_parent_child_data(\n            self.array[child_idx], self.array[parent_idx]\n            ):\n            temp = self.array[child_idx]\n            self.array[child_idx] = self.array[parent_idx]\n            self.array[parent_idx] = temp\n        \n        # Lanjutkan heapify pada child tersebut\n        self.heapify_topdown(child_idx)\n    \n    # Mengintip apa yang ada di root\n    def peek(self):\n        nilai = self.get_root()\n        if nilai == self.emptydata:\n            print(\"Error peek: heap tree sedang kosong\")\n            return None\n        else:\n            return nilai\n\n    # Delete root\n    def delete(self):\n        # 1. Peroleh nilai root untuk di-return\n        nilai_root = self.get_root()\n\n        # Kalau ternyata sudah kosong sebelumnya, tidak ada yang bisa dihapus\n        if nilai_root == self.emptydata:\n            print(\"Error delete: heap tree sudah kosong sebelumnya\")\n            return None\n        # Kalau tidak kosong, lanjut\n\n        # 2. Ganti nilai di root dengan elemen ter-kanan di array\n        self.set_root(self.array[self.n_nodes-1])\n\n        # 3. \"Hapus\" elemen ter-kanan tersebut\n        self.array[self.n_nodes-1] = self.emptydata\n        self.n_nodes -= 1\n\n        # 4. Lakukan heapify dari root ke bawah\n        self.heapify_topdown()\n\n        # 5. return nilai yang baru saja dihapus\n        return nilai_root\n\n    # Heapify untuk semua node\n    def heapify_all(self):\n        # Periksa dari node ter-kanan hingga node ter-kiri (kecuali root)\n        for child_idx in range(self.n_nodes, 0, -1): # i = n, n-1, ..., 2, 1\n            parent_idx = self.get_parent_idx(child_idx)\n            # Jika heap property tidak terpenuhi, tukar\n            if not (self.is_correct_parent_child_data(\n                self.array[parent_idx], self.array[child_idx]\n                )):\n                temp = self.array[parent_idx]\n                self.array[parent_idx] = self.array[child_idx]\n                self.array[child_idx] = temp\n\nMengubah suatu binary tree (representasi array) menjadi heap tree\n\nbintree1 = ArrayMaxHeap(int, 3)\n\n\nlist1 = [15, 22, 14, 75, -9999, 67, -9999, 32]\nfor i in range(len(list1)):\n    bintree1.array[i] = list1[i]\n\n\nprint(bintree1.array)\n\n[   15    22    14    75 -9999    67 -9999    32 -9999 -9999 -9999 -9999\n -9999 -9999 -9999]\n\n\n\ndisplay(bintree1.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nbintree1.completify()\n\n\nprint(bintree1.array)\n\n[   15    22    14    75    67    32 -9999 -9999 -9999 -9999 -9999 -9999\n -9999 -9999 -9999]\n\n\n\ndisplay(bintree1.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nbintree1.array[4]\n\n67\n\n\n\nbintree1.heapify_bottomup(4)\n\n\ndisplay(bintree1.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nbintree1.heapify_topdown()\n\n\ndisplay(bintree1.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nprint(bintree1.array)\n\n[   67    75    14    15    22    32 -9999 -9999 -9999 -9999 -9999 -9999\n -9999 -9999 -9999]\n\n\n\nbintree1.array[5]\n\n32\n\n\n\nbintree1.heapify_bottomup(5)\n\n\ndisplay(bintree1.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nbintree1.heapify_all()\n\n\ndisplay(bintree1.get_digraph_simple())\n\n\n\n\n\n\n\n\nMembangun max heap baru dari awal\n\narraymaxheap = ArrayMaxHeap(int, 4)\n\n\narraymaxheap.insert(50)\n\n\ndisplay(arraymaxheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraymaxheap.insert(40)\n\n\ndisplay(arraymaxheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraymaxheap.insert(70)\n\n\ndisplay(arraymaxheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraymaxheap.insert(45)\n\n\ndisplay(arraymaxheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraymaxheap.insert(60)\n\n\ndisplay(arraymaxheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraymaxheap.delete()\n\n70\n\n\n\ndisplay(arraymaxheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narraymaxheap.delete()\n\n60\n\n\n\ndisplay(arraymaxheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\n\n\nDibandingkan dengan implementasi max heap di atas, hanya dua hal yang perlu diubah untuk memperoleh implementasi min heap:\n\nUbah nama class dari ArrayMaxHeap menjadi ArrayMinHeap\nModifikasi deinisi fungsi is_correct_parent_child_data di bagian (parent_data &gt;= child_data) menjadi (parent_data &lt;= child_data) (agar menggunakan min heap property daripada max heap property)\n\n\nclass ArrayMinHeap(ArrayBintree):\n    def __init__(self, dtype, height, emptydata=-9999):\n        # menggunakan __init__ dari ArrayBintree,\n        # melalui super() yaitu parent class\n        super().__init__(dtype, height, emptydata)\n\n        # atribut tambahan: banyaknya node yang sudah ada\n        self.n_nodes = 0\n    \n    # semua method dari ArrayBintree otomatis sudah terdefinisi\n\n    # Memeriksa apakah dua nilai (parent, child) memenuhi min heap property\n    def is_correct_parent_child_data(self, parent_data, child_data):\n        if (parent_data &lt;= child_data):\n            return True\n        else:\n            return False\n\n    # Membuat binary tree menjadi complete (atau almost complete)\n    # Idenya, tiap elemen yang bukan \"data kosong\" harus didempetkan ke kiri\n    def completify(self):\n        # Sangat mirip dengan insertion sort, hanya saja syaratnya yang beda\n        for i in range(self.array_size): # i = 0, 1, 2, ..., n-1\n            for j in range(i, 0, -1): # j = i, i-1, ..., 2, 1\n                if ((self.array[j] != self.emptydata)\n                    and (self.array[j-1] == self.emptydata)):\n                    self.array[j-1] = self.array[j]\n                    self.array[j] = self.emptydata\n        # Setelah selesai, tentukan nilai n_nodes\n        i = 0\n        while (i &lt; self.array_size) and (self.array[i] != self.emptydata):\n            i += 1\n        self.n_nodes = i\n\n    # Pastikan, dari leaf tertentu ke atas, bahwa heap tree memang memenuhi\n    # heap property\n    def heapify_bottomup(self, child_idx):\n        if child_idx &gt; 0:\n            parent_idx = self.get_parent_idx(child_idx)\n            if not (self.is_correct_parent_child_data(\n                self.array[parent_idx], self.array[child_idx]\n                )): # Jika tidak memenuhi heap property, tukar\n                temp = self.array[parent_idx]\n                self.array[parent_idx] = self.array[child_idx]\n                self.array[child_idx] = temp\n            # heapify parent nya\n            self.heapify_bottomup(parent_idx)\n\n    def insert(self, newdata):\n        if self.n_nodes == self.array_size:\n            print(\"Error insert: array heap sudah penuh\")\n        else:\n            self.array[self.n_nodes] = newdata\n            self.heapify_bottomup(self.n_nodes)\n            self.n_nodes += 1\n    \n    # Pastikan, dari atas ke bawah, bahwa heap tree memang memenuhi\n    # heap property\n    def heapify_topdown(self, parent_idx=None):\n        # Awalnya mulai dari root\n        if parent_idx == None:\n            parent_idx = 0\n        \n        # Menentukan yang mana antara left child atau right child yang\n        # lebih layak menjadi parent\n        left_idx = self.get_left_child_idx(parent_idx)\n        right_idx = self.get_right_child_idx(parent_idx)\n\n        if ((left_idx != -1) and (right_idx != -1)\n            and (self.array[left_idx] != self.emptydata)\n            and (self.array[right_idx] != self.emptydata)):\n            # Kasus dua child, mana yang lebih layak jadi parent?\n            # (memperhatikan heap property)\n            if self.is_correct_parent_child_data(\n                self.array[left_idx], self.array[right_idx]\n                ): # Jika left child lebih layak, pilih itu\n                child_idx = left_idx\n            else:\n                child_idx = right_idx\n        elif (left_idx != -1) and (self.array[left_idx] != self.emptydata):\n            # Hanya satu child yaitu yang kiri, pilih saja\n            child_idx = left_idx\n        elif (right_idx != -1) and (self.array[right_idx] != self.emptydata):\n            # Hanya satu child yaitu yang kanan, pilih saja\n            child_idx = right_idx\n        else: # tidak punya child; top down selesai\n            return\n\n        # Kalau child yang dipilih bahkan lebih layak daripada parent sekarang,\n        # tukar agar heap property menjadi terpenuhi\n        if self.is_correct_parent_child_data(\n            self.array[child_idx], self.array[parent_idx]\n            ):\n            temp = self.array[child_idx]\n            self.array[child_idx] = self.array[parent_idx]\n            self.array[parent_idx] = temp\n        \n        # Lanjutkan heapify pada child tersebut\n        self.heapify_topdown(child_idx)\n    \n    # Mengintip apa yang ada di root\n    def peek(self):\n        nilai = self.get_root()\n        if nilai == self.emptydata:\n            print(\"Error peek: heap tree sedang kosong\")\n            return None\n        else:\n            return nilai\n\n    # Delete root\n    def delete(self):\n        # 1. Peroleh nilai root untuk di-return\n        nilai_root = self.get_root()\n\n        # Kalau ternyata sudah kosong sebelumnya, tidak ada yang bisa dihapus\n        if nilai_root == self.emptydata:\n            print(\"Error delete: heap tree sudah kosong sebelumnya\")\n            return None\n        # Kalau tidak kosong, lanjut\n\n        # 2. Ganti nilai di root dengan elemen ter-kanan di array\n        self.set_root(self.array[self.n_nodes-1])\n\n        # 3. \"Hapus\" elemen ter-kanan tersebut\n        self.array[self.n_nodes-1] = self.emptydata\n        self.n_nodes -= 1\n\n        # 4. Lakukan heapify dari root ke bawah\n        self.heapify_topdown()\n\n        # 5. return nilai yang baru saja dihapus\n        return nilai_root\n\n    # Heapify untuk semua node\n    def heapify_all(self):\n        # Periksa dari node ter-kanan hingga node ter-kiri (kecuali root)\n        for child_idx in range(self.n_nodes, 0, -1): # i = n, n-1, ..., 2, 1\n            parent_idx = self.get_parent_idx(child_idx)\n            # Jika heap property tidak terpenuhi, tukar\n            if not (self.is_correct_parent_child_data(\n                self.array[parent_idx], self.array[child_idx]\n                )):\n                temp = self.array[parent_idx]\n                self.array[parent_idx] = self.array[child_idx]\n                self.array[child_idx] = temp\n\n\narrayminheap = ArrayMinHeap(int, 3)\n\n\narrayminheap.insert(78)\n\n\ndisplay(arrayminheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narrayminheap.insert(43)\n\n\ndisplay(arrayminheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narrayminheap.insert(21)\n\n\ndisplay(arrayminheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narrayminheap.insert(39)\n\n\ndisplay(arrayminheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narrayminheap.insert(15)\n\n\ndisplay(arrayminheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narrayminheap.delete()\n\n15\n\n\n\ndisplay(arrayminheap.get_digraph_simple())\n\n\n\n\n\n\n\n\n\narrayminheap.delete()\n\n21\n\n\n\ndisplay(arrayminheap.get_digraph_simple())"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09.html#implementasi-avlbalance-tree-dengan-pointer-linked-avl-tree",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09.html#implementasi-avlbalance-tree-dengan-pointer-linked-avl-tree",
    "title": "Modul 9 Struktur Data: Heap Tree, AVL/Balance Tree",
    "section": "",
    "text": "Suatu AVL tree, terkadang juga disebut balance tree, adalah semacam binary search tree (BST) dengan pertimbangan tambahan ketika insertion maupun deletion, yaitu dilakukan yang namanya re-balancing agar pohon tidak terlalu “berat sebelah”. Re-balancing di AVL tree dilakukan dengan yang namanya “rotasi” (rotation) terhadap node tertentu, bisa ke kiri (left rotation) ataupun ke kanan (right rotation).\nKapan dilakukannya re-balancing, tergantung suatu ukuran yang disebut balance factor, yang dimiliki oleh tiap node, dan dihitung sebagai selisih antara height dari left subtree dengan height dari right subtree. Balance factor diharapkan tidak kurang dari -1 dan tidak lebih dari 1; kalau aturan ini dilanggar (misalnya ketika insertion maupun deletion), barulah dilakukan re-balancing dengan rotation yang sesuai agar semua balance factor kembali mematuhi aturan tersebut.\nPada AVL tree, ketika ada pelanggaran nilai balance factor, ada empat kemungkinan kasus: LL, LR, RL, dan RR, di mana L artinya left dan R artinya right. Di antara empat kasus tersebut, tindakan re-balancing yang dilakukan bisa berupa satu ataupun dua rotasi, dan tiap rotasi bisa berupa rotasi kiri atau rotasi kanan, tergantung kasusnya.\nFun fact: AVL adalah singkatan dari dua penemunya, Georgy Maximovich Adelson-Velsky dan Evgenii Mikhailovich Landis.\nKarena AVL tree adalah modifikasi dari binary search tree (BST), di bawah ini, diimplementasikan class LinkedAVL yang meng-inherit dari class LinkedBST dari Modul 8.\n\n\n\nclass LinkedAVL(LinkedBST):\n    def __init__(self):\n        # menggunakan __init__ dari LinkedBST,\n        # melalui super() yaitu parent class\n        super().__init__()\n\n    def get_node_height(self, node):\n        if node == None:\n            return -1\n        left_height = self.get_node_height(node.left)\n        right_height = self.get_node_height(node.right)\n        node_height = 1 + max(left_height, right_height)\n        return node_height\n\n    def get_tree_height(self):\n        return self.get_node_height(self.root)\n\n    def get_balance_factor(self, node):\n        if node == None:\n            return 0\n        left_height = self.get_node_height(node.left)\n        right_height = self.get_node_height(node.right)\n        balance_factor = left_height - right_height\n        return balance_factor\n\n    def left_rotate(self, x):\n        #  x\n        #   \\\n        #    y\n        #   / \\\n        #  S   z\n        y = x.right\n        S = y.left # left subtree dari y\n\n        # rotate\n        y.left = x\n        x.right = S\n        #   y\n        #  / \\\n        # x   z\n        #  \\\n        #   S\n\n        # root baru\n        return y\n\n    def right_rotate(self, x):\n        #     x\n        #    /\n        #   y\n        #  / \\\n        # z   S\n        y = x.left\n        S = y.right # right subtree dari y\n\n        # rotate\n        y.right = x\n        x.left = S\n        #   y\n        #  / \\\n        # z   x\n        #    /\n        #   S\n\n        # root baru\n        return y\n\n    # Kali ini insert harus secara rekursif\n    # agar bisa sekaligus melakukan re-balancing secara bottom-up\n    def insert(self, newdata):\n        if self.search(newdata) == None: # jika data belum ada, boleh insert\n            self.root = self.insert_rec(newdata, current=self.root)\n        else:\n            print(\"Error insert: data sudah ada di AVL tree, yaitu\", newdata)\n    def insert_rec(self, newdata, current):\n        if current == None:\n            return BintreeNode(newdata)\n        elif newdata &lt; current.data:\n            current.left = self.insert_rec(newdata, current=current.left)\n        else: # newdata &gt; temp.data\n            current.right = self.insert_rec(newdata, current=current.right)\n        \n        cur_BF = self.get_balance_factor(current)\n        left_BF = self.get_balance_factor(current.left)\n        right_BF = self.get_balance_factor(current.right)\n\n        # re-balancing, bagi kasus tergantung balance factor\n        if (cur_BF &gt; 1 and left_BF &gt; 0): # kasus LL\n            #        current\n            #       /\n            #   left\n            #  /\n            # n\n\n            # solusi: right rotate current\n            return self.right_rotate(current)\n            #   left\n            #  /    \\\n            # n      current\n        \n        elif (cur_BF &gt; 1 and left_BF &lt;= 0): # kasus LR\n            #      current\n            #     /\n            # left\n            #     \\\n            #      n\n            #       \\\n            #        S\n\n            # S: subtree\n            \n            # solusi\n            # step 1: left rotate left child\n            current.left = self.left_rotate(current.left)\n            #        current\n            #       /\n            #      n\n            #     / \\\n            # left   S\n\n            # step 2: right rotate current\n            return self.right_rotate(current)\n            #      n\n            #     / \\\n            # left   current\n            #       /\n            #      S\n\n        elif (cur_BF &lt; -1 and right_BF &lt;= 0): # kasus RR\n            # current\n            #        \\\n            #         right\n            #        /     \\\n            #       S       n\n\n            # S: subtree\n\n            # solusi: left rotate current\n            return self.left_rotate(current)\n            #         right\n            #        /     \\\n            # current       n\n            #              /\n            #             S\n\n        elif (cur_BF &lt; -1 and right_BF &gt; 0): # kasus RL\n            # current\n            #        \\\n            #         right\n            #        /\n            #       n\n            #      /\n            #     S\n\n            # S: subtree\n\n            # solusi\n            # step 1: right rotate right child\n            current.right = self.right_rotate(current.right)\n            # current\n            #        \\\n            #         n\n            #        / \\\n            #       S   right\n\n            # step 2: left rotate current\n            return self.right_rotate(current)\n            #         n\n            #        / \\\n            # current   right\n            #          /\n            #         S\n\n        return current\n\n    # Deletion juga secara rekursif\n    # agar sekaligus melakukan re-balancing secara bottom-up\n    def delete(self, x, inorder_pred=False):\n        if self.search(x) != None:\n            self.root = self.delete_rec(x, current=self.root,\n                                        inorder_pred=inorder_pred)\n        else:\n            print(\"Error delete: tidak ditemukan data\", x)\n    def delete_rec(self, x, current, inorder_pred=False):\n        if current == None:\n            return current\n        elif x &lt; current.data:\n            current.left = self.delete_rec(x, current=current.left,\n                                           inorder_pred=inorder_pred)\n        elif x &gt; current.data:\n            current.right = self.delete_rec(x, current=current.right,\n                                            inorder_pred=inorder_pred)\n        # untuk elif/else berikut ini, x == current.data, sehingga dihapus\n        elif current.left == None: # hanya satu child (kanan)\n            temp = current.right\n            del current\n            return temp\n        elif current.right == None: # hanya satu child (kiri)\n            temp = current.left\n            del current\n            return temp\n\n        # dua child\n        elif inorder_pred: # metode inorder predecessor\n            inorder_left = []\n            self.get_inorder(current=current.left, result=inorder_left)\n            inorder_pred_val = inorder_left[-1]\n\n            current.data = inorder_pred_val\n            current.left = self.delete_rec(\n                inorder_pred_val, current=current.left,\n                inorder_pred=inorder_pred\n            )\n        else: # metode inorder succcessor\n            inorder_right = []\n            self.get_inorder(current=current.right, result=inorder_right)\n            inorder_succ_val = inorder_right[0]\n\n            current.data = inorder_succ_val\n            current.right = self.delete_rec(\n                inorder_succ_val, current=current.right,\n                inorder_pred=inorder_pred\n            )\n        \n        cur_BF = self.get_balance_factor(current)\n        left_BF = self.get_balance_factor(current.left)\n        right_BF = self.get_balance_factor(current.right)\n\n        # re-balancing, bagi kasus tergantung balance factor\n        if (cur_BF &gt; 1 and left_BF &gt; 0): # kasus LL\n            # solusi: right rotate current\n            return self.right_rotate(current)\n        elif (cur_BF &gt; 1 and left_BF &lt;= 0): # kasus LR\n            # step 1: left rotate left child\n            current.left = self.left_rotate(current.left)\n            # step 2: right rotate current\n            return self.right_rotate(current)\n        elif (cur_BF &lt; -1 and right_BF &lt;= 0): # kasus RR\n            # solusi: left rotate current\n            return self.left_rotate(current)\n        elif (cur_BF &lt; -1 and right_BF &gt; 0): # kasus RL\n            # step 1: right rotate right child\n            current.right = self.right_rotate(current.right)\n            # step 2: left rotate current\n            return self.right_rotate(current)\n\n        return current\n\n\nlinkedavl = LinkedAVL()\n\n\nlinkedavl.insert(2)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.insert(1)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.insert(5)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.insert(3)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.insert(7)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.insert(10)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.delete(7)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.delete(2)\n\n\ndisplay(linkedavl.get_digraph_simple())\n\n\n\n\n\n\n\n\n\nlinkedavl.delete(5)\n\n\ndisplay(linkedavl.get_digraph_simple())"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09.html#lampiran-kode-yang-diperlukan-dari-modul-modul-sebelumnya",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul09.html#lampiran-kode-yang-diperlukan-dari-modul-modul-sebelumnya",
    "title": "Modul 9 Struktur Data: Heap Tree, AVL/Balance Tree",
    "section": "",
    "text": "class ArrayBintree:\n    def __init__(self, dtype, height, emptydata=-9999):\n        self.dtype = dtype\n        self.height = height\n        self.emptydata = emptydata\n        self.array_size = 2**(height+1) - 1\n        self.array = np.empty(self.array_size, dtype=dtype)\n        for i in range(self.array_size):\n            self.array[i] = emptydata\n\n    def get_root(self):\n        root_data = self.array[0]\n        if root_data == self.emptydata:\n            return None\n        else:\n            return root_data\n\n    def set_root(self, newdata):\n        self.array[0] = newdata\n\n    def get_data(self, node_idx):\n        if node_idx &lt; self.array_size:\n            return self.array[node_idx]\n        else:\n            print(\"Error get_data: indeks di luar ukuran tree\")\n            return None\n\n    def set_data(self, node_idx, newdata):\n        if node_idx &lt; self.array_size:\n            self.array[node_idx] = newdata\n        else:\n            print(\"Error set_data: indeks di luar ukuran tree\")\n\n    def get_left_child_idx(self, node_idx):\n        left_idx = 2*node_idx + 1\n        if left_idx &lt; self.array_size:\n            return left_idx\n        else:\n            return -1\n\n    def get_left_child(self, node_idx):\n        left_idx = self.get_left_child_idx(node_idx)\n        if left_idx != -1:\n            data = self.array[left_idx]\n            if data != self.emptydata:\n                return data\n            else:\n                return None\n        else:\n            return None\n\n    def get_right_child_idx(self, node_idx):\n        right_idx = 2*node_idx + 2\n        if right_idx &lt; self.array_size:\n            return right_idx\n        else:\n            return -1\n\n    def get_right_child(self, node_idx):\n        right_idx = self.get_right_child_idx(node_idx)\n        if right_idx != -1:\n            data = self.array[right_idx]\n            if data != self.emptydata:\n                return data\n            else:\n                return None\n        else:\n            return None\n\n    def get_parent_idx(self, node_idx):\n        if node_idx == 0:\n            return -1\n        idx = int(np.floor( (node_idx - 1)/2 ))\n        return idx\n\n    # preorder: tengah, kiri, kanan\n    def get_preorder(self, current=0, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n\n        # tengah\n        current_data = self.array[current]\n        if current_data != self.emptydata:\n            result.append(current_data)\n\n        # kiri\n        left_idx = self.get_left_child_idx(current)\n        if left_idx != -1:\n            self.get_preorder(current=left_idx, result=result)\n\n        # kanan\n        right_idx = self.get_right_child_idx(current)\n        if right_idx != -1:\n            self.get_preorder(current=right_idx, result=result)\n\n        if is_starting_node:\n            return result\n\n    # inorder: kiri, tengah, kanan\n    def get_inorder(self, current=0, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n\n        # kiri\n        left_idx = self.get_left_child_idx(current)\n        if left_idx != -1:\n            self.get_inorder(current=left_idx, result=result)\n\n        # tengah\n        current_data = self.array[current]\n        if current_data != self.emptydata:\n            result.append(current_data)\n\n        # kanan\n        right_idx = self.get_right_child_idx(current)\n        if right_idx != -1:\n            self.get_inorder(current=right_idx, result=result)\n\n        if is_starting_node:\n            return result\n\n    # postorder: kiri, kanan, tengah\n    def get_postorder(self, current=0, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n\n        # kiri\n        left_idx = self.get_left_child_idx(current)\n        if left_idx != -1:\n            self.get_postorder(current=left_idx, result=result)\n\n        # kanan\n        right_idx = self.get_right_child_idx(current)\n        if right_idx != -1:\n            self.get_postorder(current=right_idx, result=result)\n\n        # tengah\n        current_data = self.array[current]\n        if current_data != self.emptydata:\n            result.append(current_data)\n\n        if is_starting_node:\n            return result\n\n    def get_digraph_simple(self):\n        digraph = gv.Digraph()\n        for idx in range(self.array_size):\n            data = self.array[idx]\n            if data != self.emptydata:\n                digraph.node(\"node\" + str(idx), label=str(data))\n                left_idx = self.get_left_child_idx(idx)\n                right_idx = self.get_right_child_idx(idx)\n                if left_idx != -1:\n                    digraph.edge(\"node\" + str(idx), \"node\" + str(left_idx))\n                    if self.array[left_idx] == self.emptydata:\n                        digraph.node(\"node\" + str(left_idx), label=\"NULL\", shape=\"none\")\n                if right_idx != -1:\n                    digraph.edge(\"node\" + str(idx), \"node\" + str(right_idx))\n                    if self.array[right_idx] == self.emptydata:\n                        digraph.node(\"node\" + str(right_idx), label=\"NULL\", shape=\"none\")\n        return digraph\n\n\n\n\n\nclass BintreeNode:\n    def __init__(self, data, left=None, right=None):\n        self.data = data\n        self.left = left\n        self.right = right\n\n\nclass LinkedBintree:\n    def __init__(self):\n        self.root = None\n\n    def is_empty(self):\n        if self.root == None:\n            return True\n        else:\n            return False\n\n    def get_root_data(self):\n        if self.is_empty():\n            print(\"Error get_root_data: tree sedang kosong\")\n            return None\n        else:\n            return self.root.data\n\n    def set_root_data(self, newdata):\n        if self.is_empty():\n            self.root = BintreeNode(newdata)\n        else:\n            self.root.data = newdata\n\n    # preorder: tengah, kiri, kanan\n    def get_preorder(self, current=None, result=None, get_addresses=False):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n            current = self.root\n\n        if current != None:\n            # tengah\n            if (not get_addresses):\n                result.append(current.data)\n            else:\n                result.append(current)\n\n            # kiri\n            if current.left != None:\n                self.get_preorder(current.left, result=result)\n            \n            # kanan\n            if current.right != None:\n                self.get_preorder(current.right, result=result)\n\n        if is_starting_node:\n            return result\n\n    # inorder: kiri, tengah, kanan\n    def get_inorder(self, current=None, result=None, get_addresses=False):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n            current = self.root\n\n        if current != None:\n            # kiri\n            if current.left != None:\n                self.get_inorder(current.left, result=result)\n            \n            # tengah\n            if (not get_addresses):\n                result.append(current.data)\n            else:\n                result.append(current)\n\n            # kanan\n            if current.right != None:\n                self.get_inorder(current.right, result=result)\n\n        if is_starting_node:\n            return result\n\n    # postorder: kiri, kanan, tengah\n    def get_postorder(self, current=None, result=None, get_addresses=False):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = []\n            current = self.root\n\n        if current != None:\n            # kiri\n            if current.left != None:\n                self.get_postorder(current.left, result=result)\n            \n            # kanan\n            if current.right != None:\n                self.get_postorder(current.right, result=result)\n\n            # tengah\n            if (not get_addresses):\n                result.append(current.data)\n            else:\n                result.append(current)\n\n        if is_starting_node:\n            return result\n\n    # berdasarkan algoritma preorder traversal :D\n    def get_digraph_simple(self, current=None, node_name=None, result=None):\n        is_starting_node = False\n        if result == None:\n            is_starting_node = True\n            result = gv.Digraph()\n            current = self.root\n            node_name = \"root\"\n        \n        if current != None:\n            # tengah\n            result.node(node_name, label=str(current.data))\n\n            # kiri\n            left_name = node_name + \"-&gt;left\"\n            result.edge(node_name, left_name)\n            self.get_digraph_simple(\n                current=current.left, node_name=left_name, result=result\n            )\n            \n            # kanan\n            right_name = node_name + \"-&gt;right\"\n            self.get_digraph_simple(\n                current=current.right, node_name=right_name, result=result\n            )\n            result.edge(node_name, right_name)\n        else:\n            result.node(node_name, label=\"NULL\", shape=\"none\")\n        \n        if is_starting_node:\n            return result\n\n\nclass LinkedBST(LinkedBintree):\n    def __init__(self):\n        # menggunakan __init__ dari parent class,\n        # melalui super() yaitu parent class\n        super().__init__()\n    \n    # semua method dari LinkedBintree otomatis sudah terdefinisi\n\n    # cari elemen di BST\n    def search(self, x):\n        temp = self.root\n        while (temp != None):\n            if x == temp.data:\n                return x\n            elif x &lt; temp.data:\n                temp = temp.left\n            else:\n                temp = temp.right\n        return None\n\n    # insertion\n    def insert(self, newdata):\n        if self.root == None:\n            self.root = BintreeNode(newdata)\n            return\n        temp = self.root\n        while (temp != None):\n            if newdata == temp.data:\n                print(\"Error insert: data sudah ada di BST, yaitu\", newdata)\n                return\n            elif newdata &lt; temp.data:\n                if temp.left == None:\n                    temp.left = BintreeNode(newdata)\n                    return\n                else:\n                    temp = temp.left\n            else: # newdata &gt; temp.data\n                if temp.right == None:\n                    temp.right = BintreeNode(newdata)\n                    return\n                else:\n                    temp = temp.right\n\n    # deletion\n    def delete(self, x, inorder_pred=False):\n        if self.is_empty():\n            print(\"Error: BST kosong\")\n            return\n        prev = self.root\n        turn = \"\"\n        if x &lt; prev.data:\n            if prev.left == None:\n                print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                return\n            else:\n                temp = prev.left\n                turn = \"left\"\n        elif x &gt; prev.data:\n            if prev.right == None:\n                print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                return\n            else:\n                temp = prev.right\n                turn = \"right\"\n        else:\n            temp = prev\n        \n        while (temp != None):\n            if temp.data == x:\n                break\n            elif x &lt; temp.data:\n                if temp.left == None:\n                    print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                    return\n                else:\n                    prev = temp\n                    temp = temp.left\n                    turn = \"left\"\n            else: # x &gt; temp.data\n                if temp.right == None:\n                    print(\"Error delete: tidak ditemukan data yang bernilai\", x)\n                    return\n                else:\n                    prev = temp\n                    temp = temp.right\n                    turn = \"right\"\n        \n        # kasus 0 children\n        if (temp.left == None) and (temp.right == None):\n            if turn == \"left\":\n                prev.left = None\n            elif turn == \"right\":\n                prev.right = None\n            del temp\n            return\n\n        # kasus 1 child, di kiri\n        elif (temp.left != None) and (temp.right == None):\n            if turn == \"left\":\n                prev.left = temp.left\n            elif turn == \"right\":\n                prev.right = temp.left\n            del temp\n            return\n        \n        # kasus 1 child, di kanan\n        elif (temp.left == None) and (temp.right != None):\n            if turn == \"left\":\n                prev.left = temp.right\n            elif turn == \"right\":\n                prev.right = temp.right\n            del temp\n            return\n        \n        # kasus 2 children\n        elif inorder_pred: # metode inorder predecessor (left subtree)\n            inorder_left = []\n            self.get_inorder(current=temp.left, result=inorder_left)\n            replacement = inorder_left[-1] # elemen terakhir\n            self.delete(replacement, inorder_pred=inorder_pred)\n            temp.data = replacement\n            return\n        else: # metode inorder successor (right subtree)\n            inorder_right = []\n            self.get_inorder(current=temp.right, result=inorder_right)\n            replacement = inorder_right[0]\n            self.delete(replacement, inorder_pred=inorder_pred)\n            temp.data = replacement\n            return"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html",
    "title": "Modul 10 Struktur Data: Pengantar database dengan SQLite",
    "section": "",
    "text": "Kembali ke Struktur Data (dengan Python)\nSelamat datang di praktikum terakhir Struktur Data tahun 2023 ini :)\nAgak berbeda dengan beberapa praktikum sebelumnya, kali ini, kita akan membahas tentang database (terkadang disebut “basis data”) menggunakan yang namanya SQLite.\nSebelum kita mulai, singkat cerita:\n\nSuatu database adalah tempat menyimpan sekumpulan data yang saling berhubungan\nDatabase biasanya berupa sekumpulan tabel yang saling berkaitan. Jenis database ini disebut relational database\nUntuk mengelola suatu database, digunakan yang namanya database management system (DBMS). Khusus relational database, ada istilah relational database management system (RDBMS)\nUntuk relational database yang tidak terlalu besar, salah satu RDBMS yang sering digunakan adalah SQLite, dan itulah yang kita bahas di sini. Ada juga Microsoft Access\nUntuk penggunaan relational database di server atau internet, apalagi kalau ukuran datanya besar, contoh RDBMS yang biasa digunakan adalah MySQL, PostgreSQL, MariaDB, Microsoft SQL Server, Oracle Database\nSQLite bisa dioperasikan melalui Python, dengan module/package sqlite3 yang harusnya sudah terinstal bersama Python (kalau belum, bisa diinstal dengan pip install sqlite3, tapi jangan lupa conda install sqlite terlebih dahulu kalau menggunakan Anaconda)\nFile extension atau akhiran nama file untuk suatu database SQLite bisa berupa .db atau .sqlite atau lebih spesifiknya .sqlite3 (atau yang jarang digunakan: .db3, .s3db, .sl3)\nPada tiap database, bisa dilakukan yang namanya querying, yaitu melakukan filtering untuk memperoleh data yang memenuhi kriteria yang kita tentukan\nSudah ada bahasa bernama SQL (Structured Query Language) yang terstandarisasi untuk melakukan querying (maupun modifikasi) pada relational database, apapun RDBMS yang digunakan\n\n\nimport sqlite3\n\n\n\nMembuat database baru (atau membuka database yang sudah ada, kalau ada) dengan nama file yang ditentukan\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\n\n\ncur = conn.cursor()\n\n\n# Menjalankan perintah SQL\ncur.execute(\"\"\"CREATE TABLE IF NOT EXISTS tabel_produk (\n    product_id INTEGER PRIMARY KEY NOT NULL,\n    nama TEXT,\n    stok INTEGER,\n    berat_kg REAL,\n    harga_ribu_rp REAL\n)\"\"\")\n\n# Menyimpan hasil eksekusi SQL\nconn.commit()\n\nStorage class atau “kategori tipe data” di SQLite ada lima:\n\nNULL\nINTEGER\nREAL\nTEXT\nBLOB (untuk data lainnya)\n\n\n# Menutup koneksi\nconn.close()\n\n\n\n\nMenambahkan data ke database\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"INSERT INTO tabel_produk VALUES (123, 'Apel', 10, 0.2, 3.5)\")\nconn.commit()\n\ncur.execute(\"INSERT INTO tabel_produk VALUES (456, 'Jeruk', 15, 0.15, 2.1)\")\nconn.commit()\n\ncur.execute(\"INSERT INTO tabel_produk VALUES (789, 'Pisang', 40, 0.05, 1.25)\")\nconn.commit()\n\nconn.close()\n\nMelihat semua data yang ada di database\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nprint(cur.fetchall())\n\nconn.close()\n\n[(123, 'Apel', 10, 0.2, 3.5), (456, 'Jeruk', 15, 0.15, 2.1), (789, 'Pisang', 40, 0.05, 1.25)]\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nprint(semua_baris)\n\nconn.close()\n\n[(123, 'Apel', 10, 0.2, 3.5), (456, 'Jeruk', 15, 0.15, 2.1), (789, 'Pisang', 40, 0.05, 1.25)]\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 10, 0.2, 3.5)\n(456, 'Jeruk', 15, 0.15, 2.1)\n(789, 'Pisang', 40, 0.05, 1.25)\n\n\nMelihat nama kolom\nSayangnya, tidak ada cara langsung untuk memperoleh nama kolom. Namun, kita bisa melihat atribut .description pada cursor, yang berisi nama tiap kolom, disertai dengan beberapa data lainnya yang maknanya tidak perlu kita pahami.\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nprint(cur.description)\n\nconn.close()\n\n(('product_id', None, None, None, None, None, None), ('nama', None, None, None, None, None, None), ('stok', None, None, None, None, None, None), ('berat_kg', None, None, None, None, None, None), ('harga_ribu_rp', None, None, None, None, None, None))\n\n\nDengan list comprehension, kita ambil bagian pertama saja:\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nnama_kolom = [x[0] for x in cur.description]\nprint(nama_kolom)\n\nconn.close()\n\n['product_id', 'nama', 'stok', 'berat_kg', 'harga_ribu_rp']\n\n\nMelihat data di kolom-kolom tertentu saja\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT product_id, nama FROM tabel_produk\")\nprint(cur.fetchall())\n\nconn.close()\n\n[(123, 'Apel'), (456, 'Jeruk'), (789, 'Pisang')]\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT nama, stok FROM tabel_produk\")\nprint(cur.fetchall())\n\nconn.close()\n\n[('Apel', 10), ('Jeruk', 15), ('Pisang', 40)]\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT nama, berat_kg, harga_ribu_rp FROM tabel_produk\")\nprint(cur.fetchall())\n\nconn.close()\n\n[('Apel', 0.2, 3.5), ('Jeruk', 0.15, 2.1), ('Pisang', 0.05, 1.25)]\n\n\nMenambahkan data\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ndata_baru = [\n    (987, 'Brokoli', 70, 0.05, 1.5),\n    (321, 'Wortel', 30, 0.1, 1.8),\n    (135, 'Stroberi', 120, 0.04, 2)\n]\n\ncur.executemany(\"INSERT INTO tabel_produk VALUES (?, ?, ?, ?, ?)\", data_baru)\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nprint(cur.fetchall())\n\nconn.close()\n\n[(123, 'Apel', 10, 0.2, 3.5), (135, 'Stroberi', 120, 0.04, 2.0), (321, 'Wortel', 30, 0.1, 1.8), (456, 'Jeruk', 15, 0.15, 2.1), (789, 'Pisang', 40, 0.05, 1.25), (987, 'Brokoli', 70, 0.05, 1.5)]\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 10, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 1.8)\n(456, 'Jeruk', 15, 0.15, 2.1)\n(789, 'Pisang', 40, 0.05, 1.25)\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE stok &lt; 50\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 10, 0.2, 3.5)\n(321, 'Wortel', 30, 0.1, 1.8)\n(456, 'Jeruk', 15, 0.15, 2.1)\n(789, 'Pisang', 40, 0.05, 1.25)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE harga_ribu_rp &gt; 2\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 10, 0.2, 3.5)\n(456, 'Jeruk', 15, 0.15, 2.1)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE nama == 'Stroberi'\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(135, 'Stroberi', 120, 0.04, 2.0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE product_id == 987\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE product_id LIKE '45%'\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(456, 'Jeruk', 15, 0.15, 2.1)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE product_id LIKE '%9'\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(789, 'Pisang', 40, 0.05, 1.25)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE product_id LIKE '1%'\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 10, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE (stok &lt; 50) AND (product_id LIKE '1%')\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 10, 0.2, 3.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE (stok &lt;= 10) OR (harga_ribu_rp &gt; 2)\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 10, 0.2, 3.5)\n(456, 'Jeruk', 15, 0.15, 2.1)\n\n\n\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"UPDATE tabel_produk SET stok = 200 WHERE product_id == 123\")\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 1.8)\n(456, 'Jeruk', 15, 0.15, 2.1)\n(789, 'Pisang', 40, 0.05, 1.25)\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"UPDATE tabel_produk SET nama = 'Jeruk nipis' WHERE product_id == 456\")\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 1.8)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(789, 'Pisang', 40, 0.05, 1.25)\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"UPDATE tabel_produk SET harga_ribu_rp = 2.5 WHERE product_id == 321\")\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(789, 'Pisang', 40, 0.05, 1.25)\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"UPDATE tabel_produk SET stok = 10 WHERE product_id == 789\")\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(789, 'Pisang', 10, 0.05, 1.25)\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"DELETE FROM tabel_produk WHERE product_id == 789\")\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY nama\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(987, 'Brokoli', 70, 0.05, 1.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY nama DESC\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(321, 'Wortel', 30, 0.1, 2.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(987, 'Brokoli', 70, 0.05, 1.5)\n(123, 'Apel', 200, 0.2, 3.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY nama ASC\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(987, 'Brokoli', 70, 0.05, 1.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY berat_kg\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(135, 'Stroberi', 120, 0.04, 2.0)\n(987, 'Brokoli', 70, 0.05, 1.5)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(123, 'Apel', 200, 0.2, 3.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY harga_ribu_rp\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(987, 'Brokoli', 70, 0.05, 1.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(321, 'Wortel', 30, 0.1, 2.5)\n(123, 'Apel', 200, 0.2, 3.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY harga_ribu_rp DESC\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY harga_ribu_rp DESC LIMIT 3\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY product_id LIMIT 3\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk LIMIT 3\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY product_id\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"\"\"CREATE TABLE IF NOT EXISTS tabel_pesanan (\n    order_id INTEGER PRIMARY KEY NOT NULL,\n    tanggal TEXT,\n    jam TEXT,\n    kode_produk INTEGER,\n    jumlah INTEGER,\n    sudah_dibayar INTEGER,\n    FOREIGN KEY(kode_produk) REFERENCES tabel_produk(product_id)\n)\n\"\"\")\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ndata_baru = [\n    (1, '2023-11-05', '14:38:27', 123, 10, 0),\n    (2, '2023-11-16', '09:01:03', 456, 5, 0),\n    (3, '2023-11-17', '23:59:58', 987, 15, 0)\n]\n\ncur.executemany(\"INSERT INTO tabel_pesanan VALUES (?,?,?,?,?,?)\", data_baru)\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n(2, '2023-11-16', '09:01:03', 456, 5, 0)\n(3, '2023-11-17', '23:59:58', 987, 15, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ndata_baru = [\n    ('2023-11-16', '00:09:32', 456, 20, 0),\n    ('2023-11-15', '12:29:17', 135, 5, 0),\n    ('2023-11-17', '15:42:19', 321, 10, 0)\n]\n\ncur.executemany(\"\"\"INSERT INTO tabel_pesanan\n                (tanggal, jam, kode_produk, jumlah, sudah_dibayar)\n                VALUES (?,?,?,?,?)\"\"\", data_baru)\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n(2, '2023-11-16', '09:01:03', 456, 5, 0)\n(3, '2023-11-17', '23:59:58', 987, 15, 0)\n(4, '2023-11-16', '00:09:32', 456, 20, 0)\n(5, '2023-11-15', '12:29:17', 135, 5, 0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan ORDER BY tanggal\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n(5, '2023-11-15', '12:29:17', 135, 5, 0)\n(2, '2023-11-16', '09:01:03', 456, 5, 0)\n(4, '2023-11-16', '00:09:32', 456, 20, 0)\n(3, '2023-11-17', '23:59:58', 987, 15, 0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan ORDER BY tanggal, jam\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n(5, '2023-11-15', '12:29:17', 135, 5, 0)\n(4, '2023-11-16', '00:09:32', 456, 20, 0)\n(2, '2023-11-16', '09:01:03', 456, 5, 0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0)\n(3, '2023-11-17', '23:59:58', 987, 15, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan ORDER BY tanggal DESC, jam DESC\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(3, '2023-11-17', '23:59:58', 987, 15, 0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0)\n(2, '2023-11-16', '09:01:03', 456, 5, 0)\n(4, '2023-11-16', '00:09:32', 456, 20, 0)\n(5, '2023-11-15', '12:29:17', 135, 5, 0)\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan WHERE jam &gt; '12:00:00'\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n(3, '2023-11-17', '23:59:58', 987, 15, 0)\n(5, '2023-11-15', '12:29:17', 135, 5, 0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan WHERE jam &gt; '12:00:00' ORDER BY tanggal, jam\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n(5, '2023-11-15', '12:29:17', 135, 5, 0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0)\n(3, '2023-11-17', '23:59:58', 987, 15, 0)\n\n\n\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\nprint(\"=== Tabel produk ===\")\ncur.execute(\"\"\"SELECT * FROM tabel_produk\"\"\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nprint(\"=== Tabel pesanan ===\")\ncur.execute(\"\"\"SELECT * FROM tabel_pesanan\"\"\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n=== Tabel produk ===\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(987, 'Brokoli', 70, 0.05, 1.5)\n=== Tabel pesanan ===\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n(2, '2023-11-16', '09:01:03', 456, 5, 0)\n(3, '2023-11-17', '23:59:58', 987, 15, 0)\n(4, '2023-11-16', '00:09:32', 456, 20, 0)\n(5, '2023-11-15', '12:29:17', 135, 5, 0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE product_id == 456\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan WHERE kode_produk == 456\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(2, '2023-11-16', '09:01:03', 456, 5, 0)\n(4, '2023-11-16', '00:09:32', 456, 20, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"\"\"SELECT *\n            FROM tabel_produk INNER JOIN tabel_pesanan\n            ON tabel_produk.product_id == tabel_pesanan.kode_produk\n            \"\"\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5, 1, '2023-11-05', '14:38:27', 123, 10, 0)\n(456, 'Jeruk nipis', 15, 0.15, 2.1, 2, '2023-11-16', '09:01:03', 456, 5, 0)\n(987, 'Brokoli', 70, 0.05, 1.5, 3, '2023-11-17', '23:59:58', 987, 15, 0)\n(456, 'Jeruk nipis', 15, 0.15, 2.1, 4, '2023-11-16', '00:09:32', 456, 20, 0)\n(135, 'Stroberi', 120, 0.04, 2.0, 5, '2023-11-15', '12:29:17', 135, 5, 0)\n(321, 'Wortel', 30, 0.1, 2.5, 6, '2023-11-17', '15:42:19', 321, 10, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"\"\"SELECT *\n            FROM tabel_pesanan INNER JOIN tabel_produk\n            ON tabel_pesanan.kode_produk == tabel_produk.product_id\n            \"\"\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(1, '2023-11-05', '14:38:27', 123, 10, 0, 123, 'Apel', 200, 0.2, 3.5)\n(2, '2023-11-16', '09:01:03', 456, 5, 0, 456, 'Jeruk nipis', 15, 0.15, 2.1)\n(3, '2023-11-17', '23:59:58', 987, 15, 0, 987, 'Brokoli', 70, 0.05, 1.5)\n(4, '2023-11-16', '00:09:32', 456, 20, 0, 456, 'Jeruk nipis', 15, 0.15, 2.1)\n(5, '2023-11-15', '12:29:17', 135, 5, 0, 135, 'Stroberi', 120, 0.04, 2.0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0, 321, 'Wortel', 30, 0.1, 2.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"\"\"SELECT tabel_pesanan.tanggal, tabel_produk.nama, tabel_pesanan.jumlah\n            FROM tabel_pesanan INNER JOIN tabel_produk\n            ON tabel_pesanan.kode_produk == tabel_produk.product_id\n            \"\"\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n('2023-11-05', 'Apel', 10)\n('2023-11-16', 'Jeruk nipis', 5)\n('2023-11-17', 'Brokoli', 15)\n('2023-11-16', 'Jeruk nipis', 20)\n('2023-11-15', 'Stroberi', 5)\n('2023-11-17', 'Wortel', 10)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"\"\"SELECT tabel_pesanan.tanggal, tabel_produk.nama, tabel_pesanan.jumlah\n            FROM tabel_pesanan INNER JOIN tabel_produk\n            ON tabel_pesanan.kode_produk == tabel_produk.product_id\n            WHERE tabel_pesanan.jam &gt; '12:00:00'\n            \"\"\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n('2023-11-05', 'Apel', 10)\n('2023-11-17', 'Brokoli', 15)\n('2023-11-15', 'Stroberi', 5)\n('2023-11-17', 'Wortel', 10)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#membuat-database-dan-tabel",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#membuat-database-dan-tabel",
    "title": "Modul 10 Struktur Data: Pengantar database dengan SQLite",
    "section": "",
    "text": "Membuat database baru (atau membuka database yang sudah ada, kalau ada) dengan nama file yang ditentukan\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\n\n\ncur = conn.cursor()\n\n\n# Menjalankan perintah SQL\ncur.execute(\"\"\"CREATE TABLE IF NOT EXISTS tabel_produk (\n    product_id INTEGER PRIMARY KEY NOT NULL,\n    nama TEXT,\n    stok INTEGER,\n    berat_kg REAL,\n    harga_ribu_rp REAL\n)\"\"\")\n\n# Menyimpan hasil eksekusi SQL\nconn.commit()\n\nStorage class atau “kategori tipe data” di SQLite ada lima:\n\nNULL\nINTEGER\nREAL\nTEXT\nBLOB (untuk data lainnya)\n\n\n# Menutup koneksi\nconn.close()"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#menambahkan-dan-melihat-data",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#menambahkan-dan-melihat-data",
    "title": "Modul 10 Struktur Data: Pengantar database dengan SQLite",
    "section": "",
    "text": "Menambahkan data ke database\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"INSERT INTO tabel_produk VALUES (123, 'Apel', 10, 0.2, 3.5)\")\nconn.commit()\n\ncur.execute(\"INSERT INTO tabel_produk VALUES (456, 'Jeruk', 15, 0.15, 2.1)\")\nconn.commit()\n\ncur.execute(\"INSERT INTO tabel_produk VALUES (789, 'Pisang', 40, 0.05, 1.25)\")\nconn.commit()\n\nconn.close()\n\nMelihat semua data yang ada di database\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nprint(cur.fetchall())\n\nconn.close()\n\n[(123, 'Apel', 10, 0.2, 3.5), (456, 'Jeruk', 15, 0.15, 2.1), (789, 'Pisang', 40, 0.05, 1.25)]\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nprint(semua_baris)\n\nconn.close()\n\n[(123, 'Apel', 10, 0.2, 3.5), (456, 'Jeruk', 15, 0.15, 2.1), (789, 'Pisang', 40, 0.05, 1.25)]\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 10, 0.2, 3.5)\n(456, 'Jeruk', 15, 0.15, 2.1)\n(789, 'Pisang', 40, 0.05, 1.25)\n\n\nMelihat nama kolom\nSayangnya, tidak ada cara langsung untuk memperoleh nama kolom. Namun, kita bisa melihat atribut .description pada cursor, yang berisi nama tiap kolom, disertai dengan beberapa data lainnya yang maknanya tidak perlu kita pahami.\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nprint(cur.description)\n\nconn.close()\n\n(('product_id', None, None, None, None, None, None), ('nama', None, None, None, None, None, None), ('stok', None, None, None, None, None, None), ('berat_kg', None, None, None, None, None, None), ('harga_ribu_rp', None, None, None, None, None, None))\n\n\nDengan list comprehension, kita ambil bagian pertama saja:\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nnama_kolom = [x[0] for x in cur.description]\nprint(nama_kolom)\n\nconn.close()\n\n['product_id', 'nama', 'stok', 'berat_kg', 'harga_ribu_rp']\n\n\nMelihat data di kolom-kolom tertentu saja\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT product_id, nama FROM tabel_produk\")\nprint(cur.fetchall())\n\nconn.close()\n\n[(123, 'Apel'), (456, 'Jeruk'), (789, 'Pisang')]\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT nama, stok FROM tabel_produk\")\nprint(cur.fetchall())\n\nconn.close()\n\n[('Apel', 10), ('Jeruk', 15), ('Pisang', 40)]\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT nama, berat_kg, harga_ribu_rp FROM tabel_produk\")\nprint(cur.fetchall())\n\nconn.close()\n\n[('Apel', 0.2, 3.5), ('Jeruk', 0.15, 2.1), ('Pisang', 0.05, 1.25)]\n\n\nMenambahkan data\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ndata_baru = [\n    (987, 'Brokoli', 70, 0.05, 1.5),\n    (321, 'Wortel', 30, 0.1, 1.8),\n    (135, 'Stroberi', 120, 0.04, 2)\n]\n\ncur.executemany(\"INSERT INTO tabel_produk VALUES (?, ?, ?, ?, ?)\", data_baru)\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nprint(cur.fetchall())\n\nconn.close()\n\n[(123, 'Apel', 10, 0.2, 3.5), (135, 'Stroberi', 120, 0.04, 2.0), (321, 'Wortel', 30, 0.1, 1.8), (456, 'Jeruk', 15, 0.15, 2.1), (789, 'Pisang', 40, 0.05, 1.25), (987, 'Brokoli', 70, 0.05, 1.5)]\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 10, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 1.8)\n(456, 'Jeruk', 15, 0.15, 2.1)\n(789, 'Pisang', 40, 0.05, 1.25)\n(987, 'Brokoli', 70, 0.05, 1.5)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#querying",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#querying",
    "title": "Modul 10 Struktur Data: Pengantar database dengan SQLite",
    "section": "",
    "text": "conn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE stok &lt; 50\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 10, 0.2, 3.5)\n(321, 'Wortel', 30, 0.1, 1.8)\n(456, 'Jeruk', 15, 0.15, 2.1)\n(789, 'Pisang', 40, 0.05, 1.25)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE harga_ribu_rp &gt; 2\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 10, 0.2, 3.5)\n(456, 'Jeruk', 15, 0.15, 2.1)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE nama == 'Stroberi'\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(135, 'Stroberi', 120, 0.04, 2.0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE product_id == 987\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE product_id LIKE '45%'\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(456, 'Jeruk', 15, 0.15, 2.1)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE product_id LIKE '%9'\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(789, 'Pisang', 40, 0.05, 1.25)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE product_id LIKE '1%'\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 10, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE (stok &lt; 50) AND (product_id LIKE '1%')\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 10, 0.2, 3.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE (stok &lt;= 10) OR (harga_ribu_rp &gt; 2)\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 10, 0.2, 3.5)\n(456, 'Jeruk', 15, 0.15, 2.1)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#update-data",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#update-data",
    "title": "Modul 10 Struktur Data: Pengantar database dengan SQLite",
    "section": "",
    "text": "conn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"UPDATE tabel_produk SET stok = 200 WHERE product_id == 123\")\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 1.8)\n(456, 'Jeruk', 15, 0.15, 2.1)\n(789, 'Pisang', 40, 0.05, 1.25)\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"UPDATE tabel_produk SET nama = 'Jeruk nipis' WHERE product_id == 456\")\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 1.8)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(789, 'Pisang', 40, 0.05, 1.25)\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"UPDATE tabel_produk SET harga_ribu_rp = 2.5 WHERE product_id == 321\")\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(789, 'Pisang', 40, 0.05, 1.25)\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"UPDATE tabel_produk SET stok = 10 WHERE product_id == 789\")\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(789, 'Pisang', 10, 0.05, 1.25)\n(987, 'Brokoli', 70, 0.05, 1.5)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#hapus-baris",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#hapus-baris",
    "title": "Modul 10 Struktur Data: Pengantar database dengan SQLite",
    "section": "",
    "text": "conn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"DELETE FROM tabel_produk WHERE product_id == 789\")\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(987, 'Brokoli', 70, 0.05, 1.5)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#order-by-dan-limit",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#order-by-dan-limit",
    "title": "Modul 10 Struktur Data: Pengantar database dengan SQLite",
    "section": "",
    "text": "conn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY nama\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(987, 'Brokoli', 70, 0.05, 1.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY nama DESC\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(321, 'Wortel', 30, 0.1, 2.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(987, 'Brokoli', 70, 0.05, 1.5)\n(123, 'Apel', 200, 0.2, 3.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY nama ASC\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(987, 'Brokoli', 70, 0.05, 1.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY berat_kg\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(135, 'Stroberi', 120, 0.04, 2.0)\n(987, 'Brokoli', 70, 0.05, 1.5)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(123, 'Apel', 200, 0.2, 3.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY harga_ribu_rp\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(987, 'Brokoli', 70, 0.05, 1.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(321, 'Wortel', 30, 0.1, 2.5)\n(123, 'Apel', 200, 0.2, 3.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY harga_ribu_rp DESC\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY harga_ribu_rp DESC LIMIT 3\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY product_id LIMIT 3\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk LIMIT 3\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk ORDER BY product_id\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(987, 'Brokoli', 70, 0.05, 1.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(987, 'Brokoli', 70, 0.05, 1.5)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#tabel-baru-di-database-yang-sama",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#tabel-baru-di-database-yang-sama",
    "title": "Modul 10 Struktur Data: Pengantar database dengan SQLite",
    "section": "",
    "text": "conn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"\"\"CREATE TABLE IF NOT EXISTS tabel_pesanan (\n    order_id INTEGER PRIMARY KEY NOT NULL,\n    tanggal TEXT,\n    jam TEXT,\n    kode_produk INTEGER,\n    jumlah INTEGER,\n    sudah_dibayar INTEGER,\n    FOREIGN KEY(kode_produk) REFERENCES tabel_produk(product_id)\n)\n\"\"\")\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ndata_baru = [\n    (1, '2023-11-05', '14:38:27', 123, 10, 0),\n    (2, '2023-11-16', '09:01:03', 456, 5, 0),\n    (3, '2023-11-17', '23:59:58', 987, 15, 0)\n]\n\ncur.executemany(\"INSERT INTO tabel_pesanan VALUES (?,?,?,?,?,?)\", data_baru)\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n(2, '2023-11-16', '09:01:03', 456, 5, 0)\n(3, '2023-11-17', '23:59:58', 987, 15, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ndata_baru = [\n    ('2023-11-16', '00:09:32', 456, 20, 0),\n    ('2023-11-15', '12:29:17', 135, 5, 0),\n    ('2023-11-17', '15:42:19', 321, 10, 0)\n]\n\ncur.executemany(\"\"\"INSERT INTO tabel_pesanan\n                (tanggal, jam, kode_produk, jumlah, sudah_dibayar)\n                VALUES (?,?,?,?,?)\"\"\", data_baru)\nconn.commit()\n\nconn.close()\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n(2, '2023-11-16', '09:01:03', 456, 5, 0)\n(3, '2023-11-17', '23:59:58', 987, 15, 0)\n(4, '2023-11-16', '00:09:32', 456, 20, 0)\n(5, '2023-11-15', '12:29:17', 135, 5, 0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan ORDER BY tanggal\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n(5, '2023-11-15', '12:29:17', 135, 5, 0)\n(2, '2023-11-16', '09:01:03', 456, 5, 0)\n(4, '2023-11-16', '00:09:32', 456, 20, 0)\n(3, '2023-11-17', '23:59:58', 987, 15, 0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan ORDER BY tanggal, jam\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n(5, '2023-11-15', '12:29:17', 135, 5, 0)\n(4, '2023-11-16', '00:09:32', 456, 20, 0)\n(2, '2023-11-16', '09:01:03', 456, 5, 0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0)\n(3, '2023-11-17', '23:59:58', 987, 15, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan ORDER BY tanggal DESC, jam DESC\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(3, '2023-11-17', '23:59:58', 987, 15, 0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0)\n(2, '2023-11-16', '09:01:03', 456, 5, 0)\n(4, '2023-11-16', '00:09:32', 456, 20, 0)\n(5, '2023-11-15', '12:29:17', 135, 5, 0)\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan WHERE jam &gt; '12:00:00'\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n(3, '2023-11-17', '23:59:58', 987, 15, 0)\n(5, '2023-11-15', '12:29:17', 135, 5, 0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan WHERE jam &gt; '12:00:00' ORDER BY tanggal, jam\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n(5, '2023-11-15', '12:29:17', 135, 5, 0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0)\n(3, '2023-11-17', '23:59:58', 987, 15, 0)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#querying-dan-inner-join-melalui-foreign-key",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul10.html#querying-dan-inner-join-melalui-foreign-key",
    "title": "Modul 10 Struktur Data: Pengantar database dengan SQLite",
    "section": "",
    "text": "conn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\nprint(\"=== Tabel produk ===\")\ncur.execute(\"\"\"SELECT * FROM tabel_produk\"\"\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nprint(\"=== Tabel pesanan ===\")\ncur.execute(\"\"\"SELECT * FROM tabel_pesanan\"\"\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n=== Tabel produk ===\n(123, 'Apel', 200, 0.2, 3.5)\n(135, 'Stroberi', 120, 0.04, 2.0)\n(321, 'Wortel', 30, 0.1, 2.5)\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n(987, 'Brokoli', 70, 0.05, 1.5)\n=== Tabel pesanan ===\n(1, '2023-11-05', '14:38:27', 123, 10, 0)\n(2, '2023-11-16', '09:01:03', 456, 5, 0)\n(3, '2023-11-17', '23:59:58', 987, 15, 0)\n(4, '2023-11-16', '00:09:32', 456, 20, 0)\n(5, '2023-11-15', '12:29:17', 135, 5, 0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_produk WHERE product_id == 456\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(456, 'Jeruk nipis', 15, 0.15, 2.1)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"SELECT * FROM tabel_pesanan WHERE kode_produk == 456\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(2, '2023-11-16', '09:01:03', 456, 5, 0)\n(4, '2023-11-16', '00:09:32', 456, 20, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"\"\"SELECT *\n            FROM tabel_produk INNER JOIN tabel_pesanan\n            ON tabel_produk.product_id == tabel_pesanan.kode_produk\n            \"\"\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(123, 'Apel', 200, 0.2, 3.5, 1, '2023-11-05', '14:38:27', 123, 10, 0)\n(456, 'Jeruk nipis', 15, 0.15, 2.1, 2, '2023-11-16', '09:01:03', 456, 5, 0)\n(987, 'Brokoli', 70, 0.05, 1.5, 3, '2023-11-17', '23:59:58', 987, 15, 0)\n(456, 'Jeruk nipis', 15, 0.15, 2.1, 4, '2023-11-16', '00:09:32', 456, 20, 0)\n(135, 'Stroberi', 120, 0.04, 2.0, 5, '2023-11-15', '12:29:17', 135, 5, 0)\n(321, 'Wortel', 30, 0.1, 2.5, 6, '2023-11-17', '15:42:19', 321, 10, 0)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"\"\"SELECT *\n            FROM tabel_pesanan INNER JOIN tabel_produk\n            ON tabel_pesanan.kode_produk == tabel_produk.product_id\n            \"\"\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n(1, '2023-11-05', '14:38:27', 123, 10, 0, 123, 'Apel', 200, 0.2, 3.5)\n(2, '2023-11-16', '09:01:03', 456, 5, 0, 456, 'Jeruk nipis', 15, 0.15, 2.1)\n(3, '2023-11-17', '23:59:58', 987, 15, 0, 987, 'Brokoli', 70, 0.05, 1.5)\n(4, '2023-11-16', '00:09:32', 456, 20, 0, 456, 'Jeruk nipis', 15, 0.15, 2.1)\n(5, '2023-11-15', '12:29:17', 135, 5, 0, 135, 'Stroberi', 120, 0.04, 2.0)\n(6, '2023-11-17', '15:42:19', 321, 10, 0, 321, 'Wortel', 30, 0.1, 2.5)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"\"\"SELECT tabel_pesanan.tanggal, tabel_produk.nama, tabel_pesanan.jumlah\n            FROM tabel_pesanan INNER JOIN tabel_produk\n            ON tabel_pesanan.kode_produk == tabel_produk.product_id\n            \"\"\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n('2023-11-05', 'Apel', 10)\n('2023-11-16', 'Jeruk nipis', 5)\n('2023-11-17', 'Brokoli', 15)\n('2023-11-16', 'Jeruk nipis', 20)\n('2023-11-15', 'Stroberi', 5)\n('2023-11-17', 'Wortel', 10)\n\n\n\nconn = sqlite3.connect(\"pasar.sqlite3\")\ncur = conn.cursor()\n\ncur.execute(\"\"\"SELECT tabel_pesanan.tanggal, tabel_produk.nama, tabel_pesanan.jumlah\n            FROM tabel_pesanan INNER JOIN tabel_produk\n            ON tabel_pesanan.kode_produk == tabel_produk.product_id\n            WHERE tabel_pesanan.jam &gt; '12:00:00'\n            \"\"\")\nsemua_baris = cur.fetchall()\nfor baris in semua_baris:\n    print(baris)\n\nconn.close()\n\n('2023-11-05', 'Apel', 10)\n('2023-11-17', 'Brokoli', 15)\n('2023-11-15', 'Stroberi', 5)\n('2023-11-17', 'Wortel', 10)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Tugas2.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Tugas2.html",
    "title": "Tugas 2 Praktikum Struktur Data: Stack, Queue, dan berbagai Binary Tree",
    "section": "",
    "text": "Kembali ke Struktur Data (dengan Python)\nTugas ini diberikan pada hari dan tanggal: Sabtu, 25 November 2023\nLink soal dan petunjuk tugas (yaitu link menuju halaman ini):\nhttps://bit.ly/SoalTugas2PrakStrukdat2023Ganjil\n\n\n\nKerjakan secara individu.\nKerjakan tugas ini menggunakan bahasa pemrograman Python dengan file format berupa interactive Python notebook (yaitu file berbentuk .ipynb BUKAN .py), yang bisa dibuat misalnya menggunakan Jupyter Notebook atau Google Colaboratory.\nHarap sertakan penjelasan untuk setiap variabel yang digunakan dan setiap proses secara singkat di sebelah (atas/bawah/kanan) barisnya (dengan comment, #). Selain itu, sertakan juga penjelasan kode (yang bisa mencakupi idenya apa, bagaimana cara eksekusinya, atau tentang algoritma yang digunakan) pada cell di sebelah (atas/bawah) kode.\nFormat nama file untuk Tugas 2 ini adalah:\nKelas SIAK_Tugas2PrakStrukdat_Nama Lengkap_NPM.ipynb\nContoh penamaan yang benar:\nKelas C_Tugas2PrakStrukdat_Evgenii Mikhailovich Landis_2234567890.ipynb\nPengumpulan Tugas 2 dilakukan ke Google Forms berikut ini:\nhttps://bit.ly/KumpulTugas2PrakStrukdat2023Ganjil\nApabila ada yang ingin direvisi setelah pengumpulan, lakukan pengumpulan ulang di Google Forms yang sama, tambahkan keterangan bahwa ada revisi, dan tambahkan kata “revisi” pada bagian akhir nama file, contohnya menjadi\nKelas C_Tugas2PrakStrukdat_Evgenii Mikhailovich Landis_2234567890_revisi.ipynb\nKelas C_Tugas2PrakStrukdat_Evgenii Mikhailovich Landis_2234567890_revisi2.ipynb\nKelas C_Tugas2PrakStrukdat_Evgenii Mikhailovich Landis_2234567890_revisi3.ipynb\n(Revisi boleh dilakukan berkali-kali.)\nDengan durasi pengerjaan sekitar 2 (dua) minggu, tenggat waktu (deadline) pengumpulan Tugas 2 ini (termasuk revisi) adalah Sabtu, 9 Desember 2023, 23.59 WIB.\nSesuai standar Universitas Indonesia, plagiarisme dilarang keras dan bisa menyebabkan nilai tugas praktikum menjadi nol untuk semua pihak yang terlibat, tanpa peringatan apapun. Namun, Anda boleh langsung menggunakan kode yang ada di modul praktikum.\nModule atau package Python yang boleh digunakan (di-import) untuk Tugas 2 ini hanyalah numpy dan graphviz. Apabila Anda berniat ingin menggunakan module lain, harap konfirmasikan ke narahubung terlebih dahulu (bisa saja diperbolehkan).\nNarahubung untuk Tugas 2 Praktikum Struktur Data adalah:\nBisma Rohpanca Joyosumarto (ID LINE: bisma_joyosumarto)\nSilakan hubungi narahubung di atas apabila ada yang ingin ditanyakan atau dikonfirmasikan.\n\n\n\n\n\nBuatlah fungsi print_reverse() yang menerima satu string, membuat suatu ArrayStack (untuk tipe data atau dtype yang sesuai, dengan ukuran yang memadai), memasukkan tiap huruf/karakter dari string yang diinput ke dalam stack tersebut, kemudian melakukan pop terus-menerus hingga stack kosong sambil menampilkan tiap huruf yang di-pop. Pastikan tiap huruf ditampilkan di baris yang sama (kecuali apabila memang ada newline di dalam string yang menjadi input).\nContoh penggunaan fungsi:\n&gt;&gt;&gt; print_reverse(\"Satu dua tiga\")\nagit aud utaS\nHint: dtype yang sesuai adalah untuk menyimpan huruf/karakter (di mana tiap elemen di array berupa string dengan panjang \\(\\le 1\\)), yaitu dtype=str atau sama saja dtype=\"&lt;U1\"\nBuatlah fungsi odd_even_others_sep() yang menerima suatu list, lalu menggunakan sejumlah SLQueue (boleh memilih antara SLLinQueue atau SLCircQueue, sama saja) untuk memisahkan antara tiga kategori yaitu\n\nbilangan ganjil\nbilangan genap\ndata selain bilangan bulat\n\ndengan menjaga relative order (yaitu tanpa mengubah urutan data di kategori yang sama), kemudian mengembalikan list baru di mana ketiga kategori tersebut sudah dikelompokkan/terpisah dengan baik.\nContoh penggunaan fungsi:\n&gt;&gt;&gt; list_lama = [1, 2, \"rumput\", 3.14, 5, 6, 7, \"mobil\", 8]\n&gt;&gt;&gt; hasil = odd_even_others_sep(list_lama)\n&gt;&gt;&gt; print(hasil)\n[1, 5, 7, 2, 6, 8, \"rumput\", 3.14, \"mobil\"]\nHint: cobalah satu queue per kategori.\nBuatlah fungsi get_char_tree() yang menerima suatu string (misal memiliki panjang n), lalu membuat suatu ArrayBintree untuk menyimpan huruf/karakter (pilih dtype yang sesuai), dengan height yang memadai, kemudian memasang n elemen pertama di representasi array nya menjadi n huruf/karakter yang ada di string, sisanya string kosong (dengan emptydata=\"\"). Lalu, ArrayBintree tersebut di-return. Berikan contoh penggunaan fungsinya dan tampilkan gambar dari pohon yang dihasilkan.\nContoh penggunaan fungsi:\n&gt;&gt;&gt; testpohon = get_char_tree(\"strukturdata\")\n&gt;&gt;&gt; display(testpohon.get_digraph_simple())\n\n\n\ntestpohon4\n\n\nHint:\n\nJika n adalah panjang/ukuran string, height yang sesuai untuk ArrayBintree adalah\n\n\\[h = \\lceil \\log_2 \\left(n+1\\right) \\rceil -1\\]\n\nnumpy menyediakan fungsi logaritma np.log yaitu \\(\\ln \\left( x \\right)\\), dan juga fungsi ceiling np.ceil yaitu \\(\\lceil x \\rceil\\) (jangan lupa meng-convert hasil np.ceil menjadi tipe data int)\nBerdasarkan sifat logaritma, \\(\\log_2 \\left(x\\right) = \\frac{\\ln x}{\\ln 2}\\)\n\nBuatlah fungsi max_heap_sort_descending() yang menerima suatu array numpy (bukan list), memasukkan semua elemen array yang diinput ke dalam suatu ArrayMaxHeap, kemudian membentuk suatu array baru dengan mengeluarkan satu-satu elemen dari max heap tersebut, lalu me-return array baru tersebut.\nContoh penggunaan fungsi:\n&gt;&gt;&gt; array1 = np.array([10, 5, 20, 70, 30, 45])\n&gt;&gt;&gt; array2 = max_heap_sort_descending(array1)\n&gt;&gt;&gt; print(array2)\n[70 45 30 20 10  5]\nHint: dtype untuk ArrayMaxHeap bisa disamakan dengan tipe data dari elemen-elemen yang ada di array yang diinput.\nBST vs. AVL\n\nBuatlah fungsi get_bst() yang menerima suatu list atau array, melakukan insertion untuk tiap elemen list/array ke suatu LinkedBST, kemudian me-return LinkedBST tersebut.\nSerupa, buatlah fungsi get_avl() yang menerima suatu list atau array, melakukan insertion untuk tiap elemen list/array ke suatu LinkedAVL, kemudian me-return LinkedAVL tersebut.\nBuatlah array numpy berisi tiap digit di NPM Anda.\nGunakan fungsi max_heap_sort_descending() dengan array yang Anda buat di poin (c) untuk memperoleh array baru yang terurut secara menurun.\nGunakan fungsi get_bst() dan get_avl() tersebut untuk memperoleh suatu LinkedBST dan suatu LinkedAVL dari array yang Anda peroleh di soal poin (d). Abaikan error insertion. Kemudian, tampilkan gambar keduanya.\nBinary tree memiliki height -1 jika kosong, memiliki height 0 jika berisi satu node saja, dan memiliki height 1 jika berisi dua node saja (atau tiga node jika complete). Berapa kah height dari LinkedBST dan dari LinkedAVL yang Anda peroleh di soal poin (e)? Mana yang lebih dangkal/pendek?\n\nContoh penggunaan fungsi:\n&gt;&gt;&gt; arrayNPM = np.array([2, 1, 0, 6, 6, 3, 5, 5, 8, 1])\n&gt;&gt;&gt; arrdesc = max_heap_sort_descending(arrayNPM)\n&gt;&gt;&gt; contohbst = get_bst(arrdesc)\n&gt;&gt;&gt; contohavl = get_avl(arrdesc)\n&gt;&gt;&gt; display(contohbst.get_digraph_simple())\n\n\n\ncontohbst\n\n\n&gt;&gt;&gt; display(contohavl.get_digraph_simple())\n\n\n\ncontohavl"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Tugas2.html#petunjuk-umum",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Tugas2.html#petunjuk-umum",
    "title": "Tugas 2 Praktikum Struktur Data: Stack, Queue, dan berbagai Binary Tree",
    "section": "",
    "text": "Kerjakan secara individu.\nKerjakan tugas ini menggunakan bahasa pemrograman Python dengan file format berupa interactive Python notebook (yaitu file berbentuk .ipynb BUKAN .py), yang bisa dibuat misalnya menggunakan Jupyter Notebook atau Google Colaboratory.\nHarap sertakan penjelasan untuk setiap variabel yang digunakan dan setiap proses secara singkat di sebelah (atas/bawah/kanan) barisnya (dengan comment, #). Selain itu, sertakan juga penjelasan kode (yang bisa mencakupi idenya apa, bagaimana cara eksekusinya, atau tentang algoritma yang digunakan) pada cell di sebelah (atas/bawah) kode.\nFormat nama file untuk Tugas 2 ini adalah:\nKelas SIAK_Tugas2PrakStrukdat_Nama Lengkap_NPM.ipynb\nContoh penamaan yang benar:\nKelas C_Tugas2PrakStrukdat_Evgenii Mikhailovich Landis_2234567890.ipynb\nPengumpulan Tugas 2 dilakukan ke Google Forms berikut ini:\nhttps://bit.ly/KumpulTugas2PrakStrukdat2023Ganjil\nApabila ada yang ingin direvisi setelah pengumpulan, lakukan pengumpulan ulang di Google Forms yang sama, tambahkan keterangan bahwa ada revisi, dan tambahkan kata “revisi” pada bagian akhir nama file, contohnya menjadi\nKelas C_Tugas2PrakStrukdat_Evgenii Mikhailovich Landis_2234567890_revisi.ipynb\nKelas C_Tugas2PrakStrukdat_Evgenii Mikhailovich Landis_2234567890_revisi2.ipynb\nKelas C_Tugas2PrakStrukdat_Evgenii Mikhailovich Landis_2234567890_revisi3.ipynb\n(Revisi boleh dilakukan berkali-kali.)\nDengan durasi pengerjaan sekitar 2 (dua) minggu, tenggat waktu (deadline) pengumpulan Tugas 2 ini (termasuk revisi) adalah Sabtu, 9 Desember 2023, 23.59 WIB.\nSesuai standar Universitas Indonesia, plagiarisme dilarang keras dan bisa menyebabkan nilai tugas praktikum menjadi nol untuk semua pihak yang terlibat, tanpa peringatan apapun. Namun, Anda boleh langsung menggunakan kode yang ada di modul praktikum.\nModule atau package Python yang boleh digunakan (di-import) untuk Tugas 2 ini hanyalah numpy dan graphviz. Apabila Anda berniat ingin menggunakan module lain, harap konfirmasikan ke narahubung terlebih dahulu (bisa saja diperbolehkan).\nNarahubung untuk Tugas 2 Praktikum Struktur Data adalah:\nBisma Rohpanca Joyosumarto (ID LINE: bisma_joyosumarto)\nSilakan hubungi narahubung di atas apabila ada yang ingin ditanyakan atau dikonfirmasikan."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Tugas2.html#soal",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Tugas2.html#soal",
    "title": "Tugas 2 Praktikum Struktur Data: Stack, Queue, dan berbagai Binary Tree",
    "section": "",
    "text": "Buatlah fungsi print_reverse() yang menerima satu string, membuat suatu ArrayStack (untuk tipe data atau dtype yang sesuai, dengan ukuran yang memadai), memasukkan tiap huruf/karakter dari string yang diinput ke dalam stack tersebut, kemudian melakukan pop terus-menerus hingga stack kosong sambil menampilkan tiap huruf yang di-pop. Pastikan tiap huruf ditampilkan di baris yang sama (kecuali apabila memang ada newline di dalam string yang menjadi input).\nContoh penggunaan fungsi:\n&gt;&gt;&gt; print_reverse(\"Satu dua tiga\")\nagit aud utaS\nHint: dtype yang sesuai adalah untuk menyimpan huruf/karakter (di mana tiap elemen di array berupa string dengan panjang \\(\\le 1\\)), yaitu dtype=str atau sama saja dtype=\"&lt;U1\"\nBuatlah fungsi odd_even_others_sep() yang menerima suatu list, lalu menggunakan sejumlah SLQueue (boleh memilih antara SLLinQueue atau SLCircQueue, sama saja) untuk memisahkan antara tiga kategori yaitu\n\nbilangan ganjil\nbilangan genap\ndata selain bilangan bulat\n\ndengan menjaga relative order (yaitu tanpa mengubah urutan data di kategori yang sama), kemudian mengembalikan list baru di mana ketiga kategori tersebut sudah dikelompokkan/terpisah dengan baik.\nContoh penggunaan fungsi:\n&gt;&gt;&gt; list_lama = [1, 2, \"rumput\", 3.14, 5, 6, 7, \"mobil\", 8]\n&gt;&gt;&gt; hasil = odd_even_others_sep(list_lama)\n&gt;&gt;&gt; print(hasil)\n[1, 5, 7, 2, 6, 8, \"rumput\", 3.14, \"mobil\"]\nHint: cobalah satu queue per kategori.\nBuatlah fungsi get_char_tree() yang menerima suatu string (misal memiliki panjang n), lalu membuat suatu ArrayBintree untuk menyimpan huruf/karakter (pilih dtype yang sesuai), dengan height yang memadai, kemudian memasang n elemen pertama di representasi array nya menjadi n huruf/karakter yang ada di string, sisanya string kosong (dengan emptydata=\"\"). Lalu, ArrayBintree tersebut di-return. Berikan contoh penggunaan fungsinya dan tampilkan gambar dari pohon yang dihasilkan.\nContoh penggunaan fungsi:\n&gt;&gt;&gt; testpohon = get_char_tree(\"strukturdata\")\n&gt;&gt;&gt; display(testpohon.get_digraph_simple())\n\n\n\ntestpohon4\n\n\nHint:\n\nJika n adalah panjang/ukuran string, height yang sesuai untuk ArrayBintree adalah\n\n\\[h = \\lceil \\log_2 \\left(n+1\\right) \\rceil -1\\]\n\nnumpy menyediakan fungsi logaritma np.log yaitu \\(\\ln \\left( x \\right)\\), dan juga fungsi ceiling np.ceil yaitu \\(\\lceil x \\rceil\\) (jangan lupa meng-convert hasil np.ceil menjadi tipe data int)\nBerdasarkan sifat logaritma, \\(\\log_2 \\left(x\\right) = \\frac{\\ln x}{\\ln 2}\\)\n\nBuatlah fungsi max_heap_sort_descending() yang menerima suatu array numpy (bukan list), memasukkan semua elemen array yang diinput ke dalam suatu ArrayMaxHeap, kemudian membentuk suatu array baru dengan mengeluarkan satu-satu elemen dari max heap tersebut, lalu me-return array baru tersebut.\nContoh penggunaan fungsi:\n&gt;&gt;&gt; array1 = np.array([10, 5, 20, 70, 30, 45])\n&gt;&gt;&gt; array2 = max_heap_sort_descending(array1)\n&gt;&gt;&gt; print(array2)\n[70 45 30 20 10  5]\nHint: dtype untuk ArrayMaxHeap bisa disamakan dengan tipe data dari elemen-elemen yang ada di array yang diinput.\nBST vs. AVL\n\nBuatlah fungsi get_bst() yang menerima suatu list atau array, melakukan insertion untuk tiap elemen list/array ke suatu LinkedBST, kemudian me-return LinkedBST tersebut.\nSerupa, buatlah fungsi get_avl() yang menerima suatu list atau array, melakukan insertion untuk tiap elemen list/array ke suatu LinkedAVL, kemudian me-return LinkedAVL tersebut.\nBuatlah array numpy berisi tiap digit di NPM Anda.\nGunakan fungsi max_heap_sort_descending() dengan array yang Anda buat di poin (c) untuk memperoleh array baru yang terurut secara menurun.\nGunakan fungsi get_bst() dan get_avl() tersebut untuk memperoleh suatu LinkedBST dan suatu LinkedAVL dari array yang Anda peroleh di soal poin (d). Abaikan error insertion. Kemudian, tampilkan gambar keduanya.\nBinary tree memiliki height -1 jika kosong, memiliki height 0 jika berisi satu node saja, dan memiliki height 1 jika berisi dua node saja (atau tiga node jika complete). Berapa kah height dari LinkedBST dan dari LinkedAVL yang Anda peroleh di soal poin (e)? Mana yang lebih dangkal/pendek?\n\nContoh penggunaan fungsi:\n&gt;&gt;&gt; arrayNPM = np.array([2, 1, 0, 6, 6, 3, 5, 5, 8, 1])\n&gt;&gt;&gt; arrdesc = max_heap_sort_descending(arrayNPM)\n&gt;&gt;&gt; contohbst = get_bst(arrdesc)\n&gt;&gt;&gt; contohavl = get_avl(arrdesc)\n&gt;&gt;&gt; display(contohbst.get_digraph_simple())\n\n\n\ncontohbst\n\n\n&gt;&gt;&gt; display(contohavl.get_digraph_simple())\n\n\n\ncontohavl"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul1.html",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul1.html",
    "title": "Reviewing Pandas Object",
    "section": "",
    "text": "Kembali ke EDA"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul1.html#installing-pandas",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul1.html#installing-pandas",
    "title": "Reviewing Pandas Object",
    "section": "1. Installing Pandas",
    "text": "1. Installing Pandas\nProses download dan install pandas library dapat dilakukan execute baris di bawah ini di local environment’s console masing-masing:\npip install pandas\nJika menggunakan google colab, maka pandas sudah ada sehingga tidak usah menginstall lagi (cukup import). Bila menggunakan anaconda, dapat run baris tersebut di anaconda prompt.\n\nimport pandas\npandas.__version__    #cek versi\n\n'1.0.5'\n\n\nimport pandas dan dinamakan sbg ‘pd’ agar lebih mudah dan efisisen\n\nimport pandas as pd"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul1.html#data-indexing-and-selection",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul1.html#data-indexing-and-selection",
    "title": "Reviewing Pandas Object",
    "section": "3. Data Indexing and Selection",
    "text": "3. Data Indexing and Selection\n\n3.1. Data Selection in Series\n\ndata = pd.Series([0.25, 0.5, 0.75, 1.0],\n                 index=['a', 'b', 'c', 'd'])      #buat sebuah series\ndata\n\na    0.25\nb    0.50\nc    0.75\nd    1.00\ndtype: float64\n\n\n\ndata['d'] = 0.95 # update value dari index 'd' menjadi 0.95\ndata\n\na    0.25\nb    0.50\nc    0.75\nd    0.95\ndtype: float64\n\n\n\ndata['e'] = 1.25 # Menambah value baru dengan index 'e'\ndata\n\na    0.25\nb    0.50\nc    0.75\nd    0.95\ne    1.25\ndtype: float64\n\n\nMelakukan slicing dapat dilakukan dengan dua cara, secara explicit dan implicit (integer index)\n\ndata['a':'c']   #explicit\n\na    0.25\nb    0.50\nc    0.75\ndtype: float64\n\n\n\ndata[0:3]  #implicit integer index\n\na    0.25\nb    0.50\nc    0.75\ndtype: float64\n\n\nKita dapat menampilkan sekumpulan indices yang telah ditentukan dengan menaruhnya ke dalam sebuah list\n\ndata[['a', 'e']]      #  'a' dan 'e' dimasukkan dalam list menjadi ['a','e']\n\na    0.25\ne    1.25\ndtype: float64\n\n\nPerhatikan, saat melakukan slicing dengan explicit index (misal, data ['a':'c']), final index diikutsertakan dalam outputnya, sementara ketika melakukan slicing dengan implicit index (misal, data[0:2]), final index tidak diikutsertakan dalam outputnya. Ketika slicing melalui list (misal, data [['a', 'e']]), semua indices dari a sampai e akan ditampilkan.\n\n\n3.2. Indexers: loc, iloc for Series\nSecara sederhana, loc : slicing & indexing melalui explicit index. Sedangkan iloc : slicing & indexing melalui implisit index (angka)\n\ndata = pd.Series(['Hello', 'DPhir', 'world'], index=['a', 'b', 'c'])     #define sebuah series baru\ndata\n\na    Hello\nb    DPhir\nc    world\ndtype: object\n\n\n\n3.2.1. loc attribute\n\ndata.loc['a']    #menampilkan value dari index 'a'\n\n'Hello'\n\n\n\n\n3.2.2. iloc attribute\n\ndata.iloc[1]   # menampilkan index ke 1\n\n'DPhir'\n\n\n\ndata.iloc[1:3]   #menampilkan index ke 1 dan 2\n\nb    DPhir\nc    world\ndtype: object\n\n\n\n\n\n3.3. Data Selection in DataFrame\n\ndf.head(1)\n\n\n\n\n\n\n\n\nTAHUN\nNAMA PROVINSI\nNAMA KABUPATEN/KOTA\nNAMA KECAMATAN\nNAMA KELURAHAN\nLUAS WILAYAH (KM2)\nKEPADATAN (JIWA/KM2)\n35-39 Laki-Laki\n35-39 Perempuan\n40-44 Laki-Laki\n...\n55-59 Laki-Laki\n55-59 Perempuan\n60-64 Laki-Laki\n60-64 Perempuan\n65-69 Laki-Laki\n65-69 Perempuan\n70-74 Laki-Laki\n70-74 Perempuan\n&gt;75 Laki-Laki\n&gt;75 Perempuan\n\n\n\n\n0\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU UTR\nP. PANGGANG\n0,91\n6779\n231\n235\n233\n...\n98\n106\n72\n65\n36\n33\n33\n20\n13\n27\n\n\n\n\n1 rows × 25 columns\n\n\n\n\ndf['TAHUN']  #menampilkan satu kolom saja (outputnya series)\n\n0      2013\n1      2013\n2      2013\n3      2013\n4      2013\n       ... \n262    2013\n263    2013\n264    2013\n265    2013\n266    2013\nName: TAHUN, Length: 267, dtype: int64\n\n\nOutput yang sama di atas dapat diperoleh dengan :\n\ndf.TAHUN    #Tidak dapat dilakukan pada nama kolom yang mempunyai spasi\n\n0      2013\n1      2013\n2      2013\n3      2013\n4      2013\n       ... \n262    2013\n263    2013\n264    2013\n265    2013\n266    2013\nName: TAHUN, Length: 267, dtype: int64\n\n\n\ndf[['TAHUN']]     #outputnya dataframe\n\nBisa juga membuat sebuah kolom baru yang diperoleh dari gabungan dua kolom lain. Misalkan disini ingin digabung jumlah laki2 dan perempuan yang berusia 50-54\n\ndf['gabungan_50-54'] = df['50-54 Laki-Laki'] + df['50-54 Perempuan']\ndf[['gabungan_50-54','50-54 Laki-Laki','50-54 Perempuan']] .head(3)   #lihat tiga kolom ini aja\n\n\n\n\n\n\n\n\ngabungan_50-54\n50-54 Laki-Laki\n50-54 Perempuan\n\n\n\n\n0\n263\n137\n126\n\n\n1\n63\n34\n29\n\n\n2\n311\n150\n161\n\n\n\n\n\n\n\n\n\n3.4. Indexers: loc, iloc for DataFrame\nSama seperti pada series, loc digunakan untuk slicing menggunakan explicit index(nama indexnya langsung) dan iloc menggunakan implicit index (angka/urutan)\nyang penting pahami bahwa functionnya itu\ndf.iloc[baris, kolom]\n\n3.4.1. loc attribute\nDefinisikan sebuah dataframe baru menggunakan dataset penduduk sebelumnya dengan set ‘NAMA KELUARAHAN’ sebagai index (untuk contoh saja)\n\ndf1 = df.set_index('NAMA KELURAHAN')\n\n\ndf1.head(3)\n\n\n\n\n\n\n\n\nTAHUN\nNAMA PROVINSI\nNAMA KABUPATEN/KOTA\nNAMA KECAMATAN\nLUAS WILAYAH (KM2)\nKEPADATAN (JIWA/KM2)\n35-39 Laki-Laki\n35-39 Perempuan\n40-44 Laki-Laki\n40-44 Perempuan\n...\n55-59 Perempuan\n60-64 Laki-Laki\n60-64 Perempuan\n65-69 Laki-Laki\n65-69 Perempuan\n70-74 Laki-Laki\n70-74 Perempuan\n&gt;75 Laki-Laki\n&gt;75 Perempuan\ngabungan_50-54\n\n\nNAMA KELURAHAN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nP. PANGGANG\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU UTR\n0,91\n6779\n231\n235\n233\n210\n...\n106\n72\n65\n36\n33\n33\n20\n13\n27\n263\n\n\nP. KELAPA\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU UTR\n3,76\n1705\n84\n88\n99\n88\n...\n39\n29\n24\n12\n21\n13\n5\n5\n8\n63\n\n\nP. HARAPAN\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU UTR\n3,59\n628\n255\n238\n232\n234\n...\n101\n73\n56\n18\n35\n24\n25\n18\n26\n311\n\n\n\n\n3 rows × 25 columns\n\n\n\n\ndf1.loc[  :'P. TIDUNG', :'NAMA KECAMATAN']   #menampilkan baris hingga 'P. TIDUNG', kolom hingga 'NAMA KECAMATAN'\n\n\n\n\n\n\n\n\nTAHUN\nNAMA PROVINSI\nNAMA KABUPATEN/KOTA\nNAMA KECAMATAN\n\n\nNAMA KELURAHAN\n\n\n\n\n\n\n\n\nP. PANGGANG\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU UTR\n\n\nP. KELAPA\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU UTR\n\n\nP. HARAPAN\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU UTR\n\n\nP. UNTUNG JAWA\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU SLT\n\n\nP. TIDUNG\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU SLT\n\n\n\n\n\n\n\n\ndf1.loc[['P. KELAPA']]   #menampilkan data dari index 'P. KELAPA'\n\n\n\n\n\n\n\n\nTAHUN\nNAMA PROVINSI\nNAMA KABUPATEN/KOTA\nNAMA KECAMATAN\nLUAS WILAYAH (KM2)\nKEPADATAN (JIWA/KM2)\n35-39 Laki-Laki\n35-39 Perempuan\n40-44 Laki-Laki\n40-44 Perempuan\n...\n55-59 Perempuan\n60-64 Laki-Laki\n60-64 Perempuan\n65-69 Laki-Laki\n65-69 Perempuan\n70-74 Laki-Laki\n70-74 Perempuan\n&gt;75 Laki-Laki\n&gt;75 Perempuan\ngabungan_50-54\n\n\nNAMA KELURAHAN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nP. KELAPA\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU UTR\n3,76\n1705\n84\n88\n99\n88\n...\n39\n29\n24\n12\n21\n13\n5\n5\n8\n63\n\n\n\n\n1 rows × 25 columns\n\n\n\n\n\n3.4.2. iloc attribute\n\ndf1.iloc[:5, :4]\n\n\n\n\n\n\n\n\nTAHUN\nNAMA PROVINSI\nNAMA KABUPATEN/KOTA\nNAMA KECAMATAN\n\n\nNAMA KELURAHAN\n\n\n\n\n\n\n\n\nP. PANGGANG\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU UTR\n\n\nP. KELAPA\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU UTR\n\n\nP. HARAPAN\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU UTR\n\n\nP. UNTUNG JAWA\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU SLT\n\n\nP. TIDUNG\n2013\nPROVINSI DKI JAKARTA\nKAB.ADM.KEP.SERIBU\nKEP. SERIBU SLT\n\n\n\n\n\n\n\n\ndf1.iloc[[222]]\n\n\n\n\n\n\n\n\nTAHUN\nNAMA PROVINSI\nNAMA KABUPATEN/KOTA\nNAMA KECAMATAN\nLUAS WILAYAH (KM2)\nKEPADATAN (JIWA/KM2)\n35-39 Laki-Laki\n35-39 Perempuan\n40-44 Laki-Laki\n40-44 Perempuan\n...\n55-59 Perempuan\n60-64 Laki-Laki\n60-64 Perempuan\n65-69 Laki-Laki\n65-69 Perempuan\n70-74 Laki-Laki\n70-74 Perempuan\n&gt;75 Laki-Laki\n&gt;75 Perempuan\ngabungan_50-54\n\n\nNAMA KELURAHAN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCIPINANG BESAR UTARA\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nJATINEGARA\n1,15\n48850\n2704\n2409\n2344\n2180\n...\n1126\n742\n765\n403\n441\n307\n350\n228\n247\n2943\n\n\n\n\n1 rows × 25 columns\n\n\n\n\n\n\n3.5. Subsetting a Dataframe\ncondition = … (disarankan conditionnya dimasukkin ke variabel gini biar ga bingung dalam penulisannya)\ndf[condition]\ningat bahwa di condition merupakan logical statement dimana harus bernilai TRUE atau FALSE (Boolean)\nMemungkinkan kita untuk mengekstrak/filter bagian dari data yang diinginkan. Misal kita ingin menampilkan data yang luas wilayahnya memenuhi 1 (KM2).\n\ndf['LUAS WILAYAH (KM2)']&gt;1\n\nTypeError: '&gt;' not supported between instances of 'str' and 'int'\n\n\n\ndf['KEPADATAN (JIWA/KM2)']&gt;10000\n\n0      False\n1      False\n2      False\n3      False\n4      False\n       ...  \n262     True\n263    False\n264    False\n265     True\n266    False\nName: KEPADATAN (JIWA/KM2), Length: 267, dtype: bool\n\n\nDiperoleh sebuah series yang berisi boolean value. Jika kita slice data awal dengan boolean value ini, maka akan diperoleh data dengan luas wilayah &gt;1 (yang akan ditampilkan adalah yang True saja)\n\ndf[df['KEPADATAN (JIWA/KM2)']&gt;10000].head()  #head akan menunjukkan 5 baris pertama, ga pakai head juga sabi\n\n\n\n\n\n\n\n\nTAHUN\nNAMA PROVINSI\nNAMA KABUPATEN/KOTA\nNAMA KECAMATAN\nNAMA KELURAHAN\nLUAS WILAYAH (KM2)\nKEPADATAN (JIWA/KM2)\n35-39 Laki-Laki\n35-39 Perempuan\n40-44 Laki-Laki\n...\n55-59 Perempuan\n60-64 Laki-Laki\n60-64 Perempuan\n65-69 Laki-Laki\n65-69 Perempuan\n70-74 Laki-Laki\n70-74 Perempuan\n&gt;75 Laki-Laki\n&gt;75 Perempuan\ngabungan_50-54\n\n\n\n\n7\n2013\nPROVINSI DKI JAKARTA\nJAKARTA PUSAT\nGAMBIR\nCIDENG\n1,26\n14584\n850\n748\n749\n...\n537\n555\n343\n413\n215\n259\n142\n214\n165\n1377\n\n\n8\n2013\nPROVINSI DKI JAKARTA\nJAKARTA PUSAT\nGAMBIR\nPETOJO UTARA\n1,12\n18987\n954\n920\n914\n...\n510\n544\n421\n398\n235\n241\n132\n215\n159\n1415\n\n\n9\n2013\nPROVINSI DKI JAKARTA\nJAKARTA PUSAT\nGAMBIR\nPETOJO SELATAN\n1,14\n14465\n752\n675\n691\n...\n466\n428\n279\n328\n160\n215\n116\n150\n121\n1125\n\n\n10\n2013\nPROVINSI DKI JAKARTA\nJAKARTA PUSAT\nGAMBIR\nKEBON KELAPA\n0,78\n15890\n592\n491\n447\n...\n329\n353\n263\n246\n140\n152\n100\n136\n72\n858\n\n\n11\n2013\nPROVINSI DKI JAKARTA\nJAKARTA PUSAT\nGAMBIR\nDURI PULO\n0,72\n35628\n1213\n1106\n1105\n...\n616\n597\n404\n409\n215\n255\n156\n196\n138\n1682\n\n\n\n\n5 rows × 26 columns\n\n\n\nTerlihat yang ditampilkan adalah data2 dengan luas wilayah &gt;1. Bisa juga diberikan 2 kondisi dan gunakan logical operator\n\ndf[(df['LUAS WILAYAH (KM2)']&gt;1) & (df['KEPADATAN (JIWA/KM2)'] &lt; 1000)]  #  & (and) artinya dua2nyah harus terpenuhi\n\nTypeError: '&gt;' not supported between instances of 'str' and 'int'\n\n\n\ndf[(df['LUAS WILAYAH (KM2)']&gt;1) | (df['KEPADATAN (JIWA/KM2)'] &lt; 1000)].head(3)  #  | (or) artinya yg penting salah satu terpenuhi\n\nSelain operator & dan |, dapat digunakan juga operator ~, yaitu negasi.\n\ndf[~((df['LUAS WILAYAH (KM2)']&gt;1) & (df['LUAS WILAYAH (KM2)']&lt;3))] .head(3)  #selain yang di range 1-3\n\nTypeError: '&gt;' not supported between instances of 'str' and 'int'\n\n\n\ncondition = df['NAMA KECAMATAN']=='CIPAYUNG'\ndf[condition]\n\n\n\n\n\n\n\n\nTAHUN\nNAMA PROVINSI\nNAMA KABUPATEN/KOTA\nNAMA KECAMATAN\nNAMA KELURAHAN\nLUAS WILAYAH (KM2)\nKEPADATAN (JIWA/KM2)\n35-39 Laki-Laki\n35-39 Perempuan\n40-44 Laki-Laki\n...\n55-59 Perempuan\n60-64 Laki-Laki\n60-64 Perempuan\n65-69 Laki-Laki\n65-69 Perempuan\n70-74 Laki-Laki\n70-74 Perempuan\n&gt;75 Laki-Laki\n&gt;75 Perempuan\ngabungan_50-54\n\n\n\n\n259\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nCIPAYUNG\nCIPAYUNG\n3,08\n8441\n1241\n1172\n1029\n...\n469\n374\n278\n164\n177\n112\n101\n61\n110\n1398\n\n\n260\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nCIPAYUNG\nCILANGKAP\n6,03\n4396\n1237\n1276\n1195\n...\n397\n267\n235\n161\n133\n77\n90\n52\n62\n1263\n\n\n261\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nCIPAYUNG\nPONDOK RANGGON\n3,66\n6772\n1088\n1064\n969\n...\n391\n271\n227\n131\n109\n80\n105\n42\n82\n1320\n\n\n262\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nCIPAYUNG\nMUNJUL\n1,9\n12734\n1167\n1112\n1026\n...\n482\n302\n291\n173\n137\n118\n94\n52\n51\n1290\n\n\n263\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nCIPAYUNG\nSETU\n3,25\n6028\n937\n928\n857\n...\n354\n254\n211\n124\n115\n64\n83\n59\n64\n983\n\n\n264\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nCIPAYUNG\nBAMBU APUS\n3,17\n8400\n1242\n1187\n1062\n...\n476\n377\n250\n169\n179\n108\n96\n70\n84\n1572\n\n\n265\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nCIPAYUNG\nLUBANG BUAYA\n3,72\n18055\n3258\n2988\n2732\n...\n1308\n959\n739\n393\n385\n293\n291\n160\n165\n3554\n\n\n266\n2013\nPROVINSI DKI JAKARTA\nJAKARTA TIMUR\nCIPAYUNG\nCEGER\n3,63\n5492\n1007\n930\n874\n...\n390\n279\n214\n110\n153\n101\n53\n45\n44\n996\n\n\n\n\n8 rows × 26 columns\n\n\n\n\ndf['NAMA KECAMATAN']=='CIPAYUNG'\n\n0      False\n1      False\n2      False\n3      False\n4      False\n       ...  \n262     True\n263     True\n264     True\n265     True\n266     True\nName: NAMA KECAMATAN, Length: 267, dtype: bool"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/eda/modul3.html",
    "href": "semuahalaman/modulprak/2023/genap/eda/modul3.html",
    "title": "MATPLOTLIB",
    "section": "",
    "text": "Kembali ke EDA\n\nMATPLOTLIB\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n\n1. Line Plot\n\n\n2. Scatter Plot\n\n\n3. Bar Chart\n\n\n4. Pie Chart\n\n\n5. Sub Plot\n\n#Fungsi Mendasar Matplotlib\n#axes.plot(x,y,label='Sesuatu')\n\nx=[0,1,2,3,4,5,6]\ny=[10,20,30,40,50,60,70]\nfig,axes= plt.subplots(nrows=1,ncols=1,figsize=(12,8))\naxes.plot(x,y,label='Percobaan')\n\n\n\n\n\n\n\n\n\ndates=['2000-01-01','2000-01-02','2000-01-03','2000-01-04','2000-01-05',\n       '2000-01-06','2000-01-07','2000-01-08','2000-01-09','2000-01-10']\n\nmin_temperature=[20.7,17.9,18.8,14.6,17.4,21.8,20.0,15.8,15.8,15.8]\nmax_temperature=[34.7,28.9,31.8,28.4,30.8,32.0,25.6,28.8,21.8,22.8]\n\nfig,axes = plt.subplots(nrows=1,ncols=1,figsize=(12,8))\n\naxes.plot(dates,min_temperature,label='Min Temperature')\naxes.plot(dates,max_temperature,label='Max Temperature')\naxes.legend()\n\n\n\n\n\n\n\n\nAxes.set_xlabel() Mengganti label untuk sumbu x\nAxes.set_ylabel() Mengganti label untuk sumbu y\nAxes.set_xlim() Membatasi sumbu xnya\nAxes.set_ylim() Membatasi sumbu ynya\n\nfig,axes=plt.subplots(nrows=1,ncols=1,figsize=(12,8))\n\naxes.plot(dates,min_temperature,label='Min Temperature')\naxes.plot(dates,max_temperature,label='Max Temperature')\n\naxes.set_xlabel('Date',fontsize=12)\naxes.set_ylabel('Temperature',fontsize=12)\n\naxes.set_title(\"Minimum and Maximum Temperature\",fontsize=12)\n\naxes.set_xticks(dates)\naxes.set_xticklabels(dates)\naxes.tick_params('x',labelsize=12,labelrotation=45,size=12)\n\naxes.set_ylim(10,40)\naxes.set_yticks(np.arange(10,41,2))\n\naxes.legend(fontsize=12,loc='upper left')\n\n\n\n\n\n\n\n\n\nx=[1,2,3,4] #&lt;----- definisikan titik-titik yang ingin dipetakan\ny=[1,2,3,4] #&lt;----- definisikan titik-titik yang ingin dipetakan\n\nfig,axes=plt.subplots(nrows=1,ncols=1,figsize=(12,8))\n\naxes.plot(x,y,label='nama')\n\n\n\n\n\n\n\n\n\n\n\nDATAFRAMES\nSilakan download: Canada.xlsx\n\nhai='Canada.xlsx'\ndf=pd.read_excel(hai,sheet_name='Canada by Citizenship',skiprows=range(20),skipfooter=2)\n\ndf.head() #Kurang spesifik ngambil yang mana\n\n\n\n\n\n\n\n\nType\nCoverage\nOdName\nAREA\nAreaName\nREG\nRegName\nDEV\nDevName\n1980\n...\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n\n\n\n\n0\nImmigrants\nForeigners\nAfghanistan\n935\nAsia\n5501\nSouthern Asia\n902\nDeveloping regions\n16\n...\n2978\n3436\n3009\n2652\n2111\n1746\n1758\n2203\n2635\n2004\n\n\n1\nImmigrants\nForeigners\nAlbania\n908\nEurope\n925\nSouthern Europe\n901\nDeveloped regions\n1\n...\n1450\n1223\n856\n702\n560\n716\n561\n539\n620\n603\n\n\n2\nImmigrants\nForeigners\nAlgeria\n903\nAfrica\n912\nNorthern Africa\n902\nDeveloping regions\n80\n...\n3616\n3626\n4807\n3623\n4005\n5393\n4752\n4325\n3774\n4331\n\n\n3\nImmigrants\nForeigners\nAmerican Samoa\n909\nOceania\n957\nPolynesia\n902\nDeveloping regions\n0\n...\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n4\nImmigrants\nForeigners\nAndorra\n908\nEurope\n925\nSouthern Europe\n901\nDeveloped regions\n0\n...\n0\n0\n1\n1\n0\n0\n0\n0\n1\n1\n\n\n\n\n5 rows × 43 columns\n\n\n\n\n#Menghapus yang ga mau dipake\ndf.drop(['AREA','REG','DEV','Type','Coverage'],axis=1,inplace=True)\n\ndf.head()\n\n\n\n\n\n\n\n\nOdName\nAreaName\nRegName\nDevName\n1980\n1981\n1982\n1983\n1984\n1985\n...\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n\n\n\n\n0\nAfghanistan\nAsia\nSouthern Asia\nDeveloping regions\n16\n39\n39\n47\n71\n340\n...\n2978\n3436\n3009\n2652\n2111\n1746\n1758\n2203\n2635\n2004\n\n\n1\nAlbania\nEurope\nSouthern Europe\nDeveloped regions\n1\n0\n0\n0\n0\n0\n...\n1450\n1223\n856\n702\n560\n716\n561\n539\n620\n603\n\n\n2\nAlgeria\nAfrica\nNorthern Africa\nDeveloping regions\n80\n67\n71\n69\n63\n44\n...\n3616\n3626\n4807\n3623\n4005\n5393\n4752\n4325\n3774\n4331\n\n\n3\nAmerican Samoa\nOceania\nPolynesia\nDeveloping regions\n0\n1\n0\n0\n0\n0\n...\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n4\nAndorra\nEurope\nSouthern Europe\nDeveloped regions\n0\n0\n0\n0\n0\n0\n...\n0\n0\n1\n1\n0\n0\n0\n0\n1\n1\n\n\n\n\n5 rows × 38 columns\n\n\n\n\ndf.rename(columns={'OdName':'Country','AreaName':'Continent','RegName':'Region'},inplace=True)\ndf.head()\n\n\n\n\n\n\n\n\nCountry\nContinent\nRegion\nDevName\n1980\n1981\n1982\n1983\n1984\n1985\n...\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n\n\n\n\n0\nAfghanistan\nAsia\nSouthern Asia\nDeveloping regions\n16\n39\n39\n47\n71\n340\n...\n2978\n3436\n3009\n2652\n2111\n1746\n1758\n2203\n2635\n2004\n\n\n1\nAlbania\nEurope\nSouthern Europe\nDeveloped regions\n1\n0\n0\n0\n0\n0\n...\n1450\n1223\n856\n702\n560\n716\n561\n539\n620\n603\n\n\n2\nAlgeria\nAfrica\nNorthern Africa\nDeveloping regions\n80\n67\n71\n69\n63\n44\n...\n3616\n3626\n4807\n3623\n4005\n5393\n4752\n4325\n3774\n4331\n\n\n3\nAmerican Samoa\nOceania\nPolynesia\nDeveloping regions\n0\n1\n0\n0\n0\n0\n...\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n4\nAndorra\nEurope\nSouthern Europe\nDeveloped regions\n0\n0\n0\n0\n0\n0\n...\n0\n0\n1\n1\n0\n0\n0\n0\n1\n1\n\n\n\n\n5 rows × 38 columns\n\n\n\n\ndf.columns=list(map(str,df.columns)) #Mengubah semua nama kolom menjadi string\ndf.head()\n\n\n\n\n\n\n\n\nCountry\nContinent\nRegion\nDevName\n1980\n1981\n1982\n1983\n1984\n1985\n...\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n\n\n\n\n0\nAfghanistan\nAsia\nSouthern Asia\nDeveloping regions\n16\n39\n39\n47\n71\n340\n...\n2978\n3436\n3009\n2652\n2111\n1746\n1758\n2203\n2635\n2004\n\n\n1\nAlbania\nEurope\nSouthern Europe\nDeveloped regions\n1\n0\n0\n0\n0\n0\n...\n1450\n1223\n856\n702\n560\n716\n561\n539\n620\n603\n\n\n2\nAlgeria\nAfrica\nNorthern Africa\nDeveloping regions\n80\n67\n71\n69\n63\n44\n...\n3616\n3626\n4807\n3623\n4005\n5393\n4752\n4325\n3774\n4331\n\n\n3\nAmerican Samoa\nOceania\nPolynesia\nDeveloping regions\n0\n1\n0\n0\n0\n0\n...\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n4\nAndorra\nEurope\nSouthern Europe\nDeveloped regions\n0\n0\n0\n0\n0\n0\n...\n0\n0\n1\n1\n0\n0\n0\n0\n1\n1\n\n\n\n\n5 rows × 38 columns\n\n\n\n\ndf.set_index('Country',inplace=True) #Mengubah Country menajadi index\n\n\ndf.head()\n\n\n\n\n\n\n\n\nContinent\nRegion\nDevName\n1980\n1981\n1982\n1983\n1984\n1985\n1986\n...\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n\n\nCountry\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfghanistan\nAsia\nSouthern Asia\nDeveloping regions\n16\n39\n39\n47\n71\n340\n496\n...\n2978\n3436\n3009\n2652\n2111\n1746\n1758\n2203\n2635\n2004\n\n\nAlbania\nEurope\nSouthern Europe\nDeveloped regions\n1\n0\n0\n0\n0\n0\n1\n...\n1450\n1223\n856\n702\n560\n716\n561\n539\n620\n603\n\n\nAlgeria\nAfrica\nNorthern Africa\nDeveloping regions\n80\n67\n71\n69\n63\n44\n69\n...\n3616\n3626\n4807\n3623\n4005\n5393\n4752\n4325\n3774\n4331\n\n\nAmerican Samoa\nOceania\nPolynesia\nDeveloping regions\n0\n1\n0\n0\n0\n0\n0\n...\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\nAndorra\nEurope\nSouthern Europe\nDeveloped regions\n0\n0\n0\n0\n0\n0\n2\n...\n0\n0\n1\n1\n0\n0\n0\n0\n1\n1\n\n\n\n\n5 rows × 37 columns\n\n\n\n\ndf['Total']=df.sum(axis=1)\ndf.head()\n\n\n\n\n\n\n\n\nContinent\nRegion\nDevName\n1980\n1981\n1982\n1983\n1984\n1985\n1986\n...\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\nTotal\n\n\nCountry\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfghanistan\nAsia\nSouthern Asia\nDeveloping regions\n16\n39\n39\n47\n71\n340\n496\n...\n3436\n3009\n2652\n2111\n1746\n1758\n2203\n2635\n2004\n58639\n\n\nAlbania\nEurope\nSouthern Europe\nDeveloped regions\n1\n0\n0\n0\n0\n0\n1\n...\n1223\n856\n702\n560\n716\n561\n539\n620\n603\n15699\n\n\nAlgeria\nAfrica\nNorthern Africa\nDeveloping regions\n80\n67\n71\n69\n63\n44\n69\n...\n3626\n4807\n3623\n4005\n5393\n4752\n4325\n3774\n4331\n69439\n\n\nAmerican Samoa\nOceania\nPolynesia\nDeveloping regions\n0\n1\n0\n0\n0\n0\n0\n...\n0\n1\n0\n0\n0\n0\n0\n0\n0\n6\n\n\nAndorra\nEurope\nSouthern Europe\nDeveloped regions\n0\n0\n0\n0\n0\n0\n2\n...\n0\n1\n1\n0\n0\n0\n0\n1\n1\n15\n\n\n\n\n5 rows × 38 columns\n\n\n\n\nyears=list(map(str,range(1980,2014))) #buatlah sebuah list berupa pemetaan string dimana rangenya itu dari 1980 sampai 2014\nyears\n\n['1980',\n '1981',\n '1982',\n '1983',\n '1984',\n '1985',\n '1986',\n '1987',\n '1988',\n '1989',\n '1990',\n '1991',\n '1992',\n '1993',\n '1994',\n '1995',\n '1996',\n '1997',\n '1998',\n '1999',\n '2000',\n '2001',\n '2002',\n '2003',\n '2004',\n '2005',\n '2006',\n '2007',\n '2008',\n '2009',\n '2010',\n '2011',\n '2012',\n '2013']\n\n\n\n\nLINE CHART\n\nalgeria = df.loc['Algeria',years]\nalgeria\n\n1980      80\n1981      67\n1982      71\n1983      69\n1984      63\n1985      44\n1986      69\n1987     132\n1988     242\n1989     434\n1990     491\n1991     872\n1992     795\n1993     717\n1994     595\n1995    1106\n1996    2054\n1997    1842\n1998    2292\n1999    2389\n2000    2867\n2001    3418\n2002    3406\n2003    3072\n2004    3616\n2005    3626\n2006    4807\n2007    3623\n2008    4005\n2009    5393\n2010    4752\n2011    4325\n2012    3774\n2013    4331\nName: Algeria, dtype: object\n\n\n\nalgeria.index=algeria.index.map(int) #Mengubah tahun menjadi integer\nalgeria\n\n1980      80\n1981      67\n1982      71\n1983      69\n1984      63\n1985      44\n1986      69\n1987     132\n1988     242\n1989     434\n1990     491\n1991     872\n1992     795\n1993     717\n1994     595\n1995    1106\n1996    2054\n1997    1842\n1998    2292\n1999    2389\n2000    2867\n2001    3418\n2002    3406\n2003    3072\n2004    3616\n2005    3626\n2006    4807\n2007    3623\n2008    4005\n2009    5393\n2010    4752\n2011    4325\n2012    3774\n2013    4331\nName: Algeria, dtype: object\n\n\n\nalgeria.plot(kind='line',figsize=(10,6))\n\nplt.title('Citizenship Algeria')\n\nplt.ylabel('Banyak Warga')\nplt.xlabel('Tahun')\n\nText(0.5, 0, 'Tahun')\n\n\n\n\n\n\n\n\n\n\nalbania=df.loc['Albania',years]\nalbania.index=albania.index.map(int)\n\nalbania.plot(kind='line',figsize=(10,6))\nalgeria.plot(kind='line',figsize=(10,6))\n\nplt.title('Citizenship Algeria')\n\nplt.ylabel('Banyak Warga')\nplt.xlabel('Tahun')\n\nText(0.5, 0, 'Tahun')\n\n\n\n\n\n\n\n\n\n\n\nSCATTER PLOT\n\ndf_total=pd.DataFrame(df[years].sum(axis=0))\ndf_total\n\n\n\n\n\n\n\n\n0\n\n\n\n\n1980\n99137\n\n\n1981\n110563\n\n\n1982\n104271\n\n\n1983\n75550\n\n\n1984\n73417\n\n\n1985\n69978\n\n\n1986\n86048\n\n\n1987\n134771\n\n\n1988\n139306\n\n\n1989\n164432\n\n\n1990\n188054\n\n\n1991\n207509\n\n\n1992\n221687\n\n\n1993\n222049\n\n\n1994\n193665\n\n\n1995\n187712\n\n\n1996\n200085\n\n\n1997\n192885\n\n\n1998\n160727\n\n\n1999\n179818\n\n\n2000\n216712\n\n\n2001\n242643\n\n\n2002\n223111\n\n\n2003\n217297\n\n\n2004\n232083\n\n\n2005\n257457\n\n\n2006\n247057\n\n\n2007\n232405\n\n\n2008\n243047\n\n\n2009\n248768\n\n\n2010\n276956\n\n\n2011\n246194\n\n\n2012\n256222\n\n\n2013\n257537\n\n\n\n\n\n\n\n\ndf_total.reset_index(inplace=True)\ndf_total\n\n\n\n\n\n\n\n\nindex\n0\n\n\n\n\n0\n1980\n99137\n\n\n1\n1981\n110563\n\n\n2\n1982\n104271\n\n\n3\n1983\n75550\n\n\n4\n1984\n73417\n\n\n5\n1985\n69978\n\n\n6\n1986\n86048\n\n\n7\n1987\n134771\n\n\n8\n1988\n139306\n\n\n9\n1989\n164432\n\n\n10\n1990\n188054\n\n\n11\n1991\n207509\n\n\n12\n1992\n221687\n\n\n13\n1993\n222049\n\n\n14\n1994\n193665\n\n\n15\n1995\n187712\n\n\n16\n1996\n200085\n\n\n17\n1997\n192885\n\n\n18\n1998\n160727\n\n\n19\n1999\n179818\n\n\n20\n2000\n216712\n\n\n21\n2001\n242643\n\n\n22\n2002\n223111\n\n\n23\n2003\n217297\n\n\n24\n2004\n232083\n\n\n25\n2005\n257457\n\n\n26\n2006\n247057\n\n\n27\n2007\n232405\n\n\n28\n2008\n243047\n\n\n29\n2009\n248768\n\n\n30\n2010\n276956\n\n\n31\n2011\n246194\n\n\n32\n2012\n256222\n\n\n33\n2013\n257537\n\n\n\n\n\n\n\n\ndf_total.columns=['year','total']\ndf_total\n\n\n\n\n\n\n\n\nyear\ntotal\n\n\n\n\n0\n1980\n99137\n\n\n1\n1981\n110563\n\n\n2\n1982\n104271\n\n\n3\n1983\n75550\n\n\n4\n1984\n73417\n\n\n5\n1985\n69978\n\n\n6\n1986\n86048\n\n\n7\n1987\n134771\n\n\n8\n1988\n139306\n\n\n9\n1989\n164432\n\n\n10\n1990\n188054\n\n\n11\n1991\n207509\n\n\n12\n1992\n221687\n\n\n13\n1993\n222049\n\n\n14\n1994\n193665\n\n\n15\n1995\n187712\n\n\n16\n1996\n200085\n\n\n17\n1997\n192885\n\n\n18\n1998\n160727\n\n\n19\n1999\n179818\n\n\n20\n2000\n216712\n\n\n21\n2001\n242643\n\n\n22\n2002\n223111\n\n\n23\n2003\n217297\n\n\n24\n2004\n232083\n\n\n25\n2005\n257457\n\n\n26\n2006\n247057\n\n\n27\n2007\n232405\n\n\n28\n2008\n243047\n\n\n29\n2009\n248768\n\n\n30\n2010\n276956\n\n\n31\n2011\n246194\n\n\n32\n2012\n256222\n\n\n33\n2013\n257537\n\n\n\n\n\n\n\n\ndf_total.plot('year','total',kind='scatter',figsize=(10,6))\n\n\n\n\n\n\n\n\n\ndf_total.plot('year','total',kind='scatter',figsize=(10,6))\n\nplt.title('Scatters Plot')\nplt.xticks(rotation='vertical')\n\n([0,\n  1,\n  2,\n  3,\n  4,\n  5,\n  6,\n  7,\n  8,\n  9,\n  10,\n  11,\n  12,\n  13,\n  14,\n  15,\n  16,\n  17,\n  18,\n  19,\n  20,\n  21,\n  22,\n  23,\n  24,\n  25,\n  26,\n  27,\n  28,\n  29,\n  30,\n  31,\n  32,\n  33],\n &lt;a list of 34 Text major ticklabel objects&gt;)\n\n\n\n\n\n\n\n\n\n\n\nPIE CHARTS\n\ndf_continents=df.groupby('Continent',axis=0).sum()\ndf_continents\n\n\n\n\n\n\n\n\n1980\n1981\n1982\n1983\n1984\n1985\n1986\n1987\n1988\n1989\n...\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\nTotal\n\n\nContinent\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfrica\n3951\n4363\n3819\n2671\n2639\n2650\n3782\n7494\n7552\n9894\n...\n27523\n29188\n28284\n29890\n34534\n40892\n35441\n38083\n38543\n618948\n\n\nAsia\n31025\n34314\n30214\n24696\n27274\n23850\n28739\n43203\n47454\n60256\n...\n159253\n149054\n133459\n139894\n141434\n163845\n146894\n152218\n155075\n3317794\n\n\nEurope\n39760\n44802\n42720\n24638\n22287\n20844\n24370\n46698\n54726\n60893\n...\n35955\n33053\n33495\n34692\n35078\n33425\n26778\n29177\n28691\n1410947\n\n\nLatin America and the Caribbean\n13081\n15215\n16769\n15427\n13678\n15171\n21179\n28471\n21924\n25060\n...\n24747\n24676\n26011\n26547\n26867\n28818\n27856\n27173\n24950\n765148\n\n\nNorthern America\n9378\n10030\n9074\n7100\n6661\n6543\n7074\n7705\n6469\n6790\n...\n8394\n9613\n9463\n10190\n8995\n8142\n7677\n7892\n8503\n241142\n\n\nOceania\n1942\n1839\n1675\n1018\n878\n920\n904\n1200\n1181\n1539\n...\n1585\n1473\n1693\n1834\n1860\n1834\n1548\n1679\n1775\n55174\n\n\n\n\n6 rows × 35 columns\n\n\n\n\ndf_continents['Total'].plot(kind='pie',figsize=(5,6),autopct='%1.1f%%') #yang persen gaje nambahin persen\n\n\n\n\n\n\n\n\n\ndf_continents['Total'].plot(kind='pie',figsize=(5,6),autopct='%1.1f%%',startangle=90,shadow=True) #wow diputer 90 derajat plus ada bayangan\n\nplt.axis('equal') #untuk bulat sempurna katanya sih gitu\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBAR CHART\n\nalgeria.head()\n\n1980    80\n1981    67\n1982    71\n1983    69\n1984    63\nName: Algeria, dtype: object\n\n\n\nalgeria.plot(kind='bar',figsize=(10,6))\n\nplt.xlabel('Year')\nplt.ylabel('Banyak Warga')\nplt.title('Bar Chart')\n\nText(0.5, 1.0, 'Bar Chart')\n\n\n\n\n\n\n\n\n\n\nalgeria.plot(kind='barh',figsize=(10,6))\n\nplt.xlabel('Year')\nplt.ylabel('Banyak Warga')\nplt.title('Bar Chart')\n\nText(0.5, 1.0, 'Bar Chart')\n\n\n\n\n\n\n\n\n\n\n\nSUBPLOT\n\nsns.set_style('whitegrid')\n\nfig=plt.figure(figsize=(30,20))\nax0=fig.add_subplot(1,2,1)\nax1=fig.add_subplot(1,2,2)\n\n#pie\ndf_continents['Total'].plot(kind='pie',ax=ax0) #Maksudnya plotnya ini ditaruh di kanvas ax0\nax0.set_title('Pie Chart')\nax0.axis('equal')\n\n#line\nalgeria.plot(kind='line',figsize=(15,6),ax=ax1)\nalbania.plot(kind='line',figsize=(15,6),ax=ax1)\nax1.set_title('Line Plot')\n\nax1.set_ylabel('Jumlah Warga')\nax1.set_xlabel('Tahun')\n\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/metnum2023genap.html",
    "href": "semuahalaman/modulprak/2023/genap/metnum/metnum2023genap.html",
    "title": "Praktikum Metode Numerik 2023 Genap (Kurikulum 2020)",
    "section": "",
    "text": "Kembali ke Praktikum\nIni adalah versi website (yang baru dibuat setelah semester ini berakhir) dari modul dan soal tugas yang ada di link berikut: https://bit.ly/TugasModulMetnum2023Genap\n\nTimeline\n\nModul 1: Review Python, NumPy, Tabulate, 27 Februari–3 Maret 2023 (offline di Lab Departemen Matematika D.311)\nModul 2: Root-finding, 6-10 Maret 2023 (offline di Lab Departemen Matematika D.311)\nTugas 1: Root-finding\nDiberikan: Minggu, 12 Maret 2023, 17.11 WIB\nDeadline: Sabtu, 25 Maret 2023, 23.59 WIB\nModul 3: Interpolasi, 20-24 Maret 2023 (offline di Lab Departemen Matematika D.311)\nTugas 2: Interpolasi\nDiberikan: Selasa, 28 Maret 2023, 19.42 WIB\nDeadline: Selasa, 18 April 2023, 23.59 WIB\nModul 4: Diferensiasi Numerik, Ekstrapolasi Richardson, 27-31 Maret 2023 (asinkronus)\nTugas 3: Diferensiasi Numerik, Ekstrapolasi Richardson\nDiberikan: Selasa, 18 April 2023, 11.45 WIB\nDeadline: Minggu, 30 April 2023, 23.59 WIB\nModul 5: Integrasi Numerik, 8-12 Mei 2023 (offline di Lab Departemen Matematika D.311)\nTugas 4: Integrasi Numerik\nDiberikan: Minggu, 14 Mei 2023, 18.00 WIB\nDeadline: Sabtu, 27 Mei 2023, 23.59 WIB\nModul 6: Metode Langsung untuk SPL, 15-19 Mei 2023 (offline di Lab Departemen Matematika D.311)\nTugas 5: Metode Numerik untuk SPL\nDiberikan: Senin, 29 Mei 2023, 07.00 WIB\nDeadline: Minggu, 4 Juni 2023, 13.00 WIB\nModul 7: Metode Iteratif untuk SPL, 29 Mei–2 Juni 2023 (offline di Lab Departemen Matematika D.311)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul2.html",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul2.html",
    "title": "SymPy",
    "section": "",
    "text": "Praktikum Metode Numerik - Pertemuan 2\nKembali ke Metode Numerik\nOUTLINE\n\nSymPy\nMetode Bisection\nMetode Fixed Point\nMetode Newton biasa (dengan turunan analitik)\nMetode Newton dengan Beda Hingga (Finite-Difference Newton’s Method)\nMetode Secant\nMetode Regula Falsi (penjelasan tanpa kode)\nApa itu barisan? (penjelasan tanpa kode)\nMetode Aitken\nMetode Steffensen: Penerapan Metode Aitken pada Metode Fixed Point\n\n\nSymPy\nDalam pembelajaran metode numerik, seringkali kita perlu membandingkan hasil aproksimasi kita dengan nilai yang sesungguhnya. Seringkali pula, sebenarnya nilai yang sesungguhnya itu dapat kita peroleh (karena kita masih dalam tahap belajar; penerapan metode numerik di dunia nyata adalah pada kasus di mana nilai eksak tidak dapat diperoleh).\nHasil perhitungan eksak (seperti perhitungan menggunakan aljabar biasa atau ilmu kalkulus) juga disebut hasil perhitungan analitik atau simbolik. Istilah “analitik” bisa dianggap antonim dari istilah “numerik”.\nDi Python, ada module/package bernama SymPy (symbolic Python) yang dapat melakukan perhitungan simbolik, seperti menghitung turunan, yang misalnya digunakan di metode Newton.\n(Fun fact: aplikasi/package di komputer yang dapat melakukan perhitungan simbolik disebut Computer Algebra System (CAS). Beberapa contoh CAS adalah SymPy, Wolfram Mathematica, dan Maple.)\nMari kita import sympy:\n\nimport sympy\n\nSeperti untuk NumPy dan tabulate, apabila terjadi error karena sympy tidak ditemukan, artinya package sympy belum terinstall, dan bisa di-install menggunakan pip install sympy (atau dengan tanda seru: !pip install sympy)\n\npip install sympy\n\nRequirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.11.1)\nRequirement already satisfied: mpmath&gt;=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy) (1.2.1)\nNote: you may need to restart the kernel to use updated packages.\n\n\nTentunya, penggunaan SymPy melibatkan variabel. Misalnya, kita ingin melakukan perhitungan simbolik dengan variabel \\(x\\). Kita perlu memberitahu SymPy, dengan syntax seperti berikut:\n\nx = sympy.symbols(\"x\")\n\nArtinya, kita baru saja memberitahu SymPy bahwa, pada string apapun yang dijumpai oleh SymPy, huruf “x” perlu dianggap sebagai simbol, atau lebih tepatnya sebagai variabel.\nPerhatikan pula bahwa kode di atas adalah assignment ke variabel pemrograman yang juga bernama x. Dengan demikian, untuk ke depannya, variabel x yang kita ketik di mana saja pada program kita akan dianggap sebagai variabel “x” oleh SymPy.\nDengan variabel x tersebut, kita dapat mendefinisikan suatu expression (ekspresi atau kalimat matematika), misal \\(5x^4\\), seperti berikut:\n\npolinom = 5 * (x ** 4) / 2\nprint(polinom)\n\n5*x**4/2\n\n\nSymPy memiliki fitur pprint (pretty print), yaitu menampilkan suatu ekspresi secara cantik atau indah, layaknya seperti kita tulis di kertas:\n\nsympy.pprint(polinom)\n\n   4\n5⋅x \n────\n 2  \n\n\nUntuk melakukan diferensiasi atau menghitung turunan (dalam hal ini secara simbolik/analitik), gunakan sympy.diff:\n\nturunan = sympy.diff(polinom, x)\nsympy.pprint(turunan)\n\n    3\n10⋅x \n\n\ndengan begitu, SymPy menghitung turunan dari ekspresi polinom yang kita berikan itu, terhadap variabel x. Sebenarnya, mengetik sympy.diff(polinom) saja sudah cukup, tapi lebih lengkap lebih baik.\nSejauh ini, semua ekspresi yang kita jumpai masih berbentuk simbol/tulisan, sehingga kita belum bisa men-substitusi variabel x dengan sembarang nilai. Misalnya kita ingin menjadikan ekspresi di atas sebagai suatu fungsi func(x), di mana kita bisa memasukkan nilai x apapun dan mendapatkan hasil. Caranya adalah menggunakan sympy.lambdify:\n\nfunc = sympy.lambdify(x, turunan)\nprint(func(5))\n\n1250\n\n\nPada syntax lambdify di atas, kita perlu memberitahu SymPy terlebih dahulu, variabel apa yang digunakan pada ekspresi tersebut; barulah kita tuliskan ekspresinya. Dalam hal ini, kita mengetik sympy.lambdify(x, turunan) karena sedang menggunakan variabel x untuk ekspresi turunan yang ingin kita ubah menjadi fungsi yang bisa di-substitusi nilai x nya.\nFungsi hasil lambdify sudah bisa digunakan seperti fungsi lainnya pada Python. Bahkan, kita bisa mencampur penggunaan SymPy dengan NumPy (maupun package lainnya). Contohnya, setelah tadi memperoleh func(x) dari SymPy:\n\nimport numpy as np\n\n\narr = np.array([2, 3, 5, 10])\nprint(func(arr))\n\n[   80   270  1250 10000]\n\n\nSeperti NumPy, SymPy juga memiliki fungsi sin, cos, log, exp dll, sehingga kita bisa melakukan perhitungan analitik yang melibatkan fungsi-fungsi tersebut.\n\ng = x**2 * sympy.cos(x) + sympy.exp(-5*x)\nprint(\"Fungsinya:\")\nsympy.pprint(g)\n\ngp = sympy.diff(g, x)\nprint(\"Turunannya:\")\nsympy.pprint(gp)\n\nFungsinya:\n 2           -5⋅x\nx ⋅cos(x) + ℯ    \nTurunannya:\n   2                          -5⋅x\n- x ⋅sin(x) + 2⋅x⋅cos(x) - 5⋅ℯ    \n\n\nMeskipun kita bisa saja melakukan, misalnya, from sympy import cos, hal tersebut tidak disarankan, apalagi ketika program kita juga menggunkaan NumPy dengan from numpy import cos atau bahkan from numpy import *. Alasannya, dengan begitu, program bisa menjadi membingungkan, karena tidak ada pembeda antara cos dari NumPy (numerik) dengan cos dari SymPy (analitik/simbolik).\nNamun, kalau Anda berhati-hati dan hanya melakukan hal tersebut untuk salah satu package saja, silakan.\nMenariknya, SymPy bisa jadi lebih unggul daripada NumPy untuk beberapa perhitungan yang melibatkan akurasi tinggi, terutama untuk perhitungan yang sebenarnya bersifat analitik. Misalnya, kita tahu bahwa \\(\\sin(\\pi) = 0\\). Menurut SymPy,\n\nprint(\"Menurut SymPy, sin(pi) = \" + str(sympy.sin(sympy.pi)))\n\nMenurut SymPy, sin(pi) = 0\n\n\nkarena SumPy menghitung nilai sin dari \\(\\pi\\) secara analitik, yaitu tanpa perlu menghitung nilai \\(\\pi\\) (karena nilainya sudah jelas nol berdasarkan sifat fungsi sin). Sedangkan, NumPy mengaproksimasi nilai \\(\\pi\\) terlebih dahulu, barulah hasil aproksimasi tersebut yang masuk ke fungsi sin. Hasil perhitungan fungsi sin tersebut pun juga aproksimasi, sehingga didapatkan hasil seperti berikut, yaitu sangat kecil tetapi bukan nol:\n\nprint(\"Menurut NumPy, sin(pi) = \" + str(np.sin(np.pi)))\n\nMenurut NumPy, sin(pi) = 1.2246467991473532e-16\n\n\ndi mana “e-16” artinya “dikali 10 pangkat -16”.\n\n\nMetode Bisection\nMetode Bisection adalah salah satu metode yang dapat kita gunakan dalam masalah pencarian akar (root finding). Akar dari suatu persamaan didefinisikan sebagai nilai \\(x\\) yang memenuhi \\(f(x) = 0\\). Misalkan \\(f\\) adalah suatu fungsi kontinu terdefinisi di \\([a,b]\\), di mana \\(f(a)\\) dan \\(f(b)\\) berlawanan tanda (sehingga pasti ada akar pada interval tersebut, menurut Teorema Nilai Antara / Intermediate Value Theorem).\nInti sari dari metode Bisection adalah\n\nmenebak bahwa akar suatu persamaan ada di dalam interval tertentu \\([a, b]\\);\nmenelusuri nilai fungsi pada nilai tengah atau rata-rata dari interval tersebut;\nmempersempit interval dengan memanfaatkan hasil rata-rata tersebut; dan\nterus mencari nilai tengah dari interval yang baru, yang kemudian dipersempit lalu dicari nilai tengahnya, dan seterusnya hingga akar ditemukan, atau hingga ukuran interval sudah cukup kecil sehingga memuaskan (yaitu sudah lebih kecil dari toleransi).\n\nDidefinisikan nilai tengah dari interval:\n\n\n\\(p=\\frac{(a+b)}{2}\\)\n\n\nAkan dicari \\(f(p)\\) dengan syarat sebagai berikut:\n\njika \\(f(p) = 0\\), maka \\(p\\) adalah akar dari \\(f\\)\njika \\(f(p)f(a) &gt; 0\\), maka \\(sign(f(p)) = sign(f(a))\\). Sehingga, kita dapat mempersempit interval dengan memilih batasan baru yaitu a = p dan b tidak berubah.\njika \\(f(p)f(a) &lt; 0\\), maka \\(sign(f(p)) \\neq sign (f(a))\\), atau \\(sign(f(p)) = sign(f(b))\\). Sehingga, kita dapat mempersempit interval dengan memilih batasan baru yaitu a tidak berubah dan b = p.\n\nMetode Bisection memiliki order of convergence = 1, atau disebut memiliki kekonvergenan linier (linear convergence). Artinya, dalam proses menemukan akar persamaan (konvergen menuju jawabannya), metode Bisection tidak secepat beberapa metode lainnya yang memiliki order of convergence yang lebih tinggi.\n\nfrom numpy import sin, cos, tan, log, exp, sqrt, pi\n\nformula = input('Masukkan formula fungsi: ')\n\ndef f(x):\n    return eval(formula)\n\ndef Bisection(lower, upper, tolerance):\n    if f(lower)*f(upper)&lt;0:\n        p0=lower\n        p=(lower+upper)/2\n        if f(p)==0:\n            return p\n        elif f(p)*f(lower)&gt;0:\n            lower=p\n        elif f(p)*f(lower)&lt;0:\n            upper=p\n \n        abs_error=abs(p0-p)\n        p0=p\n \n        while abs_error &gt; tolerance:\n            p=(lower+upper)/2\n            \n            if f(p)==0:\n                break\n            elif f(p)*f(lower)&gt;0:\n                lower=p\n            elif f(p)*f(lower)&lt;0:\n                upper=p\n        \n            abs_error=abs(p0-p)\n            p0=p\n \n        return p\n \n    else:\n        if f(lower)*f(upper)&gt;0:\n            return \"Metode gagal mengaproksimasi akar. Silahkan ubah batas atas atau batas bawah\"\n        else:\n            if f(lower)==0:\n                return lower\n            else: #f(upper)==0\n                return upper\n\nlow_bound = eval(input(\"Masukkan batas bawah interval: \"))\nup_bound = eval(input(\"Masukkan batas atas interval: \"))\ntolerance = eval(input(\"Masukkan toleransi aproksimasi: \"))\n\nakar_bisection=Bisection(low_bound,up_bound,tolerance)\n\ntry:\n    print(\"Akar persamaan {0} = 0 adalah x = {1:.7f}\".format(formula,\n    akar_bisection))\nexcept ValueError:\n    print(akar_bisection)\n\nMasukkan formula fungsi: 2*x - 3*cos(x) + exp(-5*x) - 9\nMasukkan batas bawah interval: -3\nMasukkan batas atas interval: 2\nMasukkan toleransi aproksimasi: 10**(-7)\nAkar persamaan 2*x - 3*cos(x) + exp(-5*x) - 9 = 0 adalah x = -0.5073225\n\n\n\n\nMetode Fixed-Point\nInti sari dari Metode Fixed-Point adalah mencari fixed-point (titik tetap) dari suatu fungsi (misal fungsi \\(g(x)\\)), yaitu suatu nilai \\(p\\) sehingga \\(p = g(p)\\), atau \\(p - g(p) = 0\\). Titik \\(p\\) disebut titik tetap, karena ketika nilai \\(p\\) dimasukkan ke fungsi \\(g(x)\\), hasilnya tetaplah \\(p\\). Untuk nilai \\(x\\) yang dekat dengan \\(p\\), biasanya ada kecenderungan nilai \\(g(x)\\) menjadi semakin mendekati \\(p\\).\nPerhatikan bahwa, sembarang persamaan \\(f(x) = 0\\) bisa diubah bentuknya dengan mendefinisikan fungsi \\(g(x) = x - f(x)\\) (sehingga \\(f(x) = x - g(x)\\)). Dengan demikian, permasalahan mencari akar berubah menjadi permasalahan mencari fixed-point, yaitu mencari nilai \\(p\\) sehingga \\(p = g(p)\\) atau \\(p - g(p) = 0\\) (sehingga nilai \\(p\\) tersebut juga menyebabkan \\(f(p) = 0\\)).\n(Tentu saja, itu bukanlah satu-satunya cara untuk mengubah permasalahan mencari akar menjadi permasalahan mencari fixed-point. Bahkan, tidak semua pilihan \\(g(x)\\) yang memungkinkan itu dijamin memiliki fixed-point.)\nMisalkan \\(g\\) adalah fungsi kontinu dan memiliki fixed-point \\(p\\) pada interval \\([a,b]\\) (dan diasumsikan bahwa \\(g\\) memenuhi persyaratan untuk kekonvergenan metode fixed-point). Artinya, ada \\(p \\in [a,b]\\) sehingga \\(g(x) = x\\). Untuk mengaproksimasi penyelesaian dari persamaan \\(g(x) = x\\), diperlukan suatu tebakan awal \\(p_0\\), kemudian iterasinya adalah:\n\n\n\\(p_n = g(p_{n-1})\\)\n\n\nNilai tersebut terus dimasukkan ke dalam \\(g\\) sehingga, diharapkan, nilai \\(p_n\\) menjadi semakin mendekati suatu nilai \\(p\\) yang membuat \\(g(p) = p\\).\nPada umumnya, metode fixed-point memiliki kekonvergenan linier. Ketika \\(g(x)\\) dijamin memliki tepat satu fixed-point (atau fixed-point yang unik) pada suatu interval \\([a,b]\\), maka Metode Fixed-Point dengan \\(p_0\\) pada interval tersebut pasti memiliki kekonvergenan linier. Terkadang Metode Fixed-Point lebih cepat daripada Metode Bisection, dan terkadang Metode Bisection lebih cepat daripada Metode Fixed-Point.\nHati-hati, ada kemungkinan bahwa \\(g(p_n)\\) malah menjauhi \\(p\\), contohnya untuk \\(g(x) = x^2\\) dan \\(p_0 &gt; 1\\) (padahal \\(g(1) = 1\\)). Pada kasus seperti itu, metode fixed-point tidak dijamin konvergen (artinya tidak dijamin bisa menemukan fixed-point).\nSebagai contoh penggunaan metode fixed-point, kalian bisa mencoba untuk menyelesaikan persamaan (masalah mencari akar) berikut ini,\n\\[f(x) = x^2 - x - 1 = 0\\]\ndengan sedikit manipulasi aljabar (dibagi \\(x\\), pindah ruas) agar mendapatkan bentuk \\(x = g(x)\\),\n\\[x = 1 + \\frac{1}{x}\\]\nsehingga, dengan \\(g(x) = 1 + \\frac{1}{x}\\) bisa digunakan metode fixed-point, misal dengan tebakan awal \\(x = 2\\) atau \\(x = -3\\).\n(Jelas metode ini akan gagal untuk \\(g(x)\\) tersebut apabila dipilih tebakan awal seperti \\(x=0\\), \\(x=-1\\), atau bahkan \\(x=-\\frac{1}{2}\\) karena akan terjadi pembagian nol. Kemungkinan terjadinya pembagian nol itu bukan hanya dari metodenya seperti metode Newton, tetapi juga dari fungsi \\(f(x)\\) atau \\(g(x)\\) yang digunakan.)\nSilakan coba dengan kode di bawah ini!\nSebagai pembanding, kalian bisa menyelesaikan persamaan kuadrat \\(f(x) = x^2 - x - 1 = 0\\) di atas, dan mendapatkan solusi\n\\[x_1 = \\frac{1+\\sqrt{5}}{2} \\approx 1.618\\]\n\\[x_2 = \\frac{1-\\sqrt{5}}{2} \\approx -0.618\\]\nKebetulan, konstanta berikut ini yang berlambang phi kecil (\\(\\phi\\)),\n\\[\\phi = \\frac{1+\\sqrt{5}}{2}\\]\nadalah konstanta istimewa yang bernama golden ratio.\n\nfrom numpy import cos, sin, tan, log, exp, sqrt\nfrom tabulate import tabulate\n\nformula = input(\"Masukkan Formula Fungsi: \")\n\ndef g(x):\n    return eval(formula)\n\ndef FixedPoint(p0,tolerance):\n    table = [[\"iterasi\",\"Aproksimasi\"]]\n    iterasi = []\n    \n    i = 1\n    p = g(p0)\n    abs_error = abs(p-p0)\n    p0 = p\n    iterasi.append(i)\n    iterasi.append(p)\n    table.append(iterasi)\n\n    while abs_error &gt; tolerance:\n        iterasi = []\n        i += 1\n        p = g(p0)\n        abs_error = abs(p-p0)\n        p0 = p\n        iterasi.append(i)\n        iterasi.append(p)\n        table.append(iterasi)\n    \n    print(tabulate(table,headers='firstrow',tablefmt =\"pretty\"))\n    return p0\n    \n    print(tabulate(table,headers = 'firstrow',tablefmt=\"pretty\"))\n    return p0 # nilai terbaru, karena sudah dipasang p0 = p\n\nstarting_point = eval(input(\"Masukkan titik awal iterasi: \"))\ntolerance = eval(input(\"Masukkan batas toleransi: \"))\n\nfixed_point = FixedPoint(starting_point,tolerance)\n\nprint('Ditemukan fixed point dari g(x) = {0} yaitu x = {1:.7f}'.format(formula,fixed_point))\n\nMasukkan Formula Fungsi: 1 + 1/x\nMasukkan titik awal iterasi: 2\nMasukkan batas toleransi: 10**(-7)\n+---------+--------------------+\n| iterasi |    Aproksimasi     |\n+---------+--------------------+\n|    1    |        1.5         |\n|    2    | 1.6666666666666665 |\n|    3    |        1.6         |\n|    4    |       1.625        |\n|    5    | 1.6153846153846154 |\n|    6    | 1.619047619047619  |\n|    7    | 1.6176470588235294 |\n|    8    | 1.6181818181818182 |\n|    9    | 1.6179775280898876 |\n|   10    | 1.6180555555555556 |\n|   11    | 1.6180257510729614 |\n|   12    | 1.6180371352785146 |\n|   13    | 1.6180327868852458 |\n|   14    | 1.618034447821682  |\n|   15    | 1.618033813400125  |\n|   16    | 1.6180340557275543 |\n|   17    | 1.6180339631667064 |\n+---------+--------------------+\nDitemukan fixed point dari g(x) = 1 + 1/x yaitu x = 1.6180340\n\n\n\n\nMetode Newton biasa (dengan turunan analitik)\nMisalkan \\(f\\) kontinu dan terturunkan (memiliki turunan) di \\([a,b]\\) dan ada tebakan awal \\(p_0 \\in\\) \\([a,b]\\) sedemikian sehingga \\(f'(p_0) \\neq 0\\). Iterasi pada metode Newton untuk menyelesaian \\(f(x) = 0\\) adalah sebagai berikut:\n\n\n\\(p_n = p_{n-1} - \\frac{f(p_{n-1})}{f'(p_{n-1})}\\)\n\n\nDiharapkan bahwa, setelah banyak iterasi, nilai \\(p_n\\) yang diperoleh akan membuat \\(f(p) = 0\\) atau setidaknya sangat dekat dengan nol (lebih kecil dari batas toleransi yang kita anggap sudah memuaskan).\nMetode Newton juga dapat dipandang sebagai metode fixed-point dengan \\(g(x) = x - \\frac{f(x)}{f'(x)}\\)\nMetode Newton gagal apabila, pada suatu iterasi, tiba-tiba \\(f'(p_n) = 0\\).\nPada umumnya, Metode Newton memiliki order of convergence = 2, atau juga disebut memiliki kekonvergenan kuadratik (quadratic convergence). Artinya, selama berhasil, Metode Newton lebih cepat daripada Metode Bisection maupun Metode Fixed-Point.\n\nimport sympy\nfrom numpy import sin, cos, tan, log, exp, sqrt\n\nformula = input(\"Masukkan fungsi: \")\ndef f(x):\n    return eval(formula)\n\nx = sympy.symbols(\"x\")\n\ndf_string = str(sympy.diff(formula, x))\ndef df(x): # turunan f\n    return eval(df_string)\n\ndef Newton(p0,tolerance):\n    p = p0 - f(p0)/df(p0)\n    abs_error = abs(p-p0)\n    p0 = p\n\n    while abs_error &gt; tolerance:\n\n        try:\n            p = p0 - f(p0)/df(p0)\n        except ZeroDivisionError:\n            return \"Metode gagal mengaproksimasi akar. Silakan pilih tebakan awal lain\"\n        \n        abs_error = abs(p-p0)\n        p0 = p\n    return p\n\nstarting_point = eval(input(\"Masukkan tebakan awal / titik awal iterasi: \"))\ntolerance = eval(input(\"Masukkan toleransi aproksimasi: \"))\n\nakar_newton = Newton(starting_point, tolerance)\n\nprint(f\"Akar dari persamaan f(x) = {formula} adalah x = {akar_newton:.7f}\")\n\nMasukkan fungsi: 2*x - 3*cos(x) + exp(-5*x) - 9\nMasukkan tebakan awal / titik awal iterasi: -1\nMasukkan toleransi aproksimasi: 10**(-7)\nAkar dari persamaan f(x) = 2*x - 3*cos(x) + exp(-5*x) - 9 adalah x = -0.5073225\n\n\n\n\nMetode Newton dengan Beda Hingga (Finite-Difference Newton’s Method)\nSalah satu kekurangan Metode Newton yang biasa adalah harus mengetahui rumus turunannya secara analitik. Sebelum adanya CAS seperti SymPy, turunan analitik harus dihitung secara manual dengan kalkulus. Kalau bentuk rumus untuk \\(f(x)\\) sangat rumit, perhitungan turunan menjadi jauh lebih rumit. Untuk menghindari menghitung turunan secara analitik, kita dapat menggunakan definisi turunan (yang menggunakan limit):\n\\[f'(x) = \\lim_{h \\rightarrow 0} \\frac{f(x+h) - f(x)}{h}\\]\ndengan memilih nilai \\(h\\) yang cukup kecil (sayangnya, kita tidak bisa membuat limit \\(h\\) menuju nol). Nilai \\(h\\) yang cukup kecil itu disebut suatu beda hingga (finite difference).\nSehingga, modifikasi metode Newton ini bisa disebut Metode Newton dengan Beda Hingga (Finite-Difference Newton’s Method). Untuk fungsi \\(f\\) yang kontinu, akar persamaan \\(f(x) = 0\\) bisa ditentukan dengan iterasi sebagai berikut:\n\n\n\\(p_n = p_{n-1} - \\frac{f(p_{n-1})}{\\left(\\frac{f\\left(p_{n-1}+h\\right)-f(p_{n-1})}{h}\\right)} = p_{n-1} - \\frac{f(p_{n-1})h}{f(p_{n-1}+h)-f(p_{n-1})}\\)\n\n\ndengan tebakan awal \\(p_0\\). Perhatikan bahwa \\(f'(p_{n-1})\\) pada metode Newton yang biasa itu telah digantikan dengan\n\\[f'(p_{n-1}) \\approx \\frac{f(p_{n-1}+h) - f(p_{n-1})}{h}\\]\nTujuan modifikasi tersebut adalah agar iterasi dapat dilakukan pada titik di mana turunannya tidak ada, atau ketika turunan analitik sulit diperoleh.\n\nfrom numpy import sin, cos, tan, log, exp, sqrt\n\nformula = input(\"Masukkan fungsi: \")\ndef f(x):\n    return eval(formula)\n\ndef df(x, h=10**(-12)):\n    return (f(x+h)-f(x))/h\n\ndef Finite_Difference(p0,tolerance):\n    p = p0 - f(p0)/df(p0)\n    abs_error = abs(p-p0)\n    p0 = p\n\n    while abs_error &gt; tolerance:\n        p = p0 - f(p0)/df(p0)\n        abs_error = abs(p-p0)\n        p0 = p\n    return p\n\nstarting_point = eval(input(\"Masukkan titik awal iterasi: \"))\ntolerance = eval(input(\"Masukkan toleransi aproksimasi: \"))\n\nakar_fd = Finite_Difference(starting_point,tolerance)\n\nprint(f\"Akar dari persamaan f(x) = {formula} adalah x = {akar_fd:.7f}\")\n\nMasukkan fungsi: 2*x - 3*cos(x) + exp(-5*x) - 9\nMasukkan titik awal iterasi: -1\nMasukkan toleransi aproksimasi: 10**(-7)\nAkar dari persamaan f(x) = 2*x - 3*cos(x) + exp(-5*x) - 9 adalah x = -0.5073225\n\n\n\n\nMetode Secant\nPada Metode Newton dengan Beda Hingga, nilai \\(h\\) konstan. Kalau kita punya dua tebakan awal yang saling dekat, misal \\(p_0\\) dan \\(p_1\\), kita bisa saja memanfaatkannya dengan memasang \\(h = p_1 - p_0\\). Bahkan, ketika iterasi \\(p_n\\) sudah semakin dekat menuju akar, jarak antara \\(p_{n-1}\\) dan \\(p_{n-2}\\) menjadi semakin kecil. Sehingga, dengan memasang nilai \\(h = p_{n-2} - p_{n-1}\\) atau \\(h = p_{n-1} - p_{n-2}\\), kita berhasil membuat limit \\(h\\) menuju nol.\nModifikasi ini disebut Metode Secant, dengan iterasi sebagai berikut untuk menentukan penyelesaian \\(f(x) = 0\\) dengan fungsi \\(f\\) yang kontinu:\n\n\n\\(p_n = p_{n-1} - \\frac{f(p_{n-1})}{\\left(\\frac{f(p_{n-1})-f(p_{n-2})}{p_{n-1}-p_{n-2}}\\right)} = p_{n-1} - \\frac{f(p_{n-1})(p_{n-1} - p_{n-2})}{f(p_{n-1}) - f(p_{n-2})}\\)\n\n\nDibandingkan Metode Newton yang biasa, Metode Secant menggantikan \\(f'(p_{n-1})\\) dengan\n\\[f'(p_{n-1}) \\approx \\frac{f(p_{n-1}) - f(p_{n-2})}{p_{n-1} - p_{n-2}}\\]\nsehingga, tidak seperti Metode Newton yang hanya memerlukan satu tebakan awal, Metode Secant membutuhkan dua tebakan awal, yaitu \\(p_0\\) dan \\(p_1\\). Namun, dibandingkan dengan Metode Newton dengan Beda Hingga, nilai \\(h\\) atau beda hingga tersebut tidak perlu ditentukan secara manual.\nMenariknya, Metode Secant memiliki order of convergence = \\(\\phi \\approx 1.618\\).\n\nfrom numpy import sin, cos, tan, log, exp, sqrt\nformula = input(\"Masukkan formula fungsi: \")\n\ndef f(x):\n    return eval(formula)\n\ndef Secant(p0,p1,tolerance):\n    p = p1 - (f(p1)*(p1-p0))/(f(p1)-f(p0))\n    abs_error = abs(p-p1)\n    p0 = p1\n    p1 = p\n\n    while abs_error &gt; tolerance:\n        p = p1 - (f(p1)*(p1-p0))/(f(p1)-f(p0))\n        abs_error = abs(p-p1)\n        p0 = p1\n        p1 = p\n    return p\n\nstarting_point1 = eval(input(\"Masukkan titik awal pertama: \"))\nstarting_point2 = eval(input(\"Masukkan titik awal kedua: \"))\ntolerance = eval(input(\"Masukkan toleransi aproksimasi: \"))\n\nakar_secant = Secant(starting_point1,starting_point2,tolerance)\n\nprint(f\"Akar dari persamaan f(x) = {formula} adalah x = {akar_secant:.7f}\")\n\nMasukkan formula fungsi: 2*x - 3*cos(x) + exp(-5*x) - 9\nMasukkan titik awal pertama: -1\nMasukkan titik awal kedua: -2\nMasukkan toleransi aproksimasi: 10**(-7)\nAkar dari persamaan f(x) = 2*x - 3*cos(x) + exp(-5*x) - 9 adalah x = -0.5073225\n\n\n\n\nMetode Regula Falsi (penjelasan tanpa kode)\nSejauh ini, kita sudah membahas beberapa metode root-finding atau aproksimasi akar, yaitu:\n\nMetode Bisection\nMetode Fixed-Point\nMetode Newton biasa (dengan turunan analitik)\nMetode Newton dengan Beda Hingga (finite-difference Newton’s method)\nMetode Secant\n\nDi antara semua metode tersebut, hanya Metode Bisection yang dijamin konvergen menuju akar di interval yang diberikan; semua metode lain ada kemungkinan divergen (menjauh dari akar, seperti metode fixed-point) atau gagal karena terjadi pembagian nol. Sayangnya, Metode Bisection termasuk metode yang pelan di antara metode numerik lainnya.\nUntuk menjaga jaminan kekonvergenan oleh Metode Bisection tetapi memperbaiki kecepatan kekonvergenannya, kita bisa memodifikasi Metode Bisection, yaitu memodifikasi cara menentukan \\(p\\) yang baru yang akan mempersempit interval. Perhatikan bahwa Metode Bisection membutuhkan dua “tebakan awal” (lebih tepatnya dua batasan interval), sedangkan metode di atas yang juga membutuhkan dua tebakan awal hanyalah Metode Secant.\nApakah kita bisa menggunakan Metode Bisection, tetapi dengan modifikasi menentukan \\(p\\) seperti Metode Secant, agar mendapatkan order of convergence seperti Metode Secant?\nJawabannya adalah bisa, dan modifikasi tersebut dinamakan Metode Regula Falsi. Sehingga, Metode Regula Falsi bisa disebut perpaduan antara Metode Bisection dan Metode Secant.\nSebenarnya, perbedaan algoritma Metode Bisection dan Metode Regula Falsi hanya di satu baris saja, yaitu mengubah baris\n\\[p=\\frac{a+b}{2}\\]\nmenjadi\n\\[p = b - \\frac{f(b)(b-a)}{f(b) - f(a)}\\]\nsesuai Metode Secant. Perhatikan bahwa Metode Secant biasanya membutuhkan dua tebakan awal yang tidak harus sama dengan batasan interval, sedangkan Metode Regula Falsi secara otomatis menggunakan kedua batasan interval \\([a,b]\\) sebagai dua tebakan awal.\nUntuk pembuatan kode Metode Regula Falsi, kami serahkan ke kalian. Gampang, kok! Tinggal mengubah beberapa baris saja (baris yang menentukan nilai \\(p\\) yang baru) pada kode Metode Bisection, yaitu mengambil baris tersebut dari kode Metode Secant, kemudian menyesuaikan kedua tebakan awal menjadi kedua batasan interval.\nSeperti Metode Secant, Metode Regula Falsi juga memiliki order of convergence = \\(\\phi \\approx 1.618\\).\n\n\nApa itu barisan? (penjelasan tanpa kode)\nSuatu “barisan” (sequence) adalah sekumpulan angka yang berurut. Artinya, pada suatu barisan, ada yang bisa disebut angka pertama (atau suku pertama), angka kedua (suku kedua), angka ketiga (suku ketiga), dan sebagainya. Banyaknya suku bisa berhingga maupun tak terhingga.\nSuku-suku pada suatu barisan itu bisa saja ditentukan secara manual atau sesuka hati, atau bisa juga menggunakan rumus. Intinya, suku-suku suatu barisan itu bisa diperoleh dari manapun, bahkan dari hasil iterasi metode numerik (\\(p_0\\), \\(p_1\\), \\(p_2\\), \\(p_3\\), …) juga bisa.\nOleh karena itu, contoh barisan berhingga adalah hasil iterasi fixed-point, misalnya dengan \\(g(x) = 1 + \\frac{1}{x}\\), tebakan awal \\(p_0 = 2\\), dan batas toleransi \\(10^{-7}\\):\n\\((1.5, 1.6666666666666665, 1.6, 1.625, 1.6153846153846154, 1.619047619047619, \\dots, 1.6180339631667064)\\)\nProses tersebut berakhir setelah 17 iterasi, sehingga barisan tersebut memiliki 17 suku.\nBarisan tersebut bisa diberi nama, seperti \\(p_n\\) dengan \\(n = 1, 2, 3, \\dots, 17\\), yang bisa dituliskan \\(\\left\\{p_n\\right\\}_{n=1}^{17}\\) dengan kurung kurawal.\nContoh barisan tak berhingga adalah barisan aritmetika dan barisan geometri, seperti:\n\\[(-5, -2, 1, 4, 7, 10, 13, 16, 19, \\dots)\\]\n\\[\\left(16, 8, 4, 2, 1, \\frac{1}{2}, \\frac{1}{4}, \\frac{1}{8}, \\dots\\right)\\]\nBarisan tak berhingga dengan nama \\(p_n\\) yang mulai dari suku \\(n=1\\) bisa ditulis \\(\\left\\{p_n\\right\\}_{n=1}^{\\infty}\\) dengan kurung kurawal, atau singkatnya \\((p_n)\\) saja dengan kurung biasa (dengan begitu, biasanya ada asumsi bahwa barisan tersebut tak berhingga).\n\n\nMetode Aitken\nAlexander Aitken menemukan bahwa, untuk sembarang barisan (termasuk sembarang metode numerik) yang memiliki kekonvergenan linier, untuk nilai \\(n\\) yang besar, berlaku\n\\[\\frac{p_{n+1} - p}{p_n - p} \\approx \\frac{p_{n+2} - p}{p_{n+1} - p}\\]\ndi mana \\(p\\) adalah nilai yang ingin dicari, sedangkan \\(p_n\\), \\(p_{n+1}\\), dan \\(p_{n+2}\\) adalah tiga suku barisan (atau tiga hasil aproksimasi) berturut-turut. Artinya, perbandingan error (error ratio) antar dua pasang hasil iterasi (diperoleh dari tiga hasil iterasi berturut-turut) menjadi kurang lebih sama. Dengan manipulasi aljabar, diperoleh\n\\[p \\approx p_n - \\frac{\\left(p_{n+1} - p_n\\right)^2}{p_{n+2} - 2p_{n+1} + p_n}\\]\nseolah-olah ada jalur pintas untuk langsung mendapatkan nilai yang ingin dicari.\nTentu saja, sebelum menggunakan rumus ini, kita perlu menemukan tiga hasil aproksimasi pertama, yaitu \\(p_0\\), \\(p_1\\), dan \\(p_2\\). Kemudian, barulah kita tentukan \\(p_3\\) menggunakan rumus Aitken (hasil rumus Aitken biasa disebut \\(\\hat{p}_n\\), sehingga bisa ditulis \\(p_3 = \\hat{p}_0\\), karena perhitungan \\(p_3\\) memanfaatkan \\(p_0\\), \\(p_1\\) dan \\(p_2\\)).\nVariabel \\(\\hat{p}\\) biasa disebut p-hat atau p-cap (kata “hat” atau “cap” artinya topi).\nApabila kita definisikan \\(\\Delta p_n = p_{n+1} - p_n\\) dan \\(\\Delta^2 p_n = p_{n+2} - 2p_{n+1} + p_n\\), rumus Aitken bisa ditulis\n\\[\\hat{p}_n = p_n - \\frac{(\\Delta p_n)^2}{\\Delta^2 p_n}\\]\nsehingga teknik ini biasa disebut Aitken’s delta-squared (\\(\\Delta^2\\)) method.\nCatatan: dalam pembahasan metode Aitken/Steffensen, penulisan \\(\\Delta^2\\) BUKAN berarti \\((\\Delta)^2\\). Itu hanya penulisan saja.\nSecara umum, apabila kita punya suku-suku suatu barisan yang berturut-turut yaitu \\(p_1, p_2, p_3, \\dots, p_{k-3}, p_{k-2}, p_{k-1}, p_{k}\\), maka rumus Aitken bisa digunakan untuk menentukan \\(\\hat{p}_1, \\hat{p}_2, \\hat{p}_3, \\dots, \\hat{p}_{k-3}, \\hat{p}_{k-2}\\), yang semuanya merupakan aproksimasi nilai yang lebih akurat untuk hasil konvergen dari barisan tersebut (dengan asumsi kekonvergenan linier).\nPerhatikan: - Kita hanya bisa berhenti sampai \\(\\hat{p}_{k-2}\\), karena perhitungannya membutuhkan \\(p_{k-2}\\), \\(p_{k-1}\\) dan \\(p_k\\). - Harus ada minimal 3 suku yang diketahui, artinya \\(k \\ge 3\\).\n\ndef Aitken(p):\n    k = len(p)\n    if k &lt; 3:\n        return \"Maaf, dibutuhkan minimal 3 suku yang diketahui.\"\n    \n    # kalau lanjut ke sini, artinya k &gt;= 3\n    list_phat = []\n    for i in range(k-2):\n        Delta = p[i+1] - p[i]\n        DeltaSquared = p[i+2] - 2 * p[i+1] + p[i]\n        phat = p[i] - (Delta)**2 / DeltaSquared\n        list_phat.append(phat)\n    return list_phat\n\ntry:\n    # input suatu list\n    p = eval(input(\"Masukkan list suku-suku yang diketahui: \"))\nexcept:\n    print(\"Maaf, terjadi error. Harap masukkan list dengan benar.\")\nelse: # kalau tidak terjadi error \n    print(\"Berikut hasil metode Aitken:\") \n    print(Aitken(p))\n\nMasukkan list suku-suku yang diketahui: [2, 1.5, 1.6666666666666665, 1.6, 1.625]\nBerikut hasil metode Aitken:\n[1.625, 1.619047619047619, 1.6181818181818182]\n\n\n\n\nMetode Steffensen: Penerapan Metode Aitken pada Metode Fixed Point\nAitken hanya menemukan rumus. Johan Frederik Steffensen menemukan bahwa, karena Metode Fixed-Point memiliki kekonvergen linier, metode Aitken bisa digunakan untuk mempercepat Metode Fixed-Point.\nSecara umum, apabila kita berselang-seling antara menggunakan suatu metode dan rumus Aitken (misalnya setelah memperoleh tiga hasil aproksimasi), kita dapat mempercepat kekonvergenan (accelerating convergence), seolah-olah order of convergence menjadi lebih besar dari 1. Namun, bagaimana cara selang-selingnya?\nMenurut Steffensen, rumus Aitken bisa digunakan tiap tiga iterasi fixed-point, yaitu untuk \\(p_3\\), \\(p_6\\), \\(p_9\\), dan seterusnya.\nKita bisa memodifikasi rumus Aitken dengan menggeser indeks \\(n\\), yaitu menukar \\(n\\) dengan \\(n-3\\), untuk mendapatkan rumus iterasi:\n\\[\\hat{p} = p_{n-3} - \\frac{\\left(p_{n-2} - p_{n-3}\\right)^2}{p_{n-1} - 2p_{n-2} + p_{n-3}}\\]\ndan dalam hal ini, kita juga bisa mendefinisikan \\(\\Delta_1 = p_{n-2} - p_{n-3}\\) dan \\(\\Delta_2 = p_{n-1} - 2p_{n-2} + p_{n-3}\\) untuk mendapatkan bentuk:\n\\[\\hat{p} = p_{n-3} - \\frac{(\\Delta_1)^2}{(\\Delta_2)}\\]\n\nfrom numpy import sin, cos, tan, log, exp, sqrt\n\nformula = input(\"Masukkan formula fungsi: \")\n\ndef g(x):\n    return eval(formula)\n\ndef Steffensen(p0, tolerance):\n    # list semua nilai p agar mudah diakses\n    list_p = [p0]\n\n    # nilai sementara\n    abs_error = tolerance + 1 \n\n    iterasi = 1 # penghitung banyaknya iterasi\n    while abs_error &gt;= tolerance:\n        if iterasi % 3 == 0: # untuk kelipatan tiga, gunakan rumus Aitken\n            pn_3 = list_p[iterasi - 3] # p_(n-3)\n            pn_2 = list_p[iterasi - 2] # p_(n-2)\n            pn_1 = list_p[iterasi - 1] # p_(n-1)\n            Delta1 = pn_2 - pn_3\n            Delta2 = pn_1 - 2 * pn_2 + pn_3\n            pn = pn_3 - (Delta1)**2 / Delta2\n        else: # selain kelipatan 3, gunakan fixed point\n            pn_1 = list_p[iterasi - 1]\n            pn = g(pn_1)\n        \n        list_p.append(pn)\n        abs_error = abs( pn - pn_1 )\n        iterasi += 1\n    \n    # return bukan hanya p, tetapi juga banyaknya iterasi\n    return pn, iterasi\n\nstarting_point = eval(input(\"Masukkan titik awal iterasi: \"))\ntolerance = eval(input(\"Masukkan batas toleransi: \"))\n\np_steffensen, i_steffensen = Steffensen(starting_point, tolerance)\n\nprint(\"Metode Steffensen\")\nprint(\"Hasil: \" + str(p_steffensen))\nprint(\"setelah banyaknya iterasi: \" + str(i_steffensen))\n\nprint(\"Bandingkan banyaknya iterasi dengan hasil Metode Fixed-Point biasa:\")\n\nprint(FixedPoint(starting_point, tolerance))\n\nMasukkan formula fungsi: 1 + 1/x\nMasukkan titik awal iterasi: 2\nMasukkan batas toleransi: 10**(-7)\nMetode Steffensen\nHasil: 1.618033988749648\nsetelah banyaknya iterasi: 11\nBandingkan banyaknya iterasi dengan hasil Metode Fixed-Point biasa:\n+---------+--------------------+\n| iterasi |    Aproksimasi     |\n+---------+--------------------+\n|    1    |        1.5         |\n|    2    | 1.6666666666666665 |\n|    3    |        1.6         |\n|    4    |       1.625        |\n|    5    | 1.6153846153846154 |\n|    6    | 1.619047619047619  |\n|    7    | 1.6176470588235294 |\n|    8    | 1.6181818181818182 |\n|    9    | 1.6179775280898876 |\n|   10    | 1.6180555555555556 |\n|   11    | 1.6180257510729614 |\n|   12    | 1.6180371352785146 |\n|   13    | 1.6180327868852458 |\n|   14    | 1.618034447821682  |\n|   15    | 1.618033813400125  |\n|   16    | 1.6180340557275543 |\n|   17    | 1.6180339631667064 |\n+---------+--------------------+\n1.6180339631667064"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul4.html",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul4.html",
    "title": "Outline",
    "section": "",
    "text": "Outline\nKembali ke Metode Numerik\n\nTurunan/Diferensiasi Numerik\nPengantar Ekstrapolasi Richardson (penjelasan tanpa kode)\nEkstrapolasi Richardson khusus rumus forward/backward-difference\nEkstrapolasi Richardson dengan \\(N_1 \\left( \\frac{h}{2} \\right)\\), dari \\(O(h)\\) menjadi \\(O(h^2)\\)\nEkstrapolasi Richardson untuk truncation error \\(O\\left(h^{2j}\\right)\\) (pangkat genap)\n\n\n\nTurunan/Diferensiasi Numerik\nUntuk step size \\(h \\ne 0\\) (boleh positif maupun negatif), rumus-rumus berikut ini bisa digunakan untuk mengaproksimasi turunan.\na. Forward/Backward-Difference\ntruncation error: \\(O\\left(h\\right)\\)\n\\[f'(x_0) \\approx \\frac{f(x_0 + h) - f(x_0)}{h}\\]\ntruncation term: \\(-\\frac{h}{2}f''(\\xi) = O\\left(h\\right)\\)\nRumus diferensiasi numerik yang paling sederhana, yaitu sesuai definisi turunan, dengan nilai \\(h\\) yang dekat dengan nol (sayangnya tidak bisa dibuat limit \\(h\\) menuju nol). Rumus di atas disebut forward-difference formula jika \\(h &gt; 0\\), dan disebut backward-difference formula jika \\(h &lt; 0\\).\nb. Three-Point Formulas\ntruncation error: \\(O\\left(h^2\\right)\\)\n\nThree-Point Endpoint (TPEP): \\[f'(x_0) \\approx \\frac{1}{2h} \\left[-3f(x_0) +4f(x_0+h) - f(x_0+2h)\\right]\\]\n\ntruncation term (TPEP): \\(\\frac{h^2}{3}f^{(3)}(\\xi) = O\\left(h^2\\right)\\)\n\nThree-Point Midpoint (TPMP), juga disebut centered-difference formula: \\[f'(x_0) \\approx \\frac{1}{2h} \\left[f(x_0 + h) -f(x_0 - h)\\right]\\]\n\ntruncation term (TPMP): \\(-\\frac{h^2}{6}f^{(3)}(\\xi) = O\\left(h^2\\right)\\)\nc. Five-Point Formulas\ntruncation error: \\(O\\left(h^4\\right)\\)\n\nFive-Point Endpoint (FPEP): \\[f'(x_0) \\approx \\frac{1}{12h} \\left[-25f(x_0) + 48f(x_0 + h) - 36f(x_0 + 2h) +16f(x_0 + 3h) - 3f(x_0 + 4h) \\right]\\]\n\ntruncation term (FPEP): \\(\\frac{h^4}{5}f^{(5)}(\\xi) = O\\left(h^4\\right)\\)\n\nFive-Point Midpoint (FPMP): \\[f'(x_0) \\approx \\frac{1}{12h} \\left[f(x_0 - 2h) - 8f(x_0 - h) + 8f(x_0 + h) - f(x_0 - 2h)\\right]\\]\n\ntruncation term (FPMP): \\(\\frac{h^4}{30}f^{(5)}(\\xi) = O\\left(h^4\\right)\\)\nd. BONUS: Second Derivative Midpoint Formula\ntruncation error: \\(O\\left(h^2\\right)\\)\n\\[f''\\left(x_0\\right) \\approx \\frac{1}{h^2} \\left[ f(x_0 - h) - 2f(x_0) + f(x_0 + h) \\right]\\]\ntruncation term: \\(-\\frac{h^2}{12}f^{(4)}(\\xi) = O\\left(h^2\\right)\\)\nDari semua rumus yang kita bahas, ini adalah satu-satunya rumus yang menghitung turunan kedua.\nSayangnya, karena nilai \\(h\\) dikuadratkan dan menjadi pembagi, nilai \\(h\\) yang terlalu kecil bisa lebih mudah membuat metode/rumus ini gagal dibandingkan dengan rumus-rumus turunan pertama yang sudah dibahas sebelumnya.\nBerikut kode Python menghitung turunan secara numerik.\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Diferensiasi Numerik\")\nformula = input(\"Masukkan formula f(x) yang akan dicari nilai turunannya : \")\ndef f(x):\n    return eval(formula)\n\nx0 = eval(input(\"Masukkan titik x0 di mana nilai turunan fungsinya akan diaproksimasi : \"))\nh = eval(input(\"Masukkan besar step size (h) taknol, boleh negatif : \"))\nprint()\n\ndef FBDiff(x,h): #Forward/Backward-Difference\n    return (f(x+h)-f(x))/h\n\ndef TPEP(x,h): # Three-Point End Point\n    return (1/(2*h)) * (-3*f(x) + 4*f(x+h) - f(x+2*h))\n\ndef TPMP(x,h): # Three-Point Mid Point\n    return (1/(2*h)) * (f(x+h) - f(x-h))\n\ndef FPEP(x,h): # Five-Point End Point\n    return (1/(12*h)) * (-25*f(x) + 48*f(x+h) - 36*f(x+2*h) + 16*f(x+3*h) - 3*f(x+4*h))\n\ndef FPMP(x,h): # Five-Point Mid Point\n    return (1/(12*h)) * (f(x-2*h) - 8*f(x-h) + 8*f(x+h) - f(x+2*h))\n\ndef SDMP(x,h): # Second Derivative Mid Point\n    return (1/(h**2)) * (f(x-h) - 2*f(x) + f(x+h))\n\nprint(\"Turunan pertama dari f di x0 = {0} adalah : \".format(x0))\nprint(\"f'({0}) = {1} (Forward/Backward-Difference)\".format(x0,FBDiff(x0,h)))\nprint(\"f'({0}) = {1} (Three Point Endpoint)\".format(x0,TPEP(x0,h)))\nprint(\"f'({0}) = {1} (Three Point Midpoint)\".format(x0,TPMP(x0,h)))\nprint(\"f'({0}) = {1} (Five Point Endpoint)\".format(x0,FPEP(x0,h)))\nprint(\"f'({0}) = {1} (Five Point Midpoint)\".format(x0,FPMP(x0,h)))\nprint()\nprint(\"Turunan kedua dari f di x0 = {0} adalah : \".format(x0))\nprint(\"f''({0}) = {1} (Second Derivative Midpoint)\".format(x0,SDMP(x0,h)))\nprint(\"Note: nilai h yang terlalu kecil bisa membuat metode Second Derivative Midpoint gagal.\")\n\nDiferensiasi Numerik\nMasukkan formula f(x) yang akan dicari nilai turunannya : x**3\nMasukkan titik x0 di mana nilai turunan fungsinya akan diaproksimasi : 3\nMasukkan besar step size (h) taknol, boleh negatif : 10**-5\n\nTurunan pertama dari f di x0 = 3 adalah : \nf'(3) = 27.000090000228735 (Forward/Backward-Difference)\nf'(3) = 26.999999999866017 (Three Point Endpoint)\nf'(3) = 27.000000000221288 (Three Point Midpoint)\nf'(3) = 27.0000000002805 (Five Point Endpoint)\nf'(3) = 27.000000000014047 (Five Point Midpoint)\n\nTurunan kedua dari f di x0 = 3 adalah : \nf''(3) = 18.000001489326674 (Second Derivative Midpoint)\nNote: nilai h yang terlalu kecil bisa membuat metode Second Derivative Midpoint gagal.\n\n\n\n\nPengantar Ekstrapolasi Richardson (penjelasan tanpa kode)\nInti sari dari ekstrapolasi Richardson adalah “menggabungkan” beberapa hasil aproksimasi dengan step size yang berbeda-beda (tapi rumus/metodenya tetap sama) sedemikian sehingga diperoleh hasil aproksimasi yang lebih akurat.\nHasil aproksimasi yang dimaksud itu untuk metode numerik yang mana saja ya? Bagaimana rumus ekstrapolasinya? Simak penjelasan berikut ini.\nMisalkan \\(N_1 (h)\\) adalah hasil aproksimasi suatu metode/rumus yang dihitung dengan step size h, dan memiliki truncation error \\(O(h)\\), yaitu berbentuk seperti berikut:\n\\[K_1 h + K_2 h^2 + K_3 h^3 + \\dots\\]\ndi mana \\(K_j\\) adalah sejumlah konstanta (yang kemungkinan tidak diketahui nilainya). Misalkan pula, \\(M\\) adalah nilai eksak yang ingin diaproksimasi oleh metode tersebut. Maka, kita bisa menuliskan bahwa hasil eksak sama dengan hasil aproksimasi ditambah error, yaitu\n\\[M = N_1 (h) + K_1 h + K_2 h^2 + K_3 h^3 + \\dots\\]\natau bisa ditulis\n\\[M - N_1 (h) = K_1 h + K_2 h^2 + K_3 h^3 + \\dots\\]\nyaitu hasil eksak dikurang hasil aproksimasi sama dengan error.\nLazimnya, step size yang dipilih cukup kecil, tentu lebih kecil dari 1, sehingga berlaku \\(h &gt; h^2 &gt; h^3 &gt; \\dots\\).\nBahkan, biasanya \\(h^2\\) jauh lebih kecil daripada \\(h\\), apalagi \\(h^3\\) lebih kecil lagi, apalagi \\(h^4\\), dan seterusnya, sehingga kita bisa menuliskan aproksimasi seperti berikut:\n\\[M - N_1 (h) \\approx K_1 h\\]\nAproksimasi tersebut akan kita manfaatkan.\nSeandainya kita pilih step size \\(\\frac{h}{2}\\), kita mendapatkan\n\\[M = N_1 \\left( \\frac{h}{2} \\right) + K_1 \\frac{h}{2} + K_2 \\left(\\frac{h}{2}\\right)^2 + K_3 \\left(\\frac{h}{2}\\right)^3 + \\dots\\]\natau\n\\[M = N_1 \\left( \\frac{h}{2} \\right) + K_1 \\frac{h}{2} + K_2 \\frac{h^2}{4} + K_3 \\frac{h^3}{8} + \\dots\\]\nSaat ini, suku dengan \\(K_1\\) dikalikan dengan \\(\\frac{h}{2}\\). Kita bisa mengkalikan keseluruhan rumus dengan 2 agar ada suku \\(K_1 h\\), seperti berikut:\n\\[2M = 2N_1 \\left( \\frac{h}{2} \\right) + K_1 h + K_2 \\frac{h^2}{2} + K_3 \\frac{h^3}{4} + \\dots\\]\nKita bisa mengurangi persamaan di atas dengan \\(M = N_1 (h) + K_1 h + K_2 h^2 + K_3 h^3 + \\dots\\) agar mendapatkan\n\\[2M - M = \\left[ 2N_1 \\left( \\frac{h}{2} \\right) - N_1 (h) \\right] + \\left[ K_1 h - K_1 h \\right] + \\left[ K_2 \\frac{h^2}{2} - K_2 h^2 \\right] + \\left[ K_3 \\frac{h^3}{4} - K_3 h^2 \\right] + \\dots\\]\nsehingga\n\\[M = \\left[ 2N_1 \\left( \\frac{h}{2} \\right) - N_1 (h) \\right] + 0 + K_2 \\left( \\frac{h^2}{2} - h^2 \\right) + K_3 \\left( \\frac{h^3}{4} - h^3 \\right) + \\dots\\]\n\\[M = \\left[ 2N_1 \\left( \\frac{h}{2} \\right) - N_1 (h) \\right] - K_2 \\frac{h^2}{2} - K_3 \\frac{3h^3}{4} + \\dots\\]\n\\[M = \\left[ 2N_1 \\left( \\frac{h}{2} \\right) - N_1 (h) \\right] + \\left( \\frac{-K_2}{2} \\right) h^2 + \\left( \\frac{-3}{4} K_3 \\right) h^3 + \\dots\\]\nTiba-tiba, sudah tidak ada suku \\(K_1 h\\) lagi. Bahkan, kita telah mengelompokkan koefisien untuk mendapatkan bentuk\n\\[\\dots h^2 + \\dots h^3 + \\dots\\]\nseolah-olah error baru untuk persamaan ini menjadi \\(O\\left(h^2\\right)\\), dengan truncation error memiliki koefisien baru yaitu misal \\(\\hat{K}_1 = 0\\), \\(\\hat{K}_2 = \\frac{-K_2}{2}\\), \\(\\hat{K}_3 = \\frac{-3}{4} K_3\\), dan seterusnya, dalam bentuk truncation error tetap berupa\n\\[\\hat{K}_1 h + \\hat{K}_2 h^2 + \\hat{K}_3 h^3 + \\dots\\]\nnamun suku \\(\\hat{K}_1 h\\) bisa diabaikan (karena bernilai nol), dan truncation error bisa langsung disimpulkan berupa \\(O\\left(h^2\\right)\\).\nDengan demikian,\n\\[M \\approx 2N_1 \\left( \\frac{h}{2} \\right) - N_1 (h)\\]\nsehingga kita bisa mendefinisikan hasil aproksimasi baru:\n\\[N_2 (h) = 2N_1 \\left( \\frac{h}{2} \\right) - N_1 (h)\\]\nProses penurunan rumus tersebut, memanfaatkan hasil aproksimasi dengan step size yang berbeda, sampai mendapatkan bentuk lain dengan error baru yang lebih kecil (misal di sini dari \\(O(h)\\) menjadi \\(O(h^2)\\)), disebut ekstrapolasi Richardson.\nPada rumus ekstrapolasi Richardson, \\(N_2 (h)\\) adalah hasil aproksimasi untuk \\(M\\) yang ternyata lebih baik daripda \\(N_1\\) yang manapun (karena error yang lebih kecil). Bahkan, bentuk error untuk \\(N_2 (h)\\) tetap berbentuk semacam \\(\\hat{K}_1 h + \\hat{K}_2 h^2 + \\dots\\), sehingga kita bisa melakukan proses yang serupa (menggunakan ekstrapolasi Richardson lagi) untuk memperoleh rumus \\(N_3 (h)\\), lalu lagi untuk \\(N_4 (h)\\), dan seterusnya (yang akan membutuhkan \\(N_1 \\left( \\frac{h}{4} \\right)\\), \\(N_1 \\left( \\frac{h}{8} \\right)\\), dan seterusnya, termasuk beberapa nilai \\(N_2\\) dengan berbagai step size, beberapa nilai \\(N_3\\), dan seterusnya). Perhatikan bahwa rumus ekstrapolasi Richardson yang diperoleh akan memerlukan hasil aproksimasi untuk berbagai step size, bukan hanya dengan step size \\(h\\).\nBahkan, tidak ada kewajiban untuk memilih step size \\(\\frac{h}{2}\\). Kita juga bisa memilih step size misalnya \\(\\frac{h}{3}\\) atau dibagi bilangan lain, untuk mendapatkan rumus ekstrapolasi Richardson yang misalnya memanfaatkan \\(N_1 (h)\\) dan \\(N_1 \\left( \\frac{h}{3} \\right)\\).\nApakah benar, \\(N_1\\) memang bisa berupa hasil aproksimasi metode numerik apapun?\nSecara teori, ekstrapolasi Richardson bisa diterapkan untuk semua metode aproksimasi (termasuk diferensiasi numerik) dengan syarat: harus memiliki bentuk truncation error seperti berikut,\n\\[\\sum_{j=1}^{m-1} \\left(K_j h^{\\alpha_j}\\right) + O\\left(h^{\\alpha_m}\\right) = K_1 h^{\\alpha_1} + K_2 h^{\\alpha_2} + K_3 h^{\\alpha_3} + \\dots + K_{m-1} h^{\\alpha_{m-1}} + O\\left(h^{\\alpha_m}\\right)\\]\ndi mana \\(K_j\\) dan \\(\\alpha_j\\) adalah sejumlah konstanta (yang kemungkinan tidak diketahui nilainya) dengan \\(\\alpha_1 &lt; \\alpha_2 &lt; \\alpha_3 &lt; \\dots &lt; \\alpha_m\\).\nSebelumnya, untuk bentuk truncation error, kita telah mengasumsikan bahwa \\(\\alpha_1 = 1\\), \\(\\alpha_2 = 2\\), \\(\\alpha_3 = 3\\), dan seterusnya. Itu tidak masalah; kebetulan saja, ekstrapolasi Richardson masih bisa diterapkan pada bentuk truncation error yang lebih umum lagi.\nSebenarnya, bentuk umum tersebut memang agak ambigu, karena penulisan \\(O\\left(h^{\\alpha_m}\\right)\\) bisa dianggap sebagai “singkatan” untuk suku-suku dengan hasil pangkat \\(h\\) yang lebih kecil lagi, sama halnya dengan kita menyingkat penulisan truncation error menjadi misalnya \\(O(h)\\) atau \\(O(h^2)\\).\nBagaimanapun juga, sejauh ini, asumsi truncation error yang telah kita tuliskan sebelumnya tetap memenuhi bentuk umum di atas.\nKemudian, bagaimana penerapan ekstrapolasi Richardson pada metode numerik yang telah kita pelajari?\nMumpung rumus forward/backward-difference memiliki truncation term \\(-\\frac{h}{2}f''(\\xi) = O(h)\\), kita bisa melakukan ekstrapolasi Richardson, bahkan langsung menggunakan rumus \\(N_2 (h)\\) yang telah kita temukan tadi, yang “mengubah” error \\(O(h)\\) menjadi \\(O(h^2)\\). Mari mulai praktek!\n\n\nEkstrapolasi Richardson khusus rumus forward/backward-difference\nIngat bahwa, untuk \\(N_1\\) berupa hasil aproksimasi dengan error \\(O(h)\\), kita telah menemukan rumus ekstrapolasi Richardson dengan error \\(O(h^2)\\) sebagai berikut:\n\\[N_2 (h) = 2N_1 \\left( \\frac{h}{2} \\right) - N_1 (h)\\]\nMetode aproksimasi forward/backward-difference memiliki error \\(O(h)\\), sehingga bisa diterapkan ekstraplasi Richardson, dengan menghitung \\(N_1\\) yaitu aproksimasi \\(f'(x_0)\\), dengan step size \\(h\\) dan \\(\\frac{h}{2}\\) terlebih dahulu sebelum menggunakan rumus ekstrapolasi Richardson.\nIngat bahwa rumus forward/backward-difference (yang menjadi \\(N_1 (h)\\) di sini) adalah\n\\[f'(x_0) \\approx \\frac{f(x_0 + h) - f(x_0)}{h}\\]\nPerhatikan kode berikut.\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Ekstrapolasi Richardson khusus Forward/Backward-Difference\")\nformula = input(\"Masukkan formula f(x) yang akan dicari nilai turunannya : \")\ndef f(x):\n    return eval(formula)\n\nx0 = eval(input(\"Masukkan titik x0 di mana nilai turunan fungsinya akan diaproksimasi : \"))\nh = eval(input(\"Masukkan besar step size (h) taknol, boleh negatif : \"))\nprint()\n\ndef RichardsonOhOtomatis(N_1, x, h): # ekstrapolasi Richardson untuk O(h), otomatis\n    # N_1 adalah function\n    return 2*N_1(x, h/2) - N_1(x, h)\n\ndef FBDiff(x,h): #Forward/Backward-Difference\n    return (f(x+h)-f(x))/h\n\nN1h = FBDiff(x0, h) # N_1 (h)\nN1h2 = FBDiff(x0, h/2) # N_1 (h/2)\nN2h = RichardsonOhOtomatis(FBDiff, x0, h) # N_2 (h)\n\nprint(\"Hasil Forward/Backward-Difference:\")\nprint(\"N_1 ({0}) = {1}\".format(h, N1h))\nprint(\"N_1 ({0}) = {1}\".format(h/2, N1h2))\nprint(\"Hasil Ekstrapolasi Richardson O(h):\")\nprint(\"N_2 ({0}) = {1}\".format(h, N2h))\n\nEkstrapolasi Richardson khusus Forward/Backward-Difference\nMasukkan formula f(x) yang akan dicari nilai turunannya : x + exp(x)\nMasukkan titik x0 di mana nilai turunan fungsinya akan diaproksimasi : 0\nMasukkan besar step size (h) taknol, boleh negatif : 0.5\n\nHasil Forward/Backward-Difference:\nN_1 (0.5) = 2.2974425414002564\nN_1 (0.25) = 2.1361016667509656\nHasil Ekstrapolasi Richardson O(h):\nN_2 (0.5) = 1.9747607921016748\n\n\n\n\nEkstrapolasi Richardson dengan \\(N_1 \\left( \\frac{h}{2} \\right)\\), dari \\(O(h)\\) menjadi \\(O(h^2)\\)\nTentu saja, kita bisa menggunakan rumus \\(N_2 (h)\\) untuk apapun data \\(N_1 (h)\\) dan \\(N_1 \\left(\\frac{h}{2}\\right)\\) yang kita miliki, yang bisa berasal dari metode \\(O(h)\\) apapun yang memenuhi syarat ekstrapolasi Richardson (dilihat dari bentuk truncation error).\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Ekstrapolasi Richardson untuk truncation error O(h)\")\nprint(\"dengan sembarang data N_1 (h) dan N_1 (h/2)\")\n\ndef RichardsonOhManual(N1h, N1h2): # ekstrapolasi Richardson untuk O(h), manual\n    return 2*N1h2 - N1h\n\nN1h = eval(input(\"Masukkan data N_1 (h): \")) # N_1 (h)\nN1h2 = eval(input(\"Masukkan data N_1 (h/2): \")) # N_1 (h/2)\nN2h = RichardsonOhManual(N1h, N1h2) # N_2 (h)\n\nprint(\"Hasil Ekstrapolasi Richardson untuk truncation error O(h):\")\nprint(\"N_2 (h) = {0}\".format(N2h))\n\nEkstrapolasi Richardson untuk truncation error O(h)\ndengan sembarang data N_1 (h) dan N_1 (h/2)\nMasukkan data N_1 (h): 2.2974425414002564\nMasukkan data N_1 (h/2): 2.1361016667509656\nHasil Ekstrapolasi Richardson untuk truncation error O(h):\nN_2 (h) = 1.9747607921016748\n\n\n\n\nEkstrapolasi Richardson untuk truncation error \\(O\\left(h^{2j}\\right)\\) (pangkat genap)\nTerkadang, pada bentuk truncation error untuk beberapa metode aproksimasi, semua pangkat \\(h\\) genap, sehingga memenuhi persamaan seperti berikut:\n\\[M = N_1(h) + K_1 h^2 + K_2 h^4 + K_3 h^6 + \\dots\\]\natau bisa dikatakan memiliki error \\(O(h^{2j})\\) untuk suatu \\(j\\) (yang merupakan bilangan bulat positif). Menariknya, sesuai penurunan rumus pada buku “Numerical Analysis” (oleh Burden & Faires) edisi ke-9, halaman 187-188, untuk kasus error \\(O(h^{2j})\\), ada bentuk umum rekursif untuk rumus ekstrapolasi Richardson, yaitu sebagai berikut:\n\\[N_j (h) = N_{j-1} \\left( \\frac{h}{2} \\right) + \\frac{N_{j-1} \\left( h/2 \\right) - N_{j-1} (h)}{4^{j-1} - 1}\\]\nuntuk bilangan bulat \\(j \\ge 2\\).\nPerhatikan bahwa perhitungan \\(N_2 (h)\\) akan memerlukan \\(N_1 (h)\\) dan \\(N_1 \\left( \\frac{h}{2} \\right)\\). Kemudian, perhitungan \\(N_3 (h)\\) akan memerlukan \\(N_2 (h)\\) dan \\(N_2 \\left( \\frac{h}{2} \\right)\\), di mana perhitungan \\(N_2 \\left( \\frac{h}{2} \\right)\\) akan memerlukan \\(N_1 \\left( \\frac{h}{2} \\right)\\) dan \\(N_1 \\left( \\frac{h}{4} \\right)\\).\nKita bisa menampilkan semua hasil perhitungan menggunakan tabel, dengan bentuk yang “mirip” dengan metode Neville. Kali ini, kolom pertama adalah hasil \\(O(h^2)\\) atau \\(N_1\\), kolom kedua adalah hasil \\(O(h^4)\\) yaitu \\(N_2\\), kolom ketiga adalah hasil \\(O(h^6)\\) yaitu \\(N_3\\), dan seterusnya. Sedangkan, setidaknya untuk \\(N_1\\), baris pertama adalah hasil untuk step size h, baris kedua untuk step size \\(\\frac{h}{2}\\), baris ketiga untuk \\(\\frac{h}{4}\\), baris keempat untuk \\(\\frac{h}{8}\\), dan seterusnya.\nPerhatikan contoh tabel berikut. Angka 1, 2, 3, …, 9, 10 yang bercetak tebal melambangkan urutan perhitungan (dilakukan per baris, dari kiri ke kanan).\n\n\n\ncrop tabel 4_6 hal 188 Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org)_page-0001.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.2, “Richardson’s Extrapolation”. Hlm. 188\nBahkan, seperti metode Neville, kita bisa membuat program sehingga, selain perhitungan disimpan dalam bentuk tabel (atau list di dalam list), kita juga bisa melakukan perhitungan selanjutnya berdasarkan data pada tabel. Contohnya, untuk perhitungan \\(N_2 (h)\\) (baris kedua, kolom kedua), kita bisa menggunakan data “ke atas satu langkah, ke kiri satu langkah” untuk \\(N_1 (h)\\), dan menggunakan data “ke kiri satu langkah” untuk \\(N_1 \\left( \\frac{h}{2} \\right)\\).\nSeperti pada tabel di atas, perhitungan bisa dilakukan per baris. Bahkan, seperti pada metode Neville, kita selalu bisa menambahkan baris baru dengan mudah.\n\nfrom tabulate import tabulate\n\n# jaga-jaga ada konstanta pi atau e pada data N1 yang diberikan\nfrom numpy import pi, e\n\n# fungsi untuk menambahkan baris baru pada tabel yang sudah ada\ndef TambahkanRichardsonO2j(tabel_lama, N1baru):\n    # Duplikasi tabel lama menjadi tabel baru (karena akan dimodifikasi)\n    tabel_baru = []\n    for baris in tabel_lama:\n        calon_baris = []\n        for nilai in baris:\n            calon_baris.append(nilai)\n        tabel_baru.append(calon_baris)\n\n    # Tambahkan kolom kosong pada baris-baris yang sudah ada\n    for i in range(len(tabel_baru)):\n        tabel_baru[i].append(\"\")\n\n    # Membuat baris baru...\n    baris_baru = [N1baru]\n    # ... dengan kolom sebanyak len(tabel_lama)+1:\n    for i in range(len(tabel_lama)):\n        baris_baru.append(\"\")\n    # meskipun saat ini kosong, setelah ini akan diisi sesuai rumus.\n    # Tambahkan dulu ke tabel (sebagai baris paling bawah terbaru):\n    tabel_baru.append(baris_baru)\n\n    # Mengisi baris paling bawah\n    k = len(baris_baru) # banyaknya titik termasuk titik baru\n    i = k-1 # baris baru adalah baris ke-k, dengan indeks (k-1)\n    for j in range(1, k): # untuk kolom N2 (indeks 1), N3 (indeks 2), ...\n        # N_{j-1} (h) yaitu ke atas satu langkah, ke kiri satu langkah\n        Nj1h = tabel_baru[i-1][j-1]\n\n        # N_{j-1} (h/2) yaitu ke kiri satu langkah\n        Nj1h2 = tabel_baru[i][j-1]\n\n        # Pada rumus, \"j\" yang dimaksud bukanlah indeks, tapi kolom ke-j,\n        # sehingga indeks 1 adalah kolom ke-2, indeks 2 adalah kolom ke-3, dst\n        j_kolom = j+1\n\n        # nilai baru, N_j (h), menggunakan rumus rekursif\n        tabel_baru[i][j] = Nj1h2 + (Nj1h2 - Nj1h)/(4**(j_kolom-1) - 1)\n\n    # Tabel sudah jadi\n    return tabel_baru\n\n# Kode utama untuk Ekstrapolasi Richardson O(h^2j)\ndef EkstrapolasiRichardsonO2j(list_N1):\n    # Awal membuat tabel\n    tabel_mentah = [\n        [list_N1[0]]\n    ]\n    # mula-mula, hanya ada satu nilai yaitu N1 (h),\n    # sehingga hanya ada satu baris dan satu kolom\n\n    # banyaknya baris/kolom untuk tabel yang akan dibuat\n    k = len(list_N1)\n\n    # lakukan TambahkanRichardsonO2j untuk tiap titik berikutnya\n    for i in range(1, k):\n        tabel_mentah = TambahkanRichardsonO2j(tabel_mentah, list_N1[i])\n\n    # Mengolah tabel menggunakan tabulate\n    list_header = []\n    for i in range(k):\n        list_header.append(\"O(h^{0})\".format(2*(i+1)))\n    tabel_olahan = tabulate(tabel_mentah, headers=list_header,\n                            tablefmt=\"orgtbl\")\n    print(\"Tabel Ekstrapolasi Richardson untuk O(h^2j)\")\n    print(tabel_olahan)\n\n    # Looping\n\n    jawaban = input(\"Apakah Anda ingin menambahkan nilai? (y/n): \")\n    ingin_menambahkan = False\n    if jawaban == \"y\":\n        ingin_menambahkan = True\n\n    while ingin_menambahkan:\n        N1baru = eval(input(\"Masukkan nilai N1 (h/{0}): \".format(2**k)))\n        print()\n\n        tabel_mentah = TambahkanRichardsonO2j(tabel_mentah, N1baru)\n        list_header.append(\"O(h^{0})\".format(2**k))\n        tabel_olahan = tabulate(tabel_mentah, headers=list_header,\n                                tablefmt=\"orgtbl\")\n        print(\"Tabel Ekstrapolasi Richardson untuk O(h^2j)\")\n        print(tabel_olahan)\n\n        jawaban = input(\"Apakah Anda ingin menambahkan nilai? (y/n): \")\n        if jawaban != \"y\":\n            ingin_menambahkan = False\n\n        k += 1\n\n    print()\n    print(\"Terima kasih telah menggunakan program.\")\n\n\nbanyaknya_N1 = eval(input(\"Berapa nilai N1 yang ingin dimasukkan?: \"))\n\nlist_N1 = []\nfor i in range(banyaknya_N1):\n    pembagi = 2**i\n    if pembagi != 1:\n        pertanyaan = \"Masukkan nilai N1 (h/{0}): \".format(pembagi)\n    else:\n        pertanyaan = \"Masukkan nilai N1 (h): \"\n    N1baru = eval(input(pertanyaan))\n    list_N1.append(N1baru)\n\nprint()\nEkstrapolasiRichardsonO2j(list_N1)\n\nBerapa nilai N1 yang ingin dimasukkan?: 3\nMasukkan nilai N1 (h): 1.570796\nMasukkan nilai N1 (h/2): 1.896119\nMasukkan nilai N1 (h/4): 1.974232\n\nTabel Ekstrapolasi Richardson untuk O(h^2j)\n|   O(h^2) | O(h^4)             | O(h^6)             |\n|----------+--------------------+--------------------|\n|  1.5708  |                    |                    |\n|  1.89612 | 2.00456            |                    |\n|  1.97423 | 2.0002696666666666 | 1.9999836444444443 |\nApakah Anda ingin menambahkan nilai? (y/n): y\nMasukkan nilai N1 (h/8): 1.993570\n\nTabel Ekstrapolasi Richardson untuk O(h^2j)\n|   O(h^2) | O(h^4)             | O(h^6)             | O(h^8)            |\n|----------+--------------------+--------------------+-------------------|\n|  1.5708  |                    |                    |                   |\n|  1.89612 | 2.00456            |                    |                   |\n|  1.97423 | 2.0002696666666666 | 1.9999836444444443 |                   |\n|  1.99357 | 2.000016           | 1.999999088888889  | 1.999999334038801 |\nApakah Anda ingin menambahkan nilai? (y/n): n\n\nTerima kasih telah menggunakan program."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/metnum/modul6.html",
    "href": "semuahalaman/modulprak/2023/genap/metnum/modul6.html",
    "title": "Modul 6: Metode Langsung untuk SPL",
    "section": "",
    "text": "Modul 6: Metode Langsung untuk SPL\nKembali ke Metode Numerik\nOutline\n\nOperasi matriks pada Python\nReview SPL: sistem persamaan linier (penjelasan tanpa kode)\nMemperoleh matriks diperbesar \\(\\tilde{A}\\) dari \\(A\\textbf{x}=\\textbf{b}\\), dan sebaliknya\nEliminasi Gauss dan substitusi balik\nPartial Pivoting\nScaled Partial Pivoting\n(Materi pengayaan) Faktorisasi LU\n\n\nimport numpy as np\n\n\n\n1. Operasi matriks pada Python\nSebelum masuk ke materi metode numerik untuk sistem persamaan linier (SPL), mari kita bahas lebih lanjut tentang operasi matriks menggunakan numpy di Python.\nMengingat kembali, tanpa numpy, matriks dalam Python bisa dituliskan sebagai list dua dimensi (list di dalam list).\n\nmatriks_manual = [ [1, 2, 3], [4, 5, 6] ]\nprint(matriks_manual)\n\n[[1, 2, 3], [4, 5, 6]]\n\n\nAda beberapa keunggulan array numpy dibandingkan dengan list dua dimensi yang dibuat secara manual seperti itu. Cara membuatnya adalah memasukkan suatu list dua dimensi ke dalam np.array, seperti berikut:\n\n# sebelumnya, sudah dibuat list dua dimensi bernama \"matriks_manual\"\nmatriks_numpy = np.array(matriks_manual)\nprint(matriks_numpy)\n\n[[1 2 3]\n [4 5 6]]\n\n\nPada kode di atas, kita telah membuat list dua dimensi di variabel terpisah, sebelum memasukkannya di dalam np.array. Namun, tentu saja, kita bisa langsung membuat list dua dimensinya di dalam np.array:\n\nmatriks_baru = np.array([ [1,2,3], [4,5,6] ])\nprint(matriks_baru)\n\n[[1 2 3]\n [4 5 6]]\n\n\nPerhatikan bahwa tiap list di dalam list adalah baris pada matriks. Misalnya, ada list di dalam list, [1,2,3] yang menjadi baris pertama, diikuti dengan list di dalam list, [4,5,6] yang menjadi baris berikutnya. Kedua list tersebut merupakan bagian dari satu list besar (perhatikan, di dalam np.array itu diawali dan diakhiri kurung siku, karena sebenarnya np.array menerima input berupa list di dalam list).\nHal ini akan penting nantinya ketika ingin menerima input berupa matriks dari user (pengguna).\nSebenarnya, np.array bisa saja menerima input berupa list biasa (bisa dikatakan satu dimensi), di mana outputnya akan berupa array satu dimensi. Selain itu, numpy bisa membuat beberapa jenis array/matriks istimewa. Contohnya, array/matriks yang berisi angka nol semua, dengan np.zeros:\n\nbaris_nol = np.zeros(5) # lima elemen\nprint(baris_nol)\n\n[0. 0. 0. 0. 0.]\n\n\n\nmatriks_nol = np.zeros( (3,2) ) # tiga baris, dua kolom\nprint(matriks_nol)\n\n[[0. 0.]\n [0. 0.]\n [0. 0.]]\n\n\nPerhatikan bahwa, untuk array berdimensi dua (matriks), ada kurung di dalam kurung (seolah-olah, input yang diterima adalah semacam “koordinat”), tidak seperti untuk array biasa (satu dimensi) yang langsung dimasukkan banyaknya elemen tanpa ada kurung lagi.\nSelain nol semua, numpy juga bisa membuat array/matriks yang berisi angka 1 semua, dengan cara yang serupa, dengan np.ones.\n\nprint(np.ones(4))\n\n[1. 1. 1. 1.]\n\n\n\nprint(np.ones( (2, 5) ))\n\n[[1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1.]]\n\n\nUntuk angka selain nol dan satu, kita tinggal membuat array/matriks yang berisi satu semua, kemudian dikalikan dengan apapun angka itu.\n\n# matriks berisi 7 semua\nprint(7 * np.ones( (2, 5) ))\n\n[[7. 7. 7. 7. 7.]\n [7. 7. 7. 7. 7.]]\n\n\nKemudian, kita juga bisa membuat matriks diagonal (yang tentunya merupakan matriks persegi), dengan elemen diagonal sesuai yang kita inginkan, menggunakan np.diag.\n\nelemen_diagonal = np.array([5, 4, 3, 2])\nprint(np.diag(elemen_diagonal))\n\n[[5 0 0 0]\n [0 4 0 0]\n [0 0 3 0]\n [0 0 0 2]]\n\n\nArtinya, untuk membuat matriks identitas, kita bisa menerapkan np.diag pada np.ones.\n\nprint(np.diag(np.ones(4)))\n\n[[1. 0. 0. 0.]\n [0. 1. 0. 0.]\n [0. 0. 1. 0.]\n [0. 0. 0. 1.]]\n\n\nSebenarnya, dari numpy sudah ada fungsi khusus untuk membuat matriks identitas, yaitu np.identity.\n\nprint(np.identity(3))\n\n[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]\n\n\nSama seperti list, pada matriks juga dapat dilakukan indexing dan slicing. Indexing pada matriks juga dimulai dari 0. Matriks adalah array 2-D, sehingga indeks akan terdiri dari [i, j] di mana i menyatakan indeks baris dan j menyatakan indeks kolom.\n\nA = np.array([[1,2,3], [4,5,6]]) #mendefinisikan matriks A 2x3\nB = np.array([[-1,0,1], #mendefinisikan matriks B 2x3\n              [0,0,1]])\nC = np.array([[1,0,1], #mendefinisikan matriks B 3x3\n              [0,1,1],\n              [1,1,1]])\n\n\nprint(A)\n\n[[1 2 3]\n [4 5 6]]\n\n\n\nprint(B)\n\n[[-1  0  1]\n [ 0  0  1]]\n\n\n\nprint(C)\n\n[[1 0 1]\n [0 1 1]\n [1 1 1]]\n\n\n\nprint(A[0]) #menampilkan baris pertama (indeks 0) dari matriks A\n\n[1 2 3]\n\n\n\n#menampilkan baris pertama (indeks 0), kolom kedua (indeks 1) dari matriks A\nprint(A[0, 1])\n\n2\n\n\n\n# tampilkan baris pertama (indeks 0),\n# mulai dari kolom kedua (indeks 1) dan seterusnya\nprint(A[0, 1:])\n\n[2 3]\n\n\n\n# tampilkan baris pertama (indeks 0),\n# tampilkan semua kolom sampai sebelum kolom ketiga (sebelum indeks 2)\nprint(A[0, :2])\n\n[1 2]\n\n\n\n# tampilkan nilai pada semua baris,\n# tapi melihat kolom kedua (indeks 1) saja\nprint(A[:, 1])\n\n[2 5]\n\n\n\n# tampilkan semua baris,\n# mulai dari kolom kedua (indeks 1) dan seterusnya\nprint(A[:, 1:])\n\n[[2 3]\n [5 6]]\n\n\n\n# tampilkan baris pertama (indeks nol),\n# tapi kolom pertama dari belakang (hitung mundur)\nprint(A[0, -1])\n\n3\n\n\n\n# tampilkan baris pertama dari belakang,\n# kolom pertama dari belakang\nprint(A[-1, -1])\n\n6\n\n\nOperasi dasar seperti penjumlahan dan pengurangan dapat dilakukan secara langsung seperti halnya penjumlahan/pengurangan bilangan.\n\nprint(A+B)\nprint(A-B)\n\n[[0 2 4]\n [4 5 7]]\n[[2 2 2]\n [4 5 5]]\n\n\nOperasi perkalian skalar dapat menggunakan tanda bintang atau asterisk (*), dan urutannya boleh ditukar.\n\nprint(3*A) # 3 dikali A\nprint(B*4) # B dikali 4\n\n[[ 3  6  9]\n [12 15 18]]\n[[-4  0  4]\n [ 0  0  4]]\n\n\nApabila dua matriks dikalikan begitu saja dengan tanda bintang, maka perkalian akan dilakukan secara broadcasting, yaitu per elemen.\n\nprint(A)\nprint(B)\nprint(A*B)\n\n[[1 2 3]\n [4 5 6]]\n[[-1  0  1]\n [ 0  0  1]]\n[[-1  0  3]\n [ 0  0  6]]\n\n\nPerkalian matriks yang biasa kita kenal di aljabar linier tidak seperti itu. Numpy menyediakan fungsi khusus untuk perkalian matriks yang seperti di aljabar linier, yaitu np.matmul (matrix multiplication). Tentu saja, ada syarat ukuran matriks, yaitu \\(m \\times n\\) dan \\(n \\times p\\).\nKode berikut ini akan gagal karena tidak memenuhi syarat.\n\nnp.matmul(A,B)\n\nValueError: ignored\n\n\nPerkalian A dengan B tidak dapat dilakukan dan muncul error message. Cek ukuran dari matriks dengan menggunakan np.shape.\n\nprint(np.shape(A)) #Ukuran matriks A\nprint(np.shape(B)) #Ukuran matriks B\nprint(np.shape(C)) #Ukuran matriks C\n\n(2, 3)\n(2, 3)\n(3, 3)\n\n\nBaik A dan B memiliki ukuran 2x3, sehingga AB tidak terdefinisi. Namun, apabila kita men-transpose B, kita dapat melakukan perkalian \\(AB^T\\). Untuk mentranspose matriks, gunakan np.transpose\n\nnp.matmul(A, np.transpose(B)) #A B^T\n\narray([[2, 3],\n       [2, 6]])\n\n\nSebagai tambahan, numpy juga bisa menghitung dot product (perkalian dot, yaitu hasil kali titik) antara dua array satu dimensi, menggunakan np.dot\n\nvektor1 = np.array([1, -5, 0])\nvektor2 = np.array([-3, 7, 10])\nprint(np.dot(vektor1, vektor2))\n\n-38\n\n\nSeandainya kita menggunakan np.dot dengan dua matriks, maka numpy akan mengartikannya sebagai np.matmul\n\nnp.dot(A, np.transpose(B)) #A B^T\n\narray([[2, 3],\n       [2, 6]])\n\n\nSelebihnya bisa dibaca di dokumentasi numpy:\nhttps://numpy.org/doc/stable/reference/generated/numpy.dot.html\nTerakhir, numpy memiliki beberapa fungsi khusus lainnya untuk aljabar linier, yang menariknya mengharuskan penulisan “linalg” (linear algebra; aljabar linier), karena memang merupakan bagian khusus di dalam numpy. Contohnya adalah determinan dan invers.\n\nD = np.array([[2, -3], [-2, 5]])\n\nprint(D)\nprint(np.linalg.det(D)) # det(D), yaitu determinan dari matriks D\nprint(np.linalg.inv(D)) # D^-1, yaitu invers dari matriks D\n\nprint(np.linalg.det(np.linalg.inv(D))) # det(D^-1)\n\n[[ 2 -3]\n [-2  5]]\n4.0\n[[1.25 0.75]\n [0.5  0.5 ]]\n0.24999999999999994\n\n\nJangan lupa, apabila ada hasil yang sedikit aneh, seperti 1/4 = 0.2499999…, itu disebabkan oleh kelemahan floating-point precision yang dibahas di pertemuan pertama kuliah Metode Numerik. Python tidak kebal terhadap masalah tersebut.\nSelain itu, apabila keseluruhan matriks berisi bilangan bulat, bisa saja dilakukan integer division, di mana semua hasil pembagian itu dibulatkan ke bawah. Hal ini tentu sangat berbahaya jika ada operasi pembagian dalam metode numerik. Untuk menghindari masalah tersebut, array bisa dikonversi menjadi float semua, menggunakan .astype(float)\n\n# berisi bilangan bulat semua\narraybulat = np.array([5, 4])\nprint(arraybulat)\n\n# arraybulat[0] = 5//4 = floor(5/4) = floor(1.25) = 1\narraybulat[0] = arraybulat[0]/arraybulat[1]\nprint(arraybulat)\n\n[5 4]\n[1 4]\n\n\n\narraybulat = np.array([5, 4])\narrayfloat = arraybulat.astype(float)\nprint(arrayfloat)\n\n# mencoba hal yang sama,\n# kali ini tidak ada integer division sehingga 5/4 = 1.25\narrayfloat[0] = arrayfloat[0]/arrayfloat[1]\nprint(arrayfloat)\n\n[5. 4.]\n[1.25 4.  ]\n\n\n\n\n2. Review SPL: sistem persamaan linier (penjelasan tanpa kode)\nSuatu sistem persamaan linier (SPL) adalah kumpulan beberapa persamaan linier dalam beberapa variabel \\(x_1, x_2, \\dots, x_n\\), misal sebanyak \\(m\\) persamaan. Idealnya, banyaknya variabel sama dengan banyaknya persamaan, yaitu \\(n=m\\). (Praktikum Metode Numerik akan membahas SPL dengan \\(n=m\\).)\nBentuk umum SPL bisa dituliskan sebagai berikut:\n\\[ \\begin{align}\na_{11} x_1 + a_{12} x_2 + &\\dots + a_{1n} x_n = b_1 \\\\\na_{21} x_1 + a_{22} x_2 + &\\dots + a_{2n} x_n = b_2 \\\\\na_{31} x_1 + a_{32} x_2 + &\\dots + a_{3n} x_n = b_3 \\\\\n&\\vdots \\\\\na_{m1} x_1 + a_{m2} x_2 + &\\dots + a_{mn} x_n = b_m\n\\end{align} \\]\ndi mana koefisien \\(a_{ij}\\) adalah koefisien pada persamaan ke-i untuk variabel \\(x_j\\), dan ada konstanta \\(b_i\\) untuk tiap persamaan \\(i = 1, 2, \\dots, m\\).\nUmumnya, semua koefisien \\(a_{ij}\\) serta konstanta \\(b_i\\) sudah diketahui nilainya, dan ingin dicari nilai-nilai \\(x_j\\) yang bersama memenuhi semua persamaan sekaligus, disebut solusi dari SPL tersebut.\nApabila \\(n=m\\), bentuk umum SPL menjadi\n\\[ \\begin{align}\na_{11} x_1 + a_{12} x_2 + &\\dots + a_{1n} x_n = b_1 \\\\\na_{21} x_1 + a_{22} x_2 + &\\dots + a_{2n} x_n = b_2 \\\\\na_{31} x_1 + a_{32} x_2 + &\\dots + a_{3n} x_n = b_3 \\\\\n&\\vdots \\\\\na_{n1} x_1 + a_{n2} x_2 + &\\dots + a_{nn} x_n = b_n\n\\end{align} \\]\nyang dapat dituliskan dalam bentuk perkalian matriks-vektor:\n\\[\n\\begin{pmatrix}\na_{11} & a_{12} & \\dots & a_{1n} \\\\\na_{21} & a_{22} & \\dots & a_{2n} \\\\\na_{31} & a_{32} & \\dots & a_{3n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{n1} & a_{n2} & \\dots & a_{nn} \\\\\n\\end{pmatrix}\n\\begin{pmatrix}\nx_1 \\\\ x_2 \\\\ x_3 \\\\ \\vdots \\\\ x_n\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nb_1 \\\\ b_2 \\\\ b_3 \\\\ \\vdots \\\\ b_n\n\\end{pmatrix}\n\\]\nMatriks koefisien \\(a_{ij}\\) bisa ditulis \\(A\\), vektor kolom \\(x_j\\) bisa ditulis \\(\\textbf{x}\\), dan vektor kolom \\(b_i\\) bisa ditulis \\(\\textbf{b}\\), agar bentuk perkalian matriks-vektor di atas bisa diringkas: \\(A\\textbf{x}=\\textbf{b}\\). Dalam hal ini, \\(\\textbf{x}\\) adalah vektor solusi.\nDengan demikian, notasi \\(a_{ij}\\) bisa juga diartikan sebagai elemen matriks \\(A\\) pada baris ke-i, kolom ke-j.\nKita bisa “menggabungkan” vektor \\(\\textbf{b}\\) menjadi kolom baru (kolom paling kanan) di matriks \\(A\\), sehingga dari yang tadinya berukuran \\(n \\times n\\) menjadi berukuran \\(n \\times \\left(n+1\\right)\\):\n\\[\n\\begin{pmatrix}\na_{11} & a_{12} & \\dots & a_{1n} & b_1 \\\\\na_{21} & a_{22} & \\dots & a_{2n} & b_2 \\\\\na_{31} & a_{32} & \\dots & a_{3n} & b_3 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots & \\vdots\\\\\na_{n1} & a_{n2} & \\dots & a_{nn} & b_n\n\\end{pmatrix}\n\\]\nMatriks baru ini biasa disebut augmented matrix atau matriks diperbesar, dan biasa ditulis \\(\\tilde{A}\\).\nKita juga bisa menuliskan \\(a_{i,\\left(n+1\\right)} = b_i\\) untuk \\(i = 1, 2, \\dots, n\\), agar konsisten dengan notasi \\(a_{ij}\\) yaitu elemen matriks pada baris ke-i, kolom ke-j.\n\\[\n\\tilde{A} = \\begin{pmatrix}\na_{11} & a_{12} & \\dots & a_{1n} & a_{1,\\left(n+1\\right)} \\\\\na_{21} & a_{22} & \\dots & a_{2n} & a_{2,\\left(n+1\\right)} \\\\\na_{31} & a_{32} & \\dots & a_{3n} & a_{3,\\left(n+1\\right)} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots & \\vdots\\\\\na_{n1} & a_{n2} & \\dots & a_{nn} & a_{n,\\left(n+1\\right)}\n\\end{pmatrix}\n\\]\n\n\n3. Memperoleh matriks diperbesar dari \\(A\\textbf{x}=\\textbf{b}\\), dan sebaliknya\nMisalkan kita punya SPL seperti berikut:\n\\[ \\begin{array}{rcrcrcrc@{\\qquad}}\nx_1 & - &  x_2   & + &  2x_3 & - &  x_4 & = & -8 \\\\\n2x_1 & - & 2x_2   & + &  3x_3 & - & 3x_4 & = & -20 \\\\\nx_1 & + &  x_2   & + &   x_3 &   &      & = & -2 \\\\\nx_1 & - &  x_2   & + &  4x_3 &   & 3x_4 & = &  4\n\\end{array} \\]\nMatriks koefisien \\(A\\) dan vektor \\(\\textbf{b}\\) dari SPL di atas adalah\n\\[ A = \\begin{pmatrix}\n1 & -1 & 2 & -1 \\\\\n2 & -2 & 3 & -3 \\\\\n1 & 1 & 1 & 0 \\\\\n1 & -1 & 4 & 3\n\\end{pmatrix}, \\hspace{0.5cm} \\textbf{b} = \\begin{pmatrix}\n-8 \\\\ -20 \\\\ -2 \\\\ 4\n\\end{pmatrix}\\]\nSehingga, matriks diperbesar \\(\\tilde{A}\\) dari SPL di atas adalah\n\\[ \\tilde{A} = \\begin{pmatrix}\n1 & -1 & 2 & -1 & -8 \\\\\n2 & -2 & 3 & -3 & -20 \\\\\n1 & 1 & 1 & 0 & -2 \\\\\n1 & -1 & 4 & 3 & 4\n\\end{pmatrix} \\]\nApabila kita hanya memiliki matriks koefisien \\(A\\) dan vektor \\(\\textbf{b}\\), kita bisa saja memperoleh matriks diperbesar \\(\\tilde{A}\\) menggunakan numpy:\n\n# [[1,-1,2,-1, -8],[2,-2,3,-3,-20],[1,1,1,0,-2], [1,-1,4,3,4]]\n\nA_koef = np.array([\n    [1,-1,2,-1],\n    [2,-2,3,-3],\n    [1,1,1,0],\n    [1,-1,4,3]\n])\n\nb = np.array([-8,-20,-2,4])\n\n# n adalah banyaknya baris\nn = np.shape(A_koef)[0]\n\n# buat dulu matriks kosong berukuran n x (n+1)\nA_diperbesar = np.zeros((n, n+1))\n\n# sampai baris ke-n, kolom ke-n, gunakan saja semua nilai matriks koefisien\nA_diperbesar[:n, :n] = A_koef\n\n# untuk kolom terakhir, gunakan for loop untuk memperoleh nilai dari vektor b\nfor i in range(n):\n    A_diperbesar[i, n] = b[i]\n\nprint(A_diperbesar)\n\n[[  1.  -1.   2.  -1.  -8.]\n [  2.  -2.   3.  -3. -20.]\n [  1.   1.   1.   0.  -2.]\n [  1.  -1.   4.   3.   4.]]\n\n\nTentunya, kita juga bisa memperoleh matriks koefisien \\(A\\) dan vektor \\(\\textbf{b}\\) secara pemrograman apabila hanya diketahui matriks diperbesar \\(\\tilde{A}\\).\n\nA_diperbesar = np.array([\n    [1,-1,2,-1,-8],\n    [2,-2,3,-3,-20],\n    [1,1,1,0,-2],\n    [1,-1,4,3,4]\n])\n\n# n adalah banyaknya baris\nn = np.shape(A_diperbesar)[0]\n\n# gunakan nilai-nilai sampai baris ke-n, kolom ke-n untuk matriks koefisien\nA_koef = A_diperbesar[:n, :n]\n\n# untuk vektor b, buat array kosong dulu\nb = np.zeros(n)\n# lalu gunakan for loop untuk memperoleh nilai pada kolom terakhir\nfor i in range(n):\n    b[i] = A_diperbesar[i, n]\n\nprint(\"Matriks koefisien A:\")\nprint(A_koef)\nprint(\"Vektor b:\")\nprint(b)\n\nMatriks koefisien A:\n[[ 1 -1  2 -1]\n [ 2 -2  3 -3]\n [ 1  1  1  0]\n [ 1 -1  4  3]]\nVektor b:\n[ -8. -20.  -2.   4.]\n\n\n\n\n4. Eliminasi Gauss dan substitusi balik\nSeperti yang sudah dipelajari di aljabar linier, eliminasi Gauss adalah teknik menyelesaikan (SPL) dengan menerapkan operasi baris elementer (OBE) pada matriks diperbesarnya. OBE adalah beberapa operasi khusus bisa yang dilakukan pada satu/dua baris dalam suatu matriks diperbesar (misal baris \\(E_i\\) dan \\(E_j\\)), dengan sifat istimewa yaitu tidak akan mengubah nilai solusi SPL \\(x_1, x_2, \\dots, x_n\\) sama sekali. OBE bisa berupa:\n\nPertukaran baris: \\((E_i) \\leftrightarrow (E_j)\\)\nPerkalian baris oleh skalar: \\((\\lambda E_i) \\rightarrow (E_i)\\)\nPenjumlahan suatu baris dengan kelipatan skalar dari baris lain \\(( E_i + \\lambda E_j ) \\rightarrow (E_i)\\)\n\n(“E” adalah singkatan dari equation.)\nMisalkan terdapat SPL yang dinyatakan dalam bentuk \\(Ax = b\\), di mana A adalah matriks berukuran \\(n \\times n\\) dan \\(\\textbf{b}\\) adalah vektor berukuran \\(n \\times 1\\). Eliminasi Gauss bertujuan untuk mengubah SPL awal menjadi bentuk triangular:\n\\[ \\begin{align}\na_{11} x_1 + a_{12} x_2 + \\dots + a_{1n}x_n &= a_{1,n+1} \\\\\na_{22} x_2 + \\dots + a_{2n}x_n &= a_{2,n+1} \\\\\n\\vdots \\\\\na_{nn}x_n &= a_{n,n+1}\n\\end{align} \\]\nSebenarnya, semua koefisien yang terlihat “hilang” itu masih ada, hanya saja sudah berhasil diubah menjadi nol.\nKemudian, untuk mencari nilai \\(x_1, x_2, \\dots, x_n\\) dari bentuk triangular tersebut, lakukan substitusi balik (back substitution). Dari persamaan terakhir diperoleh\n\\[x_n = \\frac{a_{n,n+1}}{a_{nn}}\\]\nSubstitusi \\(x_n\\) ke persamaan ke-(n-1) diperoleh \\(x_{n-1}\\). Substitusi \\(x_n\\) dari \\(x_{n-1}\\) ke persamaan ke-(n-2) diperoleh \\(x_{n-2}\\). Lakukan terus sampai mendapatkan \\(x_1\\).\nUntuk menyelesaikan SPL menggunakan eliminasi Gauss dan substitusi balik (Gaussian elimination with backward substitution), SPL dapat ditulis sebagai matriks diperbesar. Kemudian, lakukan langkah-langkah berikut.\n\nBuat semua entri di bawah \\(a_{ii}\\) (untuk setiap kolom \\(i = 1, 2, \\dots, n\\)) menjadi nol dengan melakukan operasi baris elementer: \\[\\left( E_j - \\left( \\frac{a_{ji}}{a_{ii}} \\right)E_i \\right) \\rightarrow E_j\\] untuk baris ke-j, dengan \\(j = i+1, i+2, \\dots, n\\). Namun, kita bisa menuliskan \\(m = \\frac{a_{ji}}{a_{ii}}\\) (m: multiplier; pengkali) agar bentuknya menjadi \\[\\left( E_j - mE_i \\right) \\rightarrow E_j\\] atau sama saja \\[E_j \\leftarrow \\left( E_j - mE_i \\right)\\]\nLakukan substitusi balik, diawali rumus: \\[x_n = \\frac{a_{n,n+1}}{a_{nn}}\\] Kemudian, menghitung mundur, untuk \\(i = n-1, n-2, \\dots, 2, 1\\), hitung: \\[x_i = \\frac{a_{i,n+1} - \\sum_{j=i+1}^{n}a_{ij}x_j}{a_{ii}}\\] Fun fact: rumus itu diperoleh dengan melakukan pindah ruas pada persamaan di bentuk triangularnya, seperti berikut: \\[a_{ii}x_{ii} + a_{i,i+1}x_{i,i+1} + a_{i,i+2}x_{i,i+2} + \\dots + a_{in}x_{in} = b_i = a_{i,n+1}\\] \\[a_{ii}x_{ii} + \\sum_{j=i+1}^{n}a_{ij}x_j = a_{i,n+1}\\] \\[a_{ii}x_{ii} = a_{i,n+1} - \\sum_{j=i+1}^{n}a_{ij}x_j\\] \\[x_i = \\frac{a_{i,n+1} - \\sum_{j=i+1}^{n}a_{ij}x_j}{a_{ii}}\\]\n\nNamun, ketika melakukan eliminasi Gauss, apabila ada elemen diagonal \\(a_{ii}\\) yang bernilai nol, maka baris yang mengandung \\(a_{ii}\\) perlu ditukar dengan baris di bawahnya yang elemennya taknol pada kolom yamg sama (kolom ke-i), agar elemen diagonal yang baru menjadi taknol.\nImplementasi Eliminasi Gauss dan Substitusi Balik\n\ndef EliminasiGauss(matriks_input):\n    # konversi matriks_input jadi matriks baru yang isinya float semua,\n    # karena apabila ada bilangan bulat, bisa jadi dilakukan integer division\n    # yang bisa sangat memperparah error\n    matriks = matriks_input.astype(float)\n\n    # memperoleh ukuran baris dari matriks diperbesar\n    n = np.shape(matriks)[0]\n    # Ingat bahwa ukuran matriks diperbesar adalah n x (n+1)\n\n    for i in range (n): # untuk kolom ke-i (dari kolom awal sampai ke-n)\n        # Saat ini, kita sedang melakukan eliminasi Gauss untuk kolom ke-i.\n        # Semua nilai koefisien di bawah elemen diagonal akan dibuat nol\n\n        # Sebelum mengeliminasi, kita perlu memastikan elemen diagonal taknol.\n        # Kalau misalnya nol, kita perlu melihat baris-baris berikutnya\n        # untuk bertukar baris agar elemen diagonal menjadi taknol\n\n        # Variabel p (\"pivot\") akan digunakan untuk melihat baris.\n        # Kita lihat dulu baris ke-i\n        p = i\n        # sehingga, saat ini, matriks[p,i] adalah elemen diagonal.\n        # Ingat, elemen diagonal harusnya taknol.\n\n        # Kalau ternyata nilai elemen tersebut adalah nol,\n        # lanjut melihat di bawahnya (mencari calon baris yang bisa ditukar),\n        # dan kalau masih nol, lihat ke bawahnya lagi, dan seterusnya\n        while p&lt;n and matriks[p,i]==0:\n            p += 1\n        # tapi jangan sampai keluar dari matriks (melewati baris terakhir),\n        # makanya dibuat syarat p&lt;n\n        \n        # Kalau sudah keluar dari matriks, artinya semua elemen di bawah\n        # diagonal, bahkan termasuk elemen diagonal, itu nol semua.\n        # Sayangnya, SPL tidak bisa diselesaikan\n        if p == n:\n            return \"SPL tidak memiliki solusi unik.\"\n        # Namun, kalau bisa diselesaikan, lanjut...\n        else:\n            # Tadinya, p melihat baris ke-i.\n            # Kalau p sudah pindah ke bawahnya (sudah tidak sama dengan i),\n            # artinya elemen diagonal saat ini bernilai nol, dan perlu ditukar \n            # dengan baris di bawahnya yang nilainya taknol (yaitu yang sedang\n            # ditunjuk oleh indeks p). Maka tukarlah\n            if p != i:\n                matriks[[p,i], :] = matriks[[i,p], :]\n                # syntax khusus numpy untuk menukar baris ke-i dan\n                # baris ke-p, di mana semua nilai per kolom masih sama,\n                # maksudnya tidak ada kolom yang ditukar, sehingga ditulis :\n            \n            # Ada pertukaran maupun tidak, yang pasti, sekarang elemen diagonal\n            # sudah aman, sudah pasti taknol. Mari lanjut ke proses eliminasi.\n            # Lakukan untuk tiap baris ke-j, yaitu untuk semua baris di bawah\n            # elemen diagonal.\n            for j in range (i+1, n):\n                # Melakukan proses eliminasi dengan OBE (sesuai rumus di atas)\n                m = matriks[j,i]/matriks[i,i] # m: \"multiplier\" atau pengkali\n                matriks[j] = matriks[j] - m * matriks[i]\n                #   (E_j) &lt;- (   E_j    - m *    E_i   )\n    \n    # Setelah semua itu dilakukan untuk tiap kolom, eliminasi Gauss selesai\n    return matriks\n\n\ndef SubstitusiBalik(matriks_input):\n    # jaga-jaga\n    matriks = matriks_input.astype(float)\n\n    # memperoleh ukuran baris dari matriks diperbesar\n    n = np.shape(matriks)[0]\n\n    # vektor solusi, sementara isi dengan nol dulu\n    solution = np.zeros(n)\n\n    # lakukan dulu yang paling mudah, yaitu untuk baris paling bawah\n    solution[n-1] = matriks[n-1, n]/matriks[n-1, n-1]\n\n    # untuk baris-baris di atasnya, kita lakukan for loop, menghitung mundur,\n    # terapkan rumus substitusi balik\n    for i in range (n-2, -1, -1):\n        # hitung sumasi, simpan langsung ke matriks[i,n]\n        # agar langsung dijumlahkan ke b_i yaitu a_{i,n+1}\n        for j in range(i+1, n):\n            matriks[i,n] = matriks[i,n] - matriks[i,j] * solution[j]\n        # peroleh solusi menggunakan rumus (dan memanfaatkan hasil sumasi)\n        solution[i] = matriks[i,n]/matriks[i,i]\n    return solution\n\n\naug_matriks = np.array(eval(input('Masukkan matriks diperbesar dari SPL yang akan diselesaikan: ')))\n# mengubah input Anda ke dalam array numpy (matriks)\nprint(\"Berikut matriks yang dimasukkan:\")\nprint(aug_matriks)\n\ntriangular_form = EliminasiGauss(aug_matriks)\nif type(triangular_form) == type(\"\"):\n    # kalau output berupa string, artinya SPL tidak bisa diselesaikan\n    print(triangular_form)\nelse:\n    # Namun, kalau eliminasi Gauss berhasil, lanjut ke substitusi balik\n    solution = SubstitusiBalik(triangular_form)\n    print('Solusi dari SPL tersebut adalah: ')\n    for i in range(len(solution)):\n        print('x{0} = {1}'.format(i+1, solution[i]))\n\nMasukkan matriks diperbesar dari SPL yang akan diselesaikan: [[1,-1,2,-1, -8],[2,-2,3,-3,-20],[1,1,1,0,-2], [1,-1,4,3,4]]\nBerikut matriks yang dimasukkan:\n[[  1  -1   2  -1  -8]\n [  2  -2   3  -3 -20]\n [  1   1   1   0  -2]\n [  1  -1   4   3   4]]\nSolusi dari SPL tersebut adalah: \nx1 = -7.0\nx2 = 3.0\nx3 = 2.0\nx4 = 2.0\n\n\nContoh penggunaan langsung (tanpa perlu menerima input):\n\nmatriks_diperbesar = np.array([\n    [0.003, 59.14, 59.17],\n    [5.291, -6.13, 46.78]\n])\n\n# langsung print vektor solusi\nprint(SubstitusiBalik(EliminasiGauss(matriks_diperbesar)))\n\n[10.  1.]\n\n\n\nmatriks_diperbesar = np.array([\n    [4.0, -1, 0, -1, 0, 0, 0, 0, 0, 25],\n    [-1, 4, -1, 0, -1, 0, 0, 0, 0, 50],\n    [0, -1, 4, 0, 0, -1, 0, 0, 0, 150],\n    [-1, 0, 0, 4, -1, 0, -1, 0, 0, 0],\n    [0, -1, 0, -1, 4, -1, 0, -1, 0, 0],\n    [0, 0, -1, 0, -1, 4, 0, 0, -1, 50],\n    [0, 0, 0, -1, 0, 0, 4, -1, 0, 0],\n    [0, 0, 0, 0, -1, 0, -1, 4, -1, 0],\n    [0, 0, 0, 0, 0, -1, 0, -1, 4, 25]\n])\nprint(matriks_diperbesar)\n\n# langsung print vektor solusi\nprint(SubstitusiBalik(EliminasiGauss(matriks_diperbesar)))\n\n[[  4.  -1.   0.  -1.   0.   0.   0.   0.   0.  25.]\n [ -1.   4.  -1.   0.  -1.   0.   0.   0.   0.  50.]\n [  0.  -1.   4.   0.   0.  -1.   0.   0.   0. 150.]\n [ -1.   0.   0.   4.  -1.   0.  -1.   0.   0.   0.]\n [  0.  -1.   0.  -1.   4.  -1.   0.  -1.   0.   0.]\n [  0.   0.  -1.   0.  -1.   4.   0.   0.  -1.  50.]\n [  0.   0.   0.  -1.   0.   0.   4.  -1.   0.   0.]\n [  0.   0.   0.   0.  -1.   0.  -1.   4.  -1.   0.]\n [  0.   0.   0.   0.   0.  -1.   0.  -1.   4.  25.]]\n[18.75 37.5  56.25 12.5  25.   37.5   6.25 12.5  18.75]\n\n\n\n\n5. Partial Pivoting\nPada eliminasi Gauss, pertukaran baris perlu dilakukan ketika elemen diagonal bernilai nol. Namun, kalaupun tidak ada yang tepat bernilai nol, masalah round-off error bisa saja menyebabkan hasil komputasi meleset jauh ketika elemen diagonal bernilai sangat kecil mendekati nol (yang kemudian digunakan sebagai pembagi dalam eliminasi Gauss). Penyebabnya, pembagian oleh bilangan yang sangat kecil bisa sangat sensitif. Contohnya, \\(\\frac{10}{0.00025} = 40000\\), sedangkan \\(\\frac{10}{0.00020} = 50000\\). Dengan begitu, apabila nilai diagonal yang sangat kecil itu salah sedikit (karena masalah floating-point precision atau sejenisnya), hasil akhir nantinya bisa menjadi sangat meleset.\nSolusi yang paling sederhana adalah memodifikasi elminasi Gauss, yaitu agar selalu menukarkan elemen diagonal \\(a_{ii}\\) dengan elemen terbesar di kolom ke-\\(i\\) yang ada di bawahnya (tentu saja, keseluruhan baris ikut ditukar, bukan hanya dua nilai). Solusi ini disebut partial pivoting, dan apapun modifikasi pada eliminasi Gauss untuk menghindari masalah di atas disebut strategi pivoting.\nDalam menerapkan strategi pivoting, algoritma substitusi balik tetap sama persis, karena hanya algoritma eliminasi Gauss yang dimodifikasi.\nargmax dan argmin\nSebelum membahas strategi pivoting, mari kita bahas argmax dan argmin. Kedua fungsi ini tersedia dari numpy. Perbedaannya dengan max dan min cukup sederhana: max dan min mengembalikan nilainya, sedangkan argmax dan argmin mengembalikan indeksnya.\n\narraykecil = np.array([17, 8, 27, 54, 34])\n\nnilai_max = np.max(arraykecil)\nnilai_argmax = np.argmax(arraykecil)\n\nprint(f\"Nilai maksimum ada pada indeks {nilai_argmax}, yaitu {nilai_max}\")\n\nnilai_min = np.min(arraykecil)\nnilai_argmin = np.argmin(arraykecil)\n\nprint(f\"Nilai minimum ada pada indeks {nilai_argmin}, yaitu {nilai_min}\")\n\nNilai maksimum ada pada indeks 3, yaitu 54\nNilai minimum ada pada indeks 1, yaitu 8\n\n\nDengan demikian, apapun konteksnya, apabila kita memerlukan indeks letaknya saja, kita bisa langsung menggunakan argmax atau argmin.\nFun fact: baik argmax maupun argmin dikenal dalam matematika, dalam pembahasan teoritis juga. Contohnya, jika \\(f(x) = 2-x^2\\),\n\\[\\underset{x\\in\\mathbb{N}}{\\arg\\max} f(x) = 1\\]\nkarena bilangan asli \\(x\\) yang membuat nilai \\(f(x)\\) paling besar (di antara semua pilihan bilangan asli lainnya) adalah \\(x=1\\).\nPartial Pivoting\nUntuk eliminasi Gauss, daripada memeriksa apakah elemen diagonal bernilai nol atau tidak, selalu pilihlah indeks \\(p \\ge k\\) terkecil* sedemikian sehingga,\n\\[|a_{pk}^{(k)}| = \\max_{k \\le i \\le n}|a_{ik}^{(k)}|\\]\ndi mana \\(k\\) adalah indeks untuk baris/kolom dari elemen diagonal yang sedang diurus (\\(a_{kk}\\)).\n*apabila ada lebih dari satu baris yang sama-sama memuat nilai terbesar, pilih saja yang pertama kali ditemukan\nIntinya, kita mencari indeks \\(p\\) untuk baris yang memuat elemen maksimum (dari semua elemen di bawah elemen diagonal), agar baris tersebut bisa ditukar dengan baris ke-\\(k\\) yang memuat elemen diagonal yang sedang diurus.\n(“Perpangkatan” dengan \\((k)\\) itu sebenarnya hanya menandakan bahwa, pada saat itu, kita sedang mengurus elemen diagonal pada baris/kolom ke-\\(k\\). Penulisan seperti itu cukup untuk pembahasan teoritis saja. Tujuannya hanya untuk menekankan bahwa, setelah tiap OBE, nilai koefisien bisa jadi berbeda, sehingga harus diberi label tambahan seperti itu untuk memperjelas, nilai koefisien pada tahapan mana yang dimaksud.)\nSetelah indeks \\(p\\) diperoleh, barulah lakukan pertukaran baris \\((E_k) \\leftrightarrow (E_p)\\)\nImplementasi Partial Pivoting\n\ndef PartialPivoting(matriks_input):\n    # konversi matriks_input jadi matriks baru yang isinya float semua,\n    # karena apabila ada bilangan bulat, bisa jadi dilakukan integer division\n    # yang bisa sangat memperparah error\n    matriks = matriks_input.astype(float)\n\n    # n adalah banyaknya baris dari matriks diperbesar\n    n = np.shape(matriks)[0]\n\n    # untuk tiap kolom ke-i kecuali dua kolom terakhir\n    for i in range(n-1):\n        # Kumpulkan semua nilai yang ada di bawah elemen diagonal (pivot)\n        below_pivot = abs(matriks[i:,i])\n        # yaitu semua elemen pada baris di bawah elemen diagonal,\n        # tetapi pada kolom yang sama.\n        # Dibuat nilai mutlak karena yang diperhatikan hanya besarnya,\n        # apakah dekat dengan nol atau tidak, bukan positif/negatifnya\n\n        # Memilih indeks baris yang memuat elemen maksimum, sebagai \"pivot\" baru\n        pivot_row = np.argmax(below_pivot)\n        # Nilai yang disimpan itu sebenarnya adalah indeks \"pergeseran\" ke bawah\n        # Misalnya, apabila variabel pivot_row bernilai 2, artinya baris yang\n        # dipilih ada pada indeks (i+2), atau secara umum ditulis pivot_row+i\n\n        # jika nilai pada baris yang akan di-pivot itu juga nol (padahal sudah\n        # maksimum), maka sebenarnya semua nilai yang bisa ditukar itu nol semua\n        # sehingga SPL tidak mungkin bisa diselesaikan\n        if matriks[i,pivot_row+i] == 0:\n            return \"Tidak ada solusi unik\"\n        else:\n            # Apabila taknol, lakukan pertukaran baris\n            matriks[[pivot_row+i,i], :]= matriks[[i,pivot_row+i], :]\n\n        # melanjutkan eliminasi Gauss seperti biasa\n        for j in range(i+1,n):\n            m = matriks[j,i]/matriks[i,i]\n            matriks[j] = matriks[j]-m*matriks[i]\n    \n    return matriks\n\n\nmatriks = np.array(eval(input('Masukkan matriks yang akan dipivotkan: ')))\n\ntriangular_form = PartialPivoting(matriks)\n\nprint(\"Triangular matriksnya adalah :\\n {0}\".format(triangular_form))\n\nMasukkan matriks yang akan dipivotkan: [[51, -18, 21, -96, -93], [84, -69, 69, 67, -6], [-42, 50, 14, -80, 51], [2, 8, 7, 3, 6]]\nTriangular matriksnya adalah :\n [[ 8.40000000e+01 -6.90000000e+01  6.90000000e+01  6.70000000e+01\n  -6.00000000e+00]\n [ 7.10542736e-15  2.38928571e+01 -2.08928571e+01 -1.36678571e+02\n  -8.93571429e+01]\n [-4.60949996e-15  0.00000000e+00  6.20538117e+01  4.21674141e+01\n   1.05968610e+02]\n [-1.84336495e-15  0.00000000e+00  0.00000000e+00  4.71963193e+01\n   1.86585489e+01]]\n\n\nContoh penggunaan langsung (tanpa perlu menerima input):\n\nmatriks_diperbesar = np.array([\n    [51, -18, 21, -96, -93],\n    [84, -69, 69, 67, -6],\n    [-42, 50, 14, -80, 51],\n    [2, 8, 7, 3, 6]\n])\nprint(matriks_diperbesar)\n\nmatriks_triangular = PartialPivoting(matriks_diperbesar)\nprint(matriks_triangular)\n\n# vektor solusi\nprint(SubstitusiBalik(matriks_triangular))\n\n[[ 51 -18  21 -96 -93]\n [ 84 -69  69  67  -6]\n [-42  50  14 -80  51]\n [  2   8   7   3   6]]\n[[ 8.40000000e+01 -6.90000000e+01  6.90000000e+01  6.70000000e+01\n  -6.00000000e+00]\n [ 7.10542736e-15  2.38928571e+01 -2.08928571e+01 -1.36678571e+02\n  -8.93571429e+01]\n [-4.60949996e-15  0.00000000e+00  6.20538117e+01  4.21674141e+01\n   1.05968610e+02]\n [-1.84336495e-15  0.00000000e+00  0.00000000e+00  4.71963193e+01\n   1.86585489e+01]]\n[-1.74956515 -0.22002462  1.4390443   0.39533907]\n\n\n\nmatriks_diperbesar = np.array([\n    [4.0, -1, 0, -1, 0, 0, 0, 0, 0, 25],\n    [-1, 4, -1, 0, -1, 0, 0, 0, 0, 50],\n    [0, -1, 4, 0, 0, -1, 0, 0, 0, 150],\n    [-1, 0, 0, 4, -1, 0, -1, 0, 0, 0],\n    [0, -1, 0, -1, 4, -1, 0, -1, 0, 0],\n    [0, 0, -1, 0, -1, 4, 0, 0, -1, 50],\n    [0, 0, 0, -1, 0, 0, 4, -1, 0, 0],\n    [0, 0, 0, 0, -1, 0, -1, 4, -1, 0],\n    [0, 0, 0, 0, 0, -1, 0, -1, 4, 25]\n])\nprint(matriks_diperbesar)\n\n# langsung print vektor solusi\nprint(SubstitusiBalik(PartialPivoting(matriks_diperbesar)))\n\n[[  4.  -1.   0.  -1.   0.   0.   0.   0.   0.  25.]\n [ -1.   4.  -1.   0.  -1.   0.   0.   0.   0.  50.]\n [  0.  -1.   4.   0.   0.  -1.   0.   0.   0. 150.]\n [ -1.   0.   0.   4.  -1.   0.  -1.   0.   0.   0.]\n [  0.  -1.   0.  -1.   4.  -1.   0.  -1.   0.   0.]\n [  0.   0.  -1.   0.  -1.   4.   0.   0.  -1.  50.]\n [  0.   0.   0.  -1.   0.   0.   4.  -1.   0.   0.]\n [  0.   0.   0.   0.  -1.   0.  -1.   4.  -1.   0.]\n [  0.   0.   0.   0.   0.  -1.   0.  -1.   4.  25.]]\n[18.75 37.5  56.25 12.5  25.   37.5   6.25 12.5  18.75]\n\n\n\n\n6. Scaled Partial Pivoting\nSebelumnya, kita hanya mencari baris dengan nilai terbesar yang berada di bawah elemen diagonal, untuk menghindari kemungkinan elemen diagonal terlalu kecil. Namun, apabila elemen diagonal setelah pertukaran itu menjadi sangat besar, sama saja semua elemen lainnya menjadi relatif sangat kecil, sehingga bisa timbul masalah yang sama.\nOleh karena itu, ada baiknya kita memodifikasi (lagi) syarat pemilihan baris untuk ditukar dengan elemen diagonal, yaitu memilih semacam “pertengahan”, daripada sekedar memilih yang paling besar. Pada scaled partial pivoting, kita\nScaled Partial Pivoting\nDefinisikan\n\\[s_i = \\max_{k \\le i \\le n} |a_{ij}|\\]\nPilih \\(p \\le k\\) terkecil sedemikian sehingga\n\\[\\frac{|a_{pk}^{(k)}|}{s_k} = \\max_{k \\le i \\le n} \\frac{a_{ik}^{(k)}}{s_i}\\]\nKemudian, lakukan operasi \\(\\left( E_k \\right) \\leftrightarrow \\left( E_p \\right)\\)\nImplementasi Scaled Partial Pivoting\n\ndef ScaledPartialPivoting(matriks_input):\n    # konversi matriks_input jadi matriks baru yang isinya float semua,\n    # karena apabila ada bilangan bulat, bisa jadi dilakukan integer division\n    # yang bisa sangat memperparah error\n    matriks = matriks_input.astype(float)\n\n    # memperoleh banyaknya baris pada matriks\n    n = np.shape(matriks)[0]\n\n    # menentukan scalar tiap kolom dibandingan masing-masing baris yang paling besar\n    s = np.array([max(abs(matriks[i,:n])) for i in range(n)])\n\n    # Apabila ada scalar yang nol, semua nilai pada baris tersebut nol,\n    # sehingga SPL tidak bisa diselesaikan\n    if 0 in s:\n        return \"tidak ada solusi unik\"\n    # Kalau bisa diselesaikan, lanjut...\n    for i in range(n-1):\n        below_pivot = abs(matriks[i:,i])/s[i:]\n        pivot_row = np.argmax(below_pivot)\n        if matriks[i,pivot_row+i] == 0:\n            return \"Tidak ada solusi unik\"\n        else:\n            matriks[[pivot_row+i,i], :] = matriks[[i,pivot_row+i],  :]\n            s[pivot_row+i],s[i]=s[i],s[pivot_row+i]\n\n        # lanjut eleminasi Gauss\n        for j in range(i+1,n):\n            m = matriks[j,i]/matriks[i,i]\n            matriks[j] = matriks[j]-m*matriks[i]\n    return matriks\n\n\nmatriks = np.array(eval(input('Masukkan matriks yang akan dipivotkan: ')))\n\ntriangular_form = ScaledPartialPivoting(matriks)\n\nprint(\"Triangular matriksnya adalah :\\n {0}\".format(triangular_form))\n\nMasukkan matriks yang akan dipivotkan: [[51, -18, 21, -96, -93], [84, -69, 69, 67, -6], [-42, 50, 14, -80, 51], [2, 8, 7, 3, 6]]\nTriangular matriksnya adalah :\n [[ 8.40000000e+01 -6.90000000e+01  6.90000000e+01  6.70000000e+01\n  -6.00000000e+00]\n [ 0.00000000e+00  9.64285714e+00  5.35714286e+00  1.40476190e+00\n   6.14285714e+00]\n [ 0.00000000e+00  1.77635684e-15  3.98888889e+01 -4.87580247e+01\n   3.81259259e+01]\n [ 7.10542736e-15  1.52153128e-15  0.00000000e+00 -1.81922748e+02\n  -7.19211699e+01]]\n\n\nContoh penggunaan langsung (tanpa perlu menerima input):\n\nmatriks_diperbesar = np.array([\n    [51, -18, 21, -96, -93],\n    [84, -69, 69, 67, -6],\n    [-42, 50, 14, -80, 51],\n    [2, 8, 7, 3, 6]\n])\nprint(matriks_diperbesar)\n\nmatriks_triangular = ScaledPartialPivoting(matriks_diperbesar)\nprint(matriks_triangular)\n\n# vektor solusi\nprint(SubstitusiBalik(matriks_triangular))\n\n[[ 51 -18  21 -96 -93]\n [ 84 -69  69  67  -6]\n [-42  50  14 -80  51]\n [  2   8   7   3   6]]\n[[ 8.40000000e+01 -6.90000000e+01  6.90000000e+01  6.70000000e+01\n  -6.00000000e+00]\n [ 0.00000000e+00  9.64285714e+00  5.35714286e+00  1.40476190e+00\n   6.14285714e+00]\n [ 0.00000000e+00  1.77635684e-15  3.98888889e+01 -4.87580247e+01\n   3.81259259e+01]\n [ 7.10542736e-15  1.52153128e-15  0.00000000e+00 -1.81922748e+02\n  -7.19211699e+01]]\n[-1.74956515 -0.22002462  1.4390443   0.39533907]\n\n\n\nmatriks_diperbesar = np.array([\n    [4.0, -1, 0, -1, 0, 0, 0, 0, 0, 25],\n    [-1, 4, -1, 0, -1, 0, 0, 0, 0, 50],\n    [0, -1, 4, 0, 0, -1, 0, 0, 0, 150],\n    [-1, 0, 0, 4, -1, 0, -1, 0, 0, 0],\n    [0, -1, 0, -1, 4, -1, 0, -1, 0, 0],\n    [0, 0, -1, 0, -1, 4, 0, 0, -1, 50],\n    [0, 0, 0, -1, 0, 0, 4, -1, 0, 0],\n    [0, 0, 0, 0, -1, 0, -1, 4, -1, 0],\n    [0, 0, 0, 0, 0, -1, 0, -1, 4, 25]\n])\nprint(matriks_diperbesar)\n\n# langsung print vektor solusi\nprint(SubstitusiBalik(ScaledPartialPivoting(matriks_diperbesar)))\n\n[[  4.  -1.   0.  -1.   0.   0.   0.   0.   0.  25.]\n [ -1.   4.  -1.   0.  -1.   0.   0.   0.   0.  50.]\n [  0.  -1.   4.   0.   0.  -1.   0.   0.   0. 150.]\n [ -1.   0.   0.   4.  -1.   0.  -1.   0.   0.   0.]\n [  0.  -1.   0.  -1.   4.  -1.   0.  -1.   0.   0.]\n [  0.   0.  -1.   0.  -1.   4.   0.   0.  -1.  50.]\n [  0.   0.   0.  -1.   0.   0.   4.  -1.   0.   0.]\n [  0.   0.   0.   0.  -1.   0.  -1.   4.  -1.   0.]\n [  0.   0.   0.   0.   0.  -1.   0.  -1.   4.  25.]]\n[18.75 37.5  56.25 12.5  25.   37.5   6.25 12.5  18.75]\n\n\n\n\n7. (Materi pengayaan) Faktorisasi LU\nUntuk mengurangi banyaknya operasi pada penyelesaian SPL dengan matriks (serta untuk beberapa alasan lainnya), faktorisasi matriks seringkali dilakukan. Ada bermacam-macam faktorisasi matriks, namun yang paling umum digunakan adalah faktorisasi LU (juga disebut dekomposisi LU). Pada faktorisasi LU, matriks A ditulis ulang (difaktorisasi) sebagai perkalian (bukan penjumlahan) antara matriks segitiga bawah L (lower triangular) dan matriks segitiga atas U (upper triangular):\n\\[A = LU\\]\nAda tiga metode yang paing sering digunakan untuk faktorisasi LU, yaitu 1. Metode Doolittle 2. Metode Crout 3. Metode Cholesky\nPerbedaan di antara ketiga metode tersebut adalah pada bentuk matriks \\(L\\) dan \\(U\\) yang akan diperoleh, lebih tepatnya pada ketentuan untuk elemen diagonalnya akan seperti apa.\nPada bab 6.5 di buku Burden, dibahas metode Doolittle, di mana faktorisasi LU dilakukan dengan menggunakan eliminasi Gauss (sedangkan metode Cholesky dan metode Crout dibahas di bab 6.6, algoritma 6.6 dan 6.7). Berikut ini, kita hanya membahas metode Doolittle.\nJika eliminasi Gauss dapat dilakukan pada sistem \\(A\\overrightarrow{x}=\\overrightarrow{b}\\) tanpa melakukan pertukaran baris, maka \\(A=LU\\), di mana \\(m_{ji} = \\frac{a_{ji}^{(i)}}{a_{ii}^{(i)}}\\),\n\\(L = \\begin{bmatrix}\n1 & 0 & \\cdots & 0 \\\\\nm_{21} & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nm_{n1} & m_{n2} & \\cdots & 1\n\\end{bmatrix}\\)\n\\(U = \\begin{bmatrix}\na_{11}^{(1)} & a_{12}^{(1)} & \\cdots & a_{1n}^{(1)} \\\\\n0 & a_{22}^{(2)} & \\cdots & a_{2n}^{(2)} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & a_{nn}^{(n)}\n\\end{bmatrix}\\)\n(Fun fact: perhatikan bahwa, untuk metode Doolittle, semua elemen diagonal matriks \\(L\\) adalah 1, sedangkan elemen diagonal matriks \\(U\\) tidak harus satu. Untuk metode Crout, terbalik: semua elemen diagonal matriks \\(U\\) harus 1, sedangkan elemen diagonal matriks \\(L\\) boleh selain 1.)\nImplementasi Faktorisasi LU dengan Metode Doolittle\n\nimport numpy as np\nmatrix = np.array(eval(input('Masukkan matriks yang akan difaktorisasi: ')))\n\ndef LUFactorization(input_matrix):\n    matrix = input_matrix.astype(float)\n\n    n = np.shape(matrix)[0] #mengambil ukuran baris dari matriks\n    L = np.identity(n) #mendefinisikan L sebagai matriks identitas nxn\n    #operasi baris elementer\n    for i in range(n):\n        for j in range(i+1, n):\n            m = matrix[j,i]/matrix[i,i]\n            L[j,i] = m #Pasang elemen L_ji menjadi multiplisitas m = a_ji/a_ii\n            matrix[j]= matrix[j]-m*matrix[i]\n    return (L, matrix)\n\nL = LUFactorization(matrix)[0] #mengambil L pada LUFactorization\nU = LUFactorization(matrix)[1] #mengambil matrix pada LUFactorization\n\nprint(\"faktorisasi LU matriksnya adalah :\")\nprint(\"L = \\n{0}\".format(L)) #print L\n#print U\nprint(\"U = \\n{0}\".format(U))\n\nprint(\"Apabila dikalikan, hasilnya menjadi:\")\nLU = np.matmul(L,U) #Hasil perkalian L dan U\nprint(\"LU = \\n{0}\".format(LU))\n\nMasukkan matriks yang akan difaktorisasi: [[1,2,3],[4,5,6],[7,8,9]]\nfaktorisasi LU matriksnya adalah :\nL = \n[[1. 0. 0.]\n [4. 1. 0.]\n [7. 2. 1.]]\nU = \n[[ 1.  2.  3.]\n [ 0. -3. -6.]\n [ 0.  0.  0.]]\nApabila dikalikan, hasilnya menjadi:\nLU = \n[[1. 2. 3.]\n [4. 5. 6.]\n [7. 8. 9.]]"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-01.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-01.html",
    "title": "Week-01",
    "section": "",
    "text": "Week-01\nKembali ke Persamaan Diferensial Numerik\nFile modul week 1-3:\nModul Praktikum PD Numerik.pdf"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02p2.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02p2.html",
    "title": "Week-02.2 (Metode Euler dan Rungge-Kutta)",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02p2.html#metode-euler",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02p2.html#metode-euler",
    "title": "Week-02.2 (Metode Euler dan Rungge-Kutta)",
    "section": "Metode Euler",
    "text": "Metode Euler\nMetode Euler metode paling dasar dalam mencari solusi dari permasalahan nilai awal dari suatu PD. Metode ini dikembangkan dari Teorema Taylor:\nMetode Euler metode paling dasar dalam mencari solusi dari permasalahan nilai awal dari suatu PD. Metode ini dikembangkan dari Teorema Taylor:\n\\[\ny\\left(t_{i+1}\\right)=y\\left(t_i\\right)+\\left(t_{i+1}-t_I\\right) y^{\\prime}\\left(t_i\\right)+\\cdots\n\\]\nMisalkan kita mempunyai suatu persamaan diferensial dengan nilai awal:\n\\[\n\\begin{gathered}\ny^{\\prime}=f(t, y), a \\leq t \\leq b \\\\\ny(a)=\\alpha\n\\end{gathered}\n\\]\nmaka solusi secara numeriknya adalah \\(w_i= y(t_i)\\), dengan:\n\\[\n\\begin{gathered}\nw_1=\\alpha \\\\\nw_{i+1}=w_i+h f\\left(t_i, w_i\\right), \\quad i=1,2, \\ldots, n\n\\end{gathered}\n\\]\ndengan \\(n+1\\in \\mathbb{N}\\) menyatakan banyaknya titik nantinya.\nSolusi kita akan berupa titik yang nantinya dapat menggunakan interpolasi untuk nilai yang tidak dimuat di \\(w_i\\)\nAlgoritma untuk metode Euler adalah sebagai berikut:\n\nfunction [t, w] = euler(f, a, b, n, alpha)\n  h = (b - a) / n;\n  t = zeros(n + 1, 1);\n  w = zeros(n + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1: n\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    w(i + 1) = w(i) + h * m1;\n  endfor\nendfunction\n\nDisini, inputnya adalah: - \\(\\mathrm{f}=\\mathrm{E}(t, y)\\) merupakan suatu fungsi, - a dan b berturut-turut batas bawah dan batas atas dari \\(t\\) - \\(\\mathrm{n}\\) merupakan pembagi untuk step size dan \\(\\mathrm{n}+1\\) yang digunakan sebagai banyaknya titik, dan - alpha merupakan nilai awal Sekarang akan kita coba gunakan untuk menyelesaikan suatu PD. Misal diberikan PD sebagai berikut: \\[\n\\begin{aligned}\n& y^{\\prime}=y-t^2+1,0 \\leq t \\leq 2 \\\\\n& y(0)=0.5\n\\end{aligned}\n\\]\nmaka kita dapat mendefinisikan f=@(t, y)\\left(y-t^{\\wedge} 2+1\\right), a=0, b=2, dan alpha \\(=0.5\\) (@ disini menyatakan fungsi anonim yang cara kerjanya mirip dengan fungsi lambda pada Python), sehingga untuk \\(n=10\\), diperoleh kode sebagai berikut:\n\nf = @(t, y) (y-t^2 + 1);\na = 0;\nb = 2;\nn = 10;\nalpha= 0.5;\n[t_euler, w_euler] = euler(f, a, b, n, alpha)\n\nUntuk visualisasinya, kita akan membuat plot dari hasil yang kita peroleh. Sebagai referensi, solusi eksak dari PD tersebut adalah \\(y(t)=(t+1)^2- 0.5 e^t\\)\nKita tambahkan kode berikut pada file:$\n\nsln = @(t) (t + 1)^2 - 0.5 * exp(t);\nfplot(sln, [0, 2], 'b');\nhold on;\nscatter(t_euler, w_euler, 'r');\nlegend('Solusi eksak', 'Metode Euler');\ntitle(\"Metode Euler\")\n\nSaat dijalankan, akan muncul jendela pop-up yang berisi plot yang telah dibuat.\n\n\n\ngambar pop up plot\n\n\nPenjelasan: * sln berisi fungsi referensi kita untuk di-plot dan dibandingkan. * fplot(f, [a, b]) akan menampilkan plot dari suatu fungsi f dengan domain [a, b]. Argumen tambahan ‘b’ memberi warna biru pada plot. * hold on akan menahan plot yang ada agar kita bisa menampilkan banyak plot sekaligus. * scatter(x, y) akan menampilkan x-y scatter plot. * legend memberi legenda pada plot yang telah dibuat. Legenda tersebut dimasukkan berurutan mulai dari plot yang didefinsikan terlebih dahulu * title memberi judul pada plot"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02p2.html#metode-runge-kutta-dan-variasinya",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02p2.html#metode-runge-kutta-dan-variasinya",
    "title": "Week-02.2 (Metode Euler dan Rungge-Kutta)",
    "section": "Metode Runge-kutta dan variasinya",
    "text": "Metode Runge-kutta dan variasinya\n\nMetode midpoint \\[\n\\begin{gathered}\nw_1=\\alpha \\\\\nw_{i+1}=w_i+h f\\left(t_i+\\frac{h}{2}, w_i+\\frac{h}{2} f\\left(t_i, w_i\\right)\\right)\n\\end{gathered}\n\\]\nMetode Euler modifikasi \\[\n\\begin{gathered}\nw_1=\\alpha \\\\\nw_{i+1}=w_i+\\frac{h}{2}\\left(f\\left(t_i, w_i\\right)+f\\left(t_{i+1}, w_i+h f\\left(t_i, w_i\\right)\\right)\\right)\n\\end{gathered}\n\\]\nMetode Heun (tidak umum digunakan) \\[\n\\begin{gathered}\nw_1=\\alpha \\\\\nw_{i+1}=w_i+\\frac{h}{4}\\left(f\\left(t_i, w_i\\right)+3 f\\left(t_i+\\frac{2 h}{3}, w_i+\\frac{2 h}{3} f\\left(t_i+\\frac{h}{3}, w_i+\\frac{h}{3} f\\left(t_i, w_i\\right)\\right)\\right)\\right)\n\\end{gathered}\n\\]\nMetode Runge-Kutta orde 4 \\[\n\\begin{aligned}\n& w_1=\\alpha \\\\\n& m_1=h f\\left(t_i, w_i\\right) \\\\\n& m_2=h f\\left(t_i+\\frac{h}{2}, w_i+\\frac{m_1}{2}\\right) \\\\\n& m_3=h f\\left(t_i+\\frac{h}{2}, w_i+\\frac{m_2}{2}\\right) \\\\\n& m_4=h f\\left(t_{i+1}, w_i+m_3\\right) \\\\\n& w_{i+1}=w_i+\\frac{m_1+2 m_2+2 m_3+m_4}{6}\n\\end{aligned}\n\\]\n\nBerikut adalah list algoritmanya.\n\nfunction [t, w] = midpoint(f, a, b, n, alpha)\n  h = (b - a) / n;\n  t = zeros(n + 1, 1);\n  w = zeros(n + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1: n\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    m2 = f(t(i) + (h / 2), w(i) + (h / 2) * m1);\n    w(i + 1) = w(i) + h * m2;\n  endfor\nendfunction\n\n\nfunction [t, w] = modeuler(f, a, b, n, alpha)\n  h = (b - a) / n;\n  t = zeros(n + 1, 1);\n  w = zeros(n + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1: n\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    m2 = f(t(i + 1), w(i) + h * m1);\n    w(i + 1) = w(i) + h * (m1 + m2) / 2;\n  endfor\nendfunction\n\n\nfunction [t, w] = heun(f, a, b, n, alpha)\n  h = (b - a) / n;\n  t = zeros(n + 1, 1);\n  w = zeros(n + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1: n\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    m2 = f(t(i) + (h / 3), w(i) + (h / 3) * m1);\n    m3 = f(t(i) + (2 * h / 3), w(i) + (2 * h / 3) * m2);\n    m4 = m1 + 3 * m3;\n    w(i + 1) = w(i) + (h / 4) * m4;\n  endfor\nendfunction\n\n\nfunction [t, w] = rko4(f, a, b, n, alpha)\n  h = (b - a) / n;\n  t = zeros(n + 1, 1);\n  w = zeros(n + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1: n\n    t(i + 1) = t(i) + h;\n    k1 = h * f(t(i), w(i));\n    k2 = h * f(t(i) + (h / 2), w(i) + (k1 / 2));\n    k3 = h * f(t(i) + (h / 2), w(i) + (k2 / 2));\n    k4 = h * f(t(i + 1), w(i) + k3);\n    w(i + 1) = w(i) + (k1 + 2 * k2 + 2 * k3 + k4) / 6;\n  endfor\nendfunction\n\n\nf = @(t, y) (y - t ^ 2 + 1);\na = 0;\nb = 2;\nalpha = 0.5;\n[t1, w1] = midpoint(f, a, b, 10, alpha);\n[t2, w2] = modeuler(f, a, b, 10, alpha);\n[t3, w3] = heun(f, a, b, 10, alpha);\n[t4, w4] = rko4(f, a, b, 10, alpha);\n\nsln = @(t) (t + 1) ^ 2 - 0.5 * exp(t);\n\nfplot(sln, [0, 2], 'k');\nhold on;\nscatter(t1, w1, 'r');\nscatter(t2, w2, 'g');\nscatter(t3, w3, 'b');\nscatter(t4, w4, 'm');\nlegend('Fungsi eksak', 'Midpoint', 'Modified Euler', 'Heun',\n'Runge-Kutta orde 4');\nlegend(\"location\", \"northwest\");\ntitle('Perbandingan metode Runge-Kutta');\n\n\n\n\ngambar pop up plot"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-04.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-04.html",
    "title": "Week-04 (Sistem Persamaan Diferensial dan Shooting Method)",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\n\n\n\n\nBentuk umum sistem Persamaan Diferensial:\n\\(u'_1 = f_1(t,u_1,u_2,...,u_m)\\)\n\\(u'_2 = f_2(t,u_1,u_2,...,u_m)\\)\n\\(...\\)\n\\(u'_m = f_m(t,u_1,u_2,...,u_m)\\)\ndimana:\n\\(a \\leq t \\leq b\\)\n\\(u_1(a)=a_1, u_2(a)=a_2, ..., u_m(a)=a_m\\) (initial value)\n\n\n\nPada modul ini, akan dibahas mengenai metode Runge-Kutta untuk menyelesaikan sistem persamaan diferensial. Berikut merupakan code dari metode Runge-Kutta untuk sistem persamaan diferensial pada Octave yang perlu disimpan pada function file.\nfunction [t, w1, w2] = rkfs(f1, f2, a, b, n, alph1, alph2)\n  h = (b - a)/n;\n  t = w1 = w2 = [];\n  t(1) = a;\n  w1(1) = alph1;\n  w2(1) = alph2;\n  for i = 1:n\n    k11 = h * f1(t(i), w1(i), w2(i));\n    k12 = h * f2(t(i), w1(i), w2(i));\n\n    k21 = h * f1((t(i)+(h/2)), (w1(i)+(k11/2)), (w2(i)+(k12/2)));\n    k22 = h * f2((t(i)+(h/2)), (w1(i)+(k11/2)), (w2(i)+(k12/2)));\n\n    k31 = h * f1((t(i)+(h/2)), (w1(i)+(k21/2)), (w2(i)+(k22/2)));\n    k32 = h * f2((t(i)+(h/2)), (w1(i)+(k21/2)), (w2(i)+(k22/2)));\n\n    k41 = h * f1((t(i)+h), (w1(i)+k31), (w2(i)+k32));\n    k42 = h * f2((t(i)+h), (w1(i)+k31), (w2(i)+k32));\n\n    w1(i+1) = w1(i) + (k11 + 2*k21 + 2*k31 + k41)/6;\n    w2(i+1) = w2(i) + (k12 + 2*k22 + 2*k32 + k42)/6;\n    t(i+1) = a + i*h;\n  endfor\nendfunction\n\n\n\n\\(u'_1 = -4u_1+3u_2+6, \\;u_1(0)=0\\)\n\\(u'_2 = -2.4u_1+1.6u_2+3.6, \\;u_2(0)=0\\)\nAkan diuji dengan \\(h=0.1\\) dan \\(0\\leq t \\leq 0.5\\)\nSolusi eksak:\n\\(u_1(t)=-3.375e^{-2t}+1.875e^{-0.4t}+1.5\\)\n\\(u_2(t) = -2.25e^{-2t}+2.25e^{-0.4t}\\)\nBerikut adalah code script file untuk menjalankan function metode Runge-Kutta untuk sistem PD di atas:\nf1 = @(t, y1, y2) (-4*y1 + 3*y2 + 6);\nf2 = @(t, y1, y2) (-2.4*y1 + 1.6*y2 + 3.6);\n\na = 0;\nb = 0.5;\nn = 5;\nalph1 = 0;\nalph2 = 0;\n\n[t, w1, w2] = rkfs(f1, f2, a, b, n, alph1, alph2);\n\nsln1 = @(t) (-3.375*exp(-2*t) + 1.875*exp(-0.4*t) + 1.5);\nsln2 = @(t) (-2.25*exp(-2*t) + 2.25*exp(-0.4*t));\n\nw1ex = w2ex = [];\nfor i = 1:length(t)\n  w1ex(i) = sln1(t(i));\n  w2ex(i) = sln2(t(i));\nendfor\n\n[t', w1', w2', w1ex', w2ex']\n\nhold on;\nfplot(sln1, [0, 0.5], 'r');\nfplot(sln2, [0, 0.5], 'b');\nscatter(t, w1, 'r');\nscatter(t, w2, 'b');\nlegend('u1', 'u2');\nlegend('location', 'northwest');\nJika kita run script file tersebut, maka program akan mengeluarkan dua macam output, yaitu tabel serta plot perbandingan solusi eksak dan aproksimasi seperti di bawah ini:\n\n\n\nimage.png\n\n\n\n\n\nimage-3.png\n\n\n\n\n\n\n\n\nLinear Shooting merupakan metode untuk menyelesaikan masalah PD berbentuk:\n\\(-y'' + p(x)y' + q(x)y + r(x) = 0, \\;a\\leq x\\leq b\\)\n\\(y(a)=\\alpha, \\;y(b)=\\beta\\)\n\n\n\nfunction [x_i, w_1i, w_2i] = linshoot(p, q, r, a, b, n, alpha, beta)\n  h = (b - a)/n;\n  u = [alpha ; 0];\n  v = [0 ; 1];\n  x_i = w_1i = w_2i = [];\n  for i = 1:n\n    x = a + (i-1)*h;\n\n    k_11 = h * u(2,i);\n    k_12 = h * (p(x)*u(2,i) + q(x)*u(1,i) + r(x));\n\n    k_21 = h * (u(2,i)+(k_12/2));\n    k_22 = h * (p(x+(h/2))*(u(2,i)+(k_12/2)) + q(x+(h/2))*(u(1,i)+(k_11/2)) + r(x+(h/2)));\n\n    k_31 = h * (u(2,i)+(k_22/2));\n    k_32 = h * (p(x+(h/2))*(u(2,i)+(k_22/2)) + q(x+(h/2))*(u(1,i)+(k_21/2)) + r(x+(h/2)));\n\n    k_41 = h * (u(2,i)+k_32);\n    k_42 = h * (p(x+h)*(u(2,i)+k_32) + q(x+h)*(u(1,i)+k_31) + r(x+h));\n\n    u(1,i+1) = u(1,i) + ((k_11 + 2*k_21 + 2*k_31 + k_41)/6);\n    u(2,i+1) = u(2,i) + ((k_12 + 2*k_22 + 2*k_32 + k_42)/6);\n\n    kp_11 = h * v(2,i);\n    kp_12 = h * (p(x)*v(2,i) + q(x)*v(1,i));\n\n    kp_21 = h * (v(2,i) + (kp_12/2));\n    kp_22 = h * (p(x+(h/2))*(v(2,i)+(kp_12/2)) + q(x+(h/2))*(v(1,i)+(kp_11/2)));\n\n    kp_31 = h * (v(2,i)+(kp_22/2));\n    kp_32 = h * (p(x+(h/2))*(v(2,i)+(kp_22/2)) + q(x+(h/2))*(v(1,i)+(kp_21/2)));\n\n    kp_41 = h * (v(2,i)+kp_32);\n    kp_42 = h * (p(x+h)*(v(2,i)+kp_32) + q(x+h)*(v(1,i)+kp_31));\n\n    v(1,i+1) = v(1,i) + (kp_11 + 2*kp_21 + 2*kp_31 + kp_41)/6;\n    v(2,i+1) = v(2,i) + (kp_12 + 2*kp_22 + 2*kp_32 + kp_42)/6;\n  endfor\n\n  w = [alpha ; ((beta - u(1,(n+1))) / v(1,(n+1)))];\n  x_i(1) = a;\n  w_1i(1) = w(1,1);\n  w_2i(1) = w(2,1);\n\n  for i = 2:(n+1)\n    W1 = u(1,i) + w(2,1)*v(1,i);\n    W2 = u(2,i) + w(2,1)*v(2,i);\n    x = a + (i-1)*h;\n    x_i(i) = x;\n    w_1i(i) = W1;\n    w_2i(i) = W2;\n  endfor\nendfunction\n\n\n\n\\(y'' = -\\frac{2}{x}y' + \\frac{2}{x^2}y + \\frac{\\sin(\\ln(x))}{x^2}, \\; 1\\leq x\\leq 2\\)\n\\(y(1)=1,\\; y(2)=2\\)\ndengan \\(n=10\\)\ndan solusi eksak:\n\\(y=c_1x+\\frac{c_2}{x^2} - \\frac{3}{10}\\sin(\\ln(x))-\\frac{1}{10}cos(\\ln(x))\\)\n\\(c_2 = \\frac{1}{70}(8-12\\sin(\\ln(2)) - 4\\cos(\\ln(2)))\\)\n\\(c_1 = \\frac{11}{10}-c_2\\)\nBerikut code script file untuk permasalahan di atas menggunakan metode linear shooting:\np = @(x) (-2*(x^(-1)));\nq = @(x) (2*(x^(-2)));\nr = @(x) (sin(log(x))*(x^(-2)));\na = 1;\nb = 2;\nalph = 1;\nbet = 2;\n\n[xi, w1i, w2i] = linshoot(p, q, r, a, b, 10, alph, bet);\n\nc2 = (8-12*sin(log(2)) - 4*cos(log(2)))/70;\nc1 = (11/10) - c2;\nsln = @(x) (c1*x + (c2*x^(-2)) - (3/10)*sin(log(x)) - (1/10)*cos(log(x)));\nw = [];\nfor i = 1:length(xi)\n  w(i) = sln(xi(i));\nendfor\n\n[xi', w1i', w']\n\nhold on;\nfplot(sln, [1,2], 'k');\nscatter(xi, w1i, '-r');\nlegend('Eksak', 'Aproksimasi');\nlegend('location', 'northwest');\nJika kita run script file tersebut, maka program akan mengeluarkan dua macam output, yaitu tabel serta plot perbandingan solusi eksak dan aproksimasi seperti di bawah ini:\n\n\n\nimage.png\n\n\n\n\n\nimage-2.png\n\n\n\n\n\n\n\n\nNonlinear Shooting digunakan untuk menyelesaikan masalah PD berbentuk:\n\\(y'' = f(x, y, y'), \\; a\\leq x \\leq b\\)\n\\(y(a)=\\alpha, \\; y(b)=\\beta\\)\ndimana, \\(f\\) merupakan fungsi nonlinear\n\n\n\nfunction [x_i, w_1i, w_2i] = nonlinshoot(f, fy, fyp, a, b, n, alpha, beta, m, tol)  % m adalah maksimum iterasi\n  h = (b - a)/n;\n  k = 1;\n  tk = (beta - alpha)/(b - a);\n  x_i = w_1i = w_2i = [];\n  while k &lt;= m\n    w = [alpha;tk];\n    u = [0,1];\n    for i = 1:n\n      x = a + (i-1)*h;\n\n      k_11 = h*w(2,i);\n      k_12 = h*f(x, w(1,i), w(2,i));\n\n      k_21 = h*(w(2,i)+(k_12/2));\n      k_22 = h*f((x+(h/2)), (w(1,i)+(k_11/2)), (w(2,i)+(k_12/2)));\n\n      k_31 = h*(w(2,i)+(k_22/2));\n      k_32 = h*f((x+(h/2)), (w(1,i)+(k_21/2)), (w(2,i)+(k_22/2)));\n\n      k_41 = h*(w(2,i)+k_32);\n      k_42 = h*f((x+h), (w(1,i)+k_31), (w(2,i)+k_32));\n\n      w(1,i+1) = w(1,i) + ((k_11 + 2*k_21 + 2*k_31 + k_41)/6);\n      w(2,i+1) = w(2,i) + ((k_12 + 2*k_22 + 2*k_32 + k_42)/6);\n\n      kp_11 = h*u(2);\n      kp_12 = h*(fy(x, w(1,i), w(2,i))*u(1) + fyp(x, w(1,i), w(2,i))*u(2));\n\n      kp_21 = h*(u(2) + (kp_12/2));\n      kp_22 = h*(fy((x+(h/2)), w(1,i), w(2,i))*u(1) + fyp((x+(h/2)), w(1,i), w(2,i))*(u(2) + (kp_12/2)));\n\n      kp_31 = h*(u(2)+(kp_22/2));\n      kp_32 = h*(fy((x+(h/2)), w(1,i), w(2,i))*(u(1) + (kp_21/2)) + fyp((x+(h/2)), w(1,i), w(2,i))*(u(2) + (kp_22/2)));\n\n      kp_41 = h*(u(2)+kp_32);\n      kp_42 = h*(fy((x+h), w(1,i), w(2,i))*(u(1)+kp_31) + fyp((x+h), w(1,i), w(2,i))*(u(2) + kp_32));\n\n      u(1) = u(1) + (kp_11 + 2*kp_21 + 2*kp_31 + kp_41)/6;\n      u(2) = u(2) + (kp_12 + 2*kp_22 + 2*kp_32 + kp_42)/6;\n    endfor\n\n  if abs(w(1,n+1) - beta) &lt;= tol       % jika sudah mencapai batas toleransi maka program berhenti\n    for i = 1:(n+1)\n      x = a+(i-1)*h;\n      x_i(i) = x;\n      w_1i(i) = w(1,i);\n      w_2i(i) = w(2,i);\n    endfor\n    return\n  endif\n  tk = tk-((w(1,n+1) - beta)/u(1));\n  k = k + 1;\n  endwhile\n  disp('max iteration')\nendfunction\n\n\n\n\\(y'' = \\frac{1}{8}(32+2x^3-yy'), \\; 1\\leq x \\leq 3\\)\n\\(y(1) = 17, \\; y(3)=43/3\\)\ndengan \\(n=20\\), \\(m=10\\), dan toleransi \\(=10^{-5}\\)\ndan solusi eksak:\n\\(y(x)=x^2 + \\frac{16}{x}\\)\nBerikut code script file untuk permasalahan di atas menggunakan metode linear shooting:\nf = @(x, y, yp) ((1/8)*(32 + 2*x^3 - y*yp));\nfy = @(x, y, yp) (-yp/8);\nfyp = @(x, y, yp) (-y/8);\na = 1;\nb = 3;\nn = 20;\nalph = 17;\nbet = 43/3;\nm = 10;\ntol = 10^(-5);\n\n[xi, w1i, w2i] = nonlinshoot(f, fy, fyp, a, b, n, alph, bet, m, tol);\n\nsln = @(x) ((x^2) + (16/x));\nw = [];\nfor i = 1:length(xi)\n  w(i) = sln(xi(i));\nendfor\n\n[xi', w1i', w']\n\nhold on;\nfplot(sln, [1,3], 'k');\nscatter(xi, w1i, 'r');\nlegend('Eksak', 'Aproksimasi');\nJika kita run script file tersebut, maka program akan mengeluarkan dua macam output, yaitu tabel serta plot perbandingan solusi eksak dan aproksimasi seperti di bawah ini:\n\n\n\nimage.png\n\n\n\n\n\nimage-2.png"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-04.html#sistem-persamaan-diferensial",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-04.html#sistem-persamaan-diferensial",
    "title": "Week-04 (Sistem Persamaan Diferensial dan Shooting Method)",
    "section": "",
    "text": "Bentuk umum sistem Persamaan Diferensial:\n\\(u'_1 = f_1(t,u_1,u_2,...,u_m)\\)\n\\(u'_2 = f_2(t,u_1,u_2,...,u_m)\\)\n\\(...\\)\n\\(u'_m = f_m(t,u_1,u_2,...,u_m)\\)\ndimana:\n\\(a \\leq t \\leq b\\)\n\\(u_1(a)=a_1, u_2(a)=a_2, ..., u_m(a)=a_m\\) (initial value)\n\n\n\nPada modul ini, akan dibahas mengenai metode Runge-Kutta untuk menyelesaikan sistem persamaan diferensial. Berikut merupakan code dari metode Runge-Kutta untuk sistem persamaan diferensial pada Octave yang perlu disimpan pada function file.\nfunction [t, w1, w2] = rkfs(f1, f2, a, b, n, alph1, alph2)\n  h = (b - a)/n;\n  t = w1 = w2 = [];\n  t(1) = a;\n  w1(1) = alph1;\n  w2(1) = alph2;\n  for i = 1:n\n    k11 = h * f1(t(i), w1(i), w2(i));\n    k12 = h * f2(t(i), w1(i), w2(i));\n\n    k21 = h * f1((t(i)+(h/2)), (w1(i)+(k11/2)), (w2(i)+(k12/2)));\n    k22 = h * f2((t(i)+(h/2)), (w1(i)+(k11/2)), (w2(i)+(k12/2)));\n\n    k31 = h * f1((t(i)+(h/2)), (w1(i)+(k21/2)), (w2(i)+(k22/2)));\n    k32 = h * f2((t(i)+(h/2)), (w1(i)+(k21/2)), (w2(i)+(k22/2)));\n\n    k41 = h * f1((t(i)+h), (w1(i)+k31), (w2(i)+k32));\n    k42 = h * f2((t(i)+h), (w1(i)+k31), (w2(i)+k32));\n\n    w1(i+1) = w1(i) + (k11 + 2*k21 + 2*k31 + k41)/6;\n    w2(i+1) = w2(i) + (k12 + 2*k22 + 2*k32 + k42)/6;\n    t(i+1) = a + i*h;\n  endfor\nendfunction\n\n\n\n\\(u'_1 = -4u_1+3u_2+6, \\;u_1(0)=0\\)\n\\(u'_2 = -2.4u_1+1.6u_2+3.6, \\;u_2(0)=0\\)\nAkan diuji dengan \\(h=0.1\\) dan \\(0\\leq t \\leq 0.5\\)\nSolusi eksak:\n\\(u_1(t)=-3.375e^{-2t}+1.875e^{-0.4t}+1.5\\)\n\\(u_2(t) = -2.25e^{-2t}+2.25e^{-0.4t}\\)\nBerikut adalah code script file untuk menjalankan function metode Runge-Kutta untuk sistem PD di atas:\nf1 = @(t, y1, y2) (-4*y1 + 3*y2 + 6);\nf2 = @(t, y1, y2) (-2.4*y1 + 1.6*y2 + 3.6);\n\na = 0;\nb = 0.5;\nn = 5;\nalph1 = 0;\nalph2 = 0;\n\n[t, w1, w2] = rkfs(f1, f2, a, b, n, alph1, alph2);\n\nsln1 = @(t) (-3.375*exp(-2*t) + 1.875*exp(-0.4*t) + 1.5);\nsln2 = @(t) (-2.25*exp(-2*t) + 2.25*exp(-0.4*t));\n\nw1ex = w2ex = [];\nfor i = 1:length(t)\n  w1ex(i) = sln1(t(i));\n  w2ex(i) = sln2(t(i));\nendfor\n\n[t', w1', w2', w1ex', w2ex']\n\nhold on;\nfplot(sln1, [0, 0.5], 'r');\nfplot(sln2, [0, 0.5], 'b');\nscatter(t, w1, 'r');\nscatter(t, w2, 'b');\nlegend('u1', 'u2');\nlegend('location', 'northwest');\nJika kita run script file tersebut, maka program akan mengeluarkan dua macam output, yaitu tabel serta plot perbandingan solusi eksak dan aproksimasi seperti di bawah ini:\n\n\n\nimage.png\n\n\n\n\n\nimage-3.png"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-04.html#linear-shooting-method",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-04.html#linear-shooting-method",
    "title": "Week-04 (Sistem Persamaan Diferensial dan Shooting Method)",
    "section": "",
    "text": "Linear Shooting merupakan metode untuk menyelesaikan masalah PD berbentuk:\n\\(-y'' + p(x)y' + q(x)y + r(x) = 0, \\;a\\leq x\\leq b\\)\n\\(y(a)=\\alpha, \\;y(b)=\\beta\\)\n\n\n\nfunction [x_i, w_1i, w_2i] = linshoot(p, q, r, a, b, n, alpha, beta)\n  h = (b - a)/n;\n  u = [alpha ; 0];\n  v = [0 ; 1];\n  x_i = w_1i = w_2i = [];\n  for i = 1:n\n    x = a + (i-1)*h;\n\n    k_11 = h * u(2,i);\n    k_12 = h * (p(x)*u(2,i) + q(x)*u(1,i) + r(x));\n\n    k_21 = h * (u(2,i)+(k_12/2));\n    k_22 = h * (p(x+(h/2))*(u(2,i)+(k_12/2)) + q(x+(h/2))*(u(1,i)+(k_11/2)) + r(x+(h/2)));\n\n    k_31 = h * (u(2,i)+(k_22/2));\n    k_32 = h * (p(x+(h/2))*(u(2,i)+(k_22/2)) + q(x+(h/2))*(u(1,i)+(k_21/2)) + r(x+(h/2)));\n\n    k_41 = h * (u(2,i)+k_32);\n    k_42 = h * (p(x+h)*(u(2,i)+k_32) + q(x+h)*(u(1,i)+k_31) + r(x+h));\n\n    u(1,i+1) = u(1,i) + ((k_11 + 2*k_21 + 2*k_31 + k_41)/6);\n    u(2,i+1) = u(2,i) + ((k_12 + 2*k_22 + 2*k_32 + k_42)/6);\n\n    kp_11 = h * v(2,i);\n    kp_12 = h * (p(x)*v(2,i) + q(x)*v(1,i));\n\n    kp_21 = h * (v(2,i) + (kp_12/2));\n    kp_22 = h * (p(x+(h/2))*(v(2,i)+(kp_12/2)) + q(x+(h/2))*(v(1,i)+(kp_11/2)));\n\n    kp_31 = h * (v(2,i)+(kp_22/2));\n    kp_32 = h * (p(x+(h/2))*(v(2,i)+(kp_22/2)) + q(x+(h/2))*(v(1,i)+(kp_21/2)));\n\n    kp_41 = h * (v(2,i)+kp_32);\n    kp_42 = h * (p(x+h)*(v(2,i)+kp_32) + q(x+h)*(v(1,i)+kp_31));\n\n    v(1,i+1) = v(1,i) + (kp_11 + 2*kp_21 + 2*kp_31 + kp_41)/6;\n    v(2,i+1) = v(2,i) + (kp_12 + 2*kp_22 + 2*kp_32 + kp_42)/6;\n  endfor\n\n  w = [alpha ; ((beta - u(1,(n+1))) / v(1,(n+1)))];\n  x_i(1) = a;\n  w_1i(1) = w(1,1);\n  w_2i(1) = w(2,1);\n\n  for i = 2:(n+1)\n    W1 = u(1,i) + w(2,1)*v(1,i);\n    W2 = u(2,i) + w(2,1)*v(2,i);\n    x = a + (i-1)*h;\n    x_i(i) = x;\n    w_1i(i) = W1;\n    w_2i(i) = W2;\n  endfor\nendfunction\n\n\n\n\\(y'' = -\\frac{2}{x}y' + \\frac{2}{x^2}y + \\frac{\\sin(\\ln(x))}{x^2}, \\; 1\\leq x\\leq 2\\)\n\\(y(1)=1,\\; y(2)=2\\)\ndengan \\(n=10\\)\ndan solusi eksak:\n\\(y=c_1x+\\frac{c_2}{x^2} - \\frac{3}{10}\\sin(\\ln(x))-\\frac{1}{10}cos(\\ln(x))\\)\n\\(c_2 = \\frac{1}{70}(8-12\\sin(\\ln(2)) - 4\\cos(\\ln(2)))\\)\n\\(c_1 = \\frac{11}{10}-c_2\\)\nBerikut code script file untuk permasalahan di atas menggunakan metode linear shooting:\np = @(x) (-2*(x^(-1)));\nq = @(x) (2*(x^(-2)));\nr = @(x) (sin(log(x))*(x^(-2)));\na = 1;\nb = 2;\nalph = 1;\nbet = 2;\n\n[xi, w1i, w2i] = linshoot(p, q, r, a, b, 10, alph, bet);\n\nc2 = (8-12*sin(log(2)) - 4*cos(log(2)))/70;\nc1 = (11/10) - c2;\nsln = @(x) (c1*x + (c2*x^(-2)) - (3/10)*sin(log(x)) - (1/10)*cos(log(x)));\nw = [];\nfor i = 1:length(xi)\n  w(i) = sln(xi(i));\nendfor\n\n[xi', w1i', w']\n\nhold on;\nfplot(sln, [1,2], 'k');\nscatter(xi, w1i, '-r');\nlegend('Eksak', 'Aproksimasi');\nlegend('location', 'northwest');\nJika kita run script file tersebut, maka program akan mengeluarkan dua macam output, yaitu tabel serta plot perbandingan solusi eksak dan aproksimasi seperti di bawah ini:\n\n\n\nimage.png\n\n\n\n\n\nimage-2.png"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-04.html#nonlinear-shooting-method",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-04.html#nonlinear-shooting-method",
    "title": "Week-04 (Sistem Persamaan Diferensial dan Shooting Method)",
    "section": "",
    "text": "Nonlinear Shooting digunakan untuk menyelesaikan masalah PD berbentuk:\n\\(y'' = f(x, y, y'), \\; a\\leq x \\leq b\\)\n\\(y(a)=\\alpha, \\; y(b)=\\beta\\)\ndimana, \\(f\\) merupakan fungsi nonlinear\n\n\n\nfunction [x_i, w_1i, w_2i] = nonlinshoot(f, fy, fyp, a, b, n, alpha, beta, m, tol)  % m adalah maksimum iterasi\n  h = (b - a)/n;\n  k = 1;\n  tk = (beta - alpha)/(b - a);\n  x_i = w_1i = w_2i = [];\n  while k &lt;= m\n    w = [alpha;tk];\n    u = [0,1];\n    for i = 1:n\n      x = a + (i-1)*h;\n\n      k_11 = h*w(2,i);\n      k_12 = h*f(x, w(1,i), w(2,i));\n\n      k_21 = h*(w(2,i)+(k_12/2));\n      k_22 = h*f((x+(h/2)), (w(1,i)+(k_11/2)), (w(2,i)+(k_12/2)));\n\n      k_31 = h*(w(2,i)+(k_22/2));\n      k_32 = h*f((x+(h/2)), (w(1,i)+(k_21/2)), (w(2,i)+(k_22/2)));\n\n      k_41 = h*(w(2,i)+k_32);\n      k_42 = h*f((x+h), (w(1,i)+k_31), (w(2,i)+k_32));\n\n      w(1,i+1) = w(1,i) + ((k_11 + 2*k_21 + 2*k_31 + k_41)/6);\n      w(2,i+1) = w(2,i) + ((k_12 + 2*k_22 + 2*k_32 + k_42)/6);\n\n      kp_11 = h*u(2);\n      kp_12 = h*(fy(x, w(1,i), w(2,i))*u(1) + fyp(x, w(1,i), w(2,i))*u(2));\n\n      kp_21 = h*(u(2) + (kp_12/2));\n      kp_22 = h*(fy((x+(h/2)), w(1,i), w(2,i))*u(1) + fyp((x+(h/2)), w(1,i), w(2,i))*(u(2) + (kp_12/2)));\n\n      kp_31 = h*(u(2)+(kp_22/2));\n      kp_32 = h*(fy((x+(h/2)), w(1,i), w(2,i))*(u(1) + (kp_21/2)) + fyp((x+(h/2)), w(1,i), w(2,i))*(u(2) + (kp_22/2)));\n\n      kp_41 = h*(u(2)+kp_32);\n      kp_42 = h*(fy((x+h), w(1,i), w(2,i))*(u(1)+kp_31) + fyp((x+h), w(1,i), w(2,i))*(u(2) + kp_32));\n\n      u(1) = u(1) + (kp_11 + 2*kp_21 + 2*kp_31 + kp_41)/6;\n      u(2) = u(2) + (kp_12 + 2*kp_22 + 2*kp_32 + kp_42)/6;\n    endfor\n\n  if abs(w(1,n+1) - beta) &lt;= tol       % jika sudah mencapai batas toleransi maka program berhenti\n    for i = 1:(n+1)\n      x = a+(i-1)*h;\n      x_i(i) = x;\n      w_1i(i) = w(1,i);\n      w_2i(i) = w(2,i);\n    endfor\n    return\n  endif\n  tk = tk-((w(1,n+1) - beta)/u(1));\n  k = k + 1;\n  endwhile\n  disp('max iteration')\nendfunction\n\n\n\n\\(y'' = \\frac{1}{8}(32+2x^3-yy'), \\; 1\\leq x \\leq 3\\)\n\\(y(1) = 17, \\; y(3)=43/3\\)\ndengan \\(n=20\\), \\(m=10\\), dan toleransi \\(=10^{-5}\\)\ndan solusi eksak:\n\\(y(x)=x^2 + \\frac{16}{x}\\)\nBerikut code script file untuk permasalahan di atas menggunakan metode linear shooting:\nf = @(x, y, yp) ((1/8)*(32 + 2*x^3 - y*yp));\nfy = @(x, y, yp) (-yp/8);\nfyp = @(x, y, yp) (-y/8);\na = 1;\nb = 3;\nn = 20;\nalph = 17;\nbet = 43/3;\nm = 10;\ntol = 10^(-5);\n\n[xi, w1i, w2i] = nonlinshoot(f, fy, fyp, a, b, n, alph, bet, m, tol);\n\nsln = @(x) ((x^2) + (16/x));\nw = [];\nfor i = 1:length(xi)\n  w(i) = sln(xi(i));\nendfor\n\n[xi', w1i', w']\n\nhold on;\nfplot(sln, [1,3], 'k');\nscatter(xi, w1i, 'r');\nlegend('Eksak', 'Aproksimasi');\nJika kita run script file tersebut, maka program akan mengeluarkan dua macam output, yaitu tabel serta plot perbandingan solusi eksak dan aproksimasi seperti di bawah ini:\n\n\n\nimage.png\n\n\n\n\n\nimage-2.png"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-06.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-06.html",
    "title": "Week-06 (Skema Beda Hingga)",
    "section": "",
    "text": "Week-06 (Skema Beda Hingga)\nKembali ke Persamaan Diferensial Numerik\n\nModul Skema Beda Hingga I.pdf\nModul Skema Beda Hingga II.pdf\nModul Skema Beda Hingga Transport.pdf"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-01.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-01.html",
    "title": "Tugas Praktikum 1 PD NUMERIK",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\n\n\n\nTugas ini dikerjakan secara individu.\nTerdapat satu (1) soal yang harus dijawab.\nFile yang harus diunggah terdiri dari:\n\n\nbeberapa function file sesuai kebutuhan. Penamaan untuk function file dibebaskan, selama masih relevan dengan isi fungsinya (dilarang menamakan function file “adamsorde5.m” jika isinya adalah metode Runge-Kutta).\nsatu (1) script file untuk jawaban. Penamaannya adalah “soal.m” untuk soal yang diberikan.\nsatu (1) file PDF untuk penjelasan keseluruhan soal. Penjelasan diketik dalam Word atau sejenisnya dengan format penamaan “Penjelasan.pdf”.\n\n\nSemua file disatukan dalam satu file .zip dengan format penamaan:\n\n[Nama][NPM][Kelas SIAK]_Tugas 1_Prak PDNum.zip\nContoh: “Cristiano Ronaldo_2101234567_C_Tugas 1_Prak PDNum.zip”\n\nBatas pengumpulan tugas ini adalah Selasa, 21 Maret 2023, pukul 23.59 WIB.\n\nTugas dikumpulkan melalui gform sesuai dengan kelas masing-masing:\nLink: https://bit.ly/Tugas1PrakPDNum\n*mohon perhatikan waktu pengumpulan yang tertera dan kumpulkan tugas secara tepat waktu.\n\nDilarang melakukan plagiarisme. Jika terdapat mahasisya yang terindikasi melakukan plagiarisme, maka mahasiswa tersebut memperoleh nilai 0 untuk tugas ini.\nApabila ada pertanyaan, harap huibungi CP:\n\nTulus Setiawan (WA/LINE: tlsnew/081213679316) Diberikan suatu initial value problem\n\n\n\n\\[\n\\begin{aligned}\n& y^{\\prime}=\\frac{y^{2}}{1+t}, \\quad 1 \\leq t \\leq 2 \\\\\n& y(1)=-(\\ln 2)^{-1}\n\\end{aligned}\n\\]\nDiketahui solusi eksak dari IVP tersebut adalah:\n\\[\ny(t)=-\\frac{1}{\\ln (t+1)}\n\\]\n\nGunakan tiga metode one-step pilihan Anda untuk mengaproksimasi dan membandingkan solusi dari IVP tersebut menggunakan stepsize \\(h=0.05\\).\nBuatlah grafik perbandingan dari metode tersebut."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-01.html#petunjuk-pengumpulan-tugas",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-01.html#petunjuk-pengumpulan-tugas",
    "title": "Tugas Praktikum 1 PD NUMERIK",
    "section": "",
    "text": "Tugas ini dikerjakan secara individu.\nTerdapat satu (1) soal yang harus dijawab.\nFile yang harus diunggah terdiri dari:\n\n\nbeberapa function file sesuai kebutuhan. Penamaan untuk function file dibebaskan, selama masih relevan dengan isi fungsinya (dilarang menamakan function file “adamsorde5.m” jika isinya adalah metode Runge-Kutta).\nsatu (1) script file untuk jawaban. Penamaannya adalah “soal.m” untuk soal yang diberikan.\nsatu (1) file PDF untuk penjelasan keseluruhan soal. Penjelasan diketik dalam Word atau sejenisnya dengan format penamaan “Penjelasan.pdf”.\n\n\nSemua file disatukan dalam satu file .zip dengan format penamaan:\n\n[Nama][NPM][Kelas SIAK]_Tugas 1_Prak PDNum.zip\nContoh: “Cristiano Ronaldo_2101234567_C_Tugas 1_Prak PDNum.zip”\n\nBatas pengumpulan tugas ini adalah Selasa, 21 Maret 2023, pukul 23.59 WIB.\n\nTugas dikumpulkan melalui gform sesuai dengan kelas masing-masing:\nLink: https://bit.ly/Tugas1PrakPDNum\n*mohon perhatikan waktu pengumpulan yang tertera dan kumpulkan tugas secara tepat waktu.\n\nDilarang melakukan plagiarisme. Jika terdapat mahasisya yang terindikasi melakukan plagiarisme, maka mahasiswa tersebut memperoleh nilai 0 untuk tugas ini.\nApabila ada pertanyaan, harap huibungi CP:\n\nTulus Setiawan (WA/LINE: tlsnew/081213679316) Diberikan suatu initial value problem"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-01.html#soal",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-01.html#soal",
    "title": "Tugas Praktikum 1 PD NUMERIK",
    "section": "",
    "text": "\\[\n\\begin{aligned}\n& y^{\\prime}=\\frac{y^{2}}{1+t}, \\quad 1 \\leq t \\leq 2 \\\\\n& y(1)=-(\\ln 2)^{-1}\n\\end{aligned}\n\\]\nDiketahui solusi eksak dari IVP tersebut adalah:\n\\[\ny(t)=-\\frac{1}{\\ln (t+1)}\n\\]\n\nGunakan tiga metode one-step pilihan Anda untuk mengaproksimasi dan membandingkan solusi dari IVP tersebut menggunakan stepsize \\(h=0.05\\).\nBuatlah grafik perbandingan dari metode tersebut."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-03.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-03.html",
    "title": "Tugas Praktikum 3 PD NUMERIK",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\n\n\n\nTugas ini dikerjakan secara individu.\nTerdapat satu (1) soal yang harus dijawab.\nFile yang harus diunggah terdiri dari:\n\nbeberapa function file sesuai kebutuhan. Penamaan untuk function file dibebaskan, selama masih relevan dengan isi fungsinya (dilarang menamakan function file “adamsorde5.m” jika isinya adalah metode Runge-Kutta).\nsatu (1) script file untuk jawaban. Penamaannya adalah “soal.m” untuk soal yang diberikan.\nsatu (1) file PDF untuk penjelasan keseluruhan soal. Penjelasan diketik dalam Word atau sejenisnya dengan format penamaan “Penjelasan.pdf”.\n\nSemua file disatukan dalam satu file .zip dengan format penamaan:\n\n[Nama]_[NPM]_[Kelas SIAK]_Tugas 1_Prak PDNum.zip\nContoh: “Cristiano-Ronaldo_2101234567_C_Tugas 1_Prak PDNum.zip”\n\nBatas pengumpulan tugas ini adalah 16 April 2023, pukul 23.59 WIB.\n\nTugas dikumpulkan melalui gform sesuai dengan kelas masing-masing:\nLink: ristek.link/Tugas3PrakPDNum\n\nDilarang melakukan plagiarisme. Jika terdapat mahasisya yang terindikasi melakukan plagiarisme, maka mahasiswa tersebut memperoleh nilai 0 untuk tugas ini.\nApabila ada yang ingin ditanyakan anda dapat bertanya pada kolom komentar atau, silakan mengontak salah satu kontak berikut:\n\nLINE: Carles_Octavianus (carles)\n\n\n\n\n\n\n\nUbahlah 2 metode persamaan differential numerik (dapat berupa metode single-step ataupun multi-step) favorit (selain runge-kutta tentunya) menjadi metode yang dapat menyelesaikan sistem persamaan differensial.\ngunakan kedua metode tersebut unutk menyelesaikan persamaan differensial berikut:\n\\(y^{\\prime \\prime}-2 y^{\\prime}+y=t e^t-t, \\quad 0 \\leq t \\leq 1, \\quad y(0)=y^{\\prime}(0)=0\\), dengan \\(h=0.1\\) dengan solusi analitiknya: \\(y(t)=\\frac{1}{6} t^3 e^t-t e^t+2 e^t-t-2\\)\ndan Buatlah grafik perbandingan dari metode tersebut."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-03.html#petunjuk-pengumpulan-tugas",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-03.html#petunjuk-pengumpulan-tugas",
    "title": "Tugas Praktikum 3 PD NUMERIK",
    "section": "",
    "text": "Tugas ini dikerjakan secara individu.\nTerdapat satu (1) soal yang harus dijawab.\nFile yang harus diunggah terdiri dari:\n\nbeberapa function file sesuai kebutuhan. Penamaan untuk function file dibebaskan, selama masih relevan dengan isi fungsinya (dilarang menamakan function file “adamsorde5.m” jika isinya adalah metode Runge-Kutta).\nsatu (1) script file untuk jawaban. Penamaannya adalah “soal.m” untuk soal yang diberikan.\nsatu (1) file PDF untuk penjelasan keseluruhan soal. Penjelasan diketik dalam Word atau sejenisnya dengan format penamaan “Penjelasan.pdf”.\n\nSemua file disatukan dalam satu file .zip dengan format penamaan:\n\n[Nama]_[NPM]_[Kelas SIAK]_Tugas 1_Prak PDNum.zip\nContoh: “Cristiano-Ronaldo_2101234567_C_Tugas 1_Prak PDNum.zip”\n\nBatas pengumpulan tugas ini adalah 16 April 2023, pukul 23.59 WIB.\n\nTugas dikumpulkan melalui gform sesuai dengan kelas masing-masing:\nLink: ristek.link/Tugas3PrakPDNum\n\nDilarang melakukan plagiarisme. Jika terdapat mahasisya yang terindikasi melakukan plagiarisme, maka mahasiswa tersebut memperoleh nilai 0 untuk tugas ini.\nApabila ada yang ingin ditanyakan anda dapat bertanya pada kolom komentar atau, silakan mengontak salah satu kontak berikut:\n\nLINE: Carles_Octavianus (carles)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-03.html#soal",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-03.html#soal",
    "title": "Tugas Praktikum 3 PD NUMERIK",
    "section": "",
    "text": "Ubahlah 2 metode persamaan differential numerik (dapat berupa metode single-step ataupun multi-step) favorit (selain runge-kutta tentunya) menjadi metode yang dapat menyelesaikan sistem persamaan differensial.\ngunakan kedua metode tersebut unutk menyelesaikan persamaan differensial berikut:\n\\(y^{\\prime \\prime}-2 y^{\\prime}+y=t e^t-t, \\quad 0 \\leq t \\leq 1, \\quad y(0)=y^{\\prime}(0)=0\\), dengan \\(h=0.1\\) dengan solusi analitiknya: \\(y(t)=\\frac{1}{6} t^3 e^t-t e^t+2 e^t-t-2\\)\ndan Buatlah grafik perbandingan dari metode tersebut."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/module-tahun-lalu.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/module-tahun-lalu.html",
    "title": "Module 2021/2022",
    "section": "",
    "text": "Module 2021/2022\nKembali ke Sains Data\nberikut ini adalah module pengajaran sains-data tahun 2021/2022. https://drive.google.com/open?id=1x2SR_L3pWH0W8Z0IUbL1ifBOcMSkWVYe"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-02.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-02.html",
    "title": "Week 02 (Data Visualization)",
    "section": "",
    "text": "Kembali ke Sains Data\nPada modul ini kita akan mempelajari beberapa cara untuk membuat visualisasi data menggunakan package Matplotlib dan Seaborn. Seaborn merupakan salah satu package visualisasi data yang sangat sering digunakan karena fleksibilitas dan banyaknya jenis plot yang disediakan.\n\n\n\n\nSebelum memulai, mari kita import terlebih dahulu module - module yang diperlukan.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n\nPada module kali ini, akan digunakan tiga data csv yang berbeda untuk mempermudah kebutuhan visualisasi.\nKetiga data tersebut dapat kalian unduh pada tautan berikut: https://bit.ly/DataWeek2\n\nspotify_df = pd.read_csv('data/week 2/spotify.csv', index_col='Date', parse_dates=['Date'])\nflight_df = pd.read_csv('data/week 2/flight_delays.csv')\ninsurance_df = pd.read_csv('data/week 2/insurance.csv')\n\n\n\n\n\nSeperti yang sudah dipelajari pada Algoritma dan Pemrograman, visualisasi data dapat dilakukan dengan module matplotlib, antara lain untuk membuat line plot dan scatter plot.\nPertama, kita akan menggunakan data Spotify, yaitu data total daily streams 5 lagu hits pada masanya.\n\nspotify_df\n\n\n\n\n\n\n\n\nShape of You\nDespacito\nSomething Just Like This\nHUMBLE.\nUnforgettable\n\n\nDate\n\n\n\n\n\n\n\n\n\n2017-01-06\n12287078\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-07\n13190270\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-08\n13099919\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-09\n14506351\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-10\n14275628\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n\n\n2018-01-05\n4492978\n3450315.0\n2408365.0\n2685857.0\n2869783.0\n\n\n2018-01-06\n4416476\n3394284.0\n2188035.0\n2559044.0\n2743748.0\n\n\n2018-01-07\n4009104\n3020789.0\n1908129.0\n2350985.0\n2441045.0\n\n\n2018-01-08\n4135505\n2755266.0\n2023251.0\n2523265.0\n2622693.0\n\n\n2018-01-09\n4168506\n2791601.0\n2058016.0\n2727678.0\n2627334.0\n\n\n\n\n366 rows × 5 columns\n\n\n\nBerikut adalah cara untuk membuat line plot pada satu fitur di dataframe menggunakan matplotlib\n\n\"\"\"\nMembuat line plot untuk lagu Shape of You menggunakan matplotlib\n\"\"\"\n\n# Mengatur besar figur plot\nplt.subplots(figsize=(8,6))\n\n# Membuat line plot\nplt.plot(spotify_df['Shape of You'], 'b')\n# Membuat label sumbu-x dan sumbu-y\nplt.xlabel('Date')\nplt.ylabel('Shape of You Total Daily Streams')\n# Menampilkan plot\nplt.show()\n\n\n\n\n\n\n\n\nApabila kita ingin menampilkan fitur-fitur lain dalam figur yang sama, kita dapat memanfaatkan loop\n\n\"\"\"\nMembuat line plot untuk semua lagu dalam spotify_df menggunakan loop\n\"\"\"\n\nplt.subplots(figsize=(8,6))\n\n# Loop setiap nama kolom pada dataframe, lalu plot\nfor column in spotify_df.columns:\n    plt.plot(spotify_df[column])\n\nplt.legend(spotify_df.columns)\nplt.show()\n\n\n\n\n\n\n\n\nNamun, terdapat cara yang lebih mudah selain menggunakan looping. pandas dataframe memiliki method yang dapat secara langsung memvisualisasikan keseluruhan fiturnya, yaitu .plot().\nPada .plot() kita memiliki beberapa parameter yang dapat diatur, antara lain kind dan figsize. kind berfungsi untuk mengatur jenis plot yang ingin kita buat, sedangkan figsize berfungsi untuk mengatur besar figur yang dihasilkan.\nParameter lainnya dapat dilihat pada: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n\n\"\"\"\nMembuat line plot untuk semua lagu dalam spotify_df menggunakan pandas .plot()\n\"\"\"\n\nspotify_df.plot(kind='line', figsize=(8,6))\nplt.xlabel('Date')\nplt.ylabel('Total Daily Streams')\nplt.show()\n\n\n\n\n\n\n\n\nSelain line plot, terdapat banyak macam kind yang bisa digunakan. Pada code cell dibawah terlihat bahwa pandas .plot() dapat menghasilkan histogram (perlu diperhatikan bahwa jenis plot perlu menyesuaikan tipe data yang dimiliki, terlihat bahwa menggunakan data spotify, histogram tidak menghasilkan insight yang cukup berguna).\n\nspotify_df.plot(kind='hist', figsize=(8,6), alpha=.7)\n\nplt.show()\n\n\n\n\n\n\n\n\nPada praktikum Algoritma dan Pemrograman kita juga telah mempelajari cara untuk membuat scatter plot. Berikut code untuk membuat scatter plot menggunakan matplotlib, untuk melihat korelasi antara daily streams lagu Shape of You dengan Something Just Like This.\n\n\"\"\"\nMembuat scatter plot untuk melihat korelasi antara lagu\nShape of You dengan Something Just Like This menggunakan\nmatplotlib\n\"\"\"\n\nplt.subplots(figsize=(8,6))\n\nplt.scatter(x=spotify_df['Shape of You'], \n            y=spotify_df['Something Just Like This'],\n            alpha=.5)\nplt.xlabel('\"Shape of You\" Total Daily Streams')\nplt.ylabel('\"Something Just Like This\" Total Daily Streams')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nWalaupun matplotlib cukup fleksibel dalam menghasilkan plot, tetapi tipe plot yang disediakan cenderung terbatas. Oleh karena itu, kita dapat menggunakan Seaborn karena tipe plot yang disediakan sangat banyak sesuai kebutuhan kita, antara lain line, bar, heatmap, scatter, box, swarm, histogram, density, dan masih banyak lagi.\n\n\nLine plot biasa digunakan untuk melihat trend data dalam jangka waktu tertentu.\nUntuk membuat line plot pada seaborn, kita dapat menggunakan sns.lineplot(). Jika data yang ingin kita visualisasikan adalah dataframe, kita dapat memasukkan variabel dataframe tersebut pada parameter data, seperti code di bawah ini.\n\n\"\"\"\nMembuat line plot dengan module seaborn\n\"\"\"\n\nplt.subplots(figsize=(8,6))\nsns.lineplot(data=spotify_df)\nplt.show()\n\n\n\n\n\n\n\n\nFleksibilitas Seaborn membuat kita dapat memilih color palette yang sesuai dengan keinginan kita. Kita dapat memilih palette yang sudah disediakan oleh seaborn (antara lain: bright, deep, pastel, dan masih banyak lagi) atau kita dapat mengatur sendiri palette yang ingin kita gunakan.\nUntuk memilih palette yang akan digunakan untuk plot selanjutnya pada seaborn, kita dapat menggunakan sns.set_palette().\nJenis palette yang disediakan seaborn serta cara membuat color palette secara mandiri dapat dilihat pada: https://seaborn.pydata.org/tutorial/color_palettes.html#tools-for-choosing-color-palettes\n\n# Mengganti color palette menjadi \"bright\"\nsns.set_palette('bright')\n\n\n\"\"\"\nMembuat line plot setelah color palette diubah menjadi \"bright\"\n\"\"\"\n\n# Mengatur besar figur yang ingin ditampilkan\nplt.figure(figsize=(14,6))\n\n# Membuat line plot\nsns.lineplot(data=spotify_df)\n# Membuat judul figur\nplt.title(\"Daily Global Streams of Popular Songs in 2017-2018\")\n# Menampilkan plot\nplt.show()\n\n\n\n\n\n\n\n\nApabila tidak semua fitur pada data ingin kita visualisasikan, kita dapat menggunakan sns.lineplot() beberapa kali, sesuai dengan banyaknya fitur yang ingin kita tampilkan, seperti pada code di bawah.\n\nplt.figure(figsize=(14,6))\n\n# Membuat line plot hanya dengan lagu Shape of You\nsns.lineplot(data=spotify_df['Shape of You'], label=\"Shape of You\")\n# Menambahkan line plot pada figur dengan lagu Despacito\nsns.lineplot(data=spotify_df['Despacito'], label=\"Despacito\")\n\nplt.title(\"Daily Global Streams of Popular Songs in 2017-2018\")\nplt.xlabel(\"Date\")\nplt.ylabel('')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nBar plot biasa digunakan untuk membandingkan kuantitas/nilai pada data bertipe kategori.\nSelanjutnya, kita akan menggunakan data flight_delays.csv, yaitu data rata-rata keterlambatan beberapa maskapai pesawat pada setiap bulannya.\n\nflight_df\n\n\n\n\n\n\n\n\nMonth\nAA\nAS\nB6\nDL\nEV\nF9\nHA\nMQ\nNK\nOO\nUA\nUS\nVX\nWN\n\n\n\n\n0\n1\n6.955843\n-0.320888\n7.347281\n-2.043847\n8.537497\n18.357238\n3.512640\n18.164974\n11.398054\n10.889894\n6.352729\n3.107457\n1.420702\n3.389466\n\n\n1\n2\n7.530204\n-0.782923\n18.657673\n5.614745\n10.417236\n27.424179\n6.029967\n21.301627\n16.474466\n9.588895\n7.260662\n7.114455\n7.784410\n3.501363\n\n\n2\n3\n6.693587\n-0.544731\n10.741317\n2.077965\n6.730101\n20.074855\n3.468383\n11.018418\n10.039118\n3.181693\n4.892212\n3.330787\n5.348207\n3.263341\n\n\n3\n4\n4.931778\n-3.009003\n2.780105\n0.083343\n4.821253\n12.640440\n0.011022\n5.131228\n8.766224\n3.223796\n4.376092\n2.660290\n0.995507\n2.996399\n\n\n4\n5\n5.173878\n-1.716398\n-0.709019\n0.149333\n7.724290\n13.007554\n0.826426\n5.466790\n22.397347\n4.141162\n6.827695\n0.681605\n7.102021\n5.680777\n\n\n5\n6\n8.191017\n-0.220621\n5.047155\n4.419594\n13.952793\n19.712951\n0.882786\n9.639323\n35.561501\n8.338477\n16.932663\n5.766296\n5.779415\n10.743462\n\n\n6\n7\n3.870440\n0.377408\n5.841454\n1.204862\n6.926421\n14.464543\n2.001586\n3.980289\n14.352382\n6.790333\n10.262551\nNaN\n7.135773\n10.504942\n\n\n7\n8\n3.193907\n2.503899\n9.280950\n0.653114\n5.154422\n9.175737\n7.448029\n1.896565\n20.519018\n5.606689\n5.014041\nNaN\n5.106221\n5.532108\n\n\n8\n9\n-1.432732\n-1.813800\n3.539154\n-3.703377\n0.851062\n0.978460\n3.696915\n-2.167268\n8.000101\n1.530896\n-1.794265\nNaN\n0.070998\n-1.336260\n\n\n9\n10\n-0.580930\n-2.993617\n3.676787\n-5.011516\n2.303760\n0.082127\n0.467074\n-3.735054\n6.810736\n1.750897\n-2.456542\nNaN\n2.254278\n-0.688851\n\n\n10\n11\n0.772630\n-1.916516\n1.418299\n-3.175414\n4.415930\n11.164527\n-2.719894\n0.220061\n7.543881\n4.925548\n0.281064\nNaN\n0.116370\n0.995684\n\n\n11\n12\n4.149684\n-1.846681\n13.839290\n2.504595\n6.685176\n9.346221\n-1.706475\n0.662486\n12.733123\n10.947612\n7.012079\nNaN\n13.498720\n6.720893\n\n\n\n\n\n\n\nUntuk membuat bar plot pada seaborn dengan dataframe, kita dapat menggunakan sns.barplot() dengan tiga parameter yang wajib kita set, yaitu:\n- data: dataframe yang ingin kita visualisasikan\n\n- x: nama fitur pada dataframe yang ingin kita jadikan sumbu-x\n\n- y: nama fitur pada dataframe yang ingin kita jadikan sumbu-y\nPada kode di bawah, juga digunakan satu parameter opsional, yaitu palette yang merupakan cara lain untuk mengatur color palette yang ingin kita gunakan\n\n\"\"\"\nMembuat bar plot keterlambatan maskapai EV setiap \nbulannya menggunakan seaborn\n\"\"\"\n\nplt.figure(figsize=(14,6))\n\nsns.barplot(data=flight_df, x='Month', y='EV',\n            palette=sns.color_palette('deep'))\nplt.ylabel('EV Flight Delays (minute)')\nplt.title('Average EV Flight Delays per Month')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan hasil plot di atas, terlihat bahwa maskapai EV memiliki rata-rata keterlambatan terlama pada bulan Juni, serta tercepat pada bulan September.\nSelanjutnya, mari kita coba lihat urutan rata-rata keterlambatan semua maskapai dalam satu tahun (maskapai mana yang memiliki rata-rata keterlambatan terlama, serta maskapai mana yang tercepat).\nHal pertama yang perlu kita lakukan adalah, jadikan fitur Month sebagai index dataframe.\n\n# Set fitur \"Month\" menjadi index dataframe\nflight_df = flight_df.set_index('Month')\nflight_df.head(2)\n\n\n\n\n\n\n\n\nAA\nAS\nB6\nDL\nEV\nF9\nHA\nMQ\nNK\nOO\nUA\nUS\nVX\nWN\n\n\nMonth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n6.955843\n-0.320888\n7.347281\n-2.043847\n8.537497\n18.357238\n3.512640\n18.164974\n11.398054\n10.889894\n6.352729\n3.107457\n1.420702\n3.389466\n\n\n2\n7.530204\n-0.782923\n18.657673\n5.614745\n10.417236\n27.424179\n6.029967\n21.301627\n16.474466\n9.588895\n7.260662\n7.114455\n7.784410\n3.501363\n\n\n\n\n\n\n\nSelanjutnya, kita perlu hitung rata-rata keterlambatan tiap maskapai dalam satu tahun, yaitu hitung rata-rata tiap kolom pada dataframe menggunakan .mean() (Tambahan: apabila kita ingin menghitung rata-rata tiap barisnya, kita dapat menggunakan parameter axis=1 pada .mean()). .mean() akan menghasilkan pandas Series.\nLalu, agar mempermudah kita dalam melihat visualisasi bar plotnya, kita dapat menggunakan .sort_values().\n\n# Simpan rata-rata keterlambatan semua maskapai dalam satu tahun pada variabel flight_mean_inyear\nflight_mean_inyear = flight_df.mean()\n# Urutkan flight_mean_inyear secara ascending\nflight_mean_inyear = flight_mean_inyear.sort_values()\n\nflight_mean_inyear\n\nAS    -1.023656\nDL     0.231116\nHA     1.993205\nUS     3.776815\nAA     4.120776\nWN     4.275277\nVX     4.717718\nUA     5.413415\nOO     5.909658\nMQ     5.964953\nEV     6.543328\nB6     6.788370\nF9    13.035736\nNK    14.549663\ndtype: float64\n\n\nTerakhir, visualisasikan bar plot menggunakan cara seperti sebelumnya.\nKita dapat lihat pada code dibawah bahwa tidak digunakan parameter data, karena flight_mean_inyear merupakan pandas Series (bukan dataframe) sehingga lebih mudah jika kita langsung menggunakan parameter x dan y saja.\n\nplt.subplots(figsize=(14,6))\nsns.barplot(x=flight_mean_inyear.index, \n            y=flight_mean_inyear.values,\n            palette=sns.color_palette('deep'))\nplt.title('Average Delay per Flight in a Year')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan plot diatas, NK merupakan maskapai dengan rata-rata keterlambatan terlama dalam satu tahun, sedangkan AS adalah yang tercepat (AS bernilai negatif yang berarti rata-rata kedatangan pesawat lebih cepat dari yang dijadwalkan dalam satu tahun.\n\n\n\nHeatmap biasa digunakan untuk mempermudah melihat pola pada data berdasarkan warna yang dihasilkan.\nPada seaborn, kita dapat menggunakan heatmap dengan sns.heatmap() seperti pada kode dibawah. Parameter annot berfungsi untuk menampilkan nilai data (jika True) atau tidak (jika False).\nBar sebelah kanan heatmap menunjukkan bahwa, semakin lama keterlambatan pesawat, maka warna yang dihasilkan semakin terang. Sebaliknya, semakin gelap warna yang dihasilkan berarti semakin cepat pesawat datang tersebut.\n\n\"\"\"\nMembuat heatmap menggunakan Seaborn\n\"\"\"\nplt.figure(figsize=(14,10))\n\nsns.heatmap(data=flight_df, annot=True)\nplt.title(\"Average Arrival Delay for Each Airline, by Month\")\nplt.xlabel(\"Airline\")\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan heatmap di atas, kita dapat melihat dengan mudah pada bulan apa suatu maskapai sangat terlambat (contoh: maskapai NK pada bulan Juni).\nHeatmap sangat sering digunakan untuk melihat korelasi antarfitur pada dataset agar kita dapat mengerti lebih jauh tentang fitur-fitur pada data, atau juga dapat dimanfaatkan untuk melakukan feature selection sebelum membuat sebuat model Machine Learning.\nUntuk melakukan hal tersebut, kita perlu menghitung dahulu korelasi antar fitur menggunakan pandas .corr(), yaitu fungsi yang akan menghitung korelasi antar dua fitur menggunakan korelasi Pearson.\nNotes: Metode korelasi dapat diubah dengan menggunakan parameter method pada .corr(), contoh: .corr(method='spearman'). Metode lainnya dapat dilihat pada: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\n\n# Hitung korelasi antar dua fitur pada flight_df\nflight_corr = flight_df.corr()\n\nflight_corr\n\n\n\n\n\n\n\n\nAA\nAS\nB6\nDL\nEV\nF9\nHA\nMQ\nNK\nOO\nUA\nUS\nVX\nWN\n\n\n\n\nAA\n1.000000\n0.334980\n0.429854\n0.805229\n0.896523\n0.903986\n0.220065\n0.842701\n0.573716\n0.620477\n0.809874\n0.823713\n0.425237\n0.615664\n\n\nAS\n0.334980\n1.000000\n0.340359\n0.394359\n0.356608\n0.336791\n0.684979\n0.283977\n0.480863\n0.350657\n0.457414\n0.489025\n0.229571\n0.519228\n\n\nB6\n0.429854\n0.340359\n1.000000\n0.643313\n0.342627\n0.510718\n0.467905\n0.529724\n0.032038\n0.591115\n0.233021\n0.788345\n0.579750\n0.151750\n\n\nDL\n0.805229\n0.394359\n0.643313\n1.000000\n0.796951\n0.783265\n0.262251\n0.598765\n0.625277\n0.569073\n0.797339\n0.821757\n0.700605\n0.691805\n\n\nEV\n0.896523\n0.356608\n0.342627\n0.796951\n1.000000\n0.828515\n0.099369\n0.721468\n0.784026\n0.692697\n0.911499\n0.669736\n0.462638\n0.730115\n\n\nF9\n0.903986\n0.336791\n0.510718\n0.783265\n0.828515\n1.000000\n0.273878\n0.912984\n0.414064\n0.582509\n0.671986\n0.878874\n0.308397\n0.465765\n\n\nHA\n0.220065\n0.684979\n0.467905\n0.262251\n0.099369\n0.273878\n1.000000\n0.436015\n0.176485\n0.056941\n0.066821\n0.586160\n-0.008439\n-0.007296\n\n\nMQ\n0.842701\n0.283977\n0.529724\n0.598765\n0.721468\n0.912984\n0.436015\n1.000000\n0.281890\n0.586963\n0.503575\n0.660181\n0.150111\n0.239744\n\n\nNK\n0.573716\n0.480863\n0.032038\n0.625277\n0.784026\n0.414064\n0.176485\n0.281890\n1.000000\n0.365273\n0.827455\n0.293515\n0.395419\n0.742869\n\n\nOO\n0.620477\n0.350657\n0.591115\n0.569073\n0.692697\n0.582509\n0.056941\n0.586963\n0.365273\n1.000000\n0.626051\n0.590313\n0.561515\n0.548304\n\n\nUA\n0.809874\n0.457414\n0.233021\n0.797339\n0.911499\n0.671986\n0.066821\n0.503575\n0.827455\n0.626051\n1.000000\n0.477816\n0.536968\n0.926800\n\n\nUS\n0.823713\n0.489025\n0.788345\n0.821757\n0.669736\n0.878874\n0.586160\n0.660181\n0.293515\n0.590313\n0.477816\n1.000000\n0.333396\n0.242344\n\n\nVX\n0.425237\n0.229571\n0.579750\n0.700605\n0.462638\n0.308397\n-0.008439\n0.150111\n0.395419\n0.561515\n0.536968\n0.333396\n1.000000\n0.630278\n\n\nWN\n0.615664\n0.519228\n0.151750\n0.691805\n0.730115\n0.465765\n-0.007296\n0.239744\n0.742869\n0.548304\n0.926800\n0.242344\n0.630278\n1.000000\n\n\n\n\n\n\n\nPandas .corr() menghasilkan dataframe dengan nama baris dan kolom yang sama, serta berisi nilai korelasi antara baris dan kolom yang ditinjau (contoh: korelasi antara maskapai AA dan AS adalah 0,334980). Serta, dataframe yang dihasilkan adalah sebuat matriks simetris.\nTentu dengan hanya melihat dataframe di atas, tidak terlihat begitu jelas mana fitur yang memiliki korelasi tinggi dan mana yang yang memiliki korelasi rendah. Oleh karena itu, kita dapat memanfaatkan heatmap.\nPada code di bawah, untuk mempermudah pembacaan heatmap, kita menggunakan parameter vmin, vmax, dan center pada sns.heatmap(). vmin berfungsi untuk mengatur nilai terendah, vmax berfungsi untuk mengatur nilai tertinggi, dan center berfungsi untuk mengatur nilai tengah pada heatmap. Korelasi Pearson menghasilkan nilai antara -1 hingga 1, sehingga kita dapat set ketiga parameter tersebut seperti pada code di bawah.\n\nplt.figure(figsize=(14,10))\n\nsns.heatmap(data=flight_corr, vmin=-1, vmax=1, center=0, annot=True)\nplt.title(\"Pearson Correlation of Each Airline Flight Delays\")\nplt.xlabel(\"Airline\")\nplt.show()\n\n\n\n\n\n\n\n\nDengan menggunakan heatmap, sekarang terlihat bahwa mana maskapai yang keterlambatannya berkorelasi tinggi dan mana yang rendah. Misal, AA dan EV menghasilkan korelasi yang cukup tinggi positif, yaitu 0.9, yang artinya jika keterlambatan maskapai AA tinggi, begitu juga maskapai EV, dan sebaliknya jika keterlambatan maskapai AA rendah, begitu juga maskapai EV.\nUntuk meyakinkan kita dengan hal tersebut, kita dapat lihat pada materi selanjutnya, yaitu Scatter Plot.\n\n\n\nScatter plot biasa digunakan untuk melihat korelasi antara dua fitur bertipe numerik.\nUntuk menggunakan scatter plot pada seaborn, kita dapat menggunakan sns.scatterplot(), dengan parameter yang sama seperti kita membuat bar plot.\n\n\"\"\"\nMembuat scatter plot untuk melihat \nketerkaitan pada keterlambatan pesawat\nmaskapai EV dan AA\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='EV', y='AA')\nplt.show()\n\n\n\n\n\n\n\n\nMelalui scatter plot di atas, kita dapat semakin yakin bahwa kesimpulan yang kita ambil dengan melihat heatmap sebelumnya benar.\n\n\"\"\"\nTambahan scatter plot pada maskapai lain yang\nmemiliki korelasi tinggi\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='EV', y='UA')\nplt.show()\n\n\n\n\n\n\n\n\n\n\"\"\"\nScatter plot pada maskapai yang memiliki\nkorelasi rendah (mendekati 0)\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='UA', y='HA')\nplt.show()\n\n\n\n\n\n\n\n\nPada heatmap, terlihat bahwa maskapai UA dan HA memiliki korelasi yang rendah, yaitu 0.067. Sehingga, jika kita buat scatter plotnya, menghasilkan plot seperti di atas.\nUntuk memahami scatter plot lebih baik, kita akan menggunakan dataset lainnya, yaitu insurance.csv yang merupakan data berisi biaya asuransi (charges) beberapa orang.\n\ninsurance_df.head()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n\n\n\n\n\n\n\nMisal, kita ingin melihat keterkaitan indeks massa tubuh (bmi) seseorang dengan biaya asuransi (charges) orang tersebut. Sama seperti sebelumnya, kita dapat melakukannya seperti pada code di bawah.\n\n# Mengubah palette menjadi default\nsns.set_palette('tab10')\n# Membuat scatter plot antara fitur bmi dan charges\nsns.scatterplot(data=insurance_df, x='bmi', y='charges')\n\nplt.show()\n\n\n\n\n\n\n\n\nScatter plot di atas menunjukkan bahwa korelasi antara bmi dan charges adalah cenderung positif, tetapi tidak terlalu tinggi. Yang artinya, orang dengan BMI tinggi, cenderung akan membayar biaya asuransi lebih tinggi.\nAgar kita semakin yakin dengan kesimpulan tersebut, kita dapat menambahakn garis regresi pada scatter plot tersebut dengan menggunakan sns.regplot().\n\nsns.regplot(data=insurance_df, x='bmi', y='charges')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan scatter plot dan garis regresi dihasilkan, terlihat bahwa kesimpulan yang kita ambil benar. Agar semakin yakin lagi, kita juga dapat menghitung langsung korelasi Pearsonnya menggunakan cara sebelumnya, yaitu pandas .corr().\n\ninsurance_df[['bmi', 'charges']].corr()\n\n\n\n\n\n\n\n\nbmi\ncharges\n\n\n\n\nbmi\n1.000000\n0.198341\n\n\ncharges\n0.198341\n1.000000\n\n\n\n\n\n\n\nDengan menggunakan seaborn, kita juga dapat memvisualisasikan scatter plot berdasarkan dengan pewarnaan yang berbeda berdasarkan fitur lainnya yang bertipe kategorik.\nMisal, kita ingin membuat scatter plot antara fitur bmi dan charges dengan pewarnaannya berdasarkan nilai dari fitur smoker, yaitu yes atau no. Kita dapat set parameter hue='smoker' pada sns.scatterplot() seperti pada code di bawah.\n\nsns.scatterplot(data=insurance_df, x='bmi', y='charges', hue='smoker')\nplt.show()\n\n\n\n\n\n\n\n\nSehingga dihasilkan pewarnaan yang berbeda untuk seseorang yang merupakan perokok (biru) dan yang tidak (orange). Berdasarkan scatter plot di atas, terlihat bahwa korelasi antara bmi dan charges untuk perokok cendering tinggi positif (semakin besar bmi, semakin besar juga charges). Sedangkan, untuk bukan perokok, korelasinya cenderung rendah (semakin besar bmi, tidak terlalu berpengaruh terhadap charges).\nSeperti cara sebelumnya, kita dapat menambahkan garis regresi. Namun, karena kita disini menggunakan hue, terdapat dua cara untuk menambahkan garis regresi, yaitu yang pertama adalah menggunakan sns.regplot() seperti di bawah ini.\n\nsns.regplot(data=insurance_df.query('smoker == \"yes\"'), x='bmi', y='charges') # axes 1\nsns.regplot(data=insurance_df.query('smoker == \"no\"'), x='bmi', y='charges') # axes 2\nplt.show()\n\n\n\n\n\n\n\n\nPerhatikan bahwa sns.regplot() dipanggil dua kali karena fungsi tersebut tidak memiliki parameter hue.\nUntuk mempermudah, kita dapat menggunakan cara kedua, yaitu menggunakan sns.lmplot(). Cara kerja sns.lmplot() yaitu menggabungkan dua (atau lebih) sns.regplot() dalam satu figur.\n\nsns.lmplot(data=insurance_df, x='bmi', y='charges', hue='smoker')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nBox plot dan swarm plot biasa digunakan untuk melihat keterkaitan antara data kategorik dan data numerik. Swarm plot biasa disebut sebagai “categorical scatter plot”, karena plot yang dihasilkan mirip seperti scatter plot, tetapi untuk data kategorik.\nUntuk menggunakan box plot pada seaborn kita dapat menggunakan sns.boxplot().\nUntuk menggunakan swarm plot pada seaborn kita dapat menggunakan sns.swarmplot().\nMisal, kita ingin melihat keterkaitan antara fitur smoker dan charges menggunakan swarm plot. Maka, kita dapat menggunakan code seperti di bawah ini.\n\nplt.subplots(figsize=(10,6))\n\nsns.swarmplot(data=insurance_df, x='smoker', y='charges', size=3)\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan swarm plot di atas, terlihat bahwa perokok cenderung memiliki biaya asuransi yang lebih tinggi dibandingkan yang bukan perokok. Selain itu, semakin lebar “swarm” pada suatu kategori berarti semakin banyak seseorang dengan nilai charges tersebut.\nApabila kita ingin menggunakan box plot, maka dapat digunakan code seperti di bawah ini.\n\nsns.boxplot(data=insurance_df, x='smoker', y='charges')\nplt.show()\n\n\n\n\n\n\n\n\nPada box plot, terdapat dua istilah yang umum digunakan, yaitu “box” dan “whiskers”. Pada box plot di atas, “box” merupakan persegi panjang berwarna biru dan orange. Garis di tengah box merupakan nilai mediannya, serta garis bawah dan garis atas box merupakan kuartil bawah (Q1) dan kuartil atas (Q3) secara berurutan. “Whiskers” adalah garis yang merupakan perpanjangan dari box. Ujung dari whiskers atas adalah Q3 + (1.5 x IQR) data, sedangkan ujung whiskers bawah adalah Q1 - (1.5 x IQR) data.\nTitik di luar box dan whiskers tersebut adalah titik yang biasa dijadikan sebagai outlier (penentuan outlier diserahkan ke diri masing-masing, apakah hanya dengan melihat box plot atau dengan menggunakan metode lain, tetapi untuk mempermudah dapat menggunakan box plot).\n\n\n\nSelain box plot dan swarm plot, kita juga dapat melihat persebaran data menggunakan histogram dan density plot. Histogram biasa digunakan untuk melihat persebaran data secara diskrit, sedangkan density plot untuk melihat persebaran data secara kontinu.\nUntuk membuat histogram pada seaborn, kita dapat menggunakan sns.histplot().\nUntuk membuat density plot pada seaborn, kita dapat menggunakan sns.kdeplot().\nMisal, kita ingin melihat persebaran dari fitur charges pada insurance_df. Maka dapat digunakan code seperti di bawah.\n\nplt.subplots(figsize=(12,6))\n\nsns.histplot(data=insurance_df, x='charges')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan histogram di atas, terlihat bahwa distribusi charges cenderung “skew” atau miring ke kanan. “Skewness” atau tingkat kecondongan merupakan aspek yang penting untuk diperhatikan ketika kita ingin membuat model Machine Learning.\nSeperti scatter plot, kita juga dapat menentukan pewarnaan histogram berdasarkan fitur lainnya dengan menggunakan parameter hue seperti di bawah ini/\n\nplt.subplots(figsize=(12,6))\nsns.histplot(data=insurance_df, x='charges', hue='smoker')\nplt.show()\n\n\n\n\n\n\n\n\nJika ingin membuat density plot dari fitur charges, kita dapat menggunakan kode seperti di bawah ini. Parameter shade berfungsi untuk memberikan warna di bawah kurva.\n\nplt.subplots(figsize=(12,6))\nsns.kdeplot(data=insurance_df, x='charges', shade=True)\nplt.show()\n\n\n\n\n\n\n\n\nsns.kdeplot() juga dapat menggunakan parameter hue.\n\nplt.subplots(figsize=(12,6))\nsns.kdeplot(data=insurance_df, x='charges',\n            hue='smoker', shade=True)\nplt.show()\n\n\n\n\n\n\n\n\nApabila kita ingin menggabungkan histogram dan density plot dalam satu figur, kita dapat menggunakan sns.histplot() dengan parameter kde=True.\n\nplt.subplots(figsize=(12,6))\nsns.histplot(data=insurance_df, x='charges', hue='smoker', kde=True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPada seaborn, kita juga dapat membuat dua plot yang berbeda dari dua fitur dalam satu figur yang sama menggunakan sns.jointplot().\nJenis plot yang dihasilkan dapat diatur pada parameter kind. Pilihan jenis kind yang disediakan dapat dilihat pada: https://seaborn.pydata.org/generated/seaborn.jointplot.html\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"scatter\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"hist\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"kde\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimage.png\n\n\nsource: https://www.kaggle.com/code/alexisbcook/choosing-plot-types-and-custom-styles"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-02.html#prerequisites",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-02.html#prerequisites",
    "title": "Week 02 (Data Visualization)",
    "section": "",
    "text": "Sebelum memulai, mari kita import terlebih dahulu module - module yang diperlukan.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n\nPada module kali ini, akan digunakan tiga data csv yang berbeda untuk mempermudah kebutuhan visualisasi.\nKetiga data tersebut dapat kalian unduh pada tautan berikut: https://bit.ly/DataWeek2\n\nspotify_df = pd.read_csv('data/week 2/spotify.csv', index_col='Date', parse_dates=['Date'])\nflight_df = pd.read_csv('data/week 2/flight_delays.csv')\ninsurance_df = pd.read_csv('data/week 2/insurance.csv')"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-02.html#review-matplotlib",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-02.html#review-matplotlib",
    "title": "Week 02 (Data Visualization)",
    "section": "",
    "text": "Seperti yang sudah dipelajari pada Algoritma dan Pemrograman, visualisasi data dapat dilakukan dengan module matplotlib, antara lain untuk membuat line plot dan scatter plot.\nPertama, kita akan menggunakan data Spotify, yaitu data total daily streams 5 lagu hits pada masanya.\n\nspotify_df\n\n\n\n\n\n\n\n\nShape of You\nDespacito\nSomething Just Like This\nHUMBLE.\nUnforgettable\n\n\nDate\n\n\n\n\n\n\n\n\n\n2017-01-06\n12287078\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-07\n13190270\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-08\n13099919\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-09\n14506351\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-10\n14275628\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n\n\n2018-01-05\n4492978\n3450315.0\n2408365.0\n2685857.0\n2869783.0\n\n\n2018-01-06\n4416476\n3394284.0\n2188035.0\n2559044.0\n2743748.0\n\n\n2018-01-07\n4009104\n3020789.0\n1908129.0\n2350985.0\n2441045.0\n\n\n2018-01-08\n4135505\n2755266.0\n2023251.0\n2523265.0\n2622693.0\n\n\n2018-01-09\n4168506\n2791601.0\n2058016.0\n2727678.0\n2627334.0\n\n\n\n\n366 rows × 5 columns\n\n\n\nBerikut adalah cara untuk membuat line plot pada satu fitur di dataframe menggunakan matplotlib\n\n\"\"\"\nMembuat line plot untuk lagu Shape of You menggunakan matplotlib\n\"\"\"\n\n# Mengatur besar figur plot\nplt.subplots(figsize=(8,6))\n\n# Membuat line plot\nplt.plot(spotify_df['Shape of You'], 'b')\n# Membuat label sumbu-x dan sumbu-y\nplt.xlabel('Date')\nplt.ylabel('Shape of You Total Daily Streams')\n# Menampilkan plot\nplt.show()\n\n\n\n\n\n\n\n\nApabila kita ingin menampilkan fitur-fitur lain dalam figur yang sama, kita dapat memanfaatkan loop\n\n\"\"\"\nMembuat line plot untuk semua lagu dalam spotify_df menggunakan loop\n\"\"\"\n\nplt.subplots(figsize=(8,6))\n\n# Loop setiap nama kolom pada dataframe, lalu plot\nfor column in spotify_df.columns:\n    plt.plot(spotify_df[column])\n\nplt.legend(spotify_df.columns)\nplt.show()\n\n\n\n\n\n\n\n\nNamun, terdapat cara yang lebih mudah selain menggunakan looping. pandas dataframe memiliki method yang dapat secara langsung memvisualisasikan keseluruhan fiturnya, yaitu .plot().\nPada .plot() kita memiliki beberapa parameter yang dapat diatur, antara lain kind dan figsize. kind berfungsi untuk mengatur jenis plot yang ingin kita buat, sedangkan figsize berfungsi untuk mengatur besar figur yang dihasilkan.\nParameter lainnya dapat dilihat pada: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n\n\"\"\"\nMembuat line plot untuk semua lagu dalam spotify_df menggunakan pandas .plot()\n\"\"\"\n\nspotify_df.plot(kind='line', figsize=(8,6))\nplt.xlabel('Date')\nplt.ylabel('Total Daily Streams')\nplt.show()\n\n\n\n\n\n\n\n\nSelain line plot, terdapat banyak macam kind yang bisa digunakan. Pada code cell dibawah terlihat bahwa pandas .plot() dapat menghasilkan histogram (perlu diperhatikan bahwa jenis plot perlu menyesuaikan tipe data yang dimiliki, terlihat bahwa menggunakan data spotify, histogram tidak menghasilkan insight yang cukup berguna).\n\nspotify_df.plot(kind='hist', figsize=(8,6), alpha=.7)\n\nplt.show()\n\n\n\n\n\n\n\n\nPada praktikum Algoritma dan Pemrograman kita juga telah mempelajari cara untuk membuat scatter plot. Berikut code untuk membuat scatter plot menggunakan matplotlib, untuk melihat korelasi antara daily streams lagu Shape of You dengan Something Just Like This.\n\n\"\"\"\nMembuat scatter plot untuk melihat korelasi antara lagu\nShape of You dengan Something Just Like This menggunakan\nmatplotlib\n\"\"\"\n\nplt.subplots(figsize=(8,6))\n\nplt.scatter(x=spotify_df['Shape of You'], \n            y=spotify_df['Something Just Like This'],\n            alpha=.5)\nplt.xlabel('\"Shape of You\" Total Daily Streams')\nplt.ylabel('\"Something Just Like This\" Total Daily Streams')\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-02.html#pengenalan-seaborn",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-02.html#pengenalan-seaborn",
    "title": "Week 02 (Data Visualization)",
    "section": "",
    "text": "Walaupun matplotlib cukup fleksibel dalam menghasilkan plot, tetapi tipe plot yang disediakan cenderung terbatas. Oleh karena itu, kita dapat menggunakan Seaborn karena tipe plot yang disediakan sangat banyak sesuai kebutuhan kita, antara lain line, bar, heatmap, scatter, box, swarm, histogram, density, dan masih banyak lagi.\n\n\nLine plot biasa digunakan untuk melihat trend data dalam jangka waktu tertentu.\nUntuk membuat line plot pada seaborn, kita dapat menggunakan sns.lineplot(). Jika data yang ingin kita visualisasikan adalah dataframe, kita dapat memasukkan variabel dataframe tersebut pada parameter data, seperti code di bawah ini.\n\n\"\"\"\nMembuat line plot dengan module seaborn\n\"\"\"\n\nplt.subplots(figsize=(8,6))\nsns.lineplot(data=spotify_df)\nplt.show()\n\n\n\n\n\n\n\n\nFleksibilitas Seaborn membuat kita dapat memilih color palette yang sesuai dengan keinginan kita. Kita dapat memilih palette yang sudah disediakan oleh seaborn (antara lain: bright, deep, pastel, dan masih banyak lagi) atau kita dapat mengatur sendiri palette yang ingin kita gunakan.\nUntuk memilih palette yang akan digunakan untuk plot selanjutnya pada seaborn, kita dapat menggunakan sns.set_palette().\nJenis palette yang disediakan seaborn serta cara membuat color palette secara mandiri dapat dilihat pada: https://seaborn.pydata.org/tutorial/color_palettes.html#tools-for-choosing-color-palettes\n\n# Mengganti color palette menjadi \"bright\"\nsns.set_palette('bright')\n\n\n\"\"\"\nMembuat line plot setelah color palette diubah menjadi \"bright\"\n\"\"\"\n\n# Mengatur besar figur yang ingin ditampilkan\nplt.figure(figsize=(14,6))\n\n# Membuat line plot\nsns.lineplot(data=spotify_df)\n# Membuat judul figur\nplt.title(\"Daily Global Streams of Popular Songs in 2017-2018\")\n# Menampilkan plot\nplt.show()\n\n\n\n\n\n\n\n\nApabila tidak semua fitur pada data ingin kita visualisasikan, kita dapat menggunakan sns.lineplot() beberapa kali, sesuai dengan banyaknya fitur yang ingin kita tampilkan, seperti pada code di bawah.\n\nplt.figure(figsize=(14,6))\n\n# Membuat line plot hanya dengan lagu Shape of You\nsns.lineplot(data=spotify_df['Shape of You'], label=\"Shape of You\")\n# Menambahkan line plot pada figur dengan lagu Despacito\nsns.lineplot(data=spotify_df['Despacito'], label=\"Despacito\")\n\nplt.title(\"Daily Global Streams of Popular Songs in 2017-2018\")\nplt.xlabel(\"Date\")\nplt.ylabel('')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nBar plot biasa digunakan untuk membandingkan kuantitas/nilai pada data bertipe kategori.\nSelanjutnya, kita akan menggunakan data flight_delays.csv, yaitu data rata-rata keterlambatan beberapa maskapai pesawat pada setiap bulannya.\n\nflight_df\n\n\n\n\n\n\n\n\nMonth\nAA\nAS\nB6\nDL\nEV\nF9\nHA\nMQ\nNK\nOO\nUA\nUS\nVX\nWN\n\n\n\n\n0\n1\n6.955843\n-0.320888\n7.347281\n-2.043847\n8.537497\n18.357238\n3.512640\n18.164974\n11.398054\n10.889894\n6.352729\n3.107457\n1.420702\n3.389466\n\n\n1\n2\n7.530204\n-0.782923\n18.657673\n5.614745\n10.417236\n27.424179\n6.029967\n21.301627\n16.474466\n9.588895\n7.260662\n7.114455\n7.784410\n3.501363\n\n\n2\n3\n6.693587\n-0.544731\n10.741317\n2.077965\n6.730101\n20.074855\n3.468383\n11.018418\n10.039118\n3.181693\n4.892212\n3.330787\n5.348207\n3.263341\n\n\n3\n4\n4.931778\n-3.009003\n2.780105\n0.083343\n4.821253\n12.640440\n0.011022\n5.131228\n8.766224\n3.223796\n4.376092\n2.660290\n0.995507\n2.996399\n\n\n4\n5\n5.173878\n-1.716398\n-0.709019\n0.149333\n7.724290\n13.007554\n0.826426\n5.466790\n22.397347\n4.141162\n6.827695\n0.681605\n7.102021\n5.680777\n\n\n5\n6\n8.191017\n-0.220621\n5.047155\n4.419594\n13.952793\n19.712951\n0.882786\n9.639323\n35.561501\n8.338477\n16.932663\n5.766296\n5.779415\n10.743462\n\n\n6\n7\n3.870440\n0.377408\n5.841454\n1.204862\n6.926421\n14.464543\n2.001586\n3.980289\n14.352382\n6.790333\n10.262551\nNaN\n7.135773\n10.504942\n\n\n7\n8\n3.193907\n2.503899\n9.280950\n0.653114\n5.154422\n9.175737\n7.448029\n1.896565\n20.519018\n5.606689\n5.014041\nNaN\n5.106221\n5.532108\n\n\n8\n9\n-1.432732\n-1.813800\n3.539154\n-3.703377\n0.851062\n0.978460\n3.696915\n-2.167268\n8.000101\n1.530896\n-1.794265\nNaN\n0.070998\n-1.336260\n\n\n9\n10\n-0.580930\n-2.993617\n3.676787\n-5.011516\n2.303760\n0.082127\n0.467074\n-3.735054\n6.810736\n1.750897\n-2.456542\nNaN\n2.254278\n-0.688851\n\n\n10\n11\n0.772630\n-1.916516\n1.418299\n-3.175414\n4.415930\n11.164527\n-2.719894\n0.220061\n7.543881\n4.925548\n0.281064\nNaN\n0.116370\n0.995684\n\n\n11\n12\n4.149684\n-1.846681\n13.839290\n2.504595\n6.685176\n9.346221\n-1.706475\n0.662486\n12.733123\n10.947612\n7.012079\nNaN\n13.498720\n6.720893\n\n\n\n\n\n\n\nUntuk membuat bar plot pada seaborn dengan dataframe, kita dapat menggunakan sns.barplot() dengan tiga parameter yang wajib kita set, yaitu:\n- data: dataframe yang ingin kita visualisasikan\n\n- x: nama fitur pada dataframe yang ingin kita jadikan sumbu-x\n\n- y: nama fitur pada dataframe yang ingin kita jadikan sumbu-y\nPada kode di bawah, juga digunakan satu parameter opsional, yaitu palette yang merupakan cara lain untuk mengatur color palette yang ingin kita gunakan\n\n\"\"\"\nMembuat bar plot keterlambatan maskapai EV setiap \nbulannya menggunakan seaborn\n\"\"\"\n\nplt.figure(figsize=(14,6))\n\nsns.barplot(data=flight_df, x='Month', y='EV',\n            palette=sns.color_palette('deep'))\nplt.ylabel('EV Flight Delays (minute)')\nplt.title('Average EV Flight Delays per Month')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan hasil plot di atas, terlihat bahwa maskapai EV memiliki rata-rata keterlambatan terlama pada bulan Juni, serta tercepat pada bulan September.\nSelanjutnya, mari kita coba lihat urutan rata-rata keterlambatan semua maskapai dalam satu tahun (maskapai mana yang memiliki rata-rata keterlambatan terlama, serta maskapai mana yang tercepat).\nHal pertama yang perlu kita lakukan adalah, jadikan fitur Month sebagai index dataframe.\n\n# Set fitur \"Month\" menjadi index dataframe\nflight_df = flight_df.set_index('Month')\nflight_df.head(2)\n\n\n\n\n\n\n\n\nAA\nAS\nB6\nDL\nEV\nF9\nHA\nMQ\nNK\nOO\nUA\nUS\nVX\nWN\n\n\nMonth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n6.955843\n-0.320888\n7.347281\n-2.043847\n8.537497\n18.357238\n3.512640\n18.164974\n11.398054\n10.889894\n6.352729\n3.107457\n1.420702\n3.389466\n\n\n2\n7.530204\n-0.782923\n18.657673\n5.614745\n10.417236\n27.424179\n6.029967\n21.301627\n16.474466\n9.588895\n7.260662\n7.114455\n7.784410\n3.501363\n\n\n\n\n\n\n\nSelanjutnya, kita perlu hitung rata-rata keterlambatan tiap maskapai dalam satu tahun, yaitu hitung rata-rata tiap kolom pada dataframe menggunakan .mean() (Tambahan: apabila kita ingin menghitung rata-rata tiap barisnya, kita dapat menggunakan parameter axis=1 pada .mean()). .mean() akan menghasilkan pandas Series.\nLalu, agar mempermudah kita dalam melihat visualisasi bar plotnya, kita dapat menggunakan .sort_values().\n\n# Simpan rata-rata keterlambatan semua maskapai dalam satu tahun pada variabel flight_mean_inyear\nflight_mean_inyear = flight_df.mean()\n# Urutkan flight_mean_inyear secara ascending\nflight_mean_inyear = flight_mean_inyear.sort_values()\n\nflight_mean_inyear\n\nAS    -1.023656\nDL     0.231116\nHA     1.993205\nUS     3.776815\nAA     4.120776\nWN     4.275277\nVX     4.717718\nUA     5.413415\nOO     5.909658\nMQ     5.964953\nEV     6.543328\nB6     6.788370\nF9    13.035736\nNK    14.549663\ndtype: float64\n\n\nTerakhir, visualisasikan bar plot menggunakan cara seperti sebelumnya.\nKita dapat lihat pada code dibawah bahwa tidak digunakan parameter data, karena flight_mean_inyear merupakan pandas Series (bukan dataframe) sehingga lebih mudah jika kita langsung menggunakan parameter x dan y saja.\n\nplt.subplots(figsize=(14,6))\nsns.barplot(x=flight_mean_inyear.index, \n            y=flight_mean_inyear.values,\n            palette=sns.color_palette('deep'))\nplt.title('Average Delay per Flight in a Year')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan plot diatas, NK merupakan maskapai dengan rata-rata keterlambatan terlama dalam satu tahun, sedangkan AS adalah yang tercepat (AS bernilai negatif yang berarti rata-rata kedatangan pesawat lebih cepat dari yang dijadwalkan dalam satu tahun.\n\n\n\nHeatmap biasa digunakan untuk mempermudah melihat pola pada data berdasarkan warna yang dihasilkan.\nPada seaborn, kita dapat menggunakan heatmap dengan sns.heatmap() seperti pada kode dibawah. Parameter annot berfungsi untuk menampilkan nilai data (jika True) atau tidak (jika False).\nBar sebelah kanan heatmap menunjukkan bahwa, semakin lama keterlambatan pesawat, maka warna yang dihasilkan semakin terang. Sebaliknya, semakin gelap warna yang dihasilkan berarti semakin cepat pesawat datang tersebut.\n\n\"\"\"\nMembuat heatmap menggunakan Seaborn\n\"\"\"\nplt.figure(figsize=(14,10))\n\nsns.heatmap(data=flight_df, annot=True)\nplt.title(\"Average Arrival Delay for Each Airline, by Month\")\nplt.xlabel(\"Airline\")\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan heatmap di atas, kita dapat melihat dengan mudah pada bulan apa suatu maskapai sangat terlambat (contoh: maskapai NK pada bulan Juni).\nHeatmap sangat sering digunakan untuk melihat korelasi antarfitur pada dataset agar kita dapat mengerti lebih jauh tentang fitur-fitur pada data, atau juga dapat dimanfaatkan untuk melakukan feature selection sebelum membuat sebuat model Machine Learning.\nUntuk melakukan hal tersebut, kita perlu menghitung dahulu korelasi antar fitur menggunakan pandas .corr(), yaitu fungsi yang akan menghitung korelasi antar dua fitur menggunakan korelasi Pearson.\nNotes: Metode korelasi dapat diubah dengan menggunakan parameter method pada .corr(), contoh: .corr(method='spearman'). Metode lainnya dapat dilihat pada: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\n\n# Hitung korelasi antar dua fitur pada flight_df\nflight_corr = flight_df.corr()\n\nflight_corr\n\n\n\n\n\n\n\n\nAA\nAS\nB6\nDL\nEV\nF9\nHA\nMQ\nNK\nOO\nUA\nUS\nVX\nWN\n\n\n\n\nAA\n1.000000\n0.334980\n0.429854\n0.805229\n0.896523\n0.903986\n0.220065\n0.842701\n0.573716\n0.620477\n0.809874\n0.823713\n0.425237\n0.615664\n\n\nAS\n0.334980\n1.000000\n0.340359\n0.394359\n0.356608\n0.336791\n0.684979\n0.283977\n0.480863\n0.350657\n0.457414\n0.489025\n0.229571\n0.519228\n\n\nB6\n0.429854\n0.340359\n1.000000\n0.643313\n0.342627\n0.510718\n0.467905\n0.529724\n0.032038\n0.591115\n0.233021\n0.788345\n0.579750\n0.151750\n\n\nDL\n0.805229\n0.394359\n0.643313\n1.000000\n0.796951\n0.783265\n0.262251\n0.598765\n0.625277\n0.569073\n0.797339\n0.821757\n0.700605\n0.691805\n\n\nEV\n0.896523\n0.356608\n0.342627\n0.796951\n1.000000\n0.828515\n0.099369\n0.721468\n0.784026\n0.692697\n0.911499\n0.669736\n0.462638\n0.730115\n\n\nF9\n0.903986\n0.336791\n0.510718\n0.783265\n0.828515\n1.000000\n0.273878\n0.912984\n0.414064\n0.582509\n0.671986\n0.878874\n0.308397\n0.465765\n\n\nHA\n0.220065\n0.684979\n0.467905\n0.262251\n0.099369\n0.273878\n1.000000\n0.436015\n0.176485\n0.056941\n0.066821\n0.586160\n-0.008439\n-0.007296\n\n\nMQ\n0.842701\n0.283977\n0.529724\n0.598765\n0.721468\n0.912984\n0.436015\n1.000000\n0.281890\n0.586963\n0.503575\n0.660181\n0.150111\n0.239744\n\n\nNK\n0.573716\n0.480863\n0.032038\n0.625277\n0.784026\n0.414064\n0.176485\n0.281890\n1.000000\n0.365273\n0.827455\n0.293515\n0.395419\n0.742869\n\n\nOO\n0.620477\n0.350657\n0.591115\n0.569073\n0.692697\n0.582509\n0.056941\n0.586963\n0.365273\n1.000000\n0.626051\n0.590313\n0.561515\n0.548304\n\n\nUA\n0.809874\n0.457414\n0.233021\n0.797339\n0.911499\n0.671986\n0.066821\n0.503575\n0.827455\n0.626051\n1.000000\n0.477816\n0.536968\n0.926800\n\n\nUS\n0.823713\n0.489025\n0.788345\n0.821757\n0.669736\n0.878874\n0.586160\n0.660181\n0.293515\n0.590313\n0.477816\n1.000000\n0.333396\n0.242344\n\n\nVX\n0.425237\n0.229571\n0.579750\n0.700605\n0.462638\n0.308397\n-0.008439\n0.150111\n0.395419\n0.561515\n0.536968\n0.333396\n1.000000\n0.630278\n\n\nWN\n0.615664\n0.519228\n0.151750\n0.691805\n0.730115\n0.465765\n-0.007296\n0.239744\n0.742869\n0.548304\n0.926800\n0.242344\n0.630278\n1.000000\n\n\n\n\n\n\n\nPandas .corr() menghasilkan dataframe dengan nama baris dan kolom yang sama, serta berisi nilai korelasi antara baris dan kolom yang ditinjau (contoh: korelasi antara maskapai AA dan AS adalah 0,334980). Serta, dataframe yang dihasilkan adalah sebuat matriks simetris.\nTentu dengan hanya melihat dataframe di atas, tidak terlihat begitu jelas mana fitur yang memiliki korelasi tinggi dan mana yang yang memiliki korelasi rendah. Oleh karena itu, kita dapat memanfaatkan heatmap.\nPada code di bawah, untuk mempermudah pembacaan heatmap, kita menggunakan parameter vmin, vmax, dan center pada sns.heatmap(). vmin berfungsi untuk mengatur nilai terendah, vmax berfungsi untuk mengatur nilai tertinggi, dan center berfungsi untuk mengatur nilai tengah pada heatmap. Korelasi Pearson menghasilkan nilai antara -1 hingga 1, sehingga kita dapat set ketiga parameter tersebut seperti pada code di bawah.\n\nplt.figure(figsize=(14,10))\n\nsns.heatmap(data=flight_corr, vmin=-1, vmax=1, center=0, annot=True)\nplt.title(\"Pearson Correlation of Each Airline Flight Delays\")\nplt.xlabel(\"Airline\")\nplt.show()\n\n\n\n\n\n\n\n\nDengan menggunakan heatmap, sekarang terlihat bahwa mana maskapai yang keterlambatannya berkorelasi tinggi dan mana yang rendah. Misal, AA dan EV menghasilkan korelasi yang cukup tinggi positif, yaitu 0.9, yang artinya jika keterlambatan maskapai AA tinggi, begitu juga maskapai EV, dan sebaliknya jika keterlambatan maskapai AA rendah, begitu juga maskapai EV.\nUntuk meyakinkan kita dengan hal tersebut, kita dapat lihat pada materi selanjutnya, yaitu Scatter Plot.\n\n\n\nScatter plot biasa digunakan untuk melihat korelasi antara dua fitur bertipe numerik.\nUntuk menggunakan scatter plot pada seaborn, kita dapat menggunakan sns.scatterplot(), dengan parameter yang sama seperti kita membuat bar plot.\n\n\"\"\"\nMembuat scatter plot untuk melihat \nketerkaitan pada keterlambatan pesawat\nmaskapai EV dan AA\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='EV', y='AA')\nplt.show()\n\n\n\n\n\n\n\n\nMelalui scatter plot di atas, kita dapat semakin yakin bahwa kesimpulan yang kita ambil dengan melihat heatmap sebelumnya benar.\n\n\"\"\"\nTambahan scatter plot pada maskapai lain yang\nmemiliki korelasi tinggi\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='EV', y='UA')\nplt.show()\n\n\n\n\n\n\n\n\n\n\"\"\"\nScatter plot pada maskapai yang memiliki\nkorelasi rendah (mendekati 0)\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='UA', y='HA')\nplt.show()\n\n\n\n\n\n\n\n\nPada heatmap, terlihat bahwa maskapai UA dan HA memiliki korelasi yang rendah, yaitu 0.067. Sehingga, jika kita buat scatter plotnya, menghasilkan plot seperti di atas.\nUntuk memahami scatter plot lebih baik, kita akan menggunakan dataset lainnya, yaitu insurance.csv yang merupakan data berisi biaya asuransi (charges) beberapa orang.\n\ninsurance_df.head()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n\n\n\n\n\n\n\nMisal, kita ingin melihat keterkaitan indeks massa tubuh (bmi) seseorang dengan biaya asuransi (charges) orang tersebut. Sama seperti sebelumnya, kita dapat melakukannya seperti pada code di bawah.\n\n# Mengubah palette menjadi default\nsns.set_palette('tab10')\n# Membuat scatter plot antara fitur bmi dan charges\nsns.scatterplot(data=insurance_df, x='bmi', y='charges')\n\nplt.show()\n\n\n\n\n\n\n\n\nScatter plot di atas menunjukkan bahwa korelasi antara bmi dan charges adalah cenderung positif, tetapi tidak terlalu tinggi. Yang artinya, orang dengan BMI tinggi, cenderung akan membayar biaya asuransi lebih tinggi.\nAgar kita semakin yakin dengan kesimpulan tersebut, kita dapat menambahakn garis regresi pada scatter plot tersebut dengan menggunakan sns.regplot().\n\nsns.regplot(data=insurance_df, x='bmi', y='charges')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan scatter plot dan garis regresi dihasilkan, terlihat bahwa kesimpulan yang kita ambil benar. Agar semakin yakin lagi, kita juga dapat menghitung langsung korelasi Pearsonnya menggunakan cara sebelumnya, yaitu pandas .corr().\n\ninsurance_df[['bmi', 'charges']].corr()\n\n\n\n\n\n\n\n\nbmi\ncharges\n\n\n\n\nbmi\n1.000000\n0.198341\n\n\ncharges\n0.198341\n1.000000\n\n\n\n\n\n\n\nDengan menggunakan seaborn, kita juga dapat memvisualisasikan scatter plot berdasarkan dengan pewarnaan yang berbeda berdasarkan fitur lainnya yang bertipe kategorik.\nMisal, kita ingin membuat scatter plot antara fitur bmi dan charges dengan pewarnaannya berdasarkan nilai dari fitur smoker, yaitu yes atau no. Kita dapat set parameter hue='smoker' pada sns.scatterplot() seperti pada code di bawah.\n\nsns.scatterplot(data=insurance_df, x='bmi', y='charges', hue='smoker')\nplt.show()\n\n\n\n\n\n\n\n\nSehingga dihasilkan pewarnaan yang berbeda untuk seseorang yang merupakan perokok (biru) dan yang tidak (orange). Berdasarkan scatter plot di atas, terlihat bahwa korelasi antara bmi dan charges untuk perokok cendering tinggi positif (semakin besar bmi, semakin besar juga charges). Sedangkan, untuk bukan perokok, korelasinya cenderung rendah (semakin besar bmi, tidak terlalu berpengaruh terhadap charges).\nSeperti cara sebelumnya, kita dapat menambahkan garis regresi. Namun, karena kita disini menggunakan hue, terdapat dua cara untuk menambahkan garis regresi, yaitu yang pertama adalah menggunakan sns.regplot() seperti di bawah ini.\n\nsns.regplot(data=insurance_df.query('smoker == \"yes\"'), x='bmi', y='charges') # axes 1\nsns.regplot(data=insurance_df.query('smoker == \"no\"'), x='bmi', y='charges') # axes 2\nplt.show()\n\n\n\n\n\n\n\n\nPerhatikan bahwa sns.regplot() dipanggil dua kali karena fungsi tersebut tidak memiliki parameter hue.\nUntuk mempermudah, kita dapat menggunakan cara kedua, yaitu menggunakan sns.lmplot(). Cara kerja sns.lmplot() yaitu menggabungkan dua (atau lebih) sns.regplot() dalam satu figur.\n\nsns.lmplot(data=insurance_df, x='bmi', y='charges', hue='smoker')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nBox plot dan swarm plot biasa digunakan untuk melihat keterkaitan antara data kategorik dan data numerik. Swarm plot biasa disebut sebagai “categorical scatter plot”, karena plot yang dihasilkan mirip seperti scatter plot, tetapi untuk data kategorik.\nUntuk menggunakan box plot pada seaborn kita dapat menggunakan sns.boxplot().\nUntuk menggunakan swarm plot pada seaborn kita dapat menggunakan sns.swarmplot().\nMisal, kita ingin melihat keterkaitan antara fitur smoker dan charges menggunakan swarm plot. Maka, kita dapat menggunakan code seperti di bawah ini.\n\nplt.subplots(figsize=(10,6))\n\nsns.swarmplot(data=insurance_df, x='smoker', y='charges', size=3)\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan swarm plot di atas, terlihat bahwa perokok cenderung memiliki biaya asuransi yang lebih tinggi dibandingkan yang bukan perokok. Selain itu, semakin lebar “swarm” pada suatu kategori berarti semakin banyak seseorang dengan nilai charges tersebut.\nApabila kita ingin menggunakan box plot, maka dapat digunakan code seperti di bawah ini.\n\nsns.boxplot(data=insurance_df, x='smoker', y='charges')\nplt.show()\n\n\n\n\n\n\n\n\nPada box plot, terdapat dua istilah yang umum digunakan, yaitu “box” dan “whiskers”. Pada box plot di atas, “box” merupakan persegi panjang berwarna biru dan orange. Garis di tengah box merupakan nilai mediannya, serta garis bawah dan garis atas box merupakan kuartil bawah (Q1) dan kuartil atas (Q3) secara berurutan. “Whiskers” adalah garis yang merupakan perpanjangan dari box. Ujung dari whiskers atas adalah Q3 + (1.5 x IQR) data, sedangkan ujung whiskers bawah adalah Q1 - (1.5 x IQR) data.\nTitik di luar box dan whiskers tersebut adalah titik yang biasa dijadikan sebagai outlier (penentuan outlier diserahkan ke diri masing-masing, apakah hanya dengan melihat box plot atau dengan menggunakan metode lain, tetapi untuk mempermudah dapat menggunakan box plot).\n\n\n\nSelain box plot dan swarm plot, kita juga dapat melihat persebaran data menggunakan histogram dan density plot. Histogram biasa digunakan untuk melihat persebaran data secara diskrit, sedangkan density plot untuk melihat persebaran data secara kontinu.\nUntuk membuat histogram pada seaborn, kita dapat menggunakan sns.histplot().\nUntuk membuat density plot pada seaborn, kita dapat menggunakan sns.kdeplot().\nMisal, kita ingin melihat persebaran dari fitur charges pada insurance_df. Maka dapat digunakan code seperti di bawah.\n\nplt.subplots(figsize=(12,6))\n\nsns.histplot(data=insurance_df, x='charges')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan histogram di atas, terlihat bahwa distribusi charges cenderung “skew” atau miring ke kanan. “Skewness” atau tingkat kecondongan merupakan aspek yang penting untuk diperhatikan ketika kita ingin membuat model Machine Learning.\nSeperti scatter plot, kita juga dapat menentukan pewarnaan histogram berdasarkan fitur lainnya dengan menggunakan parameter hue seperti di bawah ini/\n\nplt.subplots(figsize=(12,6))\nsns.histplot(data=insurance_df, x='charges', hue='smoker')\nplt.show()\n\n\n\n\n\n\n\n\nJika ingin membuat density plot dari fitur charges, kita dapat menggunakan kode seperti di bawah ini. Parameter shade berfungsi untuk memberikan warna di bawah kurva.\n\nplt.subplots(figsize=(12,6))\nsns.kdeplot(data=insurance_df, x='charges', shade=True)\nplt.show()\n\n\n\n\n\n\n\n\nsns.kdeplot() juga dapat menggunakan parameter hue.\n\nplt.subplots(figsize=(12,6))\nsns.kdeplot(data=insurance_df, x='charges',\n            hue='smoker', shade=True)\nplt.show()\n\n\n\n\n\n\n\n\nApabila kita ingin menggabungkan histogram dan density plot dalam satu figur, kita dapat menggunakan sns.histplot() dengan parameter kde=True.\n\nplt.subplots(figsize=(12,6))\nsns.histplot(data=insurance_df, x='charges', hue='smoker', kde=True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPada seaborn, kita juga dapat membuat dua plot yang berbeda dari dua fitur dalam satu figur yang sama menggunakan sns.jointplot().\nJenis plot yang dihasilkan dapat diatur pada parameter kind. Pilihan jenis kind yang disediakan dapat dilihat pada: https://seaborn.pydata.org/generated/seaborn.jointplot.html\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"scatter\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"hist\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"kde\")\n\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-02.html#supplementary-panduan-pemilihan-plot",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-02.html#supplementary-panduan-pemilihan-plot",
    "title": "Week 02 (Data Visualization)",
    "section": "",
    "text": "image.png\n\n\nsource: https://www.kaggle.com/code/alexisbcook/choosing-plot-types-and-custom-styles"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-04.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-04.html",
    "title": "Week 04 (Clustering)",
    "section": "",
    "text": "Kembali ke Sains Data\nClustering adalah metode untuk membagi populasi atau titik data ke dalam sejumlah kelompok sedemikian rupa sehingga titik data dalam kelompok yang sama lebih mirip dengan titik data lain dalam kelompok yang sama dan berbeda dengan titik data dalam kelompok lain. Pada dasarnya, ini adalah kumpulan objek berdasarkan kesamaan dan ketidaksamaan di antara mereka.\nsource: https://www.geeksforgeeks.org/clustering-in-machine-learning/\nDataset: https://drive.google.com/file/d/1QWrWOYx2cZyEfYLe652Aj8IMm8mlkMy9/view?usp=sharing\n\n\nK-means clustering adalah algoritma unsupervised learning yang mengelompokkan dataset yang belum dilabel ke dalam kluster yang berbeda berdasarkan kesamaan tertentu\\(^{[1][2][3]}\\). K-means clustering membutuhkan nilai k yang menandakan jumlah kluster yang akan dibentuk\\(^{[1][4]}\\). K-means clustering berusaha untuk meminimalisasi variasi antar kluster dan memaksimalisasi variasi antar kluster\\(^{[2][5]}\\). K-means clustering menggunakan rata-rata dan jarak antara data dan centroid untuk menentukan kluster\\(^{[2][5]}\\). K-means clustering bekerja dengan baik jika kluster memiliki bentuk bola\\(^{[3]}\\).\nsource:\n[1] https://www.trivusi.web.id/2022/06/algoritma-kmeans-clustering.html\n[2] https://raharja.ac.id/2020/04/19/k-means-clustering/\n[3] https://ichi.pro/id/k-means-clustering-algoritma-aplikasi-metode-evaluasi-dan-kelemahan-186933724886154\n[4] https://dqlab.id/k-means-clustering-salah-satu-contoh-teknik-analisis-data-populer\n[5] https://sis.binus.ac.id/2022/01/31/clustering-algoritma-k-means/.\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n\ndataset = pd.read_csv('Mall_Customers.csv')\ndataset\n\n\n  \n    \n      \n\n\n\n\n\n\nCustomerID\nGenre\nAge\nAnnual Income (k$)\nSpending Score (1-100)\n\n\n\n\n0\n1\nMale\n19\n15\n39\n\n\n1\n2\nMale\n21\n15\n81\n\n\n2\n3\nFemale\n20\n16\n6\n\n\n3\n4\nFemale\n23\n16\n77\n\n\n4\n5\nFemale\n31\n17\n40\n\n\n...\n...\n...\n...\n...\n...\n\n\n195\n196\nFemale\n35\n120\n79\n\n\n196\n197\nFemale\n45\n126\n28\n\n\n197\n198\nMale\n32\n126\n74\n\n\n198\n199\nMale\n32\n137\n18\n\n\n199\n200\nMale\n30\n137\n83\n\n\n\n\n200 rows × 5 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nX = dataset.iloc[:, [3, 4]].values\nX\n\narray([[ 15,  39],\n       [ 15,  81],\n       [ 16,   6],\n       [ 16,  77],\n       [ 17,  40],\n       [ 17,  76],\n       [ 18,   6],\n       [ 18,  94],\n       [ 19,   3],\n       [ 19,  72],\n       [ 19,  14],\n       [ 19,  99],\n       [ 20,  15],\n       [ 20,  77],\n       [ 20,  13],\n       [ 20,  79],\n       [ 21,  35],\n       [ 21,  66],\n       [ 23,  29],\n       [ 23,  98],\n       [ 24,  35],\n       [ 24,  73],\n       [ 25,   5],\n       [ 25,  73],\n       [ 28,  14],\n       [ 28,  82],\n       [ 28,  32],\n       [ 28,  61],\n       [ 29,  31],\n       [ 29,  87],\n       [ 30,   4],\n       [ 30,  73],\n       [ 33,   4],\n       [ 33,  92],\n       [ 33,  14],\n       [ 33,  81],\n       [ 34,  17],\n       [ 34,  73],\n       [ 37,  26],\n       [ 37,  75],\n       [ 38,  35],\n       [ 38,  92],\n       [ 39,  36],\n       [ 39,  61],\n       [ 39,  28],\n       [ 39,  65],\n       [ 40,  55],\n       [ 40,  47],\n       [ 40,  42],\n       [ 40,  42],\n       [ 42,  52],\n       [ 42,  60],\n       [ 43,  54],\n       [ 43,  60],\n       [ 43,  45],\n       [ 43,  41],\n       [ 44,  50],\n       [ 44,  46],\n       [ 46,  51],\n       [ 46,  46],\n       [ 46,  56],\n       [ 46,  55],\n       [ 47,  52],\n       [ 47,  59],\n       [ 48,  51],\n       [ 48,  59],\n       [ 48,  50],\n       [ 48,  48],\n       [ 48,  59],\n       [ 48,  47],\n       [ 49,  55],\n       [ 49,  42],\n       [ 50,  49],\n       [ 50,  56],\n       [ 54,  47],\n       [ 54,  54],\n       [ 54,  53],\n       [ 54,  48],\n       [ 54,  52],\n       [ 54,  42],\n       [ 54,  51],\n       [ 54,  55],\n       [ 54,  41],\n       [ 54,  44],\n       [ 54,  57],\n       [ 54,  46],\n       [ 57,  58],\n       [ 57,  55],\n       [ 58,  60],\n       [ 58,  46],\n       [ 59,  55],\n       [ 59,  41],\n       [ 60,  49],\n       [ 60,  40],\n       [ 60,  42],\n       [ 60,  52],\n       [ 60,  47],\n       [ 60,  50],\n       [ 61,  42],\n       [ 61,  49],\n       [ 62,  41],\n       [ 62,  48],\n       [ 62,  59],\n       [ 62,  55],\n       [ 62,  56],\n       [ 62,  42],\n       [ 63,  50],\n       [ 63,  46],\n       [ 63,  43],\n       [ 63,  48],\n       [ 63,  52],\n       [ 63,  54],\n       [ 64,  42],\n       [ 64,  46],\n       [ 65,  48],\n       [ 65,  50],\n       [ 65,  43],\n       [ 65,  59],\n       [ 67,  43],\n       [ 67,  57],\n       [ 67,  56],\n       [ 67,  40],\n       [ 69,  58],\n       [ 69,  91],\n       [ 70,  29],\n       [ 70,  77],\n       [ 71,  35],\n       [ 71,  95],\n       [ 71,  11],\n       [ 71,  75],\n       [ 71,   9],\n       [ 71,  75],\n       [ 72,  34],\n       [ 72,  71],\n       [ 73,   5],\n       [ 73,  88],\n       [ 73,   7],\n       [ 73,  73],\n       [ 74,  10],\n       [ 74,  72],\n       [ 75,   5],\n       [ 75,  93],\n       [ 76,  40],\n       [ 76,  87],\n       [ 77,  12],\n       [ 77,  97],\n       [ 77,  36],\n       [ 77,  74],\n       [ 78,  22],\n       [ 78,  90],\n       [ 78,  17],\n       [ 78,  88],\n       [ 78,  20],\n       [ 78,  76],\n       [ 78,  16],\n       [ 78,  89],\n       [ 78,   1],\n       [ 78,  78],\n       [ 78,   1],\n       [ 78,  73],\n       [ 79,  35],\n       [ 79,  83],\n       [ 81,   5],\n       [ 81,  93],\n       [ 85,  26],\n       [ 85,  75],\n       [ 86,  20],\n       [ 86,  95],\n       [ 87,  27],\n       [ 87,  63],\n       [ 87,  13],\n       [ 87,  75],\n       [ 87,  10],\n       [ 87,  92],\n       [ 88,  13],\n       [ 88,  86],\n       [ 88,  15],\n       [ 88,  69],\n       [ 93,  14],\n       [ 93,  90],\n       [ 97,  32],\n       [ 97,  86],\n       [ 98,  15],\n       [ 98,  88],\n       [ 99,  39],\n       [ 99,  97],\n       [101,  24],\n       [101,  68],\n       [103,  17],\n       [103,  85],\n       [103,  23],\n       [103,  69],\n       [113,   8],\n       [113,  91],\n       [120,  16],\n       [120,  79],\n       [126,  28],\n       [126,  74],\n       [137,  18],\n       [137,  83]])\n\n\n\n\n\n\nhelp(KMeans)\n\nHelp on class KMeans in module sklearn.cluster._kmeans:\n\nclass KMeans(_BaseKMeans)\n |  KMeans(n_clusters=8, *, init='k-means++', n_init='warn', max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n |  \n |  K-Means clustering.\n |  \n |  Read more in the :ref:`User Guide &lt;k_means&gt;`.\n |  \n |  Parameters\n |  ----------\n |  \n |  n_clusters : int, default=8\n |      The number of clusters to form as well as the number of\n |      centroids to generate.\n |  \n |  init : {'k-means++', 'random'}, callable or array-like of shape             (n_clusters, n_features), default='k-means++'\n |      Method for initialization:\n |  \n |      'k-means++' : selects initial cluster centroids using sampling based on\n |      an empirical probability distribution of the points' contribution to the\n |      overall inertia. This technique speeds up convergence. The algorithm\n |      implemented is \"greedy k-means++\". It differs from the vanilla k-means++\n |      by making several trials at each sampling step and choosing the best centroid\n |      among them.\n |  \n |      'random': choose `n_clusters` observations (rows) at random from data\n |      for the initial centroids.\n |  \n |      If an array is passed, it should be of shape (n_clusters, n_features)\n |      and gives the initial centers.\n |  \n |      If a callable is passed, it should take arguments X, n_clusters and a\n |      random state and return an initialization.\n |  \n |  n_init : 'auto' or int, default=10\n |      Number of times the k-means algorithm is run with different centroid\n |      seeds. The final results is the best output of `n_init` consecutive runs\n |      in terms of inertia. Several runs are recommended for sparse\n |      high-dimensional problems (see :ref:`kmeans_sparse_high_dim`).\n |  \n |      When `n_init='auto'`, the number of runs depends on the value of init:\n |      10 if using `init='random'`, 1 if using `init='k-means++'`.\n |  \n |      .. versionadded:: 1.2\n |         Added 'auto' option for `n_init`.\n |  \n |      .. versionchanged:: 1.4\n |         Default value for `n_init` will change from 10 to `'auto'` in version 1.4.\n |  \n |  max_iter : int, default=300\n |      Maximum number of iterations of the k-means algorithm for a\n |      single run.\n |  \n |  tol : float, default=1e-4\n |      Relative tolerance with regards to Frobenius norm of the difference\n |      in the cluster centers of two consecutive iterations to declare\n |      convergence.\n |  \n |  verbose : int, default=0\n |      Verbosity mode.\n |  \n |  random_state : int, RandomState instance or None, default=None\n |      Determines random number generation for centroid initialization. Use\n |      an int to make the randomness deterministic.\n |      See :term:`Glossary &lt;random_state&gt;`.\n |  \n |  copy_x : bool, default=True\n |      When pre-computing distances it is more numerically accurate to center\n |      the data first. If copy_x is True (default), then the original data is\n |      not modified. If False, the original data is modified, and put back\n |      before the function returns, but small numerical differences may be\n |      introduced by subtracting and then adding the data mean. Note that if\n |      the original data is not C-contiguous, a copy will be made even if\n |      copy_x is False. If the original data is sparse, but not in CSR format,\n |      a copy will be made even if copy_x is False.\n |  \n |  algorithm : {\"lloyd\", \"elkan\", \"auto\", \"full\"}, default=\"lloyd\"\n |      K-means algorithm to use. The classical EM-style algorithm is `\"lloyd\"`.\n |      The `\"elkan\"` variation can be more efficient on some datasets with\n |      well-defined clusters, by using the triangle inequality. However it's\n |      more memory intensive due to the allocation of an extra array of shape\n |      `(n_samples, n_clusters)`.\n |  \n |      `\"auto\"` and `\"full\"` are deprecated and they will be removed in\n |      Scikit-Learn 1.3. They are both aliases for `\"lloyd\"`.\n |  \n |      .. versionchanged:: 0.18\n |          Added Elkan algorithm\n |  \n |      .. versionchanged:: 1.1\n |          Renamed \"full\" to \"lloyd\", and deprecated \"auto\" and \"full\".\n |          Changed \"auto\" to use \"lloyd\" instead of \"elkan\".\n |  \n |  Attributes\n |  ----------\n |  cluster_centers_ : ndarray of shape (n_clusters, n_features)\n |      Coordinates of cluster centers. If the algorithm stops before fully\n |      converging (see ``tol`` and ``max_iter``), these will not be\n |      consistent with ``labels_``.\n |  \n |  labels_ : ndarray of shape (n_samples,)\n |      Labels of each point\n |  \n |  inertia_ : float\n |      Sum of squared distances of samples to their closest cluster center,\n |      weighted by the sample weights if provided.\n |  \n |  n_iter_ : int\n |      Number of iterations run.\n |  \n |  n_features_in_ : int\n |      Number of features seen during :term:`fit`.\n |  \n |      .. versionadded:: 0.24\n |  \n |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n |      Names of features seen during :term:`fit`. Defined only when `X`\n |      has feature names that are all strings.\n |  \n |      .. versionadded:: 1.0\n |  \n |  See Also\n |  --------\n |  MiniBatchKMeans : Alternative online implementation that does incremental\n |      updates of the centers positions using mini-batches.\n |      For large scale learning (say n_samples &gt; 10k) MiniBatchKMeans is\n |      probably much faster than the default batch implementation.\n |  \n |  Notes\n |  -----\n |  The k-means problem is solved using either Lloyd's or Elkan's algorithm.\n |  \n |  The average complexity is given by O(k n T), where n is the number of\n |  samples and T is the number of iteration.\n |  \n |  The worst case complexity is given by O(n^(k+2/p)) with\n |  n = n_samples, p = n_features.\n |  Refer to :doi:`\"How slow is the k-means method?\" D. Arthur and S. Vassilvitskii -\n |  SoCG2006.&lt;10.1145/1137856.1137880&gt;` for more details.\n |  \n |  In practice, the k-means algorithm is very fast (one of the fastest\n |  clustering algorithms available), but it falls in local minima. That's why\n |  it can be useful to restart it several times.\n |  \n |  If the algorithm stops before fully converging (because of ``tol`` or\n |  ``max_iter``), ``labels_`` and ``cluster_centers_`` will not be consistent,\n |  i.e. the ``cluster_centers_`` will not be the means of the points in each\n |  cluster. Also, the estimator will reassign ``labels_`` after the last\n |  iteration to make ``labels_`` consistent with ``predict`` on the training\n |  set.\n |  \n |  Examples\n |  --------\n |  \n |  &gt;&gt;&gt; from sklearn.cluster import KMeans\n |  &gt;&gt;&gt; import numpy as np\n |  &gt;&gt;&gt; X = np.array([[1, 2], [1, 4], [1, 0],\n |  ...               [10, 2], [10, 4], [10, 0]])\n |  &gt;&gt;&gt; kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(X)\n |  &gt;&gt;&gt; kmeans.labels_\n |  array([1, 1, 1, 0, 0, 0], dtype=int32)\n |  &gt;&gt;&gt; kmeans.predict([[0, 0], [12, 3]])\n |  array([1, 0], dtype=int32)\n |  &gt;&gt;&gt; kmeans.cluster_centers_\n |  array([[10.,  2.],\n |         [ 1.,  2.]])\n |  \n |  Method resolution order:\n |      KMeans\n |      _BaseKMeans\n |      sklearn.base.ClassNamePrefixFeaturesOutMixin\n |      sklearn.base.TransformerMixin\n |      sklearn.utils._set_output._SetOutputMixin\n |      sklearn.base.ClusterMixin\n |      sklearn.base.BaseEstimator\n |      abc.ABC\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, n_clusters=8, *, init='k-means++', n_init='warn', max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  fit(self, X, y=None, sample_weight=None)\n |      Compute k-means clustering.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          Training instances to cluster. It must be noted that the data\n |          will be converted to C ordering, which will cause a memory\n |          copy if the given data is not C-contiguous.\n |          If a sparse matrix is passed, a copy will be made if it's not in\n |          CSR format.\n |      \n |      y : Ignored\n |          Not used, present here for API consistency by convention.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          The weights for each observation in X. If None, all observations\n |          are assigned equal weight.\n |      \n |          .. versionadded:: 0.20\n |      \n |      Returns\n |      -------\n |      self : object\n |          Fitted estimator.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __abstractmethods__ = frozenset()\n |  \n |  __annotations__ = {'_parameter_constraints': &lt;class 'dict'&gt;}\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from _BaseKMeans:\n |  \n |  fit_predict(self, X, y=None, sample_weight=None)\n |      Compute cluster centers and predict cluster index for each sample.\n |      \n |      Convenience method; equivalent to calling fit(X) followed by\n |      predict(X).\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          New data to transform.\n |      \n |      y : Ignored\n |          Not used, present here for API consistency by convention.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          The weights for each observation in X. If None, all observations\n |          are assigned equal weight.\n |      \n |      Returns\n |      -------\n |      labels : ndarray of shape (n_samples,)\n |          Index of the cluster each sample belongs to.\n |  \n |  fit_transform(self, X, y=None, sample_weight=None)\n |      Compute clustering and transform X to cluster-distance space.\n |      \n |      Equivalent to fit(X).transform(X), but more efficiently implemented.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          New data to transform.\n |      \n |      y : Ignored\n |          Not used, present here for API consistency by convention.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          The weights for each observation in X. If None, all observations\n |          are assigned equal weight.\n |      \n |      Returns\n |      -------\n |      X_new : ndarray of shape (n_samples, n_clusters)\n |          X transformed in the new space.\n |  \n |  predict(self, X, sample_weight=None)\n |      Predict the closest cluster each sample in X belongs to.\n |      \n |      In the vector quantization literature, `cluster_centers_` is called\n |      the code book and each value returned by `predict` is the index of\n |      the closest code in the code book.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          New data to predict.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          The weights for each observation in X. If None, all observations\n |          are assigned equal weight.\n |      \n |      Returns\n |      -------\n |      labels : ndarray of shape (n_samples,)\n |          Index of the cluster each sample belongs to.\n |  \n |  score(self, X, y=None, sample_weight=None)\n |      Opposite of the value of X on the K-means objective.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          New data.\n |      \n |      y : Ignored\n |          Not used, present here for API consistency by convention.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          The weights for each observation in X. If None, all observations\n |          are assigned equal weight.\n |      \n |      Returns\n |      -------\n |      score : float\n |          Opposite of the value of X on the K-means objective.\n |  \n |  transform(self, X)\n |      Transform X to a cluster-distance space.\n |      \n |      In the new space, each dimension is the distance to the cluster\n |      centers. Note that even if X is sparse, the array returned by\n |      `transform` will typically be dense.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          New data to transform.\n |      \n |      Returns\n |      -------\n |      X_new : ndarray of shape (n_samples, n_clusters)\n |          X transformed in the new space.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.base.ClassNamePrefixFeaturesOutMixin:\n |  \n |  get_feature_names_out(self, input_features=None)\n |      Get output feature names for transformation.\n |      \n |      The feature names out will prefixed by the lowercased class name. For\n |      example, if the transformer outputs 3 features, then the feature names\n |      out are: `[\"class_name0\", \"class_name1\", \"class_name2\"]`.\n |      \n |      Parameters\n |      ----------\n |      input_features : array-like of str or None, default=None\n |          Only used to validate feature names with the names seen in :meth:`fit`.\n |      \n |      Returns\n |      -------\n |      feature_names_out : ndarray of str objects\n |          Transformed feature names.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from sklearn.base.ClassNamePrefixFeaturesOutMixin:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n |  \n |  set_output(self, *, transform=None)\n |      Set output container.\n |      \n |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n |      for an example on how to use the API.\n |      \n |      Parameters\n |      ----------\n |      transform : {\"default\", \"pandas\"}, default=None\n |          Configure output of `transform` and `fit_transform`.\n |      \n |          - `\"default\"`: Default output format of a transformer\n |          - `\"pandas\"`: DataFrame output\n |          - `None`: Transform configuration is unchanged\n |      \n |      Returns\n |      -------\n |      self : estimator instance\n |          Estimator instance.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n |  \n |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs) from abc.ABCMeta\n |      This method is called when a class is subclassed.\n |      \n |      The default implementation does nothing. It may be\n |      overridden to extend subclasses.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.base.BaseEstimator:\n |  \n |  __getstate__(self)\n |  \n |  __repr__(self, N_CHAR_MAX=700)\n |      Return repr(self).\n |  \n |  __setstate__(self, state)\n |  \n |  get_params(self, deep=True)\n |      Get parameters for this estimator.\n |      \n |      Parameters\n |      ----------\n |      deep : bool, default=True\n |          If True, will return the parameters for this estimator and\n |          contained subobjects that are estimators.\n |      \n |      Returns\n |      -------\n |      params : dict\n |          Parameter names mapped to their values.\n |  \n |  set_params(self, **params)\n |      Set the parameters of this estimator.\n |      \n |      The method works on simple estimators as well as on nested objects\n |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n |      parameters of the form ``&lt;component&gt;__&lt;parameter&gt;`` so that it's\n |      possible to update each component of a nested object.\n |      \n |      Parameters\n |      ----------\n |      **params : dict\n |          Estimator parameters.\n |      \n |      Returns\n |      -------\n |      self : estimator instance\n |          Estimator instance.\n\n\n\n\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()\n\n\n\n\n\n\n\n\n\nwcss\n\n[269981.28,\n 181363.59595959593,\n 106348.37306211122,\n 73679.78903948836,\n 44448.4554479337,\n 37233.814510710006,\n 30259.65720728547,\n 25011.839349156588,\n 21862.092672182895,\n 19672.072849014323]\n\n\nWithin-Cluster Sum-of-Squares criterion:\n\\(\\sum_{i=0}^{n}\\min_{\\mu_j \\in C}(||x_i - \\mu_j||^2)\\)\nsource:\n[1] https://scikit-learn.org/stable/modules/clustering.html#k-means\n[2] https://stats.stackexchange.com/questions/158210/k-means-why-minimizing-wcss-is-maximizing-distance-between-clusters\n\n\n\nNilai Silhouette mengukur seberapa mirip sebuah titik dengan klasternya sendiri (kohesi) dibandingkan dengan klaster lain (pemisahan).\nKisaran nilai Silhouette adalah antara +1 dan -1. Nilai yang tinggi diinginkan dan mengindikasikan bahwa titik tersebut ditempatkan pada klaster yang benar. Jika banyak titik yang memiliki nilai Silhouette negatif, hal ini dapat mengindikasikan bahwa kita telah membuat terlalu banyak atau terlalu sedikit cluster.\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\nsource: https://medium.com/analytics-vidhya/how-to-determine-the-optimal-k-for-k-means-708505d204eb\n\nimport sklearn.metrics as metrics\nfor i in range(2,11):\n  labels=KMeans(n_clusters=i,random_state=200).fit(X).labels_\n  print (\"Silhouette score for k(clusters) = \"+str(i)+\" is \"+str(metrics.silhouette_score(X,labels,metric=\"euclidean\",sample_size=1000,random_state=200)))\n\nSilhouette score for k(clusters) = 2 is 0.2968969162503008\nSilhouette score for k(clusters) = 3 is 0.46761358158775423\nSilhouette score for k(clusters) = 4 is 0.4931963109249047\nSilhouette score for k(clusters) = 5 is 0.553931997444648\nSilhouette score for k(clusters) = 6 is 0.5379675585622219\nSilhouette score for k(clusters) = 7 is 0.5367379891273258\nSilhouette score for k(clusters) = 8 is 0.4592958445675391\nSilhouette score for k(clusters) = 9 is 0.45770857148861777\nSilhouette score for k(clusters) = 10 is 0.446735677440187\n\n\n\n\n\n\nkmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(X)\n\n\n\n\n\nplt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nkmeans.cluster_centers_\n\narray([[55.2962963 , 49.51851852],\n       [88.2       , 17.11428571],\n       [26.30434783, 20.91304348],\n       [25.72727273, 79.36363636],\n       [86.53846154, 82.12820513]])\n\n\n\nkmeans.labels_\n\narray([2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3,\n       2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 0,\n       2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 4, 0, 4, 1, 4, 1, 4,\n       0, 4, 1, 4, 1, 4, 1, 4, 1, 4, 0, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4,\n       1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4,\n       1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4,\n       1, 4], dtype=int32)\n\n\n\n\n\n\n\n\n\nimport scipy.cluster.hierarchy as sch\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))\nplt.title('Dendrogram')\nplt.xlabel('Customers')\nplt.ylabel('Euclidean distances')\nplt.show()\n\n\n\n\n\n\n\n\n\nhelp(sch.linkage)\n\nHelp on function linkage in module scipy.cluster.hierarchy:\n\nlinkage(y, method='single', metric='euclidean', optimal_ordering=False)\n    Perform hierarchical/agglomerative clustering.\n    \n    The input y may be either a 1-D condensed distance matrix\n    or a 2-D array of observation vectors.\n    \n    If y is a 1-D condensed distance matrix,\n    then y must be a :math:`\\binom{n}{2}` sized\n    vector, where n is the number of original observations paired\n    in the distance matrix. The behavior of this function is very\n    similar to the MATLAB linkage function.\n    \n    A :math:`(n-1)` by 4 matrix ``Z`` is returned. At the\n    :math:`i`-th iteration, clusters with indices ``Z[i, 0]`` and\n    ``Z[i, 1]`` are combined to form cluster :math:`n + i`. A\n    cluster with an index less than :math:`n` corresponds to one of\n    the :math:`n` original observations. The distance between\n    clusters ``Z[i, 0]`` and ``Z[i, 1]`` is given by ``Z[i, 2]``. The\n    fourth value ``Z[i, 3]`` represents the number of original\n    observations in the newly formed cluster.\n    \n    The following linkage methods are used to compute the distance\n    :math:`d(s, t)` between two clusters :math:`s` and\n    :math:`t`. The algorithm begins with a forest of clusters that\n    have yet to be used in the hierarchy being formed. When two\n    clusters :math:`s` and :math:`t` from this forest are combined\n    into a single cluster :math:`u`, :math:`s` and :math:`t` are\n    removed from the forest, and :math:`u` is added to the\n    forest. When only one cluster remains in the forest, the algorithm\n    stops, and this cluster becomes the root.\n    \n    A distance matrix is maintained at each iteration. The ``d[i,j]``\n    entry corresponds to the distance between cluster :math:`i` and\n    :math:`j` in the original forest.\n    \n    At each iteration, the algorithm must update the distance matrix\n    to reflect the distance of the newly formed cluster u with the\n    remaining clusters in the forest.\n    \n    Suppose there are :math:`|u|` original observations\n    :math:`u[0], \\ldots, u[|u|-1]` in cluster :math:`u` and\n    :math:`|v|` original objects :math:`v[0], \\ldots, v[|v|-1]` in\n    cluster :math:`v`. Recall, :math:`s` and :math:`t` are\n    combined to form cluster :math:`u`. Let :math:`v` be any\n    remaining cluster in the forest that is not :math:`u`.\n    \n    The following are methods for calculating the distance between the\n    newly formed cluster :math:`u` and each :math:`v`.\n    \n      * method='single' assigns\n    \n        .. math::\n           d(u,v) = \\min(dist(u[i],v[j]))\n    \n        for all points :math:`i` in cluster :math:`u` and\n        :math:`j` in cluster :math:`v`. This is also known as the\n        Nearest Point Algorithm.\n    \n      * method='complete' assigns\n    \n        .. math::\n           d(u, v) = \\max(dist(u[i],v[j]))\n    \n        for all points :math:`i` in cluster u and :math:`j` in\n        cluster :math:`v`. This is also known by the Farthest Point\n        Algorithm or Voor Hees Algorithm.\n    \n      * method='average' assigns\n    \n        .. math::\n           d(u,v) = \\sum_{ij} \\frac{d(u[i], v[j])}\n                                   {(|u|*|v|)}\n    \n        for all points :math:`i` and :math:`j` where :math:`|u|`\n        and :math:`|v|` are the cardinalities of clusters :math:`u`\n        and :math:`v`, respectively. This is also called the UPGMA\n        algorithm.\n    \n      * method='weighted' assigns\n    \n        .. math::\n           d(u,v) = (dist(s,v) + dist(t,v))/2\n    \n        where cluster u was formed with cluster s and t and v\n        is a remaining cluster in the forest (also called WPGMA).\n    \n      * method='centroid' assigns\n    \n        .. math::\n           dist(s,t) = ||c_s-c_t||_2\n    \n        where :math:`c_s` and :math:`c_t` are the centroids of\n        clusters :math:`s` and :math:`t`, respectively. When two\n        clusters :math:`s` and :math:`t` are combined into a new\n        cluster :math:`u`, the new centroid is computed over all the\n        original objects in clusters :math:`s` and :math:`t`. The\n        distance then becomes the Euclidean distance between the\n        centroid of :math:`u` and the centroid of a remaining cluster\n        :math:`v` in the forest. This is also known as the UPGMC\n        algorithm.\n    \n      * method='median' assigns :math:`d(s,t)` like the ``centroid``\n        method. When two clusters :math:`s` and :math:`t` are combined\n        into a new cluster :math:`u`, the average of centroids s and t\n        give the new centroid :math:`u`. This is also known as the\n        WPGMC algorithm.\n    \n      * method='ward' uses the Ward variance minimization algorithm.\n        The new entry :math:`d(u,v)` is computed as follows,\n    \n        .. math::\n    \n           d(u,v) = \\sqrt{\\frac{|v|+|s|}\n                               {T}d(v,s)^2\n                        + \\frac{|v|+|t|}\n                               {T}d(v,t)^2\n                        - \\frac{|v|}\n                               {T}d(s,t)^2}\n    \n        where :math:`u` is the newly joined cluster consisting of\n        clusters :math:`s` and :math:`t`, :math:`v` is an unused\n        cluster in the forest, :math:`T=|v|+|s|+|t|`, and\n        :math:`|*|` is the cardinality of its argument. This is also\n        known as the incremental algorithm.\n    \n    Warning: When the minimum distance pair in the forest is chosen, there\n    may be two or more pairs with the same minimum distance. This\n    implementation may choose a different minimum than the MATLAB\n    version.\n    \n    Parameters\n    ----------\n    y : ndarray\n        A condensed distance matrix. A condensed distance matrix\n        is a flat array containing the upper triangular of the distance matrix.\n        This is the form that ``pdist`` returns. Alternatively, a collection of\n        :math:`m` observation vectors in :math:`n` dimensions may be passed as\n        an :math:`m` by :math:`n` array. All elements of the condensed distance\n        matrix must be finite, i.e., no NaNs or infs.\n    method : str, optional\n        The linkage algorithm to use. See the ``Linkage Methods`` section below\n        for full descriptions.\n    metric : str or function, optional\n        The distance metric to use in the case that y is a collection of\n        observation vectors; ignored otherwise. See the ``pdist``\n        function for a list of valid distance metrics. A custom distance\n        function can also be used.\n    optimal_ordering : bool, optional\n        If True, the linkage matrix will be reordered so that the distance\n        between successive leaves is minimal. This results in a more intuitive\n        tree structure when the data are visualized. defaults to False, because\n        this algorithm can be slow, particularly on large datasets [2]_. See\n        also the `optimal_leaf_ordering` function.\n    \n        .. versionadded:: 1.0.0\n    \n    Returns\n    -------\n    Z : ndarray\n        The hierarchical clustering encoded as a linkage matrix.\n    \n    Notes\n    -----\n    1. For method 'single', an optimized algorithm based on minimum spanning\n       tree is implemented. It has time complexity :math:`O(n^2)`.\n       For methods 'complete', 'average', 'weighted' and 'ward', an algorithm\n       called nearest-neighbors chain is implemented. It also has time\n       complexity :math:`O(n^2)`.\n       For other methods, a naive algorithm is implemented with :math:`O(n^3)`\n       time complexity.\n       All algorithms use :math:`O(n^2)` memory.\n       Refer to [1]_ for details about the algorithms.\n    2. Methods 'centroid', 'median', and 'ward' are correctly defined only if\n       Euclidean pairwise metric is used. If `y` is passed as precomputed\n       pairwise distances, then it is the user's responsibility to assure that\n       these distances are in fact Euclidean, otherwise the produced result\n       will be incorrect.\n    \n    See Also\n    --------\n    scipy.spatial.distance.pdist : pairwise distance metrics\n    \n    References\n    ----------\n    .. [1] Daniel Mullner, \"Modern hierarchical, agglomerative clustering\n           algorithms\", :arXiv:`1109.2378v1`.\n    .. [2] Ziv Bar-Joseph, David K. Gifford, Tommi S. Jaakkola, \"Fast optimal\n           leaf ordering for hierarchical clustering\", 2001. Bioinformatics\n           :doi:`10.1093/bioinformatics/17.suppl_1.S22`\n    \n    Examples\n    --------\n    &gt;&gt;&gt; from scipy.cluster.hierarchy import dendrogram, linkage\n    &gt;&gt;&gt; from matplotlib import pyplot as plt\n    &gt;&gt;&gt; X = [[i] for i in [2, 8, 0, 4, 1, 9, 9, 0]]\n    \n    &gt;&gt;&gt; Z = linkage(X, 'ward')\n    &gt;&gt;&gt; fig = plt.figure(figsize=(25, 10))\n    &gt;&gt;&gt; dn = dendrogram(Z)\n    \n    &gt;&gt;&gt; Z = linkage(X, 'single')\n    &gt;&gt;&gt; fig = plt.figure(figsize=(25, 10))\n    &gt;&gt;&gt; dn = dendrogram(Z)\n    &gt;&gt;&gt; plt.show()\n\n\n\n\n\n\nHierarchical clustering adalah keluarga umum dari algoritma clustering yang membangun cluster bersarang dengan menggabungkan atau memisahkannya secara berurutan. Hirarki cluster ini direpresentasikan sebagai sebuah pohon (atau dendogram). Akar dari pohon adalah cluster unik yang mengumpulkan semua sampel, sedangkan daunnya adalah cluster yang hanya memiliki satu sampel.\nObjek AgglomerativeClustering melakukan pengelompokan hirarkis menggunakan pendekatan dari bawah ke atas: setiap pengamatan dimulai dari klasternya sendiri, dan klaster-klaster tersebut digabungkan secara berurutan. Kriteria keterkaitan menentukan metrik yang digunakan untuk strategi penggabungan:\n\nWard meminimalkan jumlah perbedaan kuadrat di dalam semua cluster. Ini adalah pendekatan yang meminimalkan varians dan dalam hal ini mirip dengan fungsi objektif k-means tetapi ditangani dengan pendekatan hirarki aglomeratif.\nMaximum atau complete linkage meminimalkan jarak maksimum antara pengamatan dari pasangan cluster.\nAverage linkage meminimalkan rata-rata jarak antara semua pengamatan dari pasangan cluster.\nSingle linkage meminimalkan jarak antara pengamatan terdekat dari pasangan cluster.\n\nAgglomerativeClustering juga dapat menskalakan ke sejumlah besar sampel ketika digunakan bersama dengan matriks konektivitas, tetapi secara komputasi mahal ketika tidak ada batasan konektivitas yang ditambahkan di antara sampel: ia mempertimbangkan pada setiap langkah semua kemungkinan penggabungan.\nsource : https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering\n\nfrom sklearn.cluster import AgglomerativeClustering\nhc = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage = 'ward')\ny_hc = hc.fit_predict(X)\n\n\n\n\n\nplt.scatter(X[y_hc == 0, 0], X[y_hc == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_hc == 1, 0], X[y_hc == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_hc == 3, 0], X[y_hc == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_hc == 4, 0], X[y_hc == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-04.html#k-means-clustering",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-04.html#k-means-clustering",
    "title": "Week 04 (Clustering)",
    "section": "",
    "text": "K-means clustering adalah algoritma unsupervised learning yang mengelompokkan dataset yang belum dilabel ke dalam kluster yang berbeda berdasarkan kesamaan tertentu\\(^{[1][2][3]}\\). K-means clustering membutuhkan nilai k yang menandakan jumlah kluster yang akan dibentuk\\(^{[1][4]}\\). K-means clustering berusaha untuk meminimalisasi variasi antar kluster dan memaksimalisasi variasi antar kluster\\(^{[2][5]}\\). K-means clustering menggunakan rata-rata dan jarak antara data dan centroid untuk menentukan kluster\\(^{[2][5]}\\). K-means clustering bekerja dengan baik jika kluster memiliki bentuk bola\\(^{[3]}\\).\nsource:\n[1] https://www.trivusi.web.id/2022/06/algoritma-kmeans-clustering.html\n[2] https://raharja.ac.id/2020/04/19/k-means-clustering/\n[3] https://ichi.pro/id/k-means-clustering-algoritma-aplikasi-metode-evaluasi-dan-kelemahan-186933724886154\n[4] https://dqlab.id/k-means-clustering-salah-satu-contoh-teknik-analisis-data-populer\n[5] https://sis.binus.ac.id/2022/01/31/clustering-algoritma-k-means/.\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n\ndataset = pd.read_csv('Mall_Customers.csv')\ndataset\n\n\n  \n    \n      \n\n\n\n\n\n\nCustomerID\nGenre\nAge\nAnnual Income (k$)\nSpending Score (1-100)\n\n\n\n\n0\n1\nMale\n19\n15\n39\n\n\n1\n2\nMale\n21\n15\n81\n\n\n2\n3\nFemale\n20\n16\n6\n\n\n3\n4\nFemale\n23\n16\n77\n\n\n4\n5\nFemale\n31\n17\n40\n\n\n...\n...\n...\n...\n...\n...\n\n\n195\n196\nFemale\n35\n120\n79\n\n\n196\n197\nFemale\n45\n126\n28\n\n\n197\n198\nMale\n32\n126\n74\n\n\n198\n199\nMale\n32\n137\n18\n\n\n199\n200\nMale\n30\n137\n83\n\n\n\n\n200 rows × 5 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nX = dataset.iloc[:, [3, 4]].values\nX\n\narray([[ 15,  39],\n       [ 15,  81],\n       [ 16,   6],\n       [ 16,  77],\n       [ 17,  40],\n       [ 17,  76],\n       [ 18,   6],\n       [ 18,  94],\n       [ 19,   3],\n       [ 19,  72],\n       [ 19,  14],\n       [ 19,  99],\n       [ 20,  15],\n       [ 20,  77],\n       [ 20,  13],\n       [ 20,  79],\n       [ 21,  35],\n       [ 21,  66],\n       [ 23,  29],\n       [ 23,  98],\n       [ 24,  35],\n       [ 24,  73],\n       [ 25,   5],\n       [ 25,  73],\n       [ 28,  14],\n       [ 28,  82],\n       [ 28,  32],\n       [ 28,  61],\n       [ 29,  31],\n       [ 29,  87],\n       [ 30,   4],\n       [ 30,  73],\n       [ 33,   4],\n       [ 33,  92],\n       [ 33,  14],\n       [ 33,  81],\n       [ 34,  17],\n       [ 34,  73],\n       [ 37,  26],\n       [ 37,  75],\n       [ 38,  35],\n       [ 38,  92],\n       [ 39,  36],\n       [ 39,  61],\n       [ 39,  28],\n       [ 39,  65],\n       [ 40,  55],\n       [ 40,  47],\n       [ 40,  42],\n       [ 40,  42],\n       [ 42,  52],\n       [ 42,  60],\n       [ 43,  54],\n       [ 43,  60],\n       [ 43,  45],\n       [ 43,  41],\n       [ 44,  50],\n       [ 44,  46],\n       [ 46,  51],\n       [ 46,  46],\n       [ 46,  56],\n       [ 46,  55],\n       [ 47,  52],\n       [ 47,  59],\n       [ 48,  51],\n       [ 48,  59],\n       [ 48,  50],\n       [ 48,  48],\n       [ 48,  59],\n       [ 48,  47],\n       [ 49,  55],\n       [ 49,  42],\n       [ 50,  49],\n       [ 50,  56],\n       [ 54,  47],\n       [ 54,  54],\n       [ 54,  53],\n       [ 54,  48],\n       [ 54,  52],\n       [ 54,  42],\n       [ 54,  51],\n       [ 54,  55],\n       [ 54,  41],\n       [ 54,  44],\n       [ 54,  57],\n       [ 54,  46],\n       [ 57,  58],\n       [ 57,  55],\n       [ 58,  60],\n       [ 58,  46],\n       [ 59,  55],\n       [ 59,  41],\n       [ 60,  49],\n       [ 60,  40],\n       [ 60,  42],\n       [ 60,  52],\n       [ 60,  47],\n       [ 60,  50],\n       [ 61,  42],\n       [ 61,  49],\n       [ 62,  41],\n       [ 62,  48],\n       [ 62,  59],\n       [ 62,  55],\n       [ 62,  56],\n       [ 62,  42],\n       [ 63,  50],\n       [ 63,  46],\n       [ 63,  43],\n       [ 63,  48],\n       [ 63,  52],\n       [ 63,  54],\n       [ 64,  42],\n       [ 64,  46],\n       [ 65,  48],\n       [ 65,  50],\n       [ 65,  43],\n       [ 65,  59],\n       [ 67,  43],\n       [ 67,  57],\n       [ 67,  56],\n       [ 67,  40],\n       [ 69,  58],\n       [ 69,  91],\n       [ 70,  29],\n       [ 70,  77],\n       [ 71,  35],\n       [ 71,  95],\n       [ 71,  11],\n       [ 71,  75],\n       [ 71,   9],\n       [ 71,  75],\n       [ 72,  34],\n       [ 72,  71],\n       [ 73,   5],\n       [ 73,  88],\n       [ 73,   7],\n       [ 73,  73],\n       [ 74,  10],\n       [ 74,  72],\n       [ 75,   5],\n       [ 75,  93],\n       [ 76,  40],\n       [ 76,  87],\n       [ 77,  12],\n       [ 77,  97],\n       [ 77,  36],\n       [ 77,  74],\n       [ 78,  22],\n       [ 78,  90],\n       [ 78,  17],\n       [ 78,  88],\n       [ 78,  20],\n       [ 78,  76],\n       [ 78,  16],\n       [ 78,  89],\n       [ 78,   1],\n       [ 78,  78],\n       [ 78,   1],\n       [ 78,  73],\n       [ 79,  35],\n       [ 79,  83],\n       [ 81,   5],\n       [ 81,  93],\n       [ 85,  26],\n       [ 85,  75],\n       [ 86,  20],\n       [ 86,  95],\n       [ 87,  27],\n       [ 87,  63],\n       [ 87,  13],\n       [ 87,  75],\n       [ 87,  10],\n       [ 87,  92],\n       [ 88,  13],\n       [ 88,  86],\n       [ 88,  15],\n       [ 88,  69],\n       [ 93,  14],\n       [ 93,  90],\n       [ 97,  32],\n       [ 97,  86],\n       [ 98,  15],\n       [ 98,  88],\n       [ 99,  39],\n       [ 99,  97],\n       [101,  24],\n       [101,  68],\n       [103,  17],\n       [103,  85],\n       [103,  23],\n       [103,  69],\n       [113,   8],\n       [113,  91],\n       [120,  16],\n       [120,  79],\n       [126,  28],\n       [126,  74],\n       [137,  18],\n       [137,  83]])\n\n\n\n\n\n\nhelp(KMeans)\n\nHelp on class KMeans in module sklearn.cluster._kmeans:\n\nclass KMeans(_BaseKMeans)\n |  KMeans(n_clusters=8, *, init='k-means++', n_init='warn', max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n |  \n |  K-Means clustering.\n |  \n |  Read more in the :ref:`User Guide &lt;k_means&gt;`.\n |  \n |  Parameters\n |  ----------\n |  \n |  n_clusters : int, default=8\n |      The number of clusters to form as well as the number of\n |      centroids to generate.\n |  \n |  init : {'k-means++', 'random'}, callable or array-like of shape             (n_clusters, n_features), default='k-means++'\n |      Method for initialization:\n |  \n |      'k-means++' : selects initial cluster centroids using sampling based on\n |      an empirical probability distribution of the points' contribution to the\n |      overall inertia. This technique speeds up convergence. The algorithm\n |      implemented is \"greedy k-means++\". It differs from the vanilla k-means++\n |      by making several trials at each sampling step and choosing the best centroid\n |      among them.\n |  \n |      'random': choose `n_clusters` observations (rows) at random from data\n |      for the initial centroids.\n |  \n |      If an array is passed, it should be of shape (n_clusters, n_features)\n |      and gives the initial centers.\n |  \n |      If a callable is passed, it should take arguments X, n_clusters and a\n |      random state and return an initialization.\n |  \n |  n_init : 'auto' or int, default=10\n |      Number of times the k-means algorithm is run with different centroid\n |      seeds. The final results is the best output of `n_init` consecutive runs\n |      in terms of inertia. Several runs are recommended for sparse\n |      high-dimensional problems (see :ref:`kmeans_sparse_high_dim`).\n |  \n |      When `n_init='auto'`, the number of runs depends on the value of init:\n |      10 if using `init='random'`, 1 if using `init='k-means++'`.\n |  \n |      .. versionadded:: 1.2\n |         Added 'auto' option for `n_init`.\n |  \n |      .. versionchanged:: 1.4\n |         Default value for `n_init` will change from 10 to `'auto'` in version 1.4.\n |  \n |  max_iter : int, default=300\n |      Maximum number of iterations of the k-means algorithm for a\n |      single run.\n |  \n |  tol : float, default=1e-4\n |      Relative tolerance with regards to Frobenius norm of the difference\n |      in the cluster centers of two consecutive iterations to declare\n |      convergence.\n |  \n |  verbose : int, default=0\n |      Verbosity mode.\n |  \n |  random_state : int, RandomState instance or None, default=None\n |      Determines random number generation for centroid initialization. Use\n |      an int to make the randomness deterministic.\n |      See :term:`Glossary &lt;random_state&gt;`.\n |  \n |  copy_x : bool, default=True\n |      When pre-computing distances it is more numerically accurate to center\n |      the data first. If copy_x is True (default), then the original data is\n |      not modified. If False, the original data is modified, and put back\n |      before the function returns, but small numerical differences may be\n |      introduced by subtracting and then adding the data mean. Note that if\n |      the original data is not C-contiguous, a copy will be made even if\n |      copy_x is False. If the original data is sparse, but not in CSR format,\n |      a copy will be made even if copy_x is False.\n |  \n |  algorithm : {\"lloyd\", \"elkan\", \"auto\", \"full\"}, default=\"lloyd\"\n |      K-means algorithm to use. The classical EM-style algorithm is `\"lloyd\"`.\n |      The `\"elkan\"` variation can be more efficient on some datasets with\n |      well-defined clusters, by using the triangle inequality. However it's\n |      more memory intensive due to the allocation of an extra array of shape\n |      `(n_samples, n_clusters)`.\n |  \n |      `\"auto\"` and `\"full\"` are deprecated and they will be removed in\n |      Scikit-Learn 1.3. They are both aliases for `\"lloyd\"`.\n |  \n |      .. versionchanged:: 0.18\n |          Added Elkan algorithm\n |  \n |      .. versionchanged:: 1.1\n |          Renamed \"full\" to \"lloyd\", and deprecated \"auto\" and \"full\".\n |          Changed \"auto\" to use \"lloyd\" instead of \"elkan\".\n |  \n |  Attributes\n |  ----------\n |  cluster_centers_ : ndarray of shape (n_clusters, n_features)\n |      Coordinates of cluster centers. If the algorithm stops before fully\n |      converging (see ``tol`` and ``max_iter``), these will not be\n |      consistent with ``labels_``.\n |  \n |  labels_ : ndarray of shape (n_samples,)\n |      Labels of each point\n |  \n |  inertia_ : float\n |      Sum of squared distances of samples to their closest cluster center,\n |      weighted by the sample weights if provided.\n |  \n |  n_iter_ : int\n |      Number of iterations run.\n |  \n |  n_features_in_ : int\n |      Number of features seen during :term:`fit`.\n |  \n |      .. versionadded:: 0.24\n |  \n |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n |      Names of features seen during :term:`fit`. Defined only when `X`\n |      has feature names that are all strings.\n |  \n |      .. versionadded:: 1.0\n |  \n |  See Also\n |  --------\n |  MiniBatchKMeans : Alternative online implementation that does incremental\n |      updates of the centers positions using mini-batches.\n |      For large scale learning (say n_samples &gt; 10k) MiniBatchKMeans is\n |      probably much faster than the default batch implementation.\n |  \n |  Notes\n |  -----\n |  The k-means problem is solved using either Lloyd's or Elkan's algorithm.\n |  \n |  The average complexity is given by O(k n T), where n is the number of\n |  samples and T is the number of iteration.\n |  \n |  The worst case complexity is given by O(n^(k+2/p)) with\n |  n = n_samples, p = n_features.\n |  Refer to :doi:`\"How slow is the k-means method?\" D. Arthur and S. Vassilvitskii -\n |  SoCG2006.&lt;10.1145/1137856.1137880&gt;` for more details.\n |  \n |  In practice, the k-means algorithm is very fast (one of the fastest\n |  clustering algorithms available), but it falls in local minima. That's why\n |  it can be useful to restart it several times.\n |  \n |  If the algorithm stops before fully converging (because of ``tol`` or\n |  ``max_iter``), ``labels_`` and ``cluster_centers_`` will not be consistent,\n |  i.e. the ``cluster_centers_`` will not be the means of the points in each\n |  cluster. Also, the estimator will reassign ``labels_`` after the last\n |  iteration to make ``labels_`` consistent with ``predict`` on the training\n |  set.\n |  \n |  Examples\n |  --------\n |  \n |  &gt;&gt;&gt; from sklearn.cluster import KMeans\n |  &gt;&gt;&gt; import numpy as np\n |  &gt;&gt;&gt; X = np.array([[1, 2], [1, 4], [1, 0],\n |  ...               [10, 2], [10, 4], [10, 0]])\n |  &gt;&gt;&gt; kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(X)\n |  &gt;&gt;&gt; kmeans.labels_\n |  array([1, 1, 1, 0, 0, 0], dtype=int32)\n |  &gt;&gt;&gt; kmeans.predict([[0, 0], [12, 3]])\n |  array([1, 0], dtype=int32)\n |  &gt;&gt;&gt; kmeans.cluster_centers_\n |  array([[10.,  2.],\n |         [ 1.,  2.]])\n |  \n |  Method resolution order:\n |      KMeans\n |      _BaseKMeans\n |      sklearn.base.ClassNamePrefixFeaturesOutMixin\n |      sklearn.base.TransformerMixin\n |      sklearn.utils._set_output._SetOutputMixin\n |      sklearn.base.ClusterMixin\n |      sklearn.base.BaseEstimator\n |      abc.ABC\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, n_clusters=8, *, init='k-means++', n_init='warn', max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  fit(self, X, y=None, sample_weight=None)\n |      Compute k-means clustering.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          Training instances to cluster. It must be noted that the data\n |          will be converted to C ordering, which will cause a memory\n |          copy if the given data is not C-contiguous.\n |          If a sparse matrix is passed, a copy will be made if it's not in\n |          CSR format.\n |      \n |      y : Ignored\n |          Not used, present here for API consistency by convention.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          The weights for each observation in X. If None, all observations\n |          are assigned equal weight.\n |      \n |          .. versionadded:: 0.20\n |      \n |      Returns\n |      -------\n |      self : object\n |          Fitted estimator.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __abstractmethods__ = frozenset()\n |  \n |  __annotations__ = {'_parameter_constraints': &lt;class 'dict'&gt;}\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from _BaseKMeans:\n |  \n |  fit_predict(self, X, y=None, sample_weight=None)\n |      Compute cluster centers and predict cluster index for each sample.\n |      \n |      Convenience method; equivalent to calling fit(X) followed by\n |      predict(X).\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          New data to transform.\n |      \n |      y : Ignored\n |          Not used, present here for API consistency by convention.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          The weights for each observation in X. If None, all observations\n |          are assigned equal weight.\n |      \n |      Returns\n |      -------\n |      labels : ndarray of shape (n_samples,)\n |          Index of the cluster each sample belongs to.\n |  \n |  fit_transform(self, X, y=None, sample_weight=None)\n |      Compute clustering and transform X to cluster-distance space.\n |      \n |      Equivalent to fit(X).transform(X), but more efficiently implemented.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          New data to transform.\n |      \n |      y : Ignored\n |          Not used, present here for API consistency by convention.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          The weights for each observation in X. If None, all observations\n |          are assigned equal weight.\n |      \n |      Returns\n |      -------\n |      X_new : ndarray of shape (n_samples, n_clusters)\n |          X transformed in the new space.\n |  \n |  predict(self, X, sample_weight=None)\n |      Predict the closest cluster each sample in X belongs to.\n |      \n |      In the vector quantization literature, `cluster_centers_` is called\n |      the code book and each value returned by `predict` is the index of\n |      the closest code in the code book.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          New data to predict.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          The weights for each observation in X. If None, all observations\n |          are assigned equal weight.\n |      \n |      Returns\n |      -------\n |      labels : ndarray of shape (n_samples,)\n |          Index of the cluster each sample belongs to.\n |  \n |  score(self, X, y=None, sample_weight=None)\n |      Opposite of the value of X on the K-means objective.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          New data.\n |      \n |      y : Ignored\n |          Not used, present here for API consistency by convention.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          The weights for each observation in X. If None, all observations\n |          are assigned equal weight.\n |      \n |      Returns\n |      -------\n |      score : float\n |          Opposite of the value of X on the K-means objective.\n |  \n |  transform(self, X)\n |      Transform X to a cluster-distance space.\n |      \n |      In the new space, each dimension is the distance to the cluster\n |      centers. Note that even if X is sparse, the array returned by\n |      `transform` will typically be dense.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          New data to transform.\n |      \n |      Returns\n |      -------\n |      X_new : ndarray of shape (n_samples, n_clusters)\n |          X transformed in the new space.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.base.ClassNamePrefixFeaturesOutMixin:\n |  \n |  get_feature_names_out(self, input_features=None)\n |      Get output feature names for transformation.\n |      \n |      The feature names out will prefixed by the lowercased class name. For\n |      example, if the transformer outputs 3 features, then the feature names\n |      out are: `[\"class_name0\", \"class_name1\", \"class_name2\"]`.\n |      \n |      Parameters\n |      ----------\n |      input_features : array-like of str or None, default=None\n |          Only used to validate feature names with the names seen in :meth:`fit`.\n |      \n |      Returns\n |      -------\n |      feature_names_out : ndarray of str objects\n |          Transformed feature names.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from sklearn.base.ClassNamePrefixFeaturesOutMixin:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n |  \n |  set_output(self, *, transform=None)\n |      Set output container.\n |      \n |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n |      for an example on how to use the API.\n |      \n |      Parameters\n |      ----------\n |      transform : {\"default\", \"pandas\"}, default=None\n |          Configure output of `transform` and `fit_transform`.\n |      \n |          - `\"default\"`: Default output format of a transformer\n |          - `\"pandas\"`: DataFrame output\n |          - `None`: Transform configuration is unchanged\n |      \n |      Returns\n |      -------\n |      self : estimator instance\n |          Estimator instance.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n |  \n |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs) from abc.ABCMeta\n |      This method is called when a class is subclassed.\n |      \n |      The default implementation does nothing. It may be\n |      overridden to extend subclasses.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.base.BaseEstimator:\n |  \n |  __getstate__(self)\n |  \n |  __repr__(self, N_CHAR_MAX=700)\n |      Return repr(self).\n |  \n |  __setstate__(self, state)\n |  \n |  get_params(self, deep=True)\n |      Get parameters for this estimator.\n |      \n |      Parameters\n |      ----------\n |      deep : bool, default=True\n |          If True, will return the parameters for this estimator and\n |          contained subobjects that are estimators.\n |      \n |      Returns\n |      -------\n |      params : dict\n |          Parameter names mapped to their values.\n |  \n |  set_params(self, **params)\n |      Set the parameters of this estimator.\n |      \n |      The method works on simple estimators as well as on nested objects\n |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n |      parameters of the form ``&lt;component&gt;__&lt;parameter&gt;`` so that it's\n |      possible to update each component of a nested object.\n |      \n |      Parameters\n |      ----------\n |      **params : dict\n |          Estimator parameters.\n |      \n |      Returns\n |      -------\n |      self : estimator instance\n |          Estimator instance.\n\n\n\n\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()\n\n\n\n\n\n\n\n\n\nwcss\n\n[269981.28,\n 181363.59595959593,\n 106348.37306211122,\n 73679.78903948836,\n 44448.4554479337,\n 37233.814510710006,\n 30259.65720728547,\n 25011.839349156588,\n 21862.092672182895,\n 19672.072849014323]\n\n\nWithin-Cluster Sum-of-Squares criterion:\n\\(\\sum_{i=0}^{n}\\min_{\\mu_j \\in C}(||x_i - \\mu_j||^2)\\)\nsource:\n[1] https://scikit-learn.org/stable/modules/clustering.html#k-means\n[2] https://stats.stackexchange.com/questions/158210/k-means-why-minimizing-wcss-is-maximizing-distance-between-clusters\n\n\n\nNilai Silhouette mengukur seberapa mirip sebuah titik dengan klasternya sendiri (kohesi) dibandingkan dengan klaster lain (pemisahan).\nKisaran nilai Silhouette adalah antara +1 dan -1. Nilai yang tinggi diinginkan dan mengindikasikan bahwa titik tersebut ditempatkan pada klaster yang benar. Jika banyak titik yang memiliki nilai Silhouette negatif, hal ini dapat mengindikasikan bahwa kita telah membuat terlalu banyak atau terlalu sedikit cluster.\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\nsource: https://medium.com/analytics-vidhya/how-to-determine-the-optimal-k-for-k-means-708505d204eb\n\nimport sklearn.metrics as metrics\nfor i in range(2,11):\n  labels=KMeans(n_clusters=i,random_state=200).fit(X).labels_\n  print (\"Silhouette score for k(clusters) = \"+str(i)+\" is \"+str(metrics.silhouette_score(X,labels,metric=\"euclidean\",sample_size=1000,random_state=200)))\n\nSilhouette score for k(clusters) = 2 is 0.2968969162503008\nSilhouette score for k(clusters) = 3 is 0.46761358158775423\nSilhouette score for k(clusters) = 4 is 0.4931963109249047\nSilhouette score for k(clusters) = 5 is 0.553931997444648\nSilhouette score for k(clusters) = 6 is 0.5379675585622219\nSilhouette score for k(clusters) = 7 is 0.5367379891273258\nSilhouette score for k(clusters) = 8 is 0.4592958445675391\nSilhouette score for k(clusters) = 9 is 0.45770857148861777\nSilhouette score for k(clusters) = 10 is 0.446735677440187\n\n\n\n\n\n\nkmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(X)\n\n\n\n\n\nplt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nkmeans.cluster_centers_\n\narray([[55.2962963 , 49.51851852],\n       [88.2       , 17.11428571],\n       [26.30434783, 20.91304348],\n       [25.72727273, 79.36363636],\n       [86.53846154, 82.12820513]])\n\n\n\nkmeans.labels_\n\narray([2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3,\n       2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 0,\n       2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 4, 0, 4, 1, 4, 1, 4,\n       0, 4, 1, 4, 1, 4, 1, 4, 1, 4, 0, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4,\n       1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4,\n       1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4,\n       1, 4], dtype=int32)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-04.html#hierarchical-clustering",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-04.html#hierarchical-clustering",
    "title": "Week 04 (Clustering)",
    "section": "",
    "text": "import scipy.cluster.hierarchy as sch\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))\nplt.title('Dendrogram')\nplt.xlabel('Customers')\nplt.ylabel('Euclidean distances')\nplt.show()\n\n\n\n\n\n\n\n\n\nhelp(sch.linkage)\n\nHelp on function linkage in module scipy.cluster.hierarchy:\n\nlinkage(y, method='single', metric='euclidean', optimal_ordering=False)\n    Perform hierarchical/agglomerative clustering.\n    \n    The input y may be either a 1-D condensed distance matrix\n    or a 2-D array of observation vectors.\n    \n    If y is a 1-D condensed distance matrix,\n    then y must be a :math:`\\binom{n}{2}` sized\n    vector, where n is the number of original observations paired\n    in the distance matrix. The behavior of this function is very\n    similar to the MATLAB linkage function.\n    \n    A :math:`(n-1)` by 4 matrix ``Z`` is returned. At the\n    :math:`i`-th iteration, clusters with indices ``Z[i, 0]`` and\n    ``Z[i, 1]`` are combined to form cluster :math:`n + i`. A\n    cluster with an index less than :math:`n` corresponds to one of\n    the :math:`n` original observations. The distance between\n    clusters ``Z[i, 0]`` and ``Z[i, 1]`` is given by ``Z[i, 2]``. The\n    fourth value ``Z[i, 3]`` represents the number of original\n    observations in the newly formed cluster.\n    \n    The following linkage methods are used to compute the distance\n    :math:`d(s, t)` between two clusters :math:`s` and\n    :math:`t`. The algorithm begins with a forest of clusters that\n    have yet to be used in the hierarchy being formed. When two\n    clusters :math:`s` and :math:`t` from this forest are combined\n    into a single cluster :math:`u`, :math:`s` and :math:`t` are\n    removed from the forest, and :math:`u` is added to the\n    forest. When only one cluster remains in the forest, the algorithm\n    stops, and this cluster becomes the root.\n    \n    A distance matrix is maintained at each iteration. The ``d[i,j]``\n    entry corresponds to the distance between cluster :math:`i` and\n    :math:`j` in the original forest.\n    \n    At each iteration, the algorithm must update the distance matrix\n    to reflect the distance of the newly formed cluster u with the\n    remaining clusters in the forest.\n    \n    Suppose there are :math:`|u|` original observations\n    :math:`u[0], \\ldots, u[|u|-1]` in cluster :math:`u` and\n    :math:`|v|` original objects :math:`v[0], \\ldots, v[|v|-1]` in\n    cluster :math:`v`. Recall, :math:`s` and :math:`t` are\n    combined to form cluster :math:`u`. Let :math:`v` be any\n    remaining cluster in the forest that is not :math:`u`.\n    \n    The following are methods for calculating the distance between the\n    newly formed cluster :math:`u` and each :math:`v`.\n    \n      * method='single' assigns\n    \n        .. math::\n           d(u,v) = \\min(dist(u[i],v[j]))\n    \n        for all points :math:`i` in cluster :math:`u` and\n        :math:`j` in cluster :math:`v`. This is also known as the\n        Nearest Point Algorithm.\n    \n      * method='complete' assigns\n    \n        .. math::\n           d(u, v) = \\max(dist(u[i],v[j]))\n    \n        for all points :math:`i` in cluster u and :math:`j` in\n        cluster :math:`v`. This is also known by the Farthest Point\n        Algorithm or Voor Hees Algorithm.\n    \n      * method='average' assigns\n    \n        .. math::\n           d(u,v) = \\sum_{ij} \\frac{d(u[i], v[j])}\n                                   {(|u|*|v|)}\n    \n        for all points :math:`i` and :math:`j` where :math:`|u|`\n        and :math:`|v|` are the cardinalities of clusters :math:`u`\n        and :math:`v`, respectively. This is also called the UPGMA\n        algorithm.\n    \n      * method='weighted' assigns\n    \n        .. math::\n           d(u,v) = (dist(s,v) + dist(t,v))/2\n    \n        where cluster u was formed with cluster s and t and v\n        is a remaining cluster in the forest (also called WPGMA).\n    \n      * method='centroid' assigns\n    \n        .. math::\n           dist(s,t) = ||c_s-c_t||_2\n    \n        where :math:`c_s` and :math:`c_t` are the centroids of\n        clusters :math:`s` and :math:`t`, respectively. When two\n        clusters :math:`s` and :math:`t` are combined into a new\n        cluster :math:`u`, the new centroid is computed over all the\n        original objects in clusters :math:`s` and :math:`t`. The\n        distance then becomes the Euclidean distance between the\n        centroid of :math:`u` and the centroid of a remaining cluster\n        :math:`v` in the forest. This is also known as the UPGMC\n        algorithm.\n    \n      * method='median' assigns :math:`d(s,t)` like the ``centroid``\n        method. When two clusters :math:`s` and :math:`t` are combined\n        into a new cluster :math:`u`, the average of centroids s and t\n        give the new centroid :math:`u`. This is also known as the\n        WPGMC algorithm.\n    \n      * method='ward' uses the Ward variance minimization algorithm.\n        The new entry :math:`d(u,v)` is computed as follows,\n    \n        .. math::\n    \n           d(u,v) = \\sqrt{\\frac{|v|+|s|}\n                               {T}d(v,s)^2\n                        + \\frac{|v|+|t|}\n                               {T}d(v,t)^2\n                        - \\frac{|v|}\n                               {T}d(s,t)^2}\n    \n        where :math:`u` is the newly joined cluster consisting of\n        clusters :math:`s` and :math:`t`, :math:`v` is an unused\n        cluster in the forest, :math:`T=|v|+|s|+|t|`, and\n        :math:`|*|` is the cardinality of its argument. This is also\n        known as the incremental algorithm.\n    \n    Warning: When the minimum distance pair in the forest is chosen, there\n    may be two or more pairs with the same minimum distance. This\n    implementation may choose a different minimum than the MATLAB\n    version.\n    \n    Parameters\n    ----------\n    y : ndarray\n        A condensed distance matrix. A condensed distance matrix\n        is a flat array containing the upper triangular of the distance matrix.\n        This is the form that ``pdist`` returns. Alternatively, a collection of\n        :math:`m` observation vectors in :math:`n` dimensions may be passed as\n        an :math:`m` by :math:`n` array. All elements of the condensed distance\n        matrix must be finite, i.e., no NaNs or infs.\n    method : str, optional\n        The linkage algorithm to use. See the ``Linkage Methods`` section below\n        for full descriptions.\n    metric : str or function, optional\n        The distance metric to use in the case that y is a collection of\n        observation vectors; ignored otherwise. See the ``pdist``\n        function for a list of valid distance metrics. A custom distance\n        function can also be used.\n    optimal_ordering : bool, optional\n        If True, the linkage matrix will be reordered so that the distance\n        between successive leaves is minimal. This results in a more intuitive\n        tree structure when the data are visualized. defaults to False, because\n        this algorithm can be slow, particularly on large datasets [2]_. See\n        also the `optimal_leaf_ordering` function.\n    \n        .. versionadded:: 1.0.0\n    \n    Returns\n    -------\n    Z : ndarray\n        The hierarchical clustering encoded as a linkage matrix.\n    \n    Notes\n    -----\n    1. For method 'single', an optimized algorithm based on minimum spanning\n       tree is implemented. It has time complexity :math:`O(n^2)`.\n       For methods 'complete', 'average', 'weighted' and 'ward', an algorithm\n       called nearest-neighbors chain is implemented. It also has time\n       complexity :math:`O(n^2)`.\n       For other methods, a naive algorithm is implemented with :math:`O(n^3)`\n       time complexity.\n       All algorithms use :math:`O(n^2)` memory.\n       Refer to [1]_ for details about the algorithms.\n    2. Methods 'centroid', 'median', and 'ward' are correctly defined only if\n       Euclidean pairwise metric is used. If `y` is passed as precomputed\n       pairwise distances, then it is the user's responsibility to assure that\n       these distances are in fact Euclidean, otherwise the produced result\n       will be incorrect.\n    \n    See Also\n    --------\n    scipy.spatial.distance.pdist : pairwise distance metrics\n    \n    References\n    ----------\n    .. [1] Daniel Mullner, \"Modern hierarchical, agglomerative clustering\n           algorithms\", :arXiv:`1109.2378v1`.\n    .. [2] Ziv Bar-Joseph, David K. Gifford, Tommi S. Jaakkola, \"Fast optimal\n           leaf ordering for hierarchical clustering\", 2001. Bioinformatics\n           :doi:`10.1093/bioinformatics/17.suppl_1.S22`\n    \n    Examples\n    --------\n    &gt;&gt;&gt; from scipy.cluster.hierarchy import dendrogram, linkage\n    &gt;&gt;&gt; from matplotlib import pyplot as plt\n    &gt;&gt;&gt; X = [[i] for i in [2, 8, 0, 4, 1, 9, 9, 0]]\n    \n    &gt;&gt;&gt; Z = linkage(X, 'ward')\n    &gt;&gt;&gt; fig = plt.figure(figsize=(25, 10))\n    &gt;&gt;&gt; dn = dendrogram(Z)\n    \n    &gt;&gt;&gt; Z = linkage(X, 'single')\n    &gt;&gt;&gt; fig = plt.figure(figsize=(25, 10))\n    &gt;&gt;&gt; dn = dendrogram(Z)\n    &gt;&gt;&gt; plt.show()\n\n\n\n\n\n\nHierarchical clustering adalah keluarga umum dari algoritma clustering yang membangun cluster bersarang dengan menggabungkan atau memisahkannya secara berurutan. Hirarki cluster ini direpresentasikan sebagai sebuah pohon (atau dendogram). Akar dari pohon adalah cluster unik yang mengumpulkan semua sampel, sedangkan daunnya adalah cluster yang hanya memiliki satu sampel.\nObjek AgglomerativeClustering melakukan pengelompokan hirarkis menggunakan pendekatan dari bawah ke atas: setiap pengamatan dimulai dari klasternya sendiri, dan klaster-klaster tersebut digabungkan secara berurutan. Kriteria keterkaitan menentukan metrik yang digunakan untuk strategi penggabungan:\n\nWard meminimalkan jumlah perbedaan kuadrat di dalam semua cluster. Ini adalah pendekatan yang meminimalkan varians dan dalam hal ini mirip dengan fungsi objektif k-means tetapi ditangani dengan pendekatan hirarki aglomeratif.\nMaximum atau complete linkage meminimalkan jarak maksimum antara pengamatan dari pasangan cluster.\nAverage linkage meminimalkan rata-rata jarak antara semua pengamatan dari pasangan cluster.\nSingle linkage meminimalkan jarak antara pengamatan terdekat dari pasangan cluster.\n\nAgglomerativeClustering juga dapat menskalakan ke sejumlah besar sampel ketika digunakan bersama dengan matriks konektivitas, tetapi secara komputasi mahal ketika tidak ada batasan konektivitas yang ditambahkan di antara sampel: ia mempertimbangkan pada setiap langkah semua kemungkinan penggabungan.\nsource : https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering\n\nfrom sklearn.cluster import AgglomerativeClustering\nhc = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage = 'ward')\ny_hc = hc.fit_predict(X)\n\n\n\n\n\nplt.scatter(X[y_hc == 0, 0], X[y_hc == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_hc == 1, 0], X[y_hc == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_hc == 3, 0], X[y_hc == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_hc == 4, 0], X[y_hc == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html",
    "title": "Week-06 (NN with Keras and Hyperparameter Tuning with Keras-Tuner)",
    "section": "",
    "text": "Kembali ke Sains Data\nPada modul kali ini kita akan mempelajari lebih lanjut implementasi Neural Network menggunakan Keras API serta cara melakukan hyperparameter tuning menggunakan library Keras-Tuner.\nPenjelasan modul serta code pada modul ini akan dibahas lengkap pada sesi praktikum. Penjelasan pada notebook ini hanyalah ringkasan singkat.\n\n\n\n!pip install keras-tuner\nimport tensorflow as tf\nimport keras_tuner as kt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import fetch_california_housing\nimport matplotlib.pyplot as plt\n\nLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nCollecting keras-tuner\n  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 176.1/176.1 kB 7.5 MB/s eta 0:00:00\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.27.1)\nCollecting kt-legacy\n  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (3.4)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (2.0.12)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (1.26.15)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (2022.12.7)\nInstalling collected packages: kt-legacy, keras-tuner\nSuccessfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n\n\n\n\n\nKeras memiliki tiga macam API yang dapat digunakan, yaitu Sequential, Functional, dan Subclassing. Ketiganya memiliki kelebihan dan kekurangan masing-masing, terutama di sisi kemudahan dan fleksibilitas.\nSequential API merupakan API yang sangat mudah dipahami bagi semua orang yang ingin mempelajari deep learning, tetapi Sequential tidak cukup fleksibel dalam membuat arsitektur model tingkat lanjut karena sifatnya yang mengharuskan tiap layer terhubung satu sama lain dari input hingga output.\nFunctional API merupakan API yang juga cukup mudah dipahami (sedikit lebih kompleks dibandingkan Sequential), tetapi cukup fleksibel dalam mengimplementasikan beragam arsitektur model.\nSubclassing API merupakan API yang cukup sulit dipahami bagi orang yang baru ingin mempelajari deep learning, tetapi di sisi lain API ini merupakan API terfleksibel pada Keras.\nPada modul ini, hanya akan dibahas Sequential dan Functional API.\nPertama, kita akan membuat dua macam model untuk mengklasifikasikan gambar fashion (computer vision). Pertama, kita akan membuat model ANN yang cukup simple, kemudian kita coba model CNN untuk meningkatkan akurasi.\n\n\nhttps://keras.io/api/datasets/fashion_mnist/\n\nfashion_mnist = tf.keras.datasets.fashion_mnist\n(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n\n\nprint(f'X_train_full shape: {X_train_full.shape}')\nprint(f'y_train_full shape: {y_train_full.shape}')\nprint(f'X_test shape: {X_test.shape}')\nprint(f'y_test shape: {y_test.shape}')\n\nX_train_full shape: (60000, 28, 28)\ny_train_full shape: (60000,)\nX_test shape: (10000, 28, 28)\ny_test shape: (10000,)\n\n\n\nX_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, \n                                                  test_size=1/6, \n                                                  random_state=42)\n\nprint(f'X_train shape: {X_train.shape}')\nprint(f'y_train shape: {y_train.shape}')\nprint(f'X_val shape: {X_val.shape}')\nprint(f'y_val shape: {y_val.shape}')\nprint(f'X_test shape: {X_test.shape}')\nprint(f'y_test shape: {y_test.shape}')\n\nX_train shape: (50000, 28, 28)\ny_train shape: (50000,)\nX_val shape: (10000, 28, 28)\ny_val shape: (10000,)\nX_test shape: (10000, 28, 28)\ny_test shape: (10000,)\n\n\n\nX_train = X_train / 255\nX_val = X_val / 255\nX_test = X_test / 255\n\n\nclass_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n\n\n#@title Slider to look for some image examples {run: \"auto\"}\nidx = 21402 #@param {type:\"slider\", min:0, max:49999, step:1}\n\nplt.imshow(X_train[idx], cmap='gray')\nplt.title(class_names[y_train[idx]])\nplt.axis('OFF')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel_ann_class = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28,28)),\n    tf.keras.layers.Dense(100, activation='relu'),\n    tf.keras.layers.Dense(50, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nopt = tf.keras.optimizers.Adam(learning_rate=1e-3)\nmodel_ann_class.compile(optimizer=opt, loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel_ann_class.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten (Flatten)           (None, 784)               0         \n                                                                 \n dense (Dense)               (None, 100)               78500     \n                                                                 \n dense_1 (Dense)             (None, 50)                5050      \n                                                                 \n dense_2 (Dense)             (None, 10)                510       \n                                                                 \n=================================================================\nTotal params: 84,060\nTrainable params: 84,060\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\ninit_ann_class_weights = model_ann_class.get_weights()\n\n\nprint(type(init_ann_class_weights))\nprint(len(init_ann_class_weights))\nprint(f'First dense w: {init_ann_class_weights[0].shape}')\nprint(f'First dense b: {init_ann_class_weights[1].shape}')\nprint(f'Second dense w: {init_ann_class_weights[2].shape}')\nprint(f'Second dense b: {init_ann_class_weights[3].shape}')\nprint(f'Last dense w: {init_ann_class_weights[4].shape}')\nprint(f'Last dense b: {init_ann_class_weights[5].shape}')\n\n&lt;class 'list'&gt;\n6\nFirst dense w: (784, 100)\nFirst dense b: (100,)\nSecond dense w: (100, 50)\nSecond dense b: (50,)\nLast dense w: (50, 10)\nLast dense b: (10,)\n\n\n\nhistory_ann_class = model_ann_class.fit(X_train, y_train, \n                                        validation_data=(X_val, y_val),\n                                        epochs=50, batch_size=256)\n\nEpoch 1/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.6681 - accuracy: 0.7688 - val_loss: 0.4915 - val_accuracy: 0.8307\nEpoch 2/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.4334 - accuracy: 0.8471 - val_loss: 0.4150 - val_accuracy: 0.8491\nEpoch 3/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3873 - accuracy: 0.8635 - val_loss: 0.4204 - val_accuracy: 0.8503\nEpoch 4/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3637 - accuracy: 0.8700 - val_loss: 0.3839 - val_accuracy: 0.8600\nEpoch 5/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3422 - accuracy: 0.8768 - val_loss: 0.3612 - val_accuracy: 0.8720\nEpoch 6/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3275 - accuracy: 0.8805 - val_loss: 0.3525 - val_accuracy: 0.8732\nEpoch 7/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.3116 - accuracy: 0.8868 - val_loss: 0.3400 - val_accuracy: 0.8747\nEpoch 8/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.2974 - accuracy: 0.8914 - val_loss: 0.3488 - val_accuracy: 0.8734\nEpoch 9/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2889 - accuracy: 0.8946 - val_loss: 0.3463 - val_accuracy: 0.8732\nEpoch 10/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.2777 - accuracy: 0.8982 - val_loss: 0.3333 - val_accuracy: 0.8806\nEpoch 11/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2688 - accuracy: 0.9019 - val_loss: 0.3402 - val_accuracy: 0.8796\nEpoch 12/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2641 - accuracy: 0.9022 - val_loss: 0.3277 - val_accuracy: 0.8807\nEpoch 13/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2556 - accuracy: 0.9067 - val_loss: 0.3177 - val_accuracy: 0.8848\nEpoch 14/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2491 - accuracy: 0.9085 - val_loss: 0.3287 - val_accuracy: 0.8802\nEpoch 15/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2431 - accuracy: 0.9093 - val_loss: 0.3156 - val_accuracy: 0.8868\nEpoch 16/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2358 - accuracy: 0.9119 - val_loss: 0.3266 - val_accuracy: 0.8816\nEpoch 17/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2314 - accuracy: 0.9122 - val_loss: 0.3132 - val_accuracy: 0.8859\nEpoch 18/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.2301 - accuracy: 0.9140 - val_loss: 0.3155 - val_accuracy: 0.8863\nEpoch 19/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.2193 - accuracy: 0.9189 - val_loss: 0.3328 - val_accuracy: 0.8824\nEpoch 20/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.2162 - accuracy: 0.9195 - val_loss: 0.3306 - val_accuracy: 0.8830\nEpoch 21/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2128 - accuracy: 0.9209 - val_loss: 0.3230 - val_accuracy: 0.8834\nEpoch 22/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2053 - accuracy: 0.9236 - val_loss: 0.3350 - val_accuracy: 0.8826\nEpoch 23/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2038 - accuracy: 0.9250 - val_loss: 0.3202 - val_accuracy: 0.8862\nEpoch 24/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1991 - accuracy: 0.9265 - val_loss: 0.3187 - val_accuracy: 0.8872\nEpoch 25/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1948 - accuracy: 0.9294 - val_loss: 0.3424 - val_accuracy: 0.8823\nEpoch 26/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1878 - accuracy: 0.9309 - val_loss: 0.3179 - val_accuracy: 0.8912\nEpoch 27/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1896 - accuracy: 0.9296 - val_loss: 0.3243 - val_accuracy: 0.8900\nEpoch 28/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.1812 - accuracy: 0.9325 - val_loss: 0.3260 - val_accuracy: 0.8891\nEpoch 29/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1805 - accuracy: 0.9327 - val_loss: 0.3389 - val_accuracy: 0.8868\nEpoch 30/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1777 - accuracy: 0.9350 - val_loss: 0.3296 - val_accuracy: 0.8858\nEpoch 31/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1716 - accuracy: 0.9368 - val_loss: 0.3398 - val_accuracy: 0.8887\nEpoch 32/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1683 - accuracy: 0.9377 - val_loss: 0.3484 - val_accuracy: 0.8850\nEpoch 33/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1690 - accuracy: 0.9381 - val_loss: 0.3416 - val_accuracy: 0.8880\nEpoch 34/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1635 - accuracy: 0.9391 - val_loss: 0.3423 - val_accuracy: 0.8878\nEpoch 35/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1596 - accuracy: 0.9404 - val_loss: 0.3524 - val_accuracy: 0.8859\nEpoch 36/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.1566 - accuracy: 0.9432 - val_loss: 0.3687 - val_accuracy: 0.8840\nEpoch 37/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1561 - accuracy: 0.9420 - val_loss: 0.3525 - val_accuracy: 0.8852\nEpoch 38/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1491 - accuracy: 0.9448 - val_loss: 0.3640 - val_accuracy: 0.8833\nEpoch 39/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1494 - accuracy: 0.9449 - val_loss: 0.3761 - val_accuracy: 0.8867\nEpoch 40/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1446 - accuracy: 0.9467 - val_loss: 0.3758 - val_accuracy: 0.8861\nEpoch 41/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1411 - accuracy: 0.9481 - val_loss: 0.3604 - val_accuracy: 0.8886\nEpoch 42/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1388 - accuracy: 0.9485 - val_loss: 0.3790 - val_accuracy: 0.8840\nEpoch 43/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1399 - accuracy: 0.9479 - val_loss: 0.3736 - val_accuracy: 0.8903\nEpoch 44/50\n196/196 [==============================] - 3s 15ms/step - loss: 0.1316 - accuracy: 0.9503 - val_loss: 0.3778 - val_accuracy: 0.8874\nEpoch 45/50\n196/196 [==============================] - 3s 14ms/step - loss: 0.1304 - accuracy: 0.9515 - val_loss: 0.4043 - val_accuracy: 0.8816\nEpoch 46/50\n196/196 [==============================] - 2s 12ms/step - loss: 0.1283 - accuracy: 0.9528 - val_loss: 0.3941 - val_accuracy: 0.8846\nEpoch 47/50\n196/196 [==============================] - 2s 13ms/step - loss: 0.1280 - accuracy: 0.9525 - val_loss: 0.3956 - val_accuracy: 0.8851\nEpoch 48/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1231 - accuracy: 0.9551 - val_loss: 0.3878 - val_accuracy: 0.8890\nEpoch 49/50\n196/196 [==============================] - 2s 12ms/step - loss: 0.1206 - accuracy: 0.9560 - val_loss: 0.3860 - val_accuracy: 0.8901\nEpoch 50/50\n196/196 [==============================] - 3s 17ms/step - loss: 0.1195 - accuracy: 0.9563 - val_loss: 0.4013 - val_accuracy: 0.8872\n\n\n\nloss = history_ann_class.history['loss']\nval_loss = history_ann_class.history['val_loss']\naccuracy = history_ann_class.history['accuracy']\nval_accuracy = history_ann_class.history['val_accuracy']\nepochs = range(len(loss))\n\nfig, ax = plt.subplots(1, 2, figsize=(8,3))\nax[0].plot(epochs, loss)\nax[0].plot(epochs, val_loss)\nax[0].legend(['loss', 'val_loss'], loc='upper right')\nax[0].set_title('Train Loss vs Val Loss')\nax[1].plot(epochs, accuracy)\nax[1].plot(epochs, val_accuracy)\nax[1].legend(['accuracy', 'val_accuracy'], loc='lower right')\nax[1].set_title('Train Acc vs Val Acc')\nplt.show()\n\n\n\n\n\n\n\n\n\nmodel_ann_class.evaluate(X_val, y_val)\n\n313/313 [==============================] - 1s 4ms/step - loss: 0.4013 - accuracy: 0.8872\n\n\n[0.4012959599494934, 0.8871999979019165]\n\n\n\nmodel_ann_class.evaluate(X_test, y_test)\n\n313/313 [==============================] - 1s 4ms/step - loss: 0.4228 - accuracy: 0.8853\n\n\n[0.42284178733825684, 0.8852999806404114]\n\n\n\n\n\n\nmodel_ann_class.set_weights(init_ann_class_weights)\n\n\nmodel_ann_class.evaluate(X_val, y_val)\n\n313/313 [==============================] - 1s 2ms/step - loss: 2.4112 - accuracy: 0.0420\n\n\n[2.41121768951416, 0.041999999433755875]\n\n\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss',\n                                              restore_best_weights=True,\n                                              verbose=1)\n\nhistory_ann_class = model_ann_class.fit(X_train, y_train, \n                                        validation_data=(X_val, y_val),\n                                        epochs=50, batch_size=256,\n                                        callbacks=[early_stop])\n\nEpoch 1/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.6287 - accuracy: 0.7787 - val_loss: 0.4691 - val_accuracy: 0.8378\nEpoch 2/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.4224 - accuracy: 0.8508 - val_loss: 0.4133 - val_accuracy: 0.8549\nEpoch 3/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3808 - accuracy: 0.8663 - val_loss: 0.3827 - val_accuracy: 0.8651\nEpoch 4/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3479 - accuracy: 0.8757 - val_loss: 0.3823 - val_accuracy: 0.8636\nEpoch 5/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.3341 - accuracy: 0.8803 - val_loss: 0.3610 - val_accuracy: 0.8732\nEpoch 6/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.3199 - accuracy: 0.8852 - val_loss: 0.3534 - val_accuracy: 0.8746\nEpoch 7/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3079 - accuracy: 0.8888 - val_loss: 0.3383 - val_accuracy: 0.8785\nEpoch 8/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2965 - accuracy: 0.8933 - val_loss: 0.3290 - val_accuracy: 0.8810\nEpoch 9/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2862 - accuracy: 0.8964 - val_loss: 0.3333 - val_accuracy: 0.8800\nEpoch 10/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2756 - accuracy: 0.9001 - val_loss: 0.3313 - val_accuracy: 0.8842\nEpoch 11/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2686 - accuracy: 0.9023 - val_loss: 0.3282 - val_accuracy: 0.8787\nEpoch 12/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2642 - accuracy: 0.9035 - val_loss: 0.3204 - val_accuracy: 0.8830\nEpoch 13/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2615 - accuracy: 0.9050 - val_loss: 0.3247 - val_accuracy: 0.8814\nEpoch 14/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.2525 - accuracy: 0.9069 - val_loss: 0.3182 - val_accuracy: 0.8874\nEpoch 15/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2407 - accuracy: 0.9117 - val_loss: 0.3150 - val_accuracy: 0.8872\nEpoch 16/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2378 - accuracy: 0.9132 - val_loss: 0.3320 - val_accuracy: 0.8813\nEpoch 17/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2334 - accuracy: 0.9138 - val_loss: 0.3242 - val_accuracy: 0.8843\nEpoch 18/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2265 - accuracy: 0.9167 - val_loss: 0.3242 - val_accuracy: 0.8837\nEpoch 19/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2218 - accuracy: 0.9181 - val_loss: 0.3242 - val_accuracy: 0.8848\nEpoch 20/50\n196/196 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.9198Restoring model weights from the end of the best epoch: 15.\n196/196 [==============================] - 1s 7ms/step - loss: 0.2180 - accuracy: 0.9198 - val_loss: 0.3237 - val_accuracy: 0.8864\nEpoch 20: early stopping\n\n\n\nloss = history_ann_class.history['loss']\nval_loss = history_ann_class.history['val_loss']\naccuracy = history_ann_class.history['accuracy']\nval_accuracy = history_ann_class.history['val_accuracy']\nepochs = range(len(loss))\n\nfig, ax = plt.subplots(1, 2, figsize=(8,3))\nax[0].plot(epochs, loss)\nax[0].plot(epochs, val_loss)\nax[0].legend(['loss', 'val_loss'], loc='upper right')\nax[0].set_title('Train Loss vs Val Loss')\nax[1].plot(epochs, accuracy)\nax[1].plot(epochs, val_accuracy)\nax[1].legend(['accuracy', 'val_accuracy'], loc='lower right')\nax[1].set_title('Train Acc vs Val Acc')\nplt.show()\n\n\n\n\n\n\n\n\n\nmodel_ann_class.evaluate(X_val, y_val)\n\n313/313 [==============================] - 1s 4ms/step - loss: 0.3150 - accuracy: 0.8872\n\n\n[0.31500566005706787, 0.8871999979019165]\n\n\n\nmodel_ann_class.evaluate(X_test, y_test)\n\n313/313 [==============================] - 2s 5ms/step - loss: 0.3424 - accuracy: 0.8841\n\n\n[0.342407763004303, 0.8841000199317932]\n\n\n\n\n\n\n\ntf.keras.backend.clear_session()\n\nmodel_cnn = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5),\n                           activation='relu', input_shape=(28,28,1)),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(100, activation='relu'),\n    tf.keras.layers.Dense(50, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n                  metrics='accuracy')\n\nmodel_cnn.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 24, 24, 32)        832       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 10, 10, 64)        18496     \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 1600)              0         \n                                                                 \n dense (Dense)               (None, 100)               160100    \n                                                                 \n dense_1 (Dense)             (None, 50)                5050      \n                                                                 \n dense_2 (Dense)             (None, 10)                510       \n                                                                 \n=================================================================\nTotal params: 184,988\nTrainable params: 184,988\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss',\n                                              restore_best_weights=True,\n                                              verbose=1)\n\nhistory_cnn = model_cnn.fit(X_train, y_train, validation_data=(X_val, y_val),\n                            epochs=100, batch_size=256, \n                            callbacks=[early_stop])\n\nEpoch 1/100\n196/196 [==============================] - 4s 9ms/step - loss: 0.7431 - accuracy: 0.7296 - val_loss: 0.4864 - val_accuracy: 0.8231\nEpoch 2/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.4358 - accuracy: 0.8453 - val_loss: 0.4050 - val_accuracy: 0.8536\nEpoch 3/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.3686 - accuracy: 0.8686 - val_loss: 0.3497 - val_accuracy: 0.8712\nEpoch 4/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.3341 - accuracy: 0.8812 - val_loss: 0.3283 - val_accuracy: 0.8801\nEpoch 5/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.3081 - accuracy: 0.8892 - val_loss: 0.3191 - val_accuracy: 0.8836\nEpoch 6/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.2845 - accuracy: 0.8986 - val_loss: 0.3178 - val_accuracy: 0.8832\nEpoch 7/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.2725 - accuracy: 0.9018 - val_loss: 0.2926 - val_accuracy: 0.8930\nEpoch 8/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.2596 - accuracy: 0.9049 - val_loss: 0.2756 - val_accuracy: 0.8989\nEpoch 9/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.2430 - accuracy: 0.9127 - val_loss: 0.2777 - val_accuracy: 0.8984\nEpoch 10/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.2356 - accuracy: 0.9147 - val_loss: 0.2626 - val_accuracy: 0.9062\nEpoch 11/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.2249 - accuracy: 0.9176 - val_loss: 0.2759 - val_accuracy: 0.9008\nEpoch 12/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.2127 - accuracy: 0.9226 - val_loss: 0.2729 - val_accuracy: 0.9011\nEpoch 13/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.2046 - accuracy: 0.9251 - val_loss: 0.2617 - val_accuracy: 0.9005\nEpoch 14/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1946 - accuracy: 0.9298 - val_loss: 0.2634 - val_accuracy: 0.9064\nEpoch 15/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1821 - accuracy: 0.9333 - val_loss: 0.2505 - val_accuracy: 0.9082\nEpoch 16/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1754 - accuracy: 0.9350 - val_loss: 0.2533 - val_accuracy: 0.9083\nEpoch 17/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1686 - accuracy: 0.9381 - val_loss: 0.2435 - val_accuracy: 0.9122\nEpoch 18/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1602 - accuracy: 0.9408 - val_loss: 0.2461 - val_accuracy: 0.9125\nEpoch 19/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1513 - accuracy: 0.9442 - val_loss: 0.2658 - val_accuracy: 0.9040\nEpoch 20/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1449 - accuracy: 0.9460 - val_loss: 0.2570 - val_accuracy: 0.9161\nEpoch 21/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.1357 - accuracy: 0.9506 - val_loss: 0.2469 - val_accuracy: 0.9147\nEpoch 22/100\n194/196 [============================&gt;.] - ETA: 0s - loss: 0.1297 - accuracy: 0.9521Restoring model weights from the end of the best epoch: 17.\n196/196 [==============================] - 1s 7ms/step - loss: 0.1298 - accuracy: 0.9521 - val_loss: 0.2894 - val_accuracy: 0.9066\nEpoch 22: early stopping\n\n\n\nloss = history_cnn.history['loss']\nval_loss = history_cnn.history['val_loss']\naccuracy = history_cnn.history['accuracy']\nval_accuracy = history_cnn.history['val_accuracy']\nepochs = range(len(loss))\n\nfig, ax = plt.subplots(1, 2, figsize=(8,3))\nax[0].plot(epochs, loss)\nax[0].plot(epochs, val_loss)\nax[0].legend(['loss', 'val_loss'], loc='upper right')\nax[0].set_title('Train Loss vs Val Loss')\nax[1].plot(epochs, accuracy)\nax[1].plot(epochs, val_accuracy)\nax[1].legend(['accuracy', 'val_accuracy'], loc='lower right')\nax[1].set_title('Train Acc vs Val Acc')\nplt.show()\n\n\n\n\n\n\n\n\n\nmodel_cnn.evaluate(X_val, y_val)\n\n313/313 [==============================] - 1s 3ms/step - loss: 0.2435 - accuracy: 0.9122\n\n\n[0.2434857189655304, 0.9121999740600586]\n\n\n\nmodel_cnn.evaluate(X_test, y_test)\n\n313/313 [==============================] - 1s 2ms/step - loss: 0.2664 - accuracy: 0.9079\n\n\n[0.26635172963142395, 0.9078999757766724]\n\n\n\ny_pred = tf.argmax(model_cnn.predict(X_test), axis=-1).numpy()\ny_pred[:10], y_test[:10]\n\n313/313 [==============================] - 1s 2ms/step\n\n\n(array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7]),\n array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7], dtype=uint8))\n\n\n\n#@title Wrong Prediction image {run:\"auto\"}\n\nwrong_pred = (y_pred != y_test)\n\nwrong_pred_idx = 8 #@param {type:\"slider\", min:0, max:20, step:1}\n\nprint(f'Prediction: {class_names[y_pred[wrong_pred][wrong_pred_idx]]}')\nprint(f'Truth: {class_names[y_test[wrong_pred][wrong_pred_idx]]}')\n\nplt.imshow(X_test[wrong_pred][wrong_pred_idx], cmap='gray')\nplt.axis('OFF')\nplt.show()\n\nPrediction: Coat\nTruth: Pullover\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelanjutnya, kita coba untuk membuat model ANN untuk masalah regresi (harga rumah).\n\n\n\nhousing = fetch_california_housing()\nX = housing['data']\ny = housing['target']\n\nprint(f'X shape: {X.shape}')\nprint(f'y shape: {y.shape}')\n\nX shape: (20640, 8)\ny shape: (20640,)\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4,\n                                                    random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=.5,\n                                                random_state=42)\n\nprint(f'X_train shape: {X_train.shape}')\nprint(f'y_train shape: {y_train.shape}')\nprint(f'X_val shape: {X_val.shape}')\nprint(f'y_val shape: {y_val.shape}')\nprint(f'X_test shape: {X_test.shape}')\nprint(f'y_test shape: {y_test.shape}')\n\nX_train shape: (12384, 8)\ny_train shape: (12384,)\nX_val shape: (4128, 8)\ny_val shape: (4128,)\nX_test shape: (4128, 8)\ny_test shape: (4128,)\n\n\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)\n\n\nprint(f'y min: {y_train.min()}')\nprint(f'y max: {y_train.max()}')\n\ny min: 0.14999\ny max: 5.00001\n\n\n\n\n\n\ntf.keras.backend.clear_session()\n\nmodel_reg = tf.keras.Sequential([\n    tf.keras.layers.Dense(30, activation='relu',\n                          input_shape=X_train.shape[1:]),\n    tf.keras.layers.Dense(1, activation='relu')\n])\n\nmodel_reg.compile(optimizer='adam', loss='mse')\n\nmodel_reg.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 30)                270       \n                                                                 \n dense_1 (Dense)             (None, 1)                 31        \n                                                                 \n=================================================================\nTotal params: 301\nTrainable params: 301\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss',\n                                              restore_best_weights=True,\n                                              verbose=1)\n\nhistory_reg = model_reg.fit(X_train, y_train, validation_data=(X_val, y_val),\n                            epochs=500, callbacks=[early_stop])\n\nEpoch 1/500\n387/387 [==============================] - 2s 3ms/step - loss: 1.1266 - val_loss: 0.6397\nEpoch 2/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.5616 - val_loss: 0.5056\nEpoch 3/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.4695 - val_loss: 0.4661\nEpoch 4/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.4385 - val_loss: 0.4433\nEpoch 5/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.4195 - val_loss: 0.4286\nEpoch 6/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4212\nEpoch 7/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3966 - val_loss: 0.4100\nEpoch 8/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3869 - val_loss: 0.4032\nEpoch 9/500\n387/387 [==============================] - 1s 4ms/step - loss: 0.3810 - val_loss: 0.3999\nEpoch 10/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3751 - val_loss: 0.3966\nEpoch 11/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3723 - val_loss: 0.3905\nEpoch 12/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3662 - val_loss: 0.3851\nEpoch 13/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.3816\nEpoch 14/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3576 - val_loss: 0.3778\nEpoch 15/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3537 - val_loss: 0.3785\nEpoch 16/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3505 - val_loss: 0.3734\nEpoch 17/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3483 - val_loss: 0.3933\nEpoch 18/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3487 - val_loss: 0.3685\nEpoch 19/500\n387/387 [==============================] - 3s 8ms/step - loss: 0.3406 - val_loss: 0.3654\nEpoch 20/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3827 - val_loss: 0.3608\nEpoch 21/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3379 - val_loss: 0.3623\nEpoch 22/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3342 - val_loss: 0.3568\nEpoch 23/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3342 - val_loss: 0.3583\nEpoch 24/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3322 - val_loss: 0.3565\nEpoch 25/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3310 - val_loss: 0.3567\nEpoch 26/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3294 - val_loss: 0.3529\nEpoch 27/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3287 - val_loss: 0.3545\nEpoch 28/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3297 - val_loss: 0.3495\nEpoch 29/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3249 - val_loss: 0.3585\nEpoch 30/500\n387/387 [==============================] - 1s 4ms/step - loss: 0.3247 - val_loss: 0.3511\nEpoch 31/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3226 - val_loss: 0.3478\nEpoch 32/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3234 - val_loss: 0.3475\nEpoch 33/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3231 - val_loss: 0.3502\nEpoch 34/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3316 - val_loss: 0.3473\nEpoch 35/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3212 - val_loss: 0.3471\nEpoch 36/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3192 - val_loss: 0.3448\nEpoch 37/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3443\nEpoch 38/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3195 - val_loss: 0.3426\nEpoch 39/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3180 - val_loss: 0.3437\nEpoch 40/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3148 - val_loss: 0.3434\nEpoch 41/500\n387/387 [==============================] - 1s 4ms/step - loss: 0.3148 - val_loss: 0.3402\nEpoch 42/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3146 - val_loss: 0.3408\nEpoch 43/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3157 - val_loss: 0.3396\nEpoch 44/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3115 - val_loss: 0.3438\nEpoch 45/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3114 - val_loss: 0.3403\nEpoch 46/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3155 - val_loss: 0.3378\nEpoch 47/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3117 - val_loss: 0.3367\nEpoch 48/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3099 - val_loss: 0.3349\nEpoch 49/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3085 - val_loss: 0.3338\nEpoch 50/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3088 - val_loss: 0.3373\nEpoch 51/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3080 - val_loss: 0.3387\nEpoch 52/500\n387/387 [==============================] - 1s 4ms/step - loss: 0.3094 - val_loss: 0.3539\nEpoch 53/500\n387/387 [==============================] - 2s 6ms/step - loss: 0.3487 - val_loss: 0.3349\nEpoch 54/500\n373/387 [===========================&gt;..] - ETA: 0s - loss: 0.3093Restoring model weights from the end of the best epoch: 49.\n387/387 [==============================] - 2s 6ms/step - loss: 0.3087 - val_loss: 0.3633\nEpoch 54: early stopping\n\n\n\nloss = history_reg.history['loss']\nval_loss = history_reg.history['val_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.legend(['loss', 'val_loss'], loc='upper right')\nplt.title('Train Loss vs Val Loss')\nplt.show()\n\n\n\n\n\n\n\n\n\nmodel_reg.evaluate(X_val, y_val)\n\n129/129 [==============================] - 1s 3ms/step - loss: 0.3338\n\n\n0.33384060859680176\n\n\n\nmodel_reg.evaluate(X_test, y_test)\n\n129/129 [==============================] - 0s 3ms/step - loss: 0.3242\n\n\n0.32420143485069275\n\n\n\ny_pred = model_reg.predict(X_test)\n\nplt.hist(y_pred, color='green', alpha=.6)\nplt.hist(y_test, color='blue', alpha=.6)\nplt.legend(['prediction', 'truth'], loc='upper right')\nplt.show()\n\n129/129 [==============================] - 0s 3ms/step\n\n\n\n\n\n\n\n\n\n\n\n\n\nBerikut merupakan contoh - contoh penggunaan Functional API. Pada modul ini tidak dibahas banyak karena penggunaannya yang cukup mudah, hanya sedikit berbeda dengan Sequential.\nInformasi lebih lanjut dapat dipelajari pada link berikut: https://keras.io/guides/functional_api/\n\n\nMembuat NN regressor dengan arsitekur yang sama seperti saat menggunakan Sequential API di atas.\n\ntf.keras.backend.clear_session()\n\ninput_layer = tf.keras.layers.Input(shape=X_train.shape[1:])\ndense = tf.keras.layers.Dense(30, activation='relu')(input_layer)\noutput_layer = tf.keras.layers.Dense(1, activation='relu')(dense)\n\nmodel = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n\nmodel.compile(optimizer='adam', loss='mse')\n\nmodel.summary()\n\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 8)]               0         \n                                                                 \n dense (Dense)               (None, 30)                270       \n                                                                 \n dense_1 (Dense)             (None, 1)                 31        \n                                                                 \n=================================================================\nTotal params: 301\nTrainable params: 301\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\n\n\nMembuat arsitektur “Wide & Deep”\n\n\n\nimage.png\n\n\nReference: “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow” by Aurélien Géron\n\ntf.keras.backend.clear_session()\n\ninput_layer = tf.keras.layers.Input(shape=X_train.shape[1:])\nhidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(input_layer)\nhidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\nconcat = tf.keras.layers.Concatenate()([input_layer, hidden2])\noutput = tf.keras.layers.Dense(1)(concat)\n\nmodel = tf.keras.Model(inputs=input_layer, outputs=output,\n                       name='wide_and_deep')\n\nmodel.compile(optimizer='adam', loss='mse')\n\nmodel.summary()\n\nModel: \"wide_and_deep\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 8)]          0           []                               \n                                                                                                  \n dense (Dense)                  (None, 30)           270         ['input_1[0][0]']                \n                                                                                                  \n dense_1 (Dense)                (None, 30)           930         ['dense[0][0]']                  \n                                                                                                  \n concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n                                                                  'dense_1[0][0]']                \n                                                                                                  \n dense_2 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 1,239\nTrainable params: 1,239\nNon-trainable params: 0\n__________________________________________________________________________________________________\n\n\n\n\n\nMembuat arsitektur dengan multiple input\n\n\n\nimage.png\n\n\nReference: “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow” by Aurélien Géron\n\ntf.keras.backend.clear_session()\n\ninput_A = tf.keras.layers.Input(shape=[5], name=\"wide_input\")\ninput_B = tf.keras.layers.Input(shape=[6], name=\"deep_input\")\nhidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(input_B)\nhidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\nconcat = tf.keras.layers.concatenate([input_A, hidden2])\noutput = tf.keras.layers.Dense(1, name=\"output\")(concat)\n\nmodel = tf.keras.Model(inputs=[input_A, input_B], outputs=[output],\n                       name='multiple_input')\n\nmodel.compile(optimizer='adam', loss='mse')\n\nmodel.summary()\n\nModel: \"multiple_input\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n deep_input (InputLayer)        [(None, 6)]          0           []                               \n                                                                                                  \n dense (Dense)                  (None, 30)           210         ['deep_input[0][0]']             \n                                                                                                  \n wide_input (InputLayer)        [(None, 5)]          0           []                               \n                                                                                                  \n dense_1 (Dense)                (None, 30)           930         ['dense[0][0]']                  \n                                                                                                  \n concatenate (Concatenate)      (None, 35)           0           ['wide_input[0][0]',             \n                                                                  'dense_1[0][0]']                \n                                                                                                  \n output (Dense)                 (None, 1)            36          ['concatenate[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 1,176\nTrainable params: 1,176\nNon-trainable params: 0\n__________________________________________________________________________________________________\n\n\n\n\n\n\nPada bagian terakhir dari modul ini, kita akan mencoba melakukan hyperparameter tuning untuk menentukan arsitektur NN terbaik yang menghasilkan val_loss terendah.\nInformasi lebih lanjut dapat dilihat pada dokumentasi keras-tuner: https://keras.io/api/keras_tuner/\n\ndef build_model_reg(hp):\n    model = tf.keras.Sequential()\n    n_hid_layers = hp.Int('n_hid_layers', 1, 2)\n    for layer in range(n_hid_layers):\n        n_neurons = hp.Int(f'n_neurons_{layer}', 32, 128, step=16)\n        act = hp.Choice(f'activation_{layer}', \n                        ['relu', 'linear', 'sigmoid'])\n        model.add(tf.keras.layers.Dense(n_neurons, activation=act))\n    \n    act_output = hp.Choice('activation_output', ['relu', 'linear'])\n    model.add(tf.keras.layers.Dense(1, activation=act_output))\n\n    lr = hp.Float('learning_rate', 1e-5, 1e-2)\n    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n    model.compile(optimizer=opt, loss='mse')\n\n    return model\n\n\n\n\ntf.keras.backend.clear_session()\n\ntuner = kt.BayesianOptimization(hypermodel=build_model_reg,\n                                objective='val_loss',\n                                max_trials=10,\n                                directory='tuner_dir_0',\n                                project_name='tune_housing_model')\n\ntuner.search_space_summary()\n\nSearch space summary\nDefault search space size: 5\nn_hid_layers (Int)\n{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 2, 'step': 1, 'sampling': 'linear'}\nn_neurons_0 (Int)\n{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': 'linear'}\nactivation_0 (Choice)\n{'default': 'relu', 'conditions': [], 'values': ['relu', 'linear', 'sigmoid'], 'ordered': False}\nactivation_output (Choice)\n{'default': 'relu', 'conditions': [], 'values': ['relu', 'linear'], 'ordered': False}\nlearning_rate (Float)\n{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.01, 'step': None, 'sampling': 'linear'}\n\n\n\ntuner.search(X_train, y_train, validation_data=(X_val, y_val),\n             epochs=100, batch_size=256)\n\nTrial 10 Complete [00h 00m 42s]\nval_loss: 0.27770957350730896\n\nBest val_loss So Far: 0.27770957350730896\nTotal elapsed time: 00h 06m 40s\n\n\n\ntuner.results_summary(3)\n\nResults summary\nResults in tuner_dir_0/tune_housing_model\nShowing 3 best trials\nObjective(name=\"val_loss\", direction=\"min\")\n\nTrial 09 summary\nHyperparameters:\nn_hid_layers: 2\nn_neurons_0: 48\nactivation_0: relu\nactivation_output: linear\nlearning_rate: 0.00724696590440984\nn_neurons_1: 96\nactivation_1: sigmoid\nScore: 0.27770957350730896\n\nTrial 01 summary\nHyperparameters:\nn_hid_layers: 2\nn_neurons_0: 128\nactivation_0: sigmoid\nactivation_output: linear\nlearning_rate: 0.009038408225650444\nn_neurons_1: 64\nactivation_1: relu\nScore: 0.28969764709472656\n\nTrial 02 summary\nHyperparameters:\nn_hid_layers: 1\nn_neurons_0: 80\nactivation_0: relu\nactivation_output: linear\nlearning_rate: 0.004831622738137635\nn_neurons_1: 32\nactivation_1: relu\nScore: 0.3006684482097626\n\n\n\n\n\n\nmodel = build_model_reg(tuner.get_best_hyperparameters()[0])\nmodel.build(input_shape=(None,) + X_train.shape[1:])\n\nmodel.summary()\n\nModel: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_6 (Dense)             (None, 48)                432       \n                                                                 \n dense_7 (Dense)             (None, 96)                4704      \n                                                                 \n dense_8 (Dense)             (None, 1)                 97        \n                                                                 \n=================================================================\nTotal params: 5,233\nTrainable params: 5,233\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=10, monitor='val_loss',\n                                              restore_best_weights=True,\n                                              verbose=1)\n\nhistory = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n                    epochs=500, batch_size=256, callbacks=[early_stop])\n\nEpoch 1/500\n49/49 [==============================] - 3s 11ms/step - loss: 1.1235 - val_loss: 0.5184\nEpoch 2/500\n49/49 [==============================] - 0s 7ms/step - loss: 0.4471 - val_loss: 0.4324\nEpoch 3/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.3967 - val_loss: 0.4041\nEpoch 4/500\n49/49 [==============================] - 0s 7ms/step - loss: 0.3720 - val_loss: 0.3898\nEpoch 5/500\n49/49 [==============================] - 0s 7ms/step - loss: 0.3610 - val_loss: 0.3772\nEpoch 6/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.3529 - val_loss: 0.3724\nEpoch 7/500\n49/49 [==============================] - 0s 7ms/step - loss: 0.3494 - val_loss: 0.3672\nEpoch 8/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.3378 - val_loss: 0.3561\nEpoch 9/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.3316 - val_loss: 0.3472\nEpoch 10/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3279 - val_loss: 0.3419\nEpoch 11/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3230 - val_loss: 0.3534\nEpoch 12/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3173 - val_loss: 0.3345\nEpoch 13/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3128 - val_loss: 0.3340\nEpoch 14/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3110 - val_loss: 0.3310\nEpoch 15/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3042 - val_loss: 0.3332\nEpoch 16/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3041 - val_loss: 0.3248\nEpoch 17/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2975 - val_loss: 0.3290\nEpoch 18/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2991 - val_loss: 0.3225\nEpoch 19/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2929 - val_loss: 0.3183\nEpoch 20/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2927 - val_loss: 0.3366\nEpoch 21/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2909 - val_loss: 0.3194\nEpoch 22/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2889 - val_loss: 0.3159\nEpoch 23/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2871 - val_loss: 0.3114\nEpoch 24/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2891 - val_loss: 0.3127\nEpoch 25/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2832 - val_loss: 0.3121\nEpoch 26/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2845 - val_loss: 0.3264\nEpoch 27/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2882 - val_loss: 0.3065\nEpoch 28/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2848 - val_loss: 0.3232\nEpoch 29/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2855 - val_loss: 0.3053\nEpoch 30/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2784 - val_loss: 0.3027\nEpoch 31/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2803 - val_loss: 0.3298\nEpoch 32/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2765 - val_loss: 0.3051\nEpoch 33/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2796 - val_loss: 0.2993\nEpoch 34/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2725 - val_loss: 0.3027\nEpoch 35/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2790 - val_loss: 0.3162\nEpoch 36/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2750 - val_loss: 0.3013\nEpoch 37/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2789 - val_loss: 0.3064\nEpoch 38/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2705 - val_loss: 0.3062\nEpoch 39/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2706 - val_loss: 0.3087\nEpoch 40/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2682 - val_loss: 0.2949\nEpoch 41/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2649 - val_loss: 0.3018\nEpoch 42/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2701 - val_loss: 0.3006\nEpoch 43/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2656 - val_loss: 0.2946\nEpoch 44/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2641 - val_loss: 0.2970\nEpoch 45/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2653 - val_loss: 0.2900\nEpoch 46/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2669 - val_loss: 0.3028\nEpoch 47/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2659 - val_loss: 0.2936\nEpoch 48/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2652 - val_loss: 0.2974\nEpoch 49/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2613 - val_loss: 0.3024\nEpoch 50/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2626 - val_loss: 0.2932\nEpoch 51/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2588 - val_loss: 0.2958\nEpoch 52/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2602 - val_loss: 0.2936\nEpoch 53/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2630 - val_loss: 0.2977\nEpoch 54/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2628 - val_loss: 0.2893\nEpoch 55/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2586 - val_loss: 0.2858\nEpoch 56/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2569 - val_loss: 0.2890\nEpoch 57/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2571 - val_loss: 0.2903\nEpoch 58/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2588 - val_loss: 0.2977\nEpoch 59/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2559 - val_loss: 0.2848\nEpoch 60/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2584 - val_loss: 0.3046\nEpoch 61/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2584 - val_loss: 0.3007\nEpoch 62/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2556 - val_loss: 0.2972\nEpoch 63/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2525 - val_loss: 0.2865\nEpoch 64/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2499 - val_loss: 0.2841\nEpoch 65/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2519 - val_loss: 0.2842\nEpoch 66/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2536 - val_loss: 0.2845\nEpoch 67/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2520 - val_loss: 0.2908\nEpoch 68/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2526 - val_loss: 0.2809\nEpoch 69/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2526 - val_loss: 0.2859\nEpoch 70/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2463 - val_loss: 0.2805\nEpoch 71/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2456 - val_loss: 0.2853\nEpoch 72/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2470 - val_loss: 0.2829\nEpoch 73/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2463 - val_loss: 0.2827\nEpoch 74/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2457 - val_loss: 0.2794\nEpoch 75/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2461 - val_loss: 0.2793\nEpoch 76/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2488 - val_loss: 0.2824\nEpoch 77/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2412 - val_loss: 0.2795\nEpoch 78/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2423 - val_loss: 0.2789\nEpoch 79/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2426 - val_loss: 0.2810\nEpoch 80/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2424 - val_loss: 0.2805\nEpoch 81/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2421 - val_loss: 0.2767\nEpoch 82/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2418 - val_loss: 0.2835\nEpoch 83/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2454 - val_loss: 0.2826\nEpoch 84/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2373 - val_loss: 0.2756\nEpoch 85/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2365 - val_loss: 0.2821\nEpoch 86/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2386 - val_loss: 0.2828\nEpoch 87/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2352 - val_loss: 0.2786\nEpoch 88/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2360 - val_loss: 0.2780\nEpoch 89/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2327 - val_loss: 0.2793\nEpoch 90/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2366 - val_loss: 0.2755\nEpoch 91/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2352 - val_loss: 0.2758\nEpoch 92/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2334 - val_loss: 0.2770\nEpoch 93/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2333 - val_loss: 0.2821\nEpoch 94/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2327 - val_loss: 0.2780\nEpoch 95/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2323 - val_loss: 0.2752\nEpoch 96/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2369 - val_loss: 0.2760\nEpoch 97/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2319 - val_loss: 0.2744\nEpoch 98/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2313 - val_loss: 0.2806\nEpoch 99/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2319 - val_loss: 0.2770\nEpoch 100/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2330 - val_loss: 0.2782\nEpoch 101/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2287 - val_loss: 0.2793\nEpoch 102/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2269 - val_loss: 0.2736\nEpoch 103/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2285 - val_loss: 0.2821\nEpoch 104/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2273 - val_loss: 0.2753\nEpoch 105/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2265 - val_loss: 0.2779\nEpoch 106/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2259 - val_loss: 0.2780\nEpoch 107/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2267 - val_loss: 0.2743\nEpoch 108/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2289 - val_loss: 0.2751\nEpoch 109/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2259 - val_loss: 0.2879\nEpoch 110/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2296 - val_loss: 0.2814\nEpoch 111/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2274 - val_loss: 0.2887\nEpoch 112/500\n36/49 [=====================&gt;........] - ETA: 0s - loss: 0.2293Restoring model weights from the end of the best epoch: 102.\n49/49 [==============================] - 0s 5ms/step - loss: 0.2289 - val_loss: 0.2867\nEpoch 112: early stopping\n\n\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.legend(['loss', 'val_loss'], loc='upper right')\nplt.title('Train Loss vs Val Loss')\nplt.show()\n\n\n\n\n\n\n\n\n\nmodel.evaluate(X_val, y_val)\n\n129/129 [==============================] - 0s 2ms/step - loss: 0.2736\n\n\n0.2735856771469116\n\n\n\nmodel.evaluate(X_test, y_test)\n\n129/129 [==============================] - 0s 3ms/step - loss: 0.2652\n\n\n0.2651788592338562\n\n\n\ny_pred = model.predict(X_test)\n\nplt.hist(y_pred, color='green', alpha=.6)\nplt.hist(y_test, color='blue', alpha=.6)\nplt.legend(['prediction', 'truth'], loc='upper right')\nplt.show()\n\n129/129 [==============================] - 0s 1ms/step\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://neuralnetworksanddeeplearning.com/ (membahas cara kerja neural network secara matematis, cocok untuk yang suka belajar dengan membaca)\nhttp://introtodeeplearning.com/ (membahas cara kerja neural network hingga CNN, RNN, reinforcement learning, dan lain - lain, cocok untuk yang suka belajar dengan menonton video dan ingin mendalami deep learning lebih lanjut)\nBuku “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow” by Aurélien Géron (membahas implementasi Machine Learning dan Deep Learning pada library-library yang tertera di judulnya)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html#prerequisites",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html#prerequisites",
    "title": "Week-06 (NN with Keras and Hyperparameter Tuning with Keras-Tuner)",
    "section": "",
    "text": "!pip install keras-tuner\nimport tensorflow as tf\nimport keras_tuner as kt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import fetch_california_housing\nimport matplotlib.pyplot as plt\n\nLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nCollecting keras-tuner\n  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 176.1/176.1 kB 7.5 MB/s eta 0:00:00\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.27.1)\nCollecting kt-legacy\n  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (3.4)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (2.0.12)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (1.26.15)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (2022.12.7)\nInstalling collected packages: kt-legacy, keras-tuner\nSuccessfully installed keras-tuner-1.3.5 kt-legacy-1.0.5"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html#build-image-classifier-with-sequential-api",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html#build-image-classifier-with-sequential-api",
    "title": "Week-06 (NN with Keras and Hyperparameter Tuning with Keras-Tuner)",
    "section": "",
    "text": "Keras memiliki tiga macam API yang dapat digunakan, yaitu Sequential, Functional, dan Subclassing. Ketiganya memiliki kelebihan dan kekurangan masing-masing, terutama di sisi kemudahan dan fleksibilitas.\nSequential API merupakan API yang sangat mudah dipahami bagi semua orang yang ingin mempelajari deep learning, tetapi Sequential tidak cukup fleksibel dalam membuat arsitektur model tingkat lanjut karena sifatnya yang mengharuskan tiap layer terhubung satu sama lain dari input hingga output.\nFunctional API merupakan API yang juga cukup mudah dipahami (sedikit lebih kompleks dibandingkan Sequential), tetapi cukup fleksibel dalam mengimplementasikan beragam arsitektur model.\nSubclassing API merupakan API yang cukup sulit dipahami bagi orang yang baru ingin mempelajari deep learning, tetapi di sisi lain API ini merupakan API terfleksibel pada Keras.\nPada modul ini, hanya akan dibahas Sequential dan Functional API.\nPertama, kita akan membuat dua macam model untuk mengklasifikasikan gambar fashion (computer vision). Pertama, kita akan membuat model ANN yang cukup simple, kemudian kita coba model CNN untuk meningkatkan akurasi.\n\n\nhttps://keras.io/api/datasets/fashion_mnist/\n\nfashion_mnist = tf.keras.datasets.fashion_mnist\n(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n\n\nprint(f'X_train_full shape: {X_train_full.shape}')\nprint(f'y_train_full shape: {y_train_full.shape}')\nprint(f'X_test shape: {X_test.shape}')\nprint(f'y_test shape: {y_test.shape}')\n\nX_train_full shape: (60000, 28, 28)\ny_train_full shape: (60000,)\nX_test shape: (10000, 28, 28)\ny_test shape: (10000,)\n\n\n\nX_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, \n                                                  test_size=1/6, \n                                                  random_state=42)\n\nprint(f'X_train shape: {X_train.shape}')\nprint(f'y_train shape: {y_train.shape}')\nprint(f'X_val shape: {X_val.shape}')\nprint(f'y_val shape: {y_val.shape}')\nprint(f'X_test shape: {X_test.shape}')\nprint(f'y_test shape: {y_test.shape}')\n\nX_train shape: (50000, 28, 28)\ny_train shape: (50000,)\nX_val shape: (10000, 28, 28)\ny_val shape: (10000,)\nX_test shape: (10000, 28, 28)\ny_test shape: (10000,)\n\n\n\nX_train = X_train / 255\nX_val = X_val / 255\nX_test = X_test / 255\n\n\nclass_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n\n\n#@title Slider to look for some image examples {run: \"auto\"}\nidx = 21402 #@param {type:\"slider\", min:0, max:49999, step:1}\n\nplt.imshow(X_train[idx], cmap='gray')\nplt.title(class_names[y_train[idx]])\nplt.axis('OFF')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel_ann_class = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28,28)),\n    tf.keras.layers.Dense(100, activation='relu'),\n    tf.keras.layers.Dense(50, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nopt = tf.keras.optimizers.Adam(learning_rate=1e-3)\nmodel_ann_class.compile(optimizer=opt, loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel_ann_class.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten (Flatten)           (None, 784)               0         \n                                                                 \n dense (Dense)               (None, 100)               78500     \n                                                                 \n dense_1 (Dense)             (None, 50)                5050      \n                                                                 \n dense_2 (Dense)             (None, 10)                510       \n                                                                 \n=================================================================\nTotal params: 84,060\nTrainable params: 84,060\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\ninit_ann_class_weights = model_ann_class.get_weights()\n\n\nprint(type(init_ann_class_weights))\nprint(len(init_ann_class_weights))\nprint(f'First dense w: {init_ann_class_weights[0].shape}')\nprint(f'First dense b: {init_ann_class_weights[1].shape}')\nprint(f'Second dense w: {init_ann_class_weights[2].shape}')\nprint(f'Second dense b: {init_ann_class_weights[3].shape}')\nprint(f'Last dense w: {init_ann_class_weights[4].shape}')\nprint(f'Last dense b: {init_ann_class_weights[5].shape}')\n\n&lt;class 'list'&gt;\n6\nFirst dense w: (784, 100)\nFirst dense b: (100,)\nSecond dense w: (100, 50)\nSecond dense b: (50,)\nLast dense w: (50, 10)\nLast dense b: (10,)\n\n\n\nhistory_ann_class = model_ann_class.fit(X_train, y_train, \n                                        validation_data=(X_val, y_val),\n                                        epochs=50, batch_size=256)\n\nEpoch 1/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.6681 - accuracy: 0.7688 - val_loss: 0.4915 - val_accuracy: 0.8307\nEpoch 2/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.4334 - accuracy: 0.8471 - val_loss: 0.4150 - val_accuracy: 0.8491\nEpoch 3/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3873 - accuracy: 0.8635 - val_loss: 0.4204 - val_accuracy: 0.8503\nEpoch 4/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3637 - accuracy: 0.8700 - val_loss: 0.3839 - val_accuracy: 0.8600\nEpoch 5/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3422 - accuracy: 0.8768 - val_loss: 0.3612 - val_accuracy: 0.8720\nEpoch 6/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3275 - accuracy: 0.8805 - val_loss: 0.3525 - val_accuracy: 0.8732\nEpoch 7/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.3116 - accuracy: 0.8868 - val_loss: 0.3400 - val_accuracy: 0.8747\nEpoch 8/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.2974 - accuracy: 0.8914 - val_loss: 0.3488 - val_accuracy: 0.8734\nEpoch 9/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2889 - accuracy: 0.8946 - val_loss: 0.3463 - val_accuracy: 0.8732\nEpoch 10/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.2777 - accuracy: 0.8982 - val_loss: 0.3333 - val_accuracy: 0.8806\nEpoch 11/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2688 - accuracy: 0.9019 - val_loss: 0.3402 - val_accuracy: 0.8796\nEpoch 12/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2641 - accuracy: 0.9022 - val_loss: 0.3277 - val_accuracy: 0.8807\nEpoch 13/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2556 - accuracy: 0.9067 - val_loss: 0.3177 - val_accuracy: 0.8848\nEpoch 14/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2491 - accuracy: 0.9085 - val_loss: 0.3287 - val_accuracy: 0.8802\nEpoch 15/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2431 - accuracy: 0.9093 - val_loss: 0.3156 - val_accuracy: 0.8868\nEpoch 16/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2358 - accuracy: 0.9119 - val_loss: 0.3266 - val_accuracy: 0.8816\nEpoch 17/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2314 - accuracy: 0.9122 - val_loss: 0.3132 - val_accuracy: 0.8859\nEpoch 18/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.2301 - accuracy: 0.9140 - val_loss: 0.3155 - val_accuracy: 0.8863\nEpoch 19/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.2193 - accuracy: 0.9189 - val_loss: 0.3328 - val_accuracy: 0.8824\nEpoch 20/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.2162 - accuracy: 0.9195 - val_loss: 0.3306 - val_accuracy: 0.8830\nEpoch 21/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2128 - accuracy: 0.9209 - val_loss: 0.3230 - val_accuracy: 0.8834\nEpoch 22/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2053 - accuracy: 0.9236 - val_loss: 0.3350 - val_accuracy: 0.8826\nEpoch 23/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2038 - accuracy: 0.9250 - val_loss: 0.3202 - val_accuracy: 0.8862\nEpoch 24/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1991 - accuracy: 0.9265 - val_loss: 0.3187 - val_accuracy: 0.8872\nEpoch 25/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1948 - accuracy: 0.9294 - val_loss: 0.3424 - val_accuracy: 0.8823\nEpoch 26/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1878 - accuracy: 0.9309 - val_loss: 0.3179 - val_accuracy: 0.8912\nEpoch 27/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1896 - accuracy: 0.9296 - val_loss: 0.3243 - val_accuracy: 0.8900\nEpoch 28/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.1812 - accuracy: 0.9325 - val_loss: 0.3260 - val_accuracy: 0.8891\nEpoch 29/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1805 - accuracy: 0.9327 - val_loss: 0.3389 - val_accuracy: 0.8868\nEpoch 30/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1777 - accuracy: 0.9350 - val_loss: 0.3296 - val_accuracy: 0.8858\nEpoch 31/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1716 - accuracy: 0.9368 - val_loss: 0.3398 - val_accuracy: 0.8887\nEpoch 32/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1683 - accuracy: 0.9377 - val_loss: 0.3484 - val_accuracy: 0.8850\nEpoch 33/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1690 - accuracy: 0.9381 - val_loss: 0.3416 - val_accuracy: 0.8880\nEpoch 34/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1635 - accuracy: 0.9391 - val_loss: 0.3423 - val_accuracy: 0.8878\nEpoch 35/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1596 - accuracy: 0.9404 - val_loss: 0.3524 - val_accuracy: 0.8859\nEpoch 36/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.1566 - accuracy: 0.9432 - val_loss: 0.3687 - val_accuracy: 0.8840\nEpoch 37/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1561 - accuracy: 0.9420 - val_loss: 0.3525 - val_accuracy: 0.8852\nEpoch 38/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1491 - accuracy: 0.9448 - val_loss: 0.3640 - val_accuracy: 0.8833\nEpoch 39/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1494 - accuracy: 0.9449 - val_loss: 0.3761 - val_accuracy: 0.8867\nEpoch 40/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1446 - accuracy: 0.9467 - val_loss: 0.3758 - val_accuracy: 0.8861\nEpoch 41/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1411 - accuracy: 0.9481 - val_loss: 0.3604 - val_accuracy: 0.8886\nEpoch 42/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1388 - accuracy: 0.9485 - val_loss: 0.3790 - val_accuracy: 0.8840\nEpoch 43/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1399 - accuracy: 0.9479 - val_loss: 0.3736 - val_accuracy: 0.8903\nEpoch 44/50\n196/196 [==============================] - 3s 15ms/step - loss: 0.1316 - accuracy: 0.9503 - val_loss: 0.3778 - val_accuracy: 0.8874\nEpoch 45/50\n196/196 [==============================] - 3s 14ms/step - loss: 0.1304 - accuracy: 0.9515 - val_loss: 0.4043 - val_accuracy: 0.8816\nEpoch 46/50\n196/196 [==============================] - 2s 12ms/step - loss: 0.1283 - accuracy: 0.9528 - val_loss: 0.3941 - val_accuracy: 0.8846\nEpoch 47/50\n196/196 [==============================] - 2s 13ms/step - loss: 0.1280 - accuracy: 0.9525 - val_loss: 0.3956 - val_accuracy: 0.8851\nEpoch 48/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1231 - accuracy: 0.9551 - val_loss: 0.3878 - val_accuracy: 0.8890\nEpoch 49/50\n196/196 [==============================] - 2s 12ms/step - loss: 0.1206 - accuracy: 0.9560 - val_loss: 0.3860 - val_accuracy: 0.8901\nEpoch 50/50\n196/196 [==============================] - 3s 17ms/step - loss: 0.1195 - accuracy: 0.9563 - val_loss: 0.4013 - val_accuracy: 0.8872\n\n\n\nloss = history_ann_class.history['loss']\nval_loss = history_ann_class.history['val_loss']\naccuracy = history_ann_class.history['accuracy']\nval_accuracy = history_ann_class.history['val_accuracy']\nepochs = range(len(loss))\n\nfig, ax = plt.subplots(1, 2, figsize=(8,3))\nax[0].plot(epochs, loss)\nax[0].plot(epochs, val_loss)\nax[0].legend(['loss', 'val_loss'], loc='upper right')\nax[0].set_title('Train Loss vs Val Loss')\nax[1].plot(epochs, accuracy)\nax[1].plot(epochs, val_accuracy)\nax[1].legend(['accuracy', 'val_accuracy'], loc='lower right')\nax[1].set_title('Train Acc vs Val Acc')\nplt.show()\n\n\n\n\n\n\n\n\n\nmodel_ann_class.evaluate(X_val, y_val)\n\n313/313 [==============================] - 1s 4ms/step - loss: 0.4013 - accuracy: 0.8872\n\n\n[0.4012959599494934, 0.8871999979019165]\n\n\n\nmodel_ann_class.evaluate(X_test, y_test)\n\n313/313 [==============================] - 1s 4ms/step - loss: 0.4228 - accuracy: 0.8853\n\n\n[0.42284178733825684, 0.8852999806404114]\n\n\n\n\n\n\nmodel_ann_class.set_weights(init_ann_class_weights)\n\n\nmodel_ann_class.evaluate(X_val, y_val)\n\n313/313 [==============================] - 1s 2ms/step - loss: 2.4112 - accuracy: 0.0420\n\n\n[2.41121768951416, 0.041999999433755875]\n\n\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss',\n                                              restore_best_weights=True,\n                                              verbose=1)\n\nhistory_ann_class = model_ann_class.fit(X_train, y_train, \n                                        validation_data=(X_val, y_val),\n                                        epochs=50, batch_size=256,\n                                        callbacks=[early_stop])\n\nEpoch 1/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.6287 - accuracy: 0.7787 - val_loss: 0.4691 - val_accuracy: 0.8378\nEpoch 2/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.4224 - accuracy: 0.8508 - val_loss: 0.4133 - val_accuracy: 0.8549\nEpoch 3/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3808 - accuracy: 0.8663 - val_loss: 0.3827 - val_accuracy: 0.8651\nEpoch 4/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3479 - accuracy: 0.8757 - val_loss: 0.3823 - val_accuracy: 0.8636\nEpoch 5/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.3341 - accuracy: 0.8803 - val_loss: 0.3610 - val_accuracy: 0.8732\nEpoch 6/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.3199 - accuracy: 0.8852 - val_loss: 0.3534 - val_accuracy: 0.8746\nEpoch 7/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3079 - accuracy: 0.8888 - val_loss: 0.3383 - val_accuracy: 0.8785\nEpoch 8/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2965 - accuracy: 0.8933 - val_loss: 0.3290 - val_accuracy: 0.8810\nEpoch 9/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2862 - accuracy: 0.8964 - val_loss: 0.3333 - val_accuracy: 0.8800\nEpoch 10/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2756 - accuracy: 0.9001 - val_loss: 0.3313 - val_accuracy: 0.8842\nEpoch 11/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2686 - accuracy: 0.9023 - val_loss: 0.3282 - val_accuracy: 0.8787\nEpoch 12/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2642 - accuracy: 0.9035 - val_loss: 0.3204 - val_accuracy: 0.8830\nEpoch 13/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2615 - accuracy: 0.9050 - val_loss: 0.3247 - val_accuracy: 0.8814\nEpoch 14/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.2525 - accuracy: 0.9069 - val_loss: 0.3182 - val_accuracy: 0.8874\nEpoch 15/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2407 - accuracy: 0.9117 - val_loss: 0.3150 - val_accuracy: 0.8872\nEpoch 16/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2378 - accuracy: 0.9132 - val_loss: 0.3320 - val_accuracy: 0.8813\nEpoch 17/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2334 - accuracy: 0.9138 - val_loss: 0.3242 - val_accuracy: 0.8843\nEpoch 18/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2265 - accuracy: 0.9167 - val_loss: 0.3242 - val_accuracy: 0.8837\nEpoch 19/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2218 - accuracy: 0.9181 - val_loss: 0.3242 - val_accuracy: 0.8848\nEpoch 20/50\n196/196 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.9198Restoring model weights from the end of the best epoch: 15.\n196/196 [==============================] - 1s 7ms/step - loss: 0.2180 - accuracy: 0.9198 - val_loss: 0.3237 - val_accuracy: 0.8864\nEpoch 20: early stopping\n\n\n\nloss = history_ann_class.history['loss']\nval_loss = history_ann_class.history['val_loss']\naccuracy = history_ann_class.history['accuracy']\nval_accuracy = history_ann_class.history['val_accuracy']\nepochs = range(len(loss))\n\nfig, ax = plt.subplots(1, 2, figsize=(8,3))\nax[0].plot(epochs, loss)\nax[0].plot(epochs, val_loss)\nax[0].legend(['loss', 'val_loss'], loc='upper right')\nax[0].set_title('Train Loss vs Val Loss')\nax[1].plot(epochs, accuracy)\nax[1].plot(epochs, val_accuracy)\nax[1].legend(['accuracy', 'val_accuracy'], loc='lower right')\nax[1].set_title('Train Acc vs Val Acc')\nplt.show()\n\n\n\n\n\n\n\n\n\nmodel_ann_class.evaluate(X_val, y_val)\n\n313/313 [==============================] - 1s 4ms/step - loss: 0.3150 - accuracy: 0.8872\n\n\n[0.31500566005706787, 0.8871999979019165]\n\n\n\nmodel_ann_class.evaluate(X_test, y_test)\n\n313/313 [==============================] - 2s 5ms/step - loss: 0.3424 - accuracy: 0.8841\n\n\n[0.342407763004303, 0.8841000199317932]\n\n\n\n\n\n\n\ntf.keras.backend.clear_session()\n\nmodel_cnn = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5),\n                           activation='relu', input_shape=(28,28,1)),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(100, activation='relu'),\n    tf.keras.layers.Dense(50, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n                  metrics='accuracy')\n\nmodel_cnn.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 24, 24, 32)        832       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 10, 10, 64)        18496     \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 1600)              0         \n                                                                 \n dense (Dense)               (None, 100)               160100    \n                                                                 \n dense_1 (Dense)             (None, 50)                5050      \n                                                                 \n dense_2 (Dense)             (None, 10)                510       \n                                                                 \n=================================================================\nTotal params: 184,988\nTrainable params: 184,988\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss',\n                                              restore_best_weights=True,\n                                              verbose=1)\n\nhistory_cnn = model_cnn.fit(X_train, y_train, validation_data=(X_val, y_val),\n                            epochs=100, batch_size=256, \n                            callbacks=[early_stop])\n\nEpoch 1/100\n196/196 [==============================] - 4s 9ms/step - loss: 0.7431 - accuracy: 0.7296 - val_loss: 0.4864 - val_accuracy: 0.8231\nEpoch 2/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.4358 - accuracy: 0.8453 - val_loss: 0.4050 - val_accuracy: 0.8536\nEpoch 3/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.3686 - accuracy: 0.8686 - val_loss: 0.3497 - val_accuracy: 0.8712\nEpoch 4/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.3341 - accuracy: 0.8812 - val_loss: 0.3283 - val_accuracy: 0.8801\nEpoch 5/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.3081 - accuracy: 0.8892 - val_loss: 0.3191 - val_accuracy: 0.8836\nEpoch 6/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.2845 - accuracy: 0.8986 - val_loss: 0.3178 - val_accuracy: 0.8832\nEpoch 7/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.2725 - accuracy: 0.9018 - val_loss: 0.2926 - val_accuracy: 0.8930\nEpoch 8/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.2596 - accuracy: 0.9049 - val_loss: 0.2756 - val_accuracy: 0.8989\nEpoch 9/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.2430 - accuracy: 0.9127 - val_loss: 0.2777 - val_accuracy: 0.8984\nEpoch 10/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.2356 - accuracy: 0.9147 - val_loss: 0.2626 - val_accuracy: 0.9062\nEpoch 11/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.2249 - accuracy: 0.9176 - val_loss: 0.2759 - val_accuracy: 0.9008\nEpoch 12/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.2127 - accuracy: 0.9226 - val_loss: 0.2729 - val_accuracy: 0.9011\nEpoch 13/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.2046 - accuracy: 0.9251 - val_loss: 0.2617 - val_accuracy: 0.9005\nEpoch 14/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1946 - accuracy: 0.9298 - val_loss: 0.2634 - val_accuracy: 0.9064\nEpoch 15/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1821 - accuracy: 0.9333 - val_loss: 0.2505 - val_accuracy: 0.9082\nEpoch 16/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1754 - accuracy: 0.9350 - val_loss: 0.2533 - val_accuracy: 0.9083\nEpoch 17/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1686 - accuracy: 0.9381 - val_loss: 0.2435 - val_accuracy: 0.9122\nEpoch 18/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1602 - accuracy: 0.9408 - val_loss: 0.2461 - val_accuracy: 0.9125\nEpoch 19/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1513 - accuracy: 0.9442 - val_loss: 0.2658 - val_accuracy: 0.9040\nEpoch 20/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1449 - accuracy: 0.9460 - val_loss: 0.2570 - val_accuracy: 0.9161\nEpoch 21/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.1357 - accuracy: 0.9506 - val_loss: 0.2469 - val_accuracy: 0.9147\nEpoch 22/100\n194/196 [============================&gt;.] - ETA: 0s - loss: 0.1297 - accuracy: 0.9521Restoring model weights from the end of the best epoch: 17.\n196/196 [==============================] - 1s 7ms/step - loss: 0.1298 - accuracy: 0.9521 - val_loss: 0.2894 - val_accuracy: 0.9066\nEpoch 22: early stopping\n\n\n\nloss = history_cnn.history['loss']\nval_loss = history_cnn.history['val_loss']\naccuracy = history_cnn.history['accuracy']\nval_accuracy = history_cnn.history['val_accuracy']\nepochs = range(len(loss))\n\nfig, ax = plt.subplots(1, 2, figsize=(8,3))\nax[0].plot(epochs, loss)\nax[0].plot(epochs, val_loss)\nax[0].legend(['loss', 'val_loss'], loc='upper right')\nax[0].set_title('Train Loss vs Val Loss')\nax[1].plot(epochs, accuracy)\nax[1].plot(epochs, val_accuracy)\nax[1].legend(['accuracy', 'val_accuracy'], loc='lower right')\nax[1].set_title('Train Acc vs Val Acc')\nplt.show()\n\n\n\n\n\n\n\n\n\nmodel_cnn.evaluate(X_val, y_val)\n\n313/313 [==============================] - 1s 3ms/step - loss: 0.2435 - accuracy: 0.9122\n\n\n[0.2434857189655304, 0.9121999740600586]\n\n\n\nmodel_cnn.evaluate(X_test, y_test)\n\n313/313 [==============================] - 1s 2ms/step - loss: 0.2664 - accuracy: 0.9079\n\n\n[0.26635172963142395, 0.9078999757766724]\n\n\n\ny_pred = tf.argmax(model_cnn.predict(X_test), axis=-1).numpy()\ny_pred[:10], y_test[:10]\n\n313/313 [==============================] - 1s 2ms/step\n\n\n(array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7]),\n array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7], dtype=uint8))\n\n\n\n#@title Wrong Prediction image {run:\"auto\"}\n\nwrong_pred = (y_pred != y_test)\n\nwrong_pred_idx = 8 #@param {type:\"slider\", min:0, max:20, step:1}\n\nprint(f'Prediction: {class_names[y_pred[wrong_pred][wrong_pred_idx]]}')\nprint(f'Truth: {class_names[y_test[wrong_pred][wrong_pred_idx]]}')\n\nplt.imshow(X_test[wrong_pred][wrong_pred_idx], cmap='gray')\nplt.axis('OFF')\nplt.show()\n\nPrediction: Coat\nTruth: Pullover"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html#build-nn-regressor-with-sequential-api",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html#build-nn-regressor-with-sequential-api",
    "title": "Week-06 (NN with Keras and Hyperparameter Tuning with Keras-Tuner)",
    "section": "",
    "text": "Selanjutnya, kita coba untuk membuat model ANN untuk masalah regresi (harga rumah).\n\n\n\nhousing = fetch_california_housing()\nX = housing['data']\ny = housing['target']\n\nprint(f'X shape: {X.shape}')\nprint(f'y shape: {y.shape}')\n\nX shape: (20640, 8)\ny shape: (20640,)\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4,\n                                                    random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=.5,\n                                                random_state=42)\n\nprint(f'X_train shape: {X_train.shape}')\nprint(f'y_train shape: {y_train.shape}')\nprint(f'X_val shape: {X_val.shape}')\nprint(f'y_val shape: {y_val.shape}')\nprint(f'X_test shape: {X_test.shape}')\nprint(f'y_test shape: {y_test.shape}')\n\nX_train shape: (12384, 8)\ny_train shape: (12384,)\nX_val shape: (4128, 8)\ny_val shape: (4128,)\nX_test shape: (4128, 8)\ny_test shape: (4128,)\n\n\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)\n\n\nprint(f'y min: {y_train.min()}')\nprint(f'y max: {y_train.max()}')\n\ny min: 0.14999\ny max: 5.00001\n\n\n\n\n\n\ntf.keras.backend.clear_session()\n\nmodel_reg = tf.keras.Sequential([\n    tf.keras.layers.Dense(30, activation='relu',\n                          input_shape=X_train.shape[1:]),\n    tf.keras.layers.Dense(1, activation='relu')\n])\n\nmodel_reg.compile(optimizer='adam', loss='mse')\n\nmodel_reg.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 30)                270       \n                                                                 \n dense_1 (Dense)             (None, 1)                 31        \n                                                                 \n=================================================================\nTotal params: 301\nTrainable params: 301\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss',\n                                              restore_best_weights=True,\n                                              verbose=1)\n\nhistory_reg = model_reg.fit(X_train, y_train, validation_data=(X_val, y_val),\n                            epochs=500, callbacks=[early_stop])\n\nEpoch 1/500\n387/387 [==============================] - 2s 3ms/step - loss: 1.1266 - val_loss: 0.6397\nEpoch 2/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.5616 - val_loss: 0.5056\nEpoch 3/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.4695 - val_loss: 0.4661\nEpoch 4/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.4385 - val_loss: 0.4433\nEpoch 5/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.4195 - val_loss: 0.4286\nEpoch 6/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4212\nEpoch 7/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3966 - val_loss: 0.4100\nEpoch 8/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3869 - val_loss: 0.4032\nEpoch 9/500\n387/387 [==============================] - 1s 4ms/step - loss: 0.3810 - val_loss: 0.3999\nEpoch 10/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3751 - val_loss: 0.3966\nEpoch 11/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3723 - val_loss: 0.3905\nEpoch 12/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3662 - val_loss: 0.3851\nEpoch 13/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.3816\nEpoch 14/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3576 - val_loss: 0.3778\nEpoch 15/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3537 - val_loss: 0.3785\nEpoch 16/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3505 - val_loss: 0.3734\nEpoch 17/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3483 - val_loss: 0.3933\nEpoch 18/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3487 - val_loss: 0.3685\nEpoch 19/500\n387/387 [==============================] - 3s 8ms/step - loss: 0.3406 - val_loss: 0.3654\nEpoch 20/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3827 - val_loss: 0.3608\nEpoch 21/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3379 - val_loss: 0.3623\nEpoch 22/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3342 - val_loss: 0.3568\nEpoch 23/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3342 - val_loss: 0.3583\nEpoch 24/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3322 - val_loss: 0.3565\nEpoch 25/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3310 - val_loss: 0.3567\nEpoch 26/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3294 - val_loss: 0.3529\nEpoch 27/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3287 - val_loss: 0.3545\nEpoch 28/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3297 - val_loss: 0.3495\nEpoch 29/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3249 - val_loss: 0.3585\nEpoch 30/500\n387/387 [==============================] - 1s 4ms/step - loss: 0.3247 - val_loss: 0.3511\nEpoch 31/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3226 - val_loss: 0.3478\nEpoch 32/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3234 - val_loss: 0.3475\nEpoch 33/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3231 - val_loss: 0.3502\nEpoch 34/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3316 - val_loss: 0.3473\nEpoch 35/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3212 - val_loss: 0.3471\nEpoch 36/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3192 - val_loss: 0.3448\nEpoch 37/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3443\nEpoch 38/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3195 - val_loss: 0.3426\nEpoch 39/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3180 - val_loss: 0.3437\nEpoch 40/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3148 - val_loss: 0.3434\nEpoch 41/500\n387/387 [==============================] - 1s 4ms/step - loss: 0.3148 - val_loss: 0.3402\nEpoch 42/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3146 - val_loss: 0.3408\nEpoch 43/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3157 - val_loss: 0.3396\nEpoch 44/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3115 - val_loss: 0.3438\nEpoch 45/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3114 - val_loss: 0.3403\nEpoch 46/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3155 - val_loss: 0.3378\nEpoch 47/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3117 - val_loss: 0.3367\nEpoch 48/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3099 - val_loss: 0.3349\nEpoch 49/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3085 - val_loss: 0.3338\nEpoch 50/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3088 - val_loss: 0.3373\nEpoch 51/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3080 - val_loss: 0.3387\nEpoch 52/500\n387/387 [==============================] - 1s 4ms/step - loss: 0.3094 - val_loss: 0.3539\nEpoch 53/500\n387/387 [==============================] - 2s 6ms/step - loss: 0.3487 - val_loss: 0.3349\nEpoch 54/500\n373/387 [===========================&gt;..] - ETA: 0s - loss: 0.3093Restoring model weights from the end of the best epoch: 49.\n387/387 [==============================] - 2s 6ms/step - loss: 0.3087 - val_loss: 0.3633\nEpoch 54: early stopping\n\n\n\nloss = history_reg.history['loss']\nval_loss = history_reg.history['val_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.legend(['loss', 'val_loss'], loc='upper right')\nplt.title('Train Loss vs Val Loss')\nplt.show()\n\n\n\n\n\n\n\n\n\nmodel_reg.evaluate(X_val, y_val)\n\n129/129 [==============================] - 1s 3ms/step - loss: 0.3338\n\n\n0.33384060859680176\n\n\n\nmodel_reg.evaluate(X_test, y_test)\n\n129/129 [==============================] - 0s 3ms/step - loss: 0.3242\n\n\n0.32420143485069275\n\n\n\ny_pred = model_reg.predict(X_test)\n\nplt.hist(y_pred, color='green', alpha=.6)\nplt.hist(y_test, color='blue', alpha=.6)\nplt.legend(['prediction', 'truth'], loc='upper right')\nplt.show()\n\n129/129 [==============================] - 0s 3ms/step"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html#functional-api",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html#functional-api",
    "title": "Week-06 (NN with Keras and Hyperparameter Tuning with Keras-Tuner)",
    "section": "",
    "text": "Berikut merupakan contoh - contoh penggunaan Functional API. Pada modul ini tidak dibahas banyak karena penggunaannya yang cukup mudah, hanya sedikit berbeda dengan Sequential.\nInformasi lebih lanjut dapat dipelajari pada link berikut: https://keras.io/guides/functional_api/\n\n\nMembuat NN regressor dengan arsitekur yang sama seperti saat menggunakan Sequential API di atas.\n\ntf.keras.backend.clear_session()\n\ninput_layer = tf.keras.layers.Input(shape=X_train.shape[1:])\ndense = tf.keras.layers.Dense(30, activation='relu')(input_layer)\noutput_layer = tf.keras.layers.Dense(1, activation='relu')(dense)\n\nmodel = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n\nmodel.compile(optimizer='adam', loss='mse')\n\nmodel.summary()\n\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 8)]               0         \n                                                                 \n dense (Dense)               (None, 30)                270       \n                                                                 \n dense_1 (Dense)             (None, 1)                 31        \n                                                                 \n=================================================================\nTotal params: 301\nTrainable params: 301\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\n\n\nMembuat arsitektur “Wide & Deep”\n\n\n\nimage.png\n\n\nReference: “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow” by Aurélien Géron\n\ntf.keras.backend.clear_session()\n\ninput_layer = tf.keras.layers.Input(shape=X_train.shape[1:])\nhidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(input_layer)\nhidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\nconcat = tf.keras.layers.Concatenate()([input_layer, hidden2])\noutput = tf.keras.layers.Dense(1)(concat)\n\nmodel = tf.keras.Model(inputs=input_layer, outputs=output,\n                       name='wide_and_deep')\n\nmodel.compile(optimizer='adam', loss='mse')\n\nmodel.summary()\n\nModel: \"wide_and_deep\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 8)]          0           []                               \n                                                                                                  \n dense (Dense)                  (None, 30)           270         ['input_1[0][0]']                \n                                                                                                  \n dense_1 (Dense)                (None, 30)           930         ['dense[0][0]']                  \n                                                                                                  \n concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n                                                                  'dense_1[0][0]']                \n                                                                                                  \n dense_2 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 1,239\nTrainable params: 1,239\nNon-trainable params: 0\n__________________________________________________________________________________________________\n\n\n\n\n\nMembuat arsitektur dengan multiple input\n\n\n\nimage.png\n\n\nReference: “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow” by Aurélien Géron\n\ntf.keras.backend.clear_session()\n\ninput_A = tf.keras.layers.Input(shape=[5], name=\"wide_input\")\ninput_B = tf.keras.layers.Input(shape=[6], name=\"deep_input\")\nhidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(input_B)\nhidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\nconcat = tf.keras.layers.concatenate([input_A, hidden2])\noutput = tf.keras.layers.Dense(1, name=\"output\")(concat)\n\nmodel = tf.keras.Model(inputs=[input_A, input_B], outputs=[output],\n                       name='multiple_input')\n\nmodel.compile(optimizer='adam', loss='mse')\n\nmodel.summary()\n\nModel: \"multiple_input\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n deep_input (InputLayer)        [(None, 6)]          0           []                               \n                                                                                                  \n dense (Dense)                  (None, 30)           210         ['deep_input[0][0]']             \n                                                                                                  \n wide_input (InputLayer)        [(None, 5)]          0           []                               \n                                                                                                  \n dense_1 (Dense)                (None, 30)           930         ['dense[0][0]']                  \n                                                                                                  \n concatenate (Concatenate)      (None, 35)           0           ['wide_input[0][0]',             \n                                                                  'dense_1[0][0]']                \n                                                                                                  \n output (Dense)                 (None, 1)            36          ['concatenate[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 1,176\nTrainable params: 1,176\nNon-trainable params: 0\n__________________________________________________________________________________________________"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html#hyperparameter-tuning-with-keras-tuner",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html#hyperparameter-tuning-with-keras-tuner",
    "title": "Week-06 (NN with Keras and Hyperparameter Tuning with Keras-Tuner)",
    "section": "",
    "text": "Pada bagian terakhir dari modul ini, kita akan mencoba melakukan hyperparameter tuning untuk menentukan arsitektur NN terbaik yang menghasilkan val_loss terendah.\nInformasi lebih lanjut dapat dilihat pada dokumentasi keras-tuner: https://keras.io/api/keras_tuner/\n\ndef build_model_reg(hp):\n    model = tf.keras.Sequential()\n    n_hid_layers = hp.Int('n_hid_layers', 1, 2)\n    for layer in range(n_hid_layers):\n        n_neurons = hp.Int(f'n_neurons_{layer}', 32, 128, step=16)\n        act = hp.Choice(f'activation_{layer}', \n                        ['relu', 'linear', 'sigmoid'])\n        model.add(tf.keras.layers.Dense(n_neurons, activation=act))\n    \n    act_output = hp.Choice('activation_output', ['relu', 'linear'])\n    model.add(tf.keras.layers.Dense(1, activation=act_output))\n\n    lr = hp.Float('learning_rate', 1e-5, 1e-2)\n    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n    model.compile(optimizer=opt, loss='mse')\n\n    return model\n\n\n\n\ntf.keras.backend.clear_session()\n\ntuner = kt.BayesianOptimization(hypermodel=build_model_reg,\n                                objective='val_loss',\n                                max_trials=10,\n                                directory='tuner_dir_0',\n                                project_name='tune_housing_model')\n\ntuner.search_space_summary()\n\nSearch space summary\nDefault search space size: 5\nn_hid_layers (Int)\n{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 2, 'step': 1, 'sampling': 'linear'}\nn_neurons_0 (Int)\n{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': 'linear'}\nactivation_0 (Choice)\n{'default': 'relu', 'conditions': [], 'values': ['relu', 'linear', 'sigmoid'], 'ordered': False}\nactivation_output (Choice)\n{'default': 'relu', 'conditions': [], 'values': ['relu', 'linear'], 'ordered': False}\nlearning_rate (Float)\n{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.01, 'step': None, 'sampling': 'linear'}\n\n\n\ntuner.search(X_train, y_train, validation_data=(X_val, y_val),\n             epochs=100, batch_size=256)\n\nTrial 10 Complete [00h 00m 42s]\nval_loss: 0.27770957350730896\n\nBest val_loss So Far: 0.27770957350730896\nTotal elapsed time: 00h 06m 40s\n\n\n\ntuner.results_summary(3)\n\nResults summary\nResults in tuner_dir_0/tune_housing_model\nShowing 3 best trials\nObjective(name=\"val_loss\", direction=\"min\")\n\nTrial 09 summary\nHyperparameters:\nn_hid_layers: 2\nn_neurons_0: 48\nactivation_0: relu\nactivation_output: linear\nlearning_rate: 0.00724696590440984\nn_neurons_1: 96\nactivation_1: sigmoid\nScore: 0.27770957350730896\n\nTrial 01 summary\nHyperparameters:\nn_hid_layers: 2\nn_neurons_0: 128\nactivation_0: sigmoid\nactivation_output: linear\nlearning_rate: 0.009038408225650444\nn_neurons_1: 64\nactivation_1: relu\nScore: 0.28969764709472656\n\nTrial 02 summary\nHyperparameters:\nn_hid_layers: 1\nn_neurons_0: 80\nactivation_0: relu\nactivation_output: linear\nlearning_rate: 0.004831622738137635\nn_neurons_1: 32\nactivation_1: relu\nScore: 0.3006684482097626\n\n\n\n\n\n\nmodel = build_model_reg(tuner.get_best_hyperparameters()[0])\nmodel.build(input_shape=(None,) + X_train.shape[1:])\n\nmodel.summary()\n\nModel: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_6 (Dense)             (None, 48)                432       \n                                                                 \n dense_7 (Dense)             (None, 96)                4704      \n                                                                 \n dense_8 (Dense)             (None, 1)                 97        \n                                                                 \n=================================================================\nTotal params: 5,233\nTrainable params: 5,233\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=10, monitor='val_loss',\n                                              restore_best_weights=True,\n                                              verbose=1)\n\nhistory = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n                    epochs=500, batch_size=256, callbacks=[early_stop])\n\nEpoch 1/500\n49/49 [==============================] - 3s 11ms/step - loss: 1.1235 - val_loss: 0.5184\nEpoch 2/500\n49/49 [==============================] - 0s 7ms/step - loss: 0.4471 - val_loss: 0.4324\nEpoch 3/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.3967 - val_loss: 0.4041\nEpoch 4/500\n49/49 [==============================] - 0s 7ms/step - loss: 0.3720 - val_loss: 0.3898\nEpoch 5/500\n49/49 [==============================] - 0s 7ms/step - loss: 0.3610 - val_loss: 0.3772\nEpoch 6/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.3529 - val_loss: 0.3724\nEpoch 7/500\n49/49 [==============================] - 0s 7ms/step - loss: 0.3494 - val_loss: 0.3672\nEpoch 8/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.3378 - val_loss: 0.3561\nEpoch 9/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.3316 - val_loss: 0.3472\nEpoch 10/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3279 - val_loss: 0.3419\nEpoch 11/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3230 - val_loss: 0.3534\nEpoch 12/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3173 - val_loss: 0.3345\nEpoch 13/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3128 - val_loss: 0.3340\nEpoch 14/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3110 - val_loss: 0.3310\nEpoch 15/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3042 - val_loss: 0.3332\nEpoch 16/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3041 - val_loss: 0.3248\nEpoch 17/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2975 - val_loss: 0.3290\nEpoch 18/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2991 - val_loss: 0.3225\nEpoch 19/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2929 - val_loss: 0.3183\nEpoch 20/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2927 - val_loss: 0.3366\nEpoch 21/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2909 - val_loss: 0.3194\nEpoch 22/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2889 - val_loss: 0.3159\nEpoch 23/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2871 - val_loss: 0.3114\nEpoch 24/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2891 - val_loss: 0.3127\nEpoch 25/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2832 - val_loss: 0.3121\nEpoch 26/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2845 - val_loss: 0.3264\nEpoch 27/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2882 - val_loss: 0.3065\nEpoch 28/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2848 - val_loss: 0.3232\nEpoch 29/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2855 - val_loss: 0.3053\nEpoch 30/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2784 - val_loss: 0.3027\nEpoch 31/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2803 - val_loss: 0.3298\nEpoch 32/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2765 - val_loss: 0.3051\nEpoch 33/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2796 - val_loss: 0.2993\nEpoch 34/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2725 - val_loss: 0.3027\nEpoch 35/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2790 - val_loss: 0.3162\nEpoch 36/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2750 - val_loss: 0.3013\nEpoch 37/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2789 - val_loss: 0.3064\nEpoch 38/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2705 - val_loss: 0.3062\nEpoch 39/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2706 - val_loss: 0.3087\nEpoch 40/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2682 - val_loss: 0.2949\nEpoch 41/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2649 - val_loss: 0.3018\nEpoch 42/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2701 - val_loss: 0.3006\nEpoch 43/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2656 - val_loss: 0.2946\nEpoch 44/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2641 - val_loss: 0.2970\nEpoch 45/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2653 - val_loss: 0.2900\nEpoch 46/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2669 - val_loss: 0.3028\nEpoch 47/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2659 - val_loss: 0.2936\nEpoch 48/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2652 - val_loss: 0.2974\nEpoch 49/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2613 - val_loss: 0.3024\nEpoch 50/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2626 - val_loss: 0.2932\nEpoch 51/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2588 - val_loss: 0.2958\nEpoch 52/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2602 - val_loss: 0.2936\nEpoch 53/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2630 - val_loss: 0.2977\nEpoch 54/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2628 - val_loss: 0.2893\nEpoch 55/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2586 - val_loss: 0.2858\nEpoch 56/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2569 - val_loss: 0.2890\nEpoch 57/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2571 - val_loss: 0.2903\nEpoch 58/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2588 - val_loss: 0.2977\nEpoch 59/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2559 - val_loss: 0.2848\nEpoch 60/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2584 - val_loss: 0.3046\nEpoch 61/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2584 - val_loss: 0.3007\nEpoch 62/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2556 - val_loss: 0.2972\nEpoch 63/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2525 - val_loss: 0.2865\nEpoch 64/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2499 - val_loss: 0.2841\nEpoch 65/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2519 - val_loss: 0.2842\nEpoch 66/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2536 - val_loss: 0.2845\nEpoch 67/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2520 - val_loss: 0.2908\nEpoch 68/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2526 - val_loss: 0.2809\nEpoch 69/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2526 - val_loss: 0.2859\nEpoch 70/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2463 - val_loss: 0.2805\nEpoch 71/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2456 - val_loss: 0.2853\nEpoch 72/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2470 - val_loss: 0.2829\nEpoch 73/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2463 - val_loss: 0.2827\nEpoch 74/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2457 - val_loss: 0.2794\nEpoch 75/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2461 - val_loss: 0.2793\nEpoch 76/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2488 - val_loss: 0.2824\nEpoch 77/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2412 - val_loss: 0.2795\nEpoch 78/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2423 - val_loss: 0.2789\nEpoch 79/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2426 - val_loss: 0.2810\nEpoch 80/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2424 - val_loss: 0.2805\nEpoch 81/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2421 - val_loss: 0.2767\nEpoch 82/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2418 - val_loss: 0.2835\nEpoch 83/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2454 - val_loss: 0.2826\nEpoch 84/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2373 - val_loss: 0.2756\nEpoch 85/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2365 - val_loss: 0.2821\nEpoch 86/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2386 - val_loss: 0.2828\nEpoch 87/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2352 - val_loss: 0.2786\nEpoch 88/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2360 - val_loss: 0.2780\nEpoch 89/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2327 - val_loss: 0.2793\nEpoch 90/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2366 - val_loss: 0.2755\nEpoch 91/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2352 - val_loss: 0.2758\nEpoch 92/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2334 - val_loss: 0.2770\nEpoch 93/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2333 - val_loss: 0.2821\nEpoch 94/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2327 - val_loss: 0.2780\nEpoch 95/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2323 - val_loss: 0.2752\nEpoch 96/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2369 - val_loss: 0.2760\nEpoch 97/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2319 - val_loss: 0.2744\nEpoch 98/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2313 - val_loss: 0.2806\nEpoch 99/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2319 - val_loss: 0.2770\nEpoch 100/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2330 - val_loss: 0.2782\nEpoch 101/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2287 - val_loss: 0.2793\nEpoch 102/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2269 - val_loss: 0.2736\nEpoch 103/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2285 - val_loss: 0.2821\nEpoch 104/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2273 - val_loss: 0.2753\nEpoch 105/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2265 - val_loss: 0.2779\nEpoch 106/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2259 - val_loss: 0.2780\nEpoch 107/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2267 - val_loss: 0.2743\nEpoch 108/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2289 - val_loss: 0.2751\nEpoch 109/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2259 - val_loss: 0.2879\nEpoch 110/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2296 - val_loss: 0.2814\nEpoch 111/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2274 - val_loss: 0.2887\nEpoch 112/500\n36/49 [=====================&gt;........] - ETA: 0s - loss: 0.2293Restoring model weights from the end of the best epoch: 102.\n49/49 [==============================] - 0s 5ms/step - loss: 0.2289 - val_loss: 0.2867\nEpoch 112: early stopping\n\n\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.legend(['loss', 'val_loss'], loc='upper right')\nplt.title('Train Loss vs Val Loss')\nplt.show()\n\n\n\n\n\n\n\n\n\nmodel.evaluate(X_val, y_val)\n\n129/129 [==============================] - 0s 2ms/step - loss: 0.2736\n\n\n0.2735856771469116\n\n\n\nmodel.evaluate(X_test, y_test)\n\n129/129 [==============================] - 0s 3ms/step - loss: 0.2652\n\n\n0.2651788592338562\n\n\n\ny_pred = model.predict(X_test)\n\nplt.hist(y_pred, color='green', alpha=.6)\nplt.hist(y_test, color='blue', alpha=.6)\nplt.legend(['prediction', 'truth'], loc='upper right')\nplt.show()\n\n129/129 [==============================] - 0s 1ms/step"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html#valuable-resources-to-learn-more",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html#valuable-resources-to-learn-more",
    "title": "Week-06 (NN with Keras and Hyperparameter Tuning with Keras-Tuner)",
    "section": "",
    "text": "http://neuralnetworksanddeeplearning.com/ (membahas cara kerja neural network secara matematis, cocok untuk yang suka belajar dengan membaca)\nhttp://introtodeeplearning.com/ (membahas cara kerja neural network hingga CNN, RNN, reinforcement learning, dan lain - lain, cocok untuk yang suka belajar dengan menonton video dan ingin mendalami deep learning lebih lanjut)\nBuku “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow” by Aurélien Géron (membahas implementasi Machine Learning dan Deep Learning pada library-library yang tertera di judulnya)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-2.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-2.html",
    "title": "Tugas 02 (End to End machine learning regresi)",
    "section": "",
    "text": "Kembali ke Sains Data\n\n\n\nKerjakan secara individu\nKerjakan tugas ini dengan bahasa pemrograman python. Anda disarankan menggunakan jupyter untuk mengerjakan tugas ini.\nUntuk setiap proses sains data (pembersihan data, transformasi data, EDA, dan pemodela ) yang dilakukan Anda diperlukan untuk menuliskan justifikasi-nya. Justifikasi-nya dapat berupa penjelasan singkat mengenai proses yang dilakukan, dan penjelasan mengenai alasan mengapa anda melakukan proses tersebut.\nFile yang harus diunggah terdiri dari:\n\nbeberapa model dalam format .pkl. Penamaan untuk model dibebaskan, namun harus jelas mengenai model apa yang disimpan.\nsatu file python notebook (file berbentuk .ipynb BUKAN .py) dengan ketentuan serupa.\n\nSemua file disatukan dalam 1 (satu) file .zip, dengan format penamaan: Nama_NPM_Kelas SIAK Sains Data_Tugas2PrakSainsData.zip. contoh: Itadori-Yuji_190688675_A_Tugas2PrakSainsData.zip\nBatas pengumpulan tugas ini adalah 21 April 2023 pukul 23.59. Tugas dikumpulkan sesuai dengan link berikut: https://ristek.link/tugas-sains-data-02\nDilarang melakukan plagiarisme atau menduplikasi dalam mengerjakan tugas ini. Apabila terdapat kesamaan program atau penjelasan pada tugas yang dikumpulkan, NILAI TUGAS PRAKTIKUM SAINS DATA ANDA LANGSUNG MENJADI 0 TANPA PERINGATAN bagi semua pihak yang terlibat plagiarisme dalam tugas ini.\nGunakan module (python package) yang telah dipelajari di praktikum atau kelas. Anda diperbolehkan untuk menggunakan module (python package) lain dengan catatan bahwa Anda harus menuliskan penjelasan singkat mengenai module tersebut.\nApabila ada yang ingin ditanyakan anda dapat bertanya pada kolom komentar atau, silakan mengontak salah satu kontak berikut:\n\nLINE: Carles_Octavianus (carles)\n\n\n\n\n\n[akses-data]: https://drive.google.com/open?id=1whKzd5rd-Rtg8bGmEYeBonsXLQMKfxTB&authuser=carlesoctavianus%40gmail.com&usp=drive_fs\nKerjakan secara end-to-end (pembersihan data, transformasi data , EDA, dan pemodelan) untuk memprediksi harga rumah berdasarkan data yang diberikan. Gunakan metode yang telah dipelajari di praktikum ataupun kelas (model regresi)."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-2.html#petunjuk-umum",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-2.html#petunjuk-umum",
    "title": "Tugas 02 (End to End machine learning regresi)",
    "section": "",
    "text": "Kerjakan secara individu\nKerjakan tugas ini dengan bahasa pemrograman python. Anda disarankan menggunakan jupyter untuk mengerjakan tugas ini.\nUntuk setiap proses sains data (pembersihan data, transformasi data, EDA, dan pemodela ) yang dilakukan Anda diperlukan untuk menuliskan justifikasi-nya. Justifikasi-nya dapat berupa penjelasan singkat mengenai proses yang dilakukan, dan penjelasan mengenai alasan mengapa anda melakukan proses tersebut.\nFile yang harus diunggah terdiri dari:\n\nbeberapa model dalam format .pkl. Penamaan untuk model dibebaskan, namun harus jelas mengenai model apa yang disimpan.\nsatu file python notebook (file berbentuk .ipynb BUKAN .py) dengan ketentuan serupa.\n\nSemua file disatukan dalam 1 (satu) file .zip, dengan format penamaan: Nama_NPM_Kelas SIAK Sains Data_Tugas2PrakSainsData.zip. contoh: Itadori-Yuji_190688675_A_Tugas2PrakSainsData.zip\nBatas pengumpulan tugas ini adalah 21 April 2023 pukul 23.59. Tugas dikumpulkan sesuai dengan link berikut: https://ristek.link/tugas-sains-data-02\nDilarang melakukan plagiarisme atau menduplikasi dalam mengerjakan tugas ini. Apabila terdapat kesamaan program atau penjelasan pada tugas yang dikumpulkan, NILAI TUGAS PRAKTIKUM SAINS DATA ANDA LANGSUNG MENJADI 0 TANPA PERINGATAN bagi semua pihak yang terlibat plagiarisme dalam tugas ini.\nGunakan module (python package) yang telah dipelajari di praktikum atau kelas. Anda diperbolehkan untuk menggunakan module (python package) lain dengan catatan bahwa Anda harus menuliskan penjelasan singkat mengenai module tersebut.\nApabila ada yang ingin ditanyakan anda dapat bertanya pada kolom komentar atau, silakan mengontak salah satu kontak berikut:\n\nLINE: Carles_Octavianus (carles)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-2.html#soal",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-2.html#soal",
    "title": "Tugas 02 (End to End machine learning regresi)",
    "section": "",
    "text": "[akses-data]: https://drive.google.com/open?id=1whKzd5rd-Rtg8bGmEYeBonsXLQMKfxTB&authuser=carlesoctavianus%40gmail.com&usp=drive_fs\nKerjakan secara end-to-end (pembersihan data, transformasi data , EDA, dan pemodelan) untuk memprediksi harga rumah berdasarkan data yang diberikan. Gunakan metode yang telah dipelajari di praktikum ataupun kelas (model regresi)."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-akhir.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-akhir.html",
    "title": "Tugas Akhir",
    "section": "",
    "text": "Tugas Akhir\nKembali ke Sains Data\nTulisan di bawah ini adalah salinan dari: https://linevoom.line.me/post/1168595921012325899\n[TUGAS AKHIR PRAKTIKUM SAINS DATA dan PDNUM]\nSelamat sore, warga Departemen Matematika!\nBerikut ini adalah tugas praktikum yang harus dikerjakan bagi mahasiswa yang mengambil mata kuliah Sains Data dan PDNum.\nhttps://drive.google.com/drive/folders/10hEyh6MTFnrx2kwC4IEL74cOCo-_NoNQ\nTugas dikerjakan secara individu dengan ketentuan yang sudah tentukan di masing masing tugas yang tertera pada tautan di atas.\nTugas dikumpulkan paling lambat pada hari Rabu, 21 Juni 2023 pukul 23.59 WIB melalui tautan berikut.\nSains Data: https://forms.gle/4i2tj8Zf7v7kDPoG7\nPDNum: https://forms.gle/m8s6iqyufpH9g3fUA\nDemikian informasi yang dapat kami sampaikan. Jika ada pertanyaan lebih lanjut, silakan hubungi kontak berikut.\nNarahubung:\n■ Justin (LINE: iamjustin10)\n■ Carles (LINE: Carles_octavianus)\n■ Tulus (LINE: tlsnew)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul1.html",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul1.html",
    "title": "Pertemuan 1 : Python for Data Analysis",
    "section": "",
    "text": "Kembali ke EDA"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul1.html#series",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul1.html#series",
    "title": "Pertemuan 1 : Python for Data Analysis",
    "section": "Series",
    "text": "Series\n\nSeries adalah suatu object yang menyerupai array 1 dimensi yang memiliki nilai dengan array index yang berkaitan dengan masing-masing nilai.\n\nimport pandas as pd\n\nobj = pd.Series([4, 7, -5, 3])\nobj\n\n0    4\n1    7\n2   -5\n3    3\ndtype: int64\n\n\nkolom kiri adalah index, kolom kanan adalah Values (nilai).\n\nUntuk mengakses values saja :\n\nobj.values\n\narray([ 4,  7, -5,  3], dtype=int64)\n\n\n\nUntuk mengakses index saja :\n\nobj.index\n\nRangeIndex(start=0, stop=4, step=1)\n\n\n\n\n\nPerbedaan Series dengan Array\n\nDengan Series kita bisa menggunakan index untuk mengakses value yang berkaitan dengan index tersebut.\n\nobj[0]\n\n4\n\n\n\nobj[1] = 2\nobj[[0, 1, 3]]\n\n0    4\n1    2\n3    3\ndtype: int64\n\n\n\nobj[0:2]\n\n0    4\n1    2\ndtype: int64\n\n\n\n\n\n\nSeries dengan custom index\n\n\nobj2 = pd.Series([0.25, 0.5, 0.75, 1.0], index=['d', 'b', 'a', 'c'])\nobj2\n\nd    0.25\nb    0.50\na    0.75\nc    1.00\ndtype: float64\n\n\n\n\n\n\n\n\nError warning\n\n\n\nPerhatikan jumlah index harus sama dengan jumlah value yang ditetapkan.\n\n\n\nobj2.index\n\nIndex(['d', 'b', 'a', 'c'], dtype='object')\n\n\n\nobj2['b']\n\n0.5\n\n\n\nobj2['d':'a']\n\nd    0.25\nb    0.50\na    0.75\ndtype: float64\n\n\n\nUntuk mengubah index suatu series bisa juga dengan mengubah nilai &lt;series&gt;.index\n\nobj2.index = ['A', 'B', 'C', 'D']\nobj2\n\nA    0.25\nB    0.50\nC    0.75\nD    1.00\ndtype: float64\n\n\n\n\n\n\nSeries as specialized dictionary\n\nDictionary pada python adalah struktur data yang berisi pasangan key-value. Kita dapat melihat series sebagai pasangan key-value dengan index sebagai key. Bahkan kita bisa membuat suatu series dari sebuah dictionary.\n\ndata_dict = {\n  'Jakarta': 400,\n  'Bandung': 200,\n  'Bogor': 300,\n  'Depok': 500\n}\ndata_dict\n\n{'Jakarta': 400, 'Bandung': 200, 'Bogor': 300, 'Depok': 500}\n\n\n\ndata_series = pd.Series(data_dict)\ndata_series\n\nJakarta    400\nBandung    200\nBogor      300\nDepok      500\ndtype: int64\n\n\n\nJika kita ingin index dengan urutan tertentu, maka kita dapat memasukkan argumen index berupa list index sesuai dengan urutan yang kita inginkan.\n\nkota = ['Surabaya', 'Bandung', 'Bogor', 'Jakarta']\ndata_series2 = pd.Series(data_dict, index=kota)\ndata_series2\n\nSurabaya      NaN\nBandung     200.0\nBogor       300.0\nJakarta     400.0\ndtype: float64\n\n\n\n\n\n\n\n\nTip\n\n\n\nPerhatikan bahwa jika kita memasukkan index yang tidak ada pada dictionary awal, index akan dimasukkan dengan nilai NaN (Not a Number)\n\n\n\n\n\n\nOperasi Aritmatika\n\nSeries secara otomatis menyamakan index ketika melakukan operasi aritmatika.\n\ndata_series + data_series2 # Silahkan coba untuk operasi aritmatika lainnya\n\nBandung     400.0\nBogor       600.0\nDepok         NaN\nJakarta     800.0\nSurabaya      NaN\ndtype: float64\n\n\n\n\n\n\n\n\nTip\n\n\n\nPerhatikan bahwa Depok dan Surabaya bernilai NaN. Hal ini dikarenakan kedua index tersebut tidak terdapat pada kedua series yang kita operasikan.\n\n\n\n\n\n\nname attribute\n\nObject series dan index pada pandas memiliki atribut name yaitu nama dari series/index tersebut.\n\ndata_series.name = 'populasi'\ndata_series.index.name = 'kota'\ndata_series\n\nkota\nJakarta    400\nBandung    200\nBogor      300\nDepok      500\nName: populasi, dtype: int64"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul1.html#dataframe",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul1.html#dataframe",
    "title": "Pertemuan 1 : Python for Data Analysis",
    "section": "DataFrame",
    "text": "DataFrame\n\nDataFrame adalah struktur data 2 dimensi yang terdiri atas baris dan kolom (disebut juga tabel). Kita dapat melihat dataframe sebagai gabungan dari 2 atau lebih series.\n\n\n\nKarena memiliki 2 dimensi (baris dan kolom), DataFrame memiliki indeks untuk masing-masing baris dan kolom.\n\nAda banyak cara untuk membangun DataFrame, salah satu yang paling umum adalah membuat dictionary dengan\nkey : nama kolom\nvalue : nilai-nilai dalam list atau NumPy Array dengan panjang yang sama untuk setiap kolom.\n\ndata = {'kota': ['Bogor', 'Bogor', 'Bogor', 'Depok', 'Depok', 'Depok'],\n 'tahun': [2000, 2001, 2002, 2001, 2002, 2003],\n 'populasi': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n\ndf = pd.DataFrame(data) # `df` adalah singkatan yang umum digunakan oleh komunitas python dalam mendefinisikan suatu `dataframe`\n\ndf\n\n\n\n\n\n\n\n\nkota\ntahun\npopulasi\n\n\n\n\n0\nBogor\n2000\n1.5\n\n\n1\nBogor\n2001\n1.7\n\n\n2\nBogor\n2002\n3.6\n\n\n3\nDepok\n2001\n2.4\n\n\n4\nDepok\n2002\n2.9\n\n\n5\nDepok\n2003\n3.2\n\n\n\n\n\n\n\npd.DataFrame() menerima argumen columns= yang dapat digunakan untuk menentukan urutan kolom dataframe.\n\ndf2 = pd.DataFrame(data, columns=['tahun', 'kota', 'populasi'])\n\ndf2\n\n\n\n\n\n\n\n\ntahun\nkota\npopulasi\n\n\n\n\n0\n2000\nBogor\n1.5\n\n\n1\n2001\nBogor\n1.7\n\n\n2\n2002\nBogor\n3.6\n\n\n3\n2001\nDepok\n2.4\n\n\n4\n2002\nDepok\n2.9\n\n\n5\n2003\nDepok\n3.2\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nmenambahkan kolom baru yang tidak ada pada data akan menghasilkan kolom berisi nilai NaN\npd.DataFrame juga menerima argumen index= untuk mengubah index seperti pada pd.Series\n\n\ndf2 = pd.DataFrame(data, columns=['tahun', 'kota', 'populasi', 'luas_wilayah'], \n                   index=['one', 'two', 'three', 'four', 'five', 'six'])\n\ndf2\n\n\n\n\n\n\n\n\ntahun\nkota\npopulasi\nluas_wilayah\n\n\n\n\none\n2000\nBogor\n1.5\nNaN\n\n\ntwo\n2001\nBogor\n1.7\nNaN\n\n\nthree\n2002\nBogor\n3.6\nNaN\n\n\nfour\n2001\nDepok\n2.4\nNaN\n\n\nfive\n2002\nDepok\n2.9\nNaN\n\n\nsix\n2003\nDepok\n3.2\nNaN\n\n\n\n\n\n\n\n\n\n\n\nImporting datasets\n\nDalam mengolah suatu data, tidaklah mungkin kita harus menulis ulang seluruh data yang sudah tertulis dengan format tertentu (misalnya Spreadsheet/.xlsx, .csv, atau .dat) pastinya kita perlu suatu cara untuk mengimpor data yang memiliki berbagai format. Pandas memiliki beberapa function yang dapat kita gunakan untuk membaca data dengan berbagai format.\n\n.csv (comma separated values)\n\ndf = pd.read_csv('&lt;path-to-csv&gt;')\n\n.xlsx (excel spreadsheet)\n\ndf = pd.read_excel('&lt;path-to-xlsx&gt;')\n\nOthers\n\nUntuk tipe file lainnya, silahkan baca dokumentasi pandas di link berikut : Pandas IO Tools\n\n\n\nDataFrame Attributes/Properties and Methods\n\nSejauh ini kita sudah berkenalan dengan 2 object pandas yaitu Series dan DataFrame. Dalam pemrograman python, sebuah object bisa memiliki suatu method, attribute/property, atau keduanya.\nUntuk materi selanjutnya, kita akan menggunakan dataset pokemon sebagai contoh. Jalankan code block di bawah ini.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/farhanage/dataset-for-study/main/pokemon_data.csv')\n\n\n\n\nhead()\nMemanggil method head akan mengembalikan beberapa baris pertama dari suatu dataframe.\n\ndf.head(3)  # Membaca 3 baris pertama\n\n\n\n\n\n\n\n\n#\nName\nType 1\nType 2\nHP\nAttack\nDefense\nSp. Atk\nSp. Def\nSpeed\nGeneration\nLegendary\n\n\n\n\n0\n1\nBulbasaur\nGrass\nPoison\n45\n49\n49\n65\n65\n45\n1\nFalse\n\n\n1\n2\nIvysaur\nGrass\nPoison\n60\n62\n63\n80\n80\n60\n1\nFalse\n\n\n2\n3\nVenusaur\nGrass\nPoison\n80\n82\n83\n100\n100\n80\n1\nFalse\n\n\n\n\n\n\n\n\n\n\ntail()\nMemanggil method tail akan mengembalikan beberapa baris terakhir dari suatu dataframe.\n\ndf.tail(3)  # Membaca 3 baris terakhir\n\n\n\n\n\n\n\n\n#\nName\nType 1\nType 2\nHP\nAttack\nDefense\nSp. Atk\nSp. Def\nSpeed\nGeneration\nLegendary\n\n\n\n\n797\n720\nHoopaHoopa Confined\nPsychic\nGhost\n80\n110\n60\n150\n130\n70\n6\nTrue\n\n\n798\n720\nHoopaHoopa Unbound\nPsychic\nDark\n80\n160\n60\n170\n130\n80\n6\nTrue\n\n\n799\n721\nVolcanion\nFire\nWater\n80\n110\n120\n130\n90\n70\n6\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nSecara default, method head() dan tail() akan mengembalikan 5 baris pertama/terakhir jika tidak diberikan suatu argumen.\n\n\n\n\n\nshape\nMemanggil attribute shape akan memberikan kita jumlah baris dan kolom dari suatu dataframe.\n\ndf.shape  # Mengembalikan (jumlah_baris, jumlah_kolom)\n\n(800, 12)\n\n\n\n\n\ncolumns\nMemanggil attribute columns akan memberikan kita index object berisi semua nama kolom dari suatu dataframe.\n\ndf.columns  # Mengembalikan index object berisi semua nama kolom dari suatu dataframe\n\nIndex(['#', 'Name', 'Type 1', 'Type 2', 'HP', 'Attack', 'Defense', 'Sp. Atk',\n       'Sp. Def', 'Speed', 'Generation', 'Legendary'],\n      dtype='object')\n\n\n\n\n\nindex\nMemanggil attribute columns akan memberikan kita index object berisi index baris suatu dataframe.\n\ndf.index  # Mengembalikan index object berisi index suatu dataframe\n\nRangeIndex(start=0, stop=800, step=1)\n\n\nPandas dataframe memiliki banyak sekali methods dan attributes/properties. Untuk mempelajari lebih lanjut mengenai dataframe pandas, dokumentasi library pandas bisa diakses pada link berikut : Pandas essential basic functionality"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul1.html#index-1",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul1.html#index-1",
    "title": "Pertemuan 1 : Python for Data Analysis",
    "section": "Index",
    "text": "Index\n\nPerhatikan pada atribut columns dan index yang telah dibahas sebelumnya, output kode adalah object index. Apa itu object index? Dalam library Pandas, object index digunakan sebagai object yang menyimpan label suatu object lainnya.\nContoh : dalam object DataFrame, index object digunakan untuk menyimpan label baris (df.index) dan kolom (df.columns).\n\nobj = pd.Series(range(3), index=['a', 'b', 'c'])\nobj.index\n\nIndex(['a', 'b', 'c'], dtype='object')\n\n\n\nobj.index[1]\n\n'b'\n\n\n\nobj.index[1:]\n\nIndex(['b', 'c'], dtype='object')\n\n\n\n\n\n\n\n\nError warning\n\n\n\nIndex object bersifat immutable, artinya nilai dari suatu index tidak dapat diubah.\n\nobj.index[1] = 'd'\n\nTypeError: Index does not support mutable operations\n\n\n\n\nIndex object juga memiliki beberapa attribute dan methods. Beberapa diantaranya :"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul1.html#basic-functionality",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul1.html#basic-functionality",
    "title": "Pertemuan 1 : Python for Data Analysis",
    "section": "Basic Functionality",
    "text": "Basic Functionality\n\nIndexing, Selection and Filtering\n\nIndexing and Selection\n\nSeries indexing digunakan untuk mengambil value yang berkaitan dengan suatu index.\n\nimport numpy as np\nobj = pd.Series(np.arange(4.), index=['a', 'b', 'c', 'd'])\nobj\n\na    0.0\nb    1.0\nc    2.0\nd    3.0\ndtype: float64\n\n\n\nobj['b']  # Memanggil nilai dengan index `a`\n\n1.0\n\n\n\nobj['a':'c']  # Memanggil nilai dengan index `a` hingga `c`\n\na    0.0\nb    1.0\nc    2.0\ndtype: float64\n\n\n\n\n\n\n\n\nImportant\n\n\n\nPerhatikan, saat melakukan slicing dengan explicit index (misal, data['a':'c']), final index diikutsertakan dalam outputnya (inklusif), sementara ketika melakukan slicing dengan implicit index (misal, data[0:2]), final index tidak diikutsertakan dalam outputnya (tidak inklusif).\n\n\n\nDataFrame indexing digunakan untuk mengambil 1 atau beberapa kolom dengan memanggil label/nama kolom yang bersesuaian.\n\ndf['Name']\n\n0                  Bulbasaur\n1                    Ivysaur\n2                   Venusaur\n3      VenusaurMega Venusaur\n4                 Charmander\n               ...          \n795                  Diancie\n796      DiancieMega Diancie\n797      HoopaHoopa Confined\n798       HoopaHoopa Unbound\n799                Volcanion\nName: Name, Length: 800, dtype: object\n\n\n\ndf[['Name']]\n\n\n\n\n\n\n\n\nName\n\n\n\n\n0\nBulbasaur\n\n\n1\nIvysaur\n\n\n2\nVenusaur\n\n\n3\nVenusaurMega Venusaur\n\n\n4\nCharmander\n\n\n...\n...\n\n\n795\nDiancie\n\n\n796\nDiancieMega Diancie\n\n\n797\nHoopaHoopa Confined\n\n\n798\nHoopaHoopa Unbound\n\n\n799\nVolcanion\n\n\n\n\n800 rows × 1 columns\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\ndf['&lt;column-name&gt;'] akan mengembalikan kolom yang bersesuaian dalam bentuk Series.\ndf[['&lt;column-name&gt;']] akan mengembalikan kolom yang bersesuaian dalam bentuk dataframe.\n\n\n\ndf[['Name','HP','Defense']]\n\n\n\n\n\n\n\n\nName\nHP\nDefense\n\n\n\n\n0\nBulbasaur\n45\n49\n\n\n1\nIvysaur\n60\n63\n\n\n2\nVenusaur\n80\n83\n\n\n3\nVenusaurMega Venusaur\n80\n123\n\n\n4\nCharmander\n39\n43\n\n\n...\n...\n...\n...\n\n\n795\nDiancie\n50\n150\n\n\n796\nDiancieMega Diancie\n50\n110\n\n\n797\nHoopaHoopa Confined\n80\n60\n\n\n798\nHoopaHoopa Unbound\n80\n60\n\n\n799\nVolcanion\n80\n120\n\n\n\n\n800 rows × 3 columns\n\n\n\n\nKita bisa membuat suatu kolom baru dari kolom-kolom yang sudah ada. Misalkan kita buat suatu variabel bernama Total Attack yang berisi hasil penjumlahan variabel Attack dan Sp. Atk\n\ndf['Total Attack'] = df['Attack'] + df['Sp. Atk']\ndf[['Attack','Sp. Atk','Total Attack']]\n\n\n\n\n\n\n\n\nAttack\nSp. Atk\nTotal Attack\n\n\n\n\n0\n49\n65\n114\n\n\n1\n62\n80\n142\n\n\n2\n82\n100\n182\n\n\n3\n100\n122\n222\n\n\n4\n52\n60\n112\n\n\n...\n...\n...\n...\n\n\n795\n100\n100\n200\n\n\n796\n160\n160\n320\n\n\n797\n110\n150\n260\n\n\n798\n160\n170\n330\n\n\n799\n110\n130\n240\n\n\n\n\n800 rows × 3 columns\n\n\n\n\nUntuk indexing baris suatu dataframe, gunakan index baris\n\ndf[:3] # Mengambil baris dengan index 0 - 2\n\n\n\n\n\n\n\n\n#\nName\nType 1\nType 2\nHP\nAttack\nDefense\nSp. Atk\nSp. Def\nSpeed\nGeneration\nLegendary\nTotal Attack\n\n\n\n\n0\n1\nBulbasaur\nGrass\nPoison\n45\n49\n49\n65\n65\n45\n1\nFalse\n114\n\n\n1\n2\nIvysaur\nGrass\nPoison\n60\n62\n63\n80\n80\n60\n1\nFalse\n142\n\n\n2\n3\nVenusaur\nGrass\nPoison\n80\n82\n83\n100\n100\n80\n1\nFalse\n182\n\n\n\n\n\n\n\n\ndf[0:5:2]  # Mengambil dengan index 0 sampai 4 dengan step 2\n\n\n\n\n\n\n\n\n#\nName\nType 1\nType 2\nHP\nAttack\nDefense\nSp. Atk\nSp. Def\nSpeed\nGeneration\nLegendary\nTotal Attack\n\n\n\n\n0\n1\nBulbasaur\nGrass\nPoison\n45\n49\n49\n65\n65\n45\n1\nFalse\n114\n\n\n2\n3\nVenusaur\nGrass\nPoison\n80\n82\n83\n100\n100\n80\n1\nFalse\n182\n\n\n4\n4\nCharmander\nFire\nNaN\n39\n52\n43\n60\n50\n65\n1\nFalse\n112\n\n\n\n\n\n\n\n\n\n\nFiltering\n\nUntuk melakukan filtering pada suatu dataframe :\n\ndf[df['HP'] == 50]  # Mengambil data pada dataframe df yang memiliki nilai kolom `HP` == 50\n\n\n\n\n\n\n\n\n#\nName\nType 1\nType 2\nHP\nAttack\nDefense\nSp. Atk\nSp. Def\nSpeed\nGeneration\nLegendary\nTotal Attack\n\n\n\n\n14\n11\nMetapod\nBug\nNaN\n50\n20\n55\n25\n25\n30\n1\nFalse\n45\n\n\n32\n27\nSandshrew\nGround\nNaN\n50\n75\n85\n20\n30\n40\n1\nFalse\n95\n\n\n59\n54\nPsyduck\nWater\nNaN\n50\n52\n48\n65\n50\n55\n1\nFalse\n117\n\n\n75\n69\nBellsprout\nGrass\nPoison\n50\n75\n35\n70\n30\n40\n1\nFalse\n145\n\n\n83\n77\nPonyta\nFire\nNaN\n50\n85\n55\n65\n65\n90\n1\nFalse\n150\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n760\n690\nSkrelp\nPoison\nWater\n50\n60\n60\n60\n60\n30\n6\nFalse\n120\n\n\n762\n692\nClauncher\nWater\nNaN\n50\n53\n62\n58\n63\n44\n6\nFalse\n111\n\n\n773\n703\nCarbink\nRock\nFairy\n50\n50\n150\n50\n150\n50\n6\nFalse\n100\n\n\n795\n719\nDiancie\nRock\nFairy\n50\n100\n150\n100\n150\n50\n6\nTrue\n200\n\n\n796\n719\nDiancieMega Diancie\nRock\nFairy\n50\n160\n110\n160\n110\n110\n6\nTrue\n320\n\n\n\n\n63 rows × 13 columns\n\n\n\n\ndf[df['HP'] &gt; 50]  # Mengambil data pada dataframe df yang memiliki nilai kolom `HP` &gt; 50\n\n\n\n\n\n\n\n\n#\nName\nType 1\nType 2\nHP\nAttack\nDefense\nSp. Atk\nSp. Def\nSpeed\nGeneration\nLegendary\nTotal Attack\n\n\n\n\n1\n2\nIvysaur\nGrass\nPoison\n60\n62\n63\n80\n80\n60\n1\nFalse\n142\n\n\n2\n3\nVenusaur\nGrass\nPoison\n80\n82\n83\n100\n100\n80\n1\nFalse\n182\n\n\n3\n3\nVenusaurMega Venusaur\nGrass\nPoison\n80\n100\n123\n122\n120\n80\n1\nFalse\n222\n\n\n5\n5\nCharmeleon\nFire\nNaN\n58\n64\n58\n80\n65\n80\n1\nFalse\n144\n\n\n6\n6\nCharizard\nFire\nFlying\n78\n84\n78\n109\n85\n100\n1\nFalse\n193\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n793\n717\nYveltal\nDark\nFlying\n126\n131\n95\n131\n98\n99\n6\nTrue\n262\n\n\n794\n718\nZygarde50% Forme\nDragon\nGround\n108\n100\n121\n81\n95\n95\n6\nTrue\n181\n\n\n797\n720\nHoopaHoopa Confined\nPsychic\nGhost\n80\n110\n60\n150\n130\n70\n6\nTrue\n260\n\n\n798\n720\nHoopaHoopa Unbound\nPsychic\nDark\n80\n160\n60\n170\n130\n80\n6\nTrue\n330\n\n\n799\n721\nVolcanion\nFire\nWater\n80\n110\n120\n130\n90\n70\n6\nTrue\n240\n\n\n\n\n589 rows × 13 columns\n\n\n\n\ndf[(df['HP'] &gt; 100) & (df['Type 1'] == 'Fire')]  # Mengambil data pada dataframe df yang memiliki nilai kolom `HP` &gt; 100 dan `Type 1` == Fire\n\n\n\n\n\n\n\n\n#\nName\nType 1\nType 2\nHP\nAttack\nDefense\nSp. Atk\nSp. Def\nSpeed\nGeneration\nLegendary\nTotal Attack\n\n\n\n\n263\n244\nEntei\nFire\nNaN\n115\n115\n85\n90\n75\n100\n2\nTrue\n205\n\n\n270\n250\nHo-oh\nFire\nFlying\n106\n130\n90\n110\n154\n90\n2\nTrue\n240\n\n\n559\n500\nEmboar\nFire\nFighting\n110\n123\n65\n100\n65\n65\n5\nFalse\n223\n\n\n615\n555\nDarmanitanStandard Mode\nFire\nNaN\n105\n140\n55\n30\n55\n95\n5\nFalse\n170\n\n\n616\n555\nDarmanitanZen Mode\nFire\nPsychic\n105\n30\n105\n140\n105\n55\n5\nFalse\n170\n\n\n\n\n\n\n\n\ndf[(df['HP'] &gt; 100) | (df['Type 1'] == 'Fire')]  # Mengambil data pada dataframe df yang memiliki nilai kolom `HP` &gt; 100 atau `Type 1` == Fire\n\n\n\n\n\n\n\n\n#\nName\nType 1\nType 2\nHP\nAttack\nDefense\nSp. Atk\nSp. Def\nSpeed\nGeneration\nLegendary\nTotal Attack\n\n\n\n\n4\n4\nCharmander\nFire\nNaN\n39\n52\n43\n60\n50\n65\n1\nFalse\n112\n\n\n5\n5\nCharmeleon\nFire\nNaN\n58\n64\n58\n80\n65\n80\n1\nFalse\n144\n\n\n6\n6\nCharizard\nFire\nFlying\n78\n84\n78\n109\n85\n100\n1\nFalse\n193\n\n\n7\n6\nCharizardMega Charizard X\nFire\nDragon\n78\n130\n111\n130\n85\n100\n1\nFalse\n260\n\n\n8\n6\nCharizardMega Charizard Y\nFire\nFlying\n78\n104\n78\n159\n115\n100\n1\nFalse\n263\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n769\n699\nAurorus\nRock\nIce\n123\n77\n72\n99\n92\n58\n6\nFalse\n176\n\n\n792\n716\nXerneas\nFairy\nNaN\n126\n131\n95\n131\n98\n99\n6\nTrue\n262\n\n\n793\n717\nYveltal\nDark\nFlying\n126\n131\n95\n131\n98\n99\n6\nTrue\n262\n\n\n794\n718\nZygarde50% Forme\nDragon\nGround\n108\n100\n121\n81\n95\n95\n6\nTrue\n181\n\n\n799\n721\nVolcanion\nFire\nWater\n80\n110\n120\n130\n90\n70\n6\nTrue\n240\n\n\n\n\n114 rows × 13 columns\n\n\n\nUntuk filter yang lebih rumit, disarankan untuk mendefinisikan variabel condition agar kode mudah terbaca.\nContoh : Filter (HP &gt;= 150) dan ((Type 1 == Water) atau (Legendary == True))\n\ncondition = (df['HP'] &gt;= 150) & ((df['Type 1'] == 'Water') | (df['Legendary'] == True))\ndf[condition]\n\n\n\n\n\n\n\n\n#\nName\nType 1\nType 2\nHP\nAttack\nDefense\nSp. Atk\nSp. Def\nSpeed\nGeneration\nLegendary\nTotal Attack\n\n\n\n\n351\n321\nWailord\nWater\nNaN\n170\n90\n45\n90\n45\n60\n3\nFalse\n180\n\n\n544\n487\nGiratinaAltered Forme\nGhost\nDragon\n150\n100\n120\n100\n120\n90\n4\nTrue\n200\n\n\n545\n487\nGiratinaOrigin Forme\nGhost\nDragon\n150\n120\n100\n120\n100\n90\n4\nTrue\n240\n\n\n655\n594\nAlomomola\nWater\nNaN\n165\n75\n80\n40\n45\n65\n5\nFalse\n115"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul3.html",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul3.html",
    "title": "Pertemuan 3 : Simple Data Visualization (matplotlib)",
    "section": "",
    "text": "Kembali ke EDA"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul3.html#box-plot",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul3.html#box-plot",
    "title": "Pertemuan 3 : Simple Data Visualization (matplotlib)",
    "section": "Box Plot",
    "text": "Box Plot\n\n# Box Plot variabel `age`\nplt.boxplot(x='age', data=df)\n\n# Menambahkan Judul Plot\nplt.title(\"Box Plot\")\n \n# Menambahkan label sumbu X dan Y\nplt.xlabel('Age')\nplt.ylabel('Value')\n\n# Menunjukkan plot\nplt.show()\n\n\n\n\n\n\n\n\n\n# Box Plot variabel `bmi`\nplt.boxplot(x='bmi', data=df)\n\n# Menambahkan Judul Plot\nplt.title(\"Box Plot\")\n \n# Menambahkan label sumbu X dan Y\nplt.xlabel('bmi')\nplt.ylabel('Value')\n\n# Menunjukkan plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nSeperti halnya penggunaan syntax ? pada bahasa pemrograman R, kita dapat mengakses dokumentasi suatu fungsi dalam suatu modul pada python dengan menggunakan function help()\n\n\n# Melihat dokumentasi mengenai function plt.boxplot()\nhelp(plt.boxplot)\n\nHelp on function boxplot in module matplotlib.pyplot:\n\nboxplot(x: 'ArrayLike | Sequence[ArrayLike]', notch: 'bool | None' = None, sym: 'str | None' = None, vert: 'bool | None' = None, whis: 'float | tuple[float, float] | None' = None, positions: 'ArrayLike | None' = None, widths: 'float | ArrayLike | None' = None, patch_artist: 'bool | None' = None, bootstrap: 'int | None' = None, usermedians: 'ArrayLike | None' = None, conf_intervals: 'ArrayLike | None' = None, meanline: 'bool | None' = None, showmeans: 'bool | None' = None, showcaps: 'bool | None' = None, showbox: 'bool | None' = None, showfliers: 'bool | None' = None, boxprops: 'dict[str, Any] | None' = None, labels: 'Sequence[str] | None' = None, flierprops: 'dict[str, Any] | None' = None, medianprops: 'dict[str, Any] | None' = None, meanprops: 'dict[str, Any] | None' = None, capprops: 'dict[str, Any] | None' = None, whiskerprops: 'dict[str, Any] | None' = None, manage_ticks: 'bool' = True, autorange: 'bool' = False, zorder: 'float | None' = None, capwidths: 'float | ArrayLike | None' = None, *, data=None) -&gt; 'dict[str, Any]'\n    Draw a box and whisker plot.\n\n    The box extends from the first quartile (Q1) to the third\n    quartile (Q3) of the data, with a line at the median.\n    The whiskers extend from the box to the farthest data point\n    lying within 1.5x the inter-quartile range (IQR) from the box.\n    Flier points are those past the end of the whiskers.\n    See https://en.wikipedia.org/wiki/Box_plot for reference.\n\n    .. code-block:: none\n\n              Q1-1.5IQR   Q1   median  Q3   Q3+1.5IQR\n                           |-----:-----|\n           o      |--------|     :     |--------|    o  o\n                           |-----:-----|\n         flier             &lt;-----------&gt;            fliers\n                                IQR\n\n\n    Parameters\n    ----------\n    x : Array or a sequence of vectors.\n        The input data.  If a 2D array, a boxplot is drawn for each column\n        in *x*.  If a sequence of 1D arrays, a boxplot is drawn for each\n        array in *x*.\n\n    notch : bool, default: False\n        Whether to draw a notched boxplot (`True`), or a rectangular\n        boxplot (`False`).  The notches represent the confidence interval\n        (CI) around the median.  The documentation for *bootstrap*\n        describes how the locations of the notches are computed by\n        default, but their locations may also be overridden by setting the\n        *conf_intervals* parameter.\n\n        .. note::\n\n            In cases where the values of the CI are less than the\n            lower quartile or greater than the upper quartile, the\n            notches will extend beyond the box, giving it a\n            distinctive \"flipped\" appearance. This is expected\n            behavior and consistent with other statistical\n            visualization packages.\n\n    sym : str, optional\n        The default symbol for flier points.  An empty string ('') hides\n        the fliers.  If `None`, then the fliers default to 'b+'.  More\n        control is provided by the *flierprops* parameter.\n\n    vert : bool, default: True\n        If `True`, draws vertical boxes.\n        If `False`, draw horizontal boxes.\n\n    whis : float or (float, float), default: 1.5\n        The position of the whiskers.\n\n        If a float, the lower whisker is at the lowest datum above\n        ``Q1 - whis*(Q3-Q1)``, and the upper whisker at the highest datum\n        below ``Q3 + whis*(Q3-Q1)``, where Q1 and Q3 are the first and\n        third quartiles.  The default value of ``whis = 1.5`` corresponds\n        to Tukey's original definition of boxplots.\n\n        If a pair of floats, they indicate the percentiles at which to\n        draw the whiskers (e.g., (5, 95)).  In particular, setting this to\n        (0, 100) results in whiskers covering the whole range of the data.\n\n        In the edge case where ``Q1 == Q3``, *whis* is automatically set\n        to (0, 100) (cover the whole range of the data) if *autorange* is\n        True.\n\n        Beyond the whiskers, data are considered outliers and are plotted\n        as individual points.\n\n    bootstrap : int, optional\n        Specifies whether to bootstrap the confidence intervals\n        around the median for notched boxplots. If *bootstrap* is\n        None, no bootstrapping is performed, and notches are\n        calculated using a Gaussian-based asymptotic approximation\n        (see McGill, R., Tukey, J.W., and Larsen, W.A., 1978, and\n        Kendall and Stuart, 1967). Otherwise, bootstrap specifies\n        the number of times to bootstrap the median to determine its\n        95% confidence intervals. Values between 1000 and 10000 are\n        recommended.\n\n    usermedians : 1D array-like, optional\n        A 1D array-like of length ``len(x)``.  Each entry that is not\n        `None` forces the value of the median for the corresponding\n        dataset.  For entries that are `None`, the medians are computed\n        by Matplotlib as normal.\n\n    conf_intervals : array-like, optional\n        A 2D array-like of shape ``(len(x), 2)``.  Each entry that is not\n        None forces the location of the corresponding notch (which is\n        only drawn if *notch* is `True`).  For entries that are `None`,\n        the notches are computed by the method specified by the other\n        parameters (e.g., *bootstrap*).\n\n    positions : array-like, optional\n        The positions of the boxes. The ticks and limits are\n        automatically set to match the positions. Defaults to\n        ``range(1, N+1)`` where N is the number of boxes to be drawn.\n\n    widths : float or array-like\n        The widths of the boxes.  The default is 0.5, or ``0.15*(distance\n        between extreme positions)``, if that is smaller.\n\n    patch_artist : bool, default: False\n        If `False` produces boxes with the Line2D artist. Otherwise,\n        boxes are drawn with Patch artists.\n\n    labels : sequence, optional\n        Labels for each dataset (one per dataset).\n\n    manage_ticks : bool, default: True\n        If True, the tick locations and labels will be adjusted to match\n        the boxplot positions.\n\n    autorange : bool, default: False\n        When `True` and the data are distributed such that the 25th and\n        75th percentiles are equal, *whis* is set to (0, 100) such\n        that the whisker ends are at the minimum and maximum of the data.\n\n    meanline : bool, default: False\n        If `True` (and *showmeans* is `True`), will try to render the\n        mean as a line spanning the full width of the box according to\n        *meanprops* (see below).  Not recommended if *shownotches* is also\n        True.  Otherwise, means will be shown as points.\n\n    zorder : float, default: ``Line2D.zorder = 2``\n        The zorder of the boxplot.\n\n    Returns\n    -------\n    dict\n      A dictionary mapping each component of the boxplot to a list\n      of the `.Line2D` instances created. That dictionary has the\n      following keys (assuming vertical boxplots):\n\n      - ``boxes``: the main body of the boxplot showing the\n        quartiles and the median's confidence intervals if\n        enabled.\n\n      - ``medians``: horizontal lines at the median of each box.\n\n      - ``whiskers``: the vertical lines extending to the most\n        extreme, non-outlier data points.\n\n      - ``caps``: the horizontal lines at the ends of the\n        whiskers.\n\n      - ``fliers``: points representing data that extend beyond\n        the whiskers (fliers).\n\n      - ``means``: points or lines representing the means.\n\n    Other Parameters\n    ----------------\n    showcaps : bool, default: True\n        Show the caps on the ends of whiskers.\n    showbox : bool, default: True\n        Show the central box.\n    showfliers : bool, default: True\n        Show the outliers beyond the caps.\n    showmeans : bool, default: False\n        Show the arithmetic means.\n    capprops : dict, default: None\n        The style of the caps.\n    capwidths : float or array, default: None\n        The widths of the caps.\n    boxprops : dict, default: None\n        The style of the box.\n    whiskerprops : dict, default: None\n        The style of the whiskers.\n    flierprops : dict, default: None\n        The style of the fliers.\n    medianprops : dict, default: None\n        The style of the median.\n    meanprops : dict, default: None\n        The style of the mean.\n    data : indexable object, optional\n        If given, all parameters also accept a string ``s``, which is\n        interpreted as ``data[s]`` (unless this raises an exception).\n\n    See Also\n    --------\n    violinplot : Draw an estimate of the probability density function."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul3.html#histogram",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul3.html#histogram",
    "title": "Pertemuan 3 : Simple Data Visualization (matplotlib)",
    "section": "Histogram",
    "text": "Histogram\n\n# Histogram variabel `bmi`\nplt.hist(x='bmi', data=df)\n\n# Menambahkan Judul Plot\nplt.title(\"Histogram\")\n \n# Menambahkan label sumbu X dan Y\nplt.xlabel('bmi')\nplt.ylabel('Count')\n\n# Menunjukkan plot\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul3.html#bar-chart",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul3.html#bar-chart",
    "title": "Pertemuan 3 : Simple Data Visualization (matplotlib)",
    "section": "Bar Chart",
    "text": "Bar Chart\n\n# Hitung banyaknya responden dari masing-masing gender\ndf['sex'].value_counts()\n\nsex\nmale      676\nfemale    662\nName: count, dtype: int64\n\n\n\n# Bar chart jumlah tiap jenis kelamin\ndf['sex'].value_counts().plot(kind='bar')\n\n# Menambahkan Judul Plot\nplt.title(\"Bar Chart\")\n \n# Menambahkan label sumbu X dan Y\nplt.xlabel('sex')\nplt.ylabel('count')\n\n# Menunjukkan plot\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul3.html#horizontal-bar-chart",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul3.html#horizontal-bar-chart",
    "title": "Pertemuan 3 : Simple Data Visualization (matplotlib)",
    "section": "Horizontal Bar Chart",
    "text": "Horizontal Bar Chart\n\n# Horizontal Bar chart jumlah tiap jenis kelamin\ndf['sex'].value_counts().plot(kind='barh')\n\n# Menambahkan Judul Plot\nplt.title(\"Bar Chart\")\n \n# Menambahkan label sumbu X dan Y\nplt.xlabel('count')\nplt.ylabel('sex')\n\n# Menunjukkan plot\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul3.html#pie-chart",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul3.html#pie-chart",
    "title": "Pertemuan 3 : Simple Data Visualization (matplotlib)",
    "section": "Pie Chart",
    "text": "Pie Chart\n\n# Pie chart persentase sebaran region seluruh responden\ndf['region'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n\n# Menambahkan Judul Plot\nplt.title(\"Pie Chart\")\n\n# Menunjukkan plot\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul3.html#scatter-plot",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul3.html#scatter-plot",
    "title": "Pertemuan 3 : Simple Data Visualization (matplotlib)",
    "section": "Scatter Plot",
    "text": "Scatter Plot\n\n# Scatter plot variabel `age` dan `charges`\ndf.plot(kind='scatter', x='age', y='charges')\n\n# Menambahkan Judul Plot\nplt.title(\"Scatter Plot `Age` vs `Charges`\")\n \n# Menambahkan label sumbu X dan Y\nplt.xlabel('Age')\nplt.ylabel('Charges')\n\n# Menunjukkan plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\nUntuk plot lainnya, silakan telusuri dokumentasi dari library matplotlib yang dapat diakses pada link berikut : Dokumentasi matplotlib.pyplot"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul3.html#figure-and-axes",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul3.html#figure-and-axes",
    "title": "Pertemuan 3 : Simple Data Visualization (matplotlib)",
    "section": "Figure and Axes",
    "text": "Figure and Axes\n\nPembuatan suatu plot menggunakan library matplotlib akan menghasilkan suatu figure yang memiliki beberapa komponen di dalamnya.\n\nBerikut cara membuat suatu figure menggunakan matplotlib\n\n\nfig = plt.figure()  # an empty figure with no Axes\n\nplt.show()\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\nFigure kosong tidak dapat divisualisasikan. Untuk membuat suatu figure yang memiliki axes, gunakan function plt.subplots()\n\n\nfig, ax = plt.subplots()  # a figure with a single Axes\n\nplt.show()\n\n\n\n\n\n\n\n\n\nBagaimana jika kita ingin membuat gabungan dari beberapa Axes dalam 1 figure?\nfunction subplots menerima parameter jumlah baris dan jumlah kolom untuk membentuk suatu grid yang terdiri atas 1 atau lebih axes\n\n\nfig, axs = plt.subplots(2, 2)  # a figure with a 2x2 grid of Axes\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelain dengan function subplots, ada juga function subplot_mosaic yang akan menghasilkan axes dengan ukuran yang lebih bervariasi.\n\n\n# a figure with one axes on the left, and two on the right:\nfig, axs = plt.subplot_mosaic([['left', 'right_top'],\n                               ['left', 'right_bottom']])\n\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul3.html#plots",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul3.html#plots",
    "title": "Pertemuan 3 : Simple Data Visualization (matplotlib)",
    "section": "Plots",
    "text": "Plots\n\nUntuk menambahkan plot pada tiap axis, gunakan function-function plot pada axis dengan index yang bersesuaian.\n\n\nfig, axs = plt.subplots(2, 2, layout=\"constrained\")\n\naxs[0,0].hist(df['age'])\n\naxs[0,0].set_title('Variabel `Age`')\n\naxs[0,1].hist(df['bmi'])\n\naxs[0,1].set_title('Variabel `bmi`')\n\naxs[1,0].hist(df['children'])\n\naxs[1,0].set_title('Variabel `children`')\n\naxs[1,1].hist(df['charges'])\n\naxs[1,1].set_title('Variabel `charges`')\n\nfig.suptitle('Histogram Variabel Numerik')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nLebih lanjut, silakan baca dokumentasi dari plt.subplot pada link berikut : Dokumentasi plt.subplots"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul5.html",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul5.html",
    "title": "Pertemuan 5 : Time Series Visualization",
    "section": "",
    "text": "Kembali ke EDA"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul5.html#converting-object-to-datetime",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul5.html#converting-object-to-datetime",
    "title": "Pertemuan 5 : Time Series Visualization",
    "section": "Converting object to datetime",
    "text": "Converting object to datetime\nPerhatikan code cell berikut untuk mengubah data bertipe object menjadi datetime\n\n# Mengubah data `object` -&gt; `datetime`\ndf['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y')\n\n\n\n\n\n\n\nDate Format\n\n\n\nArgumen format='%m/%d/%Y' digunakan untuk membaca format penanggalan yang tertulis pada kolom yang ingin kita ubah. %d menandakan hari, %m untuk bulan, %y untuk tahun 2 digit dan %Y untuk tahun 4 digit.\ne.g. : '2024-05-26' -&gt; '%Y-%m-%d'\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 397 entries, 0 to 396\nData columns (total 2 columns):\n #   Column               Non-Null Count  Dtype         \n---  ------               --------------  -----         \n 0   date                 397 non-null    datetime64[ns]\n 1   electric_production  397 non-null    float64       \ndtypes: datetime64[ns](1), float64(1)\nmemory usage: 6.3 KB\n\n\nTerlihat bahwa kolom date kini memiliki tipe data datetime64[ns].\n\ndf.head()\n\n\n\n\n\n\n\n\ndate\nelectric_production\n\n\n\n\n0\n1985-01-01\n72.5052\n\n\n1\n1985-02-01\n70.6720\n\n\n2\n1985-03-01\n62.4502\n\n\n3\n1985-04-01\n57.4714\n\n\n4\n1985-05-01\n55.3151\n\n\n\n\n\n\n\nTerlihat setelah dilakukan perubahan tipe data, format penanggalan pada kolom date juga berubah."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul5.html#plots",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul5.html#plots",
    "title": "Pertemuan 5 : Time Series Visualization",
    "section": "Plots",
    "text": "Plots\n\nsum_per_year = df['electric_production'].groupby(df['date'].dt.year).sum() # sum of electric_production, grouped by year\n\nsns.lineplot(sum_per_year)\n\nplt.title('Jumlah produksi listrik per tahun (1985-2018)')\n\nplt.show()\n\n\n\n\n\n\n\n\nkenapa tahun 2018 turun drastis? cek semua observasi pada tahun 2018\n\n# Ambil data dengan tahun == 2018\ndf[df['date'].dt.year == 2018]\n\n\n\n\n\n\n\n\ndate\nelectric_production\n\n\n\n\n396\n2018-01-01\n129.4048\n\n\n\n\n\n\n\nTernyata tahun 2018 hanya memiliki 1 observasi, sehingga tidak dapat dibandingkan dengan jumlah produksi tahun-tahun sebelumnya.\n\n# buang data tahun 2018\ndf.drop(df[df['date'].dt.year == 2018].index, axis=0, inplace=True)\n\n\ndf[df['date'].dt.year == 2018]\n\n\n\n\n\n\n\n\ndate\nelectric_production\n\n\n\n\n\n\n\n\n\nData sudah berhasil dibuang, sehingga dapat dilakukan visualisasi yang lebih akurat\n\nsum_per_year = df['electric_production'].groupby(df['date'].dt.year).sum() # sum of electric_production, grouped by year\n\nsns.lineplot(sum_per_year)\n\nplt.xlabel('year')\n\nplt.ylabel('electric production')\n\nplt.title('Jumlah produksi listrik per tahun (1985-2017)')\n\nplt.show()\n\n\n\n\n\n\n\n\nInterpretasinya?\n\navg_per_month = df['electric_production'].groupby(df['date'].dt.month).mean() # mean of electric_production, grouped by month\n\nsns.barplot(avg_per_month)\n\nplt.xlabel('month')\n\nplt.ylabel('average electric production')\n\nplt.title('Rata-rata produksi listrik per bulan (1985-2017)')\n\nplt.show()\n\n\n\n\n\n\n\n\nInterpretasi? Kaitkan dengan musim?"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul1.html",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul1.html",
    "title": "Modul 1 Kalkulin: Basic LaTeX Part 1",
    "section": "",
    "text": "Kembali ke Kalkulin\nDalam beberapa pertemuan ke depan, kita akan mempelajari bahasa LaTeX. Untuk itu, ada opsi offline serta opsi online untuk software yang digunakan.\nOpsi offline adalah dengan menginstal Miktex kemudian menginstal TeXStudio:\nOpsi online, yang lebih mudah dan cenderung lebih sering digunakan, adalah dengan membuat akun dan login ke website Overleaf:\nhttps://www.overleaf.com/"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul1.html#pengantar",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul1.html#pengantar",
    "title": "Modul 1 Kalkulin: Basic LaTeX Part 1",
    "section": "Pengantar",
    "text": "Pengantar"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul1.html#getting-started",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul1.html#getting-started",
    "title": "Modul 1 Kalkulin: Basic LaTeX Part 1",
    "section": "Getting started",
    "text": "Getting started\n\n\nClick here to open the example document in Overleaf"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul1.html#typesetting-text",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul1.html#typesetting-text",
    "title": "Modul 1 Kalkulin: Basic LaTeX Part 1",
    "section": "Typesetting Text",
    "text": "Typesetting Text\n\n\n\n\nClick to open this exercise in Overleaf\nclick here to see my solution\nhttp://en.wikipedia.org/wiki/Economy_of_the_United_States"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul1.html#typesetting-mathematics",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul1.html#typesetting-mathematics",
    "title": "Modul 1 Kalkulin: Basic LaTeX Part 1",
    "section": "Typesetting Mathematics",
    "text": "Typesetting Mathematics\n\n\n\n\n\n\n\n\n\nClick to open this exercise in Overleaf\nclick here to see my solution"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul1.html#penutup",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul1.html#penutup",
    "title": "Modul 1 Kalkulin: Basic LaTeX Part 1",
    "section": "Penutup",
    "text": "Penutup"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul3.html",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul3.html",
    "title": "Modul 3 Kalkulin: LaTeX Beamer",
    "section": "",
    "text": "Kembali ke Kalkulin"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul3.html#latex-recap",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul3.html#latex-recap",
    "title": "Modul 3 Kalkulin: LaTeX Beamer",
    "section": "LaTeX Recap",
    "text": "LaTeX Recap\n\n\n\n\n\n\nClick to open this exercise in Overleaf\nClick to open the model document\nhttp://www.cgd.ucar.edu/cms/agu/scientific_talk.html"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul3.html#presentations-with-beamer",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul3.html#presentations-with-beamer",
    "title": "Modul 3 Kalkulin: LaTeX Beamer",
    "section": "Presentations with beamer",
    "text": "Presentations with beamer\n\n\nClick to open the example document in Overleaf\n\n\n\n\nhttp://www.math.umbc.edu/~rouben/beamer/quickstart-Z-H-25.html\n\n\n\n\nhttp://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html\n\n\n\nClick to open this exercise in Overleaf\nClick to download image\nClick to open the model document\nhttp://norvig.com/Gettysburg"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul3.html#drawings-with-tikz",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul3.html#drawings-with-tikz",
    "title": "Modul 3 Kalkulin: LaTeX Beamer",
    "section": "Drawings with TikZ",
    "text": "Drawings with TikZ\n\n\n\n\n\n\n\n\n\nTeXample\n\nhttp://xkcd.com/1022"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul3.html#notes-with-todonotes",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul3.html#notes-with-todonotes",
    "title": "Modul 3 Kalkulin: LaTeX Beamer",
    "section": "Notes with todonotes",
    "text": "Notes with todonotes"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul3.html#spreadsheets-with-spreadtab",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul3.html#spreadsheets-with-spreadtab",
    "title": "Modul 3 Kalkulin: LaTeX Beamer",
    "section": "Spreadsheets with spreadtab",
    "text": "Spreadsheets with spreadtab\n\nhttp://www.ctan.org/pkg/spreadtab"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul5.html",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul5.html",
    "title": "Modul 5 Kalkulin: Eigen, Diagonalisasi, Ortogonalitas",
    "section": "",
    "text": "Kembali ke Kalkulin"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/latdifmetnum.html",
    "href": "semuahalaman/modulprak/2024/genap/metnum/latdifmetnum.html",
    "title": "Latihan (Wajib) Diferensiasi Numerik",
    "section": "",
    "text": "Kembali ke Metode Numerik\nDiberikan: Senin/Selasa, 22/23 April 2024 (ketika praktikum Diferensiasi Numerik & Ekstrapolasi Richardson)\nDeadline: Rabu, 24 April 2024, 23.59 WIB\nSecara pemrograman, kerjakan empat soal berikut (yang ada di buku Burden):\nExercise Set 4.1\n\nno. 1a\nno. 1b\nno. 9a\nno. 9b\n\nAnda dipersilakan memanfaatkan modul praktikum, terutama Modul 3 tentang Diferensiasi Numerik dan Ekstrapolasi Richardson.\nSetelah selesai, kumpulkan file .ipynb nya di link berikut (sesuai kelas):\n\n(Kelas A): https://bit.ly/LatDifMetnumA\n(Kelas B): https://bit.ly/LatDifMetnumB\n(Kelas C): https://bit.ly/LatDifMetnumC\n(Kelas D): https://bit.ly/LatDifMetnumD\n(Kelas E): https://bit.ly/LatDifMetnumE\n(Kelas F): https://bit.ly/LatDifMetnumF"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/metnum2024genap.html",
    "href": "semuahalaman/modulprak/2024/genap/metnum/metnum2024genap.html",
    "title": "Praktikum Metode Numerik 2024 Genap (Kurikulum 2020)",
    "section": "",
    "text": "Kembali ke Praktikum\n\nTimeline\n\nModul 0: Review Python, NumPy, Matplotlib, tidak dibahas di sesi praktikum\nModul 1: Tabulate, SymPy, Metode Root-finding, 26-27 Februari 2024 (offline di Lab Komputer D.311)\nTugas 1: Metode root-finding\nDiberikan: Jumat, 8 Maret 2024\nDeadline: Sabtu, 23 Maret 2024, 23.59 WIB\nModul 2: Interpolasi, 18 Maret 2024 (online melalui Zoom)\nModul 3: Diferensiasi Numerik, Ekstrapolasi Richardson, 22-23 April 2024 (offline di Lab Komputer D.311)\nLatihan (Wajib) Diferensiasi Numerik\nDiberikan: Senin/Selasa, 22/23 April 2024 (ketika praktikum Diferensiasi Numerik & Ekstrapolasi Richardson)\nDeadline: Rabu, 24 April 2024, 23.59 WIB\nModul 4: Integrasi Numerik, 29-30 April 2024 (offline di Lab Komputer D.311)\nLatihan (Wajib) Integrasi Numerik\nDiberikan: Senin/Selasa, 29/30 April 2024 (ketika praktikum Integrasi Numerik)\nDeadline: Minggu, 5 Mei 2024, 23.59 WIB\nModul 5: Metode Langsung untuk SPL, 6-7 Mei 2024 (offline di Lab Komputer D.311)\nTugas 2: Interpolasi, Diferensiasi Numerik\nDiberikan: Selasa, 7 Mei 2024\nDeadline: Rabu, 22 Mei 2024, 23.59 WIB\nModul 6: Metode Iteratif untuk SPL, 13-14 Mei 2024 (offline di Lab Komputer D.311)\nTugas 3: Integrasi Numerik, SPL\nDiberikan: Jumat, 24 Mei 2024\nDeadline: Minggu, 9 Juni 2024, 23.59 WIB\n\n\n\nRekaman praktikum\nUntuk pertemuan-pertemuan praktikum Metode Numerik yang dilaksanakan secara online melalui Zoom, semua rekaman disimpan di link berikut.\nhttps://bit.ly/RekamanPrakMetnum2024Genap"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul1.html",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul1.html",
    "title": "Modul 1 Metode Numerik: Tabulate, SymPy, Root-finding",
    "section": "",
    "text": "Kembali ke Metode Numerik\nSelamat datang di praktikum Metode Numerik!\nPada praktikum ini, kalian akan diajarkan esensial-esensial yang dibutuhkan dan algoritma dasar untuk metode-metode pada Metnum.\nSemua modul telah diuji menggunakan Jupyter Notebook dengan Python 3.11, serta Google Colaboratory yang menggunakan Python 3.9. Semua kode pada modul masih bisa digunakan untuk semua Python versi 3.6 ke atas.\nKalian juga bisa menggunakan aplikasi/IDE (Integrated Development Environment) lainnya seperti PyCharm, Spyder, atau bahkan IDLE (IDLE adalah IDE bawaan Python yang diinstal dari python.org), namun kalian disarankan menggunakan Jupyter Notebook atau Google Colaboratory karena file tugas menggunakan file format .ipynb.\nOUTLINE"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul1.html#tabulate",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul1.html#tabulate",
    "title": "Modul 1 Metode Numerik: Tabulate, SymPy, Root-finding",
    "section": "Tabulate",
    "text": "Tabulate\nUntuk menyajikan hasil iterasi, tabel sering digunakan karena akan mudah membacanya. Di Python, terdapat package untuk membuat tabel dengan cara sederhana. Package tersebut bernama tabulate.\nSeperti package umumnya, pertama kita import terlebih dahulu.\n\nfrom tabulate import tabulate\n\nApabila terjadi error (karena tabulate belum terinstall), kalian bisa mengetik pip install tabulate (atau !pip install tabulate dengan tanda seru)\n\npip install tabulate\n\nRequirement already satisfied: tabulate in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.9.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n!pip install tabulate\n\ndan seperti biasa, setelah instalasi selesai, mungkin kalian perlu menutup kemudian membuka kembali Jupyter Notebook sebelum bisa menggunakan tabulate.\nSekarang, buat konten tabel. Konten tabel disimpan dalam list/array 2-D dimana setiap array di dalamnya adalah baris.\nHeaders dari tabel dapat kita buat sendiri. Jumlah dari headers harus sama dengan jumlah elemen pada setiap array.\n‘tablefmt’ adalah format bentuk tabel. Format yang biasa digunakan adalah “orgtbl”, dan ada macam-macam format tabel yang bisa dicari di https://pypi.org/project/tabulate/\n\ntable = [[\"Jeruk\", 1], [\"Nanas\", 2]]\nprint(tabulate(table, headers = [\"Buah\", \"Kuantitas\"], tablefmt = \"orgtbl\"))\n\n| Buah   |   Kuantitas |\n|--------+-------------|\n| Jeruk  |           1 |\n| Nanas  |           2 |\n\n\nDalam membuat konten tabel, panjang dari setiap list harus sama dengan banyak headers. Apabila ada baris yang banyak elemennya melebihi banyak headers, maka elemen yang diambil adalah elemen sebanyak headers yang pertama. Kolom paling kiri diisi terlebih dahulu.\nPerhatikan contoh berikut.\n\ntable = [[\"Jeruk\", 1, 4], [\"Nanas\", 2, 3, 5], [\"Mangga\", 3]]\nprint(tabulate(table, headers = [\"Buah\", \"Kuantitas\", \"Harga\"], tablefmt = \"orgtbl\"))\n\n| Buah   |   Kuantitas |   Harga |\n|--------+-------------+---------|\n| Jeruk  |           1 |       4 |\n| Nanas  |           2 |       3 |\n| Mangga |           3 |         |\n\n\nApabila baris pertama digunakan sebagai header, banyak kolom akan sama dengan banyak elemen yang paling banyak di antara semua baris tabel. Penamaan kolom dimulai dari kanan.\nPerhatikan contoh berikut.\n\ntable = [[\"Saya\", 1, 4], [\"Tampan\", 2, 3, 5], [\"Banget\", 3, 5]]\nprint(tabulate(table, headers = \"firstrow\", tablefmt = \"orgtbl\"))\n\n|        |   Saya |   1 |   4 |\n|--------+--------+-----+-----|\n| Tampan |      2 |   3 |   5 |\n| Banget |      3 |   5 |     |\n\n\nTabulate sangat berguna untuk membentuk tabel secara “otomatis” atau secara pemrograman. Misalnya, kita bisa memanfaatkan looping dan pernyataan kondisional untuk membuat beberapa baris yang mengikuti pola dan syarat tertentu.\nSebagai contoh, misalnya kita punya function yang menghitung bilangan kuadrat ke-i\n\ndef kuadrat(i):\n    return i**2\n\n\nprint(kuadrat(5))\n\n25\n\n\nKita bisa membuat tabel, misalnya, yang menjabarkan bilangan kuadrat ke-1 sampai ke-5. Perhatikan struktur tabel apabila dibuat secara manual:\n\ntabel_kuadrat = [\n    [1, 1],\n    [2, 4],\n    [3, 9],\n    [4, 16],\n    [5, 15]\n]\nprint(tabulate(tabel_kuadrat, headers=[\"i\", \"kuadrat\"]))\n\n  i    kuadrat\n---  ---------\n  1          1\n  2          4\n  3          9\n  4         16\n  5         15\n\n\nTerlihat bahwa tabel tersebut memiliki lima baris, dan tiap baris berupa list yang merupakan elemen dari list besar tabel_kuadrat. Kita bisa membuatnya secara “otomatis” atau secara pemrograman:\n\ntabel_mentah = []\nfor i in range(1, 6): # mulai dari 1, lanjut selama kurang dari 6\n    calon_baris = [i, kuadrat(i)] # baris baru\n    tabel_mentah.append(calon_baris) # menambahkan baris baru ke list besar\n\nprint(tabulate(tabel_mentah, headers=[\"i\", \"kuadrat\"]))\n\n  i    kuadrat\n---  ---------\n  1          1\n  2          4\n  3          9\n  4         16\n  5         25\n\n\nTentu saja, calon_baris tidak harus langsung jadi ketika baru didefinisikan. Tiap bagian dari suatu baris bisa saja ditambahkan secara berangsur-angsur:\n\ntabel_mentah = []\nfor i in range(1, 6): # mulai dari 1, lanjut selama kurang dari 6\n    calon_baris = [] # baris baru\n    calon_baris.append(i) # bagian pertama pada baris\n\n    # bagian kedua pada baris\n    nilai_kedua = kuadrat(i)\n    calon_baris.append(nilai_kedua)\n\n    tabel_mentah.append(calon_baris) # menambahkan baris baru ke list besar\n\nprint(tabulate(tabel_mentah, headers=[\"i\", \"kuadrat\"]))\n\n  i    kuadrat\n---  ---------\n  1          1\n  2          4\n  3          9\n  4         16\n  5         25\n\n\nAdanya lebih dari dua kolom juga sangat memungkinkan, tinggal ditambahkan ke calon_baris:\n\ntabel_mentah = []\nfor i in range(1, 6): # mulai dari 1, lanjut selama kurang dari 6\n    calon_baris = [] # baris baru\n\n    # bagian pertama pada baris\n    calon_baris.append(i)\n\n    # bagian kedua pada baris\n    nilai_kedua = kuadrat(i)\n    calon_baris.append(nilai_kedua)\n\n    # bagian ketiga\n    calon_baris.append(i**3)\n\n    # bagian keempat\n    calon_baris.append(i**4)\n\n    tabel_mentah.append(calon_baris) # menambahkan baris baru ke list besar\n\nprint(tabulate(tabel_mentah, headers=[\"i\", \"kuadrat\", \"pangkat tiga\",\"pangkat empat\"]))\n\n  i    kuadrat    pangkat tiga    pangkat empat\n---  ---------  --------------  ---------------\n  1          1               1                1\n  2          4               8               16\n  3          9              27               81\n  4         16              64              256\n  5         25             125              625\n\n\nApabila kita sudah memiliki data tiap kolom dalam bentuk list, kita bisa membentuk calon_baris pada tiap iterasi for loop dengan mengakses elemen ke-i dari tiap list.\n\n# misalnya data ini sudah ada, atau sudah diolah sebelumnya\nkolom_awal = [1, 2, 3, 4, 5]\nkolom_kuadrat = [1, 4, 9, 16, 25]\nkolom_tiga = [1, 8, 27, 64, 125]\nkolom_empat = [1, 16, 81, 256, 625]\n\n# mari kita buat tabel\ntabel_mentah = []\nfor i in range(0, 5): # indeks list dimulai dari nol, lanjut selama i &lt; 5\n    calon_baris = []\n\n    # elemen ke-i dari tiap list kolom\n    calon_baris.append(kolom_awal[i])\n    calon_baris.append(kolom_kuadrat[i])\n    calon_baris.append(kolom_tiga[i])\n    calon_baris.append(kolom_empat[i])\n\n    tabel_mentah.append(calon_baris)\n\nprint(tabulate(tabel_mentah, headers=[\"i\", \"kuadrat\", \"pangkat tiga\",\"pangkat empat\"]))\n\n  i    kuadrat    pangkat tiga    pangkat empat\n---  ---------  --------------  ---------------\n  1          1               1                1\n  2          4               8               16\n  3          9              27               81\n  4         16              64              256\n  5         25             125              625\n\n\nBagaimana kalau misalnya ada data yang tidak lengkap? Kita bisa saja menggunakan try-except, untuk memasukkan “X” ketika ada data yang tidak lengkap, sekaligus menghindari error:\n\n# contoh data\nkolom_awal = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nkolom_kuadrat = [1, 4, 9, 16, 25]\n\ntabel_mentah = []\nfor i in range(0, 10): # indeks list dimulai dari nol, lanjut selama i &lt; 10\n    calon_baris = []\n\n    # elemen ke-i dari tiap list kolom\n    calon_baris.append(kolom_awal[i])\n    \n    try:\n        calon_baris.append(kolom_kuadrat[i])\n    except IndexError:\n        calon_baris.append(\"X\")\n\n    tabel_mentah.append(calon_baris)\n\nprint(tabulate(tabel_mentah, headers=[\"i\", \"kuadrat\"]))\n\n  i  kuadrat\n---  ---------\n  1  1\n  2  4\n  3  9\n  4  16\n  5  25\n  6  X\n  7  X\n  8  X\n  9  X\n 10  X\n\n\nNumPy juga memiliki semacam tipe data atau nilai yang standar untuk menandakan data yang hilang atau tidak tersedia, yaitu NaN (Not a Number), melalui numpy.nan. Sehingga, \"X\" pada kode di atas bisa diganti dengan numpy.nan:\n\n# contoh data\nkolom_awal = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nkolom_kuadrat = [1, 4, 9, 16, 25]\n\ntabel_mentah = []\nfor i in range(0, 10): # indeks list dimulai dari nol, lanjut selama i &lt; 10\n    calon_baris = []\n\n    # elemen ke-i dari tiap list kolom\n    calon_baris.append(kolom_awal[i])\n    \n    try:\n        calon_baris.append(kolom_kuadrat[i])\n    except IndexError:\n        calon_baris.append(np.nan)\n\n    tabel_mentah.append(calon_baris)\n\nprint(tabulate(tabel_mentah, headers=[\"i\", \"kuadrat\"]))\n\n  i    kuadrat\n---  ---------\n  1          1\n  2          4\n  3          9\n  4         16\n  5         25\n  6        nan\n  7        nan\n  8        nan\n  9        nan\n 10        nan"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul1.html#sympy",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul1.html#sympy",
    "title": "Modul 1 Metode Numerik: Tabulate, SymPy, Root-finding",
    "section": "SymPy",
    "text": "SymPy\nDalam pembelajaran metode numerik, seringkali kita perlu membandingkan hasil aproksimasi kita dengan nilai yang sesungguhnya. Seringkali pula, sebenarnya nilai yang sesungguhnya itu dapat kita peroleh (karena kita masih dalam tahap belajar; penerapan metode numerik di dunia nyata adalah pada kasus di mana nilai eksak tidak dapat diperoleh).\nHasil perhitungan eksak (seperti perhitungan menggunakan aljabar biasa atau ilmu kalkulus) juga disebut hasil perhitungan analitik atau simbolik. Istilah “analitik” bisa dianggap antonim dari istilah “numerik”.\nDi Python, ada module/package bernama SymPy (symbolic Python) yang dapat melakukan perhitungan simbolik, seperti menghitung turunan, yang misalnya digunakan di metode Newton.\n(Fun fact: aplikasi/package di komputer yang dapat melakukan perhitungan simbolik disebut Computer Algebra System (CAS). Beberapa contoh CAS adalah SymPy, Wolfram Mathematica, dan Maple.)\nMari kita import sympy:\n\nimport sympy\n\nSeperti untuk NumPy dan tabulate, apabila terjadi error karena sympy tidak ditemukan, artinya package sympy belum terinstall, dan bisa di-install menggunakan pip install sympy (atau dengan tanda seru: !pip install sympy)\n\npip install sympy\n\nRequirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.11.1)\nRequirement already satisfied: mpmath&gt;=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy) (1.2.1)\nNote: you may need to restart the kernel to use updated packages.\n\n\nTentunya, penggunaan SymPy melibatkan variabel. Misalnya, kita ingin melakukan perhitungan simbolik dengan variabel \\(x\\). Kita perlu memberitahu SymPy, dengan syntax seperti berikut:\n\nx = sympy.symbols(\"x\")\n\nArtinya, kita baru saja memberitahu SymPy bahwa, pada string apapun yang dijumpai oleh SymPy, huruf “x” perlu dianggap sebagai simbol, atau lebih tepatnya sebagai variabel.\nPerhatikan pula bahwa kode di atas adalah assignment ke variabel pemrograman yang juga bernama x. Dengan demikian, untuk ke depannya, variabel x yang kita ketik di mana saja pada program kita akan dianggap sebagai variabel “x” oleh SymPy.\nDengan variabel x tersebut, kita dapat mendefinisikan suatu expression (ekspresi atau kalimat matematika), misal \\(5x^4\\), seperti berikut:\n\npolinom = 5 * (x ** 4) / 2\nprint(polinom)\n\n5*x**4/2\n\n\nSymPy memiliki fitur pprint (pretty print), yaitu menampilkan suatu ekspresi secara cantik atau indah, layaknya seperti kita tulis di kertas:\n\nsympy.pprint(polinom)\n\n   4\n5⋅x \n────\n 2  \n\n\nUntuk melakukan diferensiasi atau menghitung turunan (dalam hal ini secara simbolik/analitik), gunakan sympy.diff:\n\nturunan = sympy.diff(polinom, x)\nsympy.pprint(turunan)\n\n    3\n10⋅x \n\n\ndengan begitu, SymPy menghitung turunan dari ekspresi polinom yang kita berikan itu, terhadap variabel x. Sebenarnya, mengetik sympy.diff(polinom) saja sudah cukup, tapi lebih lengkap lebih baik.\nSejauh ini, semua ekspresi yang kita jumpai masih berbentuk simbol/tulisan, sehingga kita belum bisa men-substitusi variabel x dengan sembarang nilai. Misalnya kita ingin menjadikan ekspresi di atas sebagai suatu fungsi func(x), di mana kita bisa memasukkan nilai x apapun dan mendapatkan hasil. Caranya adalah menggunakan sympy.lambdify:\n\nfunc = sympy.lambdify(x, turunan)\nprint(func(5))\n\n1250\n\n\nPada syntax lambdify di atas, kita perlu memberitahu SymPy terlebih dahulu, variabel apa yang digunakan pada ekspresi tersebut; barulah kita tuliskan ekspresinya. Dalam hal ini, kita mengetik sympy.lambdify(x, turunan) karena sedang menggunakan variabel x untuk ekspresi turunan yang ingin kita ubah menjadi fungsi yang bisa di-substitusi nilai x nya.\nFungsi hasil lambdify sudah bisa digunakan seperti fungsi lainnya pada Python. Bahkan, kita bisa mencampur penggunaan SymPy dengan NumPy (maupun package lainnya). Contohnya, setelah tadi memperoleh func(x) dari SymPy:\n\nimport numpy as np\n\n\narr = np.array([2, 3, 5, 10])\nprint(func(arr))\n\n[   80   270  1250 10000]\n\n\nSeperti NumPy, SymPy juga memiliki fungsi sin, cos, log, exp dll, sehingga kita bisa melakukan perhitungan analitik yang melibatkan fungsi-fungsi tersebut.\n\ng = x**2 * sympy.cos(x) + sympy.exp(-5*x)\nprint(\"Fungsinya:\")\nsympy.pprint(g)\n\ngp = sympy.diff(g, x)\nprint(\"Turunannya:\")\nsympy.pprint(gp)\n\nFungsinya:\n 2           -5⋅x\nx ⋅cos(x) + ℯ    \nTurunannya:\n   2                          -5⋅x\n- x ⋅sin(x) + 2⋅x⋅cos(x) - 5⋅ℯ    \n\n\nMeskipun kita bisa saja melakukan, misalnya, from sympy import cos, hal tersebut tidak disarankan, apalagi ketika program kita juga menggunkaan NumPy dengan from numpy import cos atau bahkan from numpy import *. Alasannya, dengan begitu, program bisa menjadi membingungkan, karena tidak ada pembeda antara cos dari NumPy (numerik) dengan cos dari SymPy (analitik/simbolik).\nNamun, kalau Anda berhati-hati dan hanya melakukan hal tersebut untuk salah satu package saja, silakan.\nMenariknya, SymPy bisa jadi lebih unggul daripada NumPy untuk beberapa perhitungan yang melibatkan akurasi tinggi, terutama untuk perhitungan yang sebenarnya bersifat analitik. Misalnya, kita tahu bahwa \\(\\sin(\\pi) = 0\\). Menurut SymPy,\n\nprint(\"Menurut SymPy, sin(pi) = \" + str(sympy.sin(sympy.pi)))\n\nMenurut SymPy, sin(pi) = 0\n\n\nkarena SumPy menghitung nilai sin dari \\(\\pi\\) secara analitik, yaitu tanpa perlu menghitung nilai \\(\\pi\\) (karena nilainya sudah jelas nol berdasarkan sifat fungsi sin). Sedangkan, NumPy mengaproksimasi nilai \\(\\pi\\) terlebih dahulu, barulah hasil aproksimasi tersebut yang masuk ke fungsi sin. Hasil perhitungan fungsi sin tersebut pun juga aproksimasi, sehingga didapatkan hasil seperti berikut, yaitu sangat kecil tetapi bukan nol:\n\nprint(\"Menurut NumPy, sin(pi) = \" + str(np.sin(np.pi)))\n\nMenurut NumPy, sin(pi) = 1.2246467991473532e-16\n\n\ndi mana “e-16” artinya “dikali 10 pangkat -16”."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul1.html#metode-bisection",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul1.html#metode-bisection",
    "title": "Modul 1 Metode Numerik: Tabulate, SymPy, Root-finding",
    "section": "Metode Bisection",
    "text": "Metode Bisection\nMetode Bisection adalah salah satu metode yang dapat kita gunakan dalam masalah pencarian akar (root finding). Akar dari suatu persamaan didefinisikan sebagai nilai \\(x\\) yang memenuhi \\(f(x) = 0\\). Misalkan \\(f\\) adalah suatu fungsi kontinu terdefinisi di \\([a,b]\\), di mana \\(f(a)\\) dan \\(f(b)\\) berlawanan tanda (sehingga pasti ada akar pada interval tersebut, menurut Teorema Nilai Antara / Intermediate Value Theorem).\nInti sari dari metode Bisection adalah\n\nmenebak bahwa akar suatu persamaan ada di dalam interval tertentu \\([a, b]\\);\nmenelusuri nilai fungsi pada nilai tengah atau rata-rata dari interval tersebut;\nmempersempit interval dengan memanfaatkan hasil rata-rata tersebut; dan\nterus mencari nilai tengah dari interval yang baru, yang kemudian dipersempit lalu dicari nilai tengahnya, dan seterusnya hingga akar ditemukan, atau hingga ukuran interval sudah cukup kecil sehingga memuaskan (yaitu sudah lebih kecil dari toleransi).\n\nDidefinisikan nilai tengah dari interval:\n\\[p=\\frac{(a+b)}{2}\\]\nAkan dicari \\(f(p)\\) dengan syarat sebagai berikut:\n\njika \\(f(p) = 0\\), maka \\(p\\) adalah akar dari \\(f\\)\njika \\(f(p)f(a) &gt; 0\\), maka \\(\\text{sign}(f(p)) = \\text{sign}(f(a))\\). Sehingga, kita dapat mempersempit interval dengan memilih batasan baru yaitu a = p dan b tidak berubah.\njika \\(f(p)f(a) &lt; 0\\), maka \\(\\text{sign}(f(p)) \\neq \\text{sign} (f(a))\\), atau \\(\\text{sign}(f(p)) = \\text{sign}(f(b))\\). Sehingga, kita dapat mempersempit interval dengan memilih batasan baru yaitu a tidak berubah dan b = p.\n\nMetode Bisection memiliki order of convergence = 1, atau disebut memiliki kekonvergenan linier (linear convergence). Artinya, dalam proses menemukan akar persamaan (konvergen menuju jawabannya), metode Bisection tidak secepat beberapa metode lainnya yang memiliki order of convergence yang lebih tinggi.\n\ndef Bisection(f, lower, upper, tol):\n    if f(lower)*f(upper)&lt;0:\n        p0=lower\n        p=(lower+upper)/2\n\n        if f(p)==0:\n            return p\n        elif f(p)*f(lower)&gt;0:\n            lower=p\n        elif f(p)*f(lower)&lt;0:\n            upper=p\n \n        abs_error=abs(p0-p)\n        p0=p\n \n        while abs_error &gt; tol:\n            p=(lower+upper)/2\n            \n            if f(p)==0:\n                break\n            elif f(p)*f(lower)&gt;0:\n                lower=p\n            elif f(p)*f(lower)&lt;0:\n                upper=p\n        \n            abs_error=abs(p0-p)\n            p0=p\n \n        return p\n \n    elif f(lower)*f(upper)&gt;0:\n        return \"Metode gagal mengaproksimasi akar. Silakan ubah batas atas atau batas bawah\"\n    elif f(lower)==0:\n        return lower\n    else: #f(upper)==0\n        return upper\n\n\nfrom numpy import sin, cos, tan, log, exp, sqrt, pi\n\nformula = input('Masukkan formula fungsi: ')\n\ndef f(x):\n    return eval(formula)\n\nlow_bound = eval(input(\"Masukkan batas bawah interval: \"))\nup_bound = eval(input(\"Masukkan batas atas interval: \"))\ntoleransi = eval(input(\"Masukkan toleransi aproksimasi: \"))\n\nakar_bisection=Bisection(f, low_bound, up_bound, toleransi)\n\ntry:\n    print(f\"Akar persamaan {formula} = 0 adalah x = {akar_bisection}\")\nexcept ValueError:\n    print(akar_bisection)\n\nMasukkan formula fungsi: 2*x - 3*cos(x) + exp(-5*x) - 9\nMasukkan batas bawah interval: -3\nMasukkan batas atas interval: 2\nMasukkan toleransi aproksimasi: 10**(-7)\nAkar persamaan 2*x - 3*cos(x) + exp(-5*x) - 9 = 0 adalah x = -0.5073225051164627"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul1.html#metode-fixed-point",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul1.html#metode-fixed-point",
    "title": "Modul 1 Metode Numerik: Tabulate, SymPy, Root-finding",
    "section": "Metode Fixed-Point",
    "text": "Metode Fixed-Point\nInti sari dari Metode Fixed-Point adalah mencari fixed-point (titik tetap) dari suatu fungsi (misal fungsi \\(g(x)\\)), yaitu suatu nilai \\(p\\) sehingga \\(p = g(p)\\), atau \\(p - g(p) = 0\\). Titik \\(p\\) disebut titik tetap, karena ketika nilai \\(p\\) dimasukkan ke fungsi \\(g(x)\\), hasilnya tetaplah \\(p\\). Untuk nilai \\(x\\) yang dekat dengan \\(p\\), biasanya ada kecenderungan nilai \\(g(x)\\) menjadi semakin mendekati \\(p\\).\nPerhatikan bahwa, sembarang persamaan \\(f(x) = 0\\) bisa diubah bentuknya dengan mendefinisikan fungsi \\(g(x) = x - f(x)\\) (sehingga \\(f(x) = x - g(x)\\)). Dengan demikian, permasalahan mencari akar berubah menjadi permasalahan mencari fixed-point, yaitu mencari nilai \\(p\\) sehingga \\(p = g(p)\\) atau \\(p - g(p) = 0\\) (sehingga nilai \\(p\\) tersebut juga menyebabkan \\(f(p) = 0\\)).\n(Tentu saja, itu bukanlah satu-satunya cara untuk mengubah permasalahan mencari akar menjadi permasalahan mencari fixed-point. Bahkan, tidak semua pilihan \\(g(x)\\) yang memungkinkan itu dijamin memiliki fixed-point.)\nMisalkan \\(g\\) adalah fungsi kontinu dan memiliki fixed-point \\(p\\) pada interval \\([a,b]\\) (dan diasumsikan bahwa \\(g\\) memenuhi persyaratan untuk kekonvergenan metode fixed-point). Artinya, ada \\(p \\in [a,b]\\) sehingga \\(g(x) = x\\). Untuk mengaproksimasi penyelesaian dari persamaan \\(g(x) = x\\), diperlukan suatu tebakan awal \\(p_0\\), kemudian iterasinya adalah:\n\\[p_n = g(p_{n-1})\\]\nNilai tersebut terus dimasukkan ke dalam \\(g\\) sehingga, diharapkan, nilai \\(p_n\\) menjadi semakin mendekati suatu nilai \\(p\\) yang membuat \\(g(p) = p\\).\nPada umumnya, metode fixed-point memiliki kekonvergenan linier. Ketika \\(g(x)\\) dijamin memliki tepat satu fixed-point (atau fixed-point yang unik) pada suatu interval \\([a,b]\\), maka Metode Fixed-Point dengan \\(p_0\\) pada interval tersebut pasti memiliki kekonvergenan linier. Terkadang Metode Fixed-Point lebih cepat daripada Metode Bisection, dan terkadang Metode Bisection lebih cepat daripada Metode Fixed-Point.\nHati-hati, ada kemungkinan bahwa \\(g(p_n)\\) malah menjauhi \\(p\\), contohnya untuk \\(g(x) = x^2\\) dan \\(p_0 &gt; 1\\) (padahal \\(g(1) = 1\\)). Pada kasus seperti itu, metode fixed-point tidak dijamin konvergen (artinya tidak dijamin bisa menemukan fixed-point).\nSebagai contoh penggunaan metode fixed-point, kalian bisa mencoba untuk menyelesaikan persamaan (masalah mencari akar) berikut ini,\n\\[f(x) = x^2 - x - 1 = 0\\]\ndengan sedikit manipulasi aljabar (dibagi \\(x\\), pindah ruas) agar mendapatkan bentuk \\(x = g(x)\\),\n\\[x = 1 + \\frac{1}{x}\\]\nsehingga, dengan \\(g(x) = 1 + \\frac{1}{x}\\) bisa digunakan metode fixed-point, misal dengan tebakan awal \\(x = 2\\) atau \\(x = -3\\).\n(Jelas metode ini akan gagal untuk \\(g(x)\\) tersebut apabila dipilih tebakan awal seperti \\(x=0\\), \\(x=-1\\), atau bahkan \\(x=-\\frac{1}{2}\\) karena akan terjadi pembagian nol. Kemungkinan terjadinya pembagian nol itu bukan hanya dari metodenya seperti metode Newton, tetapi juga dari fungsi \\(f(x)\\) atau \\(g(x)\\) yang digunakan.)\nSilakan coba dengan kode di bawah ini!\nSebagai pembanding, kalian bisa menyelesaikan persamaan kuadrat \\(f(x) = x^2 - x - 1 = 0\\) di atas, dan mendapatkan solusi\n\\[x_1 = \\frac{1+\\sqrt{5}}{2} \\approx 1.618\\]\n\\[x_2 = \\frac{1-\\sqrt{5}}{2} \\approx -0.618\\]\nKebetulan, konstanta berikut ini yang berlambang phi kecil (\\(\\phi\\)),\n\\[\\phi = \\frac{1+\\sqrt{5}}{2}\\]\nadalah konstanta istimewa yang bernama golden ratio.\n\nfrom tabulate import tabulate\n\ndef FixedPoint(g, p0, tol):\n    table = [[\"iterasi\",\"Aproksimasi\"]]\n    iterasi = []\n    \n    i = 1\n    p = g(p0)\n    abs_error = abs(p-p0)\n    p0 = p\n    iterasi.append(i)\n    iterasi.append(p)\n    table.append(iterasi)\n\n    while abs_error &gt; tol:\n        iterasi = []\n        i += 1\n        p = g(p0)\n        abs_error = abs(p-p0)\n        p0 = p\n        iterasi.append(i)\n        iterasi.append(p)\n        table.append(iterasi)\n    \n    tabel_siap_print = tabulate(table,headers = 'firstrow',tablefmt=\"pretty\")\n    return p0, tabel_siap_print\n\n\nfrom numpy import cos, sin, tan, log, exp, sqrt\n\nformula = input(\"Masukkan formula g(x): \")\n\ndef g(x):\n    return eval(formula)\n\ntebakan_awal = eval(input(\"Masukkan titik awal iterasi: \"))\ntoleransi = eval(input(\"Masukkan batas toleransi: \"))\n\nfixed_point, tabel = FixedPoint(g, tebakan_awal, toleransi)\n\nprint(tabel)\nprint(f\"Ditemukan fixed point dari g(x) = {formula} yaitu x = {fixed_point}\")\n\nMasukkan formula g(x): 1 + 1/x\nMasukkan titik awal iterasi: 2\nMasukkan batas toleransi: 10**(-7)\n+---------+--------------------+\n| iterasi |    Aproksimasi     |\n+---------+--------------------+\n|    1    |        1.5         |\n|    2    | 1.6666666666666665 |\n|    3    |        1.6         |\n|    4    |       1.625        |\n|    5    | 1.6153846153846154 |\n|    6    | 1.619047619047619  |\n|    7    | 1.6176470588235294 |\n|    8    | 1.6181818181818182 |\n|    9    | 1.6179775280898876 |\n|   10    | 1.6180555555555556 |\n|   11    | 1.6180257510729614 |\n|   12    | 1.6180371352785146 |\n|   13    | 1.6180327868852458 |\n|   14    | 1.618034447821682  |\n|   15    | 1.618033813400125  |\n|   16    | 1.6180340557275543 |\n|   17    | 1.6180339631667064 |\n+---------+--------------------+\nDitemukan fixed point dari g(x) = 1 + 1/x yaitu x = 1.6180339631667064"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul1.html#metode-newton-biasa-dengan-turunan-analitik",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul1.html#metode-newton-biasa-dengan-turunan-analitik",
    "title": "Modul 1 Metode Numerik: Tabulate, SymPy, Root-finding",
    "section": "Metode Newton biasa (dengan turunan analitik)",
    "text": "Metode Newton biasa (dengan turunan analitik)\nMisalkan \\(f\\) kontinu dan terturunkan (memiliki turunan) di \\([a,b]\\) dan ada tebakan awal \\(p_0 \\in\\) \\([a,b]\\) sedemikian sehingga \\(f'(p_0) \\neq 0\\). Iterasi pada metode Newton untuk menyelesaian \\(f(x) = 0\\) adalah sebagai berikut:\n\\[p_n = p_{n-1} - \\frac{f(p_{n-1})}{f'(p_{n-1})}\\]\nDiharapkan bahwa, setelah banyak iterasi, nilai \\(p_n\\) yang diperoleh akan membuat \\(f(p) = 0\\) atau setidaknya sangat dekat dengan nol (lebih kecil dari batas toleransi yang kita anggap sudah memuaskan).\nMetode Newton juga dapat dipandang sebagai metode fixed-point dengan \\(g(x) = x - \\frac{f(x)}{f'(x)}\\)\nMetode Newton gagal apabila, pada suatu iterasi, tiba-tiba \\(f'(p_n) = 0\\).\nPada umumnya, Metode Newton memiliki order of convergence = 2, atau juga disebut memiliki kekonvergenan kuadratik (quadratic convergence). Artinya, selama berhasil, Metode Newton lebih cepat daripada Metode Bisection maupun Metode Fixed-Point.\n\ndef NewtonAnalitik(f,fp,p0,tolerance):\n    p = p0 - f(p0)/fp(p0)\n    abs_error = abs(p-p0)\n    p0 = p\n\n    while abs_error &gt; tolerance:\n\n        try:\n            p = p0 - f(p0)/fp(p0)\n        except ZeroDivisionError:\n            return \"Metode gagal mengaproksimasi akar. Silakan pilih tebakan awal lain\"\n        \n        abs_error = abs(p-p0)\n        p0 = p\n    return p\n\n\nimport sympy\nfrom numpy import sin, cos, tan, log, exp, sqrt\n\nformula = input(\"Masukkan fungsi: \")\ndef f(x):\n    return eval(formula)\n\nx = sympy.symbols(\"x\")\n\ndf_string = str(sympy.diff(formula, x))\ndef fp(x): # turunan f\n    return eval(df_string)\n\ntebakan_awal = eval(input(\"Masukkan tebakan awal / titik awal iterasi: \"))\ntolerance = eval(input(\"Masukkan toleransi aproksimasi: \"))\n\nakar_newton = NewtonAnalitik(f, fp, tebakan_awal, tolerance)\n\nprint(f\"Akar dari persamaan f(x) = {formula} adalah x = {akar_newton}\")\n\nMasukkan fungsi: 2*x - 3*cos(x) + exp(-5*x) - 9\nMasukkan tebakan awal / titik awal iterasi: -1\nMasukkan toleransi aproksimasi: 10**(-7)\nAkar dari persamaan f(x) = 2*x - 3*cos(x) + exp(-5*x) - 9 adalah x = -0.5073224866379573"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul1.html#metode-newton-dengan-beda-hingga-finite-difference-newtons-method",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul1.html#metode-newton-dengan-beda-hingga-finite-difference-newtons-method",
    "title": "Modul 1 Metode Numerik: Tabulate, SymPy, Root-finding",
    "section": "Metode Newton dengan Beda Hingga (Finite-Difference Newton’s Method)",
    "text": "Metode Newton dengan Beda Hingga (Finite-Difference Newton’s Method)\nSalah satu kekurangan Metode Newton yang biasa adalah harus mengetahui rumus turunannya secara analitik. Sebelum adanya CAS seperti SymPy, turunan analitik harus dihitung secara manual dengan kalkulus. Kalau bentuk rumus untuk \\(f(x)\\) sangat rumit, perhitungan turunan menjadi jauh lebih rumit. Untuk menghindari menghitung turunan secara analitik, kita dapat menggunakan definisi turunan (yang menggunakan limit):\n\\[f'(x) = \\lim_{h \\rightarrow 0} \\frac{f(x+h) - f(x)}{h}\\]\ndengan memilih nilai \\(h\\) yang cukup kecil (sayangnya, kita tidak bisa membuat limit \\(h\\) menuju nol). Nilai \\(h\\) yang cukup kecil itu disebut suatu beda hingga (finite difference).\nSehingga, modifikasi metode Newton ini bisa disebut Metode Newton dengan Beda Hingga (Finite-Difference Newton’s Method). Untuk fungsi \\(f\\) yang kontinu, akar persamaan \\(f(x) = 0\\) bisa ditentukan dengan iterasi sebagai berikut:\n\\[\\begin{align*}\np_n &= p_{n-1} - \\frac{f(p_{n-1})}{\\left(\\frac{f\\left(p_{n-1}+h\\right)-f(p_{n-1})}{h}\\right)} \\\\\n&= p_{n-1} - \\frac{f(p_{n-1})h}{f(p_{n-1}+h)-f(p_{n-1})}\n\\end{align*}\\]\ndengan tebakan awal \\(p_0\\). Perhatikan bahwa \\(f'(p_{n-1})\\) pada metode Newton yang biasa itu telah digantikan dengan\n\\[f'(p_{n-1}) \\approx \\frac{f(p_{n-1}+h) - f(p_{n-1})}{h}\\]\nTujuan modifikasi tersebut adalah agar iterasi dapat dilakukan pada titik di mana turunannya tidak ada, atau ketika turunan analitik sulit diperoleh.\n\ndef FiniteDifferenceNewton(f,fp,p0,tolerance):\n    p = p0 - f(p0)/fp(p0)\n    abs_error = abs(p-p0)\n    p0 = p\n\n    while abs_error &gt; tolerance:\n        p = p0 - f(p0)/fp(p0)\n        abs_error = abs(p-p0)\n        p0 = p\n    return p\n\n\nfrom numpy import sin, cos, tan, log, exp, sqrt\n\nformula = input(\"Masukkan fungsi: \")\ndef f(x):\n    return eval(formula)\n\ndef fp(x, h=10**(-12)):\n    return (f(x+h)-f(x))/h\n\nstarting_point = eval(input(\"Masukkan titik awal iterasi: \"))\ntolerance = eval(input(\"Masukkan toleransi aproksimasi: \"))\n\nakar_fd = FiniteDifferenceNewton(f,fp,starting_point,tolerance)\n\nprint(f\"Akar dari persamaan f(x) = {formula} adalah x = {akar_fd}\")\n\nMasukkan fungsi: 2*x - 3*cos(x) + exp(-5*x) - 9\nMasukkan titik awal iterasi: -1\nMasukkan toleransi aproksimasi: 10**(-7)\nAkar dari persamaan f(x) = 2*x - 3*cos(x) + exp(-5*x) - 9 adalah x = -0.5073224866379543"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul1.html#tambahan",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul1.html#tambahan",
    "title": "Modul 1 Metode Numerik: Tabulate, SymPy, Root-finding",
    "section": "Tambahan",
    "text": "Tambahan\n\nContoh Tabel Faktorial\nBagaimana kalau misalnya kita sudah punya suatu fungsi yang melakukan perhitungan secara iteratif dan hanya menampilkan hasil akhirnya, tetapi kita ingin memperoleh tiap hasil iterasi, bukan hasil akhirnya saja? Contohnya, fungsi menghitung faktorial \\(n! = n * (n-1) * \\dots * 3 * 2 * 1\\) berikut ini,\n\ndef faktorial(n):\n    \n    # nilai awal\n    hasil = 1\n\n    # iterasi\n    for i in range(2, n+1):\n        # mulai dari 2, lanjut selama i &lt; n + 1\n        # sehingga iterasi terakhir adalah untuk i = n\n\n        hasil = hasil * i\n    \n    # mengembalikan hasil akhir setelah semua iterasi selesai\n    return hasil\n\n# peroleh hasil akhir dari fungsi faktorial, kemudian print\nprint(faktorial(5))\n\n120\n\n\nKita bisa saja melakukan print (di dalam fungsinya) tiap kali nilai hasil diperbarui.\n\ndef faktorial(n):\n    \n    # nilai awal\n    hasil = 1\n    print(hasil) # tampilkan hasil\n\n    # iterasi\n    for i in range(2, n+1):\n        # mulai dari 2, lanjut selama i &lt; n + 1\n        # sehingga iterasi terakhir adalah untuk i = n\n\n        hasil = hasil * i\n        print(hasil) # tampilkan hasil yang baru\n    \n    # tidak perlu return karena sudah menggunakan print\n\n# fungsi cukup dipanggil saja,\n# karena print sudah ada di dalam fungsi\nfaktorial(5)\n\n1\n2\n6\n24\n120\n\n\nAlternatifnya, kita bisa memasukkan tiap hasil baru ke dalam suatu list, yang kemudian dikembalikan oleh fungsi, lalu kita bisa print list tersebut.\n\ndef ListFaktorial(n):\n    list_baru = []\n    \n    # nilai awal\n    hasil = 1\n    list_baru.append(hasil) # tambahkan ke list\n\n    # iterasi\n    for i in range(2, n+1):\n        # mulai dari 2, lanjut selama i &lt; n + 1\n        # sehingga iterasi terakhir adalah untuk i = n\n\n        hasil = hasil * i\n        list_baru.append(hasil) # tambahkan tiap hasil baru ke list\n    \n    # kembalikan list semua hasil\n    return list_baru\n\n# peroleh list dari fungsi di atas, kemudian print\nprint(ListFaktorial(5))\n\n[1, 2, 6, 24, 120]\n\n\nBahkan, list ini bisa diubah menjadi tabel!\n\ndef ListFaktorial(n):\n    list_baru = []\n    \n    # nilai awal\n    hasil = 1\n    list_baru.append(hasil) # tambahkan ke list\n\n    # iterasi\n    for i in range(2, n+1):\n        # mulai dari 2, lanjut selama i &lt; n + 1\n        # sehingga iterasi terakhir adalah untuk i = n\n\n        hasil = hasil * i\n        list_baru.append(hasil) # tambahkan tiap hasil baru ke list\n    \n    # kembalikan list semua hasil\n    return list_baru\n\n# kolom nilai i\nkolom_kiri = [1, 2, 3, 4, 5]\n# bisa juga dibuat dengan for loop dengan range(1,6) append i\n\n# peroleh list dari fungsi di atas\nkolom_kanan = ListFaktorial(5)\n\n# \"gabung\" kedua kolom menjadi satu tabel, seperti biasa\ntabel_mentah = []\nfor i in range(0,5):\n    calon_baris = []\n    calon_baris.append(kolom_kiri[i])\n    calon_baris.append(kolom_kanan[i])\n    tabel_mentah.append(calon_baris)\n\ntabel_olahan = tabulate(tabel_mentah, headers=[\"i\", \"faktorial\"])\nprint(tabel_olahan)\n\n  i    faktorial\n---  -----------\n  1            1\n  2            2\n  3            6\n  4           24\n  5          120\n\n\nPerhatikan bahwa kita memerlukan dua list untuk membentuk tabel di atas. Bisa saja, kita membentuk kedua list sepenuhnya di dalam fungsi. Dengan begitu, setelah menggunakan fungsi, kita tinggal membentuk tabel dari kedua list.\n\ndef DuaListFaktorial(n):\n    kolom_kiri = [] # berisi i\n    kolom_kanan = [] # berisi faktorial atau i!\n    \n    # nilai awal\n    hasil = 1\n\n    # tambahkan ke list\n    kolom_kiri.append(1)\n    kolom_kanan.append(hasil)\n\n    # iterasi\n    for i in range(2, n+1):\n        # mulai dari 2, lanjut selama i &lt; n + 1\n        # sehingga iterasi terakhir adalah untuk i = n\n\n        hasil = hasil * i\n\n        # tambahkan tiap hasil baru ke list\n        kolom_kiri.append(i)\n        kolom_kanan.append(hasil)\n    \n    # kembalikan kedua list\n    return kolom_kiri, kolom_kanan\n\n# peroleh kedua list dari fungsi\nkolom_kiri, kolom_kanan = DuaListFaktorial(5)\n\n# \"gabung\" kedua kolom menjadi satu tabel, seperti biasa\ntabel_mentah = []\nfor i in range(0,5):\n    calon_baris = []\n    calon_baris.append(kolom_kiri[i])\n    calon_baris.append(kolom_kanan[i])\n    tabel_mentah.append(calon_baris)\n\ntabel_olahan = tabulate(tabel_mentah, headers=[\"i\", \"faktorial\"])\nprint(tabel_olahan)\n\n  i    faktorial\n---  -----------\n  1            1\n  2            2\n  3            6\n  4           24\n  5          120\n\n\nKalau mau, bahkan proses pembentukan tabel juga bisa dilakkukan di dalam fungsi, sehingga fungsi memberikan output berupa tabel yang siap diolah tabulate.\n\ndef TabelFaktorial(n):\n    kolom_kiri = [] # berisi i\n    kolom_kanan = [] # berisi faktorial atau i!\n    \n    # nilai awal\n    hasil = 1\n\n    # tambahkan ke list\n    kolom_kiri.append(1)\n    kolom_kanan.append(hasil)\n\n    # iterasi\n    for i in range(2, n+1):\n        # mulai dari 2, lanjut selama i &lt; n + 1\n        # sehingga iterasi terakhir adalah untuk i = n\n\n        hasil = hasil * i\n\n        # tambahkan tiap hasil baru ke list\n        kolom_kiri.append(i)\n        kolom_kanan.append(hasil)\n    \n    tabel_mentah = []\n    for i in range(0,n):\n        # sampai indeks (n-1)\n        # nilai n tergantung banyaknya iterasi\n\n        calon_baris = []\n        calon_baris.append(kolom_kiri[i])\n        calon_baris.append(kolom_kanan[i])\n        tabel_mentah.append(calon_baris)\n    \n    return tabel_mentah\n\ntabel_mentah = TabelFaktorial(5)\n\ntabel_olahan = tabulate(tabel_mentah, headers=[\"i\", \"faktorial\"])\nprint(tabel_olahan)\n\n  i    faktorial\n---  -----------\n  1            1\n  2            2\n  3            6\n  4           24\n  5          120\n\n\nBahkan, pengolahan tabel bisa dilakukan di dalam fungsi…\n\ndef TabelFaktorial(n):\n    kolom_kiri = [] # berisi i\n    kolom_kanan = [] # berisi faktorial atau i!\n    \n    # nilai awal\n    hasil = 1\n\n    # tambahkan ke list\n    kolom_kiri.append(1)\n    kolom_kanan.append(hasil)\n\n    # iterasi\n    for i in range(2, n+1):\n        # mulai dari 2, lanjut selama i &lt; n + 1\n        # sehingga iterasi terakhir adalah untuk i = n\n\n        hasil = hasil * i\n\n        # tambahkan tiap hasil baru ke list\n        kolom_kiri.append(i)\n        kolom_kanan.append(hasil)\n    \n    tabel_mentah = []\n    for i in range(0,n):\n        # sampai indeks (n-1)\n        # nilai n tergantung banyaknya iterasi\n\n        calon_baris = []\n        calon_baris.append(kolom_kiri[i])\n        calon_baris.append(kolom_kanan[i])\n        tabel_mentah.append(calon_baris)\n    \n    # mengolah tabel di dalam fungsi\n    tabel_olahan = tabulate(tabel_mentah, headers=[\"i\", \"faktorial\"])\n    return tabel_olahan\n\ntabel_jadi = TabelFaktorial(5)\nprint(tabel_jadi)\n\n  i    faktorial\n---  -----------\n  1            1\n  2            2\n  3            6\n  4           24\n  5          120\n\n\nTentu saja, nilai 5 itu selalu bisa diganti menjadi sembarang bilangan bulat positif, seperti 7, 10, 15, 22, atau bahkan lebih besar lagi, dan banyaknya baris akan menyesuaikan, karena pembentukan tabel dilakukan secara otomatis.\n\ntabel_jadi = TabelFaktorial(22)\nprint(tabel_jadi)\n\n  i               faktorial\n---  ----------------------\n  1                       1\n  2                       2\n  3                       6\n  4                      24\n  5                     120\n  6                     720\n  7                    5040\n  8                   40320\n  9                  362880\n 10                 3628800\n 11                39916800\n 12               479001600\n 13              6227020800\n 14             87178291200\n 15           1307674368000\n 16          20922789888000\n 17         355687428096000\n 18        6402373705728000\n 19      121645100408832000\n 20     2432902008176640000\n 21    51090942171709440000\n 22  1124000727777607680000\n\n\n\n\nMetode Secant\nPada Metode Newton dengan Beda Hingga, nilai \\(h\\) konstan. Kalau kita punya dua tebakan awal yang saling dekat, misal \\(p_0\\) dan \\(p_1\\), kita bisa saja memanfaatkannya dengan memasang \\(h = p_1 - p_0\\). Bahkan, ketika iterasi \\(p_n\\) sudah semakin dekat menuju akar, jarak antara \\(p_{n-1}\\) dan \\(p_{n-2}\\) menjadi semakin kecil. Sehingga, dengan memasang nilai \\(h = p_{n-2} - p_{n-1}\\) atau \\(h = p_{n-1} - p_{n-2}\\), kita berhasil membuat limit \\(h\\) menuju nol.\nModifikasi ini disebut Metode Secant, dengan iterasi sebagai berikut untuk menentukan penyelesaian \\(f(x) = 0\\) dengan fungsi \\(f\\) yang kontinu:\n\\[\\begin{align*}\np_n &= p_{n-1} - \\frac{f(p_{n-1})}{\\left(\\frac{f(p_{n-1})-f(p_{n-2})}{p_{n-1}-p_{n-2}}\\right)} \\\\\n&= p_{n-1} - \\frac{f(p_{n-1})(p_{n-1} - p_{n-2})}{f(p_{n-1}) - f(p_{n-2})}\n\\end{align*}\\]\nDibandingkan Metode Newton yang biasa, Metode Secant menggantikan \\(f'(p_{n-1})\\) dengan\n\\[f'(p_{n-1}) \\approx \\frac{f(p_{n-1}) - f(p_{n-2})}{p_{n-1} - p_{n-2}}\\]\nsehingga, tidak seperti Metode Newton yang hanya memerlukan satu tebakan awal, Metode Secant membutuhkan dua tebakan awal, yaitu \\(p_0\\) dan \\(p_1\\). Namun, dibandingkan dengan Metode Newton dengan Beda Hingga, nilai \\(h\\) atau beda hingga tersebut tidak perlu ditentukan secara manual.\nMenariknya, Metode Secant memiliki order of convergence = \\(\\phi \\approx 1.618\\).\n\ndef Secant(f,p0,p1,tolerance):\n    p = p1 - (f(p1)*(p1-p0))/(f(p1)-f(p0))\n    abs_error = abs(p-p1)\n    p0 = p1\n    p1 = p\n\n    while abs_error &gt; tolerance:\n        p = p1 - (f(p1)*(p1-p0))/(f(p1)-f(p0))\n        abs_error = abs(p-p1)\n        p0 = p1\n        p1 = p\n    return p\n\n\nfrom numpy import sin, cos, tan, log, exp, sqrt\nformula = input(\"Masukkan formula fungsi: \")\n\ndef f(x):\n    return eval(formula)\n\ntitik_1 = eval(input(\"Masukkan titik awal pertama: \"))\ntitik_2 = eval(input(\"Masukkan titik awal kedua: \"))\ntolerance = eval(input(\"Masukkan toleransi aproksimasi: \"))\n\nakar_secant = Secant(f,titik_1,titik_2,tolerance)\n\nprint(f\"Akar dari persamaan f(x) = {formula} adalah x = {akar_secant}\")\n\nMasukkan formula fungsi: 2*x - 3*cos(x) + exp(-5*x) - 9\nMasukkan titik awal pertama: -1\nMasukkan titik awal kedua: -2\nMasukkan toleransi aproksimasi: 10**(-7)\nAkar dari persamaan f(x) = 2*x - 3*cos(x) + exp(-5*x) - 9 adalah x = -0.5073224866425831\n\n\n\n\nMetode Regula Falsi (penjelasan tanpa kode)\nSejauh ini, kita sudah membahas beberapa metode root-finding atau aproksimasi akar, yaitu:\n\nMetode Bisection\nMetode Fixed-Point\nMetode Newton biasa (dengan turunan analitik)\nMetode Newton dengan Beda Hingga (finite-difference Newton’s method)\nMetode Secant\n\nDi antara semua metode tersebut, hanya Metode Bisection yang dijamin konvergen menuju akar di interval yang diberikan; semua metode lain ada kemungkinan divergen (menjauh dari akar, seperti metode fixed-point) atau gagal karena terjadi pembagian nol. Sayangnya, Metode Bisection termasuk metode yang pelan di antara metode numerik lainnya.\nUntuk menjaga jaminan kekonvergenan oleh Metode Bisection tetapi memperbaiki kecepatan kekonvergenannya, kita bisa memodifikasi Metode Bisection, yaitu memodifikasi cara menentukan \\(p\\) yang baru yang akan mempersempit interval. Perhatikan bahwa Metode Bisection membutuhkan dua “tebakan awal” (lebih tepatnya dua batasan interval), sedangkan metode di atas yang juga membutuhkan dua tebakan awal hanyalah Metode Secant.\nApakah kita bisa menggunakan Metode Bisection, tetapi dengan modifikasi menentukan \\(p\\) seperti Metode Secant, agar mendapatkan order of convergence seperti Metode Secant?\nJawabannya adalah bisa, dan modifikasi tersebut dinamakan Metode Regula Falsi. Sehingga, Metode Regula Falsi bisa disebut perpaduan antara Metode Bisection dan Metode Secant.\nSebenarnya, perbedaan algoritma Metode Bisection dan Metode Regula Falsi hanya di satu baris saja, yaitu mengubah baris\n\\[p=\\frac{a+b}{2}\\]\nmenjadi\n\\[p = b - \\frac{f(b)(b-a)}{f(b) - f(a)}\\]\nsesuai Metode Secant. Perhatikan bahwa Metode Secant biasanya membutuhkan dua tebakan awal yang tidak harus sama dengan batasan interval, sedangkan Metode Regula Falsi secara otomatis menggunakan kedua batasan interval \\([a,b]\\) sebagai dua tebakan awal.\nUntuk pembuatan kode Metode Regula Falsi, kami serahkan ke kalian. Gampang, kok! Tinggal mengubah beberapa baris saja (baris yang menentukan nilai \\(p\\) yang baru) pada kode Metode Bisection, yaitu mengambil baris tersebut dari kode Metode Secant, kemudian menyesuaikan kedua tebakan awal menjadi kedua batasan interval.\nSeperti Metode Secant, Metode Regula Falsi juga memiliki order of convergence = \\(\\phi \\approx 1.618\\).\n\n\nApa itu barisan? (penjelasan tanpa kode)\nSuatu “barisan” (sequence) adalah sekumpulan angka yang berurut. Artinya, pada suatu barisan, ada yang bisa disebut angka pertama (atau suku pertama), angka kedua (suku kedua), angka ketiga (suku ketiga), dan sebagainya. Banyaknya suku bisa berhingga maupun tak terhingga.\nSuku-suku pada suatu barisan itu bisa saja ditentukan secara manual atau sesuka hati, atau bisa juga menggunakan rumus. Intinya, suku-suku suatu barisan itu bisa diperoleh dari manapun, bahkan dari hasil iterasi metode numerik (\\(p_0\\), \\(p_1\\), \\(p_2\\), \\(p_3\\), …) juga bisa.\nOleh karena itu, contoh barisan berhingga adalah hasil iterasi fixed-point, misalnya dengan \\(g(x) = 1 + \\frac{1}{x}\\), tebakan awal \\(p_0 = 2\\), dan batas toleransi \\(10^{-7}\\):\n\\[\\begin{align*}\n(& 1.5, 1.6666666666666665, 1.6, \\\\\n& 1.625, 1.6153846153846154, \\\\\n& 1.619047619047619, \\dots, \\\\\n& 1.6180339631667064)\n\\end{align*}\\]\nProses tersebut berakhir setelah 17 iterasi, sehingga barisan tersebut memiliki 17 suku.\nBarisan tersebut bisa diberi nama, seperti \\(p_n\\) dengan \\(n = 1, 2, 3, \\dots, 17\\), yang bisa dituliskan \\(\\left\\{p_n\\right\\}_{n=1}^{17}\\) dengan kurung kurawal.\nContoh barisan tak berhingga adalah barisan aritmetika dan barisan geometri, seperti:\n\\[(-5, -2, 1, 4, 7, 10, 13, 16, 19, \\dots)\\]\n\\[\\left(16, 8, 4, 2, 1, \\frac{1}{2}, \\frac{1}{4}, \\frac{1}{8}, \\dots\\right)\\]\nBarisan tak berhingga dengan nama \\(p_n\\) yang mulai dari suku \\(n=1\\) bisa ditulis \\(\\left\\{p_n\\right\\}_{n=1}^{\\infty}\\) dengan kurung kurawal, atau singkatnya \\((p_n)\\) saja dengan kurung biasa (dengan begitu, biasanya ada asumsi bahwa barisan tersebut tak berhingga).\n\n\nMetode Aitken\nAlexander Aitken menemukan bahwa, untuk sembarang barisan (termasuk sembarang metode numerik) yang memiliki kekonvergenan linier, untuk nilai \\(n\\) yang besar, berlaku\n\\[\\frac{p_{n+1} - p}{p_n - p} \\approx \\frac{p_{n+2} - p}{p_{n+1} - p}\\]\ndi mana \\(p\\) adalah nilai yang ingin dicari, sedangkan \\(p_n\\), \\(p_{n+1}\\), dan \\(p_{n+2}\\) adalah tiga suku barisan (atau tiga hasil aproksimasi) berturut-turut. Artinya, perbandingan error (error ratio) antar dua pasang hasil iterasi (diperoleh dari tiga hasil iterasi berturut-turut) menjadi kurang lebih sama. Dengan manipulasi aljabar, diperoleh\n\\[p \\approx p_n - \\frac{\\left(p_{n+1} - p_n\\right)^2}{p_{n+2} - 2p_{n+1} + p_n}\\]\nseolah-olah ada jalur pintas untuk langsung mendapatkan nilai yang ingin dicari.\nTentu saja, sebelum menggunakan rumus ini, kita perlu menemukan tiga hasil aproksimasi pertama, yaitu \\(p_0\\), \\(p_1\\), dan \\(p_2\\). Kemudian, barulah kita tentukan \\(p_3\\) menggunakan rumus Aitken (hasil rumus Aitken biasa disebut \\(\\hat{p}_n\\), sehingga bisa ditulis \\(p_3 = \\hat{p}_0\\), karena perhitungan \\(p_3\\) memanfaatkan \\(p_0\\), \\(p_1\\) dan \\(p_2\\)).\nVariabel \\(\\hat{p}\\) biasa disebut p-hat atau p-cap (kata “hat” atau “cap” artinya topi).\nApabila kita definisikan \\(\\Delta p_n = p_{n+1} - p_n\\) dan \\(\\Delta^2 p_n = p_{n+2} - 2p_{n+1} + p_n\\), rumus Aitken bisa ditulis\n\\[\\hat{p}_n = p_n - \\frac{(\\Delta p_n)^2}{\\Delta^2 p_n}\\]\nsehingga teknik ini biasa disebut Aitken’s delta-squared (\\(\\Delta^2\\)) method.\nCatatan: dalam pembahasan metode Aitken/Steffensen, penulisan \\(\\Delta^2\\) BUKAN berarti \\((\\Delta)^2\\). Itu hanya penulisan saja.\nSecara umum, apabila kita punya suku-suku suatu barisan yang berturut-turut yaitu \\(p_1, p_2, p_3, \\dots, p_{k-3}, p_{k-2}, p_{k-1}, p_{k}\\), maka rumus Aitken bisa digunakan untuk menentukan \\(\\hat{p}_1, \\hat{p}_2, \\hat{p}_3, \\dots, \\hat{p}_{k-3}, \\hat{p}_{k-2}\\), yang semuanya merupakan aproksimasi nilai yang lebih akurat untuk hasil konvergen dari barisan tersebut (dengan asumsi kekonvergenan linier).\nPerhatikan: - Kita hanya bisa berhenti sampai \\(\\hat{p}_{k-2}\\), karena perhitungannya membutuhkan \\(p_{k-2}\\), \\(p_{k-1}\\) dan \\(p_k\\). - Harus ada minimal 3 suku yang diketahui, artinya \\(k \\ge 3\\).\n\ndef Aitken(p):\n    k = len(p)\n    if k &lt; 3:\n        return \"Maaf, dibutuhkan minimal 3 suku yang diketahui.\"\n    \n    # kalau lanjut ke sini, artinya k &gt;= 3\n    list_phat = []\n    for i in range(k-2):\n        Delta = p[i+1] - p[i]\n        DeltaSquared = p[i+2] - 2 * p[i+1] + p[i]\n        phat = p[i] - (Delta)**2 / DeltaSquared\n        list_phat.append(phat)\n    return list_phat\n\n\ntry:\n    # input suatu list\n    p = eval(input(\"Masukkan list suku-suku yang diketahui: \"))\nexcept:\n    print(\"Maaf, terjadi error. Harap masukkan list dengan benar.\")\nelse: # kalau tidak terjadi error \n    print(\"Berikut hasil metode Aitken:\") \n    print(Aitken(p))\n\nMasukkan list suku-suku yang diketahui: [2, 1.5, 1.6666666666666665, 1.6, 1.625]\nBerikut hasil metode Aitken:\n[1.625, 1.619047619047619, 1.6181818181818182]\n\n\n\n\nMetode Steffensen: Penerapan Metode Aitken pada Metode Fixed Point\nAitken hanya menemukan rumus. Johan Frederik Steffensen menemukan bahwa, karena Metode Fixed-Point memiliki kekonvergen linier, metode Aitken bisa digunakan untuk mempercepat Metode Fixed-Point.\nSecara umum, apabila kita berselang-seling antara menggunakan suatu metode dan rumus Aitken (misalnya setelah memperoleh tiga hasil aproksimasi), kita dapat mempercepat kekonvergenan (accelerating convergence), seolah-olah order of convergence menjadi lebih besar dari 1. Namun, bagaimana cara selang-selingnya?\nMenurut Steffensen, rumus Aitken bisa digunakan tiap tiga iterasi fixed-point, yaitu untuk \\(p_3\\), \\(p_6\\), \\(p_9\\), dan seterusnya.\nKita bisa memodifikasi rumus Aitken dengan menggeser indeks \\(n\\), yaitu menukar \\(n\\) dengan \\(n-3\\), untuk mendapatkan rumus iterasi:\n\\[\\hat{p} = p_{n-3} - \\frac{\\left(p_{n-2} - p_{n-3}\\right)^2}{p_{n-1} - 2p_{n-2} + p_{n-3}}\\]\ndan dalam hal ini, kita juga bisa mendefinisikan \\(\\Delta_1 = p_{n-2} - p_{n-3}\\) dan \\(\\Delta_2 = p_{n-1} - 2p_{n-2} + p_{n-3}\\) untuk mendapatkan bentuk:\n\\[\\hat{p} = p_{n-3} - \\frac{(\\Delta_1)^2}{(\\Delta_2)}\\]\n\ndef Steffensen(g, p0, tolerance):\n    # list semua nilai p agar mudah diakses\n    list_p = [p0]\n\n    # nilai sementara\n    abs_error = tolerance + 1 \n\n    iterasi = 1 # penghitung banyaknya iterasi\n    while abs_error &gt;= tolerance:\n        if iterasi % 3 == 0: # untuk kelipatan tiga, gunakan rumus Aitken\n            pn_3 = list_p[iterasi - 3] # p_(n-3)\n            pn_2 = list_p[iterasi - 2] # p_(n-2)\n            pn_1 = list_p[iterasi - 1] # p_(n-1)\n            Delta1 = pn_2 - pn_3\n            Delta2 = pn_1 - 2 * pn_2 + pn_3\n            pn = pn_3 - (Delta1)**2 / Delta2\n        else: # selain kelipatan 3, gunakan fixed point\n            pn_1 = list_p[iterasi - 1]\n            pn = g(pn_1)\n        \n        list_p.append(pn)\n        abs_error = abs( pn - pn_1 )\n        iterasi += 1\n    \n    # return bukan hanya p, tetapi juga banyaknya iterasi\n    return pn, iterasi\n\n\nfrom numpy import sin, cos, tan, log, exp, sqrt\n\nformula = input(\"Masukkan formula g(x): \")\n\ndef g(x):\n    return eval(formula)\n\nstarting_point = eval(input(\"Masukkan titik awal iterasi: \"))\ntolerance = eval(input(\"Masukkan batas toleransi: \"))\n\np_steffensen, i_steffensen = Steffensen(g, starting_point, tolerance)\n\nprint(\"Metode Steffensen\")\nprint(\"Hasil: \" + str(p_steffensen))\nprint(\"setelah banyaknya iterasi: \" + str(i_steffensen))\n\nprint(\"Bandingkan banyaknya iterasi dengan Metode Fixed-Point biasa:\")\n\nfixpoint_hasil, fixpoint_tabel = FixedPoint(g, starting_point, tolerance)\nprint(fixpoint_tabel)\n\nMasukkan formula g(x): 1 + 1/x\nMasukkan titik awal iterasi: 2\nMasukkan batas toleransi: 10**(-7)\nMetode Steffensen\nHasil: 1.618033988749648\nsetelah banyaknya iterasi: 11\nBandingkan banyaknya iterasi dengan Metode Fixed-Point biasa:\n+---------+--------------------+\n| iterasi |    Aproksimasi     |\n+---------+--------------------+\n|    1    |        1.5         |\n|    2    | 1.6666666666666665 |\n|    3    |        1.6         |\n|    4    |       1.625        |\n|    5    | 1.6153846153846154 |\n|    6    | 1.619047619047619  |\n|    7    | 1.6176470588235294 |\n|    8    | 1.6181818181818182 |\n|    9    | 1.6179775280898876 |\n|   10    | 1.6180555555555556 |\n|   11    | 1.6180257510729614 |\n|   12    | 1.6180371352785146 |\n|   13    | 1.6180327868852458 |\n|   14    | 1.618034447821682  |\n|   15    | 1.618033813400125  |\n|   16    | 1.6180340557275543 |\n|   17    | 1.6180339631667064 |\n+---------+--------------------+"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul3.html",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul3.html",
    "title": "Modul 3 Metode Numerik: Diferensiasi Numerik, Ekstrapolasi Richardson",
    "section": "",
    "text": "Kembali ke Metode Numerik\n\nTurunan/Diferensiasi Numerik\nPengantar Ekstrapolasi Richardson (penjelasan tanpa kode)\nEkstrapolasi Richardson khusus rumus forward/backward-difference\nEkstrapolasi Richardson dengan \\(N_1 \\left( \\frac{h}{2} \\right)\\), dari \\(O(h)\\) menjadi \\(O(h^2)\\)\nEkstrapolasi Richardson untuk truncation error \\(O\\left(h^{2j}\\right)\\) (pangkat genap)\n\n\nTurunan/Diferensiasi Numerik\nUntuk step size \\(h \\ne 0\\) (boleh positif maupun negatif), rumus-rumus berikut ini bisa digunakan untuk mengaproksimasi turunan.\na. Forward/Backward-Difference\ntruncation error: \\(O\\left(h\\right)\\)\n\\[f'(x_0) \\approx \\frac{f(x_0 + h) - f(x_0)}{h}\\]\ntruncation term: \\(-\\frac{h}{2}f''(\\xi) = O\\left(h\\right)\\)\nRumus diferensiasi numerik yang paling sederhana, yaitu sesuai definisi turunan, dengan nilai \\(h\\) yang dekat dengan nol (sayangnya tidak bisa dibuat limit \\(h\\) menuju nol). Rumus di atas disebut forward-difference formula jika \\(h &gt; 0\\), dan disebut backward-difference formula jika \\(h &lt; 0\\).\nb. Three-Point Formulas\ntruncation error: \\(O\\left(h^2\\right)\\)\n\nThree-Point Endpoint (TPEP): \\[f'(x_0) \\approx \\frac{1}{2h} \\left[-3f(x_0) +4f(x_0+h) - f(x_0+2h)\\right]\\]\n\ntruncation term (TPEP): \\(\\frac{h^2}{3}f^{(3)}(\\xi) = O\\left(h^2\\right)\\)\n\nThree-Point Midpoint (TPMP), juga disebut centered-difference formula: \\[f'(x_0) \\approx \\frac{1}{2h} \\left[f(x_0 + h) -f(x_0 - h)\\right]\\]\n\ntruncation term (TPMP): \\(-\\frac{h^2}{6}f^{(3)}(\\xi) = O\\left(h^2\\right)\\)\nc. Five-Point Formulas\ntruncation error: \\(O\\left(h^4\\right)\\)\n\nFive-Point Endpoint (FPEP): \\[f'(x_0) \\approx \\frac{1}{12h} \\left[-25f(x_0) + 48f(x_0 + h) - 36f(x_0 + 2h) +16f(x_0 + 3h) - 3f(x_0 + 4h) \\right]\\]\n\ntruncation term (FPEP): \\(\\frac{h^4}{5}f^{(5)}(\\xi) = O\\left(h^4\\right)\\)\n\nFive-Point Midpoint (FPMP): \\[f'(x_0) \\approx \\frac{1}{12h} \\left[f(x_0 - 2h) - 8f(x_0 - h) + 8f(x_0 + h) - f(x_0 - 2h)\\right]\\]\n\ntruncation term (FPMP): \\(\\frac{h^4}{30}f^{(5)}(\\xi) = O\\left(h^4\\right)\\)\nd. BONUS: Second Derivative Midpoint Formula\ntruncation error: \\(O\\left(h^2\\right)\\)\n\\[f''\\left(x_0\\right) \\approx \\frac{1}{h^2} \\left[ f(x_0 - h) - 2f(x_0) + f(x_0 + h) \\right]\\]\ntruncation term: \\(-\\frac{h^2}{12}f^{(4)}(\\xi) = O\\left(h^2\\right)\\)\nDari semua rumus yang kita bahas, ini adalah satu-satunya rumus yang menghitung turunan kedua.\nSayangnya, karena nilai \\(h\\) dikuadratkan dan menjadi pembagi, nilai \\(h\\) yang terlalu kecil bisa lebih mudah membuat metode/rumus ini gagal dibandingkan dengan rumus-rumus turunan pertama yang sudah dibahas sebelumnya.\nBerikut kode Python menghitung turunan secara numerik.\n\ndef FBDiff(f,x,h): #Forward/Backward-Difference\n    return (f(x+h)-f(x))/h\n\ndef TPEP(f,x,h): # Three-Point End Point\n    return (1/(2*h)) * (-3*f(x) + 4*f(x+h) - f(x+2*h))\n\ndef TPMP(f,x,h): # Three-Point Mid Point\n    return (1/(2*h)) * (f(x+h) - f(x-h))\n\ndef FPEP(f,x,h): # Five-Point End Point\n    return (1/(12*h)) * (-25*f(x) + 48*f(x+h) - 36*f(x+2*h) + 16*f(x+3*h) - 3*f(x+4*h))\n\ndef FPMP(f,x,h): # Five-Point Mid Point\n    return (1/(12*h)) * (f(x-2*h) - 8*f(x-h) + 8*f(x+h) - f(x+2*h))\n\ndef SDMP(f,x,h): # Second Derivative Mid Point\n    return (1/(h**2)) * (f(x-h) - 2*f(x) + f(x+h))\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Diferensiasi Numerik\")\nformula = input(\"Masukkan formula f(x) yang akan dicari nilai turunannya : \")\ndef f(x):\n    return eval(formula)\n\nx0 = eval(input(\"Masukkan titik x0 di mana nilai turunan fungsinya akan diaproksimasi : \"))\nh = eval(input(\"Masukkan besar step size (h) taknol, boleh negatif : \"))\nprint()\n\nprint(\"Turunan pertama dari f di x0 = {0} adalah : \".format(x0))\nprint(\"f'({0}) = {1} (Forward/Backward-Difference)\".format(x0,FBDiff(f,x0,h)))\nprint(\"f'({0}) = {1} (Three Point Endpoint)\".format(x0,TPEP(f,x0,h)))\nprint(\"f'({0}) = {1} (Three Point Midpoint)\".format(x0,TPMP(f,x0,h)))\nprint(\"f'({0}) = {1} (Five Point Endpoint)\".format(x0,FPEP(f,x0,h)))\nprint(\"f'({0}) = {1} (Five Point Midpoint)\".format(x0,FPMP(f,x0,h)))\nprint()\nprint(\"Turunan kedua dari f di x0 = {0} adalah : \".format(x0))\nprint(\"f''({0}) = {1} (Second Derivative Midpoint)\".format(x0,SDMP(f,x0,h)))\nprint(\"Note: nilai h yang terlalu kecil bisa membuat metode Second Derivative Midpoint gagal.\")\n\nDiferensiasi Numerik\nMasukkan formula f(x) yang akan dicari nilai turunannya : x**3\nMasukkan titik x0 di mana nilai turunan fungsinya akan diaproksimasi : 3\nMasukkan besar step size (h) taknol, boleh negatif : 10**-5\n\nTurunan pertama dari f di x0 = 3 adalah : \nf'(3) = 27.000090000228735 (Forward/Backward-Difference)\nf'(3) = 26.999999999866017 (Three Point Endpoint)\nf'(3) = 27.000000000221288 (Three Point Midpoint)\nf'(3) = 27.0000000002805 (Five Point Endpoint)\nf'(3) = 27.000000000014047 (Five Point Midpoint)\n\nTurunan kedua dari f di x0 = 3 adalah : \nf''(3) = 18.000001489326674 (Second Derivative Midpoint)\nNote: nilai h yang terlalu kecil bisa membuat metode Second Derivative Midpoint gagal.\n\n\n\n\nPengantar Ekstrapolasi Richardson (penjelasan tanpa kode)\nInti sari dari ekstrapolasi Richardson adalah “menggabungkan” beberapa hasil aproksimasi dengan step size yang berbeda-beda (tapi rumus/metodenya tetap sama) sedemikian sehingga diperoleh hasil aproksimasi yang lebih akurat.\nHasil aproksimasi yang dimaksud itu untuk metode numerik yang mana saja ya? Bagaimana rumus ekstrapolasinya? Simak penjelasan berikut ini.\nMisalkan \\(N_1 (h)\\) adalah hasil aproksimasi suatu metode/rumus yang dihitung dengan step size h, dan memiliki truncation error \\(O(h)\\), yaitu berbentuk seperti berikut:\n\\[K_1 h + K_2 h^2 + K_3 h^3 + \\dots\\]\ndi mana \\(K_j\\) adalah sejumlah konstanta (yang kemungkinan tidak diketahui nilainya). Misalkan pula, \\(M\\) adalah nilai eksak yang ingin diaproksimasi oleh metode tersebut. Maka, kita bisa menuliskan bahwa hasil eksak sama dengan hasil aproksimasi ditambah error, yaitu\n\\[M = N_1 (h) + K_1 h + K_2 h^2 + K_3 h^3 + \\dots\\]\natau bisa ditulis\n\\[M - N_1 (h) = K_1 h + K_2 h^2 + K_3 h^3 + \\dots\\]\nyaitu hasil eksak dikurang hasil aproksimasi sama dengan error.\nLazimnya, step size yang dipilih cukup kecil, tentu lebih kecil dari 1, sehingga berlaku \\(h &gt; h^2 &gt; h^3 &gt; \\dots\\).\nBahkan, biasanya \\(h^2\\) jauh lebih kecil daripada \\(h\\), apalagi \\(h^3\\) lebih kecil lagi, apalagi \\(h^4\\), dan seterusnya, sehingga kita bisa menuliskan aproksimasi seperti berikut:\n\\[M - N_1 (h) \\approx K_1 h\\]\nAproksimasi tersebut akan kita manfaatkan.\nSeandainya kita pilih step size \\(\\frac{h}{2}\\), kita mendapatkan\n\\[M = N_1 \\left( \\frac{h}{2} \\right) + K_1 \\frac{h}{2} + K_2 \\left(\\frac{h}{2}\\right)^2 + K_3 \\left(\\frac{h}{2}\\right)^3 + \\dots\\]\natau\n\\[M = N_1 \\left( \\frac{h}{2} \\right) + K_1 \\frac{h}{2} + K_2 \\frac{h^2}{4} + K_3 \\frac{h^3}{8} + \\dots\\]\nSaat ini, suku dengan \\(K_1\\) dikalikan dengan \\(\\frac{h}{2}\\). Kita bisa mengkalikan keseluruhan rumus dengan 2 agar ada suku \\(K_1 h\\), seperti berikut:\n\\[2M = 2N_1 \\left( \\frac{h}{2} \\right) + K_1 h + K_2 \\frac{h^2}{2} + K_3 \\frac{h^3}{4} + \\dots\\]\nKita bisa mengurangi persamaan di atas dengan \\(M = N_1 (h) + K_1 h + K_2 h^2 + K_3 h^3 + \\dots\\) agar mendapatkan\n\\[2M - M = \\left[ 2N_1 \\left( \\frac{h}{2} \\right) - N_1 (h) \\right] + \\left[ K_1 h - K_1 h \\right] + \\left[ K_2 \\frac{h^2}{2} - K_2 h^2 \\right] + \\left[ K_3 \\frac{h^3}{4} - K_3 h^2 \\right] + \\dots\\]\nsehingga\n\\[M = \\left[ 2N_1 \\left( \\frac{h}{2} \\right) - N_1 (h) \\right] + 0 + K_2 \\left( \\frac{h^2}{2} - h^2 \\right) + K_3 \\left( \\frac{h^3}{4} - h^3 \\right) + \\dots\\]\n\\[M = \\left[ 2N_1 \\left( \\frac{h}{2} \\right) - N_1 (h) \\right] - K_2 \\frac{h^2}{2} - K_3 \\frac{3h^3}{4} + \\dots\\]\n\\[M = \\left[ 2N_1 \\left( \\frac{h}{2} \\right) - N_1 (h) \\right] + \\left( \\frac{-K_2}{2} \\right) h^2 + \\left( \\frac{-3}{4} K_3 \\right) h^3 + \\dots\\]\nTiba-tiba, sudah tidak ada suku \\(K_1 h\\) lagi. Bahkan, kita telah mengelompokkan koefisien untuk mendapatkan bentuk\n\\[\\dots h^2 + \\dots h^3 + \\dots\\]\nseolah-olah error baru untuk persamaan ini menjadi \\(O\\left(h^2\\right)\\), dengan truncation error memiliki koefisien baru yaitu misal \\(\\hat{K}_1 = 0\\), \\(\\hat{K}_2 = \\frac{-K_2}{2}\\), \\(\\hat{K}_3 = \\frac{-3}{4} K_3\\), dan seterusnya, dalam bentuk truncation error tetap berupa\n\\[\\hat{K}_1 h + \\hat{K}_2 h^2 + \\hat{K}_3 h^3 + \\dots\\]\nnamun suku \\(\\hat{K}_1 h\\) bisa diabaikan (karena bernilai nol), dan truncation error bisa langsung disimpulkan berupa \\(O\\left(h^2\\right)\\).\nDengan demikian,\n\\[M \\approx 2N_1 \\left( \\frac{h}{2} \\right) - N_1 (h)\\]\nsehingga kita bisa mendefinisikan hasil aproksimasi baru:\n\\[N_2 (h) = 2N_1 \\left( \\frac{h}{2} \\right) - N_1 (h)\\]\nProses penurunan rumus tersebut, memanfaatkan hasil aproksimasi dengan step size yang berbeda, sampai mendapatkan bentuk lain dengan error baru yang lebih kecil (misal di sini dari \\(O(h)\\) menjadi \\(O(h^2)\\)), disebut ekstrapolasi Richardson.\nPada rumus ekstrapolasi Richardson, \\(N_2 (h)\\) adalah hasil aproksimasi untuk \\(M\\) yang ternyata lebih baik daripda \\(N_1\\) yang manapun (karena error yang lebih kecil). Bahkan, bentuk error untuk \\(N_2 (h)\\) tetap berbentuk semacam \\(\\hat{K}_1 h + \\hat{K}_2 h^2 + \\dots\\), sehingga kita bisa melakukan proses yang serupa (menggunakan ekstrapolasi Richardson lagi) untuk memperoleh rumus \\(N_3 (h)\\), lalu lagi untuk \\(N_4 (h)\\), dan seterusnya (yang akan membutuhkan \\(N_1 \\left( \\frac{h}{4} \\right)\\), \\(N_1 \\left( \\frac{h}{8} \\right)\\), dan seterusnya, termasuk beberapa nilai \\(N_2\\) dengan berbagai step size, beberapa nilai \\(N_3\\), dan seterusnya). Perhatikan bahwa rumus ekstrapolasi Richardson yang diperoleh akan memerlukan hasil aproksimasi untuk berbagai step size, bukan hanya dengan step size \\(h\\).\nBahkan, tidak ada kewajiban untuk memilih step size \\(\\frac{h}{2}\\). Kita juga bisa memilih step size misalnya \\(\\frac{h}{3}\\) atau dibagi bilangan lain, untuk mendapatkan rumus ekstrapolasi Richardson yang misalnya memanfaatkan \\(N_1 (h)\\) dan \\(N_1 \\left( \\frac{h}{3} \\right)\\).\nApakah benar, \\(N_1\\) memang bisa berupa hasil aproksimasi metode numerik apapun?\nSecara teori, ekstrapolasi Richardson bisa diterapkan untuk semua metode aproksimasi (termasuk diferensiasi numerik) dengan syarat: harus memiliki bentuk truncation error seperti berikut,\n\\[\\sum_{j=1}^{m-1} \\left(K_j h^{\\alpha_j}\\right) + O\\left(h^{\\alpha_m}\\right) = K_1 h^{\\alpha_1} + K_2 h^{\\alpha_2} + K_3 h^{\\alpha_3} + \\dots + K_{m-1} h^{\\alpha_{m-1}} + O\\left(h^{\\alpha_m}\\right)\\]\ndi mana \\(K_j\\) dan \\(\\alpha_j\\) adalah sejumlah konstanta (yang kemungkinan tidak diketahui nilainya) dengan \\(\\alpha_1 &lt; \\alpha_2 &lt; \\alpha_3 &lt; \\dots &lt; \\alpha_m\\).\nSebelumnya, untuk bentuk truncation error, kita telah mengasumsikan bahwa \\(\\alpha_1 = 1\\), \\(\\alpha_2 = 2\\), \\(\\alpha_3 = 3\\), dan seterusnya. Itu tidak masalah; kebetulan saja, ekstrapolasi Richardson masih bisa diterapkan pada bentuk truncation error yang lebih umum lagi.\nSebenarnya, bentuk umum tersebut memang agak ambigu, karena penulisan \\(O\\left(h^{\\alpha_m}\\right)\\) bisa dianggap sebagai “singkatan” untuk suku-suku dengan hasil pangkat \\(h\\) yang lebih kecil lagi, sama halnya dengan kita menyingkat penulisan truncation error menjadi misalnya \\(O(h)\\) atau \\(O(h^2)\\).\nBagaimanapun juga, sejauh ini, asumsi truncation error yang telah kita tuliskan sebelumnya tetap memenuhi bentuk umum di atas.\nKemudian, bagaimana penerapan ekstrapolasi Richardson pada metode numerik yang telah kita pelajari?\nMumpung rumus forward/backward-difference memiliki truncation term \\(-\\frac{h}{2}f''(\\xi) = O(h)\\), kita bisa melakukan ekstrapolasi Richardson, bahkan langsung menggunakan rumus \\(N_2 (h)\\) yang telah kita temukan tadi, yang “mengubah” error \\(O(h)\\) menjadi \\(O(h^2)\\). Mari mulai praktek!\n\n\nEkstrapolasi Richardson khusus rumus forward/backward-difference\nIngat bahwa, untuk \\(N_1\\) berupa hasil aproksimasi dengan error \\(O(h)\\), kita telah menemukan rumus ekstrapolasi Richardson dengan error \\(O(h^2)\\) sebagai berikut:\n\\[N_2 (h) = 2N_1 \\left( \\frac{h}{2} \\right) - N_1 (h)\\]\nMetode aproksimasi forward/backward-difference memiliki error \\(O(h)\\), sehingga bisa diterapkan ekstraplasi Richardson, dengan menghitung \\(N_1\\) yaitu aproksimasi \\(f'(x_0)\\), dengan step size \\(h\\) dan \\(\\frac{h}{2}\\) terlebih dahulu sebelum menggunakan rumus ekstrapolasi Richardson.\nIngat bahwa rumus forward/backward-difference (yang menjadi \\(N_1 (h)\\) di sini) adalah\n\\[f'(x_0) \\approx \\frac{f(x_0 + h) - f(x_0)}{h}\\]\nPerhatikan kode berikut.\n\ndef RichardsonOhOtomatis(N_1, f, x, h): # ekstrapolasi Richardson untuk O(h), otomatis\n    # N_1 adalah function\n    return 2*N_1(f, x, h/2) - N_1(f, x, h)\n\ndef FBDiff(f,x,h): #Forward/Backward-Difference\n    return (f(x+h)-f(x))/h\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Ekstrapolasi Richardson khusus Forward/Backward-Difference\")\nformula = input(\"Masukkan formula f(x) yang akan dicari nilai turunannya : \")\ndef f(x):\n    return eval(formula)\n\nx0 = eval(input(\"Masukkan titik x0 di mana nilai turunan fungsinya akan diaproksimasi : \"))\nh = eval(input(\"Masukkan besar step size (h) taknol, boleh negatif : \"))\nprint()\n\nN1h = FBDiff(f, x0, h) # N_1 (h)\nN1h2 = FBDiff(f, x0, h/2) # N_1 (h/2)\nN2h = RichardsonOhOtomatis(FBDiff, f, x0, h) # N_2 (h)\n\nprint(\"Hasil Forward/Backward-Difference:\")\nprint(\"N_1 ({0}) = {1}\".format(h, N1h))\nprint(\"N_1 ({0}) = {1}\".format(h/2, N1h2))\nprint(\"Hasil Ekstrapolasi Richardson O(h):\")\nprint(\"N_2 ({0}) = {1}\".format(h, N2h))\n\nEkstrapolasi Richardson khusus Forward/Backward-Difference\nMasukkan formula f(x) yang akan dicari nilai turunannya : x + exp(x)\nMasukkan titik x0 di mana nilai turunan fungsinya akan diaproksimasi : 0\nMasukkan besar step size (h) taknol, boleh negatif : 0.5\n\nHasil Forward/Backward-Difference:\nN_1 (0.5) = 2.2974425414002564\nN_1 (0.25) = 2.1361016667509656\nHasil Ekstrapolasi Richardson O(h):\nN_2 (0.5) = 1.9747607921016748\n\n\n\n\nEkstrapolasi Richardson dengan \\(N_1 \\left( \\frac{h}{2} \\right)\\), dari \\(O(h)\\) menjadi \\(O(h^2)\\)\nTentu saja, kita bisa menggunakan rumus \\(N_2 (h)\\) untuk apapun data \\(N_1 (h)\\) dan \\(N_1 \\left(\\frac{h}{2}\\right)\\) yang kita miliki, yang bisa berasal dari metode \\(O(h)\\) apapun yang memenuhi syarat ekstrapolasi Richardson (dilihat dari bentuk truncation error).\n\ndef RichardsonOhManual(N1h, N1h2): # ekstrapolasi Richardson untuk O(h), manual\n    return 2*N1h2 - N1h\n\n\nfrom numpy import sin, cos, tan, log, exp, pi\n\nprint(\"Ekstrapolasi Richardson untuk truncation error O(h)\")\nprint(\"dengan sembarang data N_1 (h) dan N_1 (h/2)\")\n\nN1h = eval(input(\"Masukkan data N_1 (h): \")) # N_1 (h)\nN1h2 = eval(input(\"Masukkan data N_1 (h/2): \")) # N_1 (h/2)\nN2h = RichardsonOhManual(N1h, N1h2) # N_2 (h)\n\nprint(\"Hasil Ekstrapolasi Richardson untuk truncation error O(h):\")\nprint(\"N_2 (h) = {0}\".format(N2h))\n\nEkstrapolasi Richardson untuk truncation error O(h)\ndengan sembarang data N_1 (h) dan N_1 (h/2)\nMasukkan data N_1 (h): 2.2974425414002564\nMasukkan data N_1 (h/2): 2.1361016667509656\nHasil Ekstrapolasi Richardson untuk truncation error O(h):\nN_2 (h) = 1.9747607921016748\n\n\n\n\nEkstrapolasi Richardson untuk truncation error \\(O\\left(h^{2j}\\right)\\) (pangkat genap)\nTerkadang, pada bentuk truncation error untuk beberapa metode aproksimasi, semua pangkat \\(h\\) genap, sehingga memenuhi persamaan seperti berikut:\n\\[M = N_1(h) + K_1 h^2 + K_2 h^4 + K_3 h^6 + \\dots\\]\natau bisa dikatakan memiliki error \\(O(h^{2j})\\) untuk suatu \\(j\\) (yang merupakan bilangan bulat positif). Menariknya, sesuai penurunan rumus pada buku “Numerical Analysis” (oleh Burden & Faires) edisi ke-9, halaman 187-188, untuk kasus error \\(O(h^{2j})\\), ada bentuk umum rekursif untuk rumus ekstrapolasi Richardson, yaitu sebagai berikut:\n\\[N_j (h) = N_{j-1} \\left( \\frac{h}{2} \\right) + \\frac{N_{j-1} \\left( h/2 \\right) - N_{j-1} (h)}{4^{j-1} - 1}\\]\nuntuk bilangan bulat \\(j \\ge 2\\).\nPerhatikan bahwa perhitungan \\(N_2 (h)\\) akan memerlukan \\(N_1 (h)\\) dan \\(N_1 \\left( \\frac{h}{2} \\right)\\). Kemudian, perhitungan \\(N_3 (h)\\) akan memerlukan \\(N_2 (h)\\) dan \\(N_2 \\left( \\frac{h}{2} \\right)\\), di mana perhitungan \\(N_2 \\left( \\frac{h}{2} \\right)\\) akan memerlukan \\(N_1 \\left( \\frac{h}{2} \\right)\\) dan \\(N_1 \\left( \\frac{h}{4} \\right)\\).\nKita bisa menampilkan semua hasil perhitungan menggunakan tabel, dengan bentuk yang “mirip” dengan metode Neville. Kali ini, kolom pertama adalah hasil \\(O(h^2)\\) atau \\(N_1\\), kolom kedua adalah hasil \\(O(h^4)\\) yaitu \\(N_2\\), kolom ketiga adalah hasil \\(O(h^6)\\) yaitu \\(N_3\\), dan seterusnya. Sedangkan, setidaknya untuk \\(N_1\\), baris pertama adalah hasil untuk step size h, baris kedua untuk step size \\(\\frac{h}{2}\\), baris ketiga untuk \\(\\frac{h}{4}\\), baris keempat untuk \\(\\frac{h}{8}\\), dan seterusnya.\nPerhatikan contoh tabel berikut. Angka 1, 2, 3, …, 9, 10 yang bercetak tebal melambangkan urutan perhitungan (dilakukan per baris, dari kiri ke kanan).\n\n\n\ncrop tabel 4_6 hal 188 Numerical analysis by Richard L Burden J Douglas Faires (z-lib.org)_page-0001.jpg\n\n\nSumber gambar: Burden, Richard L., Faires, J. Douglas. Numerical Analysis. Edisi ke-9. Bab 4, “Numerical Differentiation and Integration”. Subbab 4.2, “Richardson’s Extrapolation”. Hlm. 188\nBahkan, seperti metode Neville, kita bisa membuat program sehingga, selain perhitungan disimpan dalam bentuk tabel (atau list di dalam list), kita juga bisa melakukan perhitungan selanjutnya berdasarkan data pada tabel. Contohnya, untuk perhitungan \\(N_2 (h)\\) (baris kedua, kolom kedua), kita bisa menggunakan data “ke atas satu langkah, ke kiri satu langkah” untuk \\(N_1 (h)\\), dan menggunakan data “ke kiri satu langkah” untuk \\(N_1 \\left( \\frac{h}{2} \\right)\\).\nSeperti pada tabel di atas, perhitungan bisa dilakukan per baris. Bahkan, seperti pada metode Neville, kita selalu bisa menambahkan baris baru dengan mudah.\n\nfrom tabulate import tabulate\n\n# jaga-jaga ada konstanta pi atau e pada data N1 yang diberikan\nfrom numpy import pi, e\n\n# fungsi untuk menambahkan baris baru pada tabel yang sudah ada\ndef TambahkanRichardsonO2j(tabel_lama, N1baru):\n    # Duplikasi tabel lama menjadi tabel baru (karena akan dimodifikasi)\n    tabel_baru = tabel_lama.copy()\n\n    # Tambahkan kolom kosong pada baris-baris yang sudah ada\n    for i in range(len(tabel_baru)):\n        tabel_baru[i].append(\"\")\n\n    # Membuat baris baru...\n    baris_baru = [N1baru]\n    # ... dengan kolom sebanyak len(tabel_lama)+1:\n    for i in range(len(tabel_lama)):\n        baris_baru.append(\"\")\n    # meskipun saat ini kosong, setelah ini akan diisi sesuai rumus.\n    # Tambahkan dulu ke tabel (sebagai baris paling bawah terbaru):\n    tabel_baru.append(baris_baru)\n\n    # Mengisi baris paling bawah\n    k = len(baris_baru) # banyaknya titik termasuk titik baru\n    i = k-1 # baris baru adalah baris ke-k, dengan indeks (k-1)\n    for j in range(1, k): # untuk kolom N2 (indeks 1), N3 (indeks 2), ...\n        # N_{j-1} (h) yaitu ke atas satu langkah, ke kiri satu langkah\n        Nj1h = tabel_baru[i-1][j-1]\n\n        # N_{j-1} (h/2) yaitu ke kiri satu langkah\n        Nj1h2 = tabel_baru[i][j-1]\n\n        # Pada rumus, \"j\" yang dimaksud bukanlah indeks, tapi kolom ke-j,\n        # sehingga indeks 1 adalah kolom ke-2, indeks 2 adalah kolom ke-3, dst\n        j_kolom = j+1\n\n        # nilai baru, N_j (h), menggunakan rumus rekursif\n        tabel_baru[i][j] = Nj1h2 + (Nj1h2 - Nj1h)/(4**(j_kolom-1) - 1)\n\n    # Tabel sudah jadi\n    return tabel_baru\n\n# Kode utama untuk Ekstrapolasi Richardson O(h^2j)\ndef EkstrapolasiRichardsonO2j(list_N1):\n    # Awal membuat tabel\n    tabel_mentah = [\n        [list_N1[0]]\n    ]\n    # mula-mula, hanya ada satu nilai yaitu N1 (h),\n    # sehingga hanya ada satu baris dan satu kolom\n\n    # banyaknya baris/kolom untuk tabel yang akan dibuat\n    k = len(list_N1)\n\n    # lakukan TambahkanRichardsonO2j untuk tiap titik berikutnya\n    for i in range(1, k):\n        tabel_mentah = TambahkanRichardsonO2j(tabel_mentah, list_N1[i])\n\n    # Mengolah tabel menggunakan tabulate\n    list_header = []\n    for i in range(k):\n        list_header.append(\"O(h^{0})\".format(2*(i+1)))\n    tabel_olahan = tabulate(tabel_mentah, headers=list_header,\n                            tablefmt=\"orgtbl\")\n    print(\"Tabel Ekstrapolasi Richardson untuk O(h^2j)\")\n    print(tabel_olahan)\n\n    # Looping\n\n    jawaban = input(\"Apakah Anda ingin menambahkan nilai? (y/n): \")\n    ingin_menambahkan = False\n    if jawaban == \"y\":\n        ingin_menambahkan = True\n\n    while ingin_menambahkan:\n        N1baru = eval(input(\"Masukkan nilai N1 (h/{0}): \".format(2**k)))\n        print()\n\n        tabel_mentah = TambahkanRichardsonO2j(tabel_mentah, N1baru)\n        list_header.append(\"O(h^{0})\".format(2**k))\n        tabel_olahan = tabulate(tabel_mentah, headers=list_header,\n                                tablefmt=\"orgtbl\")\n        print(\"Tabel Ekstrapolasi Richardson untuk O(h^2j)\")\n        print(tabel_olahan)\n\n        jawaban = input(\"Apakah Anda ingin menambahkan nilai? (y/n): \")\n        if jawaban != \"y\":\n            ingin_menambahkan = False\n\n        k += 1\n\n    print()\n    print(\"Terima kasih telah menggunakan program.\")\n\n\nbanyaknya_N1 = eval(input(\"Berapa nilai N1 yang ingin dimasukkan?: \"))\n\nlist_N1 = []\nfor i in range(banyaknya_N1):\n    pembagi = 2**i\n    if pembagi != 1:\n        pertanyaan = \"Masukkan nilai N1 (h/{0}): \".format(pembagi)\n    else:\n        pertanyaan = \"Masukkan nilai N1 (h): \"\n    N1baru = eval(input(pertanyaan))\n    list_N1.append(N1baru)\n\nprint()\nEkstrapolasiRichardsonO2j(list_N1)\n\nBerapa nilai N1 yang ingin dimasukkan?: 3\nMasukkan nilai N1 (h): 1.570796\nMasukkan nilai N1 (h/2): 1.896119\nMasukkan nilai N1 (h/4): 1.974232\n\nTabel Ekstrapolasi Richardson untuk O(h^2j)\n|   O(h^2) | O(h^4)             | O(h^6)             |\n|----------+--------------------+--------------------|\n|  1.5708  |                    |                    |\n|  1.89612 | 2.00456            |                    |\n|  1.97423 | 2.0002696666666666 | 1.9999836444444443 |\nApakah Anda ingin menambahkan nilai? (y/n): y\nMasukkan nilai N1 (h/8): 1.993570\n\nTabel Ekstrapolasi Richardson untuk O(h^2j)\n|   O(h^2) | O(h^4)             | O(h^6)             | O(h^8)            |\n|----------+--------------------+--------------------+-------------------|\n|  1.5708  |                    |                    |                   |\n|  1.89612 | 2.00456            |                    |                   |\n|  1.97423 | 2.0002696666666666 | 1.9999836444444443 |                   |\n|  1.99357 | 2.000016           | 1.999999088888889  | 1.999999334038801 |\nApakah Anda ingin menambahkan nilai? (y/n): n\n\nTerima kasih telah menggunakan program."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul5.html",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul5.html",
    "title": "Modul 5: Metode Langsung untuk SPL",
    "section": "",
    "text": "Kembali ke Metode Numerik\nOutline\nimport numpy as np"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul5.html#operasi-matriks-pada-python",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul5.html#operasi-matriks-pada-python",
    "title": "Modul 5: Metode Langsung untuk SPL",
    "section": "1. Operasi matriks pada Python",
    "text": "1. Operasi matriks pada Python\nSebelum masuk ke materi metode numerik untuk sistem persamaan linier (SPL), mari kita bahas lebih lanjut tentang operasi matriks menggunakan numpy di Python.\nMengingat kembali, tanpa numpy, matriks dalam Python bisa dituliskan sebagai list dua dimensi (list di dalam list).\n\nmatriks_manual = [ [1, 2, 3], [4, 5, 6] ]\nprint(matriks_manual)\n\n[[1, 2, 3], [4, 5, 6]]\n\n\nAda beberapa keunggulan array numpy dibandingkan dengan list dua dimensi yang dibuat secara manual seperti itu. Cara membuatnya adalah memasukkan suatu list dua dimensi ke dalam np.array, seperti berikut:\n\n# sebelumnya, sudah dibuat list dua dimensi bernama \"matriks_manual\"\nmatriks_numpy = np.array(matriks_manual)\nprint(matriks_numpy)\n\n[[1 2 3]\n [4 5 6]]\n\n\nPada kode di atas, kita telah membuat list dua dimensi di variabel terpisah, sebelum memasukkannya di dalam np.array. Namun, tentu saja, kita bisa langsung membuat list dua dimensinya di dalam np.array:\n\nmatriks_baru = np.array([ [1,2,3], [4,5,6] ])\nprint(matriks_baru)\n\n[[1 2 3]\n [4 5 6]]\n\n\nPerhatikan bahwa tiap list di dalam list adalah baris pada matriks. Misalnya, ada list di dalam list, [1,2,3] yang menjadi baris pertama, diikuti dengan list di dalam list, [4,5,6] yang menjadi baris berikutnya. Kedua list tersebut merupakan bagian dari satu list besar (perhatikan, di dalam np.array itu diawali dan diakhiri kurung siku, karena sebenarnya np.array menerima input berupa list di dalam list).\nHal ini akan penting nantinya ketika ingin menerima input berupa matriks dari user (pengguna).\nSebenarnya, np.array bisa saja menerima input berupa list biasa (bisa dikatakan satu dimensi), di mana outputnya akan berupa array satu dimensi. Selain itu, numpy bisa membuat beberapa jenis array/matriks istimewa. Contohnya, array/matriks yang berisi angka nol semua, dengan np.zeros:\n\nbaris_nol = np.zeros(5) # lima elemen\nprint(baris_nol)\n\n[0. 0. 0. 0. 0.]\n\n\n\nmatriks_nol = np.zeros( (3,2) ) # tiga baris, dua kolom\nprint(matriks_nol)\n\n[[0. 0.]\n [0. 0.]\n [0. 0.]]\n\n\nPerhatikan bahwa, untuk array berdimensi dua (matriks), ada kurung di dalam kurung (seolah-olah, input yang diterima adalah semacam “koordinat”), tidak seperti untuk array biasa (satu dimensi) yang langsung dimasukkan banyaknya elemen tanpa ada kurung lagi.\nSelain nol semua, numpy juga bisa membuat array/matriks yang berisi angka 1 semua, dengan cara yang serupa, dengan np.ones.\n\nprint(np.ones(4))\n\n[1. 1. 1. 1.]\n\n\n\nprint(np.ones( (2, 5) ))\n\n[[1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1.]]\n\n\nUntuk angka selain nol dan satu, kita tinggal membuat array/matriks yang berisi satu semua, kemudian dikalikan dengan apapun angka itu.\n\n# matriks berisi 7 semua\nprint(7 * np.ones( (2, 5) ))\n\n[[7. 7. 7. 7. 7.]\n [7. 7. 7. 7. 7.]]\n\n\nKemudian, kita juga bisa membuat matriks diagonal (yang tentunya merupakan matriks persegi), dengan elemen diagonal sesuai yang kita inginkan, menggunakan np.diag.\n\nelemen_diagonal = np.array([5, 4, 3, 2])\nprint(np.diag(elemen_diagonal))\n\n[[5 0 0 0]\n [0 4 0 0]\n [0 0 3 0]\n [0 0 0 2]]\n\n\nArtinya, untuk membuat matriks identitas, kita bisa menerapkan np.diag pada np.ones.\n\nprint(np.diag(np.ones(4)))\n\n[[1. 0. 0. 0.]\n [0. 1. 0. 0.]\n [0. 0. 1. 0.]\n [0. 0. 0. 1.]]\n\n\nSebenarnya, dari numpy sudah ada fungsi khusus untuk membuat matriks identitas, yaitu np.identity.\n\nprint(np.identity(3))\n\n[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]\n\n\nSama seperti list, pada matriks juga dapat dilakukan indexing dan slicing. Indexing pada matriks juga dimulai dari 0. Matriks adalah array 2-D, sehingga indeks akan terdiri dari [i, j] di mana i menyatakan indeks baris dan j menyatakan indeks kolom.\n\nA = np.array([[1,2,3], [4,5,6]]) #mendefinisikan matriks A 2x3\nB = np.array([[-1,0,1], #mendefinisikan matriks B 2x3\n              [0,0,1]])\nC = np.array([[1,0,1], #mendefinisikan matriks B 3x3\n              [0,1,1],\n              [1,1,1]])\n\n\nprint(A)\n\n[[1 2 3]\n [4 5 6]]\n\n\n\nprint(B)\n\n[[-1  0  1]\n [ 0  0  1]]\n\n\n\nprint(C)\n\n[[1 0 1]\n [0 1 1]\n [1 1 1]]\n\n\n\nprint(A[0]) #menampilkan baris pertama (indeks 0) dari matriks A\n\n[1 2 3]\n\n\n\n#menampilkan baris pertama (indeks 0), kolom kedua (indeks 1) dari matriks A\nprint(A[0, 1])\n\n2\n\n\n\n# tampilkan baris pertama (indeks 0),\n# mulai dari kolom kedua (indeks 1) dan seterusnya\nprint(A[0, 1:])\n\n[2 3]\n\n\n\n# tampilkan baris pertama (indeks 0),\n# tampilkan semua kolom sampai sebelum kolom ketiga (sebelum indeks 2)\nprint(A[0, :2])\n\n[1 2]\n\n\n\n# tampilkan nilai pada semua baris,\n# tapi melihat kolom kedua (indeks 1) saja\nprint(A[:, 1])\n\n[2 5]\n\n\n\n# tampilkan semua baris,\n# mulai dari kolom kedua (indeks 1) dan seterusnya\nprint(A[:, 1:])\n\n[[2 3]\n [5 6]]\n\n\n\n# tampilkan baris pertama (indeks nol),\n# tapi kolom pertama dari belakang (hitung mundur)\nprint(A[0, -1])\n\n3\n\n\n\n# tampilkan baris pertama dari belakang,\n# kolom pertama dari belakang\nprint(A[-1, -1])\n\n6\n\n\nOperasi dasar seperti penjumlahan dan pengurangan dapat dilakukan secara langsung seperti halnya penjumlahan/pengurangan bilangan.\n\nprint(A+B)\nprint(A-B)\n\n[[0 2 4]\n [4 5 7]]\n[[2 2 2]\n [4 5 5]]\n\n\nOperasi perkalian skalar dapat menggunakan tanda bintang atau asterisk (*), dan urutannya boleh ditukar.\n\nprint(3*A) # 3 dikali A\nprint(B*4) # B dikali 4\n\n[[ 3  6  9]\n [12 15 18]]\n[[-4  0  4]\n [ 0  0  4]]\n\n\nApabila dua matriks dikalikan begitu saja dengan tanda bintang, maka perkalian akan dilakukan secara broadcasting, yaitu per elemen.\n\nprint(A)\nprint(B)\nprint(A*B)\n\n[[1 2 3]\n [4 5 6]]\n[[-1  0  1]\n [ 0  0  1]]\n[[-1  0  3]\n [ 0  0  6]]\n\n\nPerkalian matriks yang biasa kita kenal di aljabar linier tidak seperti itu. Numpy menyediakan fungsi khusus untuk perkalian matriks yang seperti di aljabar linier, yaitu np.matmul (matrix multiplication). Tentu saja, ada syarat ukuran matriks, yaitu \\(m \\times n\\) dan \\(n \\times p\\).\nKode berikut ini akan gagal karena tidak memenuhi syarat.\n\nnp.matmul(A,B)\n\nValueError: ignored\n\n\nPerkalian A dengan B tidak dapat dilakukan dan muncul error message. Cek ukuran dari matriks dengan menggunakan np.shape.\n\nprint(np.shape(A)) #Ukuran matriks A\nprint(np.shape(B)) #Ukuran matriks B\nprint(np.shape(C)) #Ukuran matriks C\n\n(2, 3)\n(2, 3)\n(3, 3)\n\n\nBaik A dan B memiliki ukuran 2x3, sehingga AB tidak terdefinisi. Namun, apabila kita men-transpose B, kita dapat melakukan perkalian \\(AB^T\\). Untuk mentranspose matriks, gunakan np.transpose\n\nnp.matmul(A, np.transpose(B)) #A B^T\n\narray([[2, 3],\n       [2, 6]])\n\n\nSebagai tambahan, numpy juga bisa menghitung dot product (perkalian dot, yaitu hasil kali titik) antara dua array satu dimensi, menggunakan np.dot\n\nvektor1 = np.array([1, -5, 0])\nvektor2 = np.array([-3, 7, 10])\nprint(np.dot(vektor1, vektor2))\n\n-38\n\n\nSeandainya kita menggunakan np.dot dengan dua matriks, maka numpy akan mengartikannya sebagai np.matmul\n\nnp.dot(A, np.transpose(B)) #A B^T\n\narray([[2, 3],\n       [2, 6]])\n\n\nSelebihnya bisa dibaca di dokumentasi numpy:\nhttps://numpy.org/doc/stable/reference/generated/numpy.dot.html\nTerakhir, numpy memiliki beberapa fungsi khusus lainnya untuk aljabar linier, yang menariknya mengharuskan penulisan “linalg” (linear algebra; aljabar linier), karena memang merupakan bagian khusus di dalam numpy. Contohnya adalah determinan dan invers.\n\nD = np.array([[2, -3], [-2, 5]])\n\nprint(D)\nprint(np.linalg.det(D)) # det(D), yaitu determinan dari matriks D\nprint(np.linalg.inv(D)) # D^-1, yaitu invers dari matriks D\n\nprint(np.linalg.det(np.linalg.inv(D))) # det(D^-1)\n\n[[ 2 -3]\n [-2  5]]\n4.0\n[[1.25 0.75]\n [0.5  0.5 ]]\n0.24999999999999994\n\n\nJangan lupa, apabila ada hasil yang sedikit aneh, seperti 1/4 = 0.2499999…, itu disebabkan oleh kelemahan floating-point precision yang dibahas di pertemuan pertama kuliah Metode Numerik. Python tidak kebal terhadap masalah tersebut.\nSelain itu, apabila keseluruhan matriks berisi bilangan bulat, bisa saja dilakukan integer division, di mana semua hasil pembagian itu dibulatkan ke bawah. Hal ini tentu sangat berbahaya jika ada operasi pembagian dalam metode numerik. Untuk menghindari masalah tersebut, array bisa dikonversi menjadi float semua, menggunakan .astype(float)\n\n# berisi bilangan bulat semua\narraybulat = np.array([5, 4])\nprint(arraybulat)\n\n# arraybulat[0] = 5//4 = floor(5/4) = floor(1.25) = 1\narraybulat[0] = arraybulat[0]/arraybulat[1]\nprint(arraybulat)\n\n[5 4]\n[1 4]\n\n\n\narraybulat = np.array([5, 4])\narrayfloat = arraybulat.astype(float)\nprint(arrayfloat)\n\n# mencoba hal yang sama,\n# kali ini tidak ada integer division sehingga 5/4 = 1.25\narrayfloat[0] = arrayfloat[0]/arrayfloat[1]\nprint(arrayfloat)\n\n[5. 4.]\n[1.25 4.  ]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul5.html#review-spl-sistem-persamaan-linier-penjelasan-tanpa-kode",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul5.html#review-spl-sistem-persamaan-linier-penjelasan-tanpa-kode",
    "title": "Modul 5: Metode Langsung untuk SPL",
    "section": "2. Review SPL: sistem persamaan linier (penjelasan tanpa kode)",
    "text": "2. Review SPL: sistem persamaan linier (penjelasan tanpa kode)\nSuatu sistem persamaan linier (SPL) adalah kumpulan beberapa persamaan linier dalam beberapa variabel \\(x_1, x_2, \\dots, x_n\\), misal sebanyak \\(m\\) persamaan. Idealnya, banyaknya variabel sama dengan banyaknya persamaan, yaitu \\(n=m\\). (Praktikum Metode Numerik akan membahas SPL dengan \\(n=m\\).)\nBentuk umum SPL bisa dituliskan sebagai berikut:\n\\[ \\begin{align}\na_{11} x_1 + a_{12} x_2 + &\\dots + a_{1n} x_n = b_1 \\\\\na_{21} x_1 + a_{22} x_2 + &\\dots + a_{2n} x_n = b_2 \\\\\na_{31} x_1 + a_{32} x_2 + &\\dots + a_{3n} x_n = b_3 \\\\\n&\\vdots \\\\\na_{m1} x_1 + a_{m2} x_2 + &\\dots + a_{mn} x_n = b_m\n\\end{align} \\]\ndi mana koefisien \\(a_{ij}\\) adalah koefisien pada persamaan ke-i untuk variabel \\(x_j\\), dan ada konstanta \\(b_i\\) untuk tiap persamaan \\(i = 1, 2, \\dots, m\\).\nUmumnya, semua koefisien \\(a_{ij}\\) serta konstanta \\(b_i\\) sudah diketahui nilainya, dan ingin dicari nilai-nilai \\(x_j\\) yang bersama memenuhi semua persamaan sekaligus, disebut solusi dari SPL tersebut.\nApabila \\(n=m\\), bentuk umum SPL menjadi\n\\[ \\begin{align}\na_{11} x_1 + a_{12} x_2 + &\\dots + a_{1n} x_n = b_1 \\\\\na_{21} x_1 + a_{22} x_2 + &\\dots + a_{2n} x_n = b_2 \\\\\na_{31} x_1 + a_{32} x_2 + &\\dots + a_{3n} x_n = b_3 \\\\\n&\\vdots \\\\\na_{n1} x_1 + a_{n2} x_2 + &\\dots + a_{nn} x_n = b_n\n\\end{align} \\]\nyang dapat dituliskan dalam bentuk perkalian matriks-vektor:\n\\[\n\\begin{pmatrix}\na_{11} & a_{12} & \\dots & a_{1n} \\\\\na_{21} & a_{22} & \\dots & a_{2n} \\\\\na_{31} & a_{32} & \\dots & a_{3n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{n1} & a_{n2} & \\dots & a_{nn} \\\\\n\\end{pmatrix}\n\\begin{pmatrix}\nx_1 \\\\ x_2 \\\\ x_3 \\\\ \\vdots \\\\ x_n\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nb_1 \\\\ b_2 \\\\ b_3 \\\\ \\vdots \\\\ b_n\n\\end{pmatrix}\n\\]\nMatriks koefisien \\(a_{ij}\\) bisa ditulis \\(A\\), vektor kolom \\(x_j\\) bisa ditulis \\(\\textbf{x}\\), dan vektor kolom \\(b_i\\) bisa ditulis \\(\\textbf{b}\\), agar bentuk perkalian matriks-vektor di atas bisa diringkas: \\(A\\textbf{x}=\\textbf{b}\\). Dalam hal ini, \\(\\textbf{x}\\) adalah vektor solusi.\nDengan demikian, notasi \\(a_{ij}\\) bisa juga diartikan sebagai elemen matriks \\(A\\) pada baris ke-i, kolom ke-j.\nKita bisa “menggabungkan” vektor \\(\\textbf{b}\\) menjadi kolom baru (kolom paling kanan) di matriks \\(A\\), sehingga dari yang tadinya berukuran \\(n \\times n\\) menjadi berukuran \\(n \\times \\left(n+1\\right)\\):\n\\[\n\\begin{pmatrix}\na_{11} & a_{12} & \\dots & a_{1n} & b_1 \\\\\na_{21} & a_{22} & \\dots & a_{2n} & b_2 \\\\\na_{31} & a_{32} & \\dots & a_{3n} & b_3 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots & \\vdots\\\\\na_{n1} & a_{n2} & \\dots & a_{nn} & b_n\n\\end{pmatrix}\n\\]\nMatriks baru ini biasa disebut augmented matrix atau matriks diperbesar, dan biasa ditulis \\(\\tilde{A}\\).\nKita juga bisa menuliskan \\(a_{i,\\left(n+1\\right)} = b_i\\) untuk \\(i = 1, 2, \\dots, n\\), agar konsisten dengan notasi \\(a_{ij}\\) yaitu elemen matriks pada baris ke-i, kolom ke-j.\n\\[\n\\tilde{A} = \\begin{pmatrix}\na_{11} & a_{12} & \\dots & a_{1n} & a_{1,\\left(n+1\\right)} \\\\\na_{21} & a_{22} & \\dots & a_{2n} & a_{2,\\left(n+1\\right)} \\\\\na_{31} & a_{32} & \\dots & a_{3n} & a_{3,\\left(n+1\\right)} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots & \\vdots\\\\\na_{n1} & a_{n2} & \\dots & a_{nn} & a_{n,\\left(n+1\\right)}\n\\end{pmatrix}\n\\]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul5.html#memperoleh-matriks-diperbesar-dari-atextbfxtextbfb-dan-sebaliknya",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul5.html#memperoleh-matriks-diperbesar-dari-atextbfxtextbfb-dan-sebaliknya",
    "title": "Modul 5: Metode Langsung untuk SPL",
    "section": "3. Memperoleh matriks diperbesar dari \\(A\\textbf{x}=\\textbf{b}\\), dan sebaliknya",
    "text": "3. Memperoleh matriks diperbesar dari \\(A\\textbf{x}=\\textbf{b}\\), dan sebaliknya\nMisalkan kita punya SPL seperti berikut:\n\\[ \\begin{array}{rcrcrcrc}\nx_1 & - &  x_2   & + &  2x_3 & - &  x_4 & = & -8 \\\\\n2x_1 & - & 2x_2   & + &  3x_3 & - & 3x_4 & = & -20 \\\\\nx_1 & + &  x_2   & + &   x_3 &   &      & = & -2 \\\\\nx_1 & - &  x_2   & + &  4x_3 & + & 3x_4 & = &  4\n\\end{array} \\]\nMatriks koefisien \\(A\\) dan vektor \\(\\textbf{b}\\) dari SPL di atas adalah\n\\[ A = \\begin{pmatrix}\n1 & -1 & 2 & -1 \\\\\n2 & -2 & 3 & -3 \\\\\n1 & 1 & 1 & 0 \\\\\n1 & -1 & 4 & 3\n\\end{pmatrix}, \\hspace{0.5cm} \\textbf{b} = \\begin{pmatrix}\n-8 \\\\ -20 \\\\ -2 \\\\ 4\n\\end{pmatrix}\\]\nSehingga, matriks diperbesar \\(\\tilde{A}\\) dari SPL di atas adalah\n\\[ \\tilde{A} = \\begin{pmatrix}\n1 & -1 & 2 & -1 & -8 \\\\\n2 & -2 & 3 & -3 & -20 \\\\\n1 & 1 & 1 & 0 & -2 \\\\\n1 & -1 & 4 & 3 & 4\n\\end{pmatrix} \\]\nApabila kita hanya memiliki matriks koefisien \\(A\\) dan vektor \\(\\textbf{b}\\), kita bisa saja memperoleh matriks diperbesar \\(\\tilde{A}\\) menggunakan numpy:\n\n# [[1,-1,2,-1, -8],[2,-2,3,-3,-20],[1,1,1,0,-2], [1,-1,4,3,4]]\n\nA_koef = np.array([\n    [1,-1,2,-1],\n    [2,-2,3,-3],\n    [1,1,1,0],\n    [1,-1,4,3]\n])\n\n# buat vektor baris dua dimensi, lalu transpos\n# karena diperlukan vektor kolom dua dimensi\nb = np.transpose(np.array([[-8,-20,-2,4]]))\n\n# matriks diperbesar diperoleh dengan meletakan vektor b \"di sebelah kanan\" A,\n# atau sama saja \"ditumpuk\" secara horizontal, bisa dengan numpy.hstack\nA_diperbesar = np.hstack((A_koef, b))\n\nprint(A_diperbesar)\n\n[[  1  -1   2  -1  -8]\n [  2  -2   3  -3 -20]\n [  1   1   1   0  -2]\n [  1  -1   4   3   4]]\n\n\nTentunya, kita juga bisa memperoleh matriks koefisien \\(A\\) dan vektor \\(\\textbf{b}\\) secara pemrograman apabila hanya diketahui matriks diperbesar \\(\\tilde{A}\\).\n\nA_diperbesar = np.array([\n    [1,-1,2,-1,-8],\n    [2,-2,3,-3,-20],\n    [1,1,1,0,-2],\n    [1,-1,4,3,4]\n])\n\n# n adalah banyaknya baris\nn = np.shape(A_diperbesar)[0]\n\n# gunakan nilai-nilai di semua baris sampai kolom ke-n untuk matriks koefisien\nA_koef = A_diperbesar[:, :n]\n\n# untuk vektor b, peroleh nilai pada kolom terakhir\nb = A_diperbesar[:, n]\n\nprint(\"Matriks koefisien A:\")\nprint(A_koef)\nprint(\"Vektor b:\")\nprint(b)\n\nMatriks koefisien A:\n[[ 1 -1  2 -1]\n [ 2 -2  3 -3]\n [ 1  1  1  0]\n [ 1 -1  4  3]]\nVektor b:\n[ -8 -20  -2   4]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul5.html#eliminasi-gauss-dan-substitusi-balik",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul5.html#eliminasi-gauss-dan-substitusi-balik",
    "title": "Modul 5: Metode Langsung untuk SPL",
    "section": "4. Eliminasi Gauss dan substitusi balik",
    "text": "4. Eliminasi Gauss dan substitusi balik\nSeperti yang sudah dipelajari di aljabar linier, eliminasi Gauss adalah teknik menyelesaikan (SPL) dengan menerapkan operasi baris elementer (OBE) pada matriks diperbesarnya. OBE adalah beberapa operasi khusus bisa yang dilakukan pada satu/dua baris dalam suatu matriks diperbesar (misal baris \\(E_i\\) dan \\(E_j\\)), dengan sifat istimewa yaitu tidak akan mengubah nilai solusi SPL \\(x_1, x_2, \\dots, x_n\\) sama sekali. OBE bisa berupa:\n\nPertukaran baris: \\((E_i) \\leftrightarrow (E_j)\\)\nPerkalian baris oleh skalar: \\((\\lambda E_i) \\rightarrow (E_i)\\)\nPenjumlahan suatu baris dengan kelipatan skalar dari baris lain \\(( E_i + \\lambda E_j ) \\rightarrow (E_i)\\)\n\n(“E” adalah singkatan dari equation.)\nMisalkan terdapat SPL yang dinyatakan dalam bentuk \\(Ax = b\\), di mana A adalah matriks berukuran \\(n \\times n\\) dan \\(\\textbf{b}\\) adalah vektor berukuran \\(n \\times 1\\). Eliminasi Gauss bertujuan untuk mengubah SPL awal menjadi bentuk triangular:\n\\[ \\begin{align}\na_{11} x_1 + a_{12} x_2 + \\dots + a_{1n}x_n &= a_{1,n+1} \\\\\na_{22} x_2 + \\dots + a_{2n}x_n &= a_{2,n+1} \\\\\n\\vdots \\\\\na_{nn}x_n &= a_{n,n+1}\n\\end{align} \\]\nSebenarnya, semua koefisien yang terlihat “hilang” itu masih ada, hanya saja sudah berhasil diubah menjadi nol.\nKemudian, untuk mencari nilai \\(x_1, x_2, \\dots, x_n\\) dari bentuk triangular tersebut, lakukan substitusi balik (back substitution). Dari persamaan terakhir diperoleh\n\\[x_n = \\frac{a_{n,n+1}}{a_{nn}}\\]\nSubstitusi \\(x_n\\) ke persamaan ke-(n-1) diperoleh \\(x_{n-1}\\). Substitusi \\(x_n\\) dari \\(x_{n-1}\\) ke persamaan ke-(n-2) diperoleh \\(x_{n-2}\\). Lakukan terus sampai mendapatkan \\(x_1\\).\nUntuk menyelesaikan SPL menggunakan eliminasi Gauss dan substitusi balik (Gaussian elimination with backward substitution), SPL dapat ditulis sebagai matriks diperbesar. Kemudian, lakukan langkah-langkah berikut.\n\nBuat semua entri di bawah \\(a_{ii}\\) (untuk setiap kolom \\(i = 1, 2, \\dots, n\\)) menjadi nol dengan melakukan operasi baris elementer: \\[\\left( E_j - \\left( \\frac{a_{ji}}{a_{ii}} \\right)E_i \\right) \\rightarrow E_j\\] untuk baris ke-j, dengan \\(j = i+1, i+2, \\dots, n\\). Namun, kita bisa menuliskan \\(m = \\frac{a_{ji}}{a_{ii}}\\) (m: multiplier; pengkali) agar bentuknya menjadi \\[\\left( E_j - mE_i \\right) \\rightarrow E_j\\] atau sama saja \\[E_j \\leftarrow \\left( E_j - mE_i \\right)\\]\nLakukan substitusi balik, diawali rumus: \\[x_n = \\frac{a_{n,n+1}}{a_{nn}}\\] Kemudian, menghitung mundur, untuk \\(i = n-1, n-2, \\dots, 2, 1\\), hitung: \\[x_i = \\frac{a_{i,n+1} - \\sum_{j=i+1}^{n}a_{ij}x_j}{a_{ii}}\\] Fun fact: rumus itu diperoleh dengan melakukan pindah ruas pada persamaan di bentuk triangularnya, seperti berikut: \\[a_{ii}x_{ii} + a_{i,i+1}x_{i,i+1} + a_{i,i+2}x_{i,i+2} + \\dots + a_{in}x_{in} = b_i = a_{i,n+1}\\] \\[a_{ii}x_{ii} + \\sum_{j=i+1}^{n}a_{ij}x_j = a_{i,n+1}\\] \\[a_{ii}x_{ii} = a_{i,n+1} - \\sum_{j=i+1}^{n}a_{ij}x_j\\] \\[x_i = \\frac{a_{i,n+1} - \\sum_{j=i+1}^{n}a_{ij}x_j}{a_{ii}}\\]\n\nNamun, ketika melakukan eliminasi Gauss, apabila ada elemen diagonal \\(a_{ii}\\) yang bernilai nol, maka baris yang mengandung \\(a_{ii}\\) perlu ditukar dengan baris di bawahnya yang elemennya taknol pada kolom yamg sama (kolom ke-i), agar elemen diagonal yang baru menjadi taknol.\nImplementasi Eliminasi Gauss dan Substitusi Balik\n\ndef EliminasiGauss(matriks_input):\n    # konversi matriks_input jadi matriks baru yang isinya float semua,\n    # karena apabila ada bilangan bulat, bisa jadi dilakukan integer division\n    # yang bisa sangat memperparah error\n    matriks = matriks_input.astype(float)\n\n    # memperoleh ukuran baris dari matriks diperbesar\n    n = np.shape(matriks)[0]\n    # Ingat bahwa ukuran matriks diperbesar adalah n x (n+1)\n\n    for i in range (n): # untuk kolom ke-i (dari kolom awal sampai ke-n)\n        # Saat ini, kita sedang melakukan eliminasi Gauss untuk kolom ke-i.\n        # Semua nilai koefisien di bawah elemen diagonal akan dibuat nol\n\n        # Sebelum mengeliminasi, kita perlu memastikan elemen diagonal taknol.\n        # Kalau misalnya nol, kita perlu melihat baris-baris berikutnya\n        # untuk bertukar baris agar elemen diagonal menjadi taknol\n\n        # Variabel p (\"pivot\") akan digunakan untuk melihat baris.\n        # Kita lihat dulu baris ke-i\n        p = i\n        # sehingga, saat ini, matriks[p,i] adalah elemen diagonal.\n        # Ingat, elemen diagonal harusnya taknol.\n\n        # Kalau ternyata nilai elemen tersebut adalah nol,\n        # lanjut melihat di bawahnya (mencari calon baris yang bisa ditukar),\n        # dan kalau masih nol, lihat ke bawahnya lagi, dan seterusnya\n        while p&lt;n and matriks[p,i]==0:\n            p += 1\n        # tapi jangan sampai keluar dari matriks (melewati baris terakhir),\n        # makanya dibuat syarat p&lt;n\n        \n        # Kalau sudah keluar dari matriks, artinya semua elemen di bawah\n        # diagonal, bahkan termasuk elemen diagonal, itu nol semua.\n        # Sayangnya, SPL tidak bisa diselesaikan\n        if p == n:\n            return \"SPL tidak memiliki solusi unik.\"\n        # Namun, kalau bisa diselesaikan, lanjut...\n        else:\n            # Tadinya, p melihat baris ke-i.\n            # Kalau p sudah pindah ke bawahnya (sudah tidak sama dengan i),\n            # artinya elemen diagonal saat ini bernilai nol, dan perlu ditukar \n            # dengan baris di bawahnya yang nilainya taknol (yaitu yang sedang\n            # ditunjuk oleh indeks p). Maka tukarlah\n            if p != i:\n                matriks[[p,i], :] = matriks[[i,p], :]\n                # syntax khusus numpy untuk menukar baris ke-i dan\n                # baris ke-p, di mana semua nilai per kolom masih sama,\n                # maksudnya tidak ada kolom yang ditukar, sehingga ditulis :\n            \n            # Ada pertukaran maupun tidak, yang pasti, sekarang elemen diagonal\n            # sudah aman, sudah pasti taknol. Mari lanjut ke proses eliminasi.\n            # Lakukan untuk tiap baris ke-j, yaitu untuk semua baris di bawah\n            # elemen diagonal.\n            for j in range (i+1, n):\n                # Melakukan proses eliminasi dengan OBE (sesuai rumus di atas)\n                m = matriks[j,i]/matriks[i,i] # m: \"multiplier\" atau pengkali\n                matriks[j] = matriks[j] - m * matriks[i]\n                #   (E_j) &lt;- (   E_j    - m *    E_i   )\n    \n    # Setelah semua itu dilakukan untuk tiap kolom, eliminasi Gauss selesai\n    return matriks\n\n\ndef SubstitusiBalik(matriks_input):\n    # jaga-jaga\n    matriks = matriks_input.astype(float)\n\n    # memperoleh ukuran baris dari matriks diperbesar\n    n = np.shape(matriks)[0]\n\n    # vektor solusi, sementara isi dengan nol dulu\n    solution = np.zeros(n)\n\n    # lakukan dulu yang paling mudah, yaitu untuk baris paling bawah\n    solution[n-1] = matriks[n-1, n]/matriks[n-1, n-1]\n\n    # untuk baris-baris di atasnya, kita lakukan for loop, menghitung mundur,\n    # terapkan rumus substitusi balik\n    for i in range (n-2, -1, -1):\n        # hitung sumasi, simpan langsung ke matriks[i,n]\n        # agar langsung dijumlahkan ke b_i yaitu a_{i,n+1}\n        for j in range(i+1, n):\n            matriks[i,n] = matriks[i,n] - matriks[i,j] * solution[j]\n        # peroleh solusi menggunakan rumus (dan memanfaatkan hasil sumasi)\n        solution[i] = matriks[i,n]/matriks[i,i]\n    return solution\n\n\naug_matriks = np.array(eval(input('Masukkan matriks diperbesar dari SPL yang akan diselesaikan: ')))\n# mengubah input Anda ke dalam array numpy (matriks)\nprint(\"Berikut matriks yang dimasukkan:\")\nprint(aug_matriks)\n\ntriangular_form = EliminasiGauss(aug_matriks)\nif type(triangular_form) == type(\"\"):\n    # kalau output berupa string, artinya SPL tidak bisa diselesaikan\n    print(triangular_form)\nelse:\n    # Namun, kalau eliminasi Gauss berhasil, lanjut ke substitusi balik\n    solution = SubstitusiBalik(triangular_form)\n    print('Solusi dari SPL tersebut adalah: ')\n    for i in range(len(solution)):\n        print('x{0} = {1}'.format(i+1, solution[i]))\n\nMasukkan matriks diperbesar dari SPL yang akan diselesaikan: [[1,-1,2,-1, -8],[2,-2,3,-3,-20],[1,1,1,0,-2], [1,-1,4,3,4]]\nBerikut matriks yang dimasukkan:\n[[  1  -1   2  -1  -8]\n [  2  -2   3  -3 -20]\n [  1   1   1   0  -2]\n [  1  -1   4   3   4]]\nSolusi dari SPL tersebut adalah: \nx1 = -7.0\nx2 = 3.0\nx3 = 2.0\nx4 = 2.0\n\n\nContoh penggunaan langsung (tanpa perlu menerima input):\n\nmatriks_diperbesar = np.array([\n    [0.003, 59.14, 59.17],\n    [5.291, -6.13, 46.78]\n])\n\n# langsung print vektor solusi\nprint(SubstitusiBalik(EliminasiGauss(matriks_diperbesar)))\n\n[10.  1.]\n\n\n\nmatriks_diperbesar = np.array([\n    [4.0, -1, 0, -1, 0, 0, 0, 0, 0, 25],\n    [-1, 4, -1, 0, -1, 0, 0, 0, 0, 50],\n    [0, -1, 4, 0, 0, -1, 0, 0, 0, 150],\n    [-1, 0, 0, 4, -1, 0, -1, 0, 0, 0],\n    [0, -1, 0, -1, 4, -1, 0, -1, 0, 0],\n    [0, 0, -1, 0, -1, 4, 0, 0, -1, 50],\n    [0, 0, 0, -1, 0, 0, 4, -1, 0, 0],\n    [0, 0, 0, 0, -1, 0, -1, 4, -1, 0],\n    [0, 0, 0, 0, 0, -1, 0, -1, 4, 25]\n])\nprint(matriks_diperbesar)\n\n# langsung print vektor solusi\nprint(SubstitusiBalik(EliminasiGauss(matriks_diperbesar)))\n\n[[  4.  -1.   0.  -1.   0.   0.   0.   0.   0.  25.]\n [ -1.   4.  -1.   0.  -1.   0.   0.   0.   0.  50.]\n [  0.  -1.   4.   0.   0.  -1.   0.   0.   0. 150.]\n [ -1.   0.   0.   4.  -1.   0.  -1.   0.   0.   0.]\n [  0.  -1.   0.  -1.   4.  -1.   0.  -1.   0.   0.]\n [  0.   0.  -1.   0.  -1.   4.   0.   0.  -1.  50.]\n [  0.   0.   0.  -1.   0.   0.   4.  -1.   0.   0.]\n [  0.   0.   0.   0.  -1.   0.  -1.   4.  -1.   0.]\n [  0.   0.   0.   0.   0.  -1.   0.  -1.   4.  25.]]\n[18.75 37.5  56.25 12.5  25.   37.5   6.25 12.5  18.75]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul5.html#partial-pivoting",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul5.html#partial-pivoting",
    "title": "Modul 5: Metode Langsung untuk SPL",
    "section": "5. Partial Pivoting",
    "text": "5. Partial Pivoting\nPada eliminasi Gauss, pertukaran baris perlu dilakukan ketika elemen diagonal bernilai nol. Namun, kalaupun tidak ada yang tepat bernilai nol, masalah round-off error bisa saja menyebabkan hasil komputasi meleset jauh ketika elemen diagonal bernilai sangat kecil mendekati nol (yang kemudian digunakan sebagai pembagi dalam eliminasi Gauss). Penyebabnya, pembagian oleh bilangan yang sangat kecil bisa sangat sensitif. Contohnya, \\(\\frac{10}{0.00025} = 40000\\), sedangkan \\(\\frac{10}{0.00020} = 50000\\). Dengan begitu, apabila nilai diagonal yang sangat kecil itu salah sedikit (karena masalah floating-point precision atau sejenisnya), hasil akhir nantinya bisa menjadi sangat meleset.\nSolusi yang paling sederhana adalah memodifikasi elminasi Gauss, yaitu agar selalu menukarkan elemen diagonal \\(a_{ii}\\) dengan elemen terbesar di kolom ke-\\(i\\) yang ada di bawahnya (tentu saja, keseluruhan baris ikut ditukar, bukan hanya dua nilai). Solusi ini disebut partial pivoting, dan apapun modifikasi pada eliminasi Gauss untuk menghindari masalah di atas disebut strategi pivoting.\nDalam menerapkan strategi pivoting, algoritma substitusi balik tetap sama persis, karena hanya algoritma eliminasi Gauss yang dimodifikasi.\nargmax dan argmin\nSebelum membahas strategi pivoting, mari kita bahas argmax dan argmin. Kedua fungsi ini tersedia dari numpy. Perbedaannya dengan max dan min cukup sederhana: max dan min mengembalikan nilainya, sedangkan argmax dan argmin mengembalikan indeksnya.\n\narraykecil = np.array([17, 8, 27, 54, 34])\n\nnilai_max = np.max(arraykecil)\nnilai_argmax = np.argmax(arraykecil)\n\nprint(f\"Nilai maksimum ada pada indeks {nilai_argmax}, yaitu {nilai_max}\")\n\nnilai_min = np.min(arraykecil)\nnilai_argmin = np.argmin(arraykecil)\n\nprint(f\"Nilai minimum ada pada indeks {nilai_argmin}, yaitu {nilai_min}\")\n\nNilai maksimum ada pada indeks 3, yaitu 54\nNilai minimum ada pada indeks 1, yaitu 8\n\n\nDengan demikian, apapun konteksnya, apabila kita memerlukan indeks letaknya saja, kita bisa langsung menggunakan argmax atau argmin.\nFun fact: baik argmax maupun argmin dikenal dalam matematika, dalam pembahasan teoritis juga. Contohnya, jika \\(f(x) = 2-x^2\\),\n\\[\\underset{x\\in\\mathbb{N}}{\\arg\\max} f(x) = 1\\]\nkarena bilangan asli \\(x\\) yang membuat nilai \\(f(x)\\) paling besar (di antara semua pilihan bilangan asli lainnya) adalah \\(x=1\\).\nPartial Pivoting\nUntuk eliminasi Gauss, daripada memeriksa apakah elemen diagonal bernilai nol atau tidak, selalu pilihlah indeks \\(p \\ge k\\) terkecil* sedemikian sehingga,\n\\[|a_{pk}^{(k)}| = \\max_{k \\le i \\le n}|a_{ik}^{(k)}|\\]\ndi mana \\(k\\) adalah indeks untuk baris/kolom dari elemen diagonal yang sedang diurus (\\(a_{kk}\\)).\n*apabila ada lebih dari satu baris yang sama-sama memuat nilai terbesar, pilih saja yang pertama kali ditemukan\nIntinya, kita mencari indeks \\(p\\) untuk baris yang memuat elemen maksimum (dari semua elemen di bawah elemen diagonal), agar baris tersebut bisa ditukar dengan baris ke-\\(k\\) yang memuat elemen diagonal yang sedang diurus.\n(“Perpangkatan” dengan \\((k)\\) itu sebenarnya hanya menandakan bahwa, pada saat itu, kita sedang mengurus elemen diagonal pada baris/kolom ke-\\(k\\). Penulisan seperti itu cukup untuk pembahasan teoritis saja. Tujuannya hanya untuk menekankan bahwa, setelah tiap OBE, nilai koefisien bisa jadi berbeda, sehingga harus diberi label tambahan seperti itu untuk memperjelas, nilai koefisien pada tahapan mana yang dimaksud.)\nSetelah indeks \\(p\\) diperoleh, barulah lakukan pertukaran baris \\((E_k) \\leftrightarrow (E_p)\\)\nImplementasi Partial Pivoting\n\ndef PartialPivoting(matriks_input):\n    # konversi matriks_input jadi matriks baru yang isinya float semua,\n    # karena apabila ada bilangan bulat, bisa jadi dilakukan integer division\n    # yang bisa sangat memperparah error\n    matriks = matriks_input.astype(float)\n\n    # n adalah banyaknya baris dari matriks diperbesar\n    n = np.shape(matriks)[0]\n\n    # untuk tiap kolom ke-i kecuali dua kolom terakhir\n    for i in range(n-1):\n        # Kumpulkan semua nilai yang ada di bawah elemen diagonal (pivot)\n        below_pivot = abs(matriks[i:,i])\n        # yaitu semua elemen pada baris di bawah elemen diagonal,\n        # tetapi pada kolom yang sama.\n        # Dibuat nilai mutlak karena yang diperhatikan hanya besarnya,\n        # apakah dekat dengan nol atau tidak, bukan positif/negatifnya\n\n        # Memilih indeks baris yang memuat elemen maksimum, sebagai \"pivot\" baru\n        pivot_row = np.argmax(below_pivot)\n        # Nilai yang disimpan itu sebenarnya adalah indeks \"pergeseran\" ke bawah\n        # Misalnya, apabila variabel pivot_row bernilai 2, artinya baris yang\n        # dipilih ada pada indeks (i+2), atau secara umum ditulis pivot_row+i\n\n        # jika nilai pada baris yang akan di-pivot itu juga nol (padahal sudah\n        # maksimum), maka sebenarnya semua nilai yang bisa ditukar itu nol semua\n        # sehingga SPL tidak mungkin bisa diselesaikan\n        if matriks[i,pivot_row+i] == 0:\n            return \"Tidak ada solusi unik\"\n        else:\n            # Apabila taknol, lakukan pertukaran baris\n            matriks[[pivot_row+i,i], :]= matriks[[i,pivot_row+i], :]\n\n        # melanjutkan eliminasi Gauss seperti biasa\n        for j in range(i+1,n):\n            m = matriks[j,i]/matriks[i,i]\n            matriks[j] = matriks[j]-m*matriks[i]\n    \n    return matriks\n\n\nmatriks = np.array(eval(input('Masukkan matriks yang akan dipivotkan: ')))\n\ntriangular_form = PartialPivoting(matriks)\n\nprint(\"Triangular matriksnya adalah :\\n {0}\".format(triangular_form))\n\nMasukkan matriks yang akan dipivotkan: [[51, -18, 21, -96, -93], [84, -69, 69, 67, -6], [-42, 50, 14, -80, 51], [2, 8, 7, 3, 6]]\nTriangular matriksnya adalah :\n [[ 8.40000000e+01 -6.90000000e+01  6.90000000e+01  6.70000000e+01\n  -6.00000000e+00]\n [ 7.10542736e-15  2.38928571e+01 -2.08928571e+01 -1.36678571e+02\n  -8.93571429e+01]\n [-4.60949996e-15  0.00000000e+00  6.20538117e+01  4.21674141e+01\n   1.05968610e+02]\n [-1.84336495e-15  0.00000000e+00  0.00000000e+00  4.71963193e+01\n   1.86585489e+01]]\n\n\nContoh penggunaan langsung (tanpa perlu menerima input):\n\nmatriks_diperbesar = np.array([\n    [51, -18, 21, -96, -93],\n    [84, -69, 69, 67, -6],\n    [-42, 50, 14, -80, 51],\n    [2, 8, 7, 3, 6]\n])\nprint(matriks_diperbesar)\n\nmatriks_triangular = PartialPivoting(matriks_diperbesar)\nprint(matriks_triangular)\n\n# vektor solusi\nprint(SubstitusiBalik(matriks_triangular))\n\n[[ 51 -18  21 -96 -93]\n [ 84 -69  69  67  -6]\n [-42  50  14 -80  51]\n [  2   8   7   3   6]]\n[[ 8.40000000e+01 -6.90000000e+01  6.90000000e+01  6.70000000e+01\n  -6.00000000e+00]\n [ 7.10542736e-15  2.38928571e+01 -2.08928571e+01 -1.36678571e+02\n  -8.93571429e+01]\n [-4.60949996e-15  0.00000000e+00  6.20538117e+01  4.21674141e+01\n   1.05968610e+02]\n [-1.84336495e-15  0.00000000e+00  0.00000000e+00  4.71963193e+01\n   1.86585489e+01]]\n[-1.74956515 -0.22002462  1.4390443   0.39533907]\n\n\n\nmatriks_diperbesar = np.array([\n    [4.0, -1, 0, -1, 0, 0, 0, 0, 0, 25],\n    [-1, 4, -1, 0, -1, 0, 0, 0, 0, 50],\n    [0, -1, 4, 0, 0, -1, 0, 0, 0, 150],\n    [-1, 0, 0, 4, -1, 0, -1, 0, 0, 0],\n    [0, -1, 0, -1, 4, -1, 0, -1, 0, 0],\n    [0, 0, -1, 0, -1, 4, 0, 0, -1, 50],\n    [0, 0, 0, -1, 0, 0, 4, -1, 0, 0],\n    [0, 0, 0, 0, -1, 0, -1, 4, -1, 0],\n    [0, 0, 0, 0, 0, -1, 0, -1, 4, 25]\n])\nprint(matriks_diperbesar)\n\n# langsung print vektor solusi\nprint(SubstitusiBalik(PartialPivoting(matriks_diperbesar)))\n\n[[  4.  -1.   0.  -1.   0.   0.   0.   0.   0.  25.]\n [ -1.   4.  -1.   0.  -1.   0.   0.   0.   0.  50.]\n [  0.  -1.   4.   0.   0.  -1.   0.   0.   0. 150.]\n [ -1.   0.   0.   4.  -1.   0.  -1.   0.   0.   0.]\n [  0.  -1.   0.  -1.   4.  -1.   0.  -1.   0.   0.]\n [  0.   0.  -1.   0.  -1.   4.   0.   0.  -1.  50.]\n [  0.   0.   0.  -1.   0.   0.   4.  -1.   0.   0.]\n [  0.   0.   0.   0.  -1.   0.  -1.   4.  -1.   0.]\n [  0.   0.   0.   0.   0.  -1.   0.  -1.   4.  25.]]\n[18.75 37.5  56.25 12.5  25.   37.5   6.25 12.5  18.75]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul5.html#scaled-partial-pivoting",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul5.html#scaled-partial-pivoting",
    "title": "Modul 5: Metode Langsung untuk SPL",
    "section": "6. Scaled Partial Pivoting",
    "text": "6. Scaled Partial Pivoting\nSebelumnya, kita hanya mencari baris dengan nilai terbesar yang berada di bawah elemen diagonal, untuk menghindari kemungkinan elemen diagonal terlalu kecil. Namun, apabila elemen diagonal setelah pertukaran itu menjadi sangat besar, sama saja semua elemen lainnya menjadi relatif sangat kecil, sehingga bisa timbul masalah yang sama.\nOleh karena itu, ada baiknya kita memodifikasi (lagi) syarat pemilihan baris untuk ditukar dengan elemen diagonal, yaitu memilih semacam “pertengahan”, daripada sekedar memilih yang paling besar. Pada scaled partial pivoting, kita\nScaled Partial Pivoting\nDefinisikan\n\\[s_i = \\max_{k \\le i \\le n} |a_{ij}|\\]\nPilih \\(p \\le k\\) terkecil sedemikian sehingga\n\\[\\frac{|a_{pk}^{(k)}|}{s_k} = \\max_{k \\le i \\le n} \\frac{a_{ik}^{(k)}}{s_i}\\]\nKemudian, lakukan operasi \\(\\left( E_k \\right) \\leftrightarrow \\left( E_p \\right)\\)\nImplementasi Scaled Partial Pivoting\n\ndef ScaledPartialPivoting(matriks_input):\n    # konversi matriks_input jadi matriks baru yang isinya float semua,\n    # karena apabila ada bilangan bulat, bisa jadi dilakukan integer division\n    # yang bisa sangat memperparah error\n    matriks = matriks_input.astype(float)\n\n    # memperoleh banyaknya baris pada matriks\n    n = np.shape(matriks)[0]\n\n    # menentukan scalar tiap kolom dibandingan masing-masing baris yang paling besar\n    s = np.array([max(abs(matriks[i,:n])) for i in range(n)])\n\n    # Apabila ada scalar yang nol, semua nilai pada baris tersebut nol,\n    # sehingga SPL tidak bisa diselesaikan\n    if 0 in s:\n        return \"tidak ada solusi unik\"\n    # Kalau bisa diselesaikan, lanjut...\n    for i in range(n-1):\n        below_pivot = abs(matriks[i:,i])/s[i:]\n        pivot_row = np.argmax(below_pivot)\n        if matriks[i,pivot_row+i] == 0:\n            return \"Tidak ada solusi unik\"\n        else:\n            matriks[[pivot_row+i,i], :] = matriks[[i,pivot_row+i],  :]\n            s[pivot_row+i],s[i]=s[i],s[pivot_row+i]\n\n        # lanjut eleminasi Gauss\n        for j in range(i+1,n):\n            m = matriks[j,i]/matriks[i,i]\n            matriks[j] = matriks[j]-m*matriks[i]\n    return matriks\n\n\nmatriks = np.array(eval(input('Masukkan matriks yang akan dipivotkan: ')))\n\ntriangular_form = ScaledPartialPivoting(matriks)\n\nprint(\"Triangular matriksnya adalah :\\n {0}\".format(triangular_form))\n\nMasukkan matriks yang akan dipivotkan: [[51, -18, 21, -96, -93], [84, -69, 69, 67, -6], [-42, 50, 14, -80, 51], [2, 8, 7, 3, 6]]\nTriangular matriksnya adalah :\n [[ 8.40000000e+01 -6.90000000e+01  6.90000000e+01  6.70000000e+01\n  -6.00000000e+00]\n [ 0.00000000e+00  9.64285714e+00  5.35714286e+00  1.40476190e+00\n   6.14285714e+00]\n [ 0.00000000e+00  1.77635684e-15  3.98888889e+01 -4.87580247e+01\n   3.81259259e+01]\n [ 7.10542736e-15  1.52153128e-15  0.00000000e+00 -1.81922748e+02\n  -7.19211699e+01]]\n\n\nContoh penggunaan langsung (tanpa perlu menerima input):\n\nmatriks_diperbesar = np.array([\n    [51, -18, 21, -96, -93],\n    [84, -69, 69, 67, -6],\n    [-42, 50, 14, -80, 51],\n    [2, 8, 7, 3, 6]\n])\nprint(matriks_diperbesar)\n\nmatriks_triangular = ScaledPartialPivoting(matriks_diperbesar)\nprint(matriks_triangular)\n\n# vektor solusi\nprint(SubstitusiBalik(matriks_triangular))\n\n[[ 51 -18  21 -96 -93]\n [ 84 -69  69  67  -6]\n [-42  50  14 -80  51]\n [  2   8   7   3   6]]\n[[ 8.40000000e+01 -6.90000000e+01  6.90000000e+01  6.70000000e+01\n  -6.00000000e+00]\n [ 0.00000000e+00  9.64285714e+00  5.35714286e+00  1.40476190e+00\n   6.14285714e+00]\n [ 0.00000000e+00  1.77635684e-15  3.98888889e+01 -4.87580247e+01\n   3.81259259e+01]\n [ 7.10542736e-15  1.52153128e-15  0.00000000e+00 -1.81922748e+02\n  -7.19211699e+01]]\n[-1.74956515 -0.22002462  1.4390443   0.39533907]\n\n\n\nmatriks_diperbesar = np.array([\n    [4.0, -1, 0, -1, 0, 0, 0, 0, 0, 25],\n    [-1, 4, -1, 0, -1, 0, 0, 0, 0, 50],\n    [0, -1, 4, 0, 0, -1, 0, 0, 0, 150],\n    [-1, 0, 0, 4, -1, 0, -1, 0, 0, 0],\n    [0, -1, 0, -1, 4, -1, 0, -1, 0, 0],\n    [0, 0, -1, 0, -1, 4, 0, 0, -1, 50],\n    [0, 0, 0, -1, 0, 0, 4, -1, 0, 0],\n    [0, 0, 0, 0, -1, 0, -1, 4, -1, 0],\n    [0, 0, 0, 0, 0, -1, 0, -1, 4, 25]\n])\nprint(matriks_diperbesar)\n\n# langsung print vektor solusi\nprint(SubstitusiBalik(ScaledPartialPivoting(matriks_diperbesar)))\n\n[[  4.  -1.   0.  -1.   0.   0.   0.   0.   0.  25.]\n [ -1.   4.  -1.   0.  -1.   0.   0.   0.   0.  50.]\n [  0.  -1.   4.   0.   0.  -1.   0.   0.   0. 150.]\n [ -1.   0.   0.   4.  -1.   0.  -1.   0.   0.   0.]\n [  0.  -1.   0.  -1.   4.  -1.   0.  -1.   0.   0.]\n [  0.   0.  -1.   0.  -1.   4.   0.   0.  -1.  50.]\n [  0.   0.   0.  -1.   0.   0.   4.  -1.   0.   0.]\n [  0.   0.   0.   0.  -1.   0.  -1.   4.  -1.   0.]\n [  0.   0.   0.   0.   0.  -1.   0.  -1.   4.  25.]]\n[18.75 37.5  56.25 12.5  25.   37.5   6.25 12.5  18.75]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul5.html#materi-pengayaan-faktorisasi-lu",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul5.html#materi-pengayaan-faktorisasi-lu",
    "title": "Modul 5: Metode Langsung untuk SPL",
    "section": "7. (Materi pengayaan) Faktorisasi LU",
    "text": "7. (Materi pengayaan) Faktorisasi LU\nUntuk mengurangi banyaknya operasi pada penyelesaian SPL dengan matriks (serta untuk beberapa alasan lainnya), faktorisasi matriks seringkali dilakukan. Ada bermacam-macam faktorisasi matriks, namun yang paling umum digunakan adalah faktorisasi LU (juga disebut dekomposisi LU). Pada faktorisasi LU, matriks A ditulis ulang (difaktorisasi) sebagai perkalian (bukan penjumlahan) antara matriks segitiga bawah L (lower triangular) dan matriks segitiga atas U (upper triangular):\n\\[A = LU\\]\nAda tiga metode yang paing sering digunakan untuk faktorisasi LU, yaitu 1. Metode Doolittle 2. Metode Crout 3. Metode Cholesky\nPerbedaan di antara ketiga metode tersebut adalah pada bentuk matriks \\(L\\) dan \\(U\\) yang akan diperoleh, lebih tepatnya pada ketentuan untuk elemen diagonalnya akan seperti apa.\nPada bab 6.5 di buku Burden, dibahas metode Doolittle, di mana faktorisasi LU dilakukan dengan menggunakan eliminasi Gauss (sedangkan metode Cholesky dan metode Crout dibahas di bab 6.6, algoritma 6.6 dan 6.7). Berikut ini, kita hanya membahas metode Doolittle.\nJika eliminasi Gauss dapat dilakukan pada sistem \\(A\\overrightarrow{x}=\\overrightarrow{b}\\) tanpa melakukan pertukaran baris, maka \\(A=LU\\), di mana \\(m_{ji} = \\frac{a_{ji}^{(i)}}{a_{ii}^{(i)}}\\),\n\\(L = \\begin{bmatrix}\n1 & 0 & \\cdots & 0 \\\\\nm_{21} & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nm_{n1} & m_{n2} & \\cdots & 1\n\\end{bmatrix}\\)\n\\(U = \\begin{bmatrix}\na_{11}^{(1)} & a_{12}^{(1)} & \\cdots & a_{1n}^{(1)} \\\\\n0 & a_{22}^{(2)} & \\cdots & a_{2n}^{(2)} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & a_{nn}^{(n)}\n\\end{bmatrix}\\)\n(Fun fact: perhatikan bahwa, untuk metode Doolittle, semua elemen diagonal matriks \\(L\\) adalah 1, sedangkan elemen diagonal matriks \\(U\\) tidak harus satu. Untuk metode Crout, terbalik: semua elemen diagonal matriks \\(U\\) harus 1, sedangkan elemen diagonal matriks \\(L\\) boleh selain 1.)\nImplementasi Faktorisasi LU dengan Metode Doolittle\n\nimport numpy as np\nmatrix = np.array(eval(input('Masukkan matriks yang akan difaktorisasi: ')))\n\ndef LUFactorization(input_matrix):\n    matrix = input_matrix.astype(float)\n\n    n = np.shape(matrix)[0] #mengambil ukuran baris dari matriks\n    L = np.identity(n) #mendefinisikan L sebagai matriks identitas nxn\n    #operasi baris elementer\n    for i in range(n):\n        for j in range(i+1, n):\n            m = matrix[j,i]/matrix[i,i]\n            L[j,i] = m #Pasang elemen L_ji menjadi multiplisitas m = a_ji/a_ii\n            matrix[j]= matrix[j]-m*matrix[i]\n    return (L, matrix)\n\nL = LUFactorization(matrix)[0] #mengambil L pada LUFactorization\nU = LUFactorization(matrix)[1] #mengambil matrix pada LUFactorization\n\nprint(\"faktorisasi LU matriksnya adalah :\")\nprint(\"L = \\n{0}\".format(L)) #print L\n#print U\nprint(\"U = \\n{0}\".format(U))\n\nprint(\"Apabila dikalikan, hasilnya menjadi:\")\nLU = np.matmul(L,U) #Hasil perkalian L dan U\nprint(\"LU = \\n{0}\".format(LU))\n\nMasukkan matriks yang akan difaktorisasi: [[1,2,3],[4,5,6],[7,8,9]]\nfaktorisasi LU matriksnya adalah :\nL = \n[[1. 0. 0.]\n [4. 1. 0.]\n [7. 2. 1.]]\nU = \n[[ 1.  2.  3.]\n [ 0. -3. -6.]\n [ 0.  0.  0.]]\nApabila dikalikan, hasilnya menjadi:\nLU = \n[[1. 2. 3.]\n [4. 5. 6.]\n [7. 8. 9.]]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul1.html",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul1.html",
    "title": "Modul 1 Persamaan Diferensial Numerik: Pengenalan GNU Octave",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\nOctave adalah software dan bahasa pemrograman yang umum digunakan dalam analisis numerik. Syntax pada Octave kompatibel dengan MATLAB, bahkan script file dari Octave juga menggunakan ekstensi yang sama (.m). Pada praktikum ini, akan dijelaskan tentang penggunaan Octave dan pengaplikasiannya dalam Persamaan Diferensial Numerik.\nPastikan Octave telah terinstal pada computer kalian. Kalian dapat mengunduh Octave di https://www.gnu.org/software/octave/download\nAlternatif untuk macOS: https://octave-app.org/"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul1.html#operasi-variabel-matriks",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul1.html#operasi-variabel-matriks",
    "title": "Modul 1 Persamaan Diferensial Numerik: Pengenalan GNU Octave",
    "section": "Operasi, Variabel, Matriks",
    "text": "Operasi, Variabel, Matriks\nSetelah terinstal, akan ada dua jenis launcher, yaitu “Octave (GUI)” dan “Octave (CLI)”. Jalankan “Octave (GUI)”, lalu akan muncul jendela seperti ini:\n\nSecara default, Terdapat 4 sub-jendela, yaitu File Explorer, Workspace, Command History, dan Command Window (dll.)\n\nFile Explorer berisi path yang dituju pada address bar. File Explorer berguna untuk membuka file .m ataupun file-file lain tanpa harus membuka Windows Explorer.\nWorkspace berisi data tentang variabel yang didefinisikan saat menjalankan pemrograman nantinya. Data-data yang disajikan berupa identitas dari tiap variabel, seperti nama, kelas, dimensi, value, dan atribut.\nCommand History berisi Riwayat dari semua command yang dijalankan pada Command Window.\nCommand Window sebenarnya mempunyai 3 sub-jendela lain yang dapat ditukar ataupun ditumpuk.\n\nCommand Window adalah command line utama dari Octave dan digunakan untuk menjalankan semua kode maupun program dari Octave. Untuk menjalankan kode dari Command Window, ketikkan kode yang diinginkan, lalu tekan Enter.\nDocumentation berisi dokumentasi dari Octave, seperti tutorial, detail dari fungsi-fungsi built-in, penerapan, dll.\nVariable Editor berguna untuk mengubah variabel yang ada di Workspace. Variable Editor berbentuk baris dan kolom sehingga memudahkan untuk membuat matriks.\nEditor adalah jendela scripting utama dari Octave. Script yang dibuat di Editor dapat disimpan dalam file ekstensi .m dan dijalankan dengan Command Window ataupun dengan menekan F5.\n\n\n\nAritmatika Standar\nOctave dapat digunakan untuk kalkulasi numerik dasar. Octave mengenal operator aritmatika (+, -, *, /), operator pangkat (^) (berbeda dengan kebanyakan Bahasa pemrograman), fungsi eksponen dan logaritma (exp, log), dan fungsi trigonometri (sin, cos, …). Kalkulasi pada Octave juga bekerja pada bilangan real ataupun imajiner (I, j). Beberapa konstanta, seperti bilangan Euler (e) dan bilangan pi (pi), sudah pre-defined pada Octave. Anda juga dapat menambahkan komentar pada kode dengan menggunakan persen (%).\n\n1 + 2 %Operasi Aritmatika Standar\n\nans = 3\n\n\nTerlihat bahwa value hasil running disimpan dalam suatu variabel yang bernama ans. Variabel ini akan menyimpan seluruh hasil dari ekspresi yang di-input dan akan ditimpa jika ada ekspresi baru yang menyimpan hasil.\nEkspresi tersebut juga dapat disimpan ke suatu variabel.\n\na = 2 + 3\n\na = 5\n\n\nTerlihat bahwa output menunjukkan variabel a, bukan ans.\nJika tidak ingin print hasilnya, beri titik koma (;) pada akhir line…\n\na = 1 + 3;\n\n… dan jika ingin menampilkan lagi outputnya, cukup memanggil variabelnya.\n\na\n\na = 4\n\n\nUntuk update variabel, dapat menggunakan cara ini:\n\na = a + 6 %Variabel a ditambah 6\n\na = 10\n\n\n\na = a / 5 %Dapat disesuaikan dengan operator lainnya\n\na = 2\n\n\n\na -= 6 %Idem\n\na = -4\n\n\n\na *= -5 %Idem\n\na = 20\n\n\n\na = \"ayam\" %Update variabel a dengan nilai baru\n\na = ayam\n\n\nSebagai tambahan, tidak seperti Mathematica, value pada Octave menggunakan presisi mesin (machine precision), sehingga beberapa hasil yang ditampilkan mungkin saja tidak bulat. Sebagai contoh, akan ditampilkan hasil dari \\(e^{i \\pi}\\) (Identitas Euler)\n\ne^(i*pi)\n\nans = -1.0000e+00 + 1.2246e-16i\n\n\nHarusnya tepat -1, tetapi ternyata ada sedikit error \\(10^{-16}\\).\n\n\nPendefinisian dan Pemanggilan Matriks\nMatriks ataupun vektor akan menjadi hal esensial untuk analisis numerik. Untuk mendefinisikan matriks, gunakan kurung siku ([]) untuk membuat matriks. Elemen pada baris dipisahkan dengan koma (,), dan elemen pada kolom dipisahkan dengan titik koma (;)\nContoh:\n\nA = [1, 2, 3; 4, 5, 6; 7, 8, 9]\n\nA =\n\n   1   2   3\n   4   5   6\n   7   8   9\n\n\n\nCatatan: Sebenarnya kita dapat mendefinisikan kode untuk matriks tanpa menggunakan koma ataupun titik koma. Cukup dengan menggunakan spasi dan Enter…\n\nB = [1 2 3\n4 5 6\n7 8 9]\n\nB =\n\n   1   2   3\n   4   5   6\n   7   8   9\n\n\n\n… namun hal ini dapat menyebabkan beberapa ambiguitas dalam pendefinisian beberapa elemen dalam matriks. Disarankan tetap menggunakan titik dan titik koma, kecuali untuk matriks yang isinya simpel.\nSelanjutnya, untuk memanggil elemen dari matriks, gunakan tanda kurung ((a, b)) dengan a adalah indeks baris dan b adalah indeks kolom. Catatan: Indeks pada Octave dimulai dari 1.\n\nA(2, 3)\n\nans = 6\n\n\nJika ingin memanggil lebih dari satu elemen, kalian dapat menggunakan titik dua (a:b) ataupun kurung siku ([a,b]). Titik dua (a:b) akan memanggil elemen baris/kolom dari a hingga b…\nContoh: Memanggil elemen baris ke-2 dan kolom dari 2 hingga 3:\n\nA(2, 2:3)\n\nans =\n\n   5   6\n\n\n\n… dan kurung siku ([a,b]) akan memanggil elemen baris/kolom ke-a dan ke-b.\nContoh: Memanggil elemen baris ke-1 dan kolom ke-1 dan ke-3:\n\nA(1, [1,3])\n\nans =\n\n   1   3\n\n\n\nContoh: Memanggil elemen baris ke-1 dan ke-3, dan kolom dari 2 hingga 3:\n\nA([1,3], 2:3)\n\nans =\n\n   2   3\n   8   9\n\n\n\n\n\nOperasi Matriks\nMatriks yang telah dibuat dapat diubah isinya, ditranspos, diinvers, dll. Untuk mengubah isi dari matriks, dapat menggunakan pemanggilan indeks.\n\nA\n\nA =\n\n   1   2   3\n   4   5   6\n   7   8   9\n\n\n\n\nA(2, 3) = 5 %Mengubah satu elemen\n\nA =\n\n   1   2   3\n   4   5   5\n   7   8   9\n\n\n\n\nA(2, [1,3]) = 3 %Mengubah banyak elemen dengan 1 nilai \n\nA =\n\n   1   2   3\n   3   5   3\n   7   8   9\n\n\n\nMengubah banyak elemen dengan nilai yang bersesuaian dengan tempat:\n\nA(1:3, 1) = [2; 4; 8]\n\nA =\n\n   2   2   3\n   4   5   3\n   8   8   9\n\n\n\nJika posisi salah, akan dicoba dengan transpose nya:\n\nA(1:3, 3) = [2, 4, 8] \n\nA =\n\n   2   2   2\n   4   5   4\n   8   8   8\n\n\n\nJika masih tidak bisa dengan transpose nya, akan ada pesan error\n\nA(2, 1:3) = [2, 4]\n\nerror: =: nonconformant arguments (op1 is 1x3, op2 is 1x2)\n\n\nOperasi matriks pada Octave mengikuti operasi pada aljabar linear biasa, dimana perkalian matriks harus mengikuti baris dan kolom yang sesuai.\n\nA * 2 %Perkalian scalar\n\nans =\n\n    4    4    4\n    8   10    8\n   16   16   16\n\n\n\n\nA + B %Penjumlahan matriks \n\nans =\n\n    3    4    5\n    8   10   10\n   15   16   17\n\n\n\n\nA * B %Perkalian matriks \n\nans =\n\n    24    30    36\n    52    65    78\n    96   120   144\n\n\n\nUntuk memanggil transpos dari matriks, gunakan tanda petik satu (’), dan untuk memanggil invers dari matriks, gunakan fungsi inv. Jika matriks yang diinvers singular (det = 0), maka akan muncul pesan peringatan dan elemennya akan menjadi Inf.\n\nD = [1, 2, 3; 4, 5, 6]\n\nD =\n\n   1   2   3\n   4   5   6\n\n\n\n\nD' %Transpos dari matriks \n\nans =\n\n   1   4\n   2   5\n   3   6\n\n\n\n\nE = [1, 2; 5, 7]\n\nE =\n\n   1   2\n   5   7\n\n\n\n\ninv(E) %Invers dari matriks\n\nans =\n\n  -2.3333   0.6667\n   1.6667  -0.3333\n\n\n\n\nF = [1, 2; 4, 8]\n\nF =\n\n   1   2\n   4   8\n\n\n\n\ninv(F) %Contoh invers untuk matriks singular\n\nwarning: matrix singular to machine precision\nans =\n\n   Inf   Inf\n   Inf   Inf\n\n\n\nOctave juga mempunyai operator khusus, yaitu (\\). Operator ini adalah operator “pembagian” matriks. Pendefinisian untuk A \\ b ekuivalen dengan inv(A) * b. Operasi ini sangat berguna untuk penyelesaian sistem linear. Sebagai contoh, misalkan kita mempunyai sistem linear berikut:\n\\[4x_1 - 2x_2 = 20\\] \\[-5x_1 - 5x_2 = -10\\]\nJika kita ubah dalam bentuk perkalian matriks \\(Ax=b\\) (dengan penyelesaian \\(x = A^{-1} b\\)), diperoleh:\n\\[A = \\begin{pmatrix}\n    4 & -2 \\\\\n    -5 & -5\n\\end{pmatrix}\\]\n\\[x = \\begin{pmatrix}\n    x_1 \\\\\n    x_2\n\\end{pmatrix}\\]\n\\[b = \\begin{pmatrix}\n    20 \\\\\n    -10\n\\end{pmatrix}\\]\nJika dimasukkan ke Octave, kita akan memperoleh:\n\nA = [4, -2; -5, -5]\n\nA =\n\n   4  -2\n  -5  -5\n\n\n\n\nb = [20; -10]\n\nb =\n\n   20\n  -10\n\n\n\n\nx = inv(A) * b\n\nx =\n\n   4.0000\n  -2.0000\n\n\n\n\nx = A \\ b\n\nx =\n\n   4\n  -2\n\n\n\nDiproleh \\(x_1 = 4\\) dan \\(x_2 = -2\\).\n\n\nVariable Editor\nSesuai namanya, Variable Editor digunakan untuk mengubah nilai dari suatu variabel. Untuk menggunakannya, double-click variabel yang ingin diubah pada workspace. Variabel tersebut akan muncul pada tab Variable Editor (atau tekan Ctrl+6).\n\nAntarmuka dari Variable Editor mirip seperti Excel, sehingga kalian bisa langsung mengubah nilai matriks yang ada dengan memilih kotak yang berisi elemen yang ingin diubah, lalu mengetik nilai yang baru.\nJika kalian memberi nilai baru pada kotak kosong di Variable Editor, matriks tersebut akan mengalami perubahan bentuk, menyesuaikan dengan posisi elemen nilai baru tersebut.\n\nPada gambar di atas, nilai baru dimasukkan pada baris 5 kolom 5, sehingga matriks tersebut berubah menjadi 5x5.\nUntuk menghapus suatu baris/kolom, klik kanan angka baris/kolom (atau pilih lebih dari satu baris/kolom dengan Ctrl/Shift), lalu klik Delete rows/Delete columns.\n\n\n\nFile dan Editor untuk kode\nSejauh ini, kita menggunakan command line untuk menjalankan kode. Namun, kalian juga bisa melakukan scripting seperti pemrograman pada umumnya dengan menggunakan Editor. Untuk memunculkan Editor, klik Tab Editor (atau tekan Ctrl+4).\n\nUntuk membuat file baru, klik New Script (ikon kertas). Kalian juga dapat membuka file .m (file MATLAB) yang tersimpan dengan double-click file tersebut di File Explorer pada Octave ataupun di Windows Explorer (atau /root atau lainnya).\nScript bekerja layaknya Bahasa pemrograman biasa. Kalian dapat menjalankan script yang telah dibuat dengan menekan F5 (jika file belum di-save, akan muncul kotak dialog untuk save). Output dari script tersebut akan muncul pada Command Window.\nCatatan: Jika kalian menggunakan Editor, disarankan mengubah layout dari Editor dan Command Window untuk mempermudah melihat output (tidak perlu ganti tab). Untuk memindahkan layout, klik dan drag tulisan Editor pada bagian atas jendela Editor ke tempat yang diinginkan. Contohnya seperti gambar berikut:"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul1.html#pemrograman-dan-fungsi",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul1.html#pemrograman-dan-fungsi",
    "title": "Modul 1 Persamaan Diferensial Numerik: Pengenalan GNU Octave",
    "section": "Pemrograman dan Fungsi",
    "text": "Pemrograman dan Fungsi\n\nI/O\nDalam pemrograman, seringkali pengguna diminta memberi suatu input, entah suatu nilai, string, dll., ke program, lalu program tersebut akan menggunakan input tersebut sebagai nilai dari suatu variabel. Hal ini juga dapat dilakukan pada Octave. Untuk membuat Octave meminta input dari user, gunakan syntax input(prompt), dengan prompt adalah string yang berisi pesan dalam input.\n\nA = input(\"Masukkan suatu angka: \")\n\nMasukkan suatu angka:  135\n\n\nA = 135\n\n\nJika tidak ingin membuat pesan input, cukup isi “” sebagai prompt.\n\nA = input(\"\")\n\n 100\n\n\nA = 100\n\n\nPerlu diketahui bahwa input yang diberikan pengguna akan dievaluasi sebagai ekspresi. Jadi, bisa saja input yang diberikan akan dievaluasi sebagai kode Octave (sebagaimana eval(input(...)) pada Python). Sebagai contoh, jika kita memasukkan operasi bilangan pada input…\n\nB = input(\"Operasi bilangan: \")\n\nOperasi bilangan:  2 + 3\n\n\nB = 5\n\n\n…, maka operasi tersebut akan dievaluasi dan memberikan hasil operasinya. Jika kita memasukkan kode Octave, seperti meng-assign suatu variabel…\n\nC = input(\"Assign variabel: \")\n\nAssign variabel:  x = 25\n\n\nC = 25\n\n\n…, maka nilai dari variabel yagn di-assign akan masuk ke variabel input…\n\nx\n\nx = 25\n\n\n… sekaligus variabel yang di-assign di dalam input. Jika kalian ingin agar input yang dimasukkan tidak dievaluasi, input tersebut dapat diubah terlebih dahulu menjadi string.\n\nD = input(\"Masukkan string: \")\n\nMasukkan string:  \"x + 25\"\n\n\nD = x + 25\n\n\n\ntypeinfo(D) % untuk menanyakan tipe data variabel\n\nans = string\n\n\nTernyata tipe data string, sesuai yang kita harapkan.\nCara lain, bisa juga dengan menambah argumen pada input() menjadi input(prompt, “s”). Jika menambahkan argumen, maka apapun input yang kalian masukkan akan menjadi string tanpa perlu menggunakan tanda petik.\n\nE = input(\"Masukkan string: \", \"s\")\n\nMasukkan string:  x + 25\n\n\nE = x + 25\n\n\n\ntypeinfo(E)\n\nans = sq_string\n\n\nNote: Syntax input() sebaiknya digunakan sebagai nilai dari suatu variabel.\nSelain menggunakan input(), kita juga bisa menggunakan syntax menu(title, op1, op2, …). Syntax tersebut akan memunculkan kotak dialog dengan judul title dan pilihan op1, op2, dst. (sesuai yang dimasukkan). Syntax ini sangat berguna untuk program-program interaktif karena mempunyai GUI sendiri.\nF = menu(\"Pilih buah favorit.\", \"Apel\", \"Jeruk\", \"Pisang\")\n\nF = 1\nTergantung pilihan kalian, variabel yang mengandung menu() akan diisi bilangan dari 1 hingga n tergantung banyaknya pilihan. Dalam contoh di atas, pilihan “Apel” akan memberi nilai 1, “Jeruk” akan memberi nilai 2, dan “Pisang” akan memberi nilai 3. Jika kalian memilih Cancel atau membuat pilihan yang tidak valid, maka variabelnya akan diberi nilai 0.\nUntuk output, mungkin cukup untuk memanggil variabel itu sendiri, seperti…\n\nC\n\nC = 25\n\n\n…, namun kalian juga bisa hanya memunculkan nilai dari variabelnya tanpa sekaligus memunculkan variabel tersebut dengan menggunakan syntax disp(). Syntax ini digunakan jika yang di-output hanya suatu variabel atau string simpel, dll.\n\ndisp(C)\n\n25\n\n\n\ndisp(\"Simple string\")\n\nSimple string\n\n\nJika yang ingin dimunculkan adalah pesan yang membutuhkan banyak formatting, kalian bisa menggunakan syntax printf(). Syntax tersebut dapat melakukan formatting pesan agar dapat menerima variabel selain string.\nNote: Gunakan \\n pada akhir string di printf() agar program memasukkan “Enter”.\n\nx = input(\"Masukkan angka: \"); printf(\"Anda memasukkan angka %d\\n\", x)\n\nMasukkan angka:  25Anda memasukkan angka 25\n\n\nPada contoh di atas, kita ingin agar variabel x dapat di-output bersama dengan pesan string. Kita menggunakan %d agar nilai x dapat di-print sebagai bilangan desimal. Jika variabelnya berisi string, maka gunakan %s. Jika variabelnya berisi float, gunakan %f untuk print dalam bentuk desimal, atau %.nf untuk sekaligus mengatur angka di belakang koma sebanyak n.\n\nprintf(\"pi = %f\\n\", pi)\n\npi = 3.141593\n\n\n\nprintf(\"pi = %.12f\\n\", pi)\n\npi = 3.141592653590\n\n\nJika float tersebut ingin di-print dalam notasi saintifik, gunakan %e atau %E. Keduanya hanya berbeda di hasil output yang berupa E (besar) ataupun e (kecil).\n\nprintf(\"euler = %e\\n\", e)\n\neuler = 2.718282e+00\n\n\n\nprintf(\"euler = %E\\n\", e)\n\neuler = 2.718282E+00\n\n\nJika ingin print karakter persen itu sendiri (%), gunakan %%.\nJika ada lebih dari satu formatting di satu printf(), maka variabelnya juga harus dimasukkan secara berurutan.\n\nnama = input(\"Masukkan nama: \", \"s\");\n\nMasukkan nama:  Burden\n\n\n\nminuman_fav = input(\"Minuman favorit: \", \"s\");\n\nMinuman favorit:  Kopi\n\n\n\nharga = input([\"Harga \" minuman_fav \": \"]);\n\nHarga Kopi:  25000\n\n\n\nprintf(\"%s suka %s seharga Rp%d\", nama, minuman_fav, harga);\n\nBurden suka Kopi seharga Rp25000\n\n\n\n\nStruktur Bersyarat: If-Else-Elseif, Switch-Case\nSeperti halnya bahas pemrograman, Octave pun juga memiliki conditional statements (pernyataan kondisional, pernyataan bersyarat, atau struktur bersyarat). Secara umum, conditional statement pada Octave berbentuk:\ncond\n  body\nendcond\n\nPada potongan kode di atas, cond adalah jenis conditional statement yagn digunakan, bisa berupa if, for, dan lainnya, body berisi kode yang dijalankan ketika cond terpenuhi, dan endcond adalah bagian penutup dari conditional statement, bisa berupa endif, endfor, dan lainnya tergantung cond apa yang digunakan.\n\nOperasi dasar yang digunakan pada conditional statements adalah operasi perbandingan, dimana pada dasarnya, dua atau lebih nilai dibandingkan dengan operator dan dicek apakah memenuhi atau tidak. Jika memenuhi, maka nilainya 1, dan jika tidak, maka nilainya 0. Ada 6 operator dasar untuk perbandingan:\n\n* sama dengan (==)\n* lebih dari (&gt;)\n* kurang dari (&lt;)\n* lebih dari atau sama dengan (&gt;=)\n* kurang dari atau sama dengan (&lt;=)\n* tidak sama dengan (!= atau ~=)\n\n::: {#cell-134 .cell execution_count=72}\n``` {.octave .cell-code}\n2 &lt; 3\n\nans = 1\n\n:::\n\n4 == 5\n\nans = 0\n\n\nSelain operator di atas, ada juga syntax untuk perbandingan:\n\nisequal(a, b, c, …)\nmengecek apakah a, b, dan c semuanya sama.\nstrcmp(s1, s2)\nmengecek apakah s1 dan s2 adalah string yang sama.\nstrncmp(s1, s2, n)\nmengecek apakah n karakter pertama pada s1 dan s2 sama.\nstrcmpi(s1, s2)\nmirip strcmp(), namun tidak case-sensitive.\nstrncmpi(s1, s2, n)\nmirip strncmp(), namun tidak case-sensitive.\n\n\nisequal(1, 3, 5)\n\nans = 0\n\n\n\nstrcmp(\"ayam\", \"Ayam\")\n\nans = 0\n\n\n\nstrcmpi(\"ayam\", \"Ayam\")\n\nans = 1\n\n\n\nstrncmp(\"sayamakan\", \"saya makan\", 4)\n\nans = 1\n\n\nBerikut beberapa jenis conditional statement pada Octave. Kode-kode ini akan ditulis di editor dan output akan dipisahkan oleh &gt;&gt;\n\nIf, Elseif, Else\nIf adalah conditional statement dasar dalam decision-making melalui perbandingan nilai. If memiliki 3 bentuk. Bentuk pertama:\nif (cond)\n  body\nendif\nBentuk ini adalah bentuk paling simpel dalam menggunakan if. Jika cond bernilai 1, maka body dieksekusi, dan sebaliknya. Contoh:\n\nx = input(\"Masukkan nilai x: \");\nif (x &gt; 0)\n  printf(\"%d adalah bilangan positif\\n\", x);\nendif\n\nMasukkan nilai x:  2525 adalah bilangan positif\n\n\nSeringkali if dipasangkan dengan else. Untuk itu, cukup menyelipkan bagian else layaknya if, sehingga menjadi:\nif (cond)\n  body1;\nelse\n  body2;\nendif\nContoh:\n\nx = input(\"Masukkan x: \");\nif mod(x, 2) == 0\n  printf(\"x genap\\n\");\nelse\n  printf(\"x ganjil\\n\");\nendif\n\nMasukkan x:  5x ganjil\n\n\nKita pun juga dapat membuat lebih dari 2 condition selain if dan else. Cukup tambahkan bagian elseif. Kita dapat menambahkan berapapun banyaknya elseif sesuka hati, selama bagian akhirnya adalah else.\nif (cond1)\n  body1;\nelseif (cond2)\n  body2;\nelse\n  body3;\nendif\n\n\nSwitch-Case\nUntuk beberapa kasus, sudah jelas jika kita menggunakan model kode seperti di atas. Namun, terkadang kita ingin membuat program berjalan sesuai input, dan jika menggunakan if-else, kodenya akan terlihat jelek. Maka, kita juga bisa menggantinya dengan kode switch. Bentuk umum dari switch adalah:\nswitch (var)\n  case nilai1\n    body1;\n  case nilai2\n    body2;\n  otherwise\n    body3;\nendswitch\nPada kode di atas, var akan dicocokkan dengan nilai1, nilai2, dst. yang sesuai. Jika tidak ada yang sesuai, kode akan masuk ke bagian otherwise. Layaknya elseif, kita juga dapat menambahkan berapapun banyaknya case sesuka hati, selama terdapat paling tidak satu case (bahkan bagian otherwise opsional).\nContoh:\n\npilihan = input(\"Masukkan pilihan warna (1-4): \");\nswitch (pilihan)\n  case 1\n    printf(\"Warna merah\")\n  case 2\n    printf(\"Warna hijau\")\n  case 3\n    printf(\"Warna biru\")\n  case 4\n    printf(\"Warna kuning\")\n  otherwise\n    printf(\"Input tidak valid\")\nendswitch\n\nMasukkan pilihan warna (1-4):  4Warna kuning\n\n\nJika case berisi array, kode akan masuk case tersebut jika var sesuai dengan salah satu elemen di array tersebut.\n\n\n\nStruktur Berulang: For, While-Do, Do-Until\n\nFor Loop\nBentuk umum dari for adalah:\nfor var = expr\n  body;\nendfor\nBiasanya isi dari expr adalah a:b, yang menyebabkan var diiterasi dari a hingga b. Secara umum, for akan meng-assign tiap kolom pada expr ke var (bentuk range a:b secara umum adalah vektor baris, sehingga iterasi kolom pada a:b adalah dari a hingga b). Contoh:\n\nfib = ones(1, 10); % matriks 1x10 berisi nilai 1 semua\nfor i = 3:10\n  fib(i) = fib(i-1) + fib(i-2);\nendfor\ndisp(fib)\n\n    1    1    2    3    5    8   13   21   34   55\n\n\nKarena iterasinya antar kolom, maka jika expr adalah suatu matriks, maka var akan diiterasi sebagai vektor kolom.\n\nfor i = [1, 2, 3; 4, 5, 6; 7, 8, 9]\n  disp(i)\nendfor\n\n   1\n   4\n   7\n   2\n   5\n   8\n   3\n   6\n   9\n\n\n\n\nWhile Loop\nBentuk umum dari while adalah:\nwhile (cond)\n  body;\nendwhile\nSerupa dengan if, while akan menjalankan body jika cond bernilai taknol. Namun, akan diulang terus hingga cond bernilai nol, baru berhenti.\nContoh:\n\nfib = ones(1, 10);\ni = 3;\nwhile (i &lt;= 10)\n  fib(i) = fib(i-1) + fib(i-2);\n  i++;\nendwhile\ndisp(fib)\n\n    1    1    2    3    5    8   13   21   34   55\n\n\nPada contoh di atas, penting untuk memasukkan bagian i++ agar suatu saat nilai i akan lebih dari 10. Hati-hati menggunakan while, karena dapat mengakibatkan infinite loop.\n\n\nDo-Until\nBentuk umum dari do-until adalah:\ndo\n  body\nuntil (cond)\nSekilas, do terlihat serupa dengan while. Yang membedakannya adalah do akan terus menjalankan body ketika cond bernilai 0 dan berhenti ketika cond bernilai taknol. Kondisi cond pada do juga berada di akhir, sehingga body pasti akan dijalankan paling tidak sekali. Perbedaan kecil selanjutnya adalah do tidak memakai enddo seperti layaknya endif, endwhile, dan sejenisnya.\nContoh:\n\nfib = ones(1, 10);\ni = 2;\ndo\n  i++;\n  fib(i) = fib(i-1) + fib(i-2);\nuntil (i == 10)\ndisp(fib)\n\n    1    1    2    3    5    8   13   21   34   55\n\n\n\n\nBreak, Continue\nbreak dan continue adalah dua statement yang digunakan dan hanya digunakan dalam loop. Statement break akan langsung mengeluarkan program dari loop, sedangkan continue akan langsung menuju iterasi selanjutnya tanpa menyelesaikan sisa kode pada badan loop.\nContoh perbedaan break dan continue:\n\na = [];\nfor i = 1:10\n  if mod(i, 5) == 0\n    break;\n  endif\n  a = [a, i];\nendfor\ndisp(a)\n\n   1   2   3   4\n\n\n\na = [];\nfor i = 1:10\n  if mod(i, 5) == 0\n    continue;\n  endif\n  a = [a, i];\nendfor\ndisp(a)\n\n   1   2   3   4   6   7   8   9"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul1.html#function-file-dan-script-file",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul1.html#function-file-dan-script-file",
    "title": "Modul 1 Persamaan Diferensial Numerik: Pengenalan GNU Octave",
    "section": "Function File dan Script File",
    "text": "Function File dan Script File\nSebelum kita lanjutkan, kita harus terlebih dahulu mengetahui tentang function file dan script file.\nFunction file adalah file yang dapat digunakan oleh Octave untuk memanggil fungsi yang telah didefinisikan di dalamnya. Function file ini berguna jika kalian ingin menggunakan fungsi tersebut secara berkala.\nScript file adalah file yang berisi kumpulan perintah Octave, layaknya script pemrograman. Script file berguna untuk pemrograman dan menjalankan/menyimpan suatu urutan perintah, sehingga bisa dijalankan kembali nantinya. Untuk selanjutnya, script file akan disebut “program”.\nPermasalahannya, kedua jenis file tersebut mempunyai ekstensi yang serupa (.m), namun function file tidak dapat dijalankan layaknya program.\nMisal kita mempunyai fungsi yang ingin disimpan dalam program bernama testfile.m (untuk sekarang kita akan abaikan dulu maksud dari tiap bagian dari fungsi ini. Intinya fungsi ini akan menampilkan variabel message yang kita masukkan.\n\nfunction test(message)\n  printf(\"%s\\n\", message);\nendfunction\n\ntest(\"PDNum\");\n\nPDNum\n\n\nJika program tersebut dijalankan, akan muncul pesan peringatan…\nwarning: function name 'test' does not agree with function filename...\n…dan mungkin saja akan diikuti error lain. Jika kalian ingin membuat program, jangan gunakan function di line pertama yang dieksekusi.\nSekarang kita modifikasi testfile.m di atas.\n\n1;\nfunction test(message)\n  printf(\"%s\\n\", message);\nendfunction\n\ntest(\"PDNum\");\n\nPDNum\n\n\nDi sini, kita menambahkan line yang tidak berpengaruh apa-apa dalam program kita sebelum line pendefinisian fungsi. Untuk membedakan function file dengan program, Octave mengecek perintah pertama yang dieksekusi. Jika perintah tersebut adalah pendefinisian fungsi, maka file tersebut akan dianggap sebagai function file, dan jika bukan, maka file tersebut akan dianggap sebagai program.\nSekarang kita masuk ke fungsi, pendefinisian, dan embel-embelnya. Fungsi adalah suatu bagian dari program yang nantinya akan dipanggil. Fungsi sangat berguna jika bagian program tersebut nantinya akan digunakan berkali-kali. Fungsi juga berguna agar pengorganisasian kode program lebih bagus. Syntax untuk pendefinisian fungsi adalah:\nfunction name\n  body\nendfunction\nPotongan kode di atas akan membuat fungsi name dengan body adalah isi dari fungsi tersebut. Untuk memanggil fungsi tersebut, cukup dengan memanggil name. Contoh:\n\nfunction bangun\n  printf(\"BANGUN!!!\\n\");\nendfunction\n\nbangun;\n\nBANGUN!!!\n\n\nKalian juga bisa menambahkan argumen (biasanya berupa variabel), ke fungsinya.\n\nfunction bangun(message)\n  printf(\"%s\\n\", message);\nendfunction\n\nbangun(\"BANGUN WOY!!!\");\n\nBANGUN WOY!!!\n\n\nPada kedua contoh di atas, fungsinya tidak benar-benar memberikan suatu value, melainkan hanya sekedar output. Dalam kebanyakan kasus, kita menggunakan fungsi agar bisa mendapatkan suatu nilai yang dapat di-assign ke suatu variabel. Agar kita bisa mendapatkan value, maka kita harus meng-assign variabel untuk return. Strukturnya menjadi:\nfunction retval = name (args)\n  body\nendfunction\nretval adalah variabel lokal (namanya tidak harus retval) yang akan digunakan sebagai return value sehingga dapat di-assign. retval bisa berupa variabel, jika kita ingin me-return satu value, ataupun bisa berupa list dari variabel jika ingin me-return lebih dari satu value.\nContoh return satu nilai:\n\nfunction x = kuadratkan(a)\n  x = a^2;\nendfunction\n\ny = kuadratkan(5);\ndisp(y);\n\n25\n\n\nContoh return lebih dari satu nilai:\n\nfunction [y1, y2] = jumlah_kali(x1, x2)\n  y1 = x1 + x2;\n  y2 = x1 * x2;\nendfunction\n\n[z1, z2] = jumlah_kali(5, 7);\ndisp(z1);\ndisp(z2);\n\n12\n35"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul3.html",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul3.html",
    "title": "Modul 3 Persamaan Diferensial Numerik: Metode Runge-Kutta dan variasinya",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul3.html#format-long",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul3.html#format-long",
    "title": "Modul 3 Persamaan Diferensial Numerik: Metode Runge-Kutta dan variasinya",
    "section": "Format long",
    "text": "Format long\n\nsin(pi/4)\n\nans = 0.7071\n\n\n\nformat long\n\n\nsin(pi/4)\n\nans = 0.707106781186547\n\n\nKembali ke default:\n\nformat\n\n\nsin(pi/4)\n\nans = 0.7071"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul3.html#metode-runge-kutta-dan-variasinya",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul3.html#metode-runge-kutta-dan-variasinya",
    "title": "Modul 3 Persamaan Diferensial Numerik: Metode Runge-Kutta dan variasinya",
    "section": "Metode Runge-Kutta dan variasinya",
    "text": "Metode Runge-Kutta dan variasinya\n\nOrde 2: Metode Midpoint\n\\[w_1=\\alpha\\] \\[w_{i+1}=w_i+h f\\left(t_i+\\frac{h}{2}, w_i+\\frac{h}{2} f\\left(t_i, w_i\\right)\\right)\\]\nbisa juga ditulis,\n\\[w_1=\\alpha\\] \\[m_1 = f\\left(t_i, w_i\\right)\\] \\[w_{i+1}=w_i+h f\\left(t_i+\\frac{h}{2}, w_i+\\frac{h}{2} m_1\\right)\\]\natau bahkan,\n\\[w_1=\\alpha\\] \\[m_1 = f\\left(t_i, w_i\\right)\\] \\[m_2 = f\\left(t_i+\\frac{h}{2}, w_i+\\frac{h}{2} m_1\\right)\\] \\[w_{i+1}=w_i+h m_2\\]\n\nFunction file midpoint.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = midpoint(f, a, b, N, alpha)\n  h = (b - a) / N;\n  t = zeros(N + 1, 1);\n  w = zeros(N + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1 : N\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    m2 = f(t(i) + (h / 2), w(i) + (h / 2) * m1);\n    w(i + 1) = w(i) + h * m2;\n  endfor\nendfunction\n\n\n\n\nMisalkan diberikan MNA sebagai berikut, yang ingin diselesaikan secara numerik dengan \\(N = 10\\):\n\\[y' = y - t^2 + 1\\] \\[0 \\le t \\le 2\\] \\[y(0) = 0.5\\]\nyang kebetulan memiliki solusi eksak:\n\\[y\\left(t\\right) = \\left( t + 1 \\right)^2 - 0.5 e^t\\]\nContoh penggunaan:\n\nScript file coba_midpoint.m - nama file bebas\n\n\n\nf = @(t, y) (y - t .^ 2 + 1);\na = 0;\nb = 2;\nN = 10;\nalpha = 0.5;\n\n[t, w] = midpoint(f, a, b, N, alpha);\n\nsln = @(t) (t + 1) .^ 2 - 0.5 * exp(t);\ny_eksak = sln(t);\n\nerr_midpoint = abs(w - y_eksak);\nerr_midpoint_total = sum(err_midpoint); % norm L1 (taxicab/Manhattan)\n\ndisp(\"Tabel aproksimasi w, solusi eksak y, dan error:\");\n[t, w, y_eksak, err_midpoint]\ndisp(\"Error total (norm L1):\");\ndisp(err_midpoint_total);\n\nhold on;\nfplot(sln, [a, b], 'b');\nscatter(t, w, 'r');\nlegend(\"Solusi Eksak\", \"Metode Midpoint\");\n\nTabel aproksimasi w, solusi eksak y, dan error:\nans =\n\n        0   0.5000   0.5000        0\n   0.2000   0.8280   0.8293   0.0013\n   0.4000   1.2114   1.2141   0.0027\n   0.6000   1.6447   1.6489   0.0043\n   0.8000   2.1213   2.1272   0.0059\n   1.0000   2.6332   2.6409   0.0077\n   1.2000   3.1705   3.1799   0.0095\n   1.4000   3.7212   3.7324   0.0112\n   1.6000   4.2706   4.2835   0.0129\n   1.8000   4.8010   4.8152   0.0142\n   2.0000   5.2904   5.3055   0.0151\n\nError total (norm L1):\n0.084840\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOrde 2: Metode Modified Euler\n\\[w_1=\\alpha\\] \\[w_{i+1}=w_i+\\frac{h}{2}\\left(f\\left(t_i, w_i\\right)+f\\left(t_{i+1}, w_i+h f\\left(t_i, w_i\\right)\\right)\\right)\\]\nbisa juga ditulis,\n\\[w_1=\\alpha\\] \\[m_1 = f\\left(t_i, w_i\\right)\\] \\[w_{i+1}=w_i+\\frac{h}{2}\\left(m_1+f\\left(t_{i+1}, w_i+h m_1\\right)\\right)\\]\natau bahkan,\n\\[w_1=\\alpha\\] \\[m_1 = f\\left(t_i, w_i\\right)\\] \\[m_2 = f\\left(t_{i+1}, w_i+h m_1\\right)\\] \\[w_{i+1}=w_i+\\frac{h}{2}\\left(m_1+m_2\\right)\\]\n\nFunction file modified_euler.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = modified_euler(f, a, b, N, alpha)\n  h = (b - a) / N;\n  t = zeros(N + 1, 1);\n  w = zeros(N + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1 : N\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    m2 = f(t(i + 1), w(i) + h * m1);\n    w(i + 1) = w(i) + h * (m1 + m2) / 2;\n  endfor\nendfunction\n\n\n\n\nMisalkan diberikan MNA sebagai berikut, yang ingin diselesaikan secara numerik dengan \\(N = 10\\):\n\\[y' = y - t^2 + 1\\] \\[0 \\le t \\le 2\\] \\[y(0) = 0.5\\]\ndan misalkan solusi eksak tidak diketahui.\nContoh penggunaan (perbandingan metode Runge-Kutta orde 2):\n\nScript file bandingkan_rko2.m - nama file bebas\n\n\n\nf = @(t, y) (y - t .^ 2 + 1);\na = 0;\nb = 2;\nN = 10;\nalpha = 0.5;\n\n[t1, w1] = midpoint(f, a, b, N, alpha);\n[t2, w2] = modified_euler(f, a, b, N, alpha);\n\n[t1, w1, w2]\n\nhold on;\nscatter(t1, w1, 'r');\nscatter(t2, w2, 'g');\nlegend(\"Midpoint\", \"Modified Euler\");\n\nans =\n\n        0   0.5000   0.5000\n   0.2000   0.8280   0.8260\n   0.4000   1.2114   1.2069\n   0.6000   1.6447   1.6372\n   0.8000   2.1213   2.1102\n   1.0000   2.6332   2.6177\n   1.2000   3.1705   3.1496\n   1.4000   3.7212   3.6937\n   1.6000   4.2706   4.2351\n   1.8000   4.8010   4.7556\n   2.0000   5.2904   5.2331\n\n\n\n\n\n\n\n\n\n\n\n\n\nMisalkan diketahui solusi eksak:\n\\[y\\left(t\\right) = \\left( t + 1 \\right)^2 - 0.5 e^t\\]\nMaka kita juga bisa menghitung error dari masing-masing metode.\n\nScript file bandingkan2_rko2.m - nama file bebas\n\n\n\nf = @(t, y) (y - t .^ 2 + 1);\na = 0;\nb = 2;\nN = 10;\nalpha = 0.5;\n\n[t1, w1] = midpoint(f, a, b, N, alpha);\n[t2, w2] = modified_euler(f, a, b, N, alpha);\n\nsln = @(t) (t + 1) .^ 2 - 0.5 * exp(t);\ny_eksak = sln(t1);\n\nerr1 = abs(y_eksak - w1);\nerr2 = abs(y_eksak - w2);\n\n[t1, y_eksak, w1, err1, w2, err2]\n\nhold on;\nfplot(sln, [a, b], 'b');\nscatter(t1, w1, 'r');\nscatter(t2, w2, 'g');\nlegend(\"Solusi Eksak\", \"Midpoint\", \"Modified Euler\");\n\nans =\n\n        0   0.5000   0.5000        0   0.5000        0\n   0.2000   0.8293   0.8280   0.0013   0.8260   0.0033\n   0.4000   1.2141   1.2114   0.0027   1.2069   0.0072\n   0.6000   1.6489   1.6447   0.0043   1.6372   0.0117\n   0.8000   2.1272   2.1213   0.0059   2.1102   0.0170\n   1.0000   2.6409   2.6332   0.0077   2.6177   0.0232\n   1.2000   3.1799   3.1705   0.0095   3.1496   0.0304\n   1.4000   3.7324   3.7212   0.0112   3.6937   0.0387\n   1.6000   4.2835   4.2706   0.0129   4.2351   0.0484\n   1.8000   4.8152   4.8010   0.0142   4.7556   0.0596\n   2.0000   5.3055   5.2904   0.0151   5.2331   0.0724\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOrde 3: Metode Heun\n\\[w_1=\\alpha\\] \\[w_{i+1}=w_i+\\frac{h}{4}\\left(f\\left(t_i, w_i\\right)+3 f\\left(t_i+\\frac{2 h}{3}, w_i+\\frac{2 h}{3} f\\left(t_i+\\frac{h}{3}, w_i+\\frac{h}{3} f\\left(t_i, w_i\\right)\\right)\\right)\\right)\\]\nbisa juga ditulis,\n\\[w_1=\\alpha\\] \\[m_1 = f\\left(t_i, w_i\\right)\\] \\[w_{i+1}=w_i+\\frac{h}{4}\\left(m_1+3 f\\left(t_i+\\frac{2 h}{3}, w_i+\\frac{2 h}{3} f\\left(t_i+\\frac{h}{3}, w_i+\\frac{h}{3} m_1\\right)\\right)\\right)\\]\natau,\n\\[w_1=\\alpha\\] \\[m_1 = f\\left(t_i, w_i\\right)\\] \\[m_2 = f\\left(t_i+\\frac{h}{3}, w_i+\\frac{h}{3} m_1\\right)\\] \\[w_{i+1}=w_i+\\frac{h}{4}\\left(m_1+3 f\\left(t_i+\\frac{2 h}{3}, w_i+\\frac{2 h}{3} m_2\\right)\\right)\\]\natau bahkan,\n\\[w_1=\\alpha\\] \\[m_1 = f\\left(t_i, w_i\\right)\\] \\[m_2 = f\\left(t_i+\\frac{h}{3}, w_i+\\frac{h}{3} m_1\\right)\\] \\[m_3 = f\\left(t_i+\\frac{2 h}{3}, w_i+\\frac{2 h}{3} m_2\\right)\\] \\[w_{i+1}=w_i+\\frac{h}{4}\\left(m_1+3 m_3\\right)\\]\n\nFunction file heun.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = heun(f, a, b, N, alpha)\n  h = (b - a) / N;\n  t = zeros(N + 1, 1);\n  w = zeros(N + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1 : N\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    m2 = f(t(i) + (h / 3), w(i) + (h / 3) * m1);\n    m3 = f(t(i) + (2 * h / 3), w(i) + (2 * h / 3) * m2);\n    w(i + 1) = w(i) + (h / 4) * (m1 + 3 * m3);\n  endfor\nendfunction\n\n\n\n\nMisalkan diberikan MNA sebagai berikut, yang ingin diselesaikan secara numerik dengan \\(N = 10\\):\n\\[y' = y - t^2 + 1\\] \\[0 \\le t \\le 2\\] \\[y(0) = 0.5\\]\nyang kebetulan memiliki solusi eksak:\n\\[y\\left(t\\right) = \\left( t + 1 \\right)^2 - 0.5 e^t\\]\nContoh penggunaan:\n\nScript file coba_heun.m - nama file bebas\n\n\n\nf = @(t, y) (y - t .^ 2 + 1);\na = 0;\nb = 2;\nN = 10;\nalpha = 0.5;\n\n[t, w] = heun(f, a, b, N, alpha);\n\nsln = @(t) (t + 1) .^ 2 - 0.5 * exp(t);\ny_eksak = sln(t);\n\nerr_heun = abs(w - y_eksak);\nerr_heun_total = sum(err_heun); % norm L1 (taxicab/Manhattan)\n\ndisp(\"Tabel aproksimasi w, solusi y, dan error:\");\n[t, w, y_eksak, err_heun]\ndisp(\"Error total (norm L1):\");\ndisp(err_heun_total);\n\nhold on;\nfplot(sln, [a, b], 'b');\nscatter(t, w, 'r');\nlegend(\"Solusi Eksak\", \"Metode Heun\");\n\nTabel aproksimasi w, solusi y, dan error:\nans =\n\n        0   0.5000   0.5000        0\n   0.2000   0.8292   0.8293   0.0001\n   0.4000   1.2140   1.2141   0.0001\n   0.6000   1.6488   1.6489   0.0002\n   0.8000   2.1270   2.1272   0.0002\n   1.0000   2.6406   2.6409   0.0003\n   1.2000   3.1796   3.1799   0.0004\n   1.4000   3.7320   3.7324   0.0004\n   1.6000   4.2830   4.2835   0.0005\n   1.8000   4.8147   4.8152   0.0005\n   2.0000   5.3050   5.3055   0.0005\n\nError total (norm L1):\n3.0743e-03\n\n\n\n\n\n\n\n\n\n\n\n\nTernyata errornya sangat kecil! KIta bisa melihat errornya dengan lebih detail/presisi, dengan menggunakan format long\n\nScript file coba2_heun.m - nama file bebas\n\n\n\nf = @(t, y) (y - t .^ 2 + 1);\na = 0;\nb = 2;\nN = 10;\nalpha = 0.5;\n\n[t, w] = heun(f, a, b, N, alpha);\n\nsln = @(t) (t + 1) .^ 2 - 0.5 * exp(t);\ny_eksak = sln(t);\n\nerr_heun = abs(w - y_eksak);\nerr_heun_total = sum(err_heun); % norm L1 (taxicab/Manhattan)\n\nformat long; % pasang format output menjadi panjang (lebih presisi)\ndisp(\"Tabel aproksimasi w, solusi y, dan error:\");\n[t, w, y_eksak, err_heun]\ndisp(\"Error total (norm L1):\");\ndisp(err_heun_total);\nformat; % kembali ke ukuran default\n\nhold on;\nfplot(sln, [a, b], 'b');\nscatter(t, w, 'r');\nlegend(\"Solusi Eksak\", \"Metode Heun\");\n\nTabel aproksimasi w, solusi y, dan error:\nans =\n\n                   0   0.500000000000000   0.500000000000000                   0\n   0.200000000000000   0.829244444444444   0.829298620919915   0.000054176475471\n   0.400000000000000   1.213974992592593   1.214087651179365   0.000112658586772\n   0.600000000000000   1.648765902064198   1.648940599804746   0.000174697740548\n   0.800000000000000   2.126990532832184   2.127229535753766   0.000239002921582\n   1.000000000000000   2.640555548543485   2.640859085770478   0.000303537226992\n   1.200000000000000   3.179576287732221   3.179941538631727   0.000365250899506\n   1.400000000000000   3.731980283861397   3.732400016577663   0.000419732716265\n   1.600000000000000   4.283023031133831   4.283483787802441   0.000460756668610\n   1.800000000000000   4.814696573135897   4.815176267793527   0.000479694657630\n   2.000000000000000   5.305007192434419   5.305471950534676   0.000464758100256\n\nError total (norm L1):\n3.074265993633474e-03\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetode Runge-Kutta orde 4\n\\[w_1=\\alpha\\] \\[k_1=h f\\left(t_i, w_i\\right)\\] \\[k_2=h f\\left(t_i+\\frac{h}{2}, w_i+\\frac{k_1}{2}\\right)\\] \\[k_3=h f\\left(t_i+\\frac{h}{2}, w_i+\\frac{k_2}{2}\\right)\\] \\[k_4=h f\\left(t_{i+1}, w_i+k_3\\right)\\] \\[w_{i+1}=w_i+\\frac{1}{6}\\left(k_1+2 k_2+2 k_3+k_4\\right)\\]\n\nFunction file rko4.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = rko4(f, a, b, N, alpha)\n  h = (b - a) / N;\n  t = zeros(N + 1, 1);\n  w = zeros(N + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1 : N\n    t(i + 1) = t(i) + h;\n    k1 = h * f(t(i), w(i));\n    k2 = h * f(t(i) + (h / 2), w(i) + (k1 / 2));\n    k3 = h * f(t(i) + (h / 2), w(i) + (k2 / 2));\n    k4 = h * f(t(i + 1), w(i) + k3);\n    w(i + 1) = w(i) + (k1 + 2 * k2 + 2 * k3 + k4) / 6;\n  endfor\nendfunction\n\n\n\n\nMisalkan diberikan MNA sebagai berikut, yang ingin diselesaikan secara numerik dengan \\(N = 10\\):\n\\[y' = y - t^2 + 1\\] \\[0 \\le t \\le 2\\] \\[y(0) = 0.5\\]\nyang kebetulan memiliki solusi eksak:\n\\[y\\left(t\\right) = \\left( t + 1 \\right)^2 - 0.5 e^t\\]\n\nScript file coba_rko4.m - nama file bebas\n\n\n\nf = @(t, y) (y - t .^ 2 + 1);\na = 0;\nb = 2;\nN = 10;\nalpha = 0.5;\n\n[t, w] = rko4(f, a, b, N, alpha);\n\nsln = @(t) (t + 1) .^ 2 - 0.5 * exp(t);\ny_eksak = sln(t);\n\nerr_rko4 = abs(w - y_eksak);\nerr_rko4_total = sum(err_rko4); % norm L1 (taxicab/Manhattan)\n\nformat long; % pasang format output menjadi panjang (lebih presisi)\ndisp(\"Tabel aproksimasi w, solusi y, dan error:\");\n[t, w, y_eksak, err_rko4]\ndisp(\"Error total (norm L1):\");\ndisp(err_rko4_total);\nformat; % kembali ke ukuran default\n\nhold on;\nfplot(sln, [a, b], 'b');\nscatter(t, w, 'r');\nlegend(\"Solusi Eksak\", \"Metode Runge-Kutta orde 4\");\n\nTabel aproksimasi w, solusi y, dan error:\nans =\n\n                   0   0.500000000000000   0.500000000000000                   0\n   0.200000000000000   0.829293333333333   0.829298620919915   0.000005287586582\n   0.400000000000000   1.214076210666667   1.214087651179365   0.000011440512698\n   0.600000000000000   1.648922017041600   1.648940599804746   0.000018582763146\n   0.800000000000000   2.127202684947944   2.127229535753766   0.000026850805823\n   1.000000000000000   2.640822692728752   2.640859085770478   0.000036393041726\n   1.200000000000000   3.179894170232231   3.179941538631727   0.000047368399497\n   1.400000000000000   3.732340072854980   3.732400016577663   0.000059943722683\n   1.600000000000000   4.283409498318406   4.283483787802441   0.000074289484035\n   1.800000000000000   4.815085694579435   4.815176267793527   0.000090573214092\n   2.000000000000000   5.305363000692655   5.305471950534676   0.000108949842021\n\nError total (norm L1):\n4.796793723015336e-04\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerbandingan metode Runge-Kutta orde 2, 3, 4\nMisalkan diberikan MNA sebagai berikut, yang ingin diselesaikan secara numerik dengan \\(N = 10\\):\n\\[y' = y - t^2 + 1\\] \\[0 \\le t \\le 2\\] \\[y(0) = 0.5\\]\nyang kebetulan memiliki solusi eksak:\n\\[y\\left(t\\right) = \\left( t + 1 \\right)^2 - 0.5 e^t\\]\n\nScript file bandingkan_rk234.m - nama file bebas\n\n\n\nf = @(t, y) (y - t .^ 2 + 1);\na = 0;\nb = 2;\nN = 10;\nalpha = 0.5;\n\n[t1, w1] = midpoint(f, a, b, N, alpha);\n[t2, w2] = modified_euler(f, a, b, N, alpha);\n[t3, w3] = heun(f, a, b, N, alpha);\n[t4, w4] = rko4(f, a, b, N, alpha);\n\nsln = @(t) (t + 1) .^ 2 - 0.5 * exp(t);\ny_eksak = sln(t1);\n\n[t1, w1, w2, w3, w4, y_eksak]\n\nhold on;\nfplot(sln, [a, b], 'k');\nscatter(t1, w1, 'r');\nscatter(t2, w2, 'g');\nscatter(t3, w3, 'b');\nscatter(t4, w4, 'm');\nlegend('Fungsi eksak', 'Midpoint', 'Modified Euler', 'Heun', 'Runge-Kutta orde 4');\nlegend(\"location\", \"northwest\");\ntitle('Perbandingan metode Runge-Kutta orde 2, 3, 4');\n\nans =\n\n        0   0.5000   0.5000   0.5000   0.5000   0.5000\n   0.2000   0.8280   0.8260   0.8292   0.8293   0.8293\n   0.4000   1.2114   1.2069   1.2140   1.2141   1.2141\n   0.6000   1.6447   1.6372   1.6488   1.6489   1.6489\n   0.8000   2.1213   2.1102   2.1270   2.1272   2.1272\n   1.0000   2.6332   2.6177   2.6406   2.6408   2.6409\n   1.2000   3.1705   3.1496   3.1796   3.1799   3.1799\n   1.4000   3.7212   3.6937   3.7320   3.7323   3.7324\n   1.6000   4.2706   4.2351   4.2830   4.2834   4.2835\n   1.8000   4.8010   4.7556   4.8147   4.8151   4.8152\n   2.0000   5.2904   5.2331   5.3050   5.3054   5.3055"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul5.html",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul5.html",
    "title": "Modul 5 Persamaan Diferensial Numerik: Sistem PDB orde 1 dan PDB orde tinggi",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul5.html#sistem-persamaan-diferensial-fourth-order-runge-kutta-for-systems",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul5.html#sistem-persamaan-diferensial-fourth-order-runge-kutta-for-systems",
    "title": "Modul 5 Persamaan Diferensial Numerik: Sistem PDB orde 1 dan PDB orde tinggi",
    "section": "Sistem Persamaan Diferensial: (fourth-order) Runge-Kutta for Systems",
    "text": "Sistem Persamaan Diferensial: (fourth-order) Runge-Kutta for Systems\n\nBentuk umum\nBentuk umum sistem Persamaan Diferensial:\n\\(u'_1 = f_1(t,u_1,u_2,...,u_m)\\)\n\\(u'_2 = f_2(t,u_1,u_2,...,u_m)\\)\n\\(...\\)\n\\(u'_m = f_m(t,u_1,u_2,...,u_m)\\)\ndengan:\n\\(a \\leq t \\leq b\\)\n\\(u_1(a)=a_1, u_2(a)=a_2, ..., u_m(a)=a_m\\) (initial value)\nBentuk umum algoritma metode untuk sistem PDB orde 1\nfor i = 1 : N do\n    for R in (rumus-rumus untuk iterasi ke-i) do\n        for j = 1 : m do\n            Hitung R dengan f_j\n        endfor\n    endfor\nendfor\nMisalnya, apabila ada lima rumus (seperti dalam metode Runge-Kutta orde 4), algoritma untuk sistem menjadi:\nfor i = 1 : N do\n    for j = 1 : m do\n        Hitung Rumus1 dengan f_j\n    endfor\n\n    for j = 1 : m do\n        Hitung Rumus2 dengan f_j\n    endfor\n\n    for j = 1 : m do\n        Hitung Rumus3 dengan f_j\n    endfor\n\n    for j = 1 : m do\n        Hitung Rumus4 dengan f_j\n    endfor\n\n    for j = 1 : m do\n        Hitung Rumus5 dengan f_j\n    endfor\nendfor\nApabila misalnya rumus pada iterasi 1, 2, 3 berbeda dengan rumus pada iterasi 4+ (seperti untuk metode Adams predictor-corrector orde 4), algoritma untuk sistem bisa seperti berikut:\nfor i = 1 : 3 do\n    for j = 1 : m do\n        Hitung Rumus1 dengan f_j\n    endfor\n\n    for j = 1 : m do\n        Hitung Rumus2 dengan f_j\n    endfor\n\n    for j = 1 : m do\n        Hitung Rumus3 dengan f_j\n    endfor\n\n    for j = 1 : m do\n        Hitung Rumus4 dengan f_j\n    endfor\n\n    for j = 1 : m do\n        Hitung Rumus5 dengan f_j\n    endfor \nendfor\n\nfor i = 4 : N do\n    for j = 1 : m do\n        Hitung Rumus1 dengan f_j\n    endfor\n\n    for j = 1 : m do\n        Hitung Rumus2 dengan f_j\n    endfor\nendfor\n\n\nFunction file: (fourth-order) Runge-Kutta for systems\nPada modul ini, akan dibahas mengenai metode Runge-Kutta orde 4 untuk menyelesaikan sistem persamaan diferensial. Berikut merupakan code dari metode Runge-Kutta untuk sistem persamaan diferensial pada Octave yang perlu disimpan pada function file.\nUntuk dua PDB:\n\nFunction file rko4_sys2.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w1, w2] = rko4_sys2(f1, f2, a, b, N, alph1, alph2)\n  h = (b - a)/N;\n  t = w1 = w2 = [];\n  t(1) = a;\n  w1(1) = alph1;\n  w2(1) = alph2;\n  for i = 1:N\n    k11 = h * f1(t(i), w1(i), w2(i));\n    k12 = h * f2(t(i), w1(i), w2(i));\n\n    k21 = h * f1((t(i)+(h/2)), (w1(i)+(k11/2)), (w2(i)+(k12/2)));\n    k22 = h * f2((t(i)+(h/2)), (w1(i)+(k11/2)), (w2(i)+(k12/2)));\n\n    k31 = h * f1((t(i)+(h/2)), (w1(i)+(k21/2)), (w2(i)+(k22/2)));\n    k32 = h * f2((t(i)+(h/2)), (w1(i)+(k21/2)), (w2(i)+(k22/2)));\n\n    k41 = h * f1((t(i)+h), (w1(i)+k31), (w2(i)+k32));\n    k42 = h * f2((t(i)+h), (w1(i)+k31), (w2(i)+k32));\n\n    w1(i+1) = w1(i) + (k11 + 2*k21 + 2*k31 + k41)/6;\n    w2(i+1) = w2(i) + (k12 + 2*k22 + 2*k32 + k42)/6;\n    t(i+1) = a + i*h;\n  endfor\nendfunction\n\n\n\n\nUntuk m PDB:\n\nFunction file rko4_sysm.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = rko4_sysm(cell_f, a, b, N, alphas)\n  m = length(cell_f);\n\n  h = (b - a) / N;\n  t = zeros(N + 1, 1);\n  w = zeros(m, N + 1);\n  t(1) = a;\n  w(:, 1) = alphas;\n\n  k1 = zeros(m, 1);\n  k2 = zeros(m, 1);\n  k3 = zeros(m, 1);\n  k4 = zeros(m, 1);\n  for i = 1 : N\n    t(i + 1) = t(i) + h;\n\n    for j = 1 : m\n      k1(j) = h * cell_f{j}(t(i), w(:, i));\n    endfor\n\n    for j = 1 : m\n      k2(j) = h * cell_f{j}(t(i) + (h / 2), w(:, i) + (k1 / 2));\n    endfor\n\n    for j = 1 : m\n      k3(j) = h * cell_f{j}(t(i) + (h / 2), w(:, i) + (k2 / 2));\n    endfor\n\n    for j = 1 : m\n      k4(j) = h * cell_f{j}(t(i + 1), w(:, i) + k3);\n    endfor\n\n    for j = 1 : m\n      w(j, i + 1) = w(j, i) + (k1(j) + 2 * k2(j) + 2 * k3(j) + k4(j)) / 6;\n    endfor\n  endfor\nendfunction\n\n\n\n\n\n\nContoh sistem PD\n\\(u'_1 = -4u_1+3u_2+6, \\;u_1(0)=0\\)\n\\(u'_2 = -2.4u_1+1.6u_2+3.6, \\;u_2(0)=0\\)\nAkan diuji dengan \\(h=0.1\\) dan \\(0\\leq t \\leq 0.5\\)\nSolusi eksak:\n\\(u_1(t)=-3.375e^{-2t}+1.875e^{-0.4t}+1.5\\)\n\\(u_2(t) = -2.25e^{-2t}+2.25e^{-0.4t}\\)\nBerikut adalah code script file untuk menjalankan function metode Runge-Kutta untuk sistem PD di atas (menggunakan yang khusus dua persamaan):\n\nScript file coba_rko4_sys2.m - nama file bebas\n\n\n\nf1 = @(t, y1, y2) (-4*y1 + 3*y2 + 6);\nf2 = @(t, y1, y2) (-2.4*y1 + 1.6*y2 + 3.6);\n\na = 0;\nb = 0.5;\nN = 5;\nalph1 = 0;\nalph2 = 0;\n\n[t, w1, w2] = rko4_sys2(f1, f2, a, b, N, alph1, alph2);\n\nsln1 = @(t) (-3.375*exp(-2*t) + 1.875*exp(-0.4*t) + 1.5);\nsln2 = @(t) (-2.25*exp(-2*t) + 2.25*exp(-0.4*t));\n\nw1ex = w2ex = [];\nfor i = 1:length(t)\n  w1ex(i) = sln1(t(i));\n  w2ex(i) = sln2(t(i));\nendfor\n\n[t', w1', w2', w1ex', w2ex']\n\nhold on;\nfplot(sln1, [a, b], 'r');\nfplot(sln2, [a, b], 'b');\nscatter(t, w1, 'r');\nscatter(t, w2, 'b');\nlegend('u1', 'u2');\nlegend('location', 'northwest');\n\n\n\n\nJika kita run script file tersebut, maka program akan mengeluarkan dua macam output, yaitu tabel serta plot perbandingan solusi eksak dan aproksimasi seperti di bawah ini:\n\n\n\nimage.png\n\n\n\n\n\nimage-3.png\n\n\nBerikut conoth script file menggunakan kode yang untuk m persamaan.\n\nScript file coba_rko4_sysm.m - nama file bebas\n\n\n\nf1 = @(t, u) (-4*u(1) + 3*u(2) + 6);\nf2 = @(t, u) (-2.4*u(1) + 1.6*u(2) + 3.6);\n\na = 0;\nb = 0.5;\nN = 5;\nalpha1 = 0;\nalpha2 = 0;\n\n[t, w] = rko4_sysm({f1, f2}, a, b, N, [alpha1, alpha2]);\n\nsln1 = @(t) (-3.375*exp(-2*t) + 1.875*exp(-0.4*t) + 1.5);\nsln2 = @(t) (-2.25*exp(-2*t) + 2.25*exp(-0.4*t));\n\nu1_eksak = sln1(t);\nu2_eksak = sln2(t);\n\n[t, w', u1_eksak, u2_eksak]\n\nhold on;\nfplot(sln1, [a, b], 'r');\nscatter(t, w(1, :), 'r'); % ambil baris pertama yaitu solusi u1\nfplot(sln2, [a, b], 'b');\nscatter(t, w(2, :), 'b'); % ambil baris kedua yaitu solusi u2\nlegend('u1 (eksak)', 'w1,i', 'u2 (eksak)', 'w2,i');\nlegend('location', 'northwest');\n\nans =\n\n        0        0        0        0        0\n   0.1000   0.5383   0.3196   0.5383   0.3196\n   0.2000   0.9685   0.5688   0.9685   0.5688\n   0.3000   1.3107   0.7607   1.3107   0.7607\n   0.4000   1.5813   0.9063   1.5813   0.9063\n   0.5000   1.7935   1.0144   1.7935   1.0144\n\n\n\n\n\n\n\n\n\n\n\n\n\nSebenarnya, kita bisa saja menampilkan dua plot yang terpisah, menggunakan perintah figure. Selain itu, tabelnya juga bisa dipisah antara tabel untuk \\(u_1\\) dan tabel untuk \\(u_2\\), sekaligus menghitung dan menampilkan error.\n\nScript file coba2_rko4_sysm.m - nama file bebas\n\n\n\nf1 = @(t, u) (-4*u(1) + 3*u(2) + 6);\nf2 = @(t, u) (-2.4*u(1) + 1.6*u(2) + 3.6);\n\na = 0;\nb = 0.5;\nN = 5;\nalpha1 = 0;\nalpha2 = 0;\n\n[t, w] = rko4_sysm({f1, f2}, a, b, N, [alpha1, alpha2]);\n\nsln1 = @(t) (-3.375*exp(-2*t) + 1.875*exp(-0.4*t) + 1.5);\nsln2 = @(t) (-2.25*exp(-2*t) + 2.25*exp(-0.4*t));\n\nu1_eksak = sln1(t);\nu2_eksak = sln2(t);\n\n% menghitung error\nerr_w1 = abs(w(1, :)' - u1_eksak);\nerr_w2 = abs(w(2, :)' - u2_eksak);\nerr_w1_total = sum(err_w1); % norm L1 (taxicab/Manhattan)\nerr_w2_total = sum(err_w2); % norm L1 (taxicab/Manhattan)\n\n% menampilkan tabel, termasuk error\nformat long;\ndisp(\"Tabel aproksimasi w1,i, solusi eksak u1(t), dan error:\");\n[t, w(1, :)', u1_eksak, err_w1]\ndisp(\"Tabel aproksimasi w2,i, solusi eksak u2(t), dan error:\");\n[t, w(2, :)', u2_eksak, err_w2]\ndisp(\"Error total (norm L1) untuk w1,i:\");\ndisp(err_w1_total);\ndisp(\"Error total (norm L1) untuk w2,i:\");\ndisp(err_w2_total);\nformat;\n\nfigure;\nhold on;\nfplot(sln1, [a, b], 'g');\nscatter(t, w(1, :), 'r'); % ambil baris pertama yaitu solusi u1\ntitle(\"Aproksimasi u1\");\nlegend(\"u1 (eksak)\", \"w1,i (aproksimasi)\")\nlegend('location', 'northwest');\n\nfigure;\nhold on;\nfplot(sln2, [a, b], 'g');\nscatter(t, w(2, :), 'b'); % ambil baris kedua yaitu solusi u2\ntitle(\"Aproksimasi u2\");\nlegend(\"u2 (eksak)\", \"w2,i (aproksimasi)\")\nlegend('location', 'northwest');\n\nTabel aproksimasi w1,i, solusi eksak u1(t), dan error:\nans =\n\n                   0                   0                   0                   0\n   0.100000000000000   0.538255200000000   0.538263906772417   0.000008706772417\n   0.200000000000000   0.968498737529088   0.968512994104659   0.000014256575571\n   0.300000000000000   1.310719039205257   1.310736547027331   0.000017507822074\n   0.400000000000000   1.581265238963142   1.581284350416023   0.000019111452881\n   0.500000000000000   1.793507490120283   1.793527048067598   0.000019557947315\n\nTabel aproksimasi w2,i, solusi eksak u2(t), dan error:\nans =\n\n                   0                   0                   0                   0\n   0.100000000000000   0.319626240000000   0.319632043667268   0.000005803667268\n   0.200000000000000   0.568782173034906   0.568791675789742   0.000009502754836\n   0.300000000000000   0.760733131868175   0.760744801402045   0.000011669533870\n   0.400000000000000   0.906320617948927   0.906333355910227   0.000012737961300\n   0.500000000000000   1.014402416769883   1.014415451789714   0.000013035019830\n\nError total (norm L1) untuk w1,i:\n7.914057025892873e-05\nError total (norm L1) untuk w2,i:\n5.274893710444095e-05"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul5.html#sistem-persamaan-diferensial-contoh-metode-lainnya",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul5.html#sistem-persamaan-diferensial-contoh-metode-lainnya",
    "title": "Modul 5 Persamaan Diferensial Numerik: Sistem PDB orde 1 dan PDB orde tinggi",
    "section": "Sistem Persamaan Diferensial: Contoh Metode Lainnya",
    "text": "Sistem Persamaan Diferensial: Contoh Metode Lainnya\n\nUntuk metode Taylor orde \\(n\\)\n\nfunction [t, w] = taylor_sysm(cell_f, cell_fp, a, b, N, alphas)\n  m = length(cell_f);\n  \n  h = (b - a) / N;\n  n = length(cell_fp{1}) + 1;\n  t = zeros(N + 1, 1);\n  w = zeros(m, N + 1);\n  t(1) = a;\n  w(:, 1) = alphas;\n  for i = 1 : N\n    t(i + 1) = t(i) + h;\n    \n    for j = 1 : m\n      T = cell_f{j}(t(i), w(:, i));\n      for p = 2 : n\n        T += h^(p-1) * cell_fp{j}{p-1}(t(i), w(:, i)) / factorial(p);\n      endfor\n      w(j, i + 1) = w(j, i) + h * T;\n    endfor\n  endfor\nendfunction\n\nMencoba untuk masalah yang sama, misalnya dengan n=1 (metode Euler):\n\nf1 = @(t, u) (-4*u(1) +3*u(2) + 6);\nf2 = @(t, u) (-2.4*u(1) + 1.6*u(2) + 3.6);\n\na = 0;\nb = 0.5;\nh = 0.1;\nN = (b - a) / 0.1;\nalpha1 = 0;\nalpha2 = 0;\n\n[t, w] = taylor_sysm({f1, f2}, {{}, {}}, a, b, N, [alpha1, alpha2]);\n\nsln1 = @(t) (-3.375*exp(-2*t) + 1.875*exp(-0.4*t) + 1.5);\nsln2 = @(t) (-2.25*exp(-2*t) + 2.25*exp(-0.4*t));\n\nu1_eksak = sln1(t);\nu2_eksak = sln2(t);\n\n[t, w', u1_eksak, u2_eksak]\n\nfigure;\nhold on;\nfplot(sln1, [a,b], 'r');\nscatter(t, w(1, :), 'r');\ntitle(\"u1\");\n\nfigure;\nhold on;\nfplot(sln2, [a,b], 'b');\nscatter(t, w(2, :), 'b');\ntitle(\"u2\");\n\nans =\n\n        0        0        0        0        0\n   0.1000   0.6000   0.3600   0.5383   0.3196\n   0.2000   1.0680   0.6336   0.9685   0.5688\n   0.3000   1.4309   0.8387   1.3107   0.7607\n   0.4000   1.7101   0.9894   1.5813   0.9063\n   0.5000   1.9229   1.0973   1.7935   1.0144\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUntuk metode Adams predictor-corrector orde 4\n\nfunction [t, w] = adams_pc_orde4_sysm(cell_f, a, b, N, alphas)\n  m = length(cell_f);\n  \n  % Inisiasi variabel awal\n  h = (b - a) / N;\n  t = zeros(N + 1, 1);\n  w = zeros(m, N + 1);\n  t(1) = a;\n  w(:, 1) = alphas;\n  \n  % Hitung w(2), w(3), w(4) menggunakan metode Runge-Kutta orde 4\n  k1 = zeros(m, 1);\n  k2 = zeros(m, 1);\n  k3 = zeros(m, 1);\n  k4 = zeros(m, 1);\n  for i = 1 : 3\n      t(i + 1) = t(i) + h;\n      \n      for j = 1 : m\n        k1(j) = h * cell_f{j}(t(i), w(:,i));\n      endfor\n      \n      for j = 1 : m\n        k2(j) = h * cell_f{j}(t(i) + (h/2), w(:,i) + (k1/2));\n      endfor\n      \n      for j = 1 : m\n        k3(j) = h * cell_f{j}(t(i) + (h/2), w(:,i) + (k2/2));\n      endfor\n      \n      for j = 1 : m\n        k4(j) = h * cell_f{j}(t(i + 1), w(:,i) + k3);\n      endfor\n      \n      for j = 1 : m\n        w(j,i+1) = w(j,i) + (k1(j) + 2*k2(j) + 2*k3(j) + k4(j)) / 6;\n      endfor\n  endfor\n  \n  % Algoritma utama Adams Predictor-Corrector orde 4\n  m0 = zeros(m, 1);\n  m1 = zeros(m, 1);\n  m2 = zeros(m, 1);\n  m3 = zeros(m, 1);\n  m4 = zeros(m, 1);\n  for i = 4 : N\n    t(i + 1) = t(i) + h;\n    \n    for j = 1 : m\n      m1(j) = cell_f{j}(t(i), w(:,i));\n    endfor\n    \n    for j = 1 : m\n      m2(j) = cell_f{j}(t(i-1), w(:,i-1));\n    endfor \n    \n    for j = 1 : m\n      m3(j) = cell_f{j}(t(i-2), w(:,i-2));\n    endfor\n    \n    for j = 1 : m\n      m4(j) = cell_f{j}(t(i-3), w(:,i-3));\n    endfor\n    \n    % Adams-Bashforth orde 4 (four-step)\n    for j = 1 : m\n      w(j,i+1) = w(j,i) + (h/24) * (55*m1(j) - 59*m2(j) + 37*m3(j) - 9*m4(j));\n    endfor\n    % Adams-Moulton orde 4 (three-step)\n    for j = 1 : m\n      m0(j) = cell_f{j}(t(i+1), w(:,i+1));\n    endfor\n    for j = 1 : m\n      w(j,i+1) = w(j,i) + (h/24) * (9*m0(j) + 19*m1(j) - 5*m2(j) + m3(j));\n    endfor\n  endfor\nendfunction\n\nMencoba untuk masalah yang sama:\n\nf1 = @(t, u) (-4*u(1) +3*u(2) + 6);\nf2 = @(t, u) (-2.4*u(1) + 1.6*u(2) + 3.6);\n\na = 0;\nb = 0.5;\nh = 0.1;\nN = (b - a) / 0.1;\nalpha1 = 0;\nalpha2 = 0;\n\n[t, w] = adams_pc_orde4_sysm({f1, f2}, a, b, N, [alpha1, alpha2]);\n\nsln1 = @(t) (-3.375*exp(-2*t) + 1.875*exp(-0.4*t) + 1.5);\nsln2 = @(t) (-2.25*exp(-2*t) + 2.25*exp(-0.4*t));\n\nu1_eksak = sln1(t);\nu2_eksak = sln2(t);\n\n[t, w', u1_eksak, u2_eksak]\n\nfigure;\nhold on;\nfplot(sln1, [a,b], 'r');\nscatter(t, w(1, :), 'r');\ntitle(\"u1\");\n\nfigure;\nhold on;\nfplot(sln2, [a,b], 'b');\nscatter(t, w(2, :), 'b');\ntitle(\"u2\");\n\nans =\n\n        0        0        0        0        0\n   0.1000   0.5383   0.3196   0.5383   0.3196\n   0.2000   0.9685   0.5688   0.9685   0.5688\n   0.3000   1.3107   0.7607   1.3107   0.7607\n   0.4000   1.5813   0.9063   1.5813   0.9063\n   0.5000   1.7936   1.0144   1.7935   1.0144"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul7.html",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul7.html",
    "title": "Modul 7 Persamaan Diferensial Numerik: Nonlinear Finite Difference, PDP Eliptik & Hiperbolik",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\nMelanjutkan dari modul sebelumnya, untuk masalah nilai batas PDB, kita akan membahas metode\nKemudian, kita akan membahas metode numerik untuk menyelesaikan PDP (persamaan diferensial parsial) orde 2"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul7.html#nonlinear-finite-difference",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul7.html#nonlinear-finite-difference",
    "title": "Modul 7 Persamaan Diferensial Numerik: Nonlinear Finite Difference, PDP Eliptik & Hiperbolik",
    "section": "Nonlinear Finite Difference",
    "text": "Nonlinear Finite Difference\nMetode ini digunakan untuk mengaproksimasi masalah nilai batas:\n\\[\n\\begin{gathered}\ny^{\\prime \\prime}=f\\left(x, y, y^{\\prime}\\right), \\quad a \\leq x \\leq b \\\\\ny(a)=\\alpha, \\quad y(b)=\\beta\n\\end{gathered}\n\\]\ndengan \\(f\\) boleh berupa fungsi linier maupun nonlinier.\nMetode ini bersifat iteratif, memanfaatkan yang namanya “metode Newton untuk sistem” yang dibahas di subbab 10.2 buku Burden, yang dibahas di mata kuliah Matematika Numerik. Daripada membahas secara umum mengenai metode Newton untuk sistem, kita cukup membahas bagaimana langkah-langkah metodenya khusus dalam penerapannya sebagai metode nonlinear finite difference untuk menyelesaikan masalah nilai batas.\nLangkah-langkah metode nonlinear finite difference bisa ditulis sebagai berikut:\n\nHitung rumus \\(f_y(x,y,y')\\) (yaitu \\(\\frac{\\partial f}{\\partial y}(x,y,y')\\)) dan rumus \\(f_{y'}(x,y,y')\\) (yaitu \\(\\frac{\\partial f}{\\partial y'}(x,y,y')\\)) secara analitik.\nTentukan toleransi \\(\\varepsilon\\), dan/atau maksimum banyaknya iterasi \\(M\\).\nPastikan nilai \\(N\\) dan step size \\(h\\) sudah dimiliki. Biasanya hanya salah satu nilai yang diberikan (biasanya \\(N\\)). Hubungan antara keduanya adalah\n\\[h = \\frac{b-a}{N+1}\\]\nIngat bahwa \\(w_0 = \\alpha\\) dan \\(w_{N+1} = \\beta\\). Kita perlu menentukan nilai-nilai \\(w_1, \\dots, w_N\\). Untuk nilai-nilai tersebut, pasang tebakan awal, berupa nilai-nilai di antara \\(\\alpha\\) dan \\(\\beta\\), sebagai berikut untuk \\(i = 1, \\dots, N\\):\n\\[w_i = \\alpha + i\\left(\\frac{\\beta - \\alpha}{b-a}\\right)h\\]\nSusun suatu matriks tridiagonal berukuran \\(N \\times N\\) yang dinamakan matriks Jacobian, dengan entri \\[J_{ij} = \\begin{cases}\n     -\\left(1 + \\frac{h}{2} f_{y'} \\left(x_i, w_i, \\frac{w_{i+1} - w_{i-1}}{2h}\\right)\\right) & \\text{di bawah/kiri diagonal, baris ke-$i$} \\\\\n     2 + h^2 f_{y} \\left(x_i, w_i, \\frac{w_{i+1} - w_{i-1}}{2h}\\right) & \\text{di diagonal, baris ke-$i$} \\\\\n     -\\left(1 - \\frac{h}{2} f_{y'} \\left(x_i, w_i, \\frac{w_{i+1} - w_{i-1}}{2h}\\right) \\right) & \\text{di atas/kanan diagonal, barsi ke-$i$} \\\\\n     0 & \\text{untuk semua elemen lainnya}\n\\end{cases}\\]\nSusun vektor kolom bernama \\(d\\) dengan \\(N\\) baris, yang isinya sebagai berikut untuk \\(i = 1, \\dots, N\\): \\[d_i = -w_{i-1} + 2w_i - w_{i+1} + h^2 f\\left(x_i, w_i, \\frac{w_{i+1}-w_{i-1}}{2h}\\right)\\]\nSelesaikan SPL \\(Jv = -d\\) (iya pakai minus), di mana vektor \\(v\\) berisi nilai-nilai \\(v_1,\\dots,v_N\\) yang ingin diperoleh. Metode penyelesaian SPLnya terserah.\nPerbarui vektor \\(w\\) dengan menambahkan vektor \\(v\\). Yaitu, nilai \\(w_1\\) ditambahkan \\(v_1\\), nilai \\(w_2\\) ditambahkan \\(v_2\\), dan seterusnya.\nSampai sini, selesai satu iterasi. Periksa apakah \\(\\left|\\left|v\\right|\\right| \\le \\varepsilon\\) (atau periksa apakah sudah memenuhi banyaknya iterasi yang diminta). Kalau sudah terpenuhi, metode selesai. Kalau belum, masuk ke iterasi selanjutnya, yaitu melanjutkan kembali dari langkah 5, dengan nilai-nilai \\(w_1, \\dots, w_N\\) terbaru.\n\n\nFunction file (dengan solusi SPL secara langsung)\nBerikut ini, matriks Jacobian disusun dengan mempertimbangkan tiap elemen matriks, sehingga kompleksiasnya bisa dianggap \\(O(N^2)\\):\n\nFunction file nonlinear_fd_langsung_on2.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x_grid, w_grid] = nonlinear_fd_langsung_on2(f, fy, fyp, a, b, N, alph, bet, tol, M)\n  h = (b-a) / (N+1);\n  x_grid = (a : h : b)'; % transpos juga agar menjadi vektor kolom\n  x = x_grid(2 : N+1);\n  w = zeros(N, 1);\n  for i = 1 : N\n    w(i) = alph + i * ((bet - alph)/(b-a)) * h;\n  endfor\n  \n  % banyaknya iterasi\n  k = 1;\n\n  err = tol + 1;\n  % selama belum memenuhi toleransi ataupun mencapai batas iterasi\n  while (!(err &lt;= tol) && k != M+1)\n    % menyusun matriks Jacobian\n    matriks_J = zeros(N, N);\n    for i = 1 : N\n      for j = 1 : N\n        if (i == j+1) % kiri/bawah diagonal\n          if (i == 1) % w(0) = alfa\n            matriks_J(i, j) = -(1 + h/2 * fyp(x(i), w(i), (w(i+1) - alph)/(2*h)));\n          elseif (i == N) % w(N+1) = beta\n            matriks_J(i, j) = -(1 + h/2 * fyp(x(i), w(i), (bet - w(i-1))/(2*h)));\n          else\n            matriks_J(i, j) = -(1 + h/2 * fyp(x(i), w(i), (w(i+1) - w(i-1))/(2*h)));\n          endif\n        elseif (i == j) % pada diagonal\n          if (i == 1) % w(0) = alfa\n            matriks_J(i, j) = 2 + h^2 * fy(x(i), w(i), (w(i+1) - alph)/(2*h));\n          elseif (i == N) % w(N+1) = beta\n            matriks_J(i, j) = 2 + h^2 * fy(x(i), w(i), (bet - w(i-1))/(2*h));\n          else\n            matriks_J(i, j) = 2 + h^2 * fy(x(i), w(i), (w(i+1) - w(i-1))/(2*h));\n          endif\n        elseif (i == j-1) % kanan/atas diagonal\n          if (i == 1) % w(0) = alfa\n            matriks_J(i, j) = -(1 - h/2 * fyp(x(i), w(i), (w(i+1) - alph)/(2*h)));\n          elseif (i == N) % w(N+1) = beta\n            matriks_J(i, j) = -(1 - h/2 * fyp(x(i), w(i), (bet - w(i-1))/(2*h)));\n          else\n            matriks_J(i, j) = -(1 - h/2 * fyp(x(i), w(i), (w(i+1) - w(i-1))/(2*h)));\n          endif\n        else\n          matriks_J(i, j) = 0;\n        endif\n      endfor\n    endfor\n    \n    % menyusun vektor d\n    d = zeros(N, 1);\n    % khusus baris pertama\n    i = 1;\n    d(i) = -alph + 2 * w(i) - w(i+1) + h^2 * f(x(i), w(i), (w(i+1) - alph)/(2*h));\n    for i = 2 : (N-1)\n      d(i) = -w(i-1) + 2 * w(i) - w(i+1) + h^2 * f(x(i), w(i), (w(i+1) - w(i-1))/(2*h));\n    endfor\n    % khusus baris terakhir\n    i = N;\n    d(i) = -w(i-1) + 2 * w(i) - bet + h^2 * f(x(i), w(i), (bet - w(i-1))/(2*h));\n    \n    % selesaikan SPL\n    v = matriks_J \\ (-d);\n    \n    % update w\n    w = w + v;\n\n    % hitung error dengan norm Euclid\n    err = sum(v.^2);\n\n    k += 1; % lanjut ke iterasi selanjutnya\n  endwhile\n\n  % gabungkan w_0 (alfa), dengan w_1, ..., w_N, dengan w_{N+1} (beta)\n  w_grid = [alph; w; bet];\nendfunction\n\n\n\n\nDaripada mempertimbangkan tiap elemen di matriks Jacobian, kita bisa isi matriksnya dengan nol semua terlebih dahulu, kemudian melihat per baris saja dan hanya mempertimbangkan elemen diagonal dan kolom sebelum/setelah diagonal (karena matriksnya tridiagonal). Kodenya menjadi seperti berikut:\n\nFunction file nonlinear_fd_langsung.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x_grid, w_grid] = nonlinear_fd_langsung(f, fy, fyp, a, b, N, alph, bet, tol, M)\n  h = (b-a) / (N+1);\n  x_grid = (a : h : b)'; % transpos juga agar menjadi vektor kolom\n  x = x_grid(2 : N+1);\n  w = zeros(N, 1);\n  for i = 1 : N\n    w(i) = alph + i * ((bet - alph)/(b-a)) * h;\n  endfor\n  \n  % banyaknya iterasi\n  k = 1;\n\n  err = tol + 1;\n  % selama belum memenuhi toleransi ataupun mencapai batas iterasi\n  while (!(err &lt;= tol) && k != M+1)\n    % menyusun matriks Jacobian\n    matriks_J = zeros(N, N); % isi nol semua dulu\n    for i = 1 : N % untuk tiap baris ke-i, dengan i = 1, ..., N\n      % kiri/bawah diagonal (kecuali di baris pertama)\n      if (i == N) % w(N+1) = beta\n        matriks_J(i, i-1) = -(1 + h/2 * fyp(x(i), w(i), (bet - w(i-1))/(2*h)));\n      elseif (i != 1) % rumus biasa\n        matriks_J(i, i-1) = -(1 + h/2 * fyp(x(i), w(i), (w(i+1) - w(i-1))/(2*h)));\n      endif\n\n      % pada diagonal\n      if (i == 1) % w(0) = alfa\n        matriks_J(i, i) = 2 + h^2 * fy(x(i), w(i), (w(i+1) - alph)/(2*h));\n      elseif (i == N) % w(N+1) = beta\n        matriks_J(i, i) = 2 + h^2 * fy(x(i), w(i), (bet - w(i-1))/(2*h));\n      else % rumus biasa\n        matriks_J(i, i) = 2 + h^2 * fy(x(i), w(i), (w(i+1) - w(i-1))/(2*h));\n      endif\n\n      % kanan/atas diagonal (kecuali di baris terakhir)\n      if (i == 1) % w(0) = alfa\n        matriks_J(i, i+1) = -(1 - h/2 * fyp(x(i), w(i), (w(i+1) - alph)/(2*h)));\n      elseif (i != N) % rumus biasa\n        matriks_J(i, i+1) = -(1 - h/2 * fyp(x(i), w(i), (w(i+1) - w(i-1))/(2*h)));\n      endif\n    endfor\n    \n    % menyusun vektor d\n    d = zeros(N, 1);\n    % khusus baris pertama\n    i = 1;\n    d(i) = -alph + 2 * w(i) - w(i+1) + h^2 * f(x(i), w(i), (w(i+1) - alph)/(2*h));\n    for i = 2 : (N-1)\n      d(i) = -w(i-1) + 2 * w(i) - w(i+1) + h^2 * f(x(i), w(i), (w(i+1) - w(i-1))/(2*h));\n    endfor\n    % khusus baris terakhir\n    i = N;\n    d(i) = -w(i-1) + 2 * w(i) - bet + h^2 * f(x(i), w(i), (bet - w(i-1))/(2*h));\n    \n    % selesaikan SPL\n    v = matriks_J \\ (-d);\n    \n    % update w\n    w = w + v;\n\n    % hitung error dengan norm L2 (Euclid)\n    err = sum(v.^2);\n\n    k += 1; % lanjut ke iterasi selanjutnya\n  endwhile\n\n  % gabungkan w_0 (alfa), dengan w_1, ..., w_N, dengan w_{N+1} (beta)\n  w_grid = [alph; w; bet];\nendfunction\n\n\n\n\n\n\nContoh 1\nGunakan metode beda hingga nonlinier (nonlinear finite difference) dengan \\(h=0.1\\) dan toleransi \\(10^{-4}\\) untuk mengaproksimasi Boundary Value Problem (BVP) / Masalah Nilai Batas (MNB) berikut: \\[\n\\begin{aligned}\ny^{\\prime \\prime} & =y^{\\prime}+2(y-\\ln x)^3-\\frac{1}{x}, \\quad 2 \\leq x \\leq 3 \\\\\ny(2) & =\\frac{1}{2}+\\ln 2, \\quad y(3)=\\frac{1}{3}+\\ln 3\n\\end{aligned}\n\\]\nSolusi eksak:\n\\[y(x)=\\frac{1}{x}+\\ln x\\]\nHint:\n\\[y'' = f\\left(x,y,y'\\right) = y'+2(y-\\ln x)^3-\\frac{1}{x}\\]\n\\[f_{y}\\left(x,y,y'\\right) = \\frac{\\partial f}{\\partial y} \\left(x,y,y'\\right) = 6\\left(y - \\ln{x}\\right)^2\\]\n\\[f_{y'}\\left(x,y,y'\\right) = \\frac{\\partial f}{\\partial y'} \\left(x,y,y'\\right) = 1\\]\n\nScript file coba_nonlinear_fd_langsung.m - nama file bebas\n\n\n\nf = @(x,y,yp) yp + 2*(y-log(x)).^3 - 1./x ; % fungsi f pada y=f(x,y,y')\nfy = @(x,y,yp) 6*(y-log(x)).^2; % turunan fungsi f terhadap y\nfyp = @(x,y,yp) 1; % turunan fungsi f terhadap y prime, yaitu y'\na = 2; % left boundary\nb = 3; % right boundary\nN = 9; % banyaknya partisi (pilih N=9 sehingga h=0.1)\nalph = 0.5 + log(2); % y(a)\nbet = 1/3 + log(3); % y(b)\ntol = 10^(-4); % toleransi nilai (untuk kriteria stop)\nM = 30; % maksimum iterasi\n\n[x_grid, w_grid] = nonlinear_fd_langsung(f, fy, fyp, a, b, N, alph, bet, tol, M);\n\n% solusi eksak\nsln = @(x) 1./x + log(x);\ny_eksak = sln(x_grid);\n\n% menghitung error\nerr_w = abs(y_eksak - w_grid);\nerr_total = sum(err_w); % norm L1 (taxicab/Manhattan)\n\n% tampilkan tabel\nformat long;\ndisp(\"Tabel aproksimasi, solusi y(x), dan error:\");\n[x_grid, w_grid, y_eksak, err_w]\ndisp(\"Error total (norm L1):\");\ndisp(err_total);\nformat;\n\nhold on;\nfplot(sln, [a, b], 'k');\nscatter(x_grid, w_grid, 'r');\ntitle(\"Aproksimasi y(x)\");\nlegend(\"Eksak\", \"Aproksimasi\");\nlegend(\"location\", \"northwest\");\n\nTabel aproksimasi, solusi y(x), dan error:\nans =\n\n   2.000000000000000   1.193147180559945   1.193147180559945                   0\n   2.100000000000000   1.218136665897076   1.218127820919853   0.000008844977223\n   2.200000000000000   1.243017438585886   1.243002814909725   0.000014623676161\n   2.300000000000000   1.267709758540398   1.267691731630756   0.000018026909642\n   2.400000000000000   1.292154898557824   1.292135404020567   0.000019494537257\n   2.500000000000000   1.316310046093640   1.316290731874155   0.000019314219485\n   2.600000000000000   1.340144522402694   1.340126829642821   0.000017692759873\n   2.700000000000000   1.363636945192896   1.363622143380654   0.000014801812242\n   2.800000000000000   1.386773073873609   1.386762274324015   0.000010799549594\n   2.900000000000000   1.409544153003318   1.409538323199325   0.000005829803994\n   3.000000000000000   1.431945622001443   1.431945622001443                   0\n\nError total (norm L1):\n1.294282454702422e-04\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContoh 2\nSelesaikan maslaah nilai batas berikut\n\\[y'' = \\frac{1}{8} \\left(32 + 2x^3 - yy'\\right), \\quad 1 \\le x \\le 3\\] \\[y(1) = 17, \\quad y(3) = \\frac{43}{3}\\]\ndengan \\(h=0.1\\), toleransi \\(10^{-8}\\), dan maksimum iterasi \\(M=30\\). Bandingkan hasilnya dengan solusi eksak\n\\[y(x) = x^2 + \\frac{16}{x}\\]\nHint:\n\\[y'' = f(x, y, y') = \\frac{1}{8} \\left(32 + 2x^3 - yy'\\right)\\]\n\\[f_{y} (x, y, y') = \\frac{\\partial f}{\\partial y} (x, y, y') = -\\frac{1}{8} y'\\]\n\\[f_{y'} (x, y, y') = \\frac{\\partial f}{\\partial y'} (x, y, y') = -\\frac{1}{8} y\\]\n\nScript file coba2_nonlinear_fd_langsung.m - nama file bebas\n\n\n\nf = @(x, y, yp) ((1/8)*(32 + 2 * x.^3 - y .* yp));\nfy = @(x, y, yp) (-yp/8);\nfyp = @(x, y, yp) (-y/8);\na = 1;\nb = 3;\nh = 0.1;\nN = (b - a)/h - 1;\nalph = 17;\nbet = 43/3;\ntol = 10^(-8);\nM = 30;\n\n[x_grid, w_grid] = nonlinear_fd_langsung(f, fy, fyp, a, b, N, alph, bet, tol, M);\n\n% solusi eksak\nsln = @(x) ((x .^ 2) + ((16 ./ x)));\ny_eksak = sln(x_grid);\n\n% menghitung error\nerr_w = abs(y_eksak - w_grid);\nerr_total = sum(err_w); % norm L1 (taxicab/Manhattan)\n\n% tampilkan tabel\nformat long;\ndisp(\"Tabel aproksimasi, solusi y(x), dan error:\");\n[x_grid, w_grid, y_eksak, err_w]\ndisp(\"Error total (norm L1):\");\ndisp(err_total);\nformat;\n\nhold on;\nfplot(sln, [a, b], 'k');\nscatter(x_grid, w_grid, 'r');\ntitle(\"Aproksimasi y(x)\");\nlegend(\"Eksak\", \"Aproksimasi\");\nlegend('location', 'northeast');\n\nTabel aproksimasi, solusi y(x), dan error:\nans =\n\n Columns 1 through 3:\n\n   1.000000000000000e+00   1.700000000000000e+01   1.700000000000000e+01\n   1.100000000000000e+00   1.575450253529389e+01   1.575545454545455e+01\n   1.200000000000000e+00   1.477173965356983e+01   1.477333333333333e+01\n   1.300000000000000e+00   1.399567743713438e+01   1.399769230769231e+01\n   1.400000000000000e+00   1.338629656205142e+01   1.338857142857143e+01\n   1.500000000000000e+00   1.291425241252499e+01   1.291666666666667e+01\n   1.600000000000000e+00   1.255753822750665e+01   1.256000000000000e+01\n   1.700000000000000e+00   1.229932628240154e+01   1.230176470588235e+01\n   1.800000000000000e+00   1.212652886701783e+01   1.212888888888889e+01\n   1.900000000000000e+00   1.202881380980783e+01   1.203105263157895e+01\n   2.000000000000000e+00   1.199791542246045e+01   1.200000000000000e+01\n   2.100000000000000e+00   1.202714237122990e+01   1.202904761904762e+01\n   2.200000000000000e+00   1.211101980435058e+01   1.211272727272727e+01\n   2.300000000000000e+00   1.224502486731439e+01   1.224652173913043e+01\n   2.400000000000000e+00   1.242538836268850e+01   1.242666666666667e+01\n   2.500000000000000e+00   1.264894403015380e+01   1.265000000000000e+01\n   2.600000000000000e+00   1.291301262278355e+01   1.291384615384615e+01\n   2.700000000000000e+00   1.321531175549766e+01   1.321592592592593e+01\n   2.800000000000000e+00   1.355388507997838e+01   1.355428571428571e+01\n   2.900000000000000e+00   1.392704611844152e+01   1.392724137931035e+01\n   3.000000000000000e+00   1.433333333333333e+01   1.433333333333333e+01\n\n Column 4:\n\n                       0\n   9.520101606579345e-04\n   1.593679763500333e-03\n   2.014870557925263e-03\n   2.274866520011187e-03\n   2.414254141680061e-03\n   2.461772493353109e-03\n   2.438423480807472e-03\n   2.360021871062656e-03\n   2.238821771113564e-03\n   2.084577539545052e-03\n   1.905247817717282e-03\n   1.707468376690002e-03\n   1.496871816048184e-03\n   1.278303978164530e-03\n   1.055969846202487e-03\n   8.335310626090831e-04\n   6.141704282711657e-04\n   4.006343073346130e-04\n   1.952608688231550e-04\n   1.776356839400250e-15\n\nError total (norm L1):\n3.032075680151891e-02"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul1.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul1.html",
    "title": "Modul 1 Sains Data: Pengenalan Pandas, Transformasi Data",
    "section": "",
    "text": "Kembali ke Sains Data"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#prerequisites",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#prerequisites",
    "title": "Modul 1 Sains Data: Pengenalan Pandas, Transformasi Data",
    "section": "Prerequisites",
    "text": "Prerequisites\nPada module ini kita akan coba mememahami package pandas, yang merupakan package inti dalam sains-data. kita akan coba melakukan beberapa transformasi data menggunakan pandas.\nsebelum itu, python module di bawah ini yang akan digunakan selama praktikum.\n\nimport numpy as np\nimport pandas as pd\n\nApabila ada yang belum terinstal, silakan instal terlebih dahulu menggunakan pip:\n!pip install numpy\n!pip install pandas\natau conda jika sedang menggunakan Anaconda:\nconda install numpy\nconda install pandas"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#series",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#series",
    "title": "Modul 1 Sains Data: Pengenalan Pandas, Transformasi Data",
    "section": "Series",
    "text": "Series\npandas.Series sangat mirip dengan array NumPy (bahkan dibangun di atas objek array NumPy). Yang membedakan array NumPy dari sebuah Series adalah bahwa sebuah Series dapat memiliki label index, yang berarti dapat diindeks dengan label, bukan hanya lokasi nomor saja. Selain itu, sebuah Series tidak perlu menyimpan data numerik, ia dapat menyimpan objek Python sembarang.\n\nMembuat pd.Series dengan list\nPaling mudah, ktia dapat membuat pd.Series dengan python list\n\nmy_index= ['a','b','c','d','e']\nmy_data= [1,2,3,4,5]\nmy_series= pd.Series(data=my_data, index=my_index)\n\n\nprint(my_series)\n\na    1\nb    2\nc    3\nd    4\ne    5\ndtype: int64\n\n\n\nprint(my_series.__class__)\n\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n\n\nMembuat pd.Series dengan dictionary\nKita juga dapat membuat pd.Series dengan dictionary\n\n# creating a series from a dictionary\nmy_dict= {'a':1, 'b':2, 'c':3, 'd':4, 'e':5}\nmy_series_dict= pd.Series(my_dict)\n\n\nprint(my_series_dict)\n\na    1\nb    2\nc    3\nd    4\ne    5\ndtype: int64\n\n\n\nprint(my_series_dict.__class__)\n\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n\n\nOperasi pada Series\n\n# Imaginary Sales Data for 1st and 2nd Quarters for Global Company\nq1 = {'Japan': 80, 'China': 450, 'India': 200, 'USA': 250}\nq2 = {'Brazil': 100,'China': 500, 'India': 210,'USA': 260}\n\n\n# Creating a Series from a Dictionary q1 and q2\nq1_series= pd.Series(q1)\nq2_series= pd.Series(q2)\n\n\nprint(q1_series)\n\nJapan     80\nChina    450\nIndia    200\nUSA      250\ndtype: int64\n\n\nKita dapat mengindeks dengan label\n\n# call values of q1_series based on named index\nprint(q1_series['Japan'])\nprint(q1_series['China'])\nprint(q1_series['India'])\n\n80\n450\n200\n\n\nkita dapat tetap dapat mengindeks dengan integer\n\n# u can also call values of q1_series based on positional index\nprint(q1_series[0])\nprint(q1_series[1])\nprint(q1_series[2])\n\n80\n450\n200\n\n\nhati-hati dalam melakukan indexing dengan label. bisa saja terjadi error jika label tidak ada di dalam pd.series\n\n# remember named index is case sensitive\ntry:\n    print(q1_series['japan'])\nexcept:\n    print('something went wrong')\n\nsomething went wrong\n\n\nOperasi aritmatik sederhana pada pd.Series bersifat broadcasting, yaitu diterapkan ke masing-masing elemen\n\n# operations with arithmetic on series are broadcasted to all values\nprint(q1_series*2)\n\nJapan    160\nChina    900\nIndia    400\nUSA      500\ndtype: int64\n\n\n\nprint(q1_series+1000)\n\nJapan    1080\nChina    1450\nIndia    1200\nUSA      1250\ndtype: int64\n\n\nUntuk penjumlahan antara dua pd.Series, apabila ada label yang hanya muncul di salah satu series, maka label tersebut akan muncul di hasil jumlah dengan data NaN (not a number, di sini artinya tidak ada data).\n(Kebetulan, keterangan NaN hanya bisa muncul untuk tipe data float atau koma-komaan, sehingga tipe data terpaksa diubah menjadi float.)\n\n# operation between series are also broadcasted\nprint(q1_series+q2_series)\n\nBrazil      NaN\nChina     950.0\nIndia     410.0\nJapan       NaN\nUSA       510.0\ndtype: float64\n\n\nMengapa tidak nol saja? Ketiadaan label pada salah satu series dianggap sebagai ketidaktahuan data untuk label tersebut, bukan dianggap nol.\nApabila diinginkan agar data yang tiada dianggap nol terlebih dahulu baru dijumlahkan, bisa seperti berikut:\n\nprint(q1_series.add(q2_series, fill_value=0))\n\nBrazil    100.0\nChina     950.0\nIndia     410.0\nJapan      80.0\nUSA       510.0\ndtype: float64"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#data-frame",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#data-frame",
    "title": "Modul 1 Sains Data: Pengenalan Pandas, Transformasi Data",
    "section": "data frame",
    "text": "data frame\nSebuah pd.DataFrame terdiri dari beberapa pd.Series yang berbagi nilai indeks.\nMisalkan kita punya data seperti berikut.\n\nmy_data = np.array([\n    [25, 59, 18],\n    [75, 54, 65],\n    [29, 21,  7],\n    [32, 68, 16]\n])\n\n\nmy_data\n\narray([[25, 59, 18],\n       [75, 54, 65],\n       [29, 21,  7],\n       [32, 68, 16]])\n\n\nKita akan membuat pd.Dataframe melalui python list. Perhatikan bahwa kita dapat memberikan nama pada kolom dan baris\n\nmy_index= [\"Toko A\", \"Toko B\", \"Toko C\", \"Toko D\"]\nmy_columns= [\"Apel\", \"Jeruk\", \"Pisang\"]\n\ndf= pd.DataFrame(data=my_data, index=my_index, columns=my_columns)\n\n\ndf\n\n\n\n\n\n\n\n\n\nApel\nJeruk\nPisang\n\n\n\n\nToko A\n25\n59\n18\n\n\nToko B\n75\n54\n65\n\n\nToko C\n29\n21\n7\n\n\nToko D\n32\n68\n16\n\n\n\n\n\n\n\n\n\ndf_2 = pd.DataFrame(data=my_data)\ndf_2\n\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n25\n59\n18\n\n\n1\n75\n54\n65\n\n\n2\n29\n21\n7\n\n\n3\n32\n68\n16\n\n\n\n\n\n\n\n\n\ndf_3 = pd.DataFrame(data=my_data, columns=my_columns)\ndf_3\n\n\n\n\n\n\n\n\n\nApel\nJeruk\nPisang\n\n\n\n\n0\n25\n59\n18\n\n\n1\n75\n54\n65\n\n\n2\n29\n21\n7\n\n\n3\n32\n68\n16\n\n\n\n\n\n\n\n\n\nmembaca file csv sebagai pd.DataFrame\nJika berkas .py atau .ipynb Anda berada di lokasi folder yang sama persis dengan berkas .csv yang ingin Anda baca, cukup berikan nama berkas sebagai string, misalnya:\ndf = pd.read_csv('some_file.csv')\nBerikan s berkas jika Anda berada di direktori yang berbeda. Jalur berkas harus 100% benar agar ini berfungsi. Misalnya:\ndf = pd.read_csv(\"C:\\\\Users\\\\myself\\\\files\\\\some_file.csv\")\nsebelum itu, kalian dapat mendownload dataset “Waiter’s Tips Dataset” melalui salah satu link berikut:\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle\nGoogle Drive\n\n\ndf_tips = pd.read_csv('./tips.csv')\n\n\ndf_tips\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\nSat1766\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\nSat3880\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\nSat17\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n9.39\nMichelle Hardin\n3511451626698139\nThur672\n\n\n\n\n244 rows × 11 columns\n\n\n\n\n\n\nOperasi sederhana pada DataFrame\n\n# mengecek nama kolom\ndf_tips.columns\n\nIndex(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size',\n       'price_per_person', 'Payer Name', 'CC Number', 'Payment ID'],\n      dtype='object')\n\n\n\n# mengecek \ndf_tips.index\n\nRangeIndex(start=0, stop=244, step=1)\n\n\n\ndf_tips.head()\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n\n\n\n\n\n\n\ndf_tips.head(10)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n5\n25.29\n4.71\nMale\nNo\nSun\nDinner\n4\n6.32\nErik Smith\n213140353657882\nSun9679\n\n\n6\n8.77\n2.00\nMale\nNo\nSun\nDinner\n2\n4.38\nKristopher Johnson\n2223727524230344\nSun5985\n\n\n7\n26.88\n3.12\nMale\nNo\nSun\nDinner\n4\n6.72\nRobert Buck\n3514785077705092\nSun8157\n\n\n8\n15.04\n1.96\nMale\nNo\nSun\nDinner\n2\n7.52\nJoseph Mcdonald\n3522866365840377\nSun6820\n\n\n9\n14.78\n3.23\nMale\nNo\nSun\nDinner\n2\n7.39\nJerome Abbott\n3532124519049786\nSun3775\n\n\n\n\n\n\n\n\n\ndf_tips.tail()\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\nSat1766\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\nSat3880\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\nSat17\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n9.39\nMichelle Hardin\n3511451626698139\nThur672\n\n\n\n\n\n\n\n\n\ndf_tips.tail(10)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n234\n15.53\n3.00\nMale\nYes\nSat\nDinner\n2\n7.76\nTracy Douglas\n4097938155941930\nSat7220\n\n\n235\n10.07\n1.25\nMale\nNo\nSat\nDinner\n2\n5.04\nSean Gonzalez\n3534021246117605\nSat4615\n\n\n236\n12.60\n1.00\nMale\nYes\nSat\nDinner\n2\n6.30\nMatthew Myers\n3543676378973965\nSat5032\n\n\n237\n32.83\n1.17\nMale\nYes\nSat\nDinner\n2\n16.42\nThomas Brown\n4284722681265508\nSat2929\n\n\n238\n35.83\n4.67\nFemale\nNo\nSat\nDinner\n3\n11.94\nKimberly Crane\n676184013727\nSat9777\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\nSat1766\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\nSat3880\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\nSat17\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n9.39\nMichelle Hardin\n3511451626698139\nThur672\n\n\n\n\n\n\n\n\n\ndf_tips.describe()\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsize\nprice_per_person\nCC Number\n\n\n\n\ncount\n244.000000\n244.000000\n244.000000\n244.000000\n2.440000e+02\n\n\nmean\n19.785943\n2.998279\n2.569672\n7.888197\n2.563496e+15\n\n\nstd\n8.902412\n1.383638\n0.951100\n2.914234\n2.369340e+15\n\n\nmin\n3.070000\n1.000000\n1.000000\n2.880000\n6.040679e+10\n\n\n25%\n13.347500\n2.000000\n2.000000\n5.800000\n3.040731e+13\n\n\n50%\n17.795000\n2.900000\n2.000000\n7.255000\n3.525318e+15\n\n\n75%\n24.127500\n3.562500\n3.000000\n9.390000\n4.553675e+15\n\n\nmax\n50.810000\n10.000000\n6.000000\n20.270000\n6.596454e+15\n\n\n\n\n\n\n\n\n\ndf_tips.describe().transpose()\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\ntotal_bill\n244.0\n1.978594e+01\n8.902412e+00\n3.070000e+00\n1.334750e+01\n1.779500e+01\n2.412750e+01\n5.081000e+01\n\n\ntip\n244.0\n2.998279e+00\n1.383638e+00\n1.000000e+00\n2.000000e+00\n2.900000e+00\n3.562500e+00\n1.000000e+01\n\n\nsize\n244.0\n2.569672e+00\n9.510998e-01\n1.000000e+00\n2.000000e+00\n2.000000e+00\n3.000000e+00\n6.000000e+00\n\n\nprice_per_person\n244.0\n7.888197e+00\n2.914234e+00\n2.880000e+00\n5.800000e+00\n7.255000e+00\n9.390000e+00\n2.027000e+01\n\n\nCC Number\n244.0\n2.563496e+15\n2.369340e+15\n6.040679e+10\n3.040731e+13\n3.525318e+15\n4.553675e+15\n6.596454e+15\n\n\n\n\n\n\n\n\n\n\nTransformasi data (row-wise)\n\nfiltering\n\ndf_tips.head()\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n\n\n\n\n\n\n\nprint(df_tips[\"size\"] == 3)\n\n0      False\n1       True\n2       True\n3      False\n4      False\n       ...  \n239     True\n240    False\n241    False\n242    False\n243    False\nName: size, Length: 244, dtype: bool\n\n\n\nconditional_size = (df_tips[\"size\"] == 3)\ndf_tips[conditional_size]\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n16\n10.33\n1.67\nFemale\nNo\nSun\nDinner\n3\n3.44\nElizabeth Foster\n4240025044626033\nSun9715\n\n\n17\n16.29\n3.71\nMale\nNo\nSun\nDinner\n3\n5.43\nJohn Pittman\n6521340257218708\nSun2998\n\n\n18\n16.97\n3.50\nFemale\nNo\nSun\nDinner\n3\n5.66\nLaura Martinez\n30422275171379\nSun2789\n\n\n19\n20.65\n3.35\nMale\nNo\nSat\nDinner\n3\n6.88\nTimothy Oneal\n6568069240986485\nSat9213\n\n\n35\n24.06\n3.60\nMale\nNo\nSat\nDinner\n3\n8.02\nJoseph Mullins\n5519770449260299\nSat632\n\n\n36\n16.31\n2.00\nMale\nNo\nSat\nDinner\n3\n5.44\nWilliam Ford\n3527691170179398\nSat9139\n\n\n37\n16.93\n3.07\nFemale\nNo\nSat\nDinner\n3\n5.64\nErin Lewis\n5161695527390786\nSat6406\n\n\n38\n18.69\n2.31\nMale\nNo\nSat\nDinner\n3\n6.23\nBrandon Bradley\n4427601595688633\nSat4056\n\n\n39\n31.27\n5.00\nMale\nNo\nSat\nDinner\n3\n10.42\nMr. Brandon Berry\n6011525851069856\nSat6373\n\n\n40\n16.04\n2.24\nMale\nNo\nSat\nDinner\n3\n5.35\nAdam Edwards\n3544447755679420\nSat8549\n\n\n48\n28.55\n2.05\nMale\nNo\nSun\nDinner\n3\n9.52\nAustin Fisher\n6011481668986587\nSun4142\n\n\n64\n17.59\n2.64\nMale\nNo\nSat\nDinner\n3\n5.86\nMichael Johnson\n2222114458088108\nSat1667\n\n\n65\n20.08\n3.15\nMale\nNo\nSat\nDinner\n3\n6.69\nJustin Dixon\n180021262464926\nSat6840\n\n\n71\n17.07\n3.00\nFemale\nNo\nSat\nDinner\n3\n5.69\nTeresa Fisher\n5442222963796367\nSat3469\n\n\n102\n44.30\n2.50\nFemale\nYes\nSat\nDinner\n3\n14.77\nHeather Cohen\n379771118886604\nSat6240\n\n\n112\n38.07\n4.00\nMale\nNo\nSun\nDinner\n3\n12.69\nJeff Lopez\n3572865915176463\nSun591\n\n\n114\n25.71\n4.00\nFemale\nNo\nSun\nDinner\n3\n8.57\nKatie Smith\n5400160161311292\nSun6492\n\n\n129\n22.82\n2.18\nMale\nNo\nThur\nLunch\n3\n7.61\nRaymond Torres\n4855776744024\nThur9424\n\n\n146\n18.64\n1.36\nFemale\nNo\nThur\nLunch\n3\n6.21\nKelly Estrada\n60463302327\nThur3941\n\n\n152\n17.26\n2.74\nMale\nNo\nSun\nDinner\n3\n5.75\nGregory Smith\n4292362333741\nSun5205\n\n\n162\n16.21\n2.00\nFemale\nNo\nSun\nDinner\n3\n5.40\nJennifer Baird\n4227834176859693\nSun5521\n\n\n165\n24.52\n3.48\nMale\nNo\nSun\nDinner\n3\n8.17\nJacob Hansen\n4031116007387\nSun9043\n\n\n170\n50.81\n10.00\nMale\nYes\nSat\nDinner\n3\n16.94\nGregory Clark\n5473850968388236\nSat1954\n\n\n182\n45.35\n3.50\nMale\nYes\nSun\nDinner\n3\n15.12\nJose Parsons\n4112207559459910\nSun2337\n\n\n186\n20.90\n3.50\nFemale\nYes\nSun\nDinner\n3\n6.97\nHeidi Atkinson\n4422858423131187\nSun4254\n\n\n188\n18.15\n3.50\nFemale\nYes\nSun\nDinner\n3\n6.05\nGlenda Wiggins\n578329325307\nSun430\n\n\n189\n23.10\n4.00\nMale\nYes\nSun\nDinner\n3\n7.70\nRichard Stevens\n3560193117506187\nSun1821\n\n\n200\n18.71\n4.00\nMale\nYes\nThur\nLunch\n3\n6.24\nJason Conrad\n4581233003487\nThur6048\n\n\n205\n16.47\n3.23\nFemale\nYes\nThur\nLunch\n3\n5.49\nCarly Reyes\n4787787236486\nThur8084\n\n\n206\n26.59\n3.41\nMale\nYes\nSat\nDinner\n3\n8.86\nDaniel Owens\n38971087967574\nSat1\n\n\n210\n30.06\n2.00\nMale\nYes\nSat\nDinner\n3\n10.02\nShawn Mendoza\n30184049218122\nSat8361\n\n\n214\n28.17\n6.50\nFemale\nYes\nSat\nDinner\n3\n9.39\nMarissa Jackson\n4922302538691962\nSat3374\n\n\n223\n15.98\n3.00\nFemale\nNo\nFri\nLunch\n3\n5.33\nMary Rivera\n5343428579353069\nFri6014\n\n\n231\n15.69\n3.00\nMale\nYes\nSat\nDinner\n3\n5.23\nJason Parks\n4812333796161\nSat6334\n\n\n238\n35.83\n4.67\nFemale\nNo\nSat\nDinner\n3\n11.94\nKimberly Crane\n676184013727\nSat9777\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n\n\n\n\n\n\n\nconditional = (df_tips[\"size\"] == 3) & (df_tips[\"total_bill\"] &gt; 20)\nprint(conditional)\n\n0      False\n1      False\n2       True\n3      False\n4      False\n       ...  \n239     True\n240    False\n241    False\n242    False\n243    False\nLength: 244, dtype: bool\n\n\n\ndf_tips[conditional]\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n19\n20.65\n3.35\nMale\nNo\nSat\nDinner\n3\n6.88\nTimothy Oneal\n6568069240986485\nSat9213\n\n\n35\n24.06\n3.60\nMale\nNo\nSat\nDinner\n3\n8.02\nJoseph Mullins\n5519770449260299\nSat632\n\n\n39\n31.27\n5.00\nMale\nNo\nSat\nDinner\n3\n10.42\nMr. Brandon Berry\n6011525851069856\nSat6373\n\n\n48\n28.55\n2.05\nMale\nNo\nSun\nDinner\n3\n9.52\nAustin Fisher\n6011481668986587\nSun4142\n\n\n65\n20.08\n3.15\nMale\nNo\nSat\nDinner\n3\n6.69\nJustin Dixon\n180021262464926\nSat6840\n\n\n102\n44.30\n2.50\nFemale\nYes\nSat\nDinner\n3\n14.77\nHeather Cohen\n379771118886604\nSat6240\n\n\n112\n38.07\n4.00\nMale\nNo\nSun\nDinner\n3\n12.69\nJeff Lopez\n3572865915176463\nSun591\n\n\n114\n25.71\n4.00\nFemale\nNo\nSun\nDinner\n3\n8.57\nKatie Smith\n5400160161311292\nSun6492\n\n\n129\n22.82\n2.18\nMale\nNo\nThur\nLunch\n3\n7.61\nRaymond Torres\n4855776744024\nThur9424\n\n\n165\n24.52\n3.48\nMale\nNo\nSun\nDinner\n3\n8.17\nJacob Hansen\n4031116007387\nSun9043\n\n\n170\n50.81\n10.00\nMale\nYes\nSat\nDinner\n3\n16.94\nGregory Clark\n5473850968388236\nSat1954\n\n\n182\n45.35\n3.50\nMale\nYes\nSun\nDinner\n3\n15.12\nJose Parsons\n4112207559459910\nSun2337\n\n\n186\n20.90\n3.50\nFemale\nYes\nSun\nDinner\n3\n6.97\nHeidi Atkinson\n4422858423131187\nSun4254\n\n\n189\n23.10\n4.00\nMale\nYes\nSun\nDinner\n3\n7.70\nRichard Stevens\n3560193117506187\nSun1821\n\n\n206\n26.59\n3.41\nMale\nYes\nSat\nDinner\n3\n8.86\nDaniel Owens\n38971087967574\nSat1\n\n\n210\n30.06\n2.00\nMale\nYes\nSat\nDinner\n3\n10.02\nShawn Mendoza\n30184049218122\nSat8361\n\n\n214\n28.17\n6.50\nFemale\nYes\nSat\nDinner\n3\n9.39\nMarissa Jackson\n4922302538691962\nSat3374\n\n\n238\n35.83\n4.67\nFemale\nNo\nSat\nDinner\n3\n11.94\nKimberly Crane\n676184013727\nSat9777\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n\n\n\n\n\n\n\ndf_tips[(df_tips[\"size\"] == 3) & (df_tips[\"total_bill\"] &gt; 20)]\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n19\n20.65\n3.35\nMale\nNo\nSat\nDinner\n3\n6.88\nTimothy Oneal\n6568069240986485\nSat9213\n\n\n35\n24.06\n3.60\nMale\nNo\nSat\nDinner\n3\n8.02\nJoseph Mullins\n5519770449260299\nSat632\n\n\n39\n31.27\n5.00\nMale\nNo\nSat\nDinner\n3\n10.42\nMr. Brandon Berry\n6011525851069856\nSat6373\n\n\n48\n28.55\n2.05\nMale\nNo\nSun\nDinner\n3\n9.52\nAustin Fisher\n6011481668986587\nSun4142\n\n\n65\n20.08\n3.15\nMale\nNo\nSat\nDinner\n3\n6.69\nJustin Dixon\n180021262464926\nSat6840\n\n\n102\n44.30\n2.50\nFemale\nYes\nSat\nDinner\n3\n14.77\nHeather Cohen\n379771118886604\nSat6240\n\n\n112\n38.07\n4.00\nMale\nNo\nSun\nDinner\n3\n12.69\nJeff Lopez\n3572865915176463\nSun591\n\n\n114\n25.71\n4.00\nFemale\nNo\nSun\nDinner\n3\n8.57\nKatie Smith\n5400160161311292\nSun6492\n\n\n129\n22.82\n2.18\nMale\nNo\nThur\nLunch\n3\n7.61\nRaymond Torres\n4855776744024\nThur9424\n\n\n165\n24.52\n3.48\nMale\nNo\nSun\nDinner\n3\n8.17\nJacob Hansen\n4031116007387\nSun9043\n\n\n170\n50.81\n10.00\nMale\nYes\nSat\nDinner\n3\n16.94\nGregory Clark\n5473850968388236\nSat1954\n\n\n182\n45.35\n3.50\nMale\nYes\nSun\nDinner\n3\n15.12\nJose Parsons\n4112207559459910\nSun2337\n\n\n186\n20.90\n3.50\nFemale\nYes\nSun\nDinner\n3\n6.97\nHeidi Atkinson\n4422858423131187\nSun4254\n\n\n189\n23.10\n4.00\nMale\nYes\nSun\nDinner\n3\n7.70\nRichard Stevens\n3560193117506187\nSun1821\n\n\n206\n26.59\n3.41\nMale\nYes\nSat\nDinner\n3\n8.86\nDaniel Owens\n38971087967574\nSat1\n\n\n210\n30.06\n2.00\nMale\nYes\nSat\nDinner\n3\n10.02\nShawn Mendoza\n30184049218122\nSat8361\n\n\n214\n28.17\n6.50\nFemale\nYes\nSat\nDinner\n3\n9.39\nMarissa Jackson\n4922302538691962\nSat3374\n\n\n238\n35.83\n4.67\nFemale\nNo\nSat\nDinner\n3\n11.94\nKimberly Crane\n676184013727\nSat9777\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n\n\n\n\n\n\n\nconditional_or = (df_tips[\"tip\"] &gt; 4) | (df_tips[\"total_bill\"] &gt; 20)\ndf_tips[conditional_or]\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n5\n25.29\n4.71\nMale\nNo\nSun\nDinner\n4\n6.32\nErik Smith\n213140353657882\nSun9679\n\n\n7\n26.88\n3.12\nMale\nNo\nSun\nDinner\n4\n6.72\nRobert Buck\n3514785077705092\nSun8157\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n237\n32.83\n1.17\nMale\nYes\nSat\nDinner\n2\n16.42\nThomas Brown\n4284722681265508\nSat2929\n\n\n238\n35.83\n4.67\nFemale\nNo\nSat\nDinner\n3\n11.94\nKimberly Crane\n676184013727\nSat9777\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\nSat1766\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\nSat3880\n\n\n\n\n101 rows × 11 columns\n\n\n\n\n\nweekend = [\"Sun\", \"Sat\"]\nconditional_in = df_tips[\"day\"].isin(weekend)\ndf_tips[conditional_in]\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n238\n35.83\n4.67\nFemale\nNo\nSat\nDinner\n3\n11.94\nKimberly Crane\n676184013727\nSat9777\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\nSat1766\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\nSat3880\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\nSat17\n\n\n\n\n163 rows × 11 columns\n\n\n\n\n\ndf_tips.head()\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n\n\n\n\n\n\n\n\nmencari nilai unik\n\ndf_tips[\"day\"].unique()\n\narray(['Sun', 'Sat', 'Thur', 'Fri'], dtype=object)\n\n\n\ndf_tips[[\"day\",\"time\"]]\n\n\n\n\n\n\n\n\n\nday\ntime\n\n\n\n\n0\nSun\nDinner\n\n\n1\nSun\nDinner\n\n\n2\nSun\nDinner\n\n\n3\nSun\nDinner\n\n\n4\nSun\nDinner\n\n\n...\n...\n...\n\n\n239\nSat\nDinner\n\n\n240\nSat\nDinner\n\n\n241\nSat\nDinner\n\n\n242\nSat\nDinner\n\n\n243\nThur\nDinner\n\n\n\n\n244 rows × 2 columns\n\n\n\n\n\ndf_tips.drop_duplicates([\"day\",\"time\"])[[\"day\",\"time\"]]\n\n\n\n\n\n\n\n\n\nday\ntime\n\n\n\n\n0\nSun\nDinner\n\n\n19\nSat\nDinner\n\n\n77\nThur\nLunch\n\n\n90\nFri\nDinner\n\n\n220\nFri\nLunch\n\n\n243\nThur\nDinner\n\n\n\n\n\n\n\n\n\n\n\nTransforming Data (Column Wise)\n\nSelecting Columns\n\nprint(df_tips[\"day\"])\n\n0       Sun\n1       Sun\n2       Sun\n3       Sun\n4       Sun\n       ... \n239     Sat\n240     Sat\n241     Sat\n242     Sat\n243    Thur\nName: day, Length: 244, dtype: object\n\n\n\nprint(df_tips.day)\n\n0       Sun\n1       Sun\n2       Sun\n3       Sun\n4       Sun\n       ... \n239     Sat\n240     Sat\n241     Sat\n242     Sat\n243    Thur\nName: day, Length: 244, dtype: object\n\n\n\ndf_tips[[\"day\",\"time\"]]\n\n\n\n\n\n\n\n\n\nday\ntime\n\n\n\n\n0\nSun\nDinner\n\n\n1\nSun\nDinner\n\n\n2\nSun\nDinner\n\n\n3\nSun\nDinner\n\n\n4\nSun\nDinner\n\n\n...\n...\n...\n\n\n239\nSat\nDinner\n\n\n240\nSat\nDinner\n\n\n241\nSat\nDinner\n\n\n242\nSat\nDinner\n\n\n243\nThur\nDinner\n\n\n\n\n244 rows × 2 columns\n\n\n\n\n\n\nMutating (create new column)\n\ndf_tips[\"tips_percentage\"]= df_tips[\"tip\"]/df_tips[\"total_bill\"]*100\n\ndf_tips.head()\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\ntips_percentage\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n5.944673\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n16.054159\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n16.658734\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n13.978041\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n14.680765\n\n\n\n\n\n\n\n\n\n\nrenaming column\n\ndf_tips.rename(columns={\"tips_percentage\": \"tips_%\"}, inplace=True)\ndf_tips.head()\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\ntips_%\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n5.944673\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n16.054159\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n16.658734\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n13.978041\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n14.680765\n\n\n\n\n\n\n\n\n\n\nrelocate columns\n\n#relocate tips_percentage_% column to the rightmost\ncols = list(df_tips.columns)\ncols = [cols[-1]]+ cols[:-2]\n\ndf_tips = df_tips[cols]\n\n\ndf_tips\n\n\n\n\n\n\n\n\n\ntips_%\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\n\n\n\n\n0\n5.944673\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\n\n\n1\n16.054159\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\n\n\n2\n16.658734\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\n\n\n3\n13.978041\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\n\n\n4\n14.680765\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n20.392697\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\n\n\n240\n7.358352\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\n\n\n241\n8.822232\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\n\n\n242\n9.820426\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\n\n\n243\n15.974441\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n9.39\nMichelle Hardin\n3511451626698139\n\n\n\n\n244 rows × 11 columns"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#export-dataframe-ke-csv",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#export-dataframe-ke-csv",
    "title": "Modul 1 Sains Data: Pengenalan Pandas, Transformasi Data",
    "section": "Export DataFrame ke CSV",
    "text": "Export DataFrame ke CSV\n\ndf_tips.to_csv(\"tips_modified.csv\")"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul3.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul3.html",
    "title": "Modul 3 Sains Data: Encoding Data Kategorik dan Imputasi Data",
    "section": "",
    "text": "Kembali ke Sains Data\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nInstall scikit-learn dengan:\n!pip install scikit-learn\nLalu import sklearn:\nimport sklearn"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#import-dataset",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#import-dataset",
    "title": "Modul 3 Sains Data: Encoding Data Kategorik dan Imputasi Data",
    "section": "Import Dataset",
    "text": "Import Dataset\nUntuk praktikum kali ini, kita akan menggunakan dataset “California Housing Prices” (housing.csv) yang bisa didownload dari salah satu sumber berikut:\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle: https://www.kaggle.com/datasets/camnugent/california-housing-prices\n\nKemudian, baca sebagai dataframe:\n\ndf = pd.read_csv(\"./housing.csv\")\n\nMari kita lihat isinya:\n\ndf\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\nocean_proximity\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\nNEAR BAY\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\nNEAR BAY\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\nNEAR BAY\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\nNEAR BAY\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\nNEAR BAY\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\nINLAND\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\nINLAND\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\nINLAND\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\nINLAND\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\nINLAND\n\n\n\n\n20640 rows × 10 columns\n\n\n\n\nAda satu data kategorik, yaitu ocean_proximity. Mari kita liat jenis-jenisnya (kategorinya):\n\ndf[\"ocean_proximity\"].value_counts()\n\nocean_proximity\n&lt;1H OCEAN     9136\nINLAND        6551\nNEAR OCEAN    2658\nNEAR BAY      2290\nISLAND           5\nName: count, dtype: int64\n\n\nApakah ada missing value?\n\ndf.isna().sum()\n\nlongitude               0\nlatitude                0\nhousing_median_age      0\ntotal_rooms             0\ntotal_bedrooms        207\npopulation              0\nhouseholds              0\nmedian_income           0\nmedian_house_value      0\nocean_proximity         0\ndtype: int64\n\n\n\ndf[df[\"total_bedrooms\"].isna()]\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\nocean_proximity\n\n\n\n\n290\n-122.16\n37.77\n47.0\n1256.0\nNaN\n570.0\n218.0\n4.3750\n161900.0\nNEAR BAY\n\n\n341\n-122.17\n37.75\n38.0\n992.0\nNaN\n732.0\n259.0\n1.6196\n85100.0\nNEAR BAY\n\n\n538\n-122.28\n37.78\n29.0\n5154.0\nNaN\n3741.0\n1273.0\n2.5762\n173400.0\nNEAR BAY\n\n\n563\n-122.24\n37.75\n45.0\n891.0\nNaN\n384.0\n146.0\n4.9489\n247100.0\nNEAR BAY\n\n\n696\n-122.10\n37.69\n41.0\n746.0\nNaN\n387.0\n161.0\n3.9063\n178400.0\nNEAR BAY\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20267\n-119.19\n34.20\n18.0\n3620.0\nNaN\n3171.0\n779.0\n3.3409\n220500.0\nNEAR OCEAN\n\n\n20268\n-119.18\n34.19\n19.0\n2393.0\nNaN\n1938.0\n762.0\n1.6953\n167400.0\nNEAR OCEAN\n\n\n20372\n-118.88\n34.17\n15.0\n4260.0\nNaN\n1701.0\n669.0\n5.1033\n410700.0\n&lt;1H OCEAN\n\n\n20460\n-118.75\n34.29\n17.0\n5512.0\nNaN\n2734.0\n814.0\n6.6073\n258100.0\n&lt;1H OCEAN\n\n\n20484\n-118.72\n34.28\n17.0\n3051.0\nNaN\n1705.0\n495.0\n5.7376\n218600.0\n&lt;1H OCEAN\n\n\n\n\n207 rows × 10 columns\n\n\n\n\nPerhatikan bahwa tipe datanya adalah int64 atau bilangan bulat.\nDari 20640 baris, ada satu kolom/fitur (total_bedrooms) dengan 207 missing value.\nSecara umum, ada dua cara untuk menangani missing value:\n\nMenghapus baris-baris yang memiliki missing value, dengan df.dropna()\nMelakukan metode imputasi\n\nKarena banyaknya missing value relatif sedikit, sebenarnya tidak masalah apabila baris-baris tersebut cukup dihapus saja. Namun, kita akan mempelajari metode imputasi."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#encoding-data-kategorik",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#encoding-data-kategorik",
    "title": "Modul 3 Sains Data: Encoding Data Kategorik dan Imputasi Data",
    "section": "Encoding Data Kategorik",
    "text": "Encoding Data Kategorik\nSebelum kita membahas metode imputasi, kita akan membahas tentang melakukan “encoding” untuk data kategorik.\nBanyak metode sains data / machine learning yang hanya bisa digunakan dengan data numerik. Oleh karena itu, data kategorik perlu diubah terlebih dahulu menjadi data numerik, melakukan yang namanya categorical data encoding\nMetode yang sering digunakan adalah one hot encoding. Misalnya ada satu fitur kategorik dengan \\(n\\) kemungkinan data, bernama \\(D_i\\) untuk \\(i = 1, 2, \\dots, n\\). Maka fitur tersebut diganti dengan \\(n\\) kolom baru, misal bernama \\(K_i\\) untuk \\(i = 1, 2, \\dots, n\\), di mana pada kolom ke-i, isinya adalah\n\n\\(1\\), apabila data aslinya pada baris tersebut adalah \\(D_i\\)\n\\(0\\) apabila bukan \\(D_i\\)\n\n\nfrom sklearn.preprocessing import OneHotEncoder\n\n\nencoder = OneHotEncoder()\n\n\nhasil_onehot = encoder.fit_transform(df[[\"ocean_proximity\"]])\n\n\nprint(encoder.categories_)\n\n[array(['&lt;1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n      dtype=object)]\n\n\n\nprint(encoder.categories_[0])\n\n['&lt;1H OCEAN' 'INLAND' 'ISLAND' 'NEAR BAY' 'NEAR OCEAN']\n\n\n\nkolom_encoding = list(encoder.categories_[0])\n\n\nprint(kolom_encoding)\n\n['&lt;1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']\n\n\n\nonehot_array = hasil_onehot.toarray()\n\n\nprint(onehot_array)\n\n[[0. 0. 0. 1. 0.]\n [0. 0. 0. 1. 0.]\n [0. 0. 0. 1. 0.]\n ...\n [0. 1. 0. 0. 0.]\n [0. 1. 0. 0. 0.]\n [0. 1. 0. 0. 0.]]\n\n\n\nonehot_df = pd.DataFrame(onehot_array, columns=kolom_encoding)\n\n\nonehot_df\n\n\n\n\n\n\n\n\n\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n20635\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 5 columns\n\n\n\n\n\ndf = pd.concat([df, onehot_df], axis=1)\n\n\ndf\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\nocean_proximity\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\nNEAR BAY\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\nNEAR BAY\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\nNEAR BAY\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\nNEAR BAY\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\nNEAR BAY\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\nINLAND\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\nINLAND\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\nINLAND\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\nINLAND\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\nINLAND\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 15 columns\n\n\n\n\n\ndf = df.drop([\"ocean_proximity\"], axis=1)\n\n\ndf\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 14 columns"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#metode-imputasi",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#metode-imputasi",
    "title": "Modul 3 Sains Data: Encoding Data Kategorik dan Imputasi Data",
    "section": "Metode Imputasi",
    "text": "Metode Imputasi\n\nMedian\n\ndf_fill_median = df.copy()\n\n\ndf[\"total_bedrooms\"].median()\n\n435.0\n\n\n\nbedrooms_median = df[\"total_bedrooms\"].median()\nprint(bedrooms_median)\n\n435.0\n\n\n\ndf_fill_median[\"total_bedrooms\"] = df_fill_median[\"total_bedrooms\"].fillna(bedrooms_median)\n\n\ndf_fill_median.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\nCara lain, menggunakan scikit-learn:\n\ndf_fill_median2 = df.copy()\n\n\nfrom sklearn.impute import SimpleImputer\n\n\nmedian_imputer = SimpleImputer(\n    missing_values=np.nan, strategy='median'\n)\n\n\ndf_fill_median2[[\"total_bedrooms\"]] = median_imputer.fit_transform(\n    df_fill_median2[[\"total_bedrooms\"]]\n)\n\n\ndf_fill_median2.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\n\n\nModus\n\ndf_fill_mode = df.copy()\n\n\ndf[\"total_bedrooms\"].mode()\n\n0    280.0\nName: total_bedrooms, dtype: float64\n\n\n\ndf[\"total_bedrooms\"].mode()[0]\n\n280.0\n\n\n\nbedrooms_mode = df[\"total_bedrooms\"].mode()[0]\nprint(bedrooms_mode)\n\n280.0\n\n\n\ndf_fill_mode[\"total_bedrooms\"] = df_fill_mode[\"total_bedrooms\"].fillna(bedrooms_mode)\n\n\ndf_fill_mode.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\nCara lain, menggunakan scikit-learn:\n\ndf_fill_mode2 = df.copy()\n\n\nmode_imputer = SimpleImputer(\n    missing_values=np.nan, strategy='most_frequent'\n)\n\n\ndf_fill_mode2[[\"total_bedrooms\"]] = mode_imputer.fit_transform(\n    df_fill_mode2[[\"total_bedrooms\"]]\n)\n\n\ndf_fill_mode2.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\n\n\nMean (rata-rata)\n\ndf_fill_mean = df.copy()\n\n\ndf_fill_mean[\"total_bedrooms\"].mean()\n\n537.8705525375618\n\n\n\nnp.round(df_fill_mean[\"total_bedrooms\"].mean())\n\n538.0\n\n\n\nbedrooms_mean = np.round(df_fill_mean[\"total_bedrooms\"].mean())\nprint(bedrooms_mean)\n\n538.0\n\n\n\ndf_fill_mean[\"total_bedrooms\"] = df_fill_mean[\"total_bedrooms\"].fillna(bedrooms_mean)\n\n\ndf_fill_mean.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\nCara lain, menggunakan scikit-learn:\n\ndf_fill_mean2 = df.copy()\n\n\nmean_imputer = SimpleImputer(\n    missing_values=np.nan, strategy='mean'\n)\n\n\ndf_fill_mean2[[\"total_bedrooms\"]] = mean_imputer.fit_transform(\n    df_fill_mean2[[\"total_bedrooms\"]]\n)\n\n\ndf_fill_mean2.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\n\n\nKNNImputer\n\nfrom sklearn.impute import KNNImputer\n\n\nknn_imputer = KNNImputer(n_neighbors=3)\n\n\ndf_fill_knn = df.copy()\n\nKNN Imputer memerlukan kolom-kolom lainnya sebagai acuan, dan hanya bisa bekerja dengan data numerik. Sehingga, kita perlu mem-filter terlebih dahulu kolom-kolom numerik dari dataset kita.\n\ndf_fill_knn.select_dtypes(include='number')\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 14 columns\n\n\n\n\n\ndf_fill_knn.select_dtypes(include='number').columns\n\nIndex(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n       'total_bedrooms', 'population', 'households', 'median_income',\n       'median_house_value', '&lt;1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY',\n       'NEAR OCEAN'],\n      dtype='object')\n\n\n\nnum_col = df_fill_knn.select_dtypes(include='number').columns\n\n\ndf_fill_knn[num_col] = knn_imputer.fit_transform(df_fill_knn[num_col])\n\n\ndf_fill_knn.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#perbandingan-metode-imputasi",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#perbandingan-metode-imputasi",
    "title": "Modul 3 Sains Data: Encoding Data Kategorik dan Imputasi Data",
    "section": "Perbandingan Metode Imputasi",
    "text": "Perbandingan Metode Imputasi\nKita bisa membandingkan beberapa metode imputasi (dan memilih yang mana yang terbaik) dengan langkah-langkah berikut.\n\nUse a sample of your own dataset that does not contain any missing data (will serve as ground truth).\nIntroduce increasing proportions of missing data at random (e.g. 5–50 % in 5 % increments).\nReconstruct the missing data using the various methods.\nCompute the sum of squared errors between the reconstructed and the original data, for each method and each proportion of missing data.\n\nLangkah pertama, kita perlu memperoleh sample dari dataset kita yang tidak mengandung missing value, yang bisa disebut ground truth. Cara termudah adalah dengan menghapus baris-baris yang memiliki missing value (biasanya dipilih lagi sample hanya sebagian baris, tapi di sini tidak kita lakukan):\n\ndf_ground_truth = df.dropna()\n\n\ndf_ground_truth\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20433 rows × 14 columns\n\n\n\n\nSelanjutnya, kita perlu membolong-bolongi dataset ini, agar sekian persen diisi missing value.\n\nimport random\n\n\ndef missing_value_generator(df_original, percentage):\n    df_miss = df_original.copy()\n    baris, kolom = df_miss.shape\n    n_total = baris*kolom\n\n    permutasi = list(range(n_total))\n    random.shuffle(permutasi)\n\n    n_pilih = int(percentage * n_total)\n    pilihan = permutasi[0 : n_pilih]\n\n    for p in pilihan:\n        df_miss.iloc[ int(p/kolom), p%kolom ] = np.nan\n    \n    return df_miss\n\n\ndf_miss_5 = missing_value_generator(df, 0.05)\n\n\ndf_miss_5.isna().sum()\n\nlongitude             1021\nlatitude              1015\nhousing_median_age    1064\ntotal_rooms           1004\ntotal_bedrooms        1205\npopulation            1087\nhouseholds            1032\nmedian_income         1004\nmedian_house_value    1018\n&lt;1H OCEAN             1050\nINLAND                1023\nISLAND                1085\nNEAR BAY              1051\nNEAR OCEAN             981\ndtype: int64\n\n\n\ndef compare_imputation(df_ground_truth, methods, percentages):\n    list_missing_df = []\n    for percent in percentages:\n        df_miss = missing_value_generator(df_ground_truth, percent)\n        list_missing_df.append(df_miss)\n\n    all_results = []\n    for method in methods:\n        method_results = []\n        for df_miss in list_missing_df:\n            df_imputed = method.fit_transform(df_miss)\n            SSE = ((df_ground_truth - df_imputed)**2).sum().sum()\n            method_results.append(SSE)\n        all_results.append(method_results)\n\n    return all_results\n\n\nmedian_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\nmean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nmode_imputer = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n\n\nlist_persen = [0.05, 0.10, 0.15, 0.20, 0.25]\n\n\nall_results = compare_imputation(\n    df_ground_truth,\n    [median_imputer, mean_imputer, mode_imputer],\n    list_persen\n)\n\n\nall_results\n\n[[16106399718053.193,\n  27686624654974.12,\n  42067852690522.375,\n  57674869517426.2,\n  71398507402041.0],\n [15149962314993.664,\n  26691038947100.4,\n  39993567341678.87,\n  54874386927172.04,\n  67502299532092.21],\n [104263768244576.97,\n  200631901715894.3,\n  302872434183477.3,\n  413821496079702.0,\n  502638602704461.3]]\n\n\n\nprint(\"Median:\", all_results[0])\nprint(\"Mean:\", all_results[1])\nprint(\"Mode:\", all_results[2])\n\nMedian: [16106399718053.193, 27686624654974.12, 42067852690522.375, 57674869517426.2, 71398507402041.0]\nMean: [15149962314993.664, 26691038947100.4, 39993567341678.87, 54874386927172.04, 67502299532092.21]\nMode: [104263768244576.97, 200631901715894.3, 302872434183477.3, 413821496079702.0, 502638602704461.3]\n\n\n\nplt.plot(list_persen, all_results[0])\nplt.plot(list_persen, all_results[1])\nplt.plot(list_persen, all_results[2])\nplt.legend([\"Median\", \"Mean\", \"Mode\"])\nplt.show()\n\n\n\n\n\n\n\n\nDari hasil tersebut, didapat bahwa secara keseluruhan, untuk setiap persentase missing values, metode imputasi dengan menggunakan mean menghasilkan SSE yang terkecil dibandingkan imputasi dengan median dan modus. Oleh karena itu, kita akan menggunakan metode imputasi menggunakan mean untuk mengisi missing value pada kolom “total_bedrooms” dari df asli.\n\n# melihat kembali df awal\ndf\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 14 columns\n\n\n\n\n\ndf.isna().sum()\n\nlongitude               0\nlatitude                0\nhousing_median_age      0\ntotal_rooms             0\ntotal_bedrooms        207\npopulation              0\nhouseholds              0\nmedian_income           0\nmedian_house_value      0\n&lt;1H OCEAN               0\nINLAND                  0\nISLAND                  0\nNEAR BAY                0\nNEAR OCEAN              0\ndtype: int64\n\n\n\n# lakukan imputasi dengan metode terbaik yg telah didapat, yaitu dengan mean\n\ndf[['total_bedrooms']] = mean_imputer.fit_transform(df[['total_bedrooms']] )\n\n\ndf\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 14 columns\n\n\n\n\n\ndf.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\n\nExport Dataframe yang telah diimputasi ke CSV\n\ndf.to_csv(\"housing_modified.csv\")"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul5.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul5.html",
    "title": "Modul 5 Sains Data: Decision Tree, SVM",
    "section": "",
    "text": "Kembali ke Sains Data"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul5.html#evaluation-metrics",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul5.html#evaluation-metrics",
    "title": "Modul 5 Sains Data: Decision Tree, SVM",
    "section": "1. Evaluation Metrics",
    "text": "1. Evaluation Metrics\n\nJaccard Index\n\nMengukur akurasi dari model menggunakan irisan dari hasil prediksi dengan value sebenarnya. \\[J(y, \\hat{y}) = \\frac{|y \\cap \\hat{y}|}{|y|+|\\hat{y}|-|y \\cap \\hat{y}|}\\]\n\\(y=\\) actual label\n\\(\\hat{y}=\\) predicted label\nContoh:\n\\(y = [0,0,0,0,0,1,1,1,1,1]\\)\n\\(\\hat{y} = [1,1,0,0,0,1,1,1,1,1]\\)\n\\(|y| = 10\\)\n\\(|\\hat{y}| = 10\\)\n\\(|\\hat{y}|-|y \\cap \\hat{y}| = 8\\)\n\\(J(y, \\hat{y}) = \\frac{|y \\cap \\hat{y}|}{|y|+|\\hat{y}|-|y \\cap \\hat{y}|} = \\frac{8}{10+10-8} = 0.66\\)\n\nRentang Jaccard index antara 0 hingga 1\nSemakin tinggi Jaccard Index, peforma model semakin baik\n\n\nConfusion Matrix, F1 Score\n\nTN / True Negative: kasus negatif, dengan hasil prediksi negatif\nTP / True Positive: kasus positif, dengan hasil prediksi positif\nFN / False Negative: kasus positif, dengan hasil prediksi negatif\nFP / False Positive: kasus negatif, dengan hasil prediksi positif\n\n\\[Precision = \\frac{TP}{(TP+FP)}\\]\n\\[Recall = \\frac{TN}{(TP+FN)}\\]\n\\[F1 \\text{ } Score = \\frac{2 . (Recall.Precision)}{(Recall+Precision)}\\]\nCara mengukur performa menggunakan F-1 score dengan mengambil rata rata F1-score dari masing masing label.\nContoh, label 0 memiliki F1-score 0.72 dan label 1 memiliki F1-score 0.50.\nMaka, F1-score dari model tersebut adalah 0.61\n\nRentang F1-score berkisar di antara 0 hingga 1\nSemakin tinggi F1-score, maka peforma model tersebut makin baik\n\n\nLog loss\n\nTerkadang, output dari suatu model klasifikasi berbentuk probabilitas dari suatu item memiliki label tertentu. (Contohnya pada logistic regression minggu lalu)\nKita dapat menghitung untuk masing-masing item: \\[(y. \\log(\\hat{y}) + (1-y). \\log(1-\\hat{y}))\\]\nKemudian, kita dapat menghitung rata rata dari tiap item tersebut \\[Logloss = -\\frac{1}{n} \\Sigma (y. \\log(\\hat{y}) + (1-y). \\log(1-\\hat{y}))\\]\n\\(y=\\) actual label\n\\(\\hat{y}=\\) predicted probability\nContoh:\n\n\nRentang logloss berkisar di antara 0 hingga 1\nSemakin rendah logloss, maka peforma model tersebut makin baik"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul5.html#decision-tree",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul5.html#decision-tree",
    "title": "Modul 5 Sains Data: Decision Tree, SVM",
    "section": "2. Decision Tree",
    "text": "2. Decision Tree\nSeperti namanya, pohon keputusan, konsepnya bentuknya pohon, bercabang.\nBiasanya digunakan sebagai simple binary classifier.\n\n\nMencari fitur apa yg membuat suatu item memiliki label tertentu\nEntropy = tolak ukur seberapa random data di fitur tsb, entropy 0 artinya simpul (fitur) tsb berpengaruh terhadap klasifikasi, entropy 0 itu baik \\[-P(A).\\log(P(A)) - P(B).\\log(P(B))\\]\nInformation gain : informasi yang dapat meningkatkan kejelasan dari percabangan. \\(\\newline\\) InfoGain = Entropybefore - weightedentropyafter\nPohon yg lebih baik adalah yang memiliki infogain lebih tinggi\n\nKali ini, kita akan mengklasifikasi resep obat yang cocok dari penyakit yang sama untuk fitur-fitur yang berbeda (Umur, Jenis Kelamin,Tekanan Darah, Kolestrol)\n\nImport Module\n\n#import modul dan package\nimport numpy as np\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\n\n\n\nImport Data\nPada module kali ini, akan digunakan data csv drug200 (drug200.csv) yang bisa didownload dari:\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle: https://www.kaggle.com/datasets/jeevanrh/drug200csv\n\n\n#muat dataset\nmy_data = pd.read_csv(\"./drug200.csv\")\nmy_data.head()\n\n\n\n\n\n\n\n\n\nAge\nSex\nBP\nCholesterol\nNa_to_K\nDrug\n\n\n\n\n0\n23\nF\nHIGH\nHIGH\n25.355\ndrugY\n\n\n1\n47\nM\nLOW\nHIGH\n13.093\ndrugC\n\n\n2\n47\nM\nLOW\nHIGH\n10.114\ndrugC\n\n\n3\n28\nF\nNORMAL\nHIGH\n7.798\ndrugX\n\n\n4\n61\nF\nLOW\nHIGH\n18.043\ndrugY\n\n\n\n\n\n\n\n\n\nmy_data.shape\n\n(200, 6)\n\n\n\n#melihat ada brp value berbeda pada feature/kolom Drug\nmy_data[\"Drug\"].unique()\n\narray(['drugY', 'drugC', 'drugX', 'drugA', 'drugB'], dtype=object)\n\n\n\n#feature/kolom pada dataframe\nmy_data.columns\n\nIndex(['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug'], dtype='object')\n\n\n\n#melihat value per baris\nX = my_data[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']].values\nX[0:5]\n\narray([[23, 'F', 'HIGH', 'HIGH', 25.355],\n       [47, 'M', 'LOW', 'HIGH', 13.093],\n       [47, 'M', 'LOW', 'HIGH', 10.114],\n       [28, 'F', 'NORMAL', 'HIGH', 7.798],\n       [61, 'F', 'LOW', 'HIGH', 18.043]], dtype=object)\n\n\n\n\nPreprocessing\nPada bagian ini, kita akan mengubah value kategorik menjadi data numerik (encoding). Selain OneHotEncoder, sebenarnya ada lagi yang namanya LabelEncoder.\nBedanya, OneHotEncoder bisa digunakan untuk data kategorik apapun tetapi akan membuat kolom baru untuk tiap kategori. Sedangkan, LabelEncoder dimaksudkan untuk data kategorik ordinal (yaitu ada urutannya), tetapi hanya menghasilkan satu kolom baru yang sekadar mengubah kategorinya menjadi urutan.\nApabila hanya ada dua kategori, meskipun tidak ada urutan, sebaiknya tetap menggunakan LabelEncoder daripada OneHotEncoder agar hemat kolom.\n\nfrom sklearn import preprocessing\nle_sex = preprocessing.LabelEncoder()\nle_sex.fit(['F', 'M'])\nX[:, 1] = le_sex.transform(X[:, 1]) #sex di kolom kedua df, indexnya 1\nX[0:5]\n\narray([[23, 0, 'HIGH', 'HIGH', 25.355],\n       [47, 1, 'LOW', 'HIGH', 13.093],\n       [47, 1, 'LOW', 'HIGH', 10.114],\n       [28, 0, 'NORMAL', 'HIGH', 7.798],\n       [61, 0, 'LOW', 'HIGH', 18.043]], dtype=object)\n\n\n\nle_bp = preprocessing.LabelEncoder()\nle_bp.fit(['LOW', 'NORMAL', 'HIGH'])\nX[:, 2] = le_bp.transform(X[:, 2]) #sex di kolom ketiga df, indexnya 2\nle_chol = preprocessing.LabelEncoder()\nle_chol.fit(['NORMAL', 'HIGH'])\nX[:, 3] = le_chol.transform(X[:, 3]) #sex di kolom keempat df, indexnya 3\nX[0:5]\n\narray([[23, 0, 0, 0, 25.355],\n       [47, 1, 1, 0, 13.093],\n       [47, 1, 1, 0, 10.114],\n       [28, 0, 2, 0, 7.798],\n       [61, 0, 1, 0, 18.043]], dtype=object)\n\n\n\ny = my_data['Drug']\ny[0:5]\n\n0    drugY\n1    drugC\n2    drugC\n3    drugX\n4    drugY\nName: Drug, dtype: object\n\n\n\n\nTrain/Test Split\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n\n\nprint(X_train.shape)\nprint(y_train.shape)\n\n(140, 5)\n(140,)\n\n\n\nprint(X_test.shape)\nprint(y_test.shape)\n\n(60, 5)\n(60,)\n\n\n\n\nModelling\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n\ndrugtree = DecisionTreeClassifier(criterion = 'entropy', max_depth = 4)\n\n\ndrugtree.fit(X_train, y_train)\n\nDecisionTreeClassifier(criterion='entropy', max_depth=4)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFittedDecisionTreeClassifier(criterion='entropy', max_depth=4) \n\n\n\npredTree = drugtree.predict(X_test)\npredTree\n\narray(['drugC', 'drugY', 'drugX', 'drugY', 'drugX', 'drugX', 'drugY',\n       'drugX', 'drugY', 'drugX', 'drugY', 'drugC', 'drugC', 'drugY',\n       'drugB', 'drugX', 'drugA', 'drugY', 'drugY', 'drugC', 'drugX',\n       'drugC', 'drugX', 'drugY', 'drugY', 'drugB', 'drugB', 'drugC',\n       'drugY', 'drugY', 'drugY', 'drugY', 'drugC', 'drugY', 'drugY',\n       'drugY', 'drugY', 'drugY', 'drugA', 'drugX', 'drugY', 'drugY',\n       'drugY', 'drugB', 'drugY', 'drugY', 'drugA', 'drugA', 'drugX',\n       'drugX', 'drugY', 'drugY', 'drugY', 'drugY', 'drugX', 'drugX',\n       'drugX', 'drugA', 'drugY', 'drugA'], dtype=object)\n\n\n\n#bandingkan nilai y pada data uji dengan hasil prediksi\ncomparison = {\"y_test\" : y_test,\n              \"Predicted\": predTree}\ncomp = pd.DataFrame(comparison)\ncomp\n\n\n\n\n\n\n\n\n\ny_test\nPredicted\n\n\n\n\n10\ndrugC\ndrugC\n\n\n90\ndrugY\ndrugY\n\n\n132\ndrugX\ndrugX\n\n\n23\ndrugY\ndrugY\n\n\n145\ndrugX\ndrugX\n\n\n34\ndrugX\ndrugX\n\n\n154\ndrugY\ndrugY\n\n\n37\ndrugX\ndrugX\n\n\n49\ndrugY\ndrugY\n\n\n58\ndrugX\ndrugX\n\n\n123\ndrugY\ndrugY\n\n\n47\ndrugC\ndrugC\n\n\n195\ndrugC\ndrugC\n\n\n121\ndrugY\ndrugY\n\n\n108\ndrugB\ndrugB\n\n\n135\ndrugX\ndrugX\n\n\n61\ndrugA\ndrugA\n\n\n24\ndrugY\ndrugY\n\n\n157\ndrugY\ndrugY\n\n\n84\ndrugC\ndrugC\n\n\n181\ndrugX\ndrugX\n\n\n102\ndrugC\ndrugC\n\n\n45\ndrugX\ndrugX\n\n\n19\ndrugY\ndrugY\n\n\n125\ndrugY\ndrugY\n\n\n142\ndrugB\ndrugB\n\n\n41\ndrugB\ndrugB\n\n\n2\ndrugC\ndrugC\n\n\n166\ndrugY\ndrugY\n\n\n94\ndrugY\ndrugY\n\n\n28\ndrugY\ndrugY\n\n\n9\ndrugY\ndrugY\n\n\n193\ndrugC\ndrugC\n\n\n74\ndrugY\ndrugY\n\n\n164\ndrugY\ndrugY\n\n\n91\ndrugY\ndrugY\n\n\n115\ndrugY\ndrugY\n\n\n88\ndrugY\ndrugY\n\n\n36\ndrugA\ndrugA\n\n\n160\ndrugX\ndrugX\n\n\n172\ndrugY\ndrugY\n\n\n48\ndrugY\ndrugY\n\n\n22\ndrugY\ndrugY\n\n\n136\ndrugB\ndrugB\n\n\n62\ndrugY\ndrugY\n\n\n165\ndrugY\ndrugY\n\n\n140\ndrugA\ndrugA\n\n\n100\ndrugA\ndrugA\n\n\n81\ndrugX\ndrugX\n\n\n159\ndrugX\ndrugX\n\n\n75\ndrugY\ndrugY\n\n\n0\ndrugY\ndrugY\n\n\n29\ndrugY\ndrugY\n\n\n12\ndrugY\ndrugY\n\n\n63\ndrugX\ndrugX\n\n\n182\ndrugX\ndrugX\n\n\n105\ndrugX\ndrugX\n\n\n176\ndrugA\ndrugA\n\n\n33\ndrugY\ndrugY\n\n\n174\ndrugA\ndrugA\n\n\n\n\n\n\n\n\n\n\nAkurasi\n\nfrom sklearn.metrics import accuracy_score\nprint(\"Accuracy : \", accuracy_score(y_test, predTree))\n\nAccuracy :  1.0\n\n\n\n\nVisualisasi Decision Tree\n\nfrom sklearn import tree\n\n\nfeatureNames = my_data.columns[0:5]\n\ngraph = tree.plot_tree(drugtree,\n                       feature_names=featureNames,\n                       class_names=np.unique(y_train),\n                       filled=True)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul5.html#support-vector-machine",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul5.html#support-vector-machine",
    "title": "Modul 5 Sains Data: Decision Tree, SVM",
    "section": "3. Support Vector Machine",
    "text": "3. Support Vector Machine\nSVM adalah algoritma supervised learning utk klasifikasi dengan cara menemukan separator berupa hyperplane (biasanya utk binary classification)\n\nPetakan fitur (kolom, bentuk awalnya 1d) ke ruang dimensi yg lebih tinggi (contohnya 3D) menggunakan fungsi kernel (linear, Radial Basis Function, polinom, sigmoid, dsb)\nTemukan separatornya (utk di ruang 3d biasanya bentuknya bidang)\n\n\nHyperplane yg baik adalah yg memiliki margin lebih besar (jarak ke support vector)\n\n\n\n\nSVM\n\n\nKali ini, kita akan melakukan klasifikasi sebuah cell apakah cell tersebut jinak atau ganas (berpotensi kanker)\n\n#install dulu package bila belum memiliki sklearn\n!pip install scikit-learn==0.23.1\n\n\nImport Module\n\n#import modul yang diperlukan\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\n\nImport Dataset\nPada module kali ini, akan digunakan data csv cell samples (cell_samples.csv) yang bisa didownload dari:\n\nDirect download (langsung dari GitHub Pages ini)\nKaggle: https://www.kaggle.com/datasets/sam1o1/cell-samplescsv\n\n\n#memuat dataframe\ncell_df=pd.read_csv(\"./cell_samples.csv\")\n\n\ncell_df.head()\n\n\n\n\n\n\n\n\n\nID\nClump\nUnifSize\nUnifShape\nMargAdh\nSingEpiSize\nBareNuc\nBlandChrom\nNormNucl\nMit\nClass\n\n\n\n\n0\n1000025\n5\n1\n1\n1\n2\n1\n3\n1\n1\n2\n\n\n1\n1002945\n5\n4\n4\n5\n7\n10\n3\n2\n1\n2\n\n\n2\n1015425\n3\n1\n1\n1\n2\n2\n3\n1\n1\n2\n\n\n3\n1016277\n6\n8\n8\n1\n3\n4\n3\n7\n1\n2\n\n\n4\n1017023\n4\n1\n1\n3\n2\n1\n3\n1\n1\n2\n\n\n\n\n\n\n\n\n\n#melihat sebaran datanya menggunakan scatterplot\nax = cell_df[cell_df['Class']==4][0:50].plot(kind='scatter', x='Clump', y = 'UnifSize', color = 'Blue',\n                                             label = 'ganas')\ncell_df[cell_df['Class']==2][0:50].plot(kind='scatter', x='Clump', y = 'UnifSize', color = 'Yellow', \n                                        label ='jinak',ax=ax)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nPreprocessing\n\n#cek type dari masing2 feature/kolom\ncell_df.dtypes\n\nID              int64\nClump           int64\nUnifSize        int64\nUnifShape       int64\nMargAdh         int64\nSingEpiSize     int64\nBareNuc        object\nBlandChrom      int64\nNormNucl        int64\nMit             int64\nClass           int64\ndtype: object\n\n\n\ncell_df = cell_df[pd.to_numeric(cell_df['BareNuc'],errors=\"coerce\").notnull()] #mengatasi value yg error menjadi NaN\ncell_df['BareNuc']=cell_df['BareNuc'].astype('int') #mengubah type menjadi integer\ncell_df.dtypes\n\nID             int64\nClump          int64\nUnifSize       int64\nUnifShape      int64\nMargAdh        int64\nSingEpiSize    int64\nBareNuc        int32\nBlandChrom     int64\nNormNucl       int64\nMit            int64\nClass          int64\ndtype: object\n\n\n\n\nTrain Test Split\n\n#set X\nfeature_df = cell_df[['Clump', 'UnifSize','UnifShape','MargAdh','SingEpiSize','BareNuc','BlandChrom','NormNucl','Mit']].values\nX = np.asarray(feature_df)\nX[0:5]\n\narray([[ 5,  1,  1,  1,  2,  1,  3,  1,  1],\n       [ 5,  4,  4,  5,  7, 10,  3,  2,  1],\n       [ 3,  1,  1,  1,  2,  2,  3,  1,  1],\n       [ 6,  8,  8,  1,  3,  4,  3,  7,  1],\n       [ 4,  1,  1,  3,  2,  1,  3,  1,  1]], dtype=int64)\n\n\n\n#set Y\ncell_df['Class'] = cell_df['Class'].astype('int')\ny=np.asarray(cell_df['Class'])\ny[0:5]\n\narray([2, 2, 2, 2, 2])\n\n\n\n#train-test split\ntrain_x,test_x,train_y,test_y=train_test_split(X,y, test_size=0.2,random_state=4)\nprint('Train set:', train_x.shape,train_y.shape)\nprint('Train set:', test_x.shape,test_y.shape)\n\nTrain set: (546, 9) (546,)\nTrain set: (137, 9) (137,)\n\n\n\n\nModelling\n\n#membuat model\nfrom sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit(train_x,train_y)\n\nSVC()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVC?Documentation for SVCiFittedSVC() \n\n\n\n#Prediksi\nyhat = clf.predict(test_x)\nyhat[0:5]\n\narray([2, 4, 2, 4, 2])\n\n\n\n\nEvaluasi\n\n#jaccard score\nfrom sklearn.metrics import jaccard_score\njaccard_score(test_y,yhat,pos_label=2)\n\n0.9444444444444444\n\n\n\n#f1-score\nfrom sklearn.metrics import f1_score\nf1_score(test_y,yhat,pos_label=2)\n\n0.9714285714285714\n\n\n\n#visualisasi confusion matrix\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n  \"\"\"\n  This function prints and plots the confusion matrix.\n  Normalization can be applied by setting `normalize=True`.\n  \"\"\"\n  if normalize:\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    print(\"Normalized confusion matrix\")\n  else:\n    print('Confusion matrix, without normalization')\n \n  print(cm)\n\n  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n  plt.title(title)\n  plt.colorbar()\n  tick_marks = np.arange(len(classes))\n  plt.xticks(tick_marks, classes, rotation=45)\n  plt.yticks(tick_marks, classes)\n  \n  fmt = '.2f' if normalize else 'd'\n  thresh = cm.max() / 2.\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, format(cm[i, j], fmt),\n             horizontalalignment=\"center\",\n             color=\"white\" if cm[i, j] &gt; thresh else \"black\")\n  plt.tight_layout()\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label')\nprint(confusion_matrix(test_y, yhat, labels=[2,4]))\n\n[[85  5]\n [ 0 47]]\n\n\n\n#confusion matrix\ncnf_matrix =confusion_matrix(test_y, yhat, labels=[2,4])\nplt.figure()\nplot_confusion_matrix(cnf_matrix,classes=['Jinak=2', 'Ganas=4'],normalize = False, title='Confusion matrix')\n\nConfusion matrix, without normalization\n[[85  5]\n [ 0 47]]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul7.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul7.html",
    "title": "Modul 7 Praktikum Sains Data: Pengantar Neural Network dengan TensorFlow & Keras",
    "section": "",
    "text": "Kembali ke Sains Data\nSekarang kita sudah masuk ke materi artificial neural network (ANN) atau biasa disebut neural network (NN), yang mendasari dunia deep learning.\nSaat modul praktikum ini disusun (April 2024), ada dua framework utama untuk deep learning di Python, yaitu:\n\nTensorFlow: https://www.tensorflow.org/\n(dan Keras di dalamnya: https://keras.io/)\nPyTorch: https://pytorch.org/\n\nKedua framework ini bersaing. Umumnya, TensorFlow lebih sering digunakan di industri, sedangkan PyTorch lebih sering digunakan dalam riset/penelitian.\nDi pertemuan kali ini, kita akan membahas TensorFlow, baik penggunaannya secara sendiri (pure TensorFlow, yaitu tanpa Keras) maupun dengan bantuan Keras. Kalau belum punya, instal terlebih dahulu:\n\npip install tensorflow\n\nKeras terinstal bersama TensorFlow (karena Keras ada di dalamnya).\nLalu import:\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n\nOverview:\n\nSecara umum, suatu neural network terdiri dari sejumlah layer atau lapisan (minimal dua).\nLayer pertama disebut input layer, dan layer terakhir disebut output layer.\nTiap layer terdiri dari sejumlah neuron, yang masing-masing bisa menyimpan suatu nilai.\nKecuali input layer, tiap neuron terhubung dengan sejumlah neuron di layer sebelumnya.\nTiap sambungan terdiri dari nilai weight (sebagai pengali), nilai bias (sebagai pergeseran), dan suatu “fungsi aktivasi” yang menghasilkan nilai untuk neuron tujuan.\nWeight maupun bias disebut parameter dari neural network.\nProses training adalah terus-menerus memperbarui parameter hingga hasil prediksi neural network sudah cukup baik, dengan meminimumkan suatu loss function atau fungsi objektif (yang intinya menghitung error).\nSuatu neural network bisa memiliki sejumlah layer, masing-masing dengan banyaknya neuron tertentu dan fungsi-fungsi aktivasi tertentu. Hal-hal itu disebut hyperparameter dari neural network. Suatu arsitektur adalah suatu pilihan/konfigurasi hyperparameter.\n\n\n\nANN paling pertama adalah perceptron (juga disebut SLP atau single-layer perceptron) yang dirancang oleh Frank Rosenblatt pada tahun 1957 (Géron, 2019). Ini adalah neural network yang paling sederhana, bahkan ini bisa disebut building block dari semua ANN (apabila diberi kebebasan untuk modifikasi). Konsep dasar neural network bisa kita pelajari di sini.\n\nSumber gambar: Aggarwal (2018) hal. 5\nPerceptron hanya terdiri dari satu input layer dan satu output layer. Bahkan, aslinya hanya ada satu neuron di output layer.\nApabila dibutuhkan lebih dari satu neuron di output layer, itu bisa dianggap menggunakan lebih dari satu perceptron (yaitu menggunakan banyaknya perceptron sesuai banyaknya neuron di output layer), yang saling “ditumpuk”:\n\nSumber gambar: Goodfellow, et. al. (2016) hal. 337\nPerhatikan bahwa, tiap neuron di layer asal terhubung dengan tiap neuron di layer tujuan. Layer tujuan seperti ini disebut dense (padat). Kebalikan dari dense adalah sparse.\nAslinya, fungsi aktivasi yang digunakan oleh perceptron adalah Heaviside step function \\(H(v)\\) yang mungkin kalian kenal dari mata kuliah PDB, atau juga disebut threshold activation function:\n\\[H(v) = \\begin{cases}\n    1, & v \\ge 0 \\\\\n    0, & v &lt; 0\n\\end{cases}\\]\nSehingga, untuk output neuron ke-\\(j\\) yang disambung dari \\(n\\) input neuron, model perceptron bisa dirumuskan sebagai berikut:\n\\[y_j = H\\left(\\left(\\sum_{i=1}^{n} w_{ij} x_i \\right) + b_j\\right)\\]\ndengan\n\n\\(x_i\\) adalah nilai pada input neuron ke-\\(i\\)\n\\(y_j\\) adalah nilai pada output neuron ke-\\(j\\)\n\\(w_{ij}\\) adalah parameter weight untuk sambungan input neuron ke-\\(i\\) menuju output neuron ke-\\(j\\)\n\\(b_j\\) adalah parameter bias untuk output neuron ke-\\(j\\)\n\nLebih umumnya,\n\\[y_j = \\Phi\\left(\\left(\\sum_{i=1}^{n} w_{ij} x_i \\right) + b_j\\right)\\]\ndengan \\(\\Phi(v)\\) adalah sembarang fungsi aktivasi.\nNote: seperti di gambar, sebenarnya bias juga bisa dianggap neuron istimewa yang nilai \\(x_i\\) nya selalu satu.\nBiasanya, semua nilai di layer selanjutnya dihitung secara sekaligus menggunakan perkalian matriks, dengan perumusan:\n\\[\\textbf{y} = \\Phi\\left(W^T \\textbf{x} + \\textbf{b}\\right)\\]\ndengan \\(\\textbf{x} = [x_i]\\), \\(\\textbf{y} = [y_j]\\), dan \\(\\textbf{b} = [b_j]\\) adalah vektor kolom, serta \\(W = \\left[w_{ij}\\right]\\) adalah matriks.\nItu untuk satu buah data training.\nBisa saja, beberapa data training diperhitungkan sekaligus. Caranya, vektor kolom \\(\\textbf{x}\\) itu kita “lebarkan” ke samping sehingga menjadi matriks \\(X = [x_{it}]\\), sehingga data training ke-\\(t\\) ada di kolom ke-\\(t\\). Dengan demikian, output nya akan berupa matriks \\(Y = [y_{jt}]\\) dengan hasil untuk data training ke-\\(t\\) ada di kolom ke-\\(t\\). Selain itu, vektor \\(\\textbf{b}\\) perlu diperluas menjadi matriks \\(B\\) dengan tiap kolom identik, dan fungsi aktivasi \\(\\Phi\\) dihitung per kolom.\n\\[Y = \\Phi\\left(W^T X + B\\right)\\]\nKembali ke kasus satu buah data training. Biasanya, dataset disajikan dengan tiap fitur di kolom sendiri, tidak seperti perumusan kita sejauh ini dengan tiap fitur di baris tersendiri. Untuk menyesuaikan, kita bisa men-transpose semuanya:\n\\[\\textbf{y} = \\Phi\\left(\\textbf{x} W + \\textbf{b}\\right)\\]\ndengan \\(\\textbf{x} = [x_i]\\), \\(\\textbf{y} = [y_j]\\), dan \\(\\textbf{b} = [b_j]\\) adalah vektor baris, serta \\(W = \\left[w_{ji}\\right]\\) adalah matriks berisi bobot untuk menyambung ke output neuron ke-\\(j\\) dari input neuron ke-\\(i\\).\n\n\n\nKonsep single-layer perceptron bisa diperumum menjadi multilayer perceptron atau neural network yang biasa kita kenal, dengan menambahkan beberapa layer di antara input layer dan output layer. Semua layer selain input layer dan output layer disebut hidden layer.\n\nSumber gambar: Aggarwal (2018) hal. 18\nKonsep perhitungan antara tiap layer tetap sama, yaitu\n\\[\\textbf{y} = \\Phi\\left(\\textbf{w}^T \\textbf{x} + \\textbf{b}\\right)\\]\n(versi vektor kolom), atau\n\\[\\textbf{y} = \\Phi\\left(\\textbf{x} W + \\textbf{b}\\right)\\]\n(versi vektor baris)\n\n\n\n\nSumber gambar: Aggarwal (2018) hal. 13\nBeberapa fungsi aktivasi adalah (Aggarwal, 2018, hal. 12-13):\n\n“Linier” atau identitas\n\n\\[\\Phi(v) = v\\]\n\nSign (fungsi tanda): \\(\\text{sign}(v)\\) atau \\(\\text{sgn}(v)\\)\n\n\\[\n\\Phi(v) = \\text{sign}(v) = \\begin{cases}\n    1, & v &gt; 0 \\\\\n    0, & v = 0 \\\\\n    -1, & v &lt; 0\n\\end{cases}\n\\]\n\nSigmoid, terkadang dilambangkan \\(\\sigma(v)\\) dan terkadang disebut fungsi aktivasi logistik\n\n\\[\\Phi(v) = \\frac{1}{1 + e^{-v}}\\]\n\n(Soft) tanh: \\(\\tanh(v)\\)\n\n\\[\\Phi(v) = \\frac{e^{2v} - 1}{e^{2v} + 1} = 2 * \\text{sigmoid}(2v) - 1\\]\n\nRectified Linear Unit (ReLU)\n\n\\[\\Phi(v) = \\max\\{v, 0\\}\\]\n\nHard tanh\n\n\\[\\Phi(v) = \\max\\{\\min\\{v, 1\\}, -1\\}\\]\nFungsi aktivasi yang paling sering digunakan adalah ReLU, kecuali untuk output layer.\nUntuk output layer, biasanya,\n\nuntuk regresi, banyaknya neuron sesuai banyaknya nilai prediksi (umumnya hanya satu), dan digunakan fungsi aktivasi linier\nuntuk klasifikasi multiclass (lebih dari dua kelas), biasanya banyaknya output neuron sesuai banyaknya kelas, dan digunakan fungsi aktivasi softmax sebagai berikut, agar output berupa peluang tiap kelas:\n\n\\[\\Phi(\\overline{v})_i = \\frac{\\exp(v_i)}{\\sum_{j=1}^k \\exp(v_j)}\\]\n\nuntuk klasifikasi biner, hanya ada satu neuron di output layer, dan digunakan fungsi aktivasi sigmoid. (Keberadaan hanya satu output neuron lebih hemat daripada menggunakan dua output neuron)\n\n\n\n\nMisalkan \\(y_i\\) adalah nilai sebenarnya dan \\(\\hat{y}_i\\) adalah hasil prediksi.\nUntuk regresi, biasa digunakan MSE (mean squared error), juga disebut L2 loss:\n\\[\\text{MSE}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} \\left( y_i - \\hat{y}_i \\right)^2\\]\nUntuk klasifikasi, biasa digunakan yang namanya cross-entropy loss, juga disebut logistic loss atau log loss:\n\\[L_{\\text{log}}(y,\\hat{y}) = -(y \\ln (\\hat{y}) + (1 - y) \\ln (1 - \\hat{y}))\\]\n\n\n\nProses training untuk neural network dilakukan secara iteratif, yaitu tiap iterasi akan memperbarui parameter sehingga nilai loss function menjadi lebih kecil.\nTiap iterasi melakukan langkah-langkah berikut untuk tiap data training:\n\nForward pass: menghitung nilai output akhir, yaitu \\(\\hat{y}\\) (hasil prediksi), berdasarkan input data training.\nMenghitung loss antara \\(y\\) (nilai asli) dan \\(\\hat{y}\\)\nBackpropagation: menghitung gradien dari loss terhadap tiap parameter, secara “mundur”\nUpdate optimizer: menggunakan algoritma optimizer seperti gradient descent untuk memperbarui parameter-parameter (weights and biases) berdasarkan gradien dari loss\nNote: ada banyak optimizer, seperti gradient descent, SGD (stochastic gradient descent), dan Adam (adaptive moment estimation). Pilihan optimizer (serta parameter-parameter yang bisa diatur untuk optimizer, seperti learning rate) juga menjadi hyperparameter untuk neural network.\n\nNote: istilah backward pass meliputi langkah backpropagation dan update optimizer.\nApabila data training sangat banyak, terkadang data training tersebut dibagi menjadi beberapa batch, dan tiap iterasi menggunakan batch yang berbeda. Apabila semua batch sudah diproses, sebutannya adalah satu epoch. Sehingga, satu epoch terdiri dari sejumlah iterasi sesuai banyaknya batch.\n(Apabila data training tidak dibagi menjadi batch, maka satu epoch sama dengan satu iterasi.)\n\n\n\nMetode gradient descent mencari minimum lokal dari suatu fungsi \\(g\\) (dalam hal ini, loss function) dengan rumus iterasi seperti berikut:\n\\[\\textbf{x}_{i+1} = \\textbf{x}_i - \\eta \\nabla g\\left(\\textbf{x}_i\\right)\\]\ndengan \\(\\eta\\) adalah learning rate. Simbol nabla (\\(\\nabla\\)) menandakan perhitungan gradien.\nPerhatikan bahwa gradien menandakan arah tercepat untuk kenaikan fungsi, seringkali disebut direction of steepest ascent. Di sini, justru kita mengurangi; atau sama saja, menambah dengan kebalikannya, yaitu arah tercepat untuk penurunan fungsi. Sedangkan, learning rate melambangkan seberapa jauh kita melangkah ke arah penurunan tersebut. Harapannya, kita akan cepat konvergen menuju minimum fungsi, karena kita terus melangkah ke arah penurunan tercepat.\nVariasi gradient descent adalah SGD (stochastic gradient descent). Bedanya sederhana saja:\n\nGradient descent selalu memanfaatkan keseluruhan data training yang diberikan (lebih tepatnya, keseluruhan batch) di tiap iterasi.\nSedangkan, SGD selalu memilih sebagian data training saja (lebih tepatnya, sebagian dari batch), dan cara memilihnya bersifat random atau disebut stokastik.\n\nKeuntungan SGD dibandingkan gradient descent biasa:\n\nWaktu training menjadi lebih cepat\nTidak rawan terjebak di minimum lokal: https://www.youtube.com/watch?v=UmathvAKj80&t=102\n\n\n\n\nKetika menggunakan metode machine learning yang di-training secara iteratif, seperti neural network, biasanya ada juga yang namanya validation data. Sehingga, di awal, dataset dipisah menjadi data train, data validation, dan data test.\nGunanya, kita bisa menguji akurasi model di akhir tiap epoch, menggunakan data validation daripada data test.\nRasio yang paling sering digunakan adalah 80-10-10, yaitu 80% data train, 10% data validation, dan 10% data test.\nApabila menggunakan scikit-learn, untuk melakukan train-validation-test split, caranya adalah dengan split dua kali, yaitu\n\nSplit menjadi data “train” dan data test\nData “train” itu di-split lagi menjadi data train sesungguhnya dan data validation\n\natau bisa juga\n\nSplit menjadi data train dan data “test”\nData “test” itu di-split lagi menjadi data validation dan data test sesungguhnya\n\n\n\n\n\n\nimport tensorflow as tf\n\n\n\nTensor adalah semacam perumuman dari array/vektor ataupun matriks.\n\nSkalar (bilangan) adalah tensor berdimensi nol (atau rank nol).\nArray atau vektor adalah tensor berdimensi satu (atau rank satu).\nMatriks adalah tensor berdimensi dua (atau rank dua).\nIstilah “tensor” biasanya merujuk pada tensor berdimensi tiga (atau rank tiga), yaitu semacam matriks tapi tiga dimensi, sehingga ada baris, kolom, dan satu dimensi lagi.\n\nFitur tensor di TensorFlow mirip dengan fitur array di numpy, yang memang juga bisa multidimensi.\n\nx = tf.zeros(shape = (3,4))\nprint(x)\n\ntf.Tensor(\n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]], shape=(3, 4), dtype=float32)\n\n\n\nx = tf.ones(shape = (3,4))\nprint(x)\n\ntf.Tensor(\n[[1. 1. 1. 1.]\n [1. 1. 1. 1.]\n [1. 1. 1. 1.]], shape=(3, 4), dtype=float32)\n\n\nUntuk menentukan array kita sendiri, di numpy digunakan numpy.array.\nUntuk menentukan tensor kita sendiri, di TensorFlow digunakan tensorflow.constant (agar nilainya tidak bisa diubah) atau tensorflow.Variable (nilainya bisa diubah).\nPada umumnya (apabila tidak ada keterangan), tensor di TensorFlow berupa tensorflow.constant\n\nconst0 = tf.constant(1.5)\nprint(const0)\n\ntf.Tensor(1.5, shape=(), dtype=float32)\n\n\n\nprint(tf.rank(const0))\n\ntf.Tensor(0, shape=(), dtype=int32)\n\n\n\nconst1 = tf.constant([2.31, 4.567, 8.9])\nprint(const1)\n\ntf.Tensor([2.31  4.567 8.9  ], shape=(3,), dtype=float32)\n\n\n\nprint(tf.rank(const1))\n\ntf.Tensor(1, shape=(), dtype=int32)\n\n\n\nconst1[0] = 52.5\n\nTypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n\n\n\nconst2 = tf.constant([\n    [1, 2.718, 3.14],\n    [4, 5, 6.28]\n])\nprint(const2)\n\ntf.Tensor(\n[[1.    2.718 3.14 ]\n [4.    5.    6.28 ]], shape=(2, 3), dtype=float32)\n\n\n\nprint(tf.rank(const2))\n\ntf.Tensor(2, shape=(), dtype=int32)\n\n\n\n\n\n\nv = tf.Variable(initial_value = tf.zeros(shape = (2,3)))\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[0., 0., 0.],\n       [0., 0., 0.]], dtype=float32)&gt;\n\n\nAssignment untuk variabel di TensorFlow dilakukan dengan .assign\n\nv.assign(tf.ones(shape = (2,3)))\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[1., 1., 1.],\n       [1., 1., 1.]], dtype=float32)&gt;\n\n\n\nv[0, 0].assign(9)\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[9., 1., 1.],\n       [1., 1., 1.]], dtype=float32)&gt;\n\n\nAda juga .assign_add, sama saja dengan +=\n\nv.assign_add(tf.ones(shape = (2,3)))\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[10.,  2.,  2.],\n       [ 2.,  2.,  2.]], dtype=float32)&gt;\n\n\nSerupa, ada .assign_sub yaitu -=\n\nv.assign_sub(tf.ones(shape = (2,3)))\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[9., 1., 1.],\n       [1., 1., 1.]], dtype=float32)&gt;\n\n\n\n\n\nKita bisa membuat tensor dengan nilai yang random, misalnya dari distribusi normal atau dari distribusi uniform\n\n# dari distribusi normal\nx = tf.random.normal(shape = (2,3), mean = 0, stddev = 1)\nprint(x)\n\ntf.Tensor(\n[[ 1.2542483  -0.41693744  1.0116149 ]\n [-1.4155766   0.17204648 -0.6892854 ]], shape=(2, 3), dtype=float32)\n\n\n\n# dari distribusi uniform\nx = tf.random.uniform(shape = (2,3), minval = 0, maxval = 1)\nprint(x)\n\ntf.Tensor(\n[[0.51321495 0.26164746 0.09113109]\n [0.81229377 0.67134035 0.36057925]], shape=(2, 3), dtype=float32)\n\n\n\n\n\nOperasi di TensorFlow mirip dengan numpy\n\na = 4 * tf.ones((2, 2))\nprint(a)\n\ntf.Tensor(\n[[4. 4.]\n [4. 4.]], shape=(2, 2), dtype=float32)\n\n\n\nb = tf.square(a)\nprint(b)\n\ntf.Tensor(\n[[16. 16.]\n [16. 16.]], shape=(2, 2), dtype=float32)\n\n\n\nc = tf.sqrt(a)\nprint(c)\n\ntf.Tensor(\n[[2. 2.]\n [2. 2.]], shape=(2, 2), dtype=float32)\n\n\n\nd = b + c\nprint(d)\n\ntf.Tensor(\n[[18. 18.]\n [18. 18.]], shape=(2, 2), dtype=float32)\n\n\n\n# perkalian matriks\ne = tf.matmul(a, c)\nprint(e)\n\ntf.Tensor(\n[[16. 16.]\n [16. 16.]], shape=(2, 2), dtype=float32)\n\n\n\n# perkalian per elemen\ne *= d\nprint(e)\n\ntf.Tensor(\n[[288. 288.]\n [288. 288.]], shape=(2, 2), dtype=float32)\n\n\n\n\n\nTensorFlow memiliki fitur yang bernama automatic differentiation, juga disebut autodiff atau autograd. Dengan fitur ini, TensorFlow bisa menghitung turunan/gradien secara otomatis. Fitur ini membedakan antara TensorFlow dengan numpy.\nCaranya adalah menggunakan GradientTape seperti berikut. Semua operasi di dalam with statement dicatat oleh GradientTape, yang kemudian bisa menghitung gradiennya.\nContohnya, turunan \\(x^3\\) terhadap \\(x\\) di \\(x=4\\) adalah \\(3(4)^2 = 48\\).\n\nx = tf.Variable(4.0)\nwith tf.GradientTape() as tape:\n    y = x ** 3\ndy_dx = tape.gradient(y, x)\nprint(dy_dx)\n\ntf.Tensor(48.0, shape=(), dtype=float32)\n\n\nTidak harus dengan tensorflow.Variable, bahkan dengan tensorflow.constant juga bisa. Namun, kita harus secara eksplisit meminta TensorFlow untuk memperhatikan nilai x, yaitu dengan .watch\n\nx = tf.constant(4.0)\nwith tf.GradientTape() as tape:\n    tape.watch(x)\n    y = x ** 3\ndy_dx = tape.gradient(y, x)\nprint(dy_dx)\n\ntf.Tensor(48.0, shape=(), dtype=float32)\n\n\nKita bisa menghitung turunan kedua dengan nested with statement seperti berikut, contohnya turunan kedua dari \\(x^3\\) terhadap \\(x\\) di \\(x=4\\) adalah \\(6(4) = 24\\)\n\nx = tf.Variable(4.0)\nwith tf.GradientTape() as tape2:\n    with tf.GradientTape() as tape1:\n        y = x ** 3\n    dy_dx = tape1.gradient(y, x)\ndy2_dx2 = tape2.gradient(dy_dx, x)\nprint(dy2_dx2)\n\ntf.Tensor(24.0, shape=(), dtype=float32)\n\n\n\n\n\n\nPerceptron digunakan untuk klasifikasi biner. Mari kita coba buat model perceptron dengan pure TensorFlow, menggunakannya untuk memprediksi kelas dari titik-titik dua dimensi.\n\n\nDataset titik-titik dua dimensi, dengan dua kelas (misalnya “negatif” dan “positif”), bisa kita generate:\n\nnum_samples_per_class, num_classes = 1000, 2\nnegative_samples = np.random.multivariate_normal(mean = [0,3], cov = [[1,0.5],[0.5,1]], size = num_samples_per_class)\npositive_samples = np.random.multivariate_normal(mean = [3,0], cov = [[1,0.5],[0.5,1]], size = num_samples_per_class)\n\ninputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)\ntargets = np.vstack((\n    np.zeros((num_samples_per_class, 1), dtype = 'float32'),\n    np.ones((num_samples_per_class, 1), dtype = 'float32')\n))\n\n\nprint(inputs.shape)\nprint(targets.shape)\n\n(2000, 2)\n(2000, 1)\n\n\n\nplt.scatter(inputs[:, 0], inputs[:, 1], c=targets[:, 0])\nplt.show()\n\n\n\n\n\n\n\n\nKalau mau, kita bisa susun data ini ke dalam bentuk pandas DataFrame, lalu export ke CSV:\n\ntitik_negatif_positif_df = pd.DataFrame(\n    np.hstack([inputs, targets]),\n    columns = [\"x\", \"y\", \"kelas\"]\n)\n\n\ntitik_negatif_positif_df\n\n\n\n\n\n\n\n\nx\ny\nkelas\n\n\n\n\n0\n1.173375\n4.570637\n0.0\n\n\n1\n0.195961\n3.504604\n0.0\n\n\n2\n0.121400\n2.163783\n0.0\n\n\n3\n-1.170182\n3.882771\n0.0\n\n\n4\n-0.424403\n0.534641\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n2.423160\n-0.337196\n1.0\n\n\n1996\n1.949836\n-0.627813\n1.0\n\n\n1997\n2.109928\n-0.382492\n1.0\n\n\n1998\n4.178664\n0.486168\n1.0\n\n\n1999\n2.326363\n1.228249\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\ntitik_negatif_positif_df.to_csv(\"./titik_negatif_positif.csv\", index=False)\n\n\n\n\nTentunya, karena titik-titiknya di-generate secara random, mungkin saja titik-titik yang kalian peroleh akan sedikit berbeda, bahkan tiap kali di-run ulang akan berbeda.\nKalau kalian mau menyamakan dengan modul ini, CSV nya bisa di-download dari GitHub Pages ini: titik_negatif_positif.csv\nKita bisa import kembali:\n\ndf = pd.read_csv(\"./titik_negatif_positif.csv\", dtype=\"float32\")\n\nKali ini, kita tambahkan keterangan dtype=\"float32\". Ini penting, karena TensorFlow biasanya menangani float32 (yaitu tipe data float dengan penyimpanan 32-bit), bukan float64 yang biasa digunakan oleh pandas.\n\ndf\n\n\n\n\n\n\n\n\nx\ny\nkelas\n\n\n\n\n0\n1.173375\n4.570637\n0.0\n\n\n1\n0.195961\n3.504604\n0.0\n\n\n2\n0.121400\n2.163783\n0.0\n\n\n3\n-1.170182\n3.882771\n0.0\n\n\n4\n-0.424403\n0.534641\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n2.423160\n-0.337196\n1.0\n\n\n1996\n1.949836\n-0.627813\n1.0\n\n\n1997\n2.109928\n-0.382492\n1.0\n\n\n1998\n4.178664\n0.486168\n1.0\n\n\n1999\n2.326363\n1.228249\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2000 entries, 0 to 1999\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   x       2000 non-null   float32\n 1   y       2000 non-null   float32\n 2   kelas   2000 non-null   float32\ndtypes: float32(3)\nmemory usage: 23.6 KB\n\n\n\ninputs_df = df.drop(columns=[\"kelas\"])\ntargets_df = df[[\"kelas\"]]\n\n\ninputs_df\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n1.173375\n4.570637\n\n\n1\n0.195961\n3.504604\n\n\n2\n0.121400\n2.163783\n\n\n3\n-1.170182\n3.882771\n\n\n4\n-0.424403\n0.534641\n\n\n...\n...\n...\n\n\n1995\n2.423160\n-0.337196\n\n\n1996\n1.949836\n-0.627813\n\n\n1997\n2.109928\n-0.382492\n\n\n1998\n4.178664\n0.486168\n\n\n1999\n2.326363\n1.228249\n\n\n\n\n2000 rows × 2 columns\n\n\n\n\ntargets_df\n\n\n\n\n\n\n\n\nkelas\n\n\n\n\n0\n0.0\n\n\n1\n0.0\n\n\n2\n0.0\n\n\n3\n0.0\n\n\n4\n0.0\n\n\n...\n...\n\n\n1995\n1.0\n\n\n1996\n1.0\n\n\n1997\n1.0\n\n\n1998\n1.0\n\n\n1999\n1.0\n\n\n\n\n2000 rows × 1 columns\n\n\n\n\nplt.scatter(inputs_df[\"x\"], inputs_df[\"y\"], c=targets[\"kelas\"])\nplt.show()\n\n\n\n\n\n\n\n\nTensorFlow kurang bisa menangani pandas DataFrame, sehingga harus kita ubah jadi array numpy:\n\ninputs = inputs_df.to_numpy()\ntargets = targets_df.to_numpy()\n\n\nprint(inputs.shape)\nprint(targets.shape)\n\n(2000, 2)\n(2000, 1)\n\n\n\n\n\nUntuk input dua dimensi dan klasifikasi biner, kita perlu perceptron dengan dua neuron di input layer dan satu neuron di output layer. Sebelum proses training dimulai, nilai matriks \\(W\\) dan vektor kolom \\(b\\) diisi secara random terlebih dahulu.\n\ninput_dim = 2\noutput_dim = 1\nW = tf.Variable(tf.random.normal(shape = (input_dim, output_dim)))\nb = tf.Variable(tf.random.normal(shape = (output_dim,)))\n\n\n# forward pass\ndef model(inputs):\n    return tf.sigmoid(\n        tf.matmul(inputs, W) + b\n    )\n\n\n# cross entropy loss\ndef entropy_loss(y, yhat):\n    per_sample_losses = - y * tf.math.log(yhat) - (1-y) * tf.math.log(1-yhat)\n    return tf.reduce_mean(per_sample_losses)\n\n\n# satu epoch di training loop\nlearning_rate = 0.1\ndef training_step(inputs, targets):\n    with tf.GradientTape() as tape:\n        predictions = model(inputs)\n        loss = entropy_loss(targets, predictions)\n\n        grad_loss_wrt_W, grad_loss_wrt_b = tape.gradient(loss, [W, b])\n\n        # update menggunakan gradient descent\n        W.assign_sub(learning_rate * grad_loss_wrt_W)\n        b.assign_sub(learning_rate * grad_loss_wrt_b)\n        \n        return loss\n\n\n# training loop\nfor epoch in range(100):\n    loss = training_step(inputs, targets)\n    print(f\"Loss at epoch {epoch}: {loss}\")\n\nLoss at epoch 0: 3.254241466522217\nLoss at epoch 1: 2.841676712036133\nLoss at epoch 2: 2.446164608001709\nLoss at epoch 3: 2.0740654468536377\nLoss at epoch 4: 1.7329306602478027\nLoss at epoch 5: 1.4304780960083008\nLoss at epoch 6: 1.1727027893066406\nLoss at epoch 7: 0.9617642760276794\nLoss at epoch 8: 0.7950283288955688\nLoss at epoch 9: 0.6661190390586853\nLoss at epoch 10: 0.5672049522399902\nLoss at epoch 11: 0.4909631013870239\nLoss at epoch 12: 0.43148183822631836\nLoss at epoch 13: 0.38434457778930664\nLoss at epoch 14: 0.34636563062667847\nLoss at epoch 15: 0.31527045369148254\nLoss at epoch 16: 0.2894296944141388\nLoss at epoch 17: 0.26766350865364075\nLoss at epoch 18: 0.24910621345043182\nLoss at epoch 19: 0.23311251401901245\nLoss at epoch 20: 0.21919457614421844\nLoss at epoch 21: 0.2069779932498932\nLoss at epoch 22: 0.19617150723934174\nLoss at epoch 23: 0.18654564023017883\nLoss at epoch 24: 0.1779175102710724\nLoss at epoch 25: 0.17013971507549286\nLoss at epoch 26: 0.16309219598770142\nLoss at epoch 27: 0.1566763073205948\nLoss at epoch 28: 0.15081030130386353\nLoss at epoch 29: 0.14542590081691742\nLoss at epoch 30: 0.1404656320810318\nLoss at epoch 31: 0.13588076829910278\nLoss at epoch 32: 0.13162976503372192\nLoss at epoch 33: 0.12767699360847473\nLoss at epoch 34: 0.12399168312549591\nLoss at epoch 35: 0.12054720520973206\nLoss at epoch 36: 0.11732034385204315\nLoss at epoch 37: 0.11429077386856079\nLoss at epoch 38: 0.11144062876701355\nLoss at epoch 39: 0.10875413566827774\nLoss at epoch 40: 0.10621732473373413\nLoss at epoch 41: 0.10381780564785004\nLoss at epoch 42: 0.10154449194669724\nLoss at epoch 43: 0.0993875041604042\nLoss at epoch 44: 0.09733790904283524\nLoss at epoch 45: 0.09538772702217102\nLoss at epoch 46: 0.09352975338697433\nLoss at epoch 47: 0.09175743162631989\nLoss at epoch 48: 0.09006485342979431\nLoss at epoch 49: 0.08844659477472305\nLoss at epoch 50: 0.08689778298139572\nLoss at epoch 51: 0.08541391044855118\nLoss at epoch 52: 0.08399088680744171\nLoss at epoch 53: 0.08262495696544647\nLoss at epoch 54: 0.0813126489520073\nLoss at epoch 55: 0.08005079627037048\nLoss at epoch 56: 0.07883644849061966\nLoss at epoch 57: 0.07766692340373993\nLoss at epoch 58: 0.07653970271348953\nLoss at epoch 59: 0.07545248419046402\nLoss at epoch 60: 0.07440309226512909\nLoss at epoch 61: 0.07338955998420715\nLoss at epoch 62: 0.07241000235080719\nLoss at epoch 63: 0.0714627057313919\nLoss at epoch 64: 0.07054606825113297\nLoss at epoch 65: 0.0696585550904274\nLoss at epoch 66: 0.06879876554012299\nLoss at epoch 67: 0.06796539574861526\nLoss at epoch 68: 0.06715719401836395\nLoss at epoch 69: 0.06637301295995712\nLoss at epoch 70: 0.06561177223920822\nLoss at epoch 71: 0.06487242877483368\nLoss at epoch 72: 0.06415403634309769\nLoss at epoch 73: 0.06345568597316742\nLoss at epoch 74: 0.06277652084827423\nLoss at epoch 75: 0.06211574003100395\nLoss at epoch 76: 0.061472587287425995\nLoss at epoch 77: 0.06084632873535156\nLoss at epoch 78: 0.06023630499839783\nLoss at epoch 79: 0.05964187532663345\nLoss at epoch 80: 0.0590624064207077\nLoss at epoch 81: 0.05849733576178551\nLoss at epoch 82: 0.057946112006902695\nLoss at epoch 83: 0.05740822106599808\nLoss at epoch 84: 0.05688317120075226\nLoss at epoch 85: 0.056370481848716736\nLoss at epoch 86: 0.05586971715092659\nLoss at epoch 87: 0.0553804449737072\nLoss at epoch 88: 0.05490226671099663\nLoss at epoch 89: 0.05443479120731354\nLoss at epoch 90: 0.05397764965891838\nLoss at epoch 91: 0.0535304993391037\nLoss at epoch 92: 0.05309300124645233\nLoss at epoch 93: 0.05266483128070831\nLoss at epoch 94: 0.05224568769335747\nLoss at epoch 95: 0.051835279911756516\nLoss at epoch 96: 0.05143332853913307\nLoss at epoch 97: 0.05103955790400505\nLoss at epoch 98: 0.05065372586250305\nLoss at epoch 99: 0.05027557164430618\n\n\n\n\n\nSekarang training sudah selesai, kita bisa gunakan model kita untuk memprediksi kelas berdasarkan inputs (koordinat titik-titik)\n\npredictions = model(inputs)\n\nAkibat penggunaan fungsi aktivasi sigmoid, hasil prediksi cukup jelas, apakah kelas pertama (kelas 0) atau kelas kedua (kelas 1):\n\nprint(predictions)\n\ntf.Tensor(\n[[0.0185734 ]\n [0.01658478]\n [0.06427375]\n ...\n [0.94514835]\n [0.99050665]\n [0.7908128 ]], shape=(2000, 1), dtype=float32)\n\n\nKita bisa menampilkan hasil prediksi ini dengan aturan pemilihan warna (c) seperti berikut:\n\napabila nilai prediksinya lebih dari 0.5 (pernyataan “lebih besar dari 0.5” bernilai benar), ia tergolong kelas 1 (atau sama saja nilai True);\nselain itu (pernyataan “lebih besar dari 0.5” bernilai salah), ia tergolong kelas 0 (atau sama saja nilai False).\n\n\nplt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:, 0] &gt; 0.5)\nplt.show()\n\n\n\n\n\n\n\n\nKinerja perceptron cukup mirip regresi logistik, ataupun SVM dengan kernel linier. Perhatikan bahwa, di hasil prediksi ini, seolah-olah ada perbatasan atau garis pemisah antara kedua kelas. Kalau kita bandingkan dengan data aslinya, sebenarnya ada beberapa titik yang melewati perbatasan tersebut, dan akhirnya terjadi misklasifikasi.\n\n\n\n\nDengan pure TensorFlow, banyak hal yang harus kita susun secara manual. Untuk neural network kecil seperti perceptron, mungkin tidak masalah. Namun, neural network pada umumnya sangat “dalam” atau deep, dengan puluhan hidden layer yang bervariasi.\nDaripada benar-benar membuatnya semua secara manual, ada yang namanya Keras yang sangat menyederhanakan proses penyusunan neural network. Biasanya, daripada benar-benar membuat neural network secara manual dalam pure TensorFlow seperti tadi, pengguna TensorFlow memanfaatkan Keras.\nKeras tersedia di dalam TensorFlow:\n\nfrom tensorflow import keras\n\nPerlu dicatat, ketika menggunakan Keras, sebaiknya semua fungsi/operasi yang kita gunakan juga dari dalam Keras daripada langsung dari TensorFlow. Misalnya, daripada tf.matmul, gunakan keras.ops.matmul\nTapi kalau error, tidak masalah masih menggunakan tf karena Keras masih dalam pengembangan (menuju Keras versi 3, bisa dibaca di sini: https://keras.io/guides/migrating_to_keras_3/). Mungkin, di versi yang akan datang, sudah tidak error lagi.\nDalam Keras, ada tiga “cara” atau API (application programming interface) yang bisa kita gunakan untuk menyusun neural network, yaitu\n\nSequential API\nFunctional API\nSubclassing API (yaitu dengan OOP)\n\nDi pertemuan kali ini, kita akan mencoba cara yang paling sederhana, yaitu dengan Sequential API.\nDatanya sudah siap dari yang tadi:\n\nprint(inputs.shape)\nprint(targets.shape)\n\n(2000, 2)\n(2000, 1)\n\n\n\n\nKita susun layer nya terlebih dahulu. Kali ini, kita akan membuat perceptron seperti yang cara manual / pure TensorFlow tadi. Untuk itu, kedua kode ini ekuivalen:\n\n# langsung menentukan semua layer di awal, dengan memasukkan list\nmodel2 = keras.Sequential(\n    [\n        keras.layers.InputLayer(input_shape = (2,)),\n        keras.layers.Dense(units = 1, activation = 'sigmoid')\n    ]\n)\n\n\n# menambahkan layer secara berangsur-angsur\nmodel2 = keras.Sequential()\nmodel2.add(keras.layers.InputLayer(input_shape = (2,)))\nmodel2.add(keras.layers.Dense(units = 1, activation = 'sigmoid'))\n\nDaripada menggunakan string, untuk menentukan fungsi aktivasi di kedua cara di atas, kita juga bisa mengetik keras.activations.sigmoid seperti berikut:\n\n# langsung menentukan semua layer di awal, dengan memasukkan list\nmodel2 = keras.Sequential(\n    [\n        keras.layers.InputLayer(input_shape = (2,)),\n        keras.layers.Dense(units = 1, activation = keras.activations.sigmoid)\n    ]\n)\n\n\n# menambahkan layer secara berangsur-angsur\nmodel2 = keras.Sequential()\nmodel2.add(keras.layers.InputLayer(input_shape = (2,)))\nmodel2.add(keras.layers.Dense(units = 1, activation = keras.activations.sigmoid))\n\n\n\n\nKemudian, kita bisa melihat ringkasan bentuk model yang dihasilkan:\n\nmodel2.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 1)                 3         \n                                                                 \n=================================================================\nTotal params: 3\nTrainable params: 3\nNon-trainable params: 0\n_________________________________________________________________\n\n\nKita juga bisa menampilkan semacam diagram, bahkan menyimpannya ke dalam file:\n\nkeras.utils.plot_model(\n    model2,\n    show_shapes = True,\n    show_layer_activations = True,\n    to_file = \"keras_sequential_model2.png\"\n)\n\n\nFun fact: Keras menggunakan Graphviz untuk membuat diagramnya :)\n\n\n\nUntuk memilih hyperparameter yaitu optimizer dan loss function (dan metrik evaluasi), kedua kode berikut ini ekuivalen:\n\n# dengan string\nmodel2.compile(\n    optimizer = \"sgd\",\n    loss = \"binary_crossentropy\",\n    metrics = [\"binary_accuracy\"]\n)\n\n\n# dengan objek dari class\nmodel2.compile(\n    optimizer = keras.optimizers.SGD(),\n    loss = keras.losses.BinaryCrossentropy(),\n    metrics = [keras.metrics.BinaryAccuracy()]\n)\n\nDengan cara yang kedua, kita juga bisa menentukan hyperparameter seperti learning rate:\n\n# dengan objek dari class\nmodel2.compile(\n    optimizer = keras.optimizers.SGD(learning_rate = 0.01),\n    loss = keras.losses.BinaryCrossentropy(),\n    metrics = [keras.metrics.BinaryAccuracy()]\n)\n\n\n\n\nSelanjutnya, tinggal training, menggunakan .fit seperti di scikit-learn. Bedanya, .fit di sini me-return suatu objek “history” yang berisi catatan loss di tiap epoch\n\nx_train = inputs\ny_train = targets\nhistory2 = model2.fit(x_train, y_train, epochs=100, validation_split=0.2)\n\nEpoch 1/100\n50/50 [==============================] - 2s 19ms/step - loss: 0.9972 - binary_accuracy: 0.4119 - val_loss: 0.3660 - val_binary_accuracy: 0.9975\nEpoch 2/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.3971 - binary_accuracy: 0.9488 - val_loss: 0.2875 - val_binary_accuracy: 0.9975\nEpoch 3/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.2427 - binary_accuracy: 0.9975 - val_loss: 0.2355 - val_binary_accuracy: 0.9925\nEpoch 4/100\n50/50 [==============================] - 0s 10ms/step - loss: 0.1804 - binary_accuracy: 0.9962 - val_loss: 0.1990 - val_binary_accuracy: 0.9925\nEpoch 5/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.1459 - binary_accuracy: 0.9962 - val_loss: 0.1726 - val_binary_accuracy: 0.9925\nEpoch 6/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.1238 - binary_accuracy: 0.9962 - val_loss: 0.1529 - val_binary_accuracy: 0.9925\nEpoch 7/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.1082 - binary_accuracy: 0.9969 - val_loss: 0.1376 - val_binary_accuracy: 0.9925\nEpoch 8/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0966 - binary_accuracy: 0.9962 - val_loss: 0.1254 - val_binary_accuracy: 0.9925\nEpoch 9/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0875 - binary_accuracy: 0.9962 - val_loss: 0.1156 - val_binary_accuracy: 0.9925\nEpoch 10/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0803 - binary_accuracy: 0.9962 - val_loss: 0.1075 - val_binary_accuracy: 0.9925\nEpoch 11/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0744 - binary_accuracy: 0.9962 - val_loss: 0.1006 - val_binary_accuracy: 0.9925\nEpoch 12/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0695 - binary_accuracy: 0.9962 - val_loss: 0.0948 - val_binary_accuracy: 0.9925\nEpoch 13/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0653 - binary_accuracy: 0.9962 - val_loss: 0.0898 - val_binary_accuracy: 0.9925\nEpoch 14/100\n50/50 [==============================] - 1s 14ms/step - loss: 0.0617 - binary_accuracy: 0.9962 - val_loss: 0.0854 - val_binary_accuracy: 0.9925\nEpoch 15/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0585 - binary_accuracy: 0.9962 - val_loss: 0.0815 - val_binary_accuracy: 0.9925\nEpoch 16/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0558 - binary_accuracy: 0.9962 - val_loss: 0.0781 - val_binary_accuracy: 0.9925\nEpoch 17/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0533 - binary_accuracy: 0.9962 - val_loss: 0.0750 - val_binary_accuracy: 0.9925\nEpoch 18/100\n50/50 [==============================] - 1s 17ms/step - loss: 0.0511 - binary_accuracy: 0.9962 - val_loss: 0.0722 - val_binary_accuracy: 0.9925\nEpoch 19/100\n50/50 [==============================] - 1s 17ms/step - loss: 0.0492 - binary_accuracy: 0.9962 - val_loss: 0.0697 - val_binary_accuracy: 0.9925\nEpoch 20/100\n50/50 [==============================] - 1s 12ms/step - loss: 0.0474 - binary_accuracy: 0.9962 - val_loss: 0.0674 - val_binary_accuracy: 0.9925\nEpoch 21/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0458 - binary_accuracy: 0.9962 - val_loss: 0.0653 - val_binary_accuracy: 0.9925\nEpoch 22/100\n50/50 [==============================] - 1s 27ms/step - loss: 0.0443 - binary_accuracy: 0.9962 - val_loss: 0.0634 - val_binary_accuracy: 0.9925\nEpoch 23/100\n50/50 [==============================] - 0s 10ms/step - loss: 0.0429 - binary_accuracy: 0.9969 - val_loss: 0.0616 - val_binary_accuracy: 0.9925\nEpoch 24/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0417 - binary_accuracy: 0.9969 - val_loss: 0.0600 - val_binary_accuracy: 0.9925\nEpoch 25/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0405 - binary_accuracy: 0.9969 - val_loss: 0.0585 - val_binary_accuracy: 0.9925\nEpoch 26/100\n50/50 [==============================] - 1s 12ms/step - loss: 0.0394 - binary_accuracy: 0.9969 - val_loss: 0.0571 - val_binary_accuracy: 0.9925\nEpoch 27/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0384 - binary_accuracy: 0.9969 - val_loss: 0.0558 - val_binary_accuracy: 0.9925\nEpoch 28/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0375 - binary_accuracy: 0.9969 - val_loss: 0.0545 - val_binary_accuracy: 0.9925\nEpoch 29/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0366 - binary_accuracy: 0.9969 - val_loss: 0.0534 - val_binary_accuracy: 0.9925\nEpoch 30/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0358 - binary_accuracy: 0.9969 - val_loss: 0.0523 - val_binary_accuracy: 0.9925\nEpoch 31/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0351 - binary_accuracy: 0.9969 - val_loss: 0.0513 - val_binary_accuracy: 0.9925\nEpoch 32/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0343 - binary_accuracy: 0.9969 - val_loss: 0.0503 - val_binary_accuracy: 0.9925\nEpoch 33/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0337 - binary_accuracy: 0.9969 - val_loss: 0.0494 - val_binary_accuracy: 0.9925\nEpoch 34/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0330 - binary_accuracy: 0.9969 - val_loss: 0.0485 - val_binary_accuracy: 0.9925\nEpoch 35/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0324 - binary_accuracy: 0.9969 - val_loss: 0.0477 - val_binary_accuracy: 0.9925\nEpoch 36/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0318 - binary_accuracy: 0.9969 - val_loss: 0.0469 - val_binary_accuracy: 0.9925\nEpoch 37/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0313 - binary_accuracy: 0.9969 - val_loss: 0.0462 - val_binary_accuracy: 0.9925\nEpoch 38/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0308 - binary_accuracy: 0.9969 - val_loss: 0.0455 - val_binary_accuracy: 0.9925\nEpoch 39/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0303 - binary_accuracy: 0.9969 - val_loss: 0.0448 - val_binary_accuracy: 0.9925\nEpoch 40/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0298 - binary_accuracy: 0.9969 - val_loss: 0.0442 - val_binary_accuracy: 0.9925\nEpoch 41/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0293 - binary_accuracy: 0.9969 - val_loss: 0.0435 - val_binary_accuracy: 0.9925\nEpoch 42/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0289 - binary_accuracy: 0.9969 - val_loss: 0.0429 - val_binary_accuracy: 0.9925\nEpoch 43/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0285 - binary_accuracy: 0.9969 - val_loss: 0.0424 - val_binary_accuracy: 0.9925\nEpoch 44/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0281 - binary_accuracy: 0.9969 - val_loss: 0.0418 - val_binary_accuracy: 0.9925\nEpoch 45/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0277 - binary_accuracy: 0.9969 - val_loss: 0.0413 - val_binary_accuracy: 0.9925\nEpoch 46/100\n50/50 [==============================] - 1s 10ms/step - loss: 0.0274 - binary_accuracy: 0.9969 - val_loss: 0.0408 - val_binary_accuracy: 0.9925\nEpoch 47/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0270 - binary_accuracy: 0.9969 - val_loss: 0.0403 - val_binary_accuracy: 0.9925\nEpoch 48/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0267 - binary_accuracy: 0.9969 - val_loss: 0.0399 - val_binary_accuracy: 0.9925\nEpoch 49/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0263 - binary_accuracy: 0.9969 - val_loss: 0.0394 - val_binary_accuracy: 0.9925\nEpoch 50/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0260 - binary_accuracy: 0.9969 - val_loss: 0.0390 - val_binary_accuracy: 0.9925\nEpoch 51/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0257 - binary_accuracy: 0.9969 - val_loss: 0.0386 - val_binary_accuracy: 0.9925\nEpoch 52/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0254 - binary_accuracy: 0.9969 - val_loss: 0.0382 - val_binary_accuracy: 0.9925\nEpoch 53/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0252 - binary_accuracy: 0.9969 - val_loss: 0.0378 - val_binary_accuracy: 0.9925\nEpoch 54/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0249 - binary_accuracy: 0.9969 - val_loss: 0.0374 - val_binary_accuracy: 0.9925\nEpoch 55/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0246 - binary_accuracy: 0.9969 - val_loss: 0.0371 - val_binary_accuracy: 0.9925\nEpoch 56/100\n50/50 [==============================] - 1s 10ms/step - loss: 0.0244 - binary_accuracy: 0.9969 - val_loss: 0.0367 - val_binary_accuracy: 0.9925\nEpoch 57/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0241 - binary_accuracy: 0.9969 - val_loss: 0.0364 - val_binary_accuracy: 0.9925\nEpoch 58/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0239 - binary_accuracy: 0.9969 - val_loss: 0.0360 - val_binary_accuracy: 0.9925\nEpoch 59/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0237 - binary_accuracy: 0.9969 - val_loss: 0.0357 - val_binary_accuracy: 0.9925\nEpoch 60/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0234 - binary_accuracy: 0.9969 - val_loss: 0.0354 - val_binary_accuracy: 0.9925\nEpoch 61/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0232 - binary_accuracy: 0.9969 - val_loss: 0.0351 - val_binary_accuracy: 0.9925\nEpoch 62/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0230 - binary_accuracy: 0.9969 - val_loss: 0.0348 - val_binary_accuracy: 0.9925\nEpoch 63/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0228 - binary_accuracy: 0.9969 - val_loss: 0.0345 - val_binary_accuracy: 0.9925\nEpoch 64/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0226 - binary_accuracy: 0.9969 - val_loss: 0.0342 - val_binary_accuracy: 0.9925\nEpoch 65/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0224 - binary_accuracy: 0.9969 - val_loss: 0.0340 - val_binary_accuracy: 0.9925\nEpoch 66/100\n50/50 [==============================] - 1s 10ms/step - loss: 0.0222 - binary_accuracy: 0.9969 - val_loss: 0.0337 - val_binary_accuracy: 0.9925\nEpoch 67/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0220 - binary_accuracy: 0.9969 - val_loss: 0.0335 - val_binary_accuracy: 0.9925\nEpoch 68/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0219 - binary_accuracy: 0.9969 - val_loss: 0.0332 - val_binary_accuracy: 0.9925\nEpoch 69/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0217 - binary_accuracy: 0.9969 - val_loss: 0.0330 - val_binary_accuracy: 0.9925\nEpoch 70/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0215 - binary_accuracy: 0.9969 - val_loss: 0.0327 - val_binary_accuracy: 0.9925\nEpoch 71/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0214 - binary_accuracy: 0.9969 - val_loss: 0.0325 - val_binary_accuracy: 0.9925\nEpoch 72/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0212 - binary_accuracy: 0.9969 - val_loss: 0.0323 - val_binary_accuracy: 0.9925\nEpoch 73/100\n50/50 [==============================] - 1s 15ms/step - loss: 0.0211 - binary_accuracy: 0.9969 - val_loss: 0.0320 - val_binary_accuracy: 0.9925\nEpoch 74/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0209 - binary_accuracy: 0.9969 - val_loss: 0.0318 - val_binary_accuracy: 0.9925\nEpoch 75/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0208 - binary_accuracy: 0.9969 - val_loss: 0.0316 - val_binary_accuracy: 0.9925\nEpoch 76/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0206 - binary_accuracy: 0.9969 - val_loss: 0.0314 - val_binary_accuracy: 0.9925\nEpoch 77/100\n50/50 [==============================] - 1s 20ms/step - loss: 0.0205 - binary_accuracy: 0.9969 - val_loss: 0.0312 - val_binary_accuracy: 0.9925\nEpoch 78/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0203 - binary_accuracy: 0.9969 - val_loss: 0.0310 - val_binary_accuracy: 0.9925\nEpoch 79/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0202 - binary_accuracy: 0.9969 - val_loss: 0.0308 - val_binary_accuracy: 0.9925\nEpoch 80/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0201 - binary_accuracy: 0.9969 - val_loss: 0.0306 - val_binary_accuracy: 0.9925\nEpoch 81/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0199 - binary_accuracy: 0.9969 - val_loss: 0.0304 - val_binary_accuracy: 0.9925\nEpoch 82/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0198 - binary_accuracy: 0.9969 - val_loss: 0.0303 - val_binary_accuracy: 0.9925\nEpoch 83/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0197 - binary_accuracy: 0.9969 - val_loss: 0.0301 - val_binary_accuracy: 0.9925\nEpoch 84/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0196 - binary_accuracy: 0.9969 - val_loss: 0.0299 - val_binary_accuracy: 0.9925\nEpoch 85/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0194 - binary_accuracy: 0.9969 - val_loss: 0.0298 - val_binary_accuracy: 0.9925\nEpoch 86/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0193 - binary_accuracy: 0.9969 - val_loss: 0.0296 - val_binary_accuracy: 0.9925\nEpoch 87/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0192 - binary_accuracy: 0.9969 - val_loss: 0.0294 - val_binary_accuracy: 0.9925\nEpoch 88/100\n50/50 [==============================] - 1s 12ms/step - loss: 0.0191 - binary_accuracy: 0.9969 - val_loss: 0.0293 - val_binary_accuracy: 0.9925\nEpoch 89/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0190 - binary_accuracy: 0.9969 - val_loss: 0.0291 - val_binary_accuracy: 0.9925\nEpoch 90/100\n50/50 [==============================] - 1s 14ms/step - loss: 0.0189 - binary_accuracy: 0.9969 - val_loss: 0.0290 - val_binary_accuracy: 0.9925\nEpoch 91/100\n50/50 [==============================] - 1s 13ms/step - loss: 0.0188 - binary_accuracy: 0.9969 - val_loss: 0.0288 - val_binary_accuracy: 0.9925\nEpoch 92/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0187 - binary_accuracy: 0.9969 - val_loss: 0.0287 - val_binary_accuracy: 0.9925\nEpoch 93/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0186 - binary_accuracy: 0.9969 - val_loss: 0.0285 - val_binary_accuracy: 0.9925\nEpoch 94/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0185 - binary_accuracy: 0.9969 - val_loss: 0.0284 - val_binary_accuracy: 0.9925\nEpoch 95/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0184 - binary_accuracy: 0.9969 - val_loss: 0.0282 - val_binary_accuracy: 0.9925\nEpoch 96/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0183 - binary_accuracy: 0.9969 - val_loss: 0.0281 - val_binary_accuracy: 0.9925\nEpoch 97/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0182 - binary_accuracy: 0.9969 - val_loss: 0.0280 - val_binary_accuracy: 0.9925\nEpoch 98/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0181 - binary_accuracy: 0.9969 - val_loss: 0.0278 - val_binary_accuracy: 0.9925\nEpoch 99/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0180 - binary_accuracy: 0.9969 - val_loss: 0.0277 - val_binary_accuracy: 0.9925\nEpoch 100/100\n50/50 [==============================] - 1s 19ms/step - loss: 0.0179 - binary_accuracy: 0.9969 - val_loss: 0.0276 - val_binary_accuracy: 0.9925\n\n\nObjek “history” tersebut memiliki dictionary .history. Kita bisa lihat, apa saja key yang ada:\n\nprint(history2.history.keys())\n\ndict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])\n\n\nTiap key menyimpan data per epoch, sehingga ukurannya sama semua. Oleh karena itu, sebenarnya dictionary ini bisa diubah menjadi pandas DataFrame, yang kemudian bisa kita simpan ke CSV:\n\npd.DataFrame(history2.history).to_csv(\"./keras_sequential_history2.csv\", index=False)\n\nKalau mau menyamakan, file nya bisa kalian download dari GitHub Pages ini: keras_sequential_history2.csv\nKemudian, kita bisa load kembali:\n\nhistory2_df = pd.read_csv(\"./keras_sequential_history2.csv\")\n\n\nhistory2_df\n\n\n\n\n\n\n\n\nloss\nbinary_accuracy\nval_loss\nval_binary_accuracy\n\n\n\n\n0\n0.997174\n0.411875\n0.365997\n0.9975\n\n\n1\n0.397132\n0.948750\n0.287524\n0.9975\n\n\n2\n0.242701\n0.997500\n0.235491\n0.9925\n\n\n3\n0.180374\n0.996250\n0.199048\n0.9925\n\n\n4\n0.145923\n0.996250\n0.172641\n0.9925\n\n\n...\n...\n...\n...\n...\n\n\n95\n0.018302\n0.996875\n0.028094\n0.9925\n\n\n96\n0.018211\n0.996875\n0.027959\n0.9925\n\n\n97\n0.018120\n0.996875\n0.027828\n0.9925\n\n\n98\n0.018030\n0.996875\n0.027700\n0.9925\n\n\n99\n0.017943\n0.996875\n0.027570\n0.9925\n\n\n\n\n100 rows × 4 columns\n\n\n\nDua catatan yang paling sering diperhatikan adalah loss (training loss) dan juga val_loss (validation loss). Bahkan, seringkali kedua nilai ini dibuat gambar plotnya (terhadap epoch), untuk menganalisis bagaimana proses training model.\n\nplt.plot(history2_df[\"loss\"], label = \"training loss\")\nplt.plot(history2_df[\"val_loss\"], label = \"validation loss\")\nplt.xlabel(\"epoch\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nProses training tenryata berjalan dengan sangat baik! Kali ini, baik training loss maupun validation loss turun secara drastis dan terus menuju nol.\nBiasanya, walaupun training loss tidak mungkin naik, terkadang validation loss naik turun, yang bisa jadi pertanda overfitting.\n\n\n\nSeperti di scikit-learn, panggil .predict() untuk melakukan prediksi\n\npredictions2 = model2.predict(inputs)\n\n63/63 [==============================] - 1s 6ms/step\n\n\nAda sedikit progress bar, karena proses prediksi sebenarnya adalah forward pass. Kita bisa matikan progress bar dengan verbose=False\n\npredictions2 = model2.predict(inputs, verbose=False)\n\n\nprint(predictions2)\n\n[[9.8937179e-04]\n [1.2094462e-03]\n [1.4012366e-02]\n ...\n [9.8900378e-01]\n [9.9885350e-01]\n [8.5612518e-01]]\n\n\n\nplt.scatter(inputs[:, 0], inputs[:, 1], c=predictions2[:, 0] &gt; 0.5)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPerintahnya adalah .save(path_tempat_penyimpanan) dengan file format .keras\n\nmodel2.save(\"./keras_sequential_model2.keras\")\n\nKita bisa load kembali model tersebut:\n\nmodel3 = keras.models.load_model(\"keras_sequential_model2.keras\")\n\nHasil prediksinya akan sama (karena modelnya memang sama):\n\npredictions3 = model3.predict(inputs)\n\n63/63 [==============================] - 1s 7ms/step\n\n\n\nnp.array_equal(predictions2, predictions3)\n\nTrue\n\n\n\n\n\nDaripada menyimpan keseluruhan model, kita bisa menyimpan weights atau parameternya saja, dengan perintah .save_weights(path_tempat_penyimpanan) dan file format .weights.h5\n\nmodel2.save_weights(\"keras_sequential_model2.weights.h5\")\n\nUntuk load kembali, kita perlu menyusun layer model terlebih dahulu, sama persis dengan susunan yang aslinya:\n\nmodel4 = keras.Sequential(\n    [\n        keras.layers.InputLayer(input_shape = (2,)),\n        keras.layers.Dense(units = 1, activation = keras.activations.sigmoid)\n    ]\n)\n\nBarulah kita gunakan perintah .load_weights(path_tempat_penyimpanan)\n\nmodel4.load_weights(\"./keras_sequential_model2.weights.h5\")\n\nLagi-lagi, hasil prediksinya akan sama:\n\npredictions4 = model4.predict(inputs)\n\n63/63 [==============================] - 0s 3ms/step\n\n\n\nnp.array_equal(predictions2, predictions4)\n\nTrue\n\n\nPerhatikan bahwa kita belum memanggil model4.compile, artinya kita belum memasang hyperparameter. Meskipun demikian, kita masih bisa melakukan prediksi, karena proses prediksi hanyalah forward pass, yang hanya membutuhkan parameter (weights and biases), yang memang sudah di-load.\nSetelah melakukan model4.compile, dengan hyperparameter yang bahkan tidak harus sama dengan yang aslinya, kita bisa melanjutkan proses training kalau mau.\nMengapa tidak save keseluruhan model saja? Selain lebih hemat memori, contoh kasusnya, kita ingin menyimpan progress dari training model, yang sebenarnya susunan layer nya kita ketahui dengan pasti, seperti contoh model4 di atas.\n\n\n\n\n\n\nUmum digunakan\n\nLinier (ideentitas): keras.activations.linear\nSigmoid: keras.activations.sigmoid\nReLU: keras.activations.relu\n(Soft) tanh: keras.activations.tanh\nSoftmax: keras.activations.softmax\n\nLainnya\n\nRelu6: keras.activations.relu6\n\\[\\Phi(x) = \\min \\{ \\text{ReLU}(x), 6 \\}\\]\nLeaky ReLU: keras.activations.leaky_relu\nbisa dipasang hyperparameter \\(\\alpha \\ge 0\\): negative_slope\n\\[\\Phi(x) = \\max \\{x, \\alpha x\\}\\]\nELU (Exponential Linear Unit): keras.activations.elu\nbisa dipasang hyperparameter \\(\\alpha \\ge 0\\): alpha\n\\[\n  \\Phi(x) = \\begin{cases}\n      x & x &gt; 0 \\\\\n      \\alpha (e^x - 1) & \\text{otherwise}\n  \\end{cases}\n  \\]\nSoftplus: keras.activations.softplus\n\\[\\Phi(x) = \\ln (e^x + 1)\\]\nSoftsign: keras.activations.softsign\n\\[\\Phi(x) = \\frac{x}{|x| + 1}\\]\nMish: keras.activations.mish\n\\[\\Phi(x) = x \\tanh (\\text{softplus} (x))\\]\nExponential: keras.activations.exponential\nSELU (Scaled Exponential Linear Unit): keras.activations.selu\nGELU (Gaussian error linear unit): keras.activations.gelu\nSwish / Silu: keras.activatins.silu\nHard Silu: keras.activations.hard_silu\nHard sigmoid: keras.activations.hard_sigmoid\nLog softmax: keras.activations.log_softmax\n\nSumber: https://keras.io/api/layers/activations/\n\n\n\nUmum digunakan\n\nSGD: keras.optimizers.SGD\nAdam: keras.optimizers.Adam (saat ini dianggap optimizer terbaik)\nRMSprop: keras.optimizers.RMSprop\nAdagrad: keras.optimizers.Adagrad\n\nLainnya\n\nAdamW: keras.optimizers.AdamW\nAdadelta: keras.optimizers.Adadelta\nAdamax: keras.optimizers.Adamax\nAdafactor: keras.optimizers.Adafactor\nNadam: keras.optimizers.Nadam\nFtrl: keras.optimizers.Ftrl\nLion: keras.optimizers.Lion\nLoss Scale Optimizer: keras.optimizers.LossScaleOptimizer\n\nKecuali Loss Scale Optimizer, semua optimizer bisa dipasang learning rate. Contohnya seperti berikut:\nkeras.optimizers.SGD(learning_rate=0.01)\nSumber: https://keras.io/api/optimizers/\n\n\n\nUmum digunakan\n\nBinary cross-entropy (untuk klasifikasi biner)\nclass: keras.losses.BinaryCrossentropy\nfungsi: keras.losses.binary_crossentropy\nCategorial cross-entropy (untuk klasifikasi multiclass)\nclass: keras.losses.CategoricalCrossentropy\nfungsi: keras.losses.categorical_crossentropy\nMSE / mean squared error (untuk regresi)\nclass: keras.losses.MeanSquaredError\nfungsi: keras.losses.mean_squared_error\n\nLainnya, untuk klasifikasi\n\nSparse categorical cross-entropy\nclass: keras.losses.SparseCategoricalCrossentropy\nfungsi: keras.losses.spare_categorical_crossentropy\nPoisson loss\nclass: keras.losses.Poisson\nfungsi: keras.losses.poisson\nKullback-Leibler divergence loss\nclass: keras.losses.KLDivergence\nfungsi: keras.losses.kl_divergence\n\nLainnya, untuk regresi\n\nMAE / mean absolute error\nclass: keras.losses.MeanAbsoluteError\nfungsi: keras.losses.mean_absolute_error\nMean absolute percentage error\nclass: keras.losses.MeanAbsolutePercentageError\nfungsi: keras.losses.mean_absolute_percentage_error\nMean squared logarithmic error\nclass: keras.losses.MeanSquaredLogarithmicError\nfungsi: keras.losses.mean_squared_logarithmic_error\nCosine similarity\nclass: keras.losses.CosineSimilarity\nfungsi: keras.losses.cosine_similarity\nHuber loss\nclass: keras.losses.Huber\nfungsi: keras.losses.huber\nLog Cosh loss\nclass: keras.losses.LogCosh\nfungsi: keras.losses.log_cosh\n\nSumber: https://keras.io/api/losses/\n\n\n\nUmum digunakan\n\nAccuracy: keras.metrics.Accuracy\n\\(R^2\\): keras.metrics.R2Score\nBinary accuracy: keras.metrics.BinaryAccuracy\nCategorical accuracy: keras.metrics.CategoricalAccuracy\n\nLainnya, untuk klasifikasi multiclass\n\nSparse categorical accuracy: keras.metrics.SpareCategoricalAccuracy\nTop K categorical accuracy: keras.metrics.TopKCategoricalAccuracy\nSpare top K categorical accuracy: keras.metrics.SpareTopKCategoricalAccuracy\n\nLainnya, untuk klasifikasi biner atau True/False\n\nAUC: keras.metrics.AUC\nPrecision: keras.metrics.Precision\nRecall: keras.metrics.Recall\nTrue Positives: keras.metrics.TruePositives\nTrue Negatives: keras.metrics.TrueNegatives\nFalse Positives: keras.metrics.FalsePositives\nFalse Negatives: keras.metrics.FalseNegatives\nPrecision at recall: keras.metrics.PrecisionAtRecall\nRecall at precision: keras.metrics.RecallAtPrecision\nSensitivity at specificity: keras.metrics.SensitivityAtSpecificity\nSpecificity at sensitivity: keras.metrics.SpecificityAtSensitivity\nF-1 score: keras.metrics.F1Score\nF-Beta score: keras.metrics.FBetaScore\n\nSemua pilihan loss function juga bisa digunakan sebagai metrik evaluasi.\nSumber: https://keras.io/api/metrics/\n\n\n\n\nSumber gambar\n\nAggarwal, C. Charu. 2018. Neural Networks and Deep Learning: A Textbook. Edisi Pertama. Springer.\nGoodfellow, Ian; Bengio, Yoshua; & Courville, Aaron. 2016. Deep Learning. MIT Press.\n\nBuku lainnya\n\nGéron, Aurélien. 2019. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Edisi Kedua. O’Reilly Media.\n\nInternet\n\nhttps://www.tensorflow.org/api_docs/python/tf\nhttps://keras.io/api/"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul7.html#teori-neural-network",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul7.html#teori-neural-network",
    "title": "Modul 7 Praktikum Sains Data: Pengantar Neural Network dengan TensorFlow & Keras",
    "section": "",
    "text": "Overview:\n\nSecara umum, suatu neural network terdiri dari sejumlah layer atau lapisan (minimal dua).\nLayer pertama disebut input layer, dan layer terakhir disebut output layer.\nTiap layer terdiri dari sejumlah neuron, yang masing-masing bisa menyimpan suatu nilai.\nKecuali input layer, tiap neuron terhubung dengan sejumlah neuron di layer sebelumnya.\nTiap sambungan terdiri dari nilai weight (sebagai pengali), nilai bias (sebagai pergeseran), dan suatu “fungsi aktivasi” yang menghasilkan nilai untuk neuron tujuan.\nWeight maupun bias disebut parameter dari neural network.\nProses training adalah terus-menerus memperbarui parameter hingga hasil prediksi neural network sudah cukup baik, dengan meminimumkan suatu loss function atau fungsi objektif (yang intinya menghitung error).\nSuatu neural network bisa memiliki sejumlah layer, masing-masing dengan banyaknya neuron tertentu dan fungsi-fungsi aktivasi tertentu. Hal-hal itu disebut hyperparameter dari neural network. Suatu arsitektur adalah suatu pilihan/konfigurasi hyperparameter.\n\n\n\nANN paling pertama adalah perceptron (juga disebut SLP atau single-layer perceptron) yang dirancang oleh Frank Rosenblatt pada tahun 1957 (Géron, 2019). Ini adalah neural network yang paling sederhana, bahkan ini bisa disebut building block dari semua ANN (apabila diberi kebebasan untuk modifikasi). Konsep dasar neural network bisa kita pelajari di sini.\n\nSumber gambar: Aggarwal (2018) hal. 5\nPerceptron hanya terdiri dari satu input layer dan satu output layer. Bahkan, aslinya hanya ada satu neuron di output layer.\nApabila dibutuhkan lebih dari satu neuron di output layer, itu bisa dianggap menggunakan lebih dari satu perceptron (yaitu menggunakan banyaknya perceptron sesuai banyaknya neuron di output layer), yang saling “ditumpuk”:\n\nSumber gambar: Goodfellow, et. al. (2016) hal. 337\nPerhatikan bahwa, tiap neuron di layer asal terhubung dengan tiap neuron di layer tujuan. Layer tujuan seperti ini disebut dense (padat). Kebalikan dari dense adalah sparse.\nAslinya, fungsi aktivasi yang digunakan oleh perceptron adalah Heaviside step function \\(H(v)\\) yang mungkin kalian kenal dari mata kuliah PDB, atau juga disebut threshold activation function:\n\\[H(v) = \\begin{cases}\n    1, & v \\ge 0 \\\\\n    0, & v &lt; 0\n\\end{cases}\\]\nSehingga, untuk output neuron ke-\\(j\\) yang disambung dari \\(n\\) input neuron, model perceptron bisa dirumuskan sebagai berikut:\n\\[y_j = H\\left(\\left(\\sum_{i=1}^{n} w_{ij} x_i \\right) + b_j\\right)\\]\ndengan\n\n\\(x_i\\) adalah nilai pada input neuron ke-\\(i\\)\n\\(y_j\\) adalah nilai pada output neuron ke-\\(j\\)\n\\(w_{ij}\\) adalah parameter weight untuk sambungan input neuron ke-\\(i\\) menuju output neuron ke-\\(j\\)\n\\(b_j\\) adalah parameter bias untuk output neuron ke-\\(j\\)\n\nLebih umumnya,\n\\[y_j = \\Phi\\left(\\left(\\sum_{i=1}^{n} w_{ij} x_i \\right) + b_j\\right)\\]\ndengan \\(\\Phi(v)\\) adalah sembarang fungsi aktivasi.\nNote: seperti di gambar, sebenarnya bias juga bisa dianggap neuron istimewa yang nilai \\(x_i\\) nya selalu satu.\nBiasanya, semua nilai di layer selanjutnya dihitung secara sekaligus menggunakan perkalian matriks, dengan perumusan:\n\\[\\textbf{y} = \\Phi\\left(W^T \\textbf{x} + \\textbf{b}\\right)\\]\ndengan \\(\\textbf{x} = [x_i]\\), \\(\\textbf{y} = [y_j]\\), dan \\(\\textbf{b} = [b_j]\\) adalah vektor kolom, serta \\(W = \\left[w_{ij}\\right]\\) adalah matriks.\nItu untuk satu buah data training.\nBisa saja, beberapa data training diperhitungkan sekaligus. Caranya, vektor kolom \\(\\textbf{x}\\) itu kita “lebarkan” ke samping sehingga menjadi matriks \\(X = [x_{it}]\\), sehingga data training ke-\\(t\\) ada di kolom ke-\\(t\\). Dengan demikian, output nya akan berupa matriks \\(Y = [y_{jt}]\\) dengan hasil untuk data training ke-\\(t\\) ada di kolom ke-\\(t\\). Selain itu, vektor \\(\\textbf{b}\\) perlu diperluas menjadi matriks \\(B\\) dengan tiap kolom identik, dan fungsi aktivasi \\(\\Phi\\) dihitung per kolom.\n\\[Y = \\Phi\\left(W^T X + B\\right)\\]\nKembali ke kasus satu buah data training. Biasanya, dataset disajikan dengan tiap fitur di kolom sendiri, tidak seperti perumusan kita sejauh ini dengan tiap fitur di baris tersendiri. Untuk menyesuaikan, kita bisa men-transpose semuanya:\n\\[\\textbf{y} = \\Phi\\left(\\textbf{x} W + \\textbf{b}\\right)\\]\ndengan \\(\\textbf{x} = [x_i]\\), \\(\\textbf{y} = [y_j]\\), dan \\(\\textbf{b} = [b_j]\\) adalah vektor baris, serta \\(W = \\left[w_{ji}\\right]\\) adalah matriks berisi bobot untuk menyambung ke output neuron ke-\\(j\\) dari input neuron ke-\\(i\\).\n\n\n\nKonsep single-layer perceptron bisa diperumum menjadi multilayer perceptron atau neural network yang biasa kita kenal, dengan menambahkan beberapa layer di antara input layer dan output layer. Semua layer selain input layer dan output layer disebut hidden layer.\n\nSumber gambar: Aggarwal (2018) hal. 18\nKonsep perhitungan antara tiap layer tetap sama, yaitu\n\\[\\textbf{y} = \\Phi\\left(\\textbf{w}^T \\textbf{x} + \\textbf{b}\\right)\\]\n(versi vektor kolom), atau\n\\[\\textbf{y} = \\Phi\\left(\\textbf{x} W + \\textbf{b}\\right)\\]\n(versi vektor baris)\n\n\n\n\nSumber gambar: Aggarwal (2018) hal. 13\nBeberapa fungsi aktivasi adalah (Aggarwal, 2018, hal. 12-13):\n\n“Linier” atau identitas\n\n\\[\\Phi(v) = v\\]\n\nSign (fungsi tanda): \\(\\text{sign}(v)\\) atau \\(\\text{sgn}(v)\\)\n\n\\[\n\\Phi(v) = \\text{sign}(v) = \\begin{cases}\n    1, & v &gt; 0 \\\\\n    0, & v = 0 \\\\\n    -1, & v &lt; 0\n\\end{cases}\n\\]\n\nSigmoid, terkadang dilambangkan \\(\\sigma(v)\\) dan terkadang disebut fungsi aktivasi logistik\n\n\\[\\Phi(v) = \\frac{1}{1 + e^{-v}}\\]\n\n(Soft) tanh: \\(\\tanh(v)\\)\n\n\\[\\Phi(v) = \\frac{e^{2v} - 1}{e^{2v} + 1} = 2 * \\text{sigmoid}(2v) - 1\\]\n\nRectified Linear Unit (ReLU)\n\n\\[\\Phi(v) = \\max\\{v, 0\\}\\]\n\nHard tanh\n\n\\[\\Phi(v) = \\max\\{\\min\\{v, 1\\}, -1\\}\\]\nFungsi aktivasi yang paling sering digunakan adalah ReLU, kecuali untuk output layer.\nUntuk output layer, biasanya,\n\nuntuk regresi, banyaknya neuron sesuai banyaknya nilai prediksi (umumnya hanya satu), dan digunakan fungsi aktivasi linier\nuntuk klasifikasi multiclass (lebih dari dua kelas), biasanya banyaknya output neuron sesuai banyaknya kelas, dan digunakan fungsi aktivasi softmax sebagai berikut, agar output berupa peluang tiap kelas:\n\n\\[\\Phi(\\overline{v})_i = \\frac{\\exp(v_i)}{\\sum_{j=1}^k \\exp(v_j)}\\]\n\nuntuk klasifikasi biner, hanya ada satu neuron di output layer, dan digunakan fungsi aktivasi sigmoid. (Keberadaan hanya satu output neuron lebih hemat daripada menggunakan dua output neuron)\n\n\n\n\nMisalkan \\(y_i\\) adalah nilai sebenarnya dan \\(\\hat{y}_i\\) adalah hasil prediksi.\nUntuk regresi, biasa digunakan MSE (mean squared error), juga disebut L2 loss:\n\\[\\text{MSE}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} \\left( y_i - \\hat{y}_i \\right)^2\\]\nUntuk klasifikasi, biasa digunakan yang namanya cross-entropy loss, juga disebut logistic loss atau log loss:\n\\[L_{\\text{log}}(y,\\hat{y}) = -(y \\ln (\\hat{y}) + (1 - y) \\ln (1 - \\hat{y}))\\]\n\n\n\nProses training untuk neural network dilakukan secara iteratif, yaitu tiap iterasi akan memperbarui parameter sehingga nilai loss function menjadi lebih kecil.\nTiap iterasi melakukan langkah-langkah berikut untuk tiap data training:\n\nForward pass: menghitung nilai output akhir, yaitu \\(\\hat{y}\\) (hasil prediksi), berdasarkan input data training.\nMenghitung loss antara \\(y\\) (nilai asli) dan \\(\\hat{y}\\)\nBackpropagation: menghitung gradien dari loss terhadap tiap parameter, secara “mundur”\nUpdate optimizer: menggunakan algoritma optimizer seperti gradient descent untuk memperbarui parameter-parameter (weights and biases) berdasarkan gradien dari loss\nNote: ada banyak optimizer, seperti gradient descent, SGD (stochastic gradient descent), dan Adam (adaptive moment estimation). Pilihan optimizer (serta parameter-parameter yang bisa diatur untuk optimizer, seperti learning rate) juga menjadi hyperparameter untuk neural network.\n\nNote: istilah backward pass meliputi langkah backpropagation dan update optimizer.\nApabila data training sangat banyak, terkadang data training tersebut dibagi menjadi beberapa batch, dan tiap iterasi menggunakan batch yang berbeda. Apabila semua batch sudah diproses, sebutannya adalah satu epoch. Sehingga, satu epoch terdiri dari sejumlah iterasi sesuai banyaknya batch.\n(Apabila data training tidak dibagi menjadi batch, maka satu epoch sama dengan satu iterasi.)\n\n\n\nMetode gradient descent mencari minimum lokal dari suatu fungsi \\(g\\) (dalam hal ini, loss function) dengan rumus iterasi seperti berikut:\n\\[\\textbf{x}_{i+1} = \\textbf{x}_i - \\eta \\nabla g\\left(\\textbf{x}_i\\right)\\]\ndengan \\(\\eta\\) adalah learning rate. Simbol nabla (\\(\\nabla\\)) menandakan perhitungan gradien.\nPerhatikan bahwa gradien menandakan arah tercepat untuk kenaikan fungsi, seringkali disebut direction of steepest ascent. Di sini, justru kita mengurangi; atau sama saja, menambah dengan kebalikannya, yaitu arah tercepat untuk penurunan fungsi. Sedangkan, learning rate melambangkan seberapa jauh kita melangkah ke arah penurunan tersebut. Harapannya, kita akan cepat konvergen menuju minimum fungsi, karena kita terus melangkah ke arah penurunan tercepat.\nVariasi gradient descent adalah SGD (stochastic gradient descent). Bedanya sederhana saja:\n\nGradient descent selalu memanfaatkan keseluruhan data training yang diberikan (lebih tepatnya, keseluruhan batch) di tiap iterasi.\nSedangkan, SGD selalu memilih sebagian data training saja (lebih tepatnya, sebagian dari batch), dan cara memilihnya bersifat random atau disebut stokastik.\n\nKeuntungan SGD dibandingkan gradient descent biasa:\n\nWaktu training menjadi lebih cepat\nTidak rawan terjebak di minimum lokal: https://www.youtube.com/watch?v=UmathvAKj80&t=102\n\n\n\n\nKetika menggunakan metode machine learning yang di-training secara iteratif, seperti neural network, biasanya ada juga yang namanya validation data. Sehingga, di awal, dataset dipisah menjadi data train, data validation, dan data test.\nGunanya, kita bisa menguji akurasi model di akhir tiap epoch, menggunakan data validation daripada data test.\nRasio yang paling sering digunakan adalah 80-10-10, yaitu 80% data train, 10% data validation, dan 10% data test.\nApabila menggunakan scikit-learn, untuk melakukan train-validation-test split, caranya adalah dengan split dua kali, yaitu\n\nSplit menjadi data “train” dan data test\nData “train” itu di-split lagi menjadi data train sesungguhnya dan data validation\n\natau bisa juga\n\nSplit menjadi data train dan data “test”\nData “test” itu di-split lagi menjadi data validation dan data test sesungguhnya"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul7.html#mengenal-tensorflow",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul7.html#mengenal-tensorflow",
    "title": "Modul 7 Praktikum Sains Data: Pengantar Neural Network dengan TensorFlow & Keras",
    "section": "",
    "text": "import tensorflow as tf\n\n\n\nTensor adalah semacam perumuman dari array/vektor ataupun matriks.\n\nSkalar (bilangan) adalah tensor berdimensi nol (atau rank nol).\nArray atau vektor adalah tensor berdimensi satu (atau rank satu).\nMatriks adalah tensor berdimensi dua (atau rank dua).\nIstilah “tensor” biasanya merujuk pada tensor berdimensi tiga (atau rank tiga), yaitu semacam matriks tapi tiga dimensi, sehingga ada baris, kolom, dan satu dimensi lagi.\n\nFitur tensor di TensorFlow mirip dengan fitur array di numpy, yang memang juga bisa multidimensi.\n\nx = tf.zeros(shape = (3,4))\nprint(x)\n\ntf.Tensor(\n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]], shape=(3, 4), dtype=float32)\n\n\n\nx = tf.ones(shape = (3,4))\nprint(x)\n\ntf.Tensor(\n[[1. 1. 1. 1.]\n [1. 1. 1. 1.]\n [1. 1. 1. 1.]], shape=(3, 4), dtype=float32)\n\n\nUntuk menentukan array kita sendiri, di numpy digunakan numpy.array.\nUntuk menentukan tensor kita sendiri, di TensorFlow digunakan tensorflow.constant (agar nilainya tidak bisa diubah) atau tensorflow.Variable (nilainya bisa diubah).\nPada umumnya (apabila tidak ada keterangan), tensor di TensorFlow berupa tensorflow.constant\n\nconst0 = tf.constant(1.5)\nprint(const0)\n\ntf.Tensor(1.5, shape=(), dtype=float32)\n\n\n\nprint(tf.rank(const0))\n\ntf.Tensor(0, shape=(), dtype=int32)\n\n\n\nconst1 = tf.constant([2.31, 4.567, 8.9])\nprint(const1)\n\ntf.Tensor([2.31  4.567 8.9  ], shape=(3,), dtype=float32)\n\n\n\nprint(tf.rank(const1))\n\ntf.Tensor(1, shape=(), dtype=int32)\n\n\n\nconst1[0] = 52.5\n\nTypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n\n\n\nconst2 = tf.constant([\n    [1, 2.718, 3.14],\n    [4, 5, 6.28]\n])\nprint(const2)\n\ntf.Tensor(\n[[1.    2.718 3.14 ]\n [4.    5.    6.28 ]], shape=(2, 3), dtype=float32)\n\n\n\nprint(tf.rank(const2))\n\ntf.Tensor(2, shape=(), dtype=int32)\n\n\n\n\n\n\nv = tf.Variable(initial_value = tf.zeros(shape = (2,3)))\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[0., 0., 0.],\n       [0., 0., 0.]], dtype=float32)&gt;\n\n\nAssignment untuk variabel di TensorFlow dilakukan dengan .assign\n\nv.assign(tf.ones(shape = (2,3)))\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[1., 1., 1.],\n       [1., 1., 1.]], dtype=float32)&gt;\n\n\n\nv[0, 0].assign(9)\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[9., 1., 1.],\n       [1., 1., 1.]], dtype=float32)&gt;\n\n\nAda juga .assign_add, sama saja dengan +=\n\nv.assign_add(tf.ones(shape = (2,3)))\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[10.,  2.,  2.],\n       [ 2.,  2.,  2.]], dtype=float32)&gt;\n\n\nSerupa, ada .assign_sub yaitu -=\n\nv.assign_sub(tf.ones(shape = (2,3)))\nprint(v)\n\n&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[9., 1., 1.],\n       [1., 1., 1.]], dtype=float32)&gt;\n\n\n\n\n\nKita bisa membuat tensor dengan nilai yang random, misalnya dari distribusi normal atau dari distribusi uniform\n\n# dari distribusi normal\nx = tf.random.normal(shape = (2,3), mean = 0, stddev = 1)\nprint(x)\n\ntf.Tensor(\n[[ 1.2542483  -0.41693744  1.0116149 ]\n [-1.4155766   0.17204648 -0.6892854 ]], shape=(2, 3), dtype=float32)\n\n\n\n# dari distribusi uniform\nx = tf.random.uniform(shape = (2,3), minval = 0, maxval = 1)\nprint(x)\n\ntf.Tensor(\n[[0.51321495 0.26164746 0.09113109]\n [0.81229377 0.67134035 0.36057925]], shape=(2, 3), dtype=float32)\n\n\n\n\n\nOperasi di TensorFlow mirip dengan numpy\n\na = 4 * tf.ones((2, 2))\nprint(a)\n\ntf.Tensor(\n[[4. 4.]\n [4. 4.]], shape=(2, 2), dtype=float32)\n\n\n\nb = tf.square(a)\nprint(b)\n\ntf.Tensor(\n[[16. 16.]\n [16. 16.]], shape=(2, 2), dtype=float32)\n\n\n\nc = tf.sqrt(a)\nprint(c)\n\ntf.Tensor(\n[[2. 2.]\n [2. 2.]], shape=(2, 2), dtype=float32)\n\n\n\nd = b + c\nprint(d)\n\ntf.Tensor(\n[[18. 18.]\n [18. 18.]], shape=(2, 2), dtype=float32)\n\n\n\n# perkalian matriks\ne = tf.matmul(a, c)\nprint(e)\n\ntf.Tensor(\n[[16. 16.]\n [16. 16.]], shape=(2, 2), dtype=float32)\n\n\n\n# perkalian per elemen\ne *= d\nprint(e)\n\ntf.Tensor(\n[[288. 288.]\n [288. 288.]], shape=(2, 2), dtype=float32)\n\n\n\n\n\nTensorFlow memiliki fitur yang bernama automatic differentiation, juga disebut autodiff atau autograd. Dengan fitur ini, TensorFlow bisa menghitung turunan/gradien secara otomatis. Fitur ini membedakan antara TensorFlow dengan numpy.\nCaranya adalah menggunakan GradientTape seperti berikut. Semua operasi di dalam with statement dicatat oleh GradientTape, yang kemudian bisa menghitung gradiennya.\nContohnya, turunan \\(x^3\\) terhadap \\(x\\) di \\(x=4\\) adalah \\(3(4)^2 = 48\\).\n\nx = tf.Variable(4.0)\nwith tf.GradientTape() as tape:\n    y = x ** 3\ndy_dx = tape.gradient(y, x)\nprint(dy_dx)\n\ntf.Tensor(48.0, shape=(), dtype=float32)\n\n\nTidak harus dengan tensorflow.Variable, bahkan dengan tensorflow.constant juga bisa. Namun, kita harus secara eksplisit meminta TensorFlow untuk memperhatikan nilai x, yaitu dengan .watch\n\nx = tf.constant(4.0)\nwith tf.GradientTape() as tape:\n    tape.watch(x)\n    y = x ** 3\ndy_dx = tape.gradient(y, x)\nprint(dy_dx)\n\ntf.Tensor(48.0, shape=(), dtype=float32)\n\n\nKita bisa menghitung turunan kedua dengan nested with statement seperti berikut, contohnya turunan kedua dari \\(x^3\\) terhadap \\(x\\) di \\(x=4\\) adalah \\(6(4) = 24\\)\n\nx = tf.Variable(4.0)\nwith tf.GradientTape() as tape2:\n    with tf.GradientTape() as tape1:\n        y = x ** 3\n    dy_dx = tape1.gradient(y, x)\ndy2_dx2 = tape2.gradient(dy_dx, x)\nprint(dy2_dx2)\n\ntf.Tensor(24.0, shape=(), dtype=float32)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul7.html#pure-tensorflow-klasifikasi-biner-dengan-perceptron",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul7.html#pure-tensorflow-klasifikasi-biner-dengan-perceptron",
    "title": "Modul 7 Praktikum Sains Data: Pengantar Neural Network dengan TensorFlow & Keras",
    "section": "",
    "text": "Perceptron digunakan untuk klasifikasi biner. Mari kita coba buat model perceptron dengan pure TensorFlow, menggunakannya untuk memprediksi kelas dari titik-titik dua dimensi.\n\n\nDataset titik-titik dua dimensi, dengan dua kelas (misalnya “negatif” dan “positif”), bisa kita generate:\n\nnum_samples_per_class, num_classes = 1000, 2\nnegative_samples = np.random.multivariate_normal(mean = [0,3], cov = [[1,0.5],[0.5,1]], size = num_samples_per_class)\npositive_samples = np.random.multivariate_normal(mean = [3,0], cov = [[1,0.5],[0.5,1]], size = num_samples_per_class)\n\ninputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)\ntargets = np.vstack((\n    np.zeros((num_samples_per_class, 1), dtype = 'float32'),\n    np.ones((num_samples_per_class, 1), dtype = 'float32')\n))\n\n\nprint(inputs.shape)\nprint(targets.shape)\n\n(2000, 2)\n(2000, 1)\n\n\n\nplt.scatter(inputs[:, 0], inputs[:, 1], c=targets[:, 0])\nplt.show()\n\n\n\n\n\n\n\n\nKalau mau, kita bisa susun data ini ke dalam bentuk pandas DataFrame, lalu export ke CSV:\n\ntitik_negatif_positif_df = pd.DataFrame(\n    np.hstack([inputs, targets]),\n    columns = [\"x\", \"y\", \"kelas\"]\n)\n\n\ntitik_negatif_positif_df\n\n\n\n\n\n\n\n\nx\ny\nkelas\n\n\n\n\n0\n1.173375\n4.570637\n0.0\n\n\n1\n0.195961\n3.504604\n0.0\n\n\n2\n0.121400\n2.163783\n0.0\n\n\n3\n-1.170182\n3.882771\n0.0\n\n\n4\n-0.424403\n0.534641\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n2.423160\n-0.337196\n1.0\n\n\n1996\n1.949836\n-0.627813\n1.0\n\n\n1997\n2.109928\n-0.382492\n1.0\n\n\n1998\n4.178664\n0.486168\n1.0\n\n\n1999\n2.326363\n1.228249\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\ntitik_negatif_positif_df.to_csv(\"./titik_negatif_positif.csv\", index=False)\n\n\n\n\nTentunya, karena titik-titiknya di-generate secara random, mungkin saja titik-titik yang kalian peroleh akan sedikit berbeda, bahkan tiap kali di-run ulang akan berbeda.\nKalau kalian mau menyamakan dengan modul ini, CSV nya bisa di-download dari GitHub Pages ini: titik_negatif_positif.csv\nKita bisa import kembali:\n\ndf = pd.read_csv(\"./titik_negatif_positif.csv\", dtype=\"float32\")\n\nKali ini, kita tambahkan keterangan dtype=\"float32\". Ini penting, karena TensorFlow biasanya menangani float32 (yaitu tipe data float dengan penyimpanan 32-bit), bukan float64 yang biasa digunakan oleh pandas.\n\ndf\n\n\n\n\n\n\n\n\nx\ny\nkelas\n\n\n\n\n0\n1.173375\n4.570637\n0.0\n\n\n1\n0.195961\n3.504604\n0.0\n\n\n2\n0.121400\n2.163783\n0.0\n\n\n3\n-1.170182\n3.882771\n0.0\n\n\n4\n-0.424403\n0.534641\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n2.423160\n-0.337196\n1.0\n\n\n1996\n1.949836\n-0.627813\n1.0\n\n\n1997\n2.109928\n-0.382492\n1.0\n\n\n1998\n4.178664\n0.486168\n1.0\n\n\n1999\n2.326363\n1.228249\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2000 entries, 0 to 1999\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   x       2000 non-null   float32\n 1   y       2000 non-null   float32\n 2   kelas   2000 non-null   float32\ndtypes: float32(3)\nmemory usage: 23.6 KB\n\n\n\ninputs_df = df.drop(columns=[\"kelas\"])\ntargets_df = df[[\"kelas\"]]\n\n\ninputs_df\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n1.173375\n4.570637\n\n\n1\n0.195961\n3.504604\n\n\n2\n0.121400\n2.163783\n\n\n3\n-1.170182\n3.882771\n\n\n4\n-0.424403\n0.534641\n\n\n...\n...\n...\n\n\n1995\n2.423160\n-0.337196\n\n\n1996\n1.949836\n-0.627813\n\n\n1997\n2.109928\n-0.382492\n\n\n1998\n4.178664\n0.486168\n\n\n1999\n2.326363\n1.228249\n\n\n\n\n2000 rows × 2 columns\n\n\n\n\ntargets_df\n\n\n\n\n\n\n\n\nkelas\n\n\n\n\n0\n0.0\n\n\n1\n0.0\n\n\n2\n0.0\n\n\n3\n0.0\n\n\n4\n0.0\n\n\n...\n...\n\n\n1995\n1.0\n\n\n1996\n1.0\n\n\n1997\n1.0\n\n\n1998\n1.0\n\n\n1999\n1.0\n\n\n\n\n2000 rows × 1 columns\n\n\n\n\nplt.scatter(inputs_df[\"x\"], inputs_df[\"y\"], c=targets[\"kelas\"])\nplt.show()\n\n\n\n\n\n\n\n\nTensorFlow kurang bisa menangani pandas DataFrame, sehingga harus kita ubah jadi array numpy:\n\ninputs = inputs_df.to_numpy()\ntargets = targets_df.to_numpy()\n\n\nprint(inputs.shape)\nprint(targets.shape)\n\n(2000, 2)\n(2000, 1)\n\n\n\n\n\nUntuk input dua dimensi dan klasifikasi biner, kita perlu perceptron dengan dua neuron di input layer dan satu neuron di output layer. Sebelum proses training dimulai, nilai matriks \\(W\\) dan vektor kolom \\(b\\) diisi secara random terlebih dahulu.\n\ninput_dim = 2\noutput_dim = 1\nW = tf.Variable(tf.random.normal(shape = (input_dim, output_dim)))\nb = tf.Variable(tf.random.normal(shape = (output_dim,)))\n\n\n# forward pass\ndef model(inputs):\n    return tf.sigmoid(\n        tf.matmul(inputs, W) + b\n    )\n\n\n# cross entropy loss\ndef entropy_loss(y, yhat):\n    per_sample_losses = - y * tf.math.log(yhat) - (1-y) * tf.math.log(1-yhat)\n    return tf.reduce_mean(per_sample_losses)\n\n\n# satu epoch di training loop\nlearning_rate = 0.1\ndef training_step(inputs, targets):\n    with tf.GradientTape() as tape:\n        predictions = model(inputs)\n        loss = entropy_loss(targets, predictions)\n\n        grad_loss_wrt_W, grad_loss_wrt_b = tape.gradient(loss, [W, b])\n\n        # update menggunakan gradient descent\n        W.assign_sub(learning_rate * grad_loss_wrt_W)\n        b.assign_sub(learning_rate * grad_loss_wrt_b)\n        \n        return loss\n\n\n# training loop\nfor epoch in range(100):\n    loss = training_step(inputs, targets)\n    print(f\"Loss at epoch {epoch}: {loss}\")\n\nLoss at epoch 0: 3.254241466522217\nLoss at epoch 1: 2.841676712036133\nLoss at epoch 2: 2.446164608001709\nLoss at epoch 3: 2.0740654468536377\nLoss at epoch 4: 1.7329306602478027\nLoss at epoch 5: 1.4304780960083008\nLoss at epoch 6: 1.1727027893066406\nLoss at epoch 7: 0.9617642760276794\nLoss at epoch 8: 0.7950283288955688\nLoss at epoch 9: 0.6661190390586853\nLoss at epoch 10: 0.5672049522399902\nLoss at epoch 11: 0.4909631013870239\nLoss at epoch 12: 0.43148183822631836\nLoss at epoch 13: 0.38434457778930664\nLoss at epoch 14: 0.34636563062667847\nLoss at epoch 15: 0.31527045369148254\nLoss at epoch 16: 0.2894296944141388\nLoss at epoch 17: 0.26766350865364075\nLoss at epoch 18: 0.24910621345043182\nLoss at epoch 19: 0.23311251401901245\nLoss at epoch 20: 0.21919457614421844\nLoss at epoch 21: 0.2069779932498932\nLoss at epoch 22: 0.19617150723934174\nLoss at epoch 23: 0.18654564023017883\nLoss at epoch 24: 0.1779175102710724\nLoss at epoch 25: 0.17013971507549286\nLoss at epoch 26: 0.16309219598770142\nLoss at epoch 27: 0.1566763073205948\nLoss at epoch 28: 0.15081030130386353\nLoss at epoch 29: 0.14542590081691742\nLoss at epoch 30: 0.1404656320810318\nLoss at epoch 31: 0.13588076829910278\nLoss at epoch 32: 0.13162976503372192\nLoss at epoch 33: 0.12767699360847473\nLoss at epoch 34: 0.12399168312549591\nLoss at epoch 35: 0.12054720520973206\nLoss at epoch 36: 0.11732034385204315\nLoss at epoch 37: 0.11429077386856079\nLoss at epoch 38: 0.11144062876701355\nLoss at epoch 39: 0.10875413566827774\nLoss at epoch 40: 0.10621732473373413\nLoss at epoch 41: 0.10381780564785004\nLoss at epoch 42: 0.10154449194669724\nLoss at epoch 43: 0.0993875041604042\nLoss at epoch 44: 0.09733790904283524\nLoss at epoch 45: 0.09538772702217102\nLoss at epoch 46: 0.09352975338697433\nLoss at epoch 47: 0.09175743162631989\nLoss at epoch 48: 0.09006485342979431\nLoss at epoch 49: 0.08844659477472305\nLoss at epoch 50: 0.08689778298139572\nLoss at epoch 51: 0.08541391044855118\nLoss at epoch 52: 0.08399088680744171\nLoss at epoch 53: 0.08262495696544647\nLoss at epoch 54: 0.0813126489520073\nLoss at epoch 55: 0.08005079627037048\nLoss at epoch 56: 0.07883644849061966\nLoss at epoch 57: 0.07766692340373993\nLoss at epoch 58: 0.07653970271348953\nLoss at epoch 59: 0.07545248419046402\nLoss at epoch 60: 0.07440309226512909\nLoss at epoch 61: 0.07338955998420715\nLoss at epoch 62: 0.07241000235080719\nLoss at epoch 63: 0.0714627057313919\nLoss at epoch 64: 0.07054606825113297\nLoss at epoch 65: 0.0696585550904274\nLoss at epoch 66: 0.06879876554012299\nLoss at epoch 67: 0.06796539574861526\nLoss at epoch 68: 0.06715719401836395\nLoss at epoch 69: 0.06637301295995712\nLoss at epoch 70: 0.06561177223920822\nLoss at epoch 71: 0.06487242877483368\nLoss at epoch 72: 0.06415403634309769\nLoss at epoch 73: 0.06345568597316742\nLoss at epoch 74: 0.06277652084827423\nLoss at epoch 75: 0.06211574003100395\nLoss at epoch 76: 0.061472587287425995\nLoss at epoch 77: 0.06084632873535156\nLoss at epoch 78: 0.06023630499839783\nLoss at epoch 79: 0.05964187532663345\nLoss at epoch 80: 0.0590624064207077\nLoss at epoch 81: 0.05849733576178551\nLoss at epoch 82: 0.057946112006902695\nLoss at epoch 83: 0.05740822106599808\nLoss at epoch 84: 0.05688317120075226\nLoss at epoch 85: 0.056370481848716736\nLoss at epoch 86: 0.05586971715092659\nLoss at epoch 87: 0.0553804449737072\nLoss at epoch 88: 0.05490226671099663\nLoss at epoch 89: 0.05443479120731354\nLoss at epoch 90: 0.05397764965891838\nLoss at epoch 91: 0.0535304993391037\nLoss at epoch 92: 0.05309300124645233\nLoss at epoch 93: 0.05266483128070831\nLoss at epoch 94: 0.05224568769335747\nLoss at epoch 95: 0.051835279911756516\nLoss at epoch 96: 0.05143332853913307\nLoss at epoch 97: 0.05103955790400505\nLoss at epoch 98: 0.05065372586250305\nLoss at epoch 99: 0.05027557164430618\n\n\n\n\n\nSekarang training sudah selesai, kita bisa gunakan model kita untuk memprediksi kelas berdasarkan inputs (koordinat titik-titik)\n\npredictions = model(inputs)\n\nAkibat penggunaan fungsi aktivasi sigmoid, hasil prediksi cukup jelas, apakah kelas pertama (kelas 0) atau kelas kedua (kelas 1):\n\nprint(predictions)\n\ntf.Tensor(\n[[0.0185734 ]\n [0.01658478]\n [0.06427375]\n ...\n [0.94514835]\n [0.99050665]\n [0.7908128 ]], shape=(2000, 1), dtype=float32)\n\n\nKita bisa menampilkan hasil prediksi ini dengan aturan pemilihan warna (c) seperti berikut:\n\napabila nilai prediksinya lebih dari 0.5 (pernyataan “lebih besar dari 0.5” bernilai benar), ia tergolong kelas 1 (atau sama saja nilai True);\nselain itu (pernyataan “lebih besar dari 0.5” bernilai salah), ia tergolong kelas 0 (atau sama saja nilai False).\n\n\nplt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:, 0] &gt; 0.5)\nplt.show()\n\n\n\n\n\n\n\n\nKinerja perceptron cukup mirip regresi logistik, ataupun SVM dengan kernel linier. Perhatikan bahwa, di hasil prediksi ini, seolah-olah ada perbatasan atau garis pemisah antara kedua kelas. Kalau kita bandingkan dengan data aslinya, sebenarnya ada beberapa titik yang melewati perbatasan tersebut, dan akhirnya terjadi misklasifikasi."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul7.html#mengenal-keras-dengan-sequential-api",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul7.html#mengenal-keras-dengan-sequential-api",
    "title": "Modul 7 Praktikum Sains Data: Pengantar Neural Network dengan TensorFlow & Keras",
    "section": "",
    "text": "Dengan pure TensorFlow, banyak hal yang harus kita susun secara manual. Untuk neural network kecil seperti perceptron, mungkin tidak masalah. Namun, neural network pada umumnya sangat “dalam” atau deep, dengan puluhan hidden layer yang bervariasi.\nDaripada benar-benar membuatnya semua secara manual, ada yang namanya Keras yang sangat menyederhanakan proses penyusunan neural network. Biasanya, daripada benar-benar membuat neural network secara manual dalam pure TensorFlow seperti tadi, pengguna TensorFlow memanfaatkan Keras.\nKeras tersedia di dalam TensorFlow:\n\nfrom tensorflow import keras\n\nPerlu dicatat, ketika menggunakan Keras, sebaiknya semua fungsi/operasi yang kita gunakan juga dari dalam Keras daripada langsung dari TensorFlow. Misalnya, daripada tf.matmul, gunakan keras.ops.matmul\nTapi kalau error, tidak masalah masih menggunakan tf karena Keras masih dalam pengembangan (menuju Keras versi 3, bisa dibaca di sini: https://keras.io/guides/migrating_to_keras_3/). Mungkin, di versi yang akan datang, sudah tidak error lagi.\nDalam Keras, ada tiga “cara” atau API (application programming interface) yang bisa kita gunakan untuk menyusun neural network, yaitu\n\nSequential API\nFunctional API\nSubclassing API (yaitu dengan OOP)\n\nDi pertemuan kali ini, kita akan mencoba cara yang paling sederhana, yaitu dengan Sequential API.\nDatanya sudah siap dari yang tadi:\n\nprint(inputs.shape)\nprint(targets.shape)\n\n(2000, 2)\n(2000, 1)\n\n\n\n\nKita susun layer nya terlebih dahulu. Kali ini, kita akan membuat perceptron seperti yang cara manual / pure TensorFlow tadi. Untuk itu, kedua kode ini ekuivalen:\n\n# langsung menentukan semua layer di awal, dengan memasukkan list\nmodel2 = keras.Sequential(\n    [\n        keras.layers.InputLayer(input_shape = (2,)),\n        keras.layers.Dense(units = 1, activation = 'sigmoid')\n    ]\n)\n\n\n# menambahkan layer secara berangsur-angsur\nmodel2 = keras.Sequential()\nmodel2.add(keras.layers.InputLayer(input_shape = (2,)))\nmodel2.add(keras.layers.Dense(units = 1, activation = 'sigmoid'))\n\nDaripada menggunakan string, untuk menentukan fungsi aktivasi di kedua cara di atas, kita juga bisa mengetik keras.activations.sigmoid seperti berikut:\n\n# langsung menentukan semua layer di awal, dengan memasukkan list\nmodel2 = keras.Sequential(\n    [\n        keras.layers.InputLayer(input_shape = (2,)),\n        keras.layers.Dense(units = 1, activation = keras.activations.sigmoid)\n    ]\n)\n\n\n# menambahkan layer secara berangsur-angsur\nmodel2 = keras.Sequential()\nmodel2.add(keras.layers.InputLayer(input_shape = (2,)))\nmodel2.add(keras.layers.Dense(units = 1, activation = keras.activations.sigmoid))\n\n\n\n\nKemudian, kita bisa melihat ringkasan bentuk model yang dihasilkan:\n\nmodel2.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 1)                 3         \n                                                                 \n=================================================================\nTotal params: 3\nTrainable params: 3\nNon-trainable params: 0\n_________________________________________________________________\n\n\nKita juga bisa menampilkan semacam diagram, bahkan menyimpannya ke dalam file:\n\nkeras.utils.plot_model(\n    model2,\n    show_shapes = True,\n    show_layer_activations = True,\n    to_file = \"keras_sequential_model2.png\"\n)\n\n\nFun fact: Keras menggunakan Graphviz untuk membuat diagramnya :)\n\n\n\nUntuk memilih hyperparameter yaitu optimizer dan loss function (dan metrik evaluasi), kedua kode berikut ini ekuivalen:\n\n# dengan string\nmodel2.compile(\n    optimizer = \"sgd\",\n    loss = \"binary_crossentropy\",\n    metrics = [\"binary_accuracy\"]\n)\n\n\n# dengan objek dari class\nmodel2.compile(\n    optimizer = keras.optimizers.SGD(),\n    loss = keras.losses.BinaryCrossentropy(),\n    metrics = [keras.metrics.BinaryAccuracy()]\n)\n\nDengan cara yang kedua, kita juga bisa menentukan hyperparameter seperti learning rate:\n\n# dengan objek dari class\nmodel2.compile(\n    optimizer = keras.optimizers.SGD(learning_rate = 0.01),\n    loss = keras.losses.BinaryCrossentropy(),\n    metrics = [keras.metrics.BinaryAccuracy()]\n)\n\n\n\n\nSelanjutnya, tinggal training, menggunakan .fit seperti di scikit-learn. Bedanya, .fit di sini me-return suatu objek “history” yang berisi catatan loss di tiap epoch\n\nx_train = inputs\ny_train = targets\nhistory2 = model2.fit(x_train, y_train, epochs=100, validation_split=0.2)\n\nEpoch 1/100\n50/50 [==============================] - 2s 19ms/step - loss: 0.9972 - binary_accuracy: 0.4119 - val_loss: 0.3660 - val_binary_accuracy: 0.9975\nEpoch 2/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.3971 - binary_accuracy: 0.9488 - val_loss: 0.2875 - val_binary_accuracy: 0.9975\nEpoch 3/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.2427 - binary_accuracy: 0.9975 - val_loss: 0.2355 - val_binary_accuracy: 0.9925\nEpoch 4/100\n50/50 [==============================] - 0s 10ms/step - loss: 0.1804 - binary_accuracy: 0.9962 - val_loss: 0.1990 - val_binary_accuracy: 0.9925\nEpoch 5/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.1459 - binary_accuracy: 0.9962 - val_loss: 0.1726 - val_binary_accuracy: 0.9925\nEpoch 6/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.1238 - binary_accuracy: 0.9962 - val_loss: 0.1529 - val_binary_accuracy: 0.9925\nEpoch 7/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.1082 - binary_accuracy: 0.9969 - val_loss: 0.1376 - val_binary_accuracy: 0.9925\nEpoch 8/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0966 - binary_accuracy: 0.9962 - val_loss: 0.1254 - val_binary_accuracy: 0.9925\nEpoch 9/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0875 - binary_accuracy: 0.9962 - val_loss: 0.1156 - val_binary_accuracy: 0.9925\nEpoch 10/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0803 - binary_accuracy: 0.9962 - val_loss: 0.1075 - val_binary_accuracy: 0.9925\nEpoch 11/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0744 - binary_accuracy: 0.9962 - val_loss: 0.1006 - val_binary_accuracy: 0.9925\nEpoch 12/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0695 - binary_accuracy: 0.9962 - val_loss: 0.0948 - val_binary_accuracy: 0.9925\nEpoch 13/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0653 - binary_accuracy: 0.9962 - val_loss: 0.0898 - val_binary_accuracy: 0.9925\nEpoch 14/100\n50/50 [==============================] - 1s 14ms/step - loss: 0.0617 - binary_accuracy: 0.9962 - val_loss: 0.0854 - val_binary_accuracy: 0.9925\nEpoch 15/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0585 - binary_accuracy: 0.9962 - val_loss: 0.0815 - val_binary_accuracy: 0.9925\nEpoch 16/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0558 - binary_accuracy: 0.9962 - val_loss: 0.0781 - val_binary_accuracy: 0.9925\nEpoch 17/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0533 - binary_accuracy: 0.9962 - val_loss: 0.0750 - val_binary_accuracy: 0.9925\nEpoch 18/100\n50/50 [==============================] - 1s 17ms/step - loss: 0.0511 - binary_accuracy: 0.9962 - val_loss: 0.0722 - val_binary_accuracy: 0.9925\nEpoch 19/100\n50/50 [==============================] - 1s 17ms/step - loss: 0.0492 - binary_accuracy: 0.9962 - val_loss: 0.0697 - val_binary_accuracy: 0.9925\nEpoch 20/100\n50/50 [==============================] - 1s 12ms/step - loss: 0.0474 - binary_accuracy: 0.9962 - val_loss: 0.0674 - val_binary_accuracy: 0.9925\nEpoch 21/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0458 - binary_accuracy: 0.9962 - val_loss: 0.0653 - val_binary_accuracy: 0.9925\nEpoch 22/100\n50/50 [==============================] - 1s 27ms/step - loss: 0.0443 - binary_accuracy: 0.9962 - val_loss: 0.0634 - val_binary_accuracy: 0.9925\nEpoch 23/100\n50/50 [==============================] - 0s 10ms/step - loss: 0.0429 - binary_accuracy: 0.9969 - val_loss: 0.0616 - val_binary_accuracy: 0.9925\nEpoch 24/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0417 - binary_accuracy: 0.9969 - val_loss: 0.0600 - val_binary_accuracy: 0.9925\nEpoch 25/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0405 - binary_accuracy: 0.9969 - val_loss: 0.0585 - val_binary_accuracy: 0.9925\nEpoch 26/100\n50/50 [==============================] - 1s 12ms/step - loss: 0.0394 - binary_accuracy: 0.9969 - val_loss: 0.0571 - val_binary_accuracy: 0.9925\nEpoch 27/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0384 - binary_accuracy: 0.9969 - val_loss: 0.0558 - val_binary_accuracy: 0.9925\nEpoch 28/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0375 - binary_accuracy: 0.9969 - val_loss: 0.0545 - val_binary_accuracy: 0.9925\nEpoch 29/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0366 - binary_accuracy: 0.9969 - val_loss: 0.0534 - val_binary_accuracy: 0.9925\nEpoch 30/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0358 - binary_accuracy: 0.9969 - val_loss: 0.0523 - val_binary_accuracy: 0.9925\nEpoch 31/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0351 - binary_accuracy: 0.9969 - val_loss: 0.0513 - val_binary_accuracy: 0.9925\nEpoch 32/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0343 - binary_accuracy: 0.9969 - val_loss: 0.0503 - val_binary_accuracy: 0.9925\nEpoch 33/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0337 - binary_accuracy: 0.9969 - val_loss: 0.0494 - val_binary_accuracy: 0.9925\nEpoch 34/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0330 - binary_accuracy: 0.9969 - val_loss: 0.0485 - val_binary_accuracy: 0.9925\nEpoch 35/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0324 - binary_accuracy: 0.9969 - val_loss: 0.0477 - val_binary_accuracy: 0.9925\nEpoch 36/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0318 - binary_accuracy: 0.9969 - val_loss: 0.0469 - val_binary_accuracy: 0.9925\nEpoch 37/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0313 - binary_accuracy: 0.9969 - val_loss: 0.0462 - val_binary_accuracy: 0.9925\nEpoch 38/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0308 - binary_accuracy: 0.9969 - val_loss: 0.0455 - val_binary_accuracy: 0.9925\nEpoch 39/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0303 - binary_accuracy: 0.9969 - val_loss: 0.0448 - val_binary_accuracy: 0.9925\nEpoch 40/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0298 - binary_accuracy: 0.9969 - val_loss: 0.0442 - val_binary_accuracy: 0.9925\nEpoch 41/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0293 - binary_accuracy: 0.9969 - val_loss: 0.0435 - val_binary_accuracy: 0.9925\nEpoch 42/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0289 - binary_accuracy: 0.9969 - val_loss: 0.0429 - val_binary_accuracy: 0.9925\nEpoch 43/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0285 - binary_accuracy: 0.9969 - val_loss: 0.0424 - val_binary_accuracy: 0.9925\nEpoch 44/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0281 - binary_accuracy: 0.9969 - val_loss: 0.0418 - val_binary_accuracy: 0.9925\nEpoch 45/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0277 - binary_accuracy: 0.9969 - val_loss: 0.0413 - val_binary_accuracy: 0.9925\nEpoch 46/100\n50/50 [==============================] - 1s 10ms/step - loss: 0.0274 - binary_accuracy: 0.9969 - val_loss: 0.0408 - val_binary_accuracy: 0.9925\nEpoch 47/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0270 - binary_accuracy: 0.9969 - val_loss: 0.0403 - val_binary_accuracy: 0.9925\nEpoch 48/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0267 - binary_accuracy: 0.9969 - val_loss: 0.0399 - val_binary_accuracy: 0.9925\nEpoch 49/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0263 - binary_accuracy: 0.9969 - val_loss: 0.0394 - val_binary_accuracy: 0.9925\nEpoch 50/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0260 - binary_accuracy: 0.9969 - val_loss: 0.0390 - val_binary_accuracy: 0.9925\nEpoch 51/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0257 - binary_accuracy: 0.9969 - val_loss: 0.0386 - val_binary_accuracy: 0.9925\nEpoch 52/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0254 - binary_accuracy: 0.9969 - val_loss: 0.0382 - val_binary_accuracy: 0.9925\nEpoch 53/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0252 - binary_accuracy: 0.9969 - val_loss: 0.0378 - val_binary_accuracy: 0.9925\nEpoch 54/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0249 - binary_accuracy: 0.9969 - val_loss: 0.0374 - val_binary_accuracy: 0.9925\nEpoch 55/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0246 - binary_accuracy: 0.9969 - val_loss: 0.0371 - val_binary_accuracy: 0.9925\nEpoch 56/100\n50/50 [==============================] - 1s 10ms/step - loss: 0.0244 - binary_accuracy: 0.9969 - val_loss: 0.0367 - val_binary_accuracy: 0.9925\nEpoch 57/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0241 - binary_accuracy: 0.9969 - val_loss: 0.0364 - val_binary_accuracy: 0.9925\nEpoch 58/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0239 - binary_accuracy: 0.9969 - val_loss: 0.0360 - val_binary_accuracy: 0.9925\nEpoch 59/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0237 - binary_accuracy: 0.9969 - val_loss: 0.0357 - val_binary_accuracy: 0.9925\nEpoch 60/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0234 - binary_accuracy: 0.9969 - val_loss: 0.0354 - val_binary_accuracy: 0.9925\nEpoch 61/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0232 - binary_accuracy: 0.9969 - val_loss: 0.0351 - val_binary_accuracy: 0.9925\nEpoch 62/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0230 - binary_accuracy: 0.9969 - val_loss: 0.0348 - val_binary_accuracy: 0.9925\nEpoch 63/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0228 - binary_accuracy: 0.9969 - val_loss: 0.0345 - val_binary_accuracy: 0.9925\nEpoch 64/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0226 - binary_accuracy: 0.9969 - val_loss: 0.0342 - val_binary_accuracy: 0.9925\nEpoch 65/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0224 - binary_accuracy: 0.9969 - val_loss: 0.0340 - val_binary_accuracy: 0.9925\nEpoch 66/100\n50/50 [==============================] - 1s 10ms/step - loss: 0.0222 - binary_accuracy: 0.9969 - val_loss: 0.0337 - val_binary_accuracy: 0.9925\nEpoch 67/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0220 - binary_accuracy: 0.9969 - val_loss: 0.0335 - val_binary_accuracy: 0.9925\nEpoch 68/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0219 - binary_accuracy: 0.9969 - val_loss: 0.0332 - val_binary_accuracy: 0.9925\nEpoch 69/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0217 - binary_accuracy: 0.9969 - val_loss: 0.0330 - val_binary_accuracy: 0.9925\nEpoch 70/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0215 - binary_accuracy: 0.9969 - val_loss: 0.0327 - val_binary_accuracy: 0.9925\nEpoch 71/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0214 - binary_accuracy: 0.9969 - val_loss: 0.0325 - val_binary_accuracy: 0.9925\nEpoch 72/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0212 - binary_accuracy: 0.9969 - val_loss: 0.0323 - val_binary_accuracy: 0.9925\nEpoch 73/100\n50/50 [==============================] - 1s 15ms/step - loss: 0.0211 - binary_accuracy: 0.9969 - val_loss: 0.0320 - val_binary_accuracy: 0.9925\nEpoch 74/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0209 - binary_accuracy: 0.9969 - val_loss: 0.0318 - val_binary_accuracy: 0.9925\nEpoch 75/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0208 - binary_accuracy: 0.9969 - val_loss: 0.0316 - val_binary_accuracy: 0.9925\nEpoch 76/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0206 - binary_accuracy: 0.9969 - val_loss: 0.0314 - val_binary_accuracy: 0.9925\nEpoch 77/100\n50/50 [==============================] - 1s 20ms/step - loss: 0.0205 - binary_accuracy: 0.9969 - val_loss: 0.0312 - val_binary_accuracy: 0.9925\nEpoch 78/100\n50/50 [==============================] - 1s 11ms/step - loss: 0.0203 - binary_accuracy: 0.9969 - val_loss: 0.0310 - val_binary_accuracy: 0.9925\nEpoch 79/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0202 - binary_accuracy: 0.9969 - val_loss: 0.0308 - val_binary_accuracy: 0.9925\nEpoch 80/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0201 - binary_accuracy: 0.9969 - val_loss: 0.0306 - val_binary_accuracy: 0.9925\nEpoch 81/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0199 - binary_accuracy: 0.9969 - val_loss: 0.0304 - val_binary_accuracy: 0.9925\nEpoch 82/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0198 - binary_accuracy: 0.9969 - val_loss: 0.0303 - val_binary_accuracy: 0.9925\nEpoch 83/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0197 - binary_accuracy: 0.9969 - val_loss: 0.0301 - val_binary_accuracy: 0.9925\nEpoch 84/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0196 - binary_accuracy: 0.9969 - val_loss: 0.0299 - val_binary_accuracy: 0.9925\nEpoch 85/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0194 - binary_accuracy: 0.9969 - val_loss: 0.0298 - val_binary_accuracy: 0.9925\nEpoch 86/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0193 - binary_accuracy: 0.9969 - val_loss: 0.0296 - val_binary_accuracy: 0.9925\nEpoch 87/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0192 - binary_accuracy: 0.9969 - val_loss: 0.0294 - val_binary_accuracy: 0.9925\nEpoch 88/100\n50/50 [==============================] - 1s 12ms/step - loss: 0.0191 - binary_accuracy: 0.9969 - val_loss: 0.0293 - val_binary_accuracy: 0.9925\nEpoch 89/100\n50/50 [==============================] - 0s 9ms/step - loss: 0.0190 - binary_accuracy: 0.9969 - val_loss: 0.0291 - val_binary_accuracy: 0.9925\nEpoch 90/100\n50/50 [==============================] - 1s 14ms/step - loss: 0.0189 - binary_accuracy: 0.9969 - val_loss: 0.0290 - val_binary_accuracy: 0.9925\nEpoch 91/100\n50/50 [==============================] - 1s 13ms/step - loss: 0.0188 - binary_accuracy: 0.9969 - val_loss: 0.0288 - val_binary_accuracy: 0.9925\nEpoch 92/100\n50/50 [==============================] - 0s 6ms/step - loss: 0.0187 - binary_accuracy: 0.9969 - val_loss: 0.0287 - val_binary_accuracy: 0.9925\nEpoch 93/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0186 - binary_accuracy: 0.9969 - val_loss: 0.0285 - val_binary_accuracy: 0.9925\nEpoch 94/100\n50/50 [==============================] - 0s 4ms/step - loss: 0.0185 - binary_accuracy: 0.9969 - val_loss: 0.0284 - val_binary_accuracy: 0.9925\nEpoch 95/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0184 - binary_accuracy: 0.9969 - val_loss: 0.0282 - val_binary_accuracy: 0.9925\nEpoch 96/100\n50/50 [==============================] - 0s 8ms/step - loss: 0.0183 - binary_accuracy: 0.9969 - val_loss: 0.0281 - val_binary_accuracy: 0.9925\nEpoch 97/100\n50/50 [==============================] - 0s 5ms/step - loss: 0.0182 - binary_accuracy: 0.9969 - val_loss: 0.0280 - val_binary_accuracy: 0.9925\nEpoch 98/100\n50/50 [==============================] - 0s 3ms/step - loss: 0.0181 - binary_accuracy: 0.9969 - val_loss: 0.0278 - val_binary_accuracy: 0.9925\nEpoch 99/100\n50/50 [==============================] - 0s 7ms/step - loss: 0.0180 - binary_accuracy: 0.9969 - val_loss: 0.0277 - val_binary_accuracy: 0.9925\nEpoch 100/100\n50/50 [==============================] - 1s 19ms/step - loss: 0.0179 - binary_accuracy: 0.9969 - val_loss: 0.0276 - val_binary_accuracy: 0.9925\n\n\nObjek “history” tersebut memiliki dictionary .history. Kita bisa lihat, apa saja key yang ada:\n\nprint(history2.history.keys())\n\ndict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])\n\n\nTiap key menyimpan data per epoch, sehingga ukurannya sama semua. Oleh karena itu, sebenarnya dictionary ini bisa diubah menjadi pandas DataFrame, yang kemudian bisa kita simpan ke CSV:\n\npd.DataFrame(history2.history).to_csv(\"./keras_sequential_history2.csv\", index=False)\n\nKalau mau menyamakan, file nya bisa kalian download dari GitHub Pages ini: keras_sequential_history2.csv\nKemudian, kita bisa load kembali:\n\nhistory2_df = pd.read_csv(\"./keras_sequential_history2.csv\")\n\n\nhistory2_df\n\n\n\n\n\n\n\n\nloss\nbinary_accuracy\nval_loss\nval_binary_accuracy\n\n\n\n\n0\n0.997174\n0.411875\n0.365997\n0.9975\n\n\n1\n0.397132\n0.948750\n0.287524\n0.9975\n\n\n2\n0.242701\n0.997500\n0.235491\n0.9925\n\n\n3\n0.180374\n0.996250\n0.199048\n0.9925\n\n\n4\n0.145923\n0.996250\n0.172641\n0.9925\n\n\n...\n...\n...\n...\n...\n\n\n95\n0.018302\n0.996875\n0.028094\n0.9925\n\n\n96\n0.018211\n0.996875\n0.027959\n0.9925\n\n\n97\n0.018120\n0.996875\n0.027828\n0.9925\n\n\n98\n0.018030\n0.996875\n0.027700\n0.9925\n\n\n99\n0.017943\n0.996875\n0.027570\n0.9925\n\n\n\n\n100 rows × 4 columns\n\n\n\nDua catatan yang paling sering diperhatikan adalah loss (training loss) dan juga val_loss (validation loss). Bahkan, seringkali kedua nilai ini dibuat gambar plotnya (terhadap epoch), untuk menganalisis bagaimana proses training model.\n\nplt.plot(history2_df[\"loss\"], label = \"training loss\")\nplt.plot(history2_df[\"val_loss\"], label = \"validation loss\")\nplt.xlabel(\"epoch\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nProses training tenryata berjalan dengan sangat baik! Kali ini, baik training loss maupun validation loss turun secara drastis dan terus menuju nol.\nBiasanya, walaupun training loss tidak mungkin naik, terkadang validation loss naik turun, yang bisa jadi pertanda overfitting.\n\n\n\nSeperti di scikit-learn, panggil .predict() untuk melakukan prediksi\n\npredictions2 = model2.predict(inputs)\n\n63/63 [==============================] - 1s 6ms/step\n\n\nAda sedikit progress bar, karena proses prediksi sebenarnya adalah forward pass. Kita bisa matikan progress bar dengan verbose=False\n\npredictions2 = model2.predict(inputs, verbose=False)\n\n\nprint(predictions2)\n\n[[9.8937179e-04]\n [1.2094462e-03]\n [1.4012366e-02]\n ...\n [9.8900378e-01]\n [9.9885350e-01]\n [8.5612518e-01]]\n\n\n\nplt.scatter(inputs[:, 0], inputs[:, 1], c=predictions2[:, 0] &gt; 0.5)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPerintahnya adalah .save(path_tempat_penyimpanan) dengan file format .keras\n\nmodel2.save(\"./keras_sequential_model2.keras\")\n\nKita bisa load kembali model tersebut:\n\nmodel3 = keras.models.load_model(\"keras_sequential_model2.keras\")\n\nHasil prediksinya akan sama (karena modelnya memang sama):\n\npredictions3 = model3.predict(inputs)\n\n63/63 [==============================] - 1s 7ms/step\n\n\n\nnp.array_equal(predictions2, predictions3)\n\nTrue\n\n\n\n\n\nDaripada menyimpan keseluruhan model, kita bisa menyimpan weights atau parameternya saja, dengan perintah .save_weights(path_tempat_penyimpanan) dan file format .weights.h5\n\nmodel2.save_weights(\"keras_sequential_model2.weights.h5\")\n\nUntuk load kembali, kita perlu menyusun layer model terlebih dahulu, sama persis dengan susunan yang aslinya:\n\nmodel4 = keras.Sequential(\n    [\n        keras.layers.InputLayer(input_shape = (2,)),\n        keras.layers.Dense(units = 1, activation = keras.activations.sigmoid)\n    ]\n)\n\nBarulah kita gunakan perintah .load_weights(path_tempat_penyimpanan)\n\nmodel4.load_weights(\"./keras_sequential_model2.weights.h5\")\n\nLagi-lagi, hasil prediksinya akan sama:\n\npredictions4 = model4.predict(inputs)\n\n63/63 [==============================] - 0s 3ms/step\n\n\n\nnp.array_equal(predictions2, predictions4)\n\nTrue\n\n\nPerhatikan bahwa kita belum memanggil model4.compile, artinya kita belum memasang hyperparameter. Meskipun demikian, kita masih bisa melakukan prediksi, karena proses prediksi hanyalah forward pass, yang hanya membutuhkan parameter (weights and biases), yang memang sudah di-load.\nSetelah melakukan model4.compile, dengan hyperparameter yang bahkan tidak harus sama dengan yang aslinya, kita bisa melanjutkan proses training kalau mau.\nMengapa tidak save keseluruhan model saja? Selain lebih hemat memori, contoh kasusnya, kita ingin menyimpan progress dari training model, yang sebenarnya susunan layer nya kita ketahui dengan pasti, seperti contoh model4 di atas."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul7.html#pengayaan-daftar-pilihan-hyperparameter-di-keras",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul7.html#pengayaan-daftar-pilihan-hyperparameter-di-keras",
    "title": "Modul 7 Praktikum Sains Data: Pengantar Neural Network dengan TensorFlow & Keras",
    "section": "",
    "text": "Umum digunakan\n\nLinier (ideentitas): keras.activations.linear\nSigmoid: keras.activations.sigmoid\nReLU: keras.activations.relu\n(Soft) tanh: keras.activations.tanh\nSoftmax: keras.activations.softmax\n\nLainnya\n\nRelu6: keras.activations.relu6\n\\[\\Phi(x) = \\min \\{ \\text{ReLU}(x), 6 \\}\\]\nLeaky ReLU: keras.activations.leaky_relu\nbisa dipasang hyperparameter \\(\\alpha \\ge 0\\): negative_slope\n\\[\\Phi(x) = \\max \\{x, \\alpha x\\}\\]\nELU (Exponential Linear Unit): keras.activations.elu\nbisa dipasang hyperparameter \\(\\alpha \\ge 0\\): alpha\n\\[\n  \\Phi(x) = \\begin{cases}\n      x & x &gt; 0 \\\\\n      \\alpha (e^x - 1) & \\text{otherwise}\n  \\end{cases}\n  \\]\nSoftplus: keras.activations.softplus\n\\[\\Phi(x) = \\ln (e^x + 1)\\]\nSoftsign: keras.activations.softsign\n\\[\\Phi(x) = \\frac{x}{|x| + 1}\\]\nMish: keras.activations.mish\n\\[\\Phi(x) = x \\tanh (\\text{softplus} (x))\\]\nExponential: keras.activations.exponential\nSELU (Scaled Exponential Linear Unit): keras.activations.selu\nGELU (Gaussian error linear unit): keras.activations.gelu\nSwish / Silu: keras.activatins.silu\nHard Silu: keras.activations.hard_silu\nHard sigmoid: keras.activations.hard_sigmoid\nLog softmax: keras.activations.log_softmax\n\nSumber: https://keras.io/api/layers/activations/\n\n\n\nUmum digunakan\n\nSGD: keras.optimizers.SGD\nAdam: keras.optimizers.Adam (saat ini dianggap optimizer terbaik)\nRMSprop: keras.optimizers.RMSprop\nAdagrad: keras.optimizers.Adagrad\n\nLainnya\n\nAdamW: keras.optimizers.AdamW\nAdadelta: keras.optimizers.Adadelta\nAdamax: keras.optimizers.Adamax\nAdafactor: keras.optimizers.Adafactor\nNadam: keras.optimizers.Nadam\nFtrl: keras.optimizers.Ftrl\nLion: keras.optimizers.Lion\nLoss Scale Optimizer: keras.optimizers.LossScaleOptimizer\n\nKecuali Loss Scale Optimizer, semua optimizer bisa dipasang learning rate. Contohnya seperti berikut:\nkeras.optimizers.SGD(learning_rate=0.01)\nSumber: https://keras.io/api/optimizers/\n\n\n\nUmum digunakan\n\nBinary cross-entropy (untuk klasifikasi biner)\nclass: keras.losses.BinaryCrossentropy\nfungsi: keras.losses.binary_crossentropy\nCategorial cross-entropy (untuk klasifikasi multiclass)\nclass: keras.losses.CategoricalCrossentropy\nfungsi: keras.losses.categorical_crossentropy\nMSE / mean squared error (untuk regresi)\nclass: keras.losses.MeanSquaredError\nfungsi: keras.losses.mean_squared_error\n\nLainnya, untuk klasifikasi\n\nSparse categorical cross-entropy\nclass: keras.losses.SparseCategoricalCrossentropy\nfungsi: keras.losses.spare_categorical_crossentropy\nPoisson loss\nclass: keras.losses.Poisson\nfungsi: keras.losses.poisson\nKullback-Leibler divergence loss\nclass: keras.losses.KLDivergence\nfungsi: keras.losses.kl_divergence\n\nLainnya, untuk regresi\n\nMAE / mean absolute error\nclass: keras.losses.MeanAbsoluteError\nfungsi: keras.losses.mean_absolute_error\nMean absolute percentage error\nclass: keras.losses.MeanAbsolutePercentageError\nfungsi: keras.losses.mean_absolute_percentage_error\nMean squared logarithmic error\nclass: keras.losses.MeanSquaredLogarithmicError\nfungsi: keras.losses.mean_squared_logarithmic_error\nCosine similarity\nclass: keras.losses.CosineSimilarity\nfungsi: keras.losses.cosine_similarity\nHuber loss\nclass: keras.losses.Huber\nfungsi: keras.losses.huber\nLog Cosh loss\nclass: keras.losses.LogCosh\nfungsi: keras.losses.log_cosh\n\nSumber: https://keras.io/api/losses/\n\n\n\nUmum digunakan\n\nAccuracy: keras.metrics.Accuracy\n\\(R^2\\): keras.metrics.R2Score\nBinary accuracy: keras.metrics.BinaryAccuracy\nCategorical accuracy: keras.metrics.CategoricalAccuracy\n\nLainnya, untuk klasifikasi multiclass\n\nSparse categorical accuracy: keras.metrics.SpareCategoricalAccuracy\nTop K categorical accuracy: keras.metrics.TopKCategoricalAccuracy\nSpare top K categorical accuracy: keras.metrics.SpareTopKCategoricalAccuracy\n\nLainnya, untuk klasifikasi biner atau True/False\n\nAUC: keras.metrics.AUC\nPrecision: keras.metrics.Precision\nRecall: keras.metrics.Recall\nTrue Positives: keras.metrics.TruePositives\nTrue Negatives: keras.metrics.TrueNegatives\nFalse Positives: keras.metrics.FalsePositives\nFalse Negatives: keras.metrics.FalseNegatives\nPrecision at recall: keras.metrics.PrecisionAtRecall\nRecall at precision: keras.metrics.RecallAtPrecision\nSensitivity at specificity: keras.metrics.SensitivityAtSpecificity\nSpecificity at sensitivity: keras.metrics.SpecificityAtSensitivity\nF-1 score: keras.metrics.F1Score\nF-Beta score: keras.metrics.FBetaScore\n\nSemua pilihan loss function juga bisa digunakan sebagai metrik evaluasi.\nSumber: https://keras.io/api/metrics/"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul7.html#referensi",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul7.html#referensi",
    "title": "Modul 7 Praktikum Sains Data: Pengantar Neural Network dengan TensorFlow & Keras",
    "section": "",
    "text": "Sumber gambar\n\nAggarwal, C. Charu. 2018. Neural Networks and Deep Learning: A Textbook. Edisi Pertama. Springer.\nGoodfellow, Ian; Bengio, Yoshua; & Courville, Aaron. 2016. Deep Learning. MIT Press.\n\nBuku lainnya\n\nGéron, Aurélien. 2019. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Edisi Kedua. O’Reilly Media.\n\nInternet\n\nhttps://www.tensorflow.org/api_docs/python/tf\nhttps://keras.io/api/"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/saindat2024genap.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/saindat2024genap.html",
    "title": "Praktikum Saindat (Sains Data) 2024 Genap (Kurikulum 2020)",
    "section": "",
    "text": "Kembali ke Praktikum\n\nTimeline\n\nModul 1: Pengenalan Pandas, Transformasi Data, 19-20 Februari 2024 (offline di Lab Komputer D.311)\nModul 2: Pengenalan Seaborn, Visualisasi Data, 26-27 Februari 2024 (offline di Lab Komputer D.311)\nModul 3: Encoding Data Kategorik dan Imputasi Data, 4-5 Maret 2024 (offline di Lab Komputer D.311)\nModul 4: Regresi, 13 Maret 2024 (online melalui Zoom)\nModul 5: Decision Tree, SVM, 16 April 2024 (online melalui Zoom)\nModul 6: K-Nearest Neighbors, K-Means Clustering, 22-23 April 2024\nModul 7: Pengantar Neural Network dengan TensorFlow & Keras, 29-30 April 2024\nModul 8: Deep Learning dengan Keras, Regresi dan Klasifikasi Gambar, 6-7 Mei 2024\nTugas 1: Regresi dan Clustering\nDiberikan: Kamis, 9 Mei 2024\nDeadline: Jumat, 24 Mei 2024, 23.59 WIB\nTugas 2: Perbandingan Metode Klasifikasi\nDiberikan: Kamis, 9 Mei 2024\nDeadline: Jumat, 24 Mei 2024, 23.59 WIB\nModul 9: Pengantar PyTorch, 13-14 Mei 2024\nTugas 3: Klasifikasi Gambar dengan Neural Network\nDiberikan: Sabtu, 18 Mei 2024\nDeadline: Sabtu, 8 Juni 2024, 23.59 WIB\n\n\n\nRekaman praktikum\nUntuk pertemuan-pertemuan praktikum Sains Data yang dilaksanakan secara online melalui Zoom, semua rekaman disimpan di link berikut.\nhttps://bit.ly/RekamanPrakSaindat2024Genap"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/tugas2.html",
    "href": "semuahalaman/modulprak/2024/genap/metnum/tugas2.html",
    "title": "Tugas 2 Praktikum Metode Numerik",
    "section": "",
    "text": "Semester Genap Tahun Ajaran 2023/2024\nKembali ke Metode Numerik"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/tugas2.html#petunjuk-umum",
    "href": "semuahalaman/modulprak/2024/genap/metnum/tugas2.html#petunjuk-umum",
    "title": "Tugas 2 Praktikum Metode Numerik",
    "section": "Petunjuk Umum:",
    "text": "Petunjuk Umum:\n\nKerjakan secara individu.\nKerjakan tugas ini menggunakan bahasa pemrograman Python dengan file format berupa interactive Python notebook (yaitu file berbentuk .ipynb BUKAN .py), yang bisa dibuat misalnya menggunakan Jupyter Notebook atau Google Colaboratory.\nHarap sertakan penjelasan untuk setiap variabel yang digunakan dan setiap proses secara singkat di samping potongan kode (dengan comment, ‘#’). Selain itu, sertakan juga penjelasan program (yang bisa mencakupi idenya apa, bagaimana cara eksekusi program, atau tentang algoritma program yang digunakan) pada cell di sebelah (atas/bawah) program.\nFormat nama file untuk Tugas 2 adalah:\nNama Lengkap_NPM_Kelas SIAK_Tugas2PrakMetnum.ipynb\nContoh penamaan yang benar:\nLuthfi Athallah Herdita Wiryaman_2206826980_Kelas G_Tugas2PrakMetnum.ipynb\nApabila ada yang ingin direvisi setelah pengumpulan, lakukan pengumpulan ulang di Google Forms yang sama, tambahkan keterangan bahwa ada revisi, dan tambahkan kata “revisi” pada bagian akhir nama file, contohnya menjadi\nLuthfi Athallah Herdita Wiryaman_2206826980_Kelas G_Tugas2PrakMetnum_revisi.ipynb\nLuthfi Athallah Herdita Wiryaman_2206826980_Kelas G_Tugas2PrakMetnum_revisi2.ipynb\nLuthfi Athallah Herdita Wiryaman_2206826980_Kelas G_Tugas2PrakMetnum_revisi3.ipynb\n(Revisi boleh dilakukan berkali-kali.)\nPengumpulan tugas dilakukan ke Google Forms berikut ini, sesuai dengan kelas Anda di SIAK NG (link akan selalu sama untuk semua tugas praktikum metode numerik):\n\nKelas A: https://forms.gle/AaWvGqEmY1nyx2d48\nKelas B: https://forms.gle/f433d9oJozgkdKZv5\nKelas C:https://forms.gle/iQbibikmgEacst8Z8\nKelas D: https://forms.gle/8F5D9hha2yEstd6z8\nKelas E: https://forms.gle/xz9fpedj9JLXHJH37\nKelas F: https://forms.gle/Ho7kbabuJUopkAP78\n\nDurasi pengerjaan Tugas 2 ini adalah 2 (dua) minggu, dan tenggat waktu (deadline) pengumpulan Tugas 2 ini adalah:\nRabu, 22 Mei 2024, pukul 23.59 WIB.\n(sebelumnya ada salah ketik yaitu Minggu 19 Mei, jadinya Rabu 22 Mei)\nMohon manfaatkan waktu Anda dengan baik (seperti mencicil pengerjaan, bahkan sudah selesai dari jauh-jauh hari) agar mengumpulkan tugas sebelum deadline. Keterlambatan pengumpulan bisa dikenakan pengurangan nilai atau bahkan dianggap tidak mengumpulkan, tergantung kesepakatan dari dosen. Meskipun demikian, lebih baik terlambat mengumpulkan daripada tidak mengumpulkan sama sekali.\nSesuai standar Universitas Indonesia, plagiarisme dilarang keras dan bisa menyebabkan nilai tugas praktikum menjadi nol untuk semua pihak yang terlibat, tanpa peringatan apapun.\nModule atau package Python yang boleh digunakan (di-import) untuk Tugas 2 ini hanyalah NumPy, Tabulate, matplotlib, dan SymPy. Apabila Anda berniat ingin menggunakan module lain, harap konfirmasikan ke narahubung terlebih dahulu (bisa saja diperbolehkan).\nNarahubung untuk Tugas 2 Praktikum Metode Numerik adalah:\n\nZaki - LINE: linenyazaki\nPandu - LINE: pandyadaffa\nDahut - LINE: narendrahutapea\nDani - LINE: 123_dani"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/tugas2.html#soal-tugas-2-praktikum-metode-numerik",
    "href": "semuahalaman/modulprak/2024/genap/metnum/tugas2.html#soal-tugas-2-praktikum-metode-numerik",
    "title": "Tugas 2 Praktikum Metode Numerik",
    "section": "Soal Tugas 2 Praktikum Metode Numerik",
    "text": "Soal Tugas 2 Praktikum Metode Numerik\n\nKetentuan Soal\nRenza sedang mengendarai mobil bersama Davin dan Icha. Saat memasuki jalan tol, Davin mulai mencatat data mengenai jarak yang ditempuh mobilnya tiap beberapa satuan waktu, sedangkan Icha mencatat data mengenai kecepatan mobilnya pada waktu yang sama dengan Davin. Data mereka jika disajikan pada tabel menjadi seperti berikut.\n\\[\\begin{array}{|c|c|c|c|c|c|c|c|}\n\\hline\n\\text{Waktu (jam)}&0&0.2&0.3&0.5&0.7&1.1&1.3&1.7&1.9&2.3&2.9\\\\\n\\hline\n\\text{Jarak (km)}&0&2.32&2.94&5.32&8.54&10.87&14.08&16.78&21.78&25.88&32.98\\\\\n\\hline\n\\text{Kecepatan (km/jam)}&2.13&0.59&0.74&1.62&1.44&1.3&1.19&1.85&2.35&0.25&3.36\\\\\n\\hline\n\\end{array}\\]\nSetelah Renza mengendarai mobil dan sampai, ia memeriksa catatan yang dibuat. Davin dan Icha masing-masing mencatat pada secarik kertas dengan menggunakan pulpen tinta. Sayangnya, ketika Renza memeriksa catatan Davin, kertas itu tertiup angin dan jatuh ke saluran air yang menyebabkan tintanya pudar dan banyak data yang tidak terbaca. Begitu catatan itu kering, terlihat nilai-nilai pada tabel ada yang hilang seperti tabel dibawah ini.\n\\[\\begin{array}{|c|c|c|c|c|c|c|c|}\n\\hline\n\\text{Waktu (jam)}&0&0.2&0.3&0.5&0.7&1.1&1.3&1.7&1.9&2.3&2.9\\\\\n\\hline\n\\text{Jarak (km)}&0&...&2.94&...&8.54&...&14.08&...&21.78&...&32.98\\\\\n\\hline\n\\text{Kecepatan (km/jam)}&2.13&0.59&0.74&1.62&1.44&1.3&1.19&1.85&2.35&0.25&3.36\\\\\n\\hline\n\\end{array}\\]\nPeran kalian adalah bantu Renza untuk mengembalikan nilai-nilai yang hilang tersebut menjadi keadaan semula dengan interpolasi numerik.\nBandingkan nilai-nilai yang kalian peroleh dengan nilai sebelumnya lalu analisis seberapa besar error/galat relatif antara interpolasi kalian dengan nilai sebelumnya.\n\n\nTugas Interpolasi Numerik\n\n[20] Carilah polinomial hasil interpolasi menggunakan tiga metode interpolasi berikut:\n\ninterpolasi Lagrange,\nNewton Forward atau Backward Divided Difference (gunakan salah satu saja),\nInterpolasi Hermite (boleh menggunakan Hermite Lagrange atau Hermite Divide Difference)\n\nuntuk mengembalikan nilai yang hilang di atas. Lalu nyatakan masing-masing polinomial interpolasi yang diperoleh dalam bentuk yang sudah disederhanakan/simplified.\n[10] Buat tabel perbandingan antara nilai interpolasi kalian dan nilai aslinya, disertai nilai galat relatif yang diperoleh.\n[5] Aproksimasikan titik-titik jarak yang tidak ada pada tabel, seperti pada jam \\(0.1, 0.4, 0.6, 0.8\\), dan seterusnya (dalam interval waktu \\([0,2.9]\\)) menggunakan interpolasi numerik. Buat tabel sedemikian sehingga Renza dapat mengetahui jarak yang telah ditempuh Renza pada waktu yang tidak terdata tersebut.\n\n\n\nTugas Diferensiasi Numerik\nSaat ini kalian membantu Renza untuk aproksimasikan nilai yang hilang sebelumnya ditemani secangkir kopi. Ketika kalian membantu, ada tetesan kopi yang mengenai data kecepatan pada kertas milik Icha. Beberapa data di kertas tersebut hilang sedemikian sehingga tabel baru menjadi seperti berikut ini.\n\\[\\begin{array}{|c|c|c|c|c|c|c|c|}\n\\hline\n\\text{Waktu (jam)}&0&0.2&0.3&0.5&0.7&1.1&1.3&1.7&1.9&2.3&2.9\\\\\n\\hline\n\\text{Jarak (km)}&0&2.32&2.94&5.32&8.54&10.87&14.08&16.78&21.78&25.88&32.98\\\\\n\\hline\n\\text{Kecepatan (km/jam)}&2.13&...&0.74&...&1.44&...&1.19&...&2.35&...&3.36\\\\\n\\hline\n\\end{array}\\]\nUntungnya Renza ingat pada mata kuliah Fisika Dasar bahwa kecepatan pada satu titik waktu merupakan turunan dari fungsi jarak terhadap waktu. Dengan menggunakan hasil interpolasi sebelumnya, bantu Renza untuk mencari data kecepatan yang hilang menggunakan diferensiasi numerik.\n\n[20] Manfaatkan polinomial interpolasi yang sudah kalian peroleh sebelumnya (dibebaskan menggunakan hasil polinomial dari metode interpolasi yang mana saja) untuk mengaproksimasikan nilai kecepatan dengan diferensiasi numerik untuk mengembalikan nilai yang hilang karena tetesan kopi di atas. Gunakan metode three point dan five point dengan \\(h=0.05\\); antara midpoint atau endpoint itu kalian pilih yang paling sesuai.\n[10] Buat tabel perbandingan antara nilai diferensiasi numerik kalian dan nilai asli, disertai nilai galat relatif yang diperoleh.\n[5] Aproksimasikan titik-titik kecepatan yang tidak ada pada tabel, seperti pada jam \\(0.1, 0.4, 0.6, 0.8\\), dan seterusnya (dalam interval waktu \\([0,2.9]\\)) menggunakan diferensiasi numerik. Buat tabel sedemikian sehingga Renza dapat mengetahui berapa kecepatannya pada waktu yang tidak terdata tersebut.\n\n\n\nKerapian Program\n\n[10] Keseluruhan program interpolasi dan diferensiasi numerik dikemas di dalam satu subprogram atau fungsi (function) yang bisa menerima sembarang array data waktu, jarak, dan kecepatan, dan nilai \\(h\\).\n[10] Program Anda bisa berjalan berulang kali (dengan beberapa kali input dan output) sesuai permintaan user, tanpa harus berhenti dan di-run ulang secara manual terlebih dahulu.\n\n\n\nBonus\nKetentuan berikut tidak wajib kalian buat, namun apabila dikerjakan akan menjadi nilai tambah apabila terdapat kekurangan pada program yang telah kalian buat.\n\nPilih salah satu metode interpolasi, berikan penjelasan keterangan kalian dan paparkan dengan grafik (plot) waktu-jarak sehingga Renza, Davin dan Icha dapat membaca secara visualisasi.\nPilih salah satu metode diferensiasi numerik, berikan penjelasan keterangan kalian dan paparkan dengan grafik (plot) waktu-kecepatan sehingga Renza, Davin dan Icha dapat membaca secara visualisasi.\nTerapkan metode ekstrapolasi Richardson untuk metode diferensiasi numerik three point. Tambahkan hasilnya sebagai kolom baru di tabel three point yang kalian buat.\nTerapkan metode ekstrapolasi Richardson untuk metode diferensiasi numerik yang five point. Tambahkan hasilnya sebagai kolom baru di tabel five point yang kalian buat."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/tugas2.html#contoh-output-program-disclaimer-contoh-input-berbeda-dengan-soal-dalam-pengerjaan-tetap-pakai-input-soal",
    "href": "semuahalaman/modulprak/2024/genap/metnum/tugas2.html#contoh-output-program-disclaimer-contoh-input-berbeda-dengan-soal-dalam-pengerjaan-tetap-pakai-input-soal",
    "title": "Tugas 2 Praktikum Metode Numerik",
    "section": "Contoh Output Program  (disclaimer: contoh input berbeda dengan soal, dalam pengerjaan tetap pakai input soal)",
    "text": "Contoh Output Program  (disclaimer: contoh input berbeda dengan soal, dalam pengerjaan tetap pakai input soal)\nMasukkan list nilai x : [0,3,7,13,19,29]\nMasukkan list nilai jarak di titik-titik tersebut : [0, 0.294, 0.854, 1.408, 2.178, 3.298]\nMasukkan list nilai kecepatan di titik-titik tersebut : [0.213, 0.74, 0.144, 0.119, 0.235, 0.336]\nMasukkan list nilai x yang dicari: [2,5,11,17,23]\n\n Interpolasi dengan metode interpolasi lagrange, forward/backward NDD, dan hermite lagrange\n|   s |   jarak_asli |   jarak_lagrange |   error_lagrange |   jarak_FDD |   error_FDD |   jarak_BDD |   error_BDD |   jarak_Hermite_lagrange |   error_Hermite_lagrange |\n|-----+--------------+------------------+------------------+-------------+-------------+-------------+-------------+--------------------------+--------------------------|\n|   0 |        0     |         0        |        0         |    0        |   0         |    0        |   0         |                 0        |                 0        |\n|   2 |        0.232 |         0.161997 |        0.0700026 |    0.161997 |   0.0700026 |    0.161997 |   0.0700026 |                -0.447941 |                 0.679941 |\n|   3 |        0.294 |         0.294    |        0         |    0.294    |   0         |    0.294    |   0         |                 0.294    |                 0        |\n|   5 |        0.532 |         0.584952 |        0.0529515 |    0.584952 |   0.0529515 |    0.584952 |   0.0529515 |                 0.919111 |                 0.387111 |\n|   7 |        0.854 |         0.854    |        0         |    0.854    |   0         |    0.854    |   0         |                 0.854    |                 0        |\n|  11 |        1.087 |         1.24738  |        0.160381  |    1.24738  |   0.160381  |    1.24738  |   0.160381  |                 1.55804  |                 0.471036 |\n\n(Masukkan analisis kalian)\n\n\n\nmessageImage_1714893770910.jpg\n\n\n\n\n\nmessageImage_1714894006076.jpg\n\n\nMasukkan besar step size (h) taknol, boleh negatif : 2\n\nkarena error paling bagus didapat menggunakan metode lagrange, maka akan digunakan polinomial lagrange\n  ⎛                       4                         3                        2\nx⋅⎝- 3.27025137596826e-6⋅x  + 0.000206488546994446⋅x  - 0.00434128668896137⋅x\n\n                                            ⎞\n + 0.0349970174751141⋅x + 0.0267702273679134⎠\n\nEkstrapolasi dengan metode TPEP, FPEP, dan Richardson\n|   s |   kecepatan_asli |   Kecepatan_ekstrapolasi_TPEP |   error_TPEP |   Kecepatan_ekstrapolasi_FPEP |   error_FPEP |   Kecepatan_ekstrapolasi_Richardson |   error_Richardson |\n|-----+------------------+-------------------------------+--------------+-------------------------------+--------------+-------------------------------------+--------------------|\n|   0 |            0.213 |                     0.213     |  0           |                     0.213     |    0         |                           0.213     |          0         |\n|   2 |            0.59  |                     0.135961  |  0.454039    |                     0.122265  |    0.467735  |                           0.125652  |          0.464348  |\n|   3 |            0.74  |                     0.74      |  0           |                     0.74      |    0         |                           0.74      |          0         |\n|   5 |            0.162 |                     0.147147  |  0.0148533   |                     0.145424  |    0.0165756 |                           0.145524  |          0.0164758 |\n|   7 |            0.144 |                     0.144     |  0           |                     0.144     |    0         |                           0.144     |          0         |\n|  11 |            0.13  |                     0.0739207 |  0.0560793   |                     0.0820196 |    0.0479804 |                           0.0790754 |          0.0509246 |\n|  13 |            0.119 |                     0.119     |  0           |                     0.119     |    0         |                           0.119     |          0         |\n|  17 |            0.185 |                     0.147185  |  0.0378147   |                     0.146269  |    0.0387314 |                           0.14499   |          0.0400103 |\n|  19 |            0.235 |                     0.235     |  0           |                     0.235     |    0         |                           0.235     |          0         |\n|  23 |            0.25  |                     0.250668  |  0.000668219 |                     0.221899  |    0.0281006 |                           0.226995  |          0.0230051 |\n|  29 |            0.336 |                     0.336     |  0           |                     0.336     |    0         |                           0.336     |          0         |\n(masukkan analisis kalian)\n\n```\n\n\n\nmessageImage_1714891896962.jpg"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul8.html",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul8.html",
    "title": "Modul 8 Persamaan Diferensial Numerik: PDP Parabolik (persamaan panas/difusi)",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\nBentuk umum PDP parabolik (lebih tepatnya persamaan panas atau persamaan difusi) bisa ditulis sebagai berikut:\n\\[\\frac{\\partial u}{\\partial t} (x,t) = \\alpha^2 \\frac{\\partial^2 u}{\\partial x^2}(x,t), \\quad 0 &lt; x &lt; l, \\quad 0 &lt; t &lt; T,\\]\ndengan syarat batas serta nilai awal\n\\[u(0,t) = u(l,t) = 0, \\quad 0 &lt; t \\le T, \\quad \\text{dan} \\quad u(x,0) = f(x), \\quad 0 \\le x \\le l\\]\nStep size dalam variabel \\(x\\) bisa ditulis \\(h = \\Delta x = l/m\\) untuk suatu bilangan bulat positif \\(m\\).\nStep size dalam variabel \\(t\\) bisa ditulis \\(k = \\Delta t = T/N\\) untuk suatu bilangan bulat positif \\(N\\).\nUntuk kebutuhan praktikum, kita dapat menuliskan bentuk umum persamaan panas sebagai berikut:\n\\[\\frac{\\partial u}{\\partial t} (x,t) = \\alpha^2 \\frac{\\partial^2 u}{\\partial x^2}(x,t), \\quad \\text{xb} &lt; x &lt; \\text{xu}, \\quad \\text{tb} &lt; t &lt; \\text{tu},\\]\n\\[u(x,0) = f(x), \\quad \\text{xb} \\le x \\le \\text{xu}\\]\n\\[u(0,t) = \\text{lb}(t) = 0, \\quad \\text{tb} &lt; t \\le \\text{tu}\\]\n\\[u(l,t) = \\text{rb}(t) = 0, \\quad \\text{tb} &lt; t \\le \\text{tu}\\]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul8.html#metode-forward-difference-metode-eksplisit-untuk-pdp-parabolik",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul8.html#metode-forward-difference-metode-eksplisit-untuk-pdp-parabolik",
    "title": "Modul 8 Persamaan Diferensial Numerik: PDP Parabolik (persamaan panas/difusi)",
    "section": "Metode Forward Difference / Metode Eksplisit untuk PDP Parabolik",
    "text": "Metode Forward Difference / Metode Eksplisit untuk PDP Parabolik\n\nIde utama\nMetode forward difference didasari oleh perumusan finite difference berikut,\n\\[\\left(1 - 2 \\lambda\\right)w_{i,j} - w_{i,j+1} + \\lambda \\left(w_{i+1,j} + w_{i-1,j}\\right) = 0\\]\natau bisa ditulis\n\\[w_{i,j+1} = \\left(1 - 2 \\lambda\\right)w_{i,j} + \\lambda \\left(w_{i+1,j} + w_{i-1,j}\\right)\\]\nyang kemudian diubah ke dalam bentuk matriks.\nDalam bentuk matriks, langkah-langkah metode forward difference bisa ditulis sebagai berikut.\n\nMisalkan\n\n\\[\\lambda = \\alpha^2 \\left(\\frac{k}{h^2}\\right)\\]\n\nSusun matriks tridiagonal \\(A\\) berukuran \\((m-1) \\times (m-1)\\) sebagai berikut:\n\n\\[A = \\begin{bmatrix}\n    (1-2\\lambda) & \\lambda & 0 & \\cdots & \\cdots & \\cdots & \\cdots & 0 \\\\\n    \\lambda & (1-2\\lambda) & \\lambda & 0 & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n    0 & \\lambda & (1-2\\lambda) & \\lambda & 0 & \\ddots & \\ddots & \\vdots \\\\\n    \\vdots & \\ddots & \\ddots & \\ddots & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n    \\vdots & \\ddots & \\ddots & \\ddots & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n    \\vdots & \\ddots & \\ddots & \\ddots & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n    0 & \\cdots & \\cdots & \\cdots & 0 & \\lambda & (1-2\\lambda) & \\lambda \\\\\n    0 & \\cdots & \\cdots & \\cdots & \\cdots & 0 & \\lambda & (1-2\\lambda)\n\\end{bmatrix}\\]\n\nSiapkan matriks grid \\(w\\) berukuran \\((m+1) \\times (N+1)\\) untuk menyimpan \\(w_{i,j}\\).\nIsi semua dengan nol terlebih dahulu, atau setidaknya, pastikan baris pertama dan baris terakhir terisi nol semua (sesuai syarat batas).\nMisalkan kolom ke-\\(j\\), kecuali baris pertama dan baris terakhir, ditulis \\(\\textbf{w}^{(j)}\\), yaitu\n\\[\\textbf{w}^{(j)} = (w_{2,j}, w_{3,j}, \\dots, w_{m,j})\\]\nIsi kolom pertama \\(w\\) berdasarkan nilai awal, yaitu\n\\[w_{i,1} = f(x_i)\\]\natau bisa ditulis\n\\[\\textbf{w}^{(1)} = (f(x_2), f(x_3), \\dots, f(x_m))\\]\nUntuk \\(j = 2, \\dots, N+1\\), isi kolom ke-\\(j\\) dengan perkalian matriks\n\\[\\textbf{w}^{(j)} = A\\textbf{w}^{(j-1)}\\]\n\n\n\nFunction file (dengan perumusan finite difference)\n\nFunction file parabolik_forward_fd.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x, t, w] = parabolik_forward_fd(alph2, f, lb, rb, xb, xu, tb, tu, h, k)\n  x = xb : h : xu;\n  t = tb : k : tu;\n  m_plus_1 = length(x);\n  N_plus_1 = length(t);\n  w = zeros(m_plus_1, N_plus_1);\n\n  lambd = (alph2 * k) / h^2;\n\n  % memasang nilai awal\n  for i = 1 : m_plus_1\n    w(i, 1) = f(x(i));\n  endfor\n\n  % memasang syarat batas\n  for j = 2 : N_plus_1\n    w(1, j)         = lb(t(j));\n    w(m_plus_1, j)  = rb(t(j));\n  endfor\n\n  % menggunakan perumusan finite difference untuk mengisi sisanya\n  for j = 1 : (N_plus_1 - 1)\n    for i = 2 : (m_plus_1 - 1)\n      w(i, j+1) = (1 - 2 * lambd) * w(i, j) + lambd * (w(i+1, j) + w(i-1, j));\n    endfor\n  endfor\nendfunction\n\n\n\n\n\n\nFunction file (dengan perumusan matriks)\n\nFunction file parabolik_forward_matriks.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x, t, w] = parabolik_forward_matriks(alph2, f, lb, rb, xb, xu, tb, tu, h, k)\n  x = xb : h : xu;\n  t = tb : k : tu;\n  m_plus_1 = length(x);\n  N_plus_1 = length(t);\n  w = zeros(m_plus_1, N_plus_1);\n\n  lambd = (alph2 * k) / h^2;\n\n  % memasang nilai awal\n  for i = 1 : m_plus_1\n    w(i, 1) = f(x(i));\n  endfor\n\n  % memasang syarat batas\n  for j = 2 : N_plus_1\n    w(1, j)         = lb(t(j));\n    w(m_plus_1, j)  = rb(t(j));\n  endfor\n\n  % menyusun matriks A\n  A = zeros(m_plus_1 - 2, m_plus_1 - 2); % isi dulu dengan nol semua\n  for i = 1 : (m_plus_1 - 2) % untuk tiap baris ke-i\n    % isi sebelah kiri/bawah diagonal (kecuali baris pertama)\n    if (i &gt; 1)\n      A(i, i-1) = lambd;\n    endif\n\n    % isi diagonal\n    A(i, i) = 1 - 2 * lambd;\n\n    % isi sebelah kanan/atas diagonal (kecuali baris terakhir)\n    if (i &lt; m_plus_1 - 2)\n      A(i, i+1) = lambd;\n    endif\n  endfor\n\n  % perkalian matriks untuk mengisi semua nilai lainnya\n  for j = 2 : N_plus_1 % untuk tiap waktu ke-j selain nilai awal\n    w(2 : m_plus_1 - 1, j) = A * w(2 : m_plus_1 - 1, j-1);\n  endfor\nendfunction\n\n\n\n\n\n\nContoh (stabil) dengan \\(h = 0.2\\), \\(k = 0.02\\)\nAkan kita uji menggunakan persamaan panas:\n\\[\\begin{align*}\n    u_t - u_{xx} &= 0, \\quad 0 &lt; x &lt; 1, \\quad t &gt; 0 \\\\\n    u(0,t) &= u(1,t) = 0, \\quad t \\le 0 \\\\\n    u(x,0) &= 10x^3(1-x), \\quad 0 \\le x \\le 1 \\\\\n\\end{align*}\\]\nSolusi eksak dari PDP tersebut adalah:\n\\[\\begin{align*}\n    u(x,t) &= \\sum_{n=1}^{\\infty} c_n e^{-n^2 \\pi^2 t} \\sin \\left( n\\pi x\\right) \\\\\n    c_n &= 20 \\int_0^1 x^3 (1-x) \\sin \\left( n\\pi x \\right) dx, \\quad n = 1, 2, \\dots\n\\end{align*}\\]\nUntuk keperluan komputasi, untuk solusi eksak, akan kita ambil 10 suku pertama dari ekspansi deret Fourier dari u(x,t).\nPerhatikan bahwa \\(\\alpha^2 = 1\\) sehingga\n\\[\\lambda = \\frac{\\alpha^2 k}{h^2} = \\frac{(1)(0.02)}{(0.2)^2} = \\frac{0.02}{0.04} = \\frac{1}{2} \\le \\frac{1}{2}\\]\nOleh karena itu, metode forward difference dijamin stabil untuk pemilihan step size ini.\nMenggunakan pendekatan finite difference:\n\nScript file coba1_parabolik_forward_fd.m - nama file bebas\n\n\n\nalph2 = 1;\nf = @(x) 10 * x .^ 3 .* (1 - x);\nlb = @(t) 0;\nrb = @(t) 0;\nxb = 0;\nxu = 1;\ntb = 0;\ntu = 1;\nh = 0.2;\nk = 0.02;\n\n[x, t, w] = parabolik_forward_fd(alph2, f, lb, rb, xb, xu, tb, tu, h, k);\n\nu = zeros(length(x), length(t));\nfor i = 1 : length(x)\n  for j = 1 : length(t)\n    u(i, j) = 0;\n    for n = 1 : 10\n      F = @(x) x .^ 3 .* (1 - x) .* sin(n * pi .* x);\n      cn = 20 * integral(F, 0, 1);\n      u(i, j) += cn * exp(-n^2 * pi^2 .* t(j)) .* sin(n * pi .* x(i));\n    endfor\n  endfor\nendfor\n\nfigure 1;\nmesh(x, t, w');\ntitle(\"Solusi Numerik\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"w\");\n\nfigure 2;\nmesh(x, t, u');\ntitle(\"Solusi Analitik (deret hingga n=10)\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"u\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlternatifnya, menggunakan bentuk matriks:\n\nScript file coba1_parabolik_forward_matriks.m - nama file bebas\n\n\n\nalph2 = 1;\nf = @(x) 10 * x .^ 3 .* (1 - x);\nlb = @(t) 0;\nrb = @(t) 0;\nxb = 0;\nxu = 1;\ntb = 0;\ntu = 1;\nh = 0.2;\nk = 0.02;\n\n[x, t, w] = parabolik_forward_matriks(alph2, f, lb, rb, xb, xu, tb, tu, h, k);\n\nu = zeros(length(x), length(t));\nfor i = 1 : length(x)\n  for j = 1 : length(t)\n    u(i, j) = 0;\n    for n = 1 : 10\n      F = @(x) x .^ 3 .* (1 - x) .* sin(n * pi .* x);\n      cn = 20 * integral(F, 0, 1);\n      u(i, j) += cn * exp(-n^2 * pi^2 .* t(j)) .* sin(n * pi .* x(i));\n    endfor\n  endfor\nendfor\n\nfigure 1;\nmesh(x, t, w');\ntitle(\"Solusi Numerik\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"w\");\n\nfigure 2;\nmesh(x, t, u');\ntitle(\"Solusi Analitik (deret hingga n=10)\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"u\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBaik menggunakan pendekatan finite difference maupun bentuk matriks, Anda juga bisa menampilkan animasi persebaran suhu yang terus menurun, dengan menambahkan kode berikut di akhir script file:\n\nfigure(3);\nfor j = 1:length(t)\n  plot(x, u(:, j), 'k', 'linewidth', 1.5);\n  ylim([0, 1.5]);\n  title(\"Animasi solusi aproksimasi u(x, t) seiring berjalannya t\");\n  drawnow;\n  pause(0.1);\nendfor\n\n\n\nContoh (tidak stabil) dengan \\(h = k = 0.2\\)\nMenggunakan soal yang sama,\n\\[\\begin{align*}\n    u_t - u_{xx} &= 0, \\quad 0 &lt; x &lt; 1, \\quad t &gt; 0 \\\\\n    u(0,t) &= u(1,t) = 0, \\quad t \\le 0 \\\\\n    u(x,0) &= 10x^3(1-x), \\quad 0 \\le x \\le 1 \\\\\n\\end{align*}\\]\nSolusi eksak dari PDP tersebut adalah:\n\\[\\begin{align*}\n    u(x,t) &= \\sum_{n=1}^{\\infty} c_n e^{-n^2 \\pi^2 t} \\sin \\left( n\\pi x\\right) \\\\\n    c_n &= 20 \\int_0^1 x^3 (1-x) \\sin \\left( n\\pi x \\right) dx, \\quad n = 1, 2, \\dots\n\\end{align*}\\]\nPerhatikan bahwa \\(\\alpha^2 = 1\\) sehingga\n\\[\\lambda = \\frac{\\alpha^2 k}{h^2} = \\frac{(1)(0.2)}{(0.2)^2} = \\frac{0.2}{0.04} = 5 &gt; \\frac{1}{2}\\]\nOleh karena itu, metode forward difference tidak dijamin stabil untuk pemilihan step size ini. Mari kita lihat.\nUntuk pendekatan finite difference:\n\nScript file coba2_parabolik_forward_fd.m - nama file bebas\n\n\n\nalph2 = 1;\nf = @(x) 10 * x .^ 3 .* (1 - x);\nlb = @(t) 0;\nrb = @(t) 0;\nxb = 0;\nxu = 1;\ntb = 0;\ntu = 1;\nh = 0.2;\nk = 0.2;\n\n[x, t, w] = parabolik_forward_fd(alph2, f, lb, rb, xb, xu, tb, tu, h, k);\n\nu = zeros(length(x), length(t));\nfor i = 1 : length(x)\n  for j = 1 : length(t)\n    u(i, j) = 0;\n    for n = 1 : 10\n      F = @(x) x .^ 3 .* (1 - x) .* sin(n * pi .* x);\n      cn = 20 * integral(F, 0, 1);\n      u(i, j) += cn * exp(-n^2 * pi^2 .* t(j)) .* sin(n * pi .* x(i));\n    endfor\n  endfor\nendfor\n\nfigure 1;\nmesh(x, t, w');\ntitle(\"Solusi Numerik\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"w\");\n\nfigure 2;\nmesh(x, t, u');\ntitle(\"Solusi Analitik (deret hingga n=10)\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"u\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUntuk pendekatan bentuk matriks:\n\nScript file coba2_parabolik_forward_matriks.m - nama file bebas\n\n\n\nalph2 = 1;\nf = @(x) 10 * x .^ 3 .* (1 - x);\nlb = @(t) 0;\nrb = @(t) 0;\nxb = 0;\nxu = 1;\ntb = 0;\ntu = 1;\nh = 0.2;\nk = 0.2;\n\n[x, t, w] = parabolik_forward_matriks(alph2, f, lb, rb, xb, xu, tb, tu, h, k);\n\nu = zeros(length(x), length(t));\nfor i = 1 : length(x)\n  for j = 1 : length(t)\n    u(i, j) = 0;\n    for n = 1 : 10\n      F = @(x) x .^ 3 .* (1 - x) .* sin(n * pi .* x);\n      cn = 20 * integral(F, 0, 1);\n      u(i, j) += cn * exp(-n^2 * pi^2 .* t(j)) .* sin(n * pi .* x(i));\n    endfor\n  endfor\nendfor\n\nfigure 1;\nmesh(x, t, w');\ntitle(\"Solusi Numerik\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"w\");\n\nfigure 2;\nmesh(x, t, u');\ntitle(\"Solusi Analitik (deret hingga n=10)\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"u\");"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul8.html#metode-backward-difference-untuk-pdp-parabolik",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul8.html#metode-backward-difference-untuk-pdp-parabolik",
    "title": "Modul 8 Persamaan Diferensial Numerik: PDP Parabolik (persamaan panas/difusi)",
    "section": "Metode Backward Difference untuk PDP Parabolik",
    "text": "Metode Backward Difference untuk PDP Parabolik\n\nIde utama\n\n\nFunction file (dengan faktorisasi Crout sesuai pseudocode)\n\nFunction file parabolik_backward_crout.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x, t, w] = parabolik_backward_crout(d, f, lb, rb, xb, xu, tb, tu, dx, dt)\n  x = xb:dx:xu;\n  t = tb:dt:tu;\n  nx = length(x);\n  nt = length(t);\n\n  % Nilai lambda\n  lambd = (d * dt) / (dx^2);\n\n  % Nilai awal dan syarat batas\n  for i = 1:nx\n    w(i, 1) = f(x(i));\n  endfor\n\n  for j = 2:nt\n    w(1, j) = lb(t(j));\n    w(nx, j) = rb(t(j));\n  endfor\n\n  % Penyelesaian SPL dengan faktorisasi Crout\n  l(2) = 1 + 2*lambd;\n  u(2) = -lambd / l(2);\n  for i = 3:nx-2\n    l(i) = 1 + 2*lambd + lambd*u(i-1);\n    u(i) = -lambd / l(i);\n  endfor\n  l(nx-1) = 1 + 2*lambd + lambd*u(nx-2);\n  for j = 2:nt\n    z(2) = w(2, j-1) / l(2);\n    for i = 3:nx-1\n      z(i) = (w(i, j-1) + lambd*z(i-1)) / l(i);\n    endfor\n    w(nx-1, j) = z(nx-1);\n    for i = nx-2:-1:2\n      w(i, j) = z(i) - u(i)*w(i+1, j);\n    endfor\n  endfor\nendfunction\n\n\n\n\n\n\nFunction file (dengan solusi SPL secara langsung)\n\nFunction file parabolik_backward_langsung.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x, t, u] = parabolik_backward_langsung(alph2, f, lb, rb, xb, xu, tb, tu, h, k)\n  x = xb : h : xu;\n  t = tb : k : tu;\n  m_plus_1 = length(x);\n  N_plus_1 = length(t);\n  u = zeros(m_plus_1, N_plus_1);\n\n  lambd = (alph2 * k) / h^2;\n\n  % memasang nilai awal\n  for i = 1 : m_plus_1\n    u(i, 1) = f(x(i));\n  endfor\n\n  % memasang syarat batas\n  for j = 2 : N_plus_1\n    u(1, j)         = lb(t(j));\n    u(m_plus_1, j)  = rb(t(j));\n  endfor\n\n  % menyusun matriks A\n  A = zeros(m_plus_1 - 2, m_plus_1 - 2);\n  for i = 1 : (m_plus_1 - 2)\n    % isi sebelah kiri/atas diagonal\n    if (i &gt; 1)\n      A(i, i-1) = -lambd;\n    endif\n\n    % isi diagonal\n    A(i, i) = 1 + 2 * lambd;\n\n    % isi sebelah kanan/bawah diagonal\n    if (i &lt; m_plus_1 - 2)\n      A(i, i+1) = -lambd;\n    endif\n  endfor\n\n  % mengisi semua nilai lainnya dengan penyelesaian SPL\n  for j = 2 : N_plus_1\n    u(2 : m_plus_1 - 1, j) = A \\ u(2 : m_plus_1 - 1, j-1);\n  endfor\nendfunction\n\n\n\n\n\n\nContoh soal\nAkan kita uji dengan persamaan difusi:\n\\[\\begin{align*}\n    u_t - u_{xx} &= 0, \\quad 0 &lt; x &lt; 1, \\quad t &gt; 0, \\\\\n    u(0,t) &= u(1,t) = 0, \\quad t &gt; 0, \\\\\n    u(x,0) &= \\sin \\left(\\pi x\\right), \\quad 0 \\le x \\le 1\n\\end{align*}\\]\ndengan solusi eksak:\n\\[u(x,t) = e^{-\\pi^2 t} \\sin \\left(\\pi x\\right)\\]\nKita batasi \\(t\\) menjadi \\(0 \\le t \\le 1\\) dan gunakan \\(\\Delta x = 0.2\\) dan \\(\\Delta t = 0.2\\), di mana kondisinya tidak stabil untuk metode eksplisit.\nMenggunakan function file dari pseudocode:\n\nScript file coba_parabolik_backward_crout.m - nama file bebas\n\n\n\nd = 1;\nf = @(x) sin(pi*x);\nlb = rb = @(t) 0;\nxb = 0;\nxu = 1;\ntb = 0;\ntu = 1;\ndx = 0.2;\ndt = 0.2;\n\n[x, t, w] = parabolik_backward_crout(d, f, lb, rb, xb, xu, tb, tu, dx, dt);\n\nu = @(x, t) exp(-pi^2.*t) * sin(pi.*x);\nfor i = 1:length(x)\n  for j = 1:length(t)\n    ufig(i, j) = u(x(i), t(j));\n  endfor\nendfor\n\nfigure(1);\nmesh(x, t, ufig');\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"u\");\n\nfigure(2);\nmesh(x, t, w');\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"u\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMenggunakan function file dengan solusi SPL secara langsung:\n\nScript file coba_parabolik_backward_langsung.m - nama file bebas\n\n\n\nalph2 = 1;\nf = @(x) 10 * x .^ 3 .* (1 - x);\nlb = @(t) 0;\nrb = @(t) 0;\nxb = 0;\nxu = 1;\ntb = 0;\ntu = 1;\nh = 0.2;\nk = 0.2;\n\n[x, t, w] = parabolik_backward_langsung(alph2, f, lb, rb, xb, xu, tb, tu, h, k);\n\nu = zeros(length(x), length(t));\nfor i = 1 : length(x)\n  for j = 1 : length(t)\n    u(i, j) = 0;\n    for n = 1 : 10\n      F = @(x) x .^ 3 .* (1 - x) .* sin(n * pi .* x);\n      cn = 20 * integral(F, 0, 1);\n      u(i, j) += cn * exp(-n^2 * pi^2 .* t(j)) .* sin(n * pi .* x(i));\n    endfor\n  endfor\nendfor\n\nfigure 1;\nmesh(x, t, w');\ntitle(\"Solusi Numerik\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"w\");\n\nfigure 2;\nmesh(x, t, u');\ntitle(\"Solusi Analitik (deret hingga n=10)\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"u\");"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul8.html#metode-crack-nicolson-untuk-pdp-parabolik",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul8.html#metode-crack-nicolson-untuk-pdp-parabolik",
    "title": "Modul 8 Persamaan Diferensial Numerik: PDP Parabolik (persamaan panas/difusi)",
    "section": "Metode Crack-Nicolson untuk PDP Parabolik",
    "text": "Metode Crack-Nicolson untuk PDP Parabolik\n\nIde utama\n\n\nFunction file (dengan faktorisasi Crout sesuai pseudocode)\n\nFunction file crank_nicolson_crout.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x, t, w] = crank_nicolson_crout(d, f, lb, rb, xb, xu, tb, tu, dx, dt)\n  x = xb:dx:xu;\n  t = tb:dt:tu;\n  nx = length(x);\n  nt = length(t);\n\n  % Nilai lambda\n  lambd = (d * dt) / (dx^2);\n\n  % Nilai awal dan syarat batas\n  for i = 1:nx\n    w(i, 1) = f(x(i));\n  endfor\n\n  for j = 2:nt\n    w(1, j) = lb(t(j));\n    w(nx, j) = rb(t(j));\n  endfor\n\n  % Penyelesaian SPL menggunakan faktorisasi Crout\n  l(2) = 1 + lambd;\n  u(2) = -lambd / (2*l(2));\n  for i = 3:nx-2\n    l(i) = 1 + lambd + (lambd*u(i-1))/2;\n    u(i) = -lambd / (2*l(i));\n  endfor\n  l(nx-1) = 1 + lambd + (lambd*u(nx-2))/2;\n  for j = 2:nt\n    z(2) = ((1-lambd)*w(2, j-1) + (lambd/2)*w(3, j-1)) / l(2);\n    for i = 3:nx-1\n      z(i) = ((1-lambd)*w(i, j-1) + (lambd/2)*(w(i+1, j-1) + w(i-1, j-1) + z(i-\n      1))) / l(i);\n    endfor\n    w(nx-1, j) = z(nx-1);\n    for i = nx-2:-1:2\n      w(i, j) = z(i) - u(i)*w(i+1, j);\n    endfor\n  endfor\nendfunction\n\n\n\n\n\n\nFunction file (dengan solusi SPL secara langsung)\n\nFunction file crank_nicolson_langsung.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x, t, w] = crank_nicolson_langsung(alph2, f, lb, rb, xb, xu, tb, tu, h, k)\n  x = xb : h : xu;\n  t = tb : k : tu;\n  m_plus_1 = length(x);\n  N_plus_1 = length(t);\n  w = zeros(m_plus_1, N_plus_1);\n\n  lambda = (alph2 * k) / h^2;\n\n  % memasang nilai awal\n  for i = 1 : m_plus_1\n    w(i, 1) = f(x(i));\n  endfor\n\n  % memasang syarat batas\n  for j = 2 : N_plus_1\n    w(1, j)         = lb(t(j));\n    w(m_plus_1, j)  = rb(t(j));\n  endfor\n\n  % menyusun matriks A\n  A = zeros(m_plus_1 - 2, m_plus_1 - 2);\n  for i = 1 : (m_plus_1 - 2)\n    % isi sebelah kiri/atas diagonal\n    if (i &gt; 1)\n      A(i, i-1) = -lambda/2;\n    endif\n\n    % isi diagonal\n    A(i, i) = 1 + lambda;\n\n    % isi sebelah kanan/bawah diagonal\n    if (i &lt; m_plus_1 - 2)\n      A(i, i+1) = -lambda/2;\n    endif\n  endfor\n\n  % menyusun matriks B\n  B = zeros(m_plus_1 - 2, m_plus_1 - 2);\n  for i = 1 : (m_plus_1 - 2)\n    % isi sebelah kiri/atas diagonal\n    if (i &gt; 1)\n      B(i, i-1) = lambda/2;\n    endif\n\n    % isi diagonal\n    B(i, i) = 1 - lambda;\n\n    % isi sebelah kanan/bawah diagonal\n    if (i &lt; m_plus_1 - 2)\n      B(i, i+1) = lambda/2;\n    endif\n  endfor\n\n  % penyelesaian Aw^(j) = Bw^(j-1):\n  % misalkan z = Bw^(j-1), lalu selesaikan Aw^(j) = z\n  for j = 2 : N_plus_1\n    z = B * w(2 : m_plus_1 - 1, j-1);\n    w(2 : m_plus_1 - 1, j) = A \\ z;\n  endfor\nendfunction\n\n\n\n\n\n\nContoh 1\nSama seperti untuk backward difference, akan kita uji dengan persamaan difusi:\n\\[\\begin{align*}\n    u_t - u_{xx} &= 0, \\quad 0 &lt; x &lt; 1, \\quad t &gt; 0, \\\\\n    u(0,t) &= u(1,t) = 0, \\quad t &gt; 0, \\\\\n    u(x,0) &= \\sin \\left(\\pi x\\right), \\quad 0 \\le x \\le 1\n\\end{align*}\\]\ndengan solusi eksak:\n\\[u(x,t) = e^{-\\pi^2 t} \\sin \\left(\\pi x\\right)\\]\nKita batasi \\(t\\) menjadi \\(0 \\le t \\le 1\\) dan gunakan \\(\\Delta x = 0.2\\) dan \\(\\Delta k = 0.2\\), di mana kondisinya tidak stabil untuk metode eksplisit.\nMenggunakan function file dari pseudocode:\n\nScript file coba1_crank_nicolson_crout.m - nama file bebas\n\n\n\nd = 1;\nf = @(x) sin(pi*x);\nlb = rb = @(t) 0;\nxb = 0;\nxu = 1;\ntb = 0;\ntu = 1;\ndx = 0.2;\ndt = 0.2;\n\n[x, t, w] = crank_nicolson_crout(d, f, lb, rb, xb, xu, tb, tu, dx, dt);\n\nu = @(x, t) exp(-pi^2.*t) * sin(pi.*x);\nfor i = 1:length(x)\n  for j = 1:length(t)\n    ufig(i, j) = u(x(i), t(j));\n  endfor\nendfor\n\nfigure(1);\nmesh(x, t, ufig');\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"u\");\n\nfigure(2);\nmesh(x, t, w');\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"u\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMenggunakan function file dengan penyelesaian SPL secara langsung:\n\nScript file coba1_crank_nicolson_langsung.m - nama file bebas\n\n\n\nalph2 = 1;\nf = @(x) sin(pi*x);\nlb = @(t) 0;\nrb = @(t) 0;\nxb = 0;\nxu = 1;\ntb = 0;\ntu = 1;\nh = 0.2;\nk = 0.2;\n\n[x, t, w] = crank_nicolson_langsung(alph2, f, lb, rb, xb, xu, tb, tu, h, k);\n\nu = zeros(length(x), length(t));\nsln = @(x, t) exp(-pi^2.*t) * sin(pi.*x);\nfor i = 1:length(x)\n  for j = 1:length(t)\n    u(i, j) = sln(x(i), t(j));\n  endfor\nendfor\n\nfigure 1;\nmesh(x, t, w');\ntitle(\"Solusi Numerik\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"w\");\n\nfigure 2;\nmesh(x, t, u');\ntitle(\"Solusi Analitik (deret hingga n=10)\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"u\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContoh 2\nAkan kita uji menggunakan persamaan panas:\n\\[\\begin{align*}\n    u_t - u_{xx} &= 0, \\quad 0 &lt; x &lt; 1, \\quad t &gt; 0 \\\\\n    u(0,t) &= u(1,t) = 0, \\quad t \\le 0 \\\\\n    u(x,0) &= 10x^3(1-x), \\quad 0 \\le x \\le 1 \\\\\n\\end{align*}\\]\nSolusi eksak dari PDP tersebut adalah:\n\\[\\begin{align*}\n    u(x,t) &= \\sum_{n=1}^{\\infty} c_n e^{-n^2 \\pi^2 t} \\sin \\left( n\\pi x\\right) \\\\\n    c_n &= 20 \\int_0^1 x^3 (1-x) \\sin \\left( n\\pi x \\right) dx, \\quad n = 1, 2, \\dots\n\\end{align*}\\]\nMenggunakan function file dengan solusi SPL secara langsung:\n\nScript file coba2_crank_nicolson_langsung.m - nama file bebas\n\n\n\nalph2 = 1;\nf = @(x) 10 * x .^ 3 .* (1 - x);\nlb = @(t) 0;\nrb = @(t) 0;\nxb = 0;\nxu = 1;\ntb = 0;\ntu = 1;\nh = 0.2;\nk = 0.2;\n\n[x, t, w] = crank_nicolson_langsung(alph2, f, lb, rb, xb, xu, tb, tu, h, k);\n\nu = zeros(length(x), length(t));\nfor i = 1 : length(x)\n  for j = 1 : length(t)\n    u(i, j) = 0;\n    for n = 1 : 10\n      F = @(x) x .^ 3 .* (1 - x) .* sin(n * pi .* x);\n      cn = 20 * integral(F, 0, 1);\n      u(i, j) += cn * exp(-n^2 * pi^2 .* t(j)) .* sin(n * pi .* x(i));\n    endfor\n  endfor\nendfor\n\nfigure 1;\nmesh(x, t, w');\ntitle(\"Solusi Numerik\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"w\");\n\nfigure 2;\nmesh(x, t, u');\ntitle(\"Solusi Analitik (deret hingga n=10)\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"u\");"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul7.html",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul7.html",
    "title": "Modul 7 Kalkulin 2024 Genap: Transformasi Linier Umum",
    "section": "",
    "text": "Kembali ke Kalkulin"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#regresi-linier",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#regresi-linier",
    "title": "Modul 3 Sains Data: Encoding Data Kategorik dan Imputasi Data",
    "section": "Regresi Linier",
    "text": "Regresi Linier"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/tugas2.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/tugas2.html",
    "title": "Tugas 2 Praktikum Sains Data 2024 Genap: Perbandingan Metode Klasifikasi",
    "section": "",
    "text": "Kembali ke Sains Data\n\n\n\nKerjakan secara individu.\nKerjakan tugas ini menggunakan bahasa pemrograman Python dengan file format berupa interactive Python notebook (yaitu file berbentuk .ipynb BUKAN .py), yang bisa dibuat misalnya menggunakan Jupyter Notebook atau Google Colaboratory.\nHarap sertakan penjelasan untuk setiap proses secara singkat di samping potongan kode (bisa dengan teks / text box maupun dengan comment, ‘#’).\nFormat nama file untuk Tugas 2 adalah:\nNama Lengkap_NPM_Kelas SIAK_Tugas2PrakSaindat.ipynb\nContoh penamaan yang benar:\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas2PrakSaindat.ipynb\nUntuk mengumpulkan lebih dari satu file, gunakan .zip dengan format nama yang sama (dan file .ipynb yang di dalamnya juga masih menggunakan format nama yang sama).\nApabila ada yang ingin direvisi setelah pengumpulan, lakukan pengumpulan ulang di Google Forms yang sama, tambahkan keterangan bahwa ada revisi, dan tambahkan kata “revisi” pada bagian akhir nama file, contohnya menjadi\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas2PrakSaindat_revisi.ipynb\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas2PrakSaindat_revisi2.ipynb\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas2PrakSaindat_revisi3.ipynb\n(tentunya gunakan .zip kalau ada lebih dari satu file yang ingin dikumpulkan)\n(Revisi boleh dilakukan berkali-kali selama masa pengerjaan.)\nPengumpulan tugas dilakukan ke Google Forms berikut ini, sesuai dengan kelas Anda di SIAK NG (link akan selalu sama untuk semua tugas praktikum Sains Data):\n\nKelas A: https://forms.gle/TdxprAuySMAWt5NR7\nKelas B: https://forms.gle/bk2LBnowfZhmw5qY9\n\nDengan durasi pengerjaan sekitar 2 (dua) minggu, tenggat waktu (deadline) pengumpulan Tugas 2 ini (termasuk revisi) adalah:\nJumat, 24 Mei 2024, pukul 23.59 WIB.\nMohon manfaatkan waktu Anda dengan baik (seperti mencicil pengerjaan, bahkan sudah selesai dari jauh-jauh hari) agar mengumpulkan tugas sebelum deadline. Keterlambatan pengumpulan bisa dikenakan pengurangan nilai atau bahkan dianggap tidak mengumpulkan, tergantung kesepakatan dari dosen. Meskipun demikian, lebih baik terlambat mengumpulkan daripada tidak mengumpulkan sama sekali.\nSesuai standar Universitas Indonesia, plagiarisme dilarang keras dan bisa menyebabkan nilai tugas praktikum menjadi nol untuk semua pihak yang terlibat, tanpa peringatan apapun. Namun, Anda boleh memanfaatkan kode apapun yang ada di modul praktikum.\nNarahubung untuk Tugas 2 Praktikum Sains Data adalah:\n\nRifki - LINE: rifkyprakasya_\nBisma - LINE: bisma_joyosumarto\n\n\n\n\n\nTugas 2 ini terdiri dari soal a-e.\nAda dataset water_potability.csv yang mendata kualitas air di ribuan tempat (satu baris per tempat) dan menentukan apakah air tersebut layak diminum (potable), dengan nilai 1 (satu) jika layak dan nilai 0 (nol) jika tidak layak. Dataset ini bisa di-download dari salah satu sumber berikut:\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle: https://www.kaggle.com/datasets/adityakadiwal/water-potability\n\nDi dataset ini, fitur target yang ingin diprediksi adalah kelayakan air (Potability). Perhatikan, fitur ini bersifat biner, sehingga metode machine learning yang cocok untuk prediksi adalah metode klasifikasi.\nMetode-metode klasifikasi (selain neural network) yang sudah kita pelajari selama praktikum adalah\n\nregresi logistik (khusus klasifikasi biner);\ndecision tree;\nSVM (khusus klasifikasi biner); dan\nk-nearest neighbors.\n\nMenggunakan keempat metode di atas, lakukan end-to-end machine learning, atau lebih tepatnya end-to-end classification, yang meliputi:\n\nLangkah preprocessing yang sekiranya diperlukan\nEDA\nLakukan train-test-split (rasionya bebas, misal 80:20). Jangan lupa gunakan suatu random_state.\nTraining: menggunakan scikit-learn (sklearn), untuk menyelesaikan masalah klasifikasi di atas, buatlah model\n\nregresi logistik;\ndecision tree;\nSVM; dan\nk-nearest neighbors.\n\nTampilkan juga decision tree yang terbentuk.\nAnda bebas memilih hyperparameter seperti kernel untuk SVM, nilai \\(k\\) untuk k-nearest neighbors, ataupun yang lainnya.\nEvaluasi model regresi: untuk model-model klasifikasi yang telah Anda buat, tampilkan/hitunglah metrik evaluasi untuk klasifikasi, misalnya menampilkan confusion matrix atau menghitung Jaccard score. Di antara keempat model tersebut, dengan hyperparameter yang Anda pilih, model mana yang terbaik?"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/tugas2.html#petunjuk-umum",
    "href": "semuahalaman/modulprak/2024/genap/saindat/tugas2.html#petunjuk-umum",
    "title": "Tugas 2 Praktikum Sains Data 2024 Genap: Perbandingan Metode Klasifikasi",
    "section": "",
    "text": "Kerjakan secara individu.\nKerjakan tugas ini menggunakan bahasa pemrograman Python dengan file format berupa interactive Python notebook (yaitu file berbentuk .ipynb BUKAN .py), yang bisa dibuat misalnya menggunakan Jupyter Notebook atau Google Colaboratory.\nHarap sertakan penjelasan untuk setiap proses secara singkat di samping potongan kode (bisa dengan teks / text box maupun dengan comment, ‘#’).\nFormat nama file untuk Tugas 2 adalah:\nNama Lengkap_NPM_Kelas SIAK_Tugas2PrakSaindat.ipynb\nContoh penamaan yang benar:\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas2PrakSaindat.ipynb\nUntuk mengumpulkan lebih dari satu file, gunakan .zip dengan format nama yang sama (dan file .ipynb yang di dalamnya juga masih menggunakan format nama yang sama).\nApabila ada yang ingin direvisi setelah pengumpulan, lakukan pengumpulan ulang di Google Forms yang sama, tambahkan keterangan bahwa ada revisi, dan tambahkan kata “revisi” pada bagian akhir nama file, contohnya menjadi\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas2PrakSaindat_revisi.ipynb\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas2PrakSaindat_revisi2.ipynb\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas2PrakSaindat_revisi3.ipynb\n(tentunya gunakan .zip kalau ada lebih dari satu file yang ingin dikumpulkan)\n(Revisi boleh dilakukan berkali-kali selama masa pengerjaan.)\nPengumpulan tugas dilakukan ke Google Forms berikut ini, sesuai dengan kelas Anda di SIAK NG (link akan selalu sama untuk semua tugas praktikum Sains Data):\n\nKelas A: https://forms.gle/TdxprAuySMAWt5NR7\nKelas B: https://forms.gle/bk2LBnowfZhmw5qY9\n\nDengan durasi pengerjaan sekitar 2 (dua) minggu, tenggat waktu (deadline) pengumpulan Tugas 2 ini (termasuk revisi) adalah:\nJumat, 24 Mei 2024, pukul 23.59 WIB.\nMohon manfaatkan waktu Anda dengan baik (seperti mencicil pengerjaan, bahkan sudah selesai dari jauh-jauh hari) agar mengumpulkan tugas sebelum deadline. Keterlambatan pengumpulan bisa dikenakan pengurangan nilai atau bahkan dianggap tidak mengumpulkan, tergantung kesepakatan dari dosen. Meskipun demikian, lebih baik terlambat mengumpulkan daripada tidak mengumpulkan sama sekali.\nSesuai standar Universitas Indonesia, plagiarisme dilarang keras dan bisa menyebabkan nilai tugas praktikum menjadi nol untuk semua pihak yang terlibat, tanpa peringatan apapun. Namun, Anda boleh memanfaatkan kode apapun yang ada di modul praktikum.\nNarahubung untuk Tugas 2 Praktikum Sains Data adalah:\n\nRifki - LINE: rifkyprakasya_\nBisma - LINE: bisma_joyosumarto"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/tugas2.html#soal",
    "href": "semuahalaman/modulprak/2024/genap/saindat/tugas2.html#soal",
    "title": "Tugas 2 Praktikum Sains Data 2024 Genap: Perbandingan Metode Klasifikasi",
    "section": "",
    "text": "Tugas 2 ini terdiri dari soal a-e.\nAda dataset water_potability.csv yang mendata kualitas air di ribuan tempat (satu baris per tempat) dan menentukan apakah air tersebut layak diminum (potable), dengan nilai 1 (satu) jika layak dan nilai 0 (nol) jika tidak layak. Dataset ini bisa di-download dari salah satu sumber berikut:\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle: https://www.kaggle.com/datasets/adityakadiwal/water-potability\n\nDi dataset ini, fitur target yang ingin diprediksi adalah kelayakan air (Potability). Perhatikan, fitur ini bersifat biner, sehingga metode machine learning yang cocok untuk prediksi adalah metode klasifikasi.\nMetode-metode klasifikasi (selain neural network) yang sudah kita pelajari selama praktikum adalah\n\nregresi logistik (khusus klasifikasi biner);\ndecision tree;\nSVM (khusus klasifikasi biner); dan\nk-nearest neighbors.\n\nMenggunakan keempat metode di atas, lakukan end-to-end machine learning, atau lebih tepatnya end-to-end classification, yang meliputi:\n\nLangkah preprocessing yang sekiranya diperlukan\nEDA\nLakukan train-test-split (rasionya bebas, misal 80:20). Jangan lupa gunakan suatu random_state.\nTraining: menggunakan scikit-learn (sklearn), untuk menyelesaikan masalah klasifikasi di atas, buatlah model\n\nregresi logistik;\ndecision tree;\nSVM; dan\nk-nearest neighbors.\n\nTampilkan juga decision tree yang terbentuk.\nAnda bebas memilih hyperparameter seperti kernel untuk SVM, nilai \\(k\\) untuk k-nearest neighbors, ataupun yang lainnya.\nEvaluasi model regresi: untuk model-model klasifikasi yang telah Anda buat, tampilkan/hitunglah metrik evaluasi untuk klasifikasi, misalnya menampilkan confusion matrix atau menghitung Jaccard score. Di antara keempat model tersebut, dengan hyperparameter yang Anda pilih, model mana yang terbaik?"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/tugas1.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/tugas1.html",
    "title": "Tugas 1 Praktikum Sains Data 2024 Genap: Regresi dan Clustering",
    "section": "",
    "text": "Kembali ke Sains Data\n\n\n\nKerjakan secara individu.\nKerjakan tugas ini menggunakan bahasa pemrograman Python dengan file format berupa interactive Python notebook (yaitu file berbentuk .ipynb BUKAN .py), yang bisa dibuat misalnya menggunakan Jupyter Notebook atau Google Colaboratory.\nHarap sertakan penjelasan untuk setiap proses secara singkat di samping potongan kode (bisa dengan teks / text box maupun dengan comment, ‘#’).\nFormat nama file untuk Tugas 1 adalah:\nNama Lengkap_NPM_Kelas SIAK_Tugas1PrakSaindat.ipynb\nContoh penamaan yang benar:\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas1PrakSaindat.ipynb\nUntuk mengumpulkan lebih dari satu file, gunakan .zip dengan format nama yang sama (dan file .ipynb yang di dalamnya juga masih menggunakan format nama yang sama).\nApabila ada yang ingin direvisi setelah pengumpulan, lakukan pengumpulan ulang di Google Forms yang sama, tambahkan keterangan bahwa ada revisi, dan tambahkan kata “revisi” pada bagian akhir nama file, contohnya menjadi\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas1PrakSaindat_revisi.ipynb (atau .zip)\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas1PrakSaindat_revisi2.ipynb\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas1PrakSaindat_revisi3.ipynb\n(tentunya gunakan .zip kalau ada lebih dari satu file yang ingin dikumpulkan)\n(Revisi boleh dilakukan berkali-kali selama masa pengerjaan.)\nPengumpulan tugas dilakukan ke Google Forms berikut ini, sesuai dengan kelas Anda di SIAK NG (link akan selalu sama untuk semua tugas praktikum Sains Data):\n\nKelas A: https://forms.gle/TdxprAuySMAWt5NR7\nKelas B: https://forms.gle/bk2LBnowfZhmw5qY9\n\nDengan durasi pengerjaan sekitar 2 (dua) minggu, tenggat waktu (deadline) pengumpulan Tugas 1 ini (termasuk revisi) adalah:\nJumat, 24 Mei 2024, pukul 23.59 WIB.\nMohon manfaatkan waktu Anda dengan baik (seperti mencicil pengerjaan, bahkan sudah selesai dari jauh-jauh hari) agar mengumpulkan tugas sebelum deadline. Keterlambatan pengumpulan bisa dikenakan pengurangan nilai atau bahkan dianggap tidak mengumpulkan, tergantung kesepakatan dari dosen. Meskipun demikian, lebih baik terlambat mengumpulkan daripada tidak mengumpulkan sama sekali.\nSesuai standar Universitas Indonesia, plagiarisme dilarang keras dan bisa menyebabkan nilai tugas praktikum menjadi nol untuk semua pihak yang terlibat, tanpa peringatan apapun. Namun, Anda boleh memanfaatkan kode apapun yang ada di modul praktikum.\nNarahubung untuk Tugas 1 Praktikum Sains Data adalah:\n\nRifki - LINE: rifkyprakasya_\nBisma - LINE: bisma_joyosumarto\n\n\n\n\n\nTugas 1 ini terdiri dari soal a-j.\nAda dataset penjualan mobil, Car_sales.csv, yang bisa di-download dari salah satu sumber berikut:\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle: https://www.kaggle.com/datasets/gagandeep16/car-sales\n\nDi dataset ini, fitur target yang ingin diprediksi adalah harga (Price_in_thousands). Perhatikan, fitur ini berupa harga, sehingga metode machine learning yang cocok untuk prediksi adalah metode regresi.\nLakukan end-to-end machine learning, atau lebih tepatnya end-to-end regression, yang meliputi:\n\nLangkah preprocessing yang sekiranya diperlukan: bisa meliputi seleksi fitur, imputasi, encoding, standarisasi, normalisasi, dsb. Berikan juga keterangan/penjelasan, mengapa Anda melakukan langkah preprocessing tersebut.\nEDA: cobalah menduga, kira-kira fitur/kolom/variabel apa saja yang memiliki hubungan yang erat atau menarik? Lakukan eksplorasi dengan membuat visualisasi dari fitur-fitur tersebut. Anda bebas membuat plot apa saja yang sekiranya cocok.\nLalu, tuliskan penjelasan atau interpretasi Anda untuk tiap hasil visualisasi (misalnya dugaan Anda benar/salah, atau Anda memperoleh informasi/insight baru dari visualisasi tersebut).\nLakukan train-test-split (rasionya bebas, misal 80:20). Jangan lupa gunakan suatu random_state.\nTraining: menggunakan scikit-learn (sklearn), buatlah suatu model regresi linier sederhana dan suatu model regresi linier berganda. Kemudian, tampilkan (boleh secara pemrograman maupun manual) koefisien-koefisien yang diperoleh dalam bentuk rumus umum regresi, yaitu (masukkan nilai-nilai \\(\\beta\\) yang sesuai):\n\n\\[y = \\beta_0 + \\beta_1 x\\]\n(untuk regresi linier sederhana), dan\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots\\]\n(untuk regresi linier berganda)\n\nEvaluasi model regresi: untuk model-model regresi yang telah Anda buat, (menggunakan scikit-learn) hitunglah metrik evaluasi untuk regresi, seperti MSE (mean squared error) atau \\(R^2\\). Berikan kesimpulan, apakah model regresi yang telah Anda buat sudah cukup baik.\n\nKemudian, siapa tahu, dataset yang sedang digunakan terdiri dari sejumlah cluster. Untuk mencari tahu, lakukan end-to-end clustering, yang meliputi (tahap preprocessing dan EDA dilewatkan karena sudah dilakukan di atas):\n\nPilih suatu bilangan bulat positif \\(k\\), lalu buatlah model k-means clustering (menggunakan scikit-learn) dengan banyaknya cluster sesuai nilai \\(k\\) yang Anda pilih.\nEvaluasi model clustering: untuk model k-means clustering tersebut, tampilkan metrik evaluasi untuk clustering, misalnya SSE.\nHyperparameter tuning: gunakan grid search untuk mencoba beberapa nilai \\(k\\) untuk k-means clustering dan memperoleh nilai \\(k\\) yang terbaik. Alternatif lain, Anda diperbolehkan untuk melakukan hyperparameter tuning dengan cara looping untuk mencoba beberapa nilai \\(k\\).\nPerolehlah data cluster untuk tiap titik (tiap baris) dari model k-means clustering dengan nilai \\(k\\) terbaik tersebut.\nSimpan hasil prediksi cluster untuk tiap baris sebagai fitur/kolom baru (misal beranma cluster) dalam pandas DataFrame, lalu simpan DataFrame tersebut sebagai CSV bernama tugas1_clusters.csv"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/tugas1.html#petunjuk-umum",
    "href": "semuahalaman/modulprak/2024/genap/saindat/tugas1.html#petunjuk-umum",
    "title": "Tugas 1 Praktikum Sains Data 2024 Genap: Regresi dan Clustering",
    "section": "",
    "text": "Kerjakan secara individu.\nKerjakan tugas ini menggunakan bahasa pemrograman Python dengan file format berupa interactive Python notebook (yaitu file berbentuk .ipynb BUKAN .py), yang bisa dibuat misalnya menggunakan Jupyter Notebook atau Google Colaboratory.\nHarap sertakan penjelasan untuk setiap proses secara singkat di samping potongan kode (bisa dengan teks / text box maupun dengan comment, ‘#’).\nFormat nama file untuk Tugas 1 adalah:\nNama Lengkap_NPM_Kelas SIAK_Tugas1PrakSaindat.ipynb\nContoh penamaan yang benar:\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas1PrakSaindat.ipynb\nUntuk mengumpulkan lebih dari satu file, gunakan .zip dengan format nama yang sama (dan file .ipynb yang di dalamnya juga masih menggunakan format nama yang sama).\nApabila ada yang ingin direvisi setelah pengumpulan, lakukan pengumpulan ulang di Google Forms yang sama, tambahkan keterangan bahwa ada revisi, dan tambahkan kata “revisi” pada bagian akhir nama file, contohnya menjadi\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas1PrakSaindat_revisi.ipynb (atau .zip)\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas1PrakSaindat_revisi2.ipynb\nJohann Carl Friedrich Gauss_2201234567_Kelas C_Tugas1PrakSaindat_revisi3.ipynb\n(tentunya gunakan .zip kalau ada lebih dari satu file yang ingin dikumpulkan)\n(Revisi boleh dilakukan berkali-kali selama masa pengerjaan.)\nPengumpulan tugas dilakukan ke Google Forms berikut ini, sesuai dengan kelas Anda di SIAK NG (link akan selalu sama untuk semua tugas praktikum Sains Data):\n\nKelas A: https://forms.gle/TdxprAuySMAWt5NR7\nKelas B: https://forms.gle/bk2LBnowfZhmw5qY9\n\nDengan durasi pengerjaan sekitar 2 (dua) minggu, tenggat waktu (deadline) pengumpulan Tugas 1 ini (termasuk revisi) adalah:\nJumat, 24 Mei 2024, pukul 23.59 WIB.\nMohon manfaatkan waktu Anda dengan baik (seperti mencicil pengerjaan, bahkan sudah selesai dari jauh-jauh hari) agar mengumpulkan tugas sebelum deadline. Keterlambatan pengumpulan bisa dikenakan pengurangan nilai atau bahkan dianggap tidak mengumpulkan, tergantung kesepakatan dari dosen. Meskipun demikian, lebih baik terlambat mengumpulkan daripada tidak mengumpulkan sama sekali.\nSesuai standar Universitas Indonesia, plagiarisme dilarang keras dan bisa menyebabkan nilai tugas praktikum menjadi nol untuk semua pihak yang terlibat, tanpa peringatan apapun. Namun, Anda boleh memanfaatkan kode apapun yang ada di modul praktikum.\nNarahubung untuk Tugas 1 Praktikum Sains Data adalah:\n\nRifki - LINE: rifkyprakasya_\nBisma - LINE: bisma_joyosumarto"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/tugas1.html#soal",
    "href": "semuahalaman/modulprak/2024/genap/saindat/tugas1.html#soal",
    "title": "Tugas 1 Praktikum Sains Data 2024 Genap: Regresi dan Clustering",
    "section": "",
    "text": "Tugas 1 ini terdiri dari soal a-j.\nAda dataset penjualan mobil, Car_sales.csv, yang bisa di-download dari salah satu sumber berikut:\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle: https://www.kaggle.com/datasets/gagandeep16/car-sales\n\nDi dataset ini, fitur target yang ingin diprediksi adalah harga (Price_in_thousands). Perhatikan, fitur ini berupa harga, sehingga metode machine learning yang cocok untuk prediksi adalah metode regresi.\nLakukan end-to-end machine learning, atau lebih tepatnya end-to-end regression, yang meliputi:\n\nLangkah preprocessing yang sekiranya diperlukan: bisa meliputi seleksi fitur, imputasi, encoding, standarisasi, normalisasi, dsb. Berikan juga keterangan/penjelasan, mengapa Anda melakukan langkah preprocessing tersebut.\nEDA: cobalah menduga, kira-kira fitur/kolom/variabel apa saja yang memiliki hubungan yang erat atau menarik? Lakukan eksplorasi dengan membuat visualisasi dari fitur-fitur tersebut. Anda bebas membuat plot apa saja yang sekiranya cocok.\nLalu, tuliskan penjelasan atau interpretasi Anda untuk tiap hasil visualisasi (misalnya dugaan Anda benar/salah, atau Anda memperoleh informasi/insight baru dari visualisasi tersebut).\nLakukan train-test-split (rasionya bebas, misal 80:20). Jangan lupa gunakan suatu random_state.\nTraining: menggunakan scikit-learn (sklearn), buatlah suatu model regresi linier sederhana dan suatu model regresi linier berganda. Kemudian, tampilkan (boleh secara pemrograman maupun manual) koefisien-koefisien yang diperoleh dalam bentuk rumus umum regresi, yaitu (masukkan nilai-nilai \\(\\beta\\) yang sesuai):\n\n\\[y = \\beta_0 + \\beta_1 x\\]\n(untuk regresi linier sederhana), dan\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots\\]\n(untuk regresi linier berganda)\n\nEvaluasi model regresi: untuk model-model regresi yang telah Anda buat, (menggunakan scikit-learn) hitunglah metrik evaluasi untuk regresi, seperti MSE (mean squared error) atau \\(R^2\\). Berikan kesimpulan, apakah model regresi yang telah Anda buat sudah cukup baik.\n\nKemudian, siapa tahu, dataset yang sedang digunakan terdiri dari sejumlah cluster. Untuk mencari tahu, lakukan end-to-end clustering, yang meliputi (tahap preprocessing dan EDA dilewatkan karena sudah dilakukan di atas):\n\nPilih suatu bilangan bulat positif \\(k\\), lalu buatlah model k-means clustering (menggunakan scikit-learn) dengan banyaknya cluster sesuai nilai \\(k\\) yang Anda pilih.\nEvaluasi model clustering: untuk model k-means clustering tersebut, tampilkan metrik evaluasi untuk clustering, misalnya SSE.\nHyperparameter tuning: gunakan grid search untuk mencoba beberapa nilai \\(k\\) untuk k-means clustering dan memperoleh nilai \\(k\\) yang terbaik. Alternatif lain, Anda diperbolehkan untuk melakukan hyperparameter tuning dengan cara looping untuk mencoba beberapa nilai \\(k\\).\nPerolehlah data cluster untuk tiap titik (tiap baris) dari model k-means clustering dengan nilai \\(k\\) terbaik tersebut.\nSimpan hasil prediksi cluster untuk tiap baris sebagai fitur/kolom baru (misal beranma cluster) dalam pandas DataFrame, lalu simpan DataFrame tersebut sebagai CSV bernama tugas1_clusters.csv"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul7.html#pengantar-komposisi-invers",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul7.html#pengantar-komposisi-invers",
    "title": "Modul 7 Kalkulin 2024 Genap: Transformasi Linier Umum",
    "section": "Pengantar, Komposisi, Invers",
    "text": "Pengantar, Komposisi, Invers"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul7.html#bentuk-matriks-similaritas",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul7.html#bentuk-matriks-similaritas",
    "title": "Modul 7 Kalkulin 2024 Genap: Transformasi Linier Umum",
    "section": "Bentuk Matriks, Similaritas",
    "text": "Bentuk Matriks, Similaritas"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul7.html#rank-dan-nullitas",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul7.html#rank-dan-nullitas",
    "title": "Modul 7 Kalkulin 2024 Genap: Transformasi Linier Umum",
    "section": "Rank dan Nullitas",
    "text": "Rank dan Nullitas\nMisalkan ada matriks berikut.\n\nA = {{1, 2, 3}, {2, 4, 6}}\n\n{{1, 2, 3}, {2, 4, 6}}\n\n\n\nA // MatrixForm\n\n\n\n\n(Perhatikan bahwa kedua baris di matriks A bergantung linier.)\nMatriks ini berukuran 2 x 3:\n\nDimensions[A]\n\n{2, 3}\n\n\nSehingga banyaknya kolom adalah elemen kedua dari dimensi:\n\nDimensions[A][[2]]\n\n3\n\n\nBerdasarkan Rank-Nullity Theorem,\n\\[\\text{Rank}(A) + \\text{Nullity}(A) = \\text{dimensi prapeta/domain; banyaknya kolom di matriks A}\\]\n\nMenentukan Rank dan Nullitas secara “manual”\nBentuk eselon baris tereduksi dari A adalah sebagai berikut.\n\nRowReduce[A] // MatrixForm\n\n\n\n\nSecara definisi, rank adalah dimensi dari ruang kolom (yang ternyata sama dengan dimensi dari ruang baris, berdasarkan teorema). Dari bentuk eselon baris tereduksi, kita bisa menghitung rank sebagai banyaknya leading ones (satu utama), yaitu hanya ada satu.\n\\[\\text{Rank}(A) = 1\\]\nSecara definisi, nullity adalah dimensi dari ruang null, yaitu ruang solusi dari \\(A\\textbf{x} = \\textbf{0}\\). Sehingga, kita bisa menentukan solusi (nontrivial) dari \\(A\\textbf{x} = \\textbf{0}\\) terlebih dahulu:\n\nReduce[\n    A.{x1,x2,x3} == {0,0},\n    {x1,x2,x3}\n]\n\n\n\n\nSolusinya melibatkan dua variabel bebas yaitu \\(x_1\\) dan \\(x_2\\), sehingga ruang null berdimensi dua. Maka, nullity atau nullitas dari \\(A\\) adalah 2 (dua).\n\\[\\text{Nullity}(A) = 2\\]\nHasil yang kita temukan sesuai dengan Rank-Nullity Theorem:\n\n1 + 2 == Dimensions[A][[2]]\n\n\n\n\n\n\nMenentukan Rank dan Nullitas secara otomatis\nUntuk menentukan rank suatu matriks, gunakan MatrixRank\n\nMatrixRank[A]\n\n1\n\n\nUntuk menentukan nullity, kita bisa memanfaatkan Rank-Nullity Theorem:\n\\[\\text{Nullity}(A) = \\text{(banyaknya kolom di matriks A)} - \\text{Rank}(A)\\]\n\nDimensions[A][[2]] - MatrixRank[A]\n\n2\n\n\nCara lain, ada ResourceFunction bernama Nullity yang bisa kita download dari Wolfram Function Repository (https://reference.wolfram.com/language/guide/WolframFunctionRepository.html) seperti berikut:\n\nNullity = ResourceFunction[\"Nullity\"]\n\n\n\n\n(Sayangnya, apabila versi Wolfram Mathematica yang sedang digunakan terlalu kuno, akan muncul error. Apabila error, alternatif untuk mencoba hal ini adalah menggunakan Wolfram Cloud.\n\nNullity[A]\n\n2\n\n\nKita bisa lihat dengan jelas bahwa Rank-Nullity Theorem berlaku untuk matriks A ini:\n\nMatrixRank[A] + Nullity[A] == Dimensions[A][[2]]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul7.html#pdp-eliptik-dengan-metode-gauss-seidel",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul7.html#pdp-eliptik-dengan-metode-gauss-seidel",
    "title": "Modul 7 Persamaan Diferensial Numerik: Nonlinear Finite Difference, PDP Eliptik & Hiperbolik",
    "section": "PDP Eliptik dengan metode Gauss-Seidel",
    "text": "PDP Eliptik dengan metode Gauss-Seidel\n\nBentuk umum, ide utama, penyederhanaan\n\n\nFunction file\n\nfunction [x, y, w] = metode_eliptik_iteratif(lb, rb, ub, db, f, xb, xu, yb, yu, h, k, iterasi)\n  dx = h;\n  dy = k;\n  x = xb : dx : xu;\n  y = yb : dy : yu;\n  n_1 = length(x);\n  m_1 = length(y);\n  \n  % susun matriks solusi\n  w = zeros(n_1, m_1);\n  % mengisi syarat batas\n  for i = 1 : n_1\n    w(i, 1) = db(x(i), yb);\n    w(i, m_1) = ub(x(i), yu);\n  endfor\n  for j = 2 : m_1\n    w(1, j) = lb(xb, y(j));\n    w(n_1, j) = rb(xu, y(j));\n  endfor\n  \n  for iter = 1 : iterasi\n    for i = 2 : n_1 - 1\n      for j = 2 : m_1 - 1\n        w(i, j) = w(i+1, j) + w(i-1, j) + (h/k)^2 * (w(i, j+1) + w(i, j-1));\n        w(i, j) += - h^2 * f(x(i), y(j));\n        w(i, j) /= 2 * ((h/k)^2 + 1);\n      endfor\n    endfor\n  endfor\nendfunction\n\n\n\nContoh soal\n\ndb = @(x,y) 0;\nub = @(x,y) 200*x;\nlb = @(x,y) 0;\nrb = @(x,y) 200*y;\nf = @(x,y) 0;\nxb = 0;\nxu = 0.5;\nyb = 0;\nyu = 0.5;\ndx = 0.1;\ndy = 0.1;\niterasi = 50;\n\n[x, y, w] = metode_eliptik_iteratif(db, ub, lb, rb, f, xb, xu, yb, yu, dx, dy, iterasi);\n\nmesh(x, y, w');"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul7.html#pdp-hiperbolik-persamaan-gelombang",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul7.html#pdp-hiperbolik-persamaan-gelombang",
    "title": "Modul 7 Persamaan Diferensial Numerik: Nonlinear Finite Difference, PDP Eliptik & Hiperbolik",
    "section": "PDP Hiperbolik / Persamaan Gelombang",
    "text": "PDP Hiperbolik / Persamaan Gelombang\n\nBentuk umum persamaan gelombang\nDi mata kuliah Persamaan Diferensial Numerik, PDP orde 2 hiperbolik yang dibahas adalah persamaan gelombang.\nBentuk umum dari persamaan gelombang bisa ditulis\n\\[\\frac{\\partial^2 u}{\\partial t^2}\\left(x,t\\right) - \\alpha^2 \\frac{\\partial^2 u}{\\partial  x^2}\\left(x,t\\right) = 0, \\quad 0 &lt; x &lt; l, \\quad 0 &lt; t &lt; T\\]\n\\[u\\left(x,0\\right) = f\\left(x\\right), \\quad \\frac{\\partial u}{\\partial t}\\left(x,0\\right) = g\\left(x\\right), \\quad 0 &lt; x &lt; l\\]\n\\[u\\left(0,t\\right) = u\\left(l,t\\right) = 0, \\quad t &gt; 0\\]\nPerhatikan bahwa ada nilai \\(\\alpha^2\\) yang pasti positif, ada nilai awal, kecepatan awal, serta syarat batas kiri dan kanan. (PDP ini dalam variabel \\(x, t\\).)\nUntuk kebutuhan praktikum, kita bisa menuliskan bentuk umum persamaan gelombang seperti berikut:\n\\[\\frac{\\partial^2 u}{\\partial t^2}\\left(x,t\\right) - \\alpha^2 \\frac{\\partial^2 u}{\\partial  x^2}\\left(x,t\\right) = 0, \\quad \\text{xb} &lt; x &lt; \\text{xu}, \\quad \\text{tb} &lt; t &lt; \\text{tu}\\]\n\\[u\\left(x,0\\right) = f\\left(x\\right), \\quad \\frac{\\partial u}{\\partial t}\\left(x,0\\right) = g\\left(x\\right), \\quad \\text{xb} &lt; x &lt; \\text{xu}\\]\n\\[u\\left(0,t\\right) = \\text{lb}\\left(t\\right), \\quad \\text{tb} &lt; t \\le \\text{tu}\\]\n\\[u\\left(l,t\\right) = \\text{rb}\\left(t\\right), \\quad \\text{tb} &lt; t \\le \\text{tu}\\]\n\n\nIde utama\nUntuk persamaan gelombang, hanya ada satu metode, dengan nilai lambda sebagai berikut:\n\\[\\lambda = \\frac{\\alpha k}{h}\\]\nNote: nilai \\(\\alpha\\) dipilih yang positif.\nAda dua rumus yang terlibat dalam metode ini, yaitu rumus untuk \\(j=2\\) (setelah nilai awal di \\(j=1\\)) dan rumus untuk \\(j=3,\\dots,N+1\\).\nLangkah-langkah metode untuk persamaan gelombang bisa dituliskan sebagai berikut:\n\nMisalkan\n\\[\\lambda = \\frac{\\alpha k}{h} \\quad \\text{yaitu} \\quad \\lambda^2 = \\frac{\\alpha^2 k^2}{h^2}\\]\ndengan \\(\\alpha = \\sqrt{\\alpha^2} &gt; 0\\).\nSiapkan matriks grid \\(w\\) berukuran \\((m+1) \\times (N+1)\\) untuk menyimpan \\(w_{i,j}\\).\nIsi semua dengan nol dulu, atau setidaknya, pastikan baris pertama dan baris terakhir terisi nol semua (sesuai syarat batas).\nIsi waktu pertama (\\(j=1\\)) berdasarkan nilai awal, yaitu\n\\[w_{i,1} = f(x_i)\\]\natau bisa ditulis\n\\[\\textbf{w}^{(1)} = (f(x_2), f(x_3), \\dots, f(x_m))\\]\nIsi waktu kedua (\\(j=2\\)) dengan rumus berikut untuk \\(i=2,\\dots,m+1\\)\n\\[w_{i,2} = \\left(1-\\lambda^2\\right)f\\left(x_i\\right) + \\frac{\\lambda^2}{2}f\\left(x_{i+1}\\right) + \\frac{\\lambda^2}{2}f\\left(x_{i-1}\\right) + kg\\left(x_i\\right)\\]\nSusun matriks tridiagonal \\(A\\) berukuran \\((m-1) \\times (m-1)\\) dengan\n\nnilai \\(2\\left(1-\\lambda^2\\right)\\) di diagonal\nnilai \\(\\lambda^2\\) di sebelah kiri dan kanan diagonal\nnol di semua entri lainnya\n\nIsi tiap waktu berikutnya (\\(j=3,\\dots,N+1\\)) dengan rumus berikut untuk \\(i=2,\\dots,m\\)\n\\[w^{(j)} = Aw^{(j-1)} - w^{(j-2)}\\]\n\n\n\nFunction file\n\nFunction file hiperbolik_matriks.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x, t, w] = hiperbolik_matriks(alph2, f, g, lb, rb, xb, xu, tb, tu, h, k)\n  x = xb : h : xu;\n  t = tb : k : tu;\n  m_plus_1 = length(x);\n  N_plus_1 = length(t);\n  w = zeros(m_plus_1, N_plus_1);\n\n  % alph = sqrt(alph2);\n  % lambd = alph * k / h;\n  % lambd2 = lambd^2;\n  lambd2 = (alph2 * k^2) / (h^2);\n\n  % memasang nilai awal (j=1)\n  for i = 1 : m_plus_1\n    w(i, 1) = f(x(i));\n  endfor\n\n  % memasang syarat batas\n  for j = 2 : N_plus_1\n    w(1, j)         = lb(t(j));\n    w(m_plus_1, j)  = rb(t(j));\n  endfor\n\n  % isi nilai di j=2 kecuali syarat batas\n  for i = 2 : (m_plus_1 - 1)\n    % jumlahkan secara bertahap\n    w(i, 2) = (1 - lambd2) * f((x(i)));\n    w(i, 2) += (lambd2 / 2) * (f(x(i+1)) + f(x(i-1)));\n    w(i, 2) += k * g(x(i));\n  endfor\n\n  % susun matriks A\n  A = zeros(m_plus_1 - 2, m_plus_1 - 2);\n  for i = 1 : (m_plus_1 - 2)\n    % isi sebelah kiri/bawah diagonal\n    if (i &gt; 1)\n      A(i, i-1) = lambd2;\n    endif\n\n    % isi diagonal\n    A(i, i) = 2 * (1 - lambd2);\n\n    % isi sebelah kanan/atas diagonal\n    if (i &lt; m_plus_1 - 2)\n      A(i, i+1) = lambd2;\n    endif\n  endfor\n\n  % isi nilai di sisanya yaitu j=3, ..., N+1\n  for j = 3 : N_plus_1\n    % pengurangan secara bertahap\n    w(2 : m_plus_1 - 1, j) = A * w(2 : m_plus_1 - 1, j-1);\n    w(2 : m_plus_1 - 1, j) -= w(2 : m_plus_1 - 1, j-2);\n  endfor\nendfunction\n\n\n\n\n\n\nContoh 1\nSelesaikan persamaan gelombang berikut,\n\\[\\frac{\\partial^2 u}{\\partial t^2} - \\frac{\\partial^2 u}{\\partial x^2} = 0, \\quad 0 &lt; x &lt; 1, \\quad 0 &lt; t &lt; T,\\]\ndengan nilai awal dan kecepatan awal\n\\[u(x,0) = \\sin{\\pi x}, \\quad \\frac{\\partial u}{\\partial t}(x,0) = 0, \\quad 0 \\le x \\le 1\\]\nserta syarat batas\n\\[u(0,t) = u(1,t) = 0, \\quad 0 &lt; t,\\]\ndengan \\(m=4\\), \\(N=4\\), dan \\(T=1\\).\nLalu, bandingkan hasilnya dengan solusi eksak\n\\[u(x,t) = \\cos{\\left(\\pi t\\right)} \\sin{\\left(\\pi x\\right)}\\]\n\nScript file coba1_hiperbolik_matriks.m - nama file bebas\n\n\n\nalph2 = 1;\nf = @(x) sin(pi * x);\ng = @(x) 0;\nlb = @(t) 0;\nrb = @(t) 0;\nxb = 0;\nxu = 1;\ntb = 0;\ntu = 1; % T\nm = 4;\nN = 4;\nh = (xu - xb)/m;\nk = (tu - tb)/N;\n\n[x_arr, t_arr, w] = hiperbolik_matriks(alph2, f, g, lb, rb, xb, xu, tb, tu, h, k);\n\n% solusi eksak\nsln = @(x,t) cos(pi * t) .* sin(pi * x);\n[x_grid, t_grid] = meshgrid(x_arr, t_arr);\nu = sln(x_grid, t_grid);\n\n% menampilkan nilai aproksimasi dalam bentuk seperi grid\ndisp(\"Grid nilai aproksimasi:\");\ndisp(flipud(w'));\n\n% menampilkan grid solusi eksak\ndisp(\"Grid solusi eksak:\");\ndisp(flipud(u));\n\n% perhitungan error\nerr_grid = abs(w' - u); % absolute error\nerr_total = sum(sum(err_grid)); % norm L1 (taxicab/Manhattan)\ndisp(\"Grid nilai error:\");\ndisp(flipud(err_grid));\ndisp(\"Error total (norm L1):\");\ndisp(err_total);\n\n% gambar mesh hasil aproksimasi\nfigure 1;\nmesh(x_arr, t_arr, w');\ntitle(\"Hasil aproksimasi\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"u\");\n\n% gambar mesh solusi eksak\nfigure 2;\nmesh(x_arr, t_arr, u);\ntitle(\"Solusi eksak\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"u\");\n\nGrid nilai aproksimasi:\n        0  -0.7071  -1.0000  -0.7071        0\n        0  -0.5000  -0.7071  -0.5000        0\n        0        0        0  -0.0000        0\n        0   0.5000   0.7071   0.5000        0\n        0   0.7071   1.0000   0.7071   0.0000\nGrid solusi eksak:\n        0  -0.7071  -1.0000  -0.7071  -0.0000\n        0  -0.5000  -0.7071  -0.5000  -0.0000\n        0   0.0000   0.0000   0.0000   0.0000\n        0   0.5000   0.7071   0.5000   0.0000\n        0   0.7071   1.0000   0.7071   0.0000\nGrid nilai error:\n            0   1.1102e-16            0   1.1102e-16   1.2246e-16\n            0   1.1102e-16   1.1102e-16   1.1102e-16   8.6596e-17\n            0   4.3298e-17   6.1232e-17   1.5432e-16   7.4988e-33\n            0            0   1.1102e-16            0   8.6596e-17\n            0            0            0            0            0\nError total (norm L1):\n1.2206e-15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContoh 2\nAkan kita uji menggunakan persamaan gelombang:\n\\[\\begin{align*}\n    u_{tt} - (0.25)^2 u_{xx} &= 0, \\quad 0 &lt; x &lt; 1, \\quad 0 &lt; t &lt; 1, \\\\\n    u(0,t) = u(1,t) &= 0, \\quad 0 &lt; t \\le 1, \\\\\n    u(x,0) &= 0, \\quad 0 \\le x \\le 1 \\\\\n    u_t(x,0) &= x(1-x), \\quad 0 \\le x \\le 1\n\\end{align*}\\]\nSolusi eksak dari PDP tersebut adalah\n\\[u(x,t) = \\sum_{n=1}^{\\infty} c_n \\sin{\\left(0.25n\\pi t\\right)} \\sin{\\left(n\\pi x\\right)}\\]\n\\[c_n = \\frac{2}{0.25n\\pi} \\int_0^1 x(1-x) \\sin{\\left(n\\pi x\\right)} dx, \\quad n = 1, 2, \\dots\\]\nUntuk keperluan komputasi, akan kita ambil 10 suku pertama dari ekspansi deret Fourier dari \\(u(x,t)\\).\nGunakan \\(h = \\Delta x = 0.125\\) dan \\(k = \\Delta t = 0.05\\).\n\nScript file coba2_hiperbolik_matriks.m - nama file bebas\n\n\n\nalph2 = 0.25^2;\nf = @(x) 0;\ng = @(x) x .* (1-x);\nlb = @(t) 0;\nrb = @(t) 0;\nxb = 0;\nxu = 1;\ntb = 0;\ntu = 1;\nh = 0.125;\nk = 0.05;\n\n[x_arr, t_arr, w] = hiperbolik_matriks(alph2, f, g, lb, rb, xb, xu, tb, tu, h, k);\n\n% solusi eksak dari deret\nu = zeros(length(x), length(t));\nfor i = 1 : length(x)\n  for j = 1 : length(t)\n    % penjumlahan deret secara bertahap\n    u(i,j) = 0;\n    for n = 1 : 10\n      F = @(x) x .* (1-x) .* sin(n * pi .* x);\n      cn = 2/(0.25*n*pi) * integral(F, 0, 1);\n      u(i,j) += cn * sin(0.25 * n * pi * t(j)) * sin(n * pi * x(i));\n    endfor\n  endfor\nendfor\n\n% menampilkan nilai aproksimasi dalam bentuk seperi grid\ndisp(\"Grid nilai aproksimasi:\");\ndisp(flipud(w'));\n\n% menampilkan grid solusi eksak\ndisp(\"Grid solusi eksak:\");\ndisp(flipud(u'));\n\n% perhitungan error\nerr_grid = abs(w' - u'); % absolute error\nerr_total = sum(sum(err_grid)); % norm L1 (taxicab/Manhattan)\ndisp(\"Grid nilai error:\");\ndisp(flipud(err_grid));\ndisp(\"Error total (norm L1):\");\ndisp(err_total);\n\n% gambar mesh hasil aproksimasi\nfigure 1;\nmesh(x_arr, t_arr, w');\ntitle(\"Hasil aproksimasi\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"u\");\n\n% gambar mesh solusi eksak\nfigure 2;\nmesh(x_arr, t_arr, u');\ntitle(\"Solusi eksak\");\nxlabel(\"x\");\nylabel(\"t\");\nzlabel(\"u\");\n\nGrid nilai aproksimasi:\n Columns 1 through 8:\n\n        0   0.0920   0.1670   0.2136   0.2292   0.2136   0.1670   0.0920\n        0   0.0888   0.1605   0.2049   0.2197   0.2049   0.1605   0.0888\n        0   0.0854   0.1538   0.1958   0.2099   0.1958   0.1538   0.0854\n        0   0.0818   0.1467   0.1865   0.1998   0.1865   0.1467   0.0818\n        0   0.0781   0.1394   0.1769   0.1894   0.1769   0.1394   0.0781\n        0   0.0742   0.1319   0.1670   0.1788   0.1670   0.1319   0.0742\n        0   0.0701   0.1242   0.1570   0.1679   0.1570   0.1242   0.0701\n        0   0.0658   0.1162   0.1467   0.1568   0.1467   0.1162   0.0658\n        0   0.0614   0.1080   0.1362   0.1455   0.1362   0.1080   0.0614\n        0   0.0569   0.0997   0.1255   0.1341   0.1255   0.0997   0.0569\n        0   0.0522   0.0912   0.1146   0.1224   0.1146   0.0912   0.0522\n        0   0.0474   0.0825   0.1036   0.1106   0.1036   0.0825   0.0474\n        0   0.0425   0.0737   0.0924   0.0987   0.0924   0.0737   0.0425\n        0   0.0374   0.0648   0.0812   0.0866   0.0812   0.0648   0.0374\n        0   0.0323   0.0557   0.0698   0.0745   0.0698   0.0557   0.0323\n        0   0.0270   0.0466   0.0583   0.0622   0.0583   0.0466   0.0270\n        0   0.0217   0.0373   0.0467   0.0498   0.0467   0.0373   0.0217\n        0   0.0163   0.0281   0.0351   0.0374   0.0351   0.0281   0.0163\n        0   0.0109   0.0187   0.0234   0.0250   0.0234   0.0187   0.0109\n        0   0.0055   0.0094   0.0117   0.0125   0.0117   0.0094   0.0055\n        0        0        0        0        0        0        0        0\n\n Column 9:\n\n        0\n        0\n        0\n        0\n        0\n        0\n        0\n        0\n        0\n        0\n        0\n        0\n        0\n        0\n        0\n        0\n        0\n        0\n        0\n        0\n        0\nGrid solusi eksak:\n Columns 1 through 8:\n\n        0   0.0912   0.1666   0.2135   0.2292   0.2135   0.1666   0.0912\n        0   0.0880   0.1602   0.2048   0.2197   0.2048   0.1602   0.0880\n        0   0.0846   0.1535   0.1957   0.2098   0.1957   0.1535   0.0846\n        0   0.0811   0.1466   0.1864   0.1997   0.1864   0.1466   0.0811\n        0   0.0774   0.1393   0.1768   0.1893   0.1768   0.1393   0.0774\n        0   0.0736   0.1318   0.1670   0.1787   0.1670   0.1318   0.0736\n        0   0.0696   0.1241   0.1569   0.1678   0.1569   0.1241   0.0696\n        0   0.0654   0.1162   0.1466   0.1568   0.1466   0.1162   0.0654\n        0   0.0611   0.1080   0.1361   0.1455   0.1361   0.1080   0.0611\n        0   0.0567   0.0997   0.1255   0.1340   0.1255   0.0997   0.0567\n        0   0.0520   0.0912   0.1146   0.1224   0.1146   0.0912   0.0520\n        0   0.0473   0.0825   0.1036   0.1106   0.1036   0.0825   0.0473\n        0   0.0424   0.0737   0.0924   0.0987   0.0924   0.0737   0.0424\n        0   0.0374   0.0647   0.0811   0.0866   0.0811   0.0647   0.0374\n        0   0.0323   0.0557   0.0697   0.0744   0.0697   0.0557   0.0323\n        0   0.0270   0.0465   0.0583   0.0622   0.0583   0.0465   0.0270\n        0   0.0217   0.0373   0.0467   0.0498   0.0467   0.0373   0.0217\n        0   0.0164   0.0280   0.0351   0.0374   0.0351   0.0280   0.0164\n        0   0.0109   0.0187   0.0234   0.0250   0.0234   0.0187   0.0109\n        0   0.0055   0.0094   0.0117   0.0125   0.0117   0.0094   0.0055\n        0        0        0        0        0        0        0        0\n\n Column 9:\n\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n   0.0000\n        0\nGrid nilai error:\n Columns 1 through 6:\n\n            0   8.8525e-04   3.8928e-04   7.7316e-05   3.4570e-05   7.7316e-05\n            0   8.4394e-04   2.9470e-04   7.1736e-05   3.1040e-05   7.1736e-05\n            0   7.8956e-04   2.1644e-04   6.5668e-05   3.0855e-05   6.5668e-05\n            0   7.2399e-04   1.5428e-04   5.8621e-05   3.3324e-05   5.8621e-05\n            0   6.4968e-04   1.0712e-04   5.0674e-05   3.7425e-05   5.0674e-05\n            0   5.6942e-04   7.3213e-05   4.2316e-05   4.1967e-05   4.2316e-05\n            0   4.8623e-04   5.0406e-05   3.4249e-05   4.5771e-05   3.4249e-05\n            0   4.0312e-04   3.6338e-05   2.7202e-05   4.7839e-05   2.7202e-05\n            0   3.2290e-04   2.8672e-05   2.1765e-05   4.7490e-05   2.1765e-05\n            0   2.4810e-04   2.5270e-05   1.8270e-05   4.4452e-05   1.8270e-05\n            0   1.8076e-04   2.4319e-05   1.6737e-05   3.8881e-05   1.6737e-05\n            0   1.2244e-04   2.4401e-05   1.6869e-05   3.1322e-05   1.6869e-05\n            0   7.4103e-05   2.4513e-05   1.8111e-05   2.2613e-05   1.8111e-05\n            0   3.6165e-05   2.4038e-05   1.9748e-05   1.3747e-05   1.9748e-05\n            0   8.5035e-06   2.2681e-05   2.1026e-05   5.7195e-06   2.1026e-05\n            0   9.4826e-06   2.0388e-05   2.1273e-05   6.2686e-07   2.1273e-05\n            0   1.8808e-05   1.7258e-05   2.0015e-05   4.7246e-06   2.0015e-05\n            0   2.0824e-05   1.3468e-05   1.7041e-05   6.3650e-06   1.7041e-05\n            0   1.7141e-05   9.2141e-06   1.2436e-05   5.7251e-06   1.2436e-05\n            0   9.5601e-06   4.6739e-06   6.5641e-06   3.3363e-06   6.5641e-06\n            0            0            0            0            0            0\n\n Columns 7 through 9:\n\n   3.8928e-04   8.8525e-04   2.9230e-17\n   2.9470e-04   8.4394e-04   2.8221e-17\n   2.1644e-04   7.8956e-04   2.7166e-17\n   1.5428e-04   7.2399e-04   2.6065e-17\n   1.0712e-04   6.4968e-04   2.4920e-17\n   7.3213e-05   5.6942e-04   2.3732e-17\n   5.0406e-05   4.8623e-04   2.2499e-17\n   3.6338e-05   4.0312e-04   2.1222e-17\n   2.8672e-05   3.2290e-04   1.9896e-17\n   2.5270e-05   2.4810e-04   1.8521e-17\n   2.4319e-05   1.8076e-04   1.7093e-17\n   2.4401e-05   1.2244e-04   1.5611e-17\n   2.4513e-05   7.4103e-05   1.4071e-17\n   2.4038e-05   3.6165e-05   1.2474e-17\n   2.2681e-05   8.5035e-06   1.0821e-17\n   2.0388e-05   9.4826e-06   9.1133e-18\n   1.7258e-05   1.8808e-05   7.3566e-18\n   1.3468e-05   2.0824e-05   5.5575e-18\n   9.2141e-06   1.7141e-05   3.7246e-18\n   4.6739e-06   9.5601e-06   1.8683e-18\n            0            0            0\nError total (norm L1):\n0.017764"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul9.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul9.html",
    "title": "Modul 9 Praktikum Sains Data: Pengantar PyTorch",
    "section": "",
    "text": "Kembali ke Sains Data\nIni adalah pertemuan terakhir praktikum Sains Data tahun ini.\nDi dua pertemuan sebelumnya, kita sudah membahas tentang neural network dan deep learning dengan TensorFlow dan Keras. Dari segi materi mata kuliah Sains Data, sebenarnya kita sudah selesai.\nNamun, di awal Modul 7, telah disebutkan bahwa ada dua framework utama yang umum digunakan untuk deep learning di Python, yaitu TensorFlow (dengan Keras) dan PyTorch.\nAgar wawasan kita lebih luas dan tidak terbatas satu framework saja, tidak ada salahnya kita coba mempelajari PyTorch juga :)\nLagipula, untuk riset/penelitian di dunia deep learning, saat ini PyTorch jauh lebih sering digunakan dibandingkan TensorFlow:\n\n\n\n(Gambar tren November 2014 hingga April 2024: dari semua implementasi atau kode yang telah dibuat untuk paper deep learning, berapa persen menggunakan framework tertentu. Pada April 2024, persentase PyTorch lebih dari 50%, sedangkan persentase TensorFlow kurang dari 10%.)\n\n\nGambar tren November 2014 hingga April 2024: dari semua implementasi atau kode yang telah dibuat untuk paper deep learning, berapa persen menggunakan framework tertentu. Pada April 2024, persentase PyTorch lebih dari 50%, sedangkan persentase TensorFlow kurang dari 10%.\nKalian bisa explore di link berikut: https://paperswithcode.com/trends\nApabila sewaktu-waktu kalian ingin menjalani skripsi atau semacamnya di dunia deep learning, atau setidaknya ingin membaca riset terbaru, kami harap wawasan tentang PyTorch ini bermanfaat.\n\n\n\n\n\n\nTentang urutan materi\n\n\n\nKami sengaja mengajarkan TensorFlow dan Keras terlebih dahulu, baru mengajarkan PyTorch, karena penyusunan model di PyTorch mirip dengan penggunaan subclassing API di Keras.\n\n\nSebelum kita mulai, instal terlebih dahulu PyTorch, dengan menginstal torch dan torchvision\n\npip install torch torchvision\n\n\ntorch adalah PyTorch.\ntorchvision menyediakan fitur-fitur yang membantu ketika berurusan dengan gambar, bahkan seperti sudah menjadi bagian yang tidak terpisahkan dari torch.\nSebenarnya ada juga torchaudio yang membantu ketika berurusan dengan data suara. Boleh saja kalian instal juga:\npip install torch torchvision torchaudio\n\nTerkait penginstalan PyTorch, kalian bisa membaca lebih lanjut di sini: https://pytorch.org/get-started/locally/\nKalau sudah instal, jangan lupa import:\n\nimport torch, torchvision\n\nKita bisa lihat versinya (mungkin di kalian akan lebih baru):\n\nprint(torch.__version__)\n\n2.1.0\n\n\n\nprint(torchvision.__version__)\n\n0.16.0\n\n\nJangan lupa import juga library yang biasa kita gunakan:\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n\n\n\nTiap komputer bisa memiliki kekuatan yang berbeda, termasuk ada/tiadanya komponen yang bernama GPU.\nTiap komputer pasti punya yang namanya CPU atau Central Processing Unit, yang biasanya menjadi pusat segala komputasi di komputer itu, sesuai namanya.\nNamun, untuk perhitungan dengan matriks, tensor atau semacamnya, GPU atau Graphics Processing Unit lebih cepat. Perhitungan seperti itu biasa dilakukan untuk tampilan atau graphics ketika sedang bermain game, dan juga biasa dilakukan ketika berurusan dengan neural network.\nSehingga, daripada menggunakan CPU, ada baiknya menggunakan GPU, kalau ada.\nDi Google Colaboratory, di menu Runtime &gt; Change runtime type, di bagian hardware accelerator, kalian bisa mengubah setting, apakah ingin menggunakan CPU atau GPU. (Bahkan, ada juga TPU atau tensor processing unit yang sepertinya lebih dikhususkan lagi untuk komputasi dengan tensor.)\n\n\nApapun yang tersedia, tiap kali kita ingin menggunakan PyTorch, sebaiknya kita beritahu, mana yang ingin kita gunakan. Agar tidak berantakan, caranya bisa dengan kode berikut:\n\n# Setup device-agnostic code\nif torch.cuda.is_available():\n    device = \"cuda\" # NVIDIA GPU\nelif torch.backends.mps.is_available():\n    device = \"mps\" # Apple GPU\nelse:\n    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n\nprint(f\"Using device: {device}\")\n\nUsing device: cuda\n\n\nSumber kode: https://www.learnpytorch.io/pytorch_cheatsheet/#device-agnostic-code-using-pytorch-on-cpu-gpu-or-mps\nOutput nya akan sesuai dengan pilihan terbaik yang ada, antara CPU atau GPU.\nKode di atas sebenarnya hanya menyimpan pilihan tersebut sebagai string ke dalam variabel device. Namun, variabel ini nantinya akan digunakan selama berurusan dengan PyTorch.\nSehingga, apabila kita ingin ganti dari CPU ke GPU atau sebaliknya, kita tinggal mengubah isi variabel device ini (misalnya menggunakan kode di atas), tidak perlu mengubah kode PyTorch yang sudah kita buat.\nDengan demikian, kode PyTorch yang sudah kita buat menjadi tidak tergantung device yang digunakan (apakah CPU atau GPU), atau disebut device-agnostic.\n\n\n\nSeperti di TensorFlow, di PyTorch juga ada tensor. Cara membuatnya adalah dengan torch.tensor\nContohnya, skalar:\n\ntensor0 = torch.tensor(1.5)\n\n\nprint(tensor0)\n\ntensor(1.5000)\n\n\n\nprint(type(tensor0))\n\n&lt;class 'torch.Tensor'&gt;\n\n\nKita bisa melihat dimensinya (rank/dimensi tensor) melalui .ndim\n\nprint(tensor0.ndim)\n\n0\n\n\nTipe datanya berupa torch.tensor tapi kita bisa memperoleh nilai skalarnya dengan .item()\n\ntensor0.item()\n\n1.5\n\n\n\ntype(tensor0.item())\n\nfloat\n\n\nContoh lain, array/vektor:\n\ntensor1 = torch.tensor([2.31, 4.567, 8.9])\n\n\nprint(tensor1)\n\ntensor([2.3100, 4.5670, 8.9000])\n\n\n\nprint(tensor1.ndim)\n\n1\n\n\nSelain dimensi tensor, ada juga .shape yang di sini melambangkan ukuran array/vektor, seperti .shape di numpy\n\nprint(tensor1.shape)\n\ntorch.Size([3])\n\n\nNilai suatu elemen di tensor juga bisa diubah:\n\ntensor1[0] = 52.5\n\n\nprint(tensor1)\n\ntensor([52.5000,  4.5670,  8.9000])\n\n\nAda juga tipe data:\n\nprint(tensor1.dtype)\n\ntorch.float32\n\n\nSeperti tensor di TensorFlow, tensor di PyTorch juga biasanya menggunakan bilangan float yang 32-bit daripada 64-bit.\nContoh lagi, matriks:\n\nmat1 = torch.tensor([\n    [1, 2.718, 3.14],\n    [4, 5, 6.28]\n])\n\n\nprint(mat1)\n\ntensor([[1.0000, 2.7180, 3.1400],\n        [4.0000, 5.0000, 6.2800]])\n\n\n\nprint(mat1.ndim)\n\n2\n\n\n\nprint(mat1.shape)\n\ntorch.Size([2, 3])\n\n\nKita bisa buat matriks kedua, lalu mengalikannya dengan perkalian matriks menggunakan torch.matmul\n\nmat2 = torch.tensor([\n    [9, 8],\n    [7, 6],\n    [5, 4.3]\n])\n\n\nprint(mat2.ndim)\nprint(mat2.shape)\nprint(mat2.dtype)\n\n2\ntorch.Size([3, 2])\ntorch.float32\n\n\n\nmat3 = torch.matmul(mat1, mat2)\n\n\nprint(mat3)\n\ntensor([[ 43.7260,  37.8100],\n        [102.4000,  89.0040]])\n\n\nMatriks juga bisa ditranspos dengan .T\n\nmat4 = mat3.T\nprint(mat4)\n\ntensor([[ 43.7260, 102.4000],\n        [ 37.8100,  89.0040]])\n\n\n\n\n\nKita bisa mengonversi tensor PyTorch menjadi array numpy dan sebaliknya:\n\n.numpy() untuk mengubah suatu tensor PyTorch menjadi array numpy\ntorch.from_numpy(...) untuk mengubah suatu array numpy menjadi tensor PyTorch\n\n\narr5 = mat4.numpy()\nprint(arr5)\nprint(type(arr5))\nprint(arr5.dtype)\n\n[[ 43.725998 102.4     ]\n [ 37.809998  89.004   ]]\n&lt;class 'numpy.ndarray'&gt;\nfloat32\n\n\n\nmat6 = torch.from_numpy(arr5)\nprint(mat6)\nprint(type(mat6))\nprint(mat6.dtype)\n\ntensor([[ 43.7260, 102.4000],\n        [ 37.8100,  89.0040]])\n&lt;class 'torch.Tensor'&gt;\ntorch.float32\n\n\n\n\n\nKita bisa membuat tensor berisi satu semua, atau nol semua, atau nilai random, dengan ukuran size yang bisa kita tentukan\n\nx = torch.ones(size = (3,4))\nprint(x)\n\ntensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.]])\n\n\n\nx = torch.zeros(size = (3,4))\nprint(x)\n\ntensor([[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]])\n\n\n\nx = torch.rand(size = (3,4))\nprint(x)\n\ntensor([[0.0698, 0.2004, 0.3279, 0.2525],\n        [0.2461, 0.4263, 0.4870, 0.4371],\n        [0.9545, 0.7487, 0.3990, 0.0412]])\n\n\ntorch.rand memilih nilai secara random dari distribusi uniform pada interval \\([0,1)\\)\nUntuk memilih nilai secara random dari distribusi normal (dengan \\(\\mu = 0\\) dan \\(\\sigma = 1\\)), gunakan torch.randn\n\nx = torch.randn(size = (3,4))\nprint(x)\n\ntensor([[ 1.5820, -0.1806,  0.1820, -0.6891],\n        [ 1.2161, -0.5755, -0.5172, -0.7454],\n        [ 0.3047, -0.5932, -0.3343, -1.1461]])\n\n\n\n\n\nSecara umum, operasi tensor di PyTorch memang mirip dengan array di numpy, sebagaimana operasi tensor di TensorFlow juga mirip dengan array di numpy.\n\na = 4 * torch.ones((2, 2))\nprint(a)\n\ntensor([[4., 4.],\n        [4., 4.]])\n\n\n\nb = torch.square(a)\nprint(b)\n\ntensor([[16., 16.],\n        [16., 16.]])\n\n\n\nc = torch.sqrt(a)\nprint(c)\n\ntensor([[2., 2.],\n        [2., 2.]])\n\n\n\nd = b + c\nprint(d)\n\ntensor([[18., 18.],\n        [18., 18.]])\n\n\n\n# perkalian matriks\ne = torch.matmul(a, c)\nprint(e)\n\ntensor([[16., 16.],\n        [16., 16.]])\n\n\n\n# perkalian per elemen\ne *= d\nprint(e)\n\ntensor([[288., 288.],\n        [288., 288.]])\n\n\n\n# penjumlahan per elemen\nf = e + 2\nprint(f)\n\ntensor([[290., 290.],\n        [290., 290.]])\n\n\n\n\n\nSebagaimana ada automatic differentiation atau autodiff di TensorFlow, ada juga autograd di PyTorch. Namun, syntax nya cukup berbeda.\nCaranya, inputnya kita jadikan tensor dengan parameter requires_grad=True, lalu kita operasikan (misal dengan fungsi f) dan menghasilkan tensor baru, lalu di tensor baru ini kita panggil .backward() agar turunan f dihitung dan disimpan di variabel input .grad\nContohnya, turunan \\(x^3\\) terhadap \\(x\\) di \\(x=4\\) adalah \\(3(4)^2 = 48\\).\n\n# siapkan input, dengan requires_grad=True\nx = torch.tensor(4.0, requires_grad=True)\n\n# hitung fungsi F\nF = x**3\n\n# jalankan perhitungan turunan F (terhadap input)\nF.backward()\n\n# tampilkan turunan yang tersimpan di input .grad\nprint(x.grad)\n\ntensor(48.)\n\n\nNama method nya adalah .backward() dan memang digunakan di backward pass (akan kita lihat nanti).\nContoh lain, turunan \\(3x^3 - y^2\\) terhadap \\(x\\) dengan \\(x=2\\) adalah \\(9(2)^2 = 36\\), dan turunannya terhadap \\(y\\) dengan \\(y=6\\) adalah \\(-2(6) = -12\\)\n\nx = torch.tensor(2.0, requires_grad=True)\ny = torch.tensor(6.0, requires_grad=True)\n\nF = 3 * x**3 - y**2\n\nF.backward()\n\nprint(x.grad)\nprint(y.grad)\n\ntensor(36.)\ntensor(-12.)\n\n\n\n\n\n\n\n\nUntuk model pertama kita, mari kita coba buat kembali model perceptron untuk klasifikasi biner yang pernah kita buat di Modul 7, dengan dataset titik_negatif_positif.csv yang sama, bisa kalian download dari GitHub Pages ini: titik_negatif_positif.csv\nKita buka datasetnya, jangan lupa dengan dtype=\"float32\" karena itulah tipe data yang biasa digunakan oleh PyTorch, seperti TensorFlow:\n\ntitik_df = pd.read_csv(\"./titik_negatif_positif.csv\", dtype=\"float32\")\n\n\ntitik_df\n\n\n\n\n\n\n\n\nx\ny\nkelas\n\n\n\n\n0\n1.173375\n4.570637\n0.0\n\n\n1\n0.195961\n3.504604\n0.0\n\n\n2\n0.121400\n2.163783\n0.0\n\n\n3\n-1.170182\n3.882771\n0.0\n\n\n4\n-0.424403\n0.534641\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n2.423160\n-0.337196\n1.0\n\n\n1996\n1.949836\n-0.627813\n1.0\n\n\n1997\n2.109928\n-0.382492\n1.0\n\n\n1998\n4.178664\n0.486168\n1.0\n\n\n1999\n2.326363\n1.228249\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\nMemisahkan antara inputs (prediktor) dan targets (variabel target):\n\ntitik_inputs_df = titik_df.drop(columns=[\"kelas\"])\ntitik_targets_df = titik_df[[\"kelas\"]]\n\n\ntitik_inputs_df\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n1.173375\n4.570637\n\n\n1\n0.195961\n3.504604\n\n\n2\n0.121400\n2.163783\n\n\n3\n-1.170182\n3.882771\n\n\n4\n-0.424403\n0.534641\n\n\n...\n...\n...\n\n\n1995\n2.423160\n-0.337196\n\n\n1996\n1.949836\n-0.627813\n\n\n1997\n2.109928\n-0.382492\n\n\n1998\n4.178664\n0.486168\n\n\n1999\n2.326363\n1.228249\n\n\n\n\n2000 rows × 2 columns\n\n\n\n\ntitik_targets_df\n\n\n\n\n\n\n\n\nkelas\n\n\n\n\n0\n0.0\n\n\n1\n0.0\n\n\n2\n0.0\n\n\n3\n0.0\n\n\n4\n0.0\n\n\n...\n...\n\n\n1995\n1.0\n\n\n1996\n1.0\n\n\n1997\n1.0\n\n\n1998\n1.0\n\n\n1999\n1.0\n\n\n\n\n2000 rows × 1 columns\n\n\n\nMengubahnya menjadi array numpy:\n\ntitik_inputs_arr = titik_inputs_df.to_numpy()\ntitik_targets_arr = titik_targets_df.to_numpy()\n\nKemudian mengubahnya menjadi tensor PyTorch:\n\ntitik_inputs_tensor = torch.from_numpy(titik_inputs_arr)\ntitik_targets_tensor = torch.from_numpy(titik_targets_arr)\n\nTujuan mengubah dari DataFrame menjadi tensor, tentunya supaya bisa diproses dengan PyTorch.\nKita bisa periksa, bentuknya sesuai:\n\nprint(titik_inputs_tensor)\n\ntensor([[ 1.1734,  4.5706],\n        [ 0.1960,  3.5046],\n        [ 0.1214,  2.1638],\n        ...,\n        [ 2.1099, -0.3825],\n        [ 4.1787,  0.4862],\n        [ 2.3264,  1.2282]])\n\n\n\nprint(titik_targets_tensor)\n\ntensor([[0.],\n        [0.],\n        [0.],\n        ...,\n        [1.],\n        [1.],\n        [1.]])\n\n\nKemudian, kita bisa melakukan train-validation-test split, misalnya dengan rasio 80:10:10\n\nfrom sklearn.model_selection import train_test_split\n\n\n# data utuh menjadi data train 80% dan data \"test\" 20%\ntitik_X_train, titik_X_test, titik_y_train, titik_y_test = train_test_split(\n    titik_inputs_tensor, titik_targets_tensor, test_size=0.2, random_state=42\n)\n\n# data \"test\" dibagi dua, menjadi data validation dan data test sesungguhnya\ntitik_X_val, titik_X_test, titik_y_val, titik_y_test = train_test_split(\n    titik_X_test, titik_y_test, test_size=0.5, random_state=42\n)\n\nKita bisa periksa ukurannya, rasionya sudah sesuai yang kita tetapkan:\n\nprint(titik_X_train.shape)\nprint(titik_X_val.shape)\nprint(titik_X_test.shape)\n\ntorch.Size([1600, 2])\ntorch.Size([200, 2])\ntorch.Size([200, 2])\n\n\nSebelum dataset kita benar-benar siap untuk diproses dengan PyTorch, ada dua hal yang perlu kita lakukan:\n\nmengubahnya menjadi objek Dataset dengan TensorDataset\nDataset di sini adalah format dataset umum yang dikenal oleh PyTorch.\nmengubah objek Dataset menjadi objek DataLoader\nDataLoader membuat objek Dataset menjadi “iterable” yaitu bisa diiterasikan dengan for loop, agar bisa digunakan dalam proses training maupun testing.\n\nBaik TensorDataset maupun DataLoader bisa kita import dari torch.utils.data\n\nfrom torch.utils.data import TensorDataset, DataLoader\n\nMasing-masing dari data train, data validation, dan data test bisa kita ubah menjadi objek Dataset dengan menentukan mana prediktor dan mana target:\n\ntitik_train_dataset = TensorDataset(titik_X_train, titik_y_train)\ntitik_val_dataset = TensorDataset(titik_X_val, titik_y_val)\ntitik_test_dataset = TensorDataset(titik_X_test, titik_y_test)\n\nKemudian, masing-masing bisa kita ubah menjadi DataLoader, sekasligus menentukan batch size, dan juga menentukan apakah perlu ada shuffling di tiap epoch (biasanya dilakukan di data train untuk mengurangi overfitting):\n\ntitik_train_dataloader = DataLoader(titik_train_dataset, batch_size=32, shuffle=True)\ntitik_val_dataloader = DataLoader(titik_val_dataset, batch_size=32, shuffle=False)\ntitik_test_dataloader = DataLoader(titik_test_dataset, batch_size=32, shuffle=False)\n\n\n\n\nIngat bahwa perceptron yang ingin kita susun hanya terdiri dari\n\ninput layer dengan dua neuron,\ntidak ada hidden layer,\noutput layer dengan satu neuron dan fungsi aktivasi sigmoid\n\nSehingga matriks bobot yang sesuai berukuran \\(2 \\times 1\\), dan vektor bias yang sesuai berukuran \\(1 \\times 1\\).\nDi PyTorch, tiap model berupa class dengan ketentuan:\n\nmeng-inherit dari torch.nn.Module (yaitu base class untuk semua model PyTorch)\nbaris pertama di constructor __init__ adalah\nsuper().__init__()\nharus mendefinisikan forward() untuk forward pass\nkomponen/variabel/atribut/parameter yang diperlukan biasanya didefinisikan di constructor\nCatatan: parameter biasa didefinisikan dengan torch.nn.Parameter daripada torch.tensor\n\nIni cukup mirip dengan subclassing API di Keras, yang meng-inherit dari keras.Model dan harus mendefinisikan call() untuk forward pass.\nMari kita susun perceptron kita, yang memiliki matriks bobot, vektor bias, dan fungsi aktivasi sigmoid:\n\nclass MyPerceptron(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.weights = torch.nn.Parameter(\n            torch.randn(size = (2, 1), dtype = torch.float32),\n            requires_grad=True # agar autgrad aktif\n        )\n\n        self.bias = torch.nn.Parameter(\n            torch.randn(size = (1,), dtype = torch.float32),\n            requires_grad=True\n        )\n\n    def forward(self, x):\n        return torch.sigmoid(\n            torch.matmul(x, self.weights) + self.bias\n        )\n\nKita bisa buat suatu instance atau objek dari class di atas:\n\npisah_titik = MyPerceptron()\n\nIni adalah model yang siap di-train. Sebelum training, kita bisa memeriksa parameter model (saat ini masih random sesuai torch.randn):\n\nlist(pisah_titik.parameters())\n\n[Parameter containing:\n tensor([[-0.8412],\n         [-1.1300]], requires_grad=True),\n Parameter containing:\n tensor([-0.0640], requires_grad=True)]\n\n\nMirip, ada juga yang namanya .state_dict()\n\npisah_titik.state_dict()\n\nOrderedDict([('weights',\n              tensor([[-0.8412],\n                      [-1.1300]])),\n             ('bias', tensor([-0.0640]))])\n\n\n\n\n\nUntuk klasifikasi, loss function yang biasa digunakan adalah crossentropy loss, atau mungkin lebih spesifiknya binary crossentropy loss, yang disebut torch.nn.BCELoss di PyTorch. Kita bisa menyiapkannya sebagai objek.\n\ntitik_loss_fn = torch.nn.BCELoss()\n\nSerupa, optimizer juga disiapkan sebagai objek, misalnya torch.optim.SGD untuk SGD (stochastic gradient descent):\n\ntitik_opt = torch.optim.SGD(params=pisah_titik.parameters(), # merujuk ke parameter model\n                            lr=0.01) # learning rate\n\n\n\n\nMungkin agak mengejutkan: di PyTorch, kita dibebaskan untuk membuat training loop sendiri. Artinya, tidak ada fungsi .fit() yang tinggal kita panggil; kita perlu menyusun for loop sendiri, seperti di Modul 7 :)\nIngat kembali, tiap iterasi (yaitu per batch) di proses training melibatkan:\n\nForward pass: menghitung nilai output (hasil prediksi) dari input (batch).\nMenghitung loss antara hasil prediksi dan nilai sebenarnya\nBackpropagation: menghitung gradien dari loss terhadap tiap parameter\nUpdate optimizer: memperbarui nilai parameter berdasarkan gradien dari loss, menggunakan rumus atau optimizer yang dipilih\n\nIngat juga, selain training, ada juga yang namanya validation (atau terkadang disebut testing di beberapa sumber). Tahap validation ini menguji model di akhir tiap epoch, setelah semua batch melalui proses training. Langkahnya terdiri dari:\n\nForward pass\nMenghitung loss dan/atau accuracy antara hasil prediksi dan nilai sebenarnya\n\nPerhatikan bahwa validation juga bisa dilakukan per batch, sehingga kedua langkah di atas dilakukan per batch. Kalau begitu, nilai akhir untuk loss dan/atau accuracy menjadi rata-rata dari nilainya di tiap batch.\nPenjelasan di atas menjadi kode PyTorch sebagai berikut:\n\nepochs = 10\n\ntrain_loss_list = []\nval_loss_list = []\n\n# untuk tiap epoch,\nfor epoch in range(epochs):\n    # siapkan model untuk tahap training\n    pisah_titik.to(device)\n    pisah_titik.train()\n    sum_train_loss = 0\n\n    # untuk tiap batch,\n    for X, y in titik_train_dataloader:\n        X = X.to(device)\n        y = y.to(device)\n\n        # Forward pass\n        y_pred = pisah_titik(X)\n\n        # Hitung loss\n        loss = titik_loss_fn(y_pred, y)\n        sum_train_loss += loss\n\n        # \"Optimizer zero grad\": nolkan dulu hasil hitung gradien\n        titik_opt.zero_grad()\n\n        # Backpropagation\n        loss.backward()\n\n        # Update optimizer, juga disebut \"optimizer step\"\n        titik_opt.step()\n\n    # hitung rata-rata train loss berdasarkan banyaknya batch\n    avg_train_loss = sum_train_loss / len(titik_train_dataloader)\n\n    # simpan train loss\n    train_loss_list.append(avg_train_loss)\n\n    # siapkan model untuk tahap validaion\n    pisah_titik.to(device)\n    pisah_titik.eval()\n    sum_val_loss = 0\n\n    # selalu digunakan ketika hendak testing\n    with torch.inference_mode():\n        # untuk tiap batch,\n        for X, y in titik_val_dataloader:\n            X = X.to(device)\n            y = y.to(device)\n\n            # Forward pass\n            y_pred = pisah_titik(X)\n\n            # Hitung loss\n            sum_val_loss += titik_loss_fn(y_pred, y)\n\n        # hitung rata-rata val loss berdasarkan banyaknya batch\n        avg_val_loss = sum_val_loss / len(titik_val_dataloader)\n\n        # simpan val loss\n        val_loss_list.append(avg_val_loss)\n\n    # tampilkan train loss dan val loss untuk epoch ini\n    print(f\"Epoch: {epoch} | avg train loss: {avg_train_loss} | avg val loss: {avg_val_loss}\")\n\nEpoch: 0 | avg train loss: 1.0023550987243652 | avg val loss: 0.6549612879753113\nEpoch: 1 | avg train loss: 0.424757719039917 | avg val loss: 0.3022421300411224\nEpoch: 2 | avg train loss: 0.2212503552436828 | avg val loss: 0.1808699667453766\nEpoch: 3 | avg train loss: 0.1497089713811874 | avg val loss: 0.1308697611093521\nEpoch: 4 | avg train loss: 0.1175468564033508 | avg val loss: 0.1053687334060669\nEpoch: 5 | avg train loss: 0.0995666906237602 | avg val loss: 0.0898655503988266\nEpoch: 6 | avg train loss: 0.0879358351230621 | avg val loss: 0.0794256925582885\nEpoch: 7 | avg train loss: 0.0796592533588409 | avg val loss: 0.0717914551496505\nEpoch: 8 | avg train loss: 0.0733261257410049 | avg val loss: 0.0658656656742096\nEpoch: 9 | avg train loss: 0.0682612806558609 | avg val loss: 0.061109509319067\n\n\nPerhatikan bahwa hasil loss di tiap epoch sudah kita simpan ke dalam list.\n\nprint(train_loss_list)\nprint(val_loss_list)\n\n[tensor(1.0024, grad_fn=&lt;DivBackward0&gt;), tensor(0.4248, grad_fn=&lt;DivBackward0&gt;), tensor(0.2213, grad_fn=&lt;DivBackward0&gt;), tensor(0.1497, grad_fn=&lt;DivBackward0&gt;), tensor(0.1175, grad_fn=&lt;DivBackward0&gt;), tensor(0.0996, grad_fn=&lt;DivBackward0&gt;), tensor(0.0879, grad_fn=&lt;DivBackward0&gt;), tensor(0.0797, grad_fn=&lt;DivBackward0&gt;), tensor(0.0733, grad_fn=&lt;DivBackward0&gt;), tensor(0.0683, grad_fn=&lt;DivBackward0&gt;)]\n[tensor(0.6550), tensor(0.3022), tensor(0.1809), tensor(0.1309), tensor(0.1054), tensor(0.0899), tensor(0.0794), tensor(0.0718), tensor(0.0659), tensor(0.0611)]\n\n\nMaka, kita bisa ubah jadi DataFrame lalu menyimpannya sebagai CSV:\n\ntitik_loss_df = pd.DataFrame(\n    [\n        [loss.item() for loss in train_loss_list],\n        [loss.item() for loss in val_loss_list]\n    ],\n).transpose().rename(columns={0: \"train_loss\", 1: \"val_loss\"})\n\n\ntitik_loss_df\n\n\n\n\n\n\n\n\ntrain_loss\nval_loss\n\n\n\n\n0\n1.002355\n0.654961\n\n\n1\n0.424758\n0.302242\n\n\n2\n0.221250\n0.180870\n\n\n3\n0.149709\n0.130870\n\n\n4\n0.117547\n0.105369\n\n\n5\n0.099567\n0.089866\n\n\n6\n0.087936\n0.079426\n\n\n7\n0.079659\n0.071791\n\n\n8\n0.073326\n0.065866\n\n\n9\n0.068261\n0.061110\n\n\n\n\n\n\n\n\ntitik_loss_df.to_csv(\"./pytorch_titik_loss_df.csv\", index=False)\n\nKalau mau menyamakan dengan modul, kalian bisa download melalui GitHub Pages ini: pytorch_titik_loss_df.csv\nKita bisa import kembali:\n\npytorch_titik_loss_df = pd.read_csv(\"./pytorch_titik_loss_df.csv\")\n\nLalu kita bisa plot:\n\nplt.plot(pytorch_titik_loss_df[\"train_loss\"], label = \"training loss\")\nplt.plot(pytorch_titik_loss_df[\"val_loss\"], label = \"validation loss\")\nplt.xlabel(\"epoch\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIngat kembali, kita bisa melihat parameter model dengan .state_dict()\n\npisah_titik.state_dict()\n\nOrderedDict([('weights',\n              tensor([[ 0.9372],\n                      [-1.2340]])),\n             ('bias', tensor([0.3439]))])\n\n\nKita bisa menyimpan parameter model ke dalam file berakhiran .pth menggunakan torch.save\n\ntorch.save(pisah_titik.state_dict(), \"./pisah_titik_state.pth\")\n\nApabila ingin load kembali, kita perlu membuat instance terlebih dahulu…\n\npisah_titik2 = MyPerceptron()\n\nBarulah kita panggil .load_state_dict(torch.load(PATH)) seperti berikut:\n\npisah_titik2.load_state_dict(torch.load(\"./pisah_titik_state.pth\"))\n\n&lt;All keys matched successfully&gt;\n\n\nParameternya akan sama:\n\npisah_titik2.state_dict()\n\nOrderedDict([('weights',\n              tensor([[ 0.9372],\n                      [-1.2340]])),\n             ('bias', tensor([0.3439]))])\n\n\n\n\n\n\nclass MyPerceptron_v2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # satu dense layer dengan fungsi aktivasi linier\n        self.linear_layer = torch.nn.Linear(in_features=2, out_features=1)\n\n        # fungsi aktivasi sigmoid\n        self.sigmoid = torch.nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.linear_layer(x)\n        x = self.sigmoid(x)\n        return x\n\n\nclass MyPerceptron_v3(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # perhatikan: inputnya bukan berupa list, langsung saja tiap layer\n        self.layer = torch.nn.Sequential(\n            torch.nn.Linear(in_features=2, out_features=1),\n            torch.nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.layer(x)\n        return x\n\n\n\n\n\nTraining loop kita terdiri dari dua bagian utama, yaitu tahap training dan tahap validation. Kita bisa menyusun training loop yang telah kita buat dengan lebih rapi, dengan memasukkan tiap tahap ke dalam fungsi yang nantinya tinggal dipanggil. Modifikasi yang dilakukan:\n\npisah_titik menjadi model\ntitik_train_dataloader menjadi train_dataloader\ntitik_val_dataloader menjadi val_dataloader\ntitik_loss_fn menjadi loss_fn\ntitik_opt menjadi optimizer\n\n\ndef train_step(model, train_dataloader, loss_fn, optimizer, device=device):\n    # siapkan model untuk tahap training\n    model.to(device)\n    model.train()\n    sum_train_loss = 0\n\n    # untuk tiap batch,\n    for X, y in train_dataloader:\n        X = X.to(device)\n        y = y.to(device)\n\n        # Forward pass\n        y_pred = model(X)\n\n        # Hitung loss\n        loss = loss_fn(y_pred, y)\n        sum_train_loss += loss\n\n        # \"Optimizer zero grad\": nolkan dulu hasil hitung gradien\n        optimizer.zero_grad()\n\n        # Backpropagation\n        loss.backward()\n\n        # Update optimizer, juga disebut \"optimizer step\"\n        optimizer.step()\n\n    # hitung rata-rata train loss berdasarkan banyaknya batch\n    avg_train_loss = sum_train_loss / len(train_dataloader)\n\n    # sedikit modifikasi: return train loss\n    return avg_train_loss\n\n\ndef val_step(model, val_dataloader, loss_fn, device=device):\n    # siapkan model untuk tahap validaion\n    model.to(device)\n    model.eval()\n    sum_val_loss = 0\n\n    # selalu digunakan ketika hendak testing\n    with torch.inference_mode():\n        # untuk tiap batch,\n        for X, y in val_dataloader:\n            X = X.to(device)\n            y = y.to(device)\n\n            # Forward pass\n            y_pred = model(X)\n\n            # Hitung loss\n            sum_val_loss += loss_fn(y_pred, y)\n\n        # hitung rata-rata val loss berdasarkan banyaknya batch\n        avg_val_loss = sum_val_loss / len(val_dataloader)\n\n        # sedikit modifikasi: return val loss\n        return avg_val_loss\n\nSetelah mendefinisikan kedua fungsi di atas, training loop menjadi lebih sederhana:\n\nepochs = 10\n\ntrain_loss_list = []\nval_loss_list = []\n\n# untuk tiap epoch,\nfor epoch in range(epochs):\n    # training step\n    avg_train_loss = train_step(\n        model = pisah_titik,\n        train_dataloader = titik_train_dataloader,\n        loss_fn = titik_loss_fn,\n        optimizer = titik_opt,\n        device = device\n    )\n    train_loss_list.append(avg_train_loss)\n\n    # validation step\n    avg_val_loss = val_step(\n        model = pisah_titik,\n        val_dataloader = titik_val_dataloader,\n        loss_fn = titik_loss_fn,\n        device = device\n    )\n    val_loss_list.append(avg_val_loss)\n\n    # tampilkan train loss dan val loss untuk epoch ini\n    print(f\"Epoch: {epoch} | avg train loss: {avg_train_loss} | avg val loss: {avg_val_loss}\")\n\nBahkan, training loop secara keseluruhan bisa kita jadikan fungsi juga.\n\ndef training_loop(\n        model, train_dataloader, val_dataloader,\n        loss_fn, optimizer, epochs, device = device\n    ):\n\n    train_loss_list = []\n    val_loss_list = []\n\n    # untuk tiap epoch,\n    for epoch in range(epochs):\n        # training step\n        avg_train_loss = train_step(\n            model, train_dataloader,\n            loss_fn, optimizer, device=device\n        )\n        train_loss_list.append(avg_train_loss)\n\n        # validation step\n        avg_val_loss = val_step(\n            model, val_dataloader,\n            loss_fn, device=device\n        )\n        val_loss_list.append(avg_val_loss)\n\n        # tampilkan train loss dan val loss untuk epoch ini\n        print(f\"Epoch: {epoch} | avg train loss: {avg_train_loss} | avg val loss: {avg_val_loss}\")\n\n    # menyimpan kedua list ke dalam dictionary yang kemudian di-return\n    results_dict = {\n        \"train_loss\": [loss.item() for loss in train_loss_list],\n        \"val_loss\": [loss.item() for loss in val_loss_list]\n    }\n    return results_dict\n\n\n\n\nSekarang kita akan mencoba melakukan klasifikasi gambar dengan dataset Fashion MNIST seperti di pertemuan sebelumnya.\n\n\nLangkah pertama adalah menyiapkan data, yaitu menyiapkan objek Dataset, yang kemudian diubah menjadi DataLoader. Untungnya, objek Dataset untuk Fashion MNIST sudah tersedia di torchvision.datasets.FashionMNIST sehingga tinggal kita download seperti berikut.\nPerkiraan storage yang dibutuhkan: 90 MB\nApabila download di laptop kalian terlalu pelan, silakan gunakan Google Colaboratory saja, selesai kurang dari 30 detik\n\nfashion_train = torchvision.datasets.FashionMNIST(\n    root = \"./fashion_data\", # folder tempat download\n    train = True, # data training\n    download = True, # karena belum ada\n    # agar file gambar otomatis diubah menjadi tensor\n    transform = torchvision.transforms.ToTensor()\n)\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./fashion_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\nExtracting ./fashion_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./fashion_data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./fashion_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\nExtracting ./fashion_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./fashion_data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./fashion_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\nExtracting ./fashion_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./fashion_data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./fashion_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\nExtracting ./fashion_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./fashion_data/FashionMNIST/raw\n\n\n\n100%|██████████| 26421880/26421880 [00:06&lt;00:00, 3856770.39it/s]\n100%|██████████| 29515/29515 [00:00&lt;00:00, 147617.02it/s]\n100%|██████████| 4422102/4422102 [00:01&lt;00:00, 2747505.87it/s]\n100%|██████████| 5148/5148 [00:00&lt;00:00, 5877048.72it/s]\n\n\n\nfashion_val = torchvision.datasets.FashionMNIST(\n    root = \"./fashion_data\", # folder yang sama untuk tempat download\n    train = False, # bukan data training\n    download = True,\n    transform = torchvision.transforms.ToTensor()\n)\n\nBanyaknya baris di data training dan data validation\n\nprint(len(fashion_train.data), len(fashion_train.targets))\n\n60000 60000\n\n\n\nprint(len(fashion_val.data), len(fashion_val.targets))\n\n10000 10000\n\n\nKelas-kelas:\n\nnama_kelas = fashion_train.classes\nprint(nama_kelas)\n\n['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\n\nKita bisa lihat salah satu gambarnya:\n\n#@title Slider to look for some image examples {run: \"auto\"}\nidx = 21402 #@param {type:\"slider\", min:0, max:49999, step:1}\n\nimage, label = fashion_train[idx]\nplt.imshow(image.squeeze(), cmap='gray')\nplt.title(nama_kelas[label])\nplt.axis('OFF')\nplt.show()\n\n\n\n\n\n\n\n\nSedikit berbeda dengan pertemuan sebelumnya, kali ini kita gunakan .squeeze() karena gambar yang diberikan berukuran 1 x 28 x 28 (yaitu dengan satu color channel: hitam-putih) daripada 28 x 28, sehingga perlu diubah menjadi 28 x 28.\nJangan lupa menyiapkan DataLoader\n\nBATCH_SIZE = 32\n\nfashion_train_dataloader = DataLoader(\n    fashion_train,\n    batch_size = BATCH_SIZE,\n    shuffle = True\n)\n\nfashion_val_dataloader = DataLoader(\n    fashion_val,\n    batch_size = BATCH_SIZE,\n    shuffle = False\n)\n\n\n\n\n\nclass ModelFashionMNIST(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.layer_stack = torch.nn.Sequential(\n            torch.nn.Flatten(),\n            torch.nn.Linear(in_features=784, out_features=15),\n            torch.nn.ReLU(),\n            torch.nn.Linear(in_features=15, out_features=10),\n            torch.nn.Softmax(dim=1)\n        )\n\n    def forward(self, x):\n        x = self.layer_stack(x)\n        return x\n\n\nfashion_model = ModelFashionMNIST()\n\n\n\n\n\nfashion_loss_fn = torch.nn.CrossEntropyLoss()\nfashion_opt = torch.optim.Adam(params=fashion_model.parameters(),\n                               lr=0.01)\n\n\n\n\n\nfashion_results = training_loop(\n    fashion_model, fashion_train_dataloader, fashion_val_dataloader,\n    fashion_loss_fn, fashion_opt,\n    epochs = 10,\n    device = device\n)\n\nEpoch: 0 | avg train loss: 1.9308573007583618 | avg val loss: 1.9090994596481323\nEpoch: 1 | avg train loss: 1.9126436710357666 | avg val loss: 1.9180550575256348\nEpoch: 2 | avg train loss: 1.8876198530197144 | avg val loss: 1.8480236530303955\nEpoch: 3 | avg train loss: 1.7515285015106201 | avg val loss: 1.722522497177124\nEpoch: 4 | avg train loss: 1.7178850173950195 | avg val loss: 1.715074062347412\nEpoch: 5 | avg train loss: 1.6621224880218506 | avg val loss: 1.6644155979156494\nEpoch: 6 | avg train loss: 1.6579434871673584 | avg val loss: 1.6573517322540283\nEpoch: 7 | avg train loss: 1.6579766273498535 | avg val loss: 1.675686240196228\nEpoch: 8 | avg train loss: 1.6498321294784546 | avg val loss: 1.6481648683547974\nEpoch: 9 | avg train loss: 1.6487261056900024 | avg val loss: 1.692258358001709\n\n\n\nfashion_loss_df = pd.DataFrame(\n    [\n        [loss.item() for loss in fashion_results[\"train_loss\"]],\n        [loss.item() for loss in fashion_results[\"val_loss\"]]\n    ],\n).transpose().rename(columns={0: \"train_loss\", 1: \"val_loss\"})\n\n\nfashion_loss_df\n\n\n  \n    \n\n\n\n\n\n\ntrain_loss\nval_loss\n\n\n\n\n0\n1.930857\n1.909099\n\n\n1\n1.912644\n1.918055\n\n\n2\n1.887620\n1.848024\n\n\n3\n1.751529\n1.722522\n\n\n4\n1.717885\n1.715074\n\n\n5\n1.662122\n1.664416\n\n\n6\n1.657943\n1.657352\n\n\n7\n1.657977\n1.675686\n\n\n8\n1.649832\n1.648165\n\n\n9\n1.648726\n1.692258\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nfashion_loss_df.to_csv(\"./pytorch_fashion_loss_df.csv\", index=False)\n\nKalau mau menyamakan dengan modul, bisa download dari GitHub Pages ini: pytorch_fashion_loss_df.csv\n\npytorch_fashion_loss_df = pd.read_csv(\"./pytorch_fashion_loss_df.csv\")\n\n\npytorch_fashion_loss_df\n\n\n  \n    \n\n\n\n\n\n\ntrain_loss\nval_loss\n\n\n\n\n0\n1.930857\n1.909099\n\n\n1\n1.912644\n1.918055\n\n\n2\n1.887620\n1.848024\n\n\n3\n1.751529\n1.722522\n\n\n4\n1.717885\n1.715074\n\n\n5\n1.662122\n1.664416\n\n\n6\n1.657943\n1.657352\n\n\n7\n1.657977\n1.675686\n\n\n8\n1.649832\n1.648165\n\n\n9\n1.648726\n1.692258\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nplt.plot(pytorch_fashion_loss_df[\"train_loss\"], label = \"training loss\")\nplt.plot(pytorch_fashion_loss_df[\"val_loss\"], label = \"validation loss\")\nplt.xlabel(\"epoch\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nfashion_val_list = list(fashion_val_dataloader)\n\n\ntes_batch_gambar, tes_batch_label = fashion_val_list[123]\n\n\nprint(tes_batch_gambar.shape)\n\ntorch.Size([32, 1, 28, 28])\n\n\n\nprint(tes_batch_label.shape)\n\ntorch.Size([32])\n\n\n\ntes_gambar = tes_batch_gambar[0, :, :, :].to(device)\n\n\nprint(tes_gambar.shape)\n\ntorch.Size([1, 28, 28])\n\n\n\ntes_label = tes_batch_label[0]\n\n\nprint(tes_label)\nprint(nama_kelas[tes_label])\n\ntensor(3)\nDress\n\n\n\ny_pred = fashion_model(tes_gambar)\n\n\nprint(y_pred)\n\ntensor([[4.4959e-07, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nprint(torch.argmax(y_pred).item())\n\n3\n\n\n\n#@title Slider to look for some prediction examples {run: \"auto\"}\nbatch_idx = 123 #@param {type:\"slider\", min:0, max:9999, step:1}\npic_idx = 0 #@param {type:\"slider\", min:0, max:31, step:1}\n\nbatch_gambar, batch_label = fashion_val_list[batch_idx]\n\nsatu_gambar = batch_gambar[pic_idx].to(device)\nlabel_true_idx = batch_label[pic_idx].item()\nlabel_pred_idx = torch.argmax(fashion_model(satu_gambar)).item()\n\nplt.imshow(satu_gambar.cpu().squeeze(), cmap='gray')\nplt.title(\n    f\"Predicted class: {nama_kelas[label_pred_idx]}\\n\" +\n    f\"True class: {nama_kelas[label_true_idx]}\"\n)\nplt.axis('OFF')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\ntorch.save(fashion_model.state_dict(), \"./fashion_model_state.pth\")\n\n\n\n\n\nInternet\n\nhttps://paperswithcode.com/trends\nhttps://pytorch.org/docs/stable/index.html\n\nSumber belajar PyTorch, deep learning, atau semacamnya, untuk belajar lebih lanjut\n\nhttps://www.learnpytorch.io/\nBuku Dive into Deep Learning (biasa disebut D2L), utamanya menggunakan PyTorch: https://d2l.ai/\nSitus bernama “weights and biases” (wandb) menyediakan layanan pemantauan proses training: https://wandb.ai/site"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul9.html#mengenal-pytorch",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul9.html#mengenal-pytorch",
    "title": "Modul 9 Praktikum Sains Data: Pengantar PyTorch",
    "section": "",
    "text": "Tiap komputer bisa memiliki kekuatan yang berbeda, termasuk ada/tiadanya komponen yang bernama GPU.\nTiap komputer pasti punya yang namanya CPU atau Central Processing Unit, yang biasanya menjadi pusat segala komputasi di komputer itu, sesuai namanya.\nNamun, untuk perhitungan dengan matriks, tensor atau semacamnya, GPU atau Graphics Processing Unit lebih cepat. Perhitungan seperti itu biasa dilakukan untuk tampilan atau graphics ketika sedang bermain game, dan juga biasa dilakukan ketika berurusan dengan neural network.\nSehingga, daripada menggunakan CPU, ada baiknya menggunakan GPU, kalau ada.\nDi Google Colaboratory, di menu Runtime &gt; Change runtime type, di bagian hardware accelerator, kalian bisa mengubah setting, apakah ingin menggunakan CPU atau GPU. (Bahkan, ada juga TPU atau tensor processing unit yang sepertinya lebih dikhususkan lagi untuk komputasi dengan tensor.)\n\n\nApapun yang tersedia, tiap kali kita ingin menggunakan PyTorch, sebaiknya kita beritahu, mana yang ingin kita gunakan. Agar tidak berantakan, caranya bisa dengan kode berikut:\n\n# Setup device-agnostic code\nif torch.cuda.is_available():\n    device = \"cuda\" # NVIDIA GPU\nelif torch.backends.mps.is_available():\n    device = \"mps\" # Apple GPU\nelse:\n    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n\nprint(f\"Using device: {device}\")\n\nUsing device: cuda\n\n\nSumber kode: https://www.learnpytorch.io/pytorch_cheatsheet/#device-agnostic-code-using-pytorch-on-cpu-gpu-or-mps\nOutput nya akan sesuai dengan pilihan terbaik yang ada, antara CPU atau GPU.\nKode di atas sebenarnya hanya menyimpan pilihan tersebut sebagai string ke dalam variabel device. Namun, variabel ini nantinya akan digunakan selama berurusan dengan PyTorch.\nSehingga, apabila kita ingin ganti dari CPU ke GPU atau sebaliknya, kita tinggal mengubah isi variabel device ini (misalnya menggunakan kode di atas), tidak perlu mengubah kode PyTorch yang sudah kita buat.\nDengan demikian, kode PyTorch yang sudah kita buat menjadi tidak tergantung device yang digunakan (apakah CPU atau GPU), atau disebut device-agnostic.\n\n\n\nSeperti di TensorFlow, di PyTorch juga ada tensor. Cara membuatnya adalah dengan torch.tensor\nContohnya, skalar:\n\ntensor0 = torch.tensor(1.5)\n\n\nprint(tensor0)\n\ntensor(1.5000)\n\n\n\nprint(type(tensor0))\n\n&lt;class 'torch.Tensor'&gt;\n\n\nKita bisa melihat dimensinya (rank/dimensi tensor) melalui .ndim\n\nprint(tensor0.ndim)\n\n0\n\n\nTipe datanya berupa torch.tensor tapi kita bisa memperoleh nilai skalarnya dengan .item()\n\ntensor0.item()\n\n1.5\n\n\n\ntype(tensor0.item())\n\nfloat\n\n\nContoh lain, array/vektor:\n\ntensor1 = torch.tensor([2.31, 4.567, 8.9])\n\n\nprint(tensor1)\n\ntensor([2.3100, 4.5670, 8.9000])\n\n\n\nprint(tensor1.ndim)\n\n1\n\n\nSelain dimensi tensor, ada juga .shape yang di sini melambangkan ukuran array/vektor, seperti .shape di numpy\n\nprint(tensor1.shape)\n\ntorch.Size([3])\n\n\nNilai suatu elemen di tensor juga bisa diubah:\n\ntensor1[0] = 52.5\n\n\nprint(tensor1)\n\ntensor([52.5000,  4.5670,  8.9000])\n\n\nAda juga tipe data:\n\nprint(tensor1.dtype)\n\ntorch.float32\n\n\nSeperti tensor di TensorFlow, tensor di PyTorch juga biasanya menggunakan bilangan float yang 32-bit daripada 64-bit.\nContoh lagi, matriks:\n\nmat1 = torch.tensor([\n    [1, 2.718, 3.14],\n    [4, 5, 6.28]\n])\n\n\nprint(mat1)\n\ntensor([[1.0000, 2.7180, 3.1400],\n        [4.0000, 5.0000, 6.2800]])\n\n\n\nprint(mat1.ndim)\n\n2\n\n\n\nprint(mat1.shape)\n\ntorch.Size([2, 3])\n\n\nKita bisa buat matriks kedua, lalu mengalikannya dengan perkalian matriks menggunakan torch.matmul\n\nmat2 = torch.tensor([\n    [9, 8],\n    [7, 6],\n    [5, 4.3]\n])\n\n\nprint(mat2.ndim)\nprint(mat2.shape)\nprint(mat2.dtype)\n\n2\ntorch.Size([3, 2])\ntorch.float32\n\n\n\nmat3 = torch.matmul(mat1, mat2)\n\n\nprint(mat3)\n\ntensor([[ 43.7260,  37.8100],\n        [102.4000,  89.0040]])\n\n\nMatriks juga bisa ditranspos dengan .T\n\nmat4 = mat3.T\nprint(mat4)\n\ntensor([[ 43.7260, 102.4000],\n        [ 37.8100,  89.0040]])\n\n\n\n\n\nKita bisa mengonversi tensor PyTorch menjadi array numpy dan sebaliknya:\n\n.numpy() untuk mengubah suatu tensor PyTorch menjadi array numpy\ntorch.from_numpy(...) untuk mengubah suatu array numpy menjadi tensor PyTorch\n\n\narr5 = mat4.numpy()\nprint(arr5)\nprint(type(arr5))\nprint(arr5.dtype)\n\n[[ 43.725998 102.4     ]\n [ 37.809998  89.004   ]]\n&lt;class 'numpy.ndarray'&gt;\nfloat32\n\n\n\nmat6 = torch.from_numpy(arr5)\nprint(mat6)\nprint(type(mat6))\nprint(mat6.dtype)\n\ntensor([[ 43.7260, 102.4000],\n        [ 37.8100,  89.0040]])\n&lt;class 'torch.Tensor'&gt;\ntorch.float32\n\n\n\n\n\nKita bisa membuat tensor berisi satu semua, atau nol semua, atau nilai random, dengan ukuran size yang bisa kita tentukan\n\nx = torch.ones(size = (3,4))\nprint(x)\n\ntensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.]])\n\n\n\nx = torch.zeros(size = (3,4))\nprint(x)\n\ntensor([[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]])\n\n\n\nx = torch.rand(size = (3,4))\nprint(x)\n\ntensor([[0.0698, 0.2004, 0.3279, 0.2525],\n        [0.2461, 0.4263, 0.4870, 0.4371],\n        [0.9545, 0.7487, 0.3990, 0.0412]])\n\n\ntorch.rand memilih nilai secara random dari distribusi uniform pada interval \\([0,1)\\)\nUntuk memilih nilai secara random dari distribusi normal (dengan \\(\\mu = 0\\) dan \\(\\sigma = 1\\)), gunakan torch.randn\n\nx = torch.randn(size = (3,4))\nprint(x)\n\ntensor([[ 1.5820, -0.1806,  0.1820, -0.6891],\n        [ 1.2161, -0.5755, -0.5172, -0.7454],\n        [ 0.3047, -0.5932, -0.3343, -1.1461]])\n\n\n\n\n\nSecara umum, operasi tensor di PyTorch memang mirip dengan array di numpy, sebagaimana operasi tensor di TensorFlow juga mirip dengan array di numpy.\n\na = 4 * torch.ones((2, 2))\nprint(a)\n\ntensor([[4., 4.],\n        [4., 4.]])\n\n\n\nb = torch.square(a)\nprint(b)\n\ntensor([[16., 16.],\n        [16., 16.]])\n\n\n\nc = torch.sqrt(a)\nprint(c)\n\ntensor([[2., 2.],\n        [2., 2.]])\n\n\n\nd = b + c\nprint(d)\n\ntensor([[18., 18.],\n        [18., 18.]])\n\n\n\n# perkalian matriks\ne = torch.matmul(a, c)\nprint(e)\n\ntensor([[16., 16.],\n        [16., 16.]])\n\n\n\n# perkalian per elemen\ne *= d\nprint(e)\n\ntensor([[288., 288.],\n        [288., 288.]])\n\n\n\n# penjumlahan per elemen\nf = e + 2\nprint(f)\n\ntensor([[290., 290.],\n        [290., 290.]])\n\n\n\n\n\nSebagaimana ada automatic differentiation atau autodiff di TensorFlow, ada juga autograd di PyTorch. Namun, syntax nya cukup berbeda.\nCaranya, inputnya kita jadikan tensor dengan parameter requires_grad=True, lalu kita operasikan (misal dengan fungsi f) dan menghasilkan tensor baru, lalu di tensor baru ini kita panggil .backward() agar turunan f dihitung dan disimpan di variabel input .grad\nContohnya, turunan \\(x^3\\) terhadap \\(x\\) di \\(x=4\\) adalah \\(3(4)^2 = 48\\).\n\n# siapkan input, dengan requires_grad=True\nx = torch.tensor(4.0, requires_grad=True)\n\n# hitung fungsi F\nF = x**3\n\n# jalankan perhitungan turunan F (terhadap input)\nF.backward()\n\n# tampilkan turunan yang tersimpan di input .grad\nprint(x.grad)\n\ntensor(48.)\n\n\nNama method nya adalah .backward() dan memang digunakan di backward pass (akan kita lihat nanti).\nContoh lain, turunan \\(3x^3 - y^2\\) terhadap \\(x\\) dengan \\(x=2\\) adalah \\(9(2)^2 = 36\\), dan turunannya terhadap \\(y\\) dengan \\(y=6\\) adalah \\(-2(6) = -12\\)\n\nx = torch.tensor(2.0, requires_grad=True)\ny = torch.tensor(6.0, requires_grad=True)\n\nF = 3 * x**3 - y**2\n\nF.backward()\n\nprint(x.grad)\nprint(y.grad)\n\ntensor(36.)\ntensor(-12.)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul9.html#klasifikasi-biner-dengan-perceptron",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul9.html#klasifikasi-biner-dengan-perceptron",
    "title": "Modul 9 Praktikum Sains Data: Pengantar PyTorch",
    "section": "",
    "text": "Untuk model pertama kita, mari kita coba buat kembali model perceptron untuk klasifikasi biner yang pernah kita buat di Modul 7, dengan dataset titik_negatif_positif.csv yang sama, bisa kalian download dari GitHub Pages ini: titik_negatif_positif.csv\nKita buka datasetnya, jangan lupa dengan dtype=\"float32\" karena itulah tipe data yang biasa digunakan oleh PyTorch, seperti TensorFlow:\n\ntitik_df = pd.read_csv(\"./titik_negatif_positif.csv\", dtype=\"float32\")\n\n\ntitik_df\n\n\n\n\n\n\n\n\nx\ny\nkelas\n\n\n\n\n0\n1.173375\n4.570637\n0.0\n\n\n1\n0.195961\n3.504604\n0.0\n\n\n2\n0.121400\n2.163783\n0.0\n\n\n3\n-1.170182\n3.882771\n0.0\n\n\n4\n-0.424403\n0.534641\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n2.423160\n-0.337196\n1.0\n\n\n1996\n1.949836\n-0.627813\n1.0\n\n\n1997\n2.109928\n-0.382492\n1.0\n\n\n1998\n4.178664\n0.486168\n1.0\n\n\n1999\n2.326363\n1.228249\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\nMemisahkan antara inputs (prediktor) dan targets (variabel target):\n\ntitik_inputs_df = titik_df.drop(columns=[\"kelas\"])\ntitik_targets_df = titik_df[[\"kelas\"]]\n\n\ntitik_inputs_df\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n1.173375\n4.570637\n\n\n1\n0.195961\n3.504604\n\n\n2\n0.121400\n2.163783\n\n\n3\n-1.170182\n3.882771\n\n\n4\n-0.424403\n0.534641\n\n\n...\n...\n...\n\n\n1995\n2.423160\n-0.337196\n\n\n1996\n1.949836\n-0.627813\n\n\n1997\n2.109928\n-0.382492\n\n\n1998\n4.178664\n0.486168\n\n\n1999\n2.326363\n1.228249\n\n\n\n\n2000 rows × 2 columns\n\n\n\n\ntitik_targets_df\n\n\n\n\n\n\n\n\nkelas\n\n\n\n\n0\n0.0\n\n\n1\n0.0\n\n\n2\n0.0\n\n\n3\n0.0\n\n\n4\n0.0\n\n\n...\n...\n\n\n1995\n1.0\n\n\n1996\n1.0\n\n\n1997\n1.0\n\n\n1998\n1.0\n\n\n1999\n1.0\n\n\n\n\n2000 rows × 1 columns\n\n\n\nMengubahnya menjadi array numpy:\n\ntitik_inputs_arr = titik_inputs_df.to_numpy()\ntitik_targets_arr = titik_targets_df.to_numpy()\n\nKemudian mengubahnya menjadi tensor PyTorch:\n\ntitik_inputs_tensor = torch.from_numpy(titik_inputs_arr)\ntitik_targets_tensor = torch.from_numpy(titik_targets_arr)\n\nTujuan mengubah dari DataFrame menjadi tensor, tentunya supaya bisa diproses dengan PyTorch.\nKita bisa periksa, bentuknya sesuai:\n\nprint(titik_inputs_tensor)\n\ntensor([[ 1.1734,  4.5706],\n        [ 0.1960,  3.5046],\n        [ 0.1214,  2.1638],\n        ...,\n        [ 2.1099, -0.3825],\n        [ 4.1787,  0.4862],\n        [ 2.3264,  1.2282]])\n\n\n\nprint(titik_targets_tensor)\n\ntensor([[0.],\n        [0.],\n        [0.],\n        ...,\n        [1.],\n        [1.],\n        [1.]])\n\n\nKemudian, kita bisa melakukan train-validation-test split, misalnya dengan rasio 80:10:10\n\nfrom sklearn.model_selection import train_test_split\n\n\n# data utuh menjadi data train 80% dan data \"test\" 20%\ntitik_X_train, titik_X_test, titik_y_train, titik_y_test = train_test_split(\n    titik_inputs_tensor, titik_targets_tensor, test_size=0.2, random_state=42\n)\n\n# data \"test\" dibagi dua, menjadi data validation dan data test sesungguhnya\ntitik_X_val, titik_X_test, titik_y_val, titik_y_test = train_test_split(\n    titik_X_test, titik_y_test, test_size=0.5, random_state=42\n)\n\nKita bisa periksa ukurannya, rasionya sudah sesuai yang kita tetapkan:\n\nprint(titik_X_train.shape)\nprint(titik_X_val.shape)\nprint(titik_X_test.shape)\n\ntorch.Size([1600, 2])\ntorch.Size([200, 2])\ntorch.Size([200, 2])\n\n\nSebelum dataset kita benar-benar siap untuk diproses dengan PyTorch, ada dua hal yang perlu kita lakukan:\n\nmengubahnya menjadi objek Dataset dengan TensorDataset\nDataset di sini adalah format dataset umum yang dikenal oleh PyTorch.\nmengubah objek Dataset menjadi objek DataLoader\nDataLoader membuat objek Dataset menjadi “iterable” yaitu bisa diiterasikan dengan for loop, agar bisa digunakan dalam proses training maupun testing.\n\nBaik TensorDataset maupun DataLoader bisa kita import dari torch.utils.data\n\nfrom torch.utils.data import TensorDataset, DataLoader\n\nMasing-masing dari data train, data validation, dan data test bisa kita ubah menjadi objek Dataset dengan menentukan mana prediktor dan mana target:\n\ntitik_train_dataset = TensorDataset(titik_X_train, titik_y_train)\ntitik_val_dataset = TensorDataset(titik_X_val, titik_y_val)\ntitik_test_dataset = TensorDataset(titik_X_test, titik_y_test)\n\nKemudian, masing-masing bisa kita ubah menjadi DataLoader, sekasligus menentukan batch size, dan juga menentukan apakah perlu ada shuffling di tiap epoch (biasanya dilakukan di data train untuk mengurangi overfitting):\n\ntitik_train_dataloader = DataLoader(titik_train_dataset, batch_size=32, shuffle=True)\ntitik_val_dataloader = DataLoader(titik_val_dataset, batch_size=32, shuffle=False)\ntitik_test_dataloader = DataLoader(titik_test_dataset, batch_size=32, shuffle=False)\n\n\n\n\nIngat bahwa perceptron yang ingin kita susun hanya terdiri dari\n\ninput layer dengan dua neuron,\ntidak ada hidden layer,\noutput layer dengan satu neuron dan fungsi aktivasi sigmoid\n\nSehingga matriks bobot yang sesuai berukuran \\(2 \\times 1\\), dan vektor bias yang sesuai berukuran \\(1 \\times 1\\).\nDi PyTorch, tiap model berupa class dengan ketentuan:\n\nmeng-inherit dari torch.nn.Module (yaitu base class untuk semua model PyTorch)\nbaris pertama di constructor __init__ adalah\nsuper().__init__()\nharus mendefinisikan forward() untuk forward pass\nkomponen/variabel/atribut/parameter yang diperlukan biasanya didefinisikan di constructor\nCatatan: parameter biasa didefinisikan dengan torch.nn.Parameter daripada torch.tensor\n\nIni cukup mirip dengan subclassing API di Keras, yang meng-inherit dari keras.Model dan harus mendefinisikan call() untuk forward pass.\nMari kita susun perceptron kita, yang memiliki matriks bobot, vektor bias, dan fungsi aktivasi sigmoid:\n\nclass MyPerceptron(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.weights = torch.nn.Parameter(\n            torch.randn(size = (2, 1), dtype = torch.float32),\n            requires_grad=True # agar autgrad aktif\n        )\n\n        self.bias = torch.nn.Parameter(\n            torch.randn(size = (1,), dtype = torch.float32),\n            requires_grad=True\n        )\n\n    def forward(self, x):\n        return torch.sigmoid(\n            torch.matmul(x, self.weights) + self.bias\n        )\n\nKita bisa buat suatu instance atau objek dari class di atas:\n\npisah_titik = MyPerceptron()\n\nIni adalah model yang siap di-train. Sebelum training, kita bisa memeriksa parameter model (saat ini masih random sesuai torch.randn):\n\nlist(pisah_titik.parameters())\n\n[Parameter containing:\n tensor([[-0.8412],\n         [-1.1300]], requires_grad=True),\n Parameter containing:\n tensor([-0.0640], requires_grad=True)]\n\n\nMirip, ada juga yang namanya .state_dict()\n\npisah_titik.state_dict()\n\nOrderedDict([('weights',\n              tensor([[-0.8412],\n                      [-1.1300]])),\n             ('bias', tensor([-0.0640]))])\n\n\n\n\n\nUntuk klasifikasi, loss function yang biasa digunakan adalah crossentropy loss, atau mungkin lebih spesifiknya binary crossentropy loss, yang disebut torch.nn.BCELoss di PyTorch. Kita bisa menyiapkannya sebagai objek.\n\ntitik_loss_fn = torch.nn.BCELoss()\n\nSerupa, optimizer juga disiapkan sebagai objek, misalnya torch.optim.SGD untuk SGD (stochastic gradient descent):\n\ntitik_opt = torch.optim.SGD(params=pisah_titik.parameters(), # merujuk ke parameter model\n                            lr=0.01) # learning rate\n\n\n\n\nMungkin agak mengejutkan: di PyTorch, kita dibebaskan untuk membuat training loop sendiri. Artinya, tidak ada fungsi .fit() yang tinggal kita panggil; kita perlu menyusun for loop sendiri, seperti di Modul 7 :)\nIngat kembali, tiap iterasi (yaitu per batch) di proses training melibatkan:\n\nForward pass: menghitung nilai output (hasil prediksi) dari input (batch).\nMenghitung loss antara hasil prediksi dan nilai sebenarnya\nBackpropagation: menghitung gradien dari loss terhadap tiap parameter\nUpdate optimizer: memperbarui nilai parameter berdasarkan gradien dari loss, menggunakan rumus atau optimizer yang dipilih\n\nIngat juga, selain training, ada juga yang namanya validation (atau terkadang disebut testing di beberapa sumber). Tahap validation ini menguji model di akhir tiap epoch, setelah semua batch melalui proses training. Langkahnya terdiri dari:\n\nForward pass\nMenghitung loss dan/atau accuracy antara hasil prediksi dan nilai sebenarnya\n\nPerhatikan bahwa validation juga bisa dilakukan per batch, sehingga kedua langkah di atas dilakukan per batch. Kalau begitu, nilai akhir untuk loss dan/atau accuracy menjadi rata-rata dari nilainya di tiap batch.\nPenjelasan di atas menjadi kode PyTorch sebagai berikut:\n\nepochs = 10\n\ntrain_loss_list = []\nval_loss_list = []\n\n# untuk tiap epoch,\nfor epoch in range(epochs):\n    # siapkan model untuk tahap training\n    pisah_titik.to(device)\n    pisah_titik.train()\n    sum_train_loss = 0\n\n    # untuk tiap batch,\n    for X, y in titik_train_dataloader:\n        X = X.to(device)\n        y = y.to(device)\n\n        # Forward pass\n        y_pred = pisah_titik(X)\n\n        # Hitung loss\n        loss = titik_loss_fn(y_pred, y)\n        sum_train_loss += loss\n\n        # \"Optimizer zero grad\": nolkan dulu hasil hitung gradien\n        titik_opt.zero_grad()\n\n        # Backpropagation\n        loss.backward()\n\n        # Update optimizer, juga disebut \"optimizer step\"\n        titik_opt.step()\n\n    # hitung rata-rata train loss berdasarkan banyaknya batch\n    avg_train_loss = sum_train_loss / len(titik_train_dataloader)\n\n    # simpan train loss\n    train_loss_list.append(avg_train_loss)\n\n    # siapkan model untuk tahap validaion\n    pisah_titik.to(device)\n    pisah_titik.eval()\n    sum_val_loss = 0\n\n    # selalu digunakan ketika hendak testing\n    with torch.inference_mode():\n        # untuk tiap batch,\n        for X, y in titik_val_dataloader:\n            X = X.to(device)\n            y = y.to(device)\n\n            # Forward pass\n            y_pred = pisah_titik(X)\n\n            # Hitung loss\n            sum_val_loss += titik_loss_fn(y_pred, y)\n\n        # hitung rata-rata val loss berdasarkan banyaknya batch\n        avg_val_loss = sum_val_loss / len(titik_val_dataloader)\n\n        # simpan val loss\n        val_loss_list.append(avg_val_loss)\n\n    # tampilkan train loss dan val loss untuk epoch ini\n    print(f\"Epoch: {epoch} | avg train loss: {avg_train_loss} | avg val loss: {avg_val_loss}\")\n\nEpoch: 0 | avg train loss: 1.0023550987243652 | avg val loss: 0.6549612879753113\nEpoch: 1 | avg train loss: 0.424757719039917 | avg val loss: 0.3022421300411224\nEpoch: 2 | avg train loss: 0.2212503552436828 | avg val loss: 0.1808699667453766\nEpoch: 3 | avg train loss: 0.1497089713811874 | avg val loss: 0.1308697611093521\nEpoch: 4 | avg train loss: 0.1175468564033508 | avg val loss: 0.1053687334060669\nEpoch: 5 | avg train loss: 0.0995666906237602 | avg val loss: 0.0898655503988266\nEpoch: 6 | avg train loss: 0.0879358351230621 | avg val loss: 0.0794256925582885\nEpoch: 7 | avg train loss: 0.0796592533588409 | avg val loss: 0.0717914551496505\nEpoch: 8 | avg train loss: 0.0733261257410049 | avg val loss: 0.0658656656742096\nEpoch: 9 | avg train loss: 0.0682612806558609 | avg val loss: 0.061109509319067\n\n\nPerhatikan bahwa hasil loss di tiap epoch sudah kita simpan ke dalam list.\n\nprint(train_loss_list)\nprint(val_loss_list)\n\n[tensor(1.0024, grad_fn=&lt;DivBackward0&gt;), tensor(0.4248, grad_fn=&lt;DivBackward0&gt;), tensor(0.2213, grad_fn=&lt;DivBackward0&gt;), tensor(0.1497, grad_fn=&lt;DivBackward0&gt;), tensor(0.1175, grad_fn=&lt;DivBackward0&gt;), tensor(0.0996, grad_fn=&lt;DivBackward0&gt;), tensor(0.0879, grad_fn=&lt;DivBackward0&gt;), tensor(0.0797, grad_fn=&lt;DivBackward0&gt;), tensor(0.0733, grad_fn=&lt;DivBackward0&gt;), tensor(0.0683, grad_fn=&lt;DivBackward0&gt;)]\n[tensor(0.6550), tensor(0.3022), tensor(0.1809), tensor(0.1309), tensor(0.1054), tensor(0.0899), tensor(0.0794), tensor(0.0718), tensor(0.0659), tensor(0.0611)]\n\n\nMaka, kita bisa ubah jadi DataFrame lalu menyimpannya sebagai CSV:\n\ntitik_loss_df = pd.DataFrame(\n    [\n        [loss.item() for loss in train_loss_list],\n        [loss.item() for loss in val_loss_list]\n    ],\n).transpose().rename(columns={0: \"train_loss\", 1: \"val_loss\"})\n\n\ntitik_loss_df\n\n\n\n\n\n\n\n\ntrain_loss\nval_loss\n\n\n\n\n0\n1.002355\n0.654961\n\n\n1\n0.424758\n0.302242\n\n\n2\n0.221250\n0.180870\n\n\n3\n0.149709\n0.130870\n\n\n4\n0.117547\n0.105369\n\n\n5\n0.099567\n0.089866\n\n\n6\n0.087936\n0.079426\n\n\n7\n0.079659\n0.071791\n\n\n8\n0.073326\n0.065866\n\n\n9\n0.068261\n0.061110\n\n\n\n\n\n\n\n\ntitik_loss_df.to_csv(\"./pytorch_titik_loss_df.csv\", index=False)\n\nKalau mau menyamakan dengan modul, kalian bisa download melalui GitHub Pages ini: pytorch_titik_loss_df.csv\nKita bisa import kembali:\n\npytorch_titik_loss_df = pd.read_csv(\"./pytorch_titik_loss_df.csv\")\n\nLalu kita bisa plot:\n\nplt.plot(pytorch_titik_loss_df[\"train_loss\"], label = \"training loss\")\nplt.plot(pytorch_titik_loss_df[\"val_loss\"], label = \"validation loss\")\nplt.xlabel(\"epoch\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIngat kembali, kita bisa melihat parameter model dengan .state_dict()\n\npisah_titik.state_dict()\n\nOrderedDict([('weights',\n              tensor([[ 0.9372],\n                      [-1.2340]])),\n             ('bias', tensor([0.3439]))])\n\n\nKita bisa menyimpan parameter model ke dalam file berakhiran .pth menggunakan torch.save\n\ntorch.save(pisah_titik.state_dict(), \"./pisah_titik_state.pth\")\n\nApabila ingin load kembali, kita perlu membuat instance terlebih dahulu…\n\npisah_titik2 = MyPerceptron()\n\nBarulah kita panggil .load_state_dict(torch.load(PATH)) seperti berikut:\n\npisah_titik2.load_state_dict(torch.load(\"./pisah_titik_state.pth\"))\n\n&lt;All keys matched successfully&gt;\n\n\nParameternya akan sama:\n\npisah_titik2.state_dict()\n\nOrderedDict([('weights',\n              tensor([[ 0.9372],\n                      [-1.2340]])),\n             ('bias', tensor([0.3439]))])\n\n\n\n\n\n\nclass MyPerceptron_v2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # satu dense layer dengan fungsi aktivasi linier\n        self.linear_layer = torch.nn.Linear(in_features=2, out_features=1)\n\n        # fungsi aktivasi sigmoid\n        self.sigmoid = torch.nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.linear_layer(x)\n        x = self.sigmoid(x)\n        return x\n\n\nclass MyPerceptron_v3(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # perhatikan: inputnya bukan berupa list, langsung saja tiap layer\n        self.layer = torch.nn.Sequential(\n            torch.nn.Linear(in_features=2, out_features=1),\n            torch.nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.layer(x)\n        return x"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul9.html#fungsi-train-step-dan-val-step",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul9.html#fungsi-train-step-dan-val-step",
    "title": "Modul 9 Praktikum Sains Data: Pengantar PyTorch",
    "section": "",
    "text": "Training loop kita terdiri dari dua bagian utama, yaitu tahap training dan tahap validation. Kita bisa menyusun training loop yang telah kita buat dengan lebih rapi, dengan memasukkan tiap tahap ke dalam fungsi yang nantinya tinggal dipanggil. Modifikasi yang dilakukan:\n\npisah_titik menjadi model\ntitik_train_dataloader menjadi train_dataloader\ntitik_val_dataloader menjadi val_dataloader\ntitik_loss_fn menjadi loss_fn\ntitik_opt menjadi optimizer\n\n\ndef train_step(model, train_dataloader, loss_fn, optimizer, device=device):\n    # siapkan model untuk tahap training\n    model.to(device)\n    model.train()\n    sum_train_loss = 0\n\n    # untuk tiap batch,\n    for X, y in train_dataloader:\n        X = X.to(device)\n        y = y.to(device)\n\n        # Forward pass\n        y_pred = model(X)\n\n        # Hitung loss\n        loss = loss_fn(y_pred, y)\n        sum_train_loss += loss\n\n        # \"Optimizer zero grad\": nolkan dulu hasil hitung gradien\n        optimizer.zero_grad()\n\n        # Backpropagation\n        loss.backward()\n\n        # Update optimizer, juga disebut \"optimizer step\"\n        optimizer.step()\n\n    # hitung rata-rata train loss berdasarkan banyaknya batch\n    avg_train_loss = sum_train_loss / len(train_dataloader)\n\n    # sedikit modifikasi: return train loss\n    return avg_train_loss\n\n\ndef val_step(model, val_dataloader, loss_fn, device=device):\n    # siapkan model untuk tahap validaion\n    model.to(device)\n    model.eval()\n    sum_val_loss = 0\n\n    # selalu digunakan ketika hendak testing\n    with torch.inference_mode():\n        # untuk tiap batch,\n        for X, y in val_dataloader:\n            X = X.to(device)\n            y = y.to(device)\n\n            # Forward pass\n            y_pred = model(X)\n\n            # Hitung loss\n            sum_val_loss += loss_fn(y_pred, y)\n\n        # hitung rata-rata val loss berdasarkan banyaknya batch\n        avg_val_loss = sum_val_loss / len(val_dataloader)\n\n        # sedikit modifikasi: return val loss\n        return avg_val_loss\n\nSetelah mendefinisikan kedua fungsi di atas, training loop menjadi lebih sederhana:\n\nepochs = 10\n\ntrain_loss_list = []\nval_loss_list = []\n\n# untuk tiap epoch,\nfor epoch in range(epochs):\n    # training step\n    avg_train_loss = train_step(\n        model = pisah_titik,\n        train_dataloader = titik_train_dataloader,\n        loss_fn = titik_loss_fn,\n        optimizer = titik_opt,\n        device = device\n    )\n    train_loss_list.append(avg_train_loss)\n\n    # validation step\n    avg_val_loss = val_step(\n        model = pisah_titik,\n        val_dataloader = titik_val_dataloader,\n        loss_fn = titik_loss_fn,\n        device = device\n    )\n    val_loss_list.append(avg_val_loss)\n\n    # tampilkan train loss dan val loss untuk epoch ini\n    print(f\"Epoch: {epoch} | avg train loss: {avg_train_loss} | avg val loss: {avg_val_loss}\")\n\nBahkan, training loop secara keseluruhan bisa kita jadikan fungsi juga.\n\ndef training_loop(\n        model, train_dataloader, val_dataloader,\n        loss_fn, optimizer, epochs, device = device\n    ):\n\n    train_loss_list = []\n    val_loss_list = []\n\n    # untuk tiap epoch,\n    for epoch in range(epochs):\n        # training step\n        avg_train_loss = train_step(\n            model, train_dataloader,\n            loss_fn, optimizer, device=device\n        )\n        train_loss_list.append(avg_train_loss)\n\n        # validation step\n        avg_val_loss = val_step(\n            model, val_dataloader,\n            loss_fn, device=device\n        )\n        val_loss_list.append(avg_val_loss)\n\n        # tampilkan train loss dan val loss untuk epoch ini\n        print(f\"Epoch: {epoch} | avg train loss: {avg_train_loss} | avg val loss: {avg_val_loss}\")\n\n    # menyimpan kedua list ke dalam dictionary yang kemudian di-return\n    results_dict = {\n        \"train_loss\": [loss.item() for loss in train_loss_list],\n        \"val_loss\": [loss.item() for loss in val_loss_list]\n    }\n    return results_dict"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul9.html#klasifikasi-gambar",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul9.html#klasifikasi-gambar",
    "title": "Modul 9 Praktikum Sains Data: Pengantar PyTorch",
    "section": "",
    "text": "Sekarang kita akan mencoba melakukan klasifikasi gambar dengan dataset Fashion MNIST seperti di pertemuan sebelumnya.\n\n\nLangkah pertama adalah menyiapkan data, yaitu menyiapkan objek Dataset, yang kemudian diubah menjadi DataLoader. Untungnya, objek Dataset untuk Fashion MNIST sudah tersedia di torchvision.datasets.FashionMNIST sehingga tinggal kita download seperti berikut.\nPerkiraan storage yang dibutuhkan: 90 MB\nApabila download di laptop kalian terlalu pelan, silakan gunakan Google Colaboratory saja, selesai kurang dari 30 detik\n\nfashion_train = torchvision.datasets.FashionMNIST(\n    root = \"./fashion_data\", # folder tempat download\n    train = True, # data training\n    download = True, # karena belum ada\n    # agar file gambar otomatis diubah menjadi tensor\n    transform = torchvision.transforms.ToTensor()\n)\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./fashion_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\nExtracting ./fashion_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./fashion_data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./fashion_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\nExtracting ./fashion_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./fashion_data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./fashion_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\nExtracting ./fashion_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./fashion_data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./fashion_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\nExtracting ./fashion_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./fashion_data/FashionMNIST/raw\n\n\n\n100%|██████████| 26421880/26421880 [00:06&lt;00:00, 3856770.39it/s]\n100%|██████████| 29515/29515 [00:00&lt;00:00, 147617.02it/s]\n100%|██████████| 4422102/4422102 [00:01&lt;00:00, 2747505.87it/s]\n100%|██████████| 5148/5148 [00:00&lt;00:00, 5877048.72it/s]\n\n\n\nfashion_val = torchvision.datasets.FashionMNIST(\n    root = \"./fashion_data\", # folder yang sama untuk tempat download\n    train = False, # bukan data training\n    download = True,\n    transform = torchvision.transforms.ToTensor()\n)\n\nBanyaknya baris di data training dan data validation\n\nprint(len(fashion_train.data), len(fashion_train.targets))\n\n60000 60000\n\n\n\nprint(len(fashion_val.data), len(fashion_val.targets))\n\n10000 10000\n\n\nKelas-kelas:\n\nnama_kelas = fashion_train.classes\nprint(nama_kelas)\n\n['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\n\nKita bisa lihat salah satu gambarnya:\n\n#@title Slider to look for some image examples {run: \"auto\"}\nidx = 21402 #@param {type:\"slider\", min:0, max:49999, step:1}\n\nimage, label = fashion_train[idx]\nplt.imshow(image.squeeze(), cmap='gray')\nplt.title(nama_kelas[label])\nplt.axis('OFF')\nplt.show()\n\n\n\n\n\n\n\n\nSedikit berbeda dengan pertemuan sebelumnya, kali ini kita gunakan .squeeze() karena gambar yang diberikan berukuran 1 x 28 x 28 (yaitu dengan satu color channel: hitam-putih) daripada 28 x 28, sehingga perlu diubah menjadi 28 x 28.\nJangan lupa menyiapkan DataLoader\n\nBATCH_SIZE = 32\n\nfashion_train_dataloader = DataLoader(\n    fashion_train,\n    batch_size = BATCH_SIZE,\n    shuffle = True\n)\n\nfashion_val_dataloader = DataLoader(\n    fashion_val,\n    batch_size = BATCH_SIZE,\n    shuffle = False\n)\n\n\n\n\n\nclass ModelFashionMNIST(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.layer_stack = torch.nn.Sequential(\n            torch.nn.Flatten(),\n            torch.nn.Linear(in_features=784, out_features=15),\n            torch.nn.ReLU(),\n            torch.nn.Linear(in_features=15, out_features=10),\n            torch.nn.Softmax(dim=1)\n        )\n\n    def forward(self, x):\n        x = self.layer_stack(x)\n        return x\n\n\nfashion_model = ModelFashionMNIST()\n\n\n\n\n\nfashion_loss_fn = torch.nn.CrossEntropyLoss()\nfashion_opt = torch.optim.Adam(params=fashion_model.parameters(),\n                               lr=0.01)\n\n\n\n\n\nfashion_results = training_loop(\n    fashion_model, fashion_train_dataloader, fashion_val_dataloader,\n    fashion_loss_fn, fashion_opt,\n    epochs = 10,\n    device = device\n)\n\nEpoch: 0 | avg train loss: 1.9308573007583618 | avg val loss: 1.9090994596481323\nEpoch: 1 | avg train loss: 1.9126436710357666 | avg val loss: 1.9180550575256348\nEpoch: 2 | avg train loss: 1.8876198530197144 | avg val loss: 1.8480236530303955\nEpoch: 3 | avg train loss: 1.7515285015106201 | avg val loss: 1.722522497177124\nEpoch: 4 | avg train loss: 1.7178850173950195 | avg val loss: 1.715074062347412\nEpoch: 5 | avg train loss: 1.6621224880218506 | avg val loss: 1.6644155979156494\nEpoch: 6 | avg train loss: 1.6579434871673584 | avg val loss: 1.6573517322540283\nEpoch: 7 | avg train loss: 1.6579766273498535 | avg val loss: 1.675686240196228\nEpoch: 8 | avg train loss: 1.6498321294784546 | avg val loss: 1.6481648683547974\nEpoch: 9 | avg train loss: 1.6487261056900024 | avg val loss: 1.692258358001709\n\n\n\nfashion_loss_df = pd.DataFrame(\n    [\n        [loss.item() for loss in fashion_results[\"train_loss\"]],\n        [loss.item() for loss in fashion_results[\"val_loss\"]]\n    ],\n).transpose().rename(columns={0: \"train_loss\", 1: \"val_loss\"})\n\n\nfashion_loss_df\n\n\n  \n    \n\n\n\n\n\n\ntrain_loss\nval_loss\n\n\n\n\n0\n1.930857\n1.909099\n\n\n1\n1.912644\n1.918055\n\n\n2\n1.887620\n1.848024\n\n\n3\n1.751529\n1.722522\n\n\n4\n1.717885\n1.715074\n\n\n5\n1.662122\n1.664416\n\n\n6\n1.657943\n1.657352\n\n\n7\n1.657977\n1.675686\n\n\n8\n1.649832\n1.648165\n\n\n9\n1.648726\n1.692258\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nfashion_loss_df.to_csv(\"./pytorch_fashion_loss_df.csv\", index=False)\n\nKalau mau menyamakan dengan modul, bisa download dari GitHub Pages ini: pytorch_fashion_loss_df.csv\n\npytorch_fashion_loss_df = pd.read_csv(\"./pytorch_fashion_loss_df.csv\")\n\n\npytorch_fashion_loss_df\n\n\n  \n    \n\n\n\n\n\n\ntrain_loss\nval_loss\n\n\n\n\n0\n1.930857\n1.909099\n\n\n1\n1.912644\n1.918055\n\n\n2\n1.887620\n1.848024\n\n\n3\n1.751529\n1.722522\n\n\n4\n1.717885\n1.715074\n\n\n5\n1.662122\n1.664416\n\n\n6\n1.657943\n1.657352\n\n\n7\n1.657977\n1.675686\n\n\n8\n1.649832\n1.648165\n\n\n9\n1.648726\n1.692258\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nplt.plot(pytorch_fashion_loss_df[\"train_loss\"], label = \"training loss\")\nplt.plot(pytorch_fashion_loss_df[\"val_loss\"], label = \"validation loss\")\nplt.xlabel(\"epoch\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nfashion_val_list = list(fashion_val_dataloader)\n\n\ntes_batch_gambar, tes_batch_label = fashion_val_list[123]\n\n\nprint(tes_batch_gambar.shape)\n\ntorch.Size([32, 1, 28, 28])\n\n\n\nprint(tes_batch_label.shape)\n\ntorch.Size([32])\n\n\n\ntes_gambar = tes_batch_gambar[0, :, :, :].to(device)\n\n\nprint(tes_gambar.shape)\n\ntorch.Size([1, 28, 28])\n\n\n\ntes_label = tes_batch_label[0]\n\n\nprint(tes_label)\nprint(nama_kelas[tes_label])\n\ntensor(3)\nDress\n\n\n\ny_pred = fashion_model(tes_gambar)\n\n\nprint(y_pred)\n\ntensor([[4.4959e-07, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0',\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nprint(torch.argmax(y_pred).item())\n\n3\n\n\n\n#@title Slider to look for some prediction examples {run: \"auto\"}\nbatch_idx = 123 #@param {type:\"slider\", min:0, max:9999, step:1}\npic_idx = 0 #@param {type:\"slider\", min:0, max:31, step:1}\n\nbatch_gambar, batch_label = fashion_val_list[batch_idx]\n\nsatu_gambar = batch_gambar[pic_idx].to(device)\nlabel_true_idx = batch_label[pic_idx].item()\nlabel_pred_idx = torch.argmax(fashion_model(satu_gambar)).item()\n\nplt.imshow(satu_gambar.cpu().squeeze(), cmap='gray')\nplt.title(\n    f\"Predicted class: {nama_kelas[label_pred_idx]}\\n\" +\n    f\"True class: {nama_kelas[label_true_idx]}\"\n)\nplt.axis('OFF')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\ntorch.save(fashion_model.state_dict(), \"./fashion_model_state.pth\")"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul9.html#referensi",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul9.html#referensi",
    "title": "Modul 9 Praktikum Sains Data: Pengantar PyTorch",
    "section": "",
    "text": "Internet\n\nhttps://paperswithcode.com/trends\nhttps://pytorch.org/docs/stable/index.html\n\nSumber belajar PyTorch, deep learning, atau semacamnya, untuk belajar lebih lanjut\n\nhttps://www.learnpytorch.io/\nBuku Dive into Deep Learning (biasa disebut D2L), utamanya menggunakan PyTorch: https://d2l.ai/\nSitus bernama “weights and biases” (wandb) menyediakan layanan pemantauan proses training: https://wandb.ai/site"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul6.html",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul6.html",
    "title": "Modul 6 Praktikum Metode Numerik: Metode Iteratif untuk SPL",
    "section": "",
    "text": "Kembali ke Metode Numerik\nIni adalah pertemuan terakhir praktikum Metode Numerik tahun ini.\nOutline:\nModul praktikum ini diawali dengan pembahasan tentang beberapa jenis norm vektor. Kemudian, metode yang dibahas di modul kali ini, utamanya hanyalah “versi praktis” untuk algoritma metode Jacobi, metode Gauss-Seidel, dan metode relaksasi (SOR). Metode Gauss-Seidel adalah perbaikan dari metode Jacobi, dan metode SOR adalah perbaikan dari metode Gauss-Seidel. Istilah “versi praktis” di sini maksudnya agar dibedakan dari bentuk matriks \\(T\\textbf{x}+\\textbf{c}\\) (sebagai materi pengayaan) untuk metode-metode tersebut.\nInti sari dari ketiga metode tersebut adalah perumuman dari metode fixed-point (dari bab 2, metode numerik untuk root-finding), yang tadinya dilakukan untuk satu variabel/persamaan saja, menjadi dilakukan untuk beberapa variabel/persamaan sekaligus (yang kebetulan membentuk SPL). Langkah paling pertama dalam mempersiapkan penyelesaian SPL dengan metode-metode tersebut adalah seperti melakukan pindah ruas ke sebelah kanan untuk semua suku kecuali variabel pada diagonal, mirip dengan ide substitusi balik. Langkah ini tersirat ketika menuliskan bentuk umum metode-metode tersebut dalam bentuk sumasi. Selain itu, seperti metode fixed-point, diperlukan tebakan awal untuk nilai tiap variabel.\nUntuk perumuman metode fixed-point yang lebih umum lagi, yaitu untuk sistem persamaan yang tidak harus linier (tidak harus berbentuk SPL), dibahas di bab 10.1 di buku Burden. Bab 8, 9, dan 10 di buku Burden dibahas di mata kuliah pilihan program studi S1 Matematika yang bernama “Matematika Numerik”, dengan prasyarat Metode Numerik.\nPembahasan teoritis di kelas (perkuliahan) Metode Numerik juga mencakup pembahasan metode Jacobi, metode Gauss-Seidel, dan metode SOR dalam bentuk matriks, dengan bentuk umum \\(T\\textbf{x}+\\textbf{c}\\). Bentuk matriks untuk metode-metode tersebut tidak menjadi fokus di praktikum (bahkan di buku Burden, akhir halaman 452, juga disebut bahwa bentuk matriks tersebut biasanya hanya digunakan untuk pembahasan teoritis), tetapi tetap disediakan di modul praktikum ini sebagai materi pengayaan."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#beberapa-jenis-norm-vektor",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#beberapa-jenis-norm-vektor",
    "title": "Modul 6 Praktikum Metode Numerik: Metode Iteratif untuk SPL",
    "section": "1. Beberapa jenis norm vektor",
    "text": "1. Beberapa jenis norm vektor\nAda beberapa jenis norm vektor, yaitu semacam ukuran “besar” (magnitude) atau “panjang” untuk vektor. Salah satu kegunaannya adalah membandingkan “ukuran” antara dua vektor, yang mana yang lebih besar/kecil. Tiga jenis norm yang terkenal adalah:\n\nEuclidean norm, sering disebut 2-norm atau \\(L_2\\)-norm, dan perhitungannya seperti menggunakan teorema Pythagoras. Penulisan: \\(||\\textbf{v}||_2\\)\nInfinity norm (norm tak hingga), terkadang disebut \\(L_{\\infty}\\)-norm, yaitu sama saja maksimum dari semua mutlak elemen vektor. Penulisan: \\(||\\textbf{v}||_{\\infty}\\)\nManhattan distance atau Taxicab norm, sering disebut 1-norm atau \\(L_1\\)-norm, yaitu menjumlahkan mutlak tiap elemen vektor. Penulisan: \\(||\\textbf{v}||_1\\)\n\nNumpy bisa menghitung beberapa jenis norm, termasuk ketiga jenis norm di atas, menggunakan numpy.linalg.norm(vektor, jenis_norm), di mana vektor dibuat dengan numpy.array.\n\nimport numpy as np\n\n\nvektor_kecil = np.array([3,-4])\nprint(vektor_kecil)\n\n[ 3 -4]\n\n\nContoh norm-2, dengan option ord=2:\n\nnp.linalg.norm(vektor_kecil, ord=2)\n\n5.0\n\n\nOutput adalah 5, karena \\(||\\textbf{v}||_2=\\sqrt{3^2+\\left(-4\\right)^2}=\\sqrt{25}=5\\).\nSebenarnya, “ord” tidak harus ditulis:\n\nnp.linalg.norm(vektor_kecil, 2)\n\n5.0\n\n\nContoh norm-infinity, dengan option ord=numpy.inf:\n\nnp.linalg.norm(vektor_kecil, np.inf)\n\n4.0\n\n\nOutput adalah 4, karena \\(||\\textbf{v}||_{\\infty} = \\max \\left( |3|, |-4| \\right) = \\max \\left( 3, 4 \\right) = 4\\).\nContoh norm-1:\n\nnp.linalg.norm(vektor_kecil, 1)\n\n7.0\n\n\nOutput adalah 7, karena \\(||\\textbf{v}||_1 = |3| + |-4| = 3+4=7\\).\nMasing-masing jenis norm memiliki kelebihan dan kekurangan. (Untuk ke depannya, kita akan menggunakan norm-infinity, sesuai buku Burden). Apapun jenis norm yang Anda gunakan, untuk perhitungan apapun, pastikan Anda konsisten selalu menggunakan jenis norm yang sama dari awal sampai akhir perhitungan.\nUntuk jenis norm lainnya, bisa baca lebih lanjut di dokumentasi numpy (pada keterangan option “ord”): https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#masalah-copy-untuk-array-numpy",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#masalah-copy-untuk-array-numpy",
    "title": "Modul 6 Praktikum Metode Numerik: Metode Iteratif untuk SPL",
    "section": "2. Masalah copy untuk array numpy",
    "text": "2. Masalah copy untuk array numpy\nAda satu hal yang perlu dibahas sebelum melanjutkan ke pembahasan metode iteratif untuk SPL.\nSalah satu kekurangan numpy (dan Python secara umum) adalah bahwa kita tidak bisa meng-copy suatu array (ataupun list) dengan assignment. Melakukan assignment seolah-olah hanya membuat “sinonim”, sehingga perubahan pada salah satu array/list juga akan mengubah array/list yang satunya (istilahnya shallow copy). Perhatikan,\n\nimport numpy as np\n\n\narray1 = np.array([9, 8, 7, 6])\nprint(array1)\n\n[9 8 7 6]\n\n\n\n# Apakah cara copy seperti ini?\narray2 = array1\n\n\nprint(array2)\n\n[9 8 7 6]\n\n\nSeandainya array2 diubah…\n\narray2[2] = 15\nprint(array2)\n\n[ 9  8 15  6]\n\n\n… maka array1 juga mengalami perubahan yang sama.\n\nprint(array1)\n\n[ 9  8 15  6]\n\n\nCara copy yang tepat untuk array maupun list adalah menggunakan akhiran .copy() seperti berikut ini.\n\narray3 = array1.copy()\nprint(array3)\n\n[ 9  8 15  6]\n\n\nSehingga, perubahan pada salah satu tidak akan mempengaruhi yang satunya lagi. Artinya, copy telah dilakukan secara sempurna (disebut deep copy).\n\narray3[3] = 20\nprint(array3)\nprint(array1)\n\n[ 9  8 15 20]\n[ 9  8 15  6]\n\n\nUntuk ke depannya, kita akan sering menggunakan .copy().\nFun fact: sepertinya, permasalahan shallow copy ini berhubungan erat dengan cara dibuatnya library numpy yang sebenarnya tersambung dengan bahasa pemrograman C, yang juga memiliki keanehan yang serupa untuk array."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#metode-jacobi-algoritma-praktis",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#metode-jacobi-algoritma-praktis",
    "title": "Modul 6 Praktikum Metode Numerik: Metode Iteratif untuk SPL",
    "section": "3. Metode Jacobi, algoritma praktis",
    "text": "3. Metode Jacobi, algoritma praktis\nMisalkan vektor \\(\\textbf{x}^{(k)} = \\left( x_1^{(k)}, x_2^{(k)}, \\dots, x_n^{(k)} \\right)^t\\) (ditranspos agar berupa vektor kolom) adalah hasil aproksimasi pada iterasi ke-k untuk solusi SPL \\(n\\)-variabel \\(A\\textbf{x}=\\textbf{b}\\).\nMetode Jacobi memiliki formula sebagai berikut:\n\\[x_i^{(k)} = \\frac{1}{a_{ii}} \\left[ \\sum_{j=1,j\\ne i}^{n} \\left(-a_{ij}x_j^{(k-1)} \\right) + b_i \\right],\\hspace{0.5cm} i = 1, 2, \\dots, n \\]\nKriteria pemberhentian iterasi bisa berupa * error mutlak: \\(||\\textbf{x}^{(k)}-\\textbf{x}^{(k-1)}|| &lt; \\epsilon\\) * error relatif: \\(\\frac{||\\textbf{x}^{(k)}-\\textbf{x}^{(k-1)}||}{||\\textbf{x}^{(k)}||} &lt; \\epsilon\\)\nPada kode berikut ini, kita akan menggunakan error mutlak dan norm tak hingga.\n\nimport numpy as np\n\ndef Jacobi(matriks, tebakan_awal, tol):\n    # banyaknya baris pada matriks, atau sama saja banyaknya variabel\n    n = np.shape(matriks)[0]\n\n    # definisikan vektor x0 sebagai tebakan awal\n    x0 = tebakan_awal.copy()\n\n    # error sementara (karena error belum diketahui), agar masuk while loop\n    err = tol + 1\n\n    while err &gt; tol: # selama kriteria pemberhentian belum terpenuhi,\n        # anggap x0 sebagai x^(k-1) atau hasil iterasi sebelumnya,\n        # kemudian nilai yang baru akan disimpan pada vektor x^(k) berikut:\n        x = x0.copy()\n\n        # metode Jacobi untuk tiap i\n        for i in range(n):\n            b = matriks[i, n]\n            for j in range(n):\n                if j != i:\n                    b = b - matriks[i,j] * x0[j]\n                    # perhatikan bahwa selalu digunakan x0,\n                    # yaitu nilai-nilai x^(k-1), yaitu dari iterasi sebelumnya\n            x[i] = b/matriks[i,i]\n        \n        # update error mutlak\n        err = np.linalg.norm(x-x0, np.inf)\n\n        # memasuki iterasi selanjutnya,\n        # vektor x0 sekarang adalah vektor x yang barusan dihitung\n        x0 = x\n    \n    # jika keluar while loop maka metode selesai, x(k) adalah vektor hasil akhir\n    return x\n\n\nmatriks_diperbesar = np.array(eval(input(\"Masukkan matriks diperbesar: \"))).astype(float)\ntebakan_awal = np.array(eval(input(\"Masukkan tebakan awal: \")), dtype=float)\n# catatan: .astype(float) dan dtype=float melakukan hal yang sama,\n# dengan cara penggunaan yang sedikit berbeda:\n# - numpy.array(...).astype(float)\n# - numpy.array(..., dtype=float)\n# tidak ada salahnya apabila menggunakan salah satu saja (lebih baik konsisten)\n\ntoleransi = eval(input(\"Masukkan toleransi: \"))\n\nhasil = Jacobi(matriks_diperbesar, tebakan_awal, toleransi)\nprint(\"Hasil metode Jacobi adalah:\")\nprint(hasil)\n\nMasukkan matriks diperbesar: [ [10, -1, 2, 0, 6], [-1, 11, -1, 3, 25], [2, -1, 10, -1, -11], [0, 3, -1, 8, 15] ]\nMasukkan tebakan awal: [0,0,0,0]\nMasukkan toleransi: 10**-4\nHasil metode Jacobi adalah:\n[ 0.99998973  2.00001582 -1.00001257  1.00001924]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#metode-gauss-seidel-algoritma-praktis",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#metode-gauss-seidel-algoritma-praktis",
    "title": "Modul 6 Praktikum Metode Numerik: Metode Iteratif untuk SPL",
    "section": "4. Metode Gauss-Seidel, algoritma praktis",
    "text": "4. Metode Gauss-Seidel, algoritma praktis\nMetode Gauss-Seidel adalah modifikasi/perkembangan dari metode Jacobi, di mana semua nilai \\(x_i\\) yang digunakan untuk perhitungan adalah selalu yang terbaru. Artinya, ketika menghitung \\(x_i^{(k)}\\), meskipun nilai-nilai \\(x_{i+1}, \\dots, x_n\\) yang digunakan adalah dari iterasi sebelumnya, nilai-nilai \\(x_1, x_2, \\dots, x_{i-1}\\) yang digunakan adalah yang baru saja dihitung, yaitu dari iterasi yang sama. Hal ini tidak seperti metode Jacobi yang selalu menggunakan nilai-nilai dari iterasi sebelumnya.\nOleh karena itu, untuk metode Gauss-Seidel, penulisan sumasi dipisah menjadi dua bagian, yaitu satu bagian untuk penggunaan nilai-nilai dari iterasi yang sama \\((k)\\), dan satu bagian untuk penggunaan nilai-nilai dari iterasi sebelumnya \\((k-1)\\).\n\\[x_i^{(k)} = \\frac{1}{a_{ii}} \\left[ -\\sum_{j=1}^{i-1} \\left( a_{ij}x_j^{(k)} \\right) - \\sum_{j=i+1}^{n} \\left( a_{ij}x_j^{(k-1)} \\right) + b_i \\right],\\hspace{0.5cm} i = 1, 2, \\dots, n \\]\nAkibat selalu menggunakan nilai-nilai terbaru, metode Gauss-Seidel cenderung lebih cepat konvergen memenuhi toleransi daripada metode Jacobi.\nSecara algoritma, perubahan ini pun sebenarnya sangat kecil. Antara metode Jacobi dan metode Gauss-Seidel, perbedaannya hanya di satu baris saja…\n\nimport numpy as np\n\ndef GaussSeidel(matriks, tebakan_awal, tol):\n    # banyaknya baris pada matriks, atau sama saja banyaknya variabel\n    n = np.shape(matriks)[0]\n\n    # definisikan vektor x0 sebagai tebakan awal\n    x0 = tebakan_awal.copy()\n\n    # error sementara (karena error belum diketahui), agar masuk while loop\n    err = tol + 1\n\n    while err &gt; tol: # selama kriteria pemberhentian belum terpenuhi,\n        # anggap x0 sebagai x^(k-1) atau hasil iterasi sebelumnya,\n        # kemudian nilai yang baru akan disimpan pada vektor x^(k) berikut:\n        x = x0.copy()\n\n        # metode Gauss-Seidel untuk tiap i\n        for i in range(n):\n            b = matriks[i, n]\n            for j in range(n):\n                if j != i:\n                    # perubahan dari metode Jacobi hanya di baris berikut\n                    b = b - matriks[i,j] * x[j]\n                    # perhatikan bahwa selalu digunakan x,\n                    # yaitu nilai-nilai x^(k), yaitu nilai-nilai terbaru;\n            x[i] = b/matriks[i,i]\n        \n        # update error mutlak\n        err = np.linalg.norm(x-x0, np.inf)\n\n        # memasuki iterasi selanjutnya,\n        # vektor x0 sekarang adalah vektor x yang barusan dihitung\n        x0 = x\n    \n    # jika keluar while loop maka metode selesai, x(k) adalah vektor hasil akhir\n    return x\n\n\nmatriks_diperbesar = np.array(eval(input(\"Masukkan matriks diperbesar: \"))).astype(float)\ntebakan_awal = np.array(eval(input(\"Masukkan tebakan awal: \")), dtype=float)\ntoleransi = eval(input(\"Masukkan toleransi: \"))\n\nhasil = GaussSeidel(matriks_diperbesar, tebakan_awal, toleransi)\nprint(\"Hasil Gauss-Seidel adalah:\")\nprint(hasil)\n\nMasukkan matriks diperbesar: [ [10, -1, 2, 0, 6], [-1, 11, -1, 3, 25], [2, -1, 10, -1, -11], [0, 3, -1, 8, 15] ]\nMasukkan tebakan awal: [0,0,0,0]\nMasukkan toleransi: 10**-4\nHasil Gauss-Seidel adalah:\n[ 1.00000836  2.00000117 -1.00000275  0.99999922]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#metode-relaksasi-sor-algoritma-praktis",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#metode-relaksasi-sor-algoritma-praktis",
    "title": "Modul 6 Praktikum Metode Numerik: Metode Iteratif untuk SPL",
    "section": "5. Metode Relaksasi (SOR), algoritma praktis",
    "text": "5. Metode Relaksasi (SOR), algoritma praktis\nMetode relaksasi (relaxation methods) adalah metode untuk mempercepat kekonvergenan dari solusi yang dihasilkan oleh metode iteratif untuk SPL (dalam hal ini, metode Gauss-Seidel). Berdasarkan besar faktor relaksasi \\(\\omega\\), metode relaksasi terbagi menjadi dua jenis, yaitu * metode under relaxation jika \\(0 &lt; \\omega &lt; 1\\) * metode over relaxation jika \\(\\omega &gt; 1\\)\nSesuai buku Burden, pembahasan kita akan fokus ke metode over relaxation. Metode over relaxation yang diterapkan terus-menerus untuk tiap iterasi Gauss-Seidel disebut metode Successive Over-Relaxation (SOR).\nUntuk sembarang nilai omega, rumus metode relaksasi sebagai modifikasi Gauss-Seidel bisa dituliskan sebagai berikut:\n\\[x_i^{(k)} = \\left(1-\\omega\\right)x_i^{(k-1)} + \\frac{\\omega}{a_{ii}} \\left[ -\\sum_{j=1}^{i-1} \\left( a_{ij}x_j^{(k)} \\right) - \\sum_{j=i+1}^{n} \\left( a_{ij}x_j^{(k-1)} \\right) + b_i \\right],\\hspace{0.5cm} i = 1, 2, \\dots, n \\]\nCatatan: jika \\(\\omega = 1\\), diperoleh metode Gauss-Seidel yang telah dibahas sebelumnya (tanpa relaksasi).\nLagi-lagi, perbedaan kode antara metode Gauss-Seidel dan metode SOR hanya di satu baris saja…\n\nimport numpy as np\n\ndef SOR(matriks, tebakan_awal, tol, omega=1):\n    # banyaknya baris pada matriks, atau sama saja banyaknya variabel\n    n = np.shape(matriks)[0]\n\n    # definisikan vektor x0 sebagai tebakan awal\n    x0 = tebakan_awal.copy()\n\n    # error sementara (karena error belum diketahui), agar masuk while loop\n    err = tol + 1\n\n    while err &gt; tol: # selama kriteria pemberhentian belum terpenuhi,\n        # anggap x0 sebagai x^(k-1) atau hasil iterasi sebelumnya,\n        # kemudian nilai yang baru akan disimpan pada vektor x^(k) berikut:\n        x = x0.copy()\n\n        # metode Gauss-Seidel untuk tiap i\n        for i in range(n):\n            b = matriks[i, n]\n            for j in range(n):\n                if j != i:\n                    b = b - matriks[i,j] * x[j]\n                    # perhatikan bahwa selalu digunakan x,\n                    # yaitu nilai-nilai x^(k), yaitu nilai-nilai terbaru;\n            # bedanya dengan metode Gauss-Seidel hanya di baris berikut:\n            x[i] = (1-omega) * x0[i] + omega*b/matriks[i,i] # hasil SOR\n        \n        # update error mutlak\n        err = np.linalg.norm(x-x0, np.inf)\n\n        # memasuki iterasi selanjutnya,\n        # vektor x0 sekarang adalah vektor x yang barusan dihitung\n        x0 = x\n    \n    # jika keluar while loop maka metode selesai, x(k) adalah vektor hasil akhir\n    return x\n\n\nmatriks_diperbesar = np.array(eval(input(\"Masukkan matriks diperbesar: \"))).astype(float)\ntebakan_awal = np.array(eval(input(\"Masukkan tebakan awal: \")), dtype=float)\nomega = eval(input(\"Masukkan faktor relaksasi (omega): \"))\ntoleransi = eval(input(\"Masukkan toleransi: \"))\n\nhasil = SOR(matriks_diperbesar, tebakan_awal, omega, toleransi)\nprint(\"Hasil SOR adalah:\")\nprint(hasil)\n\nMasukkan matriks diperbesar: [ [4, 3, 0, 24], [3, 4, -1, 30], [0, -1, 4, -24] ]\nMasukkan tebakan awal: [0,0,0]\nMasukkan faktor relaksasi (omega): 1.25\nMasukkan toleransi: 10**-4\nHasil SOR adalah:\n[ 2.99998919  4.00000321 -4.9999937 ]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#pengayaan-metode-jacobi-dalam-bentuk-matriks-teoritis",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#pengayaan-metode-jacobi-dalam-bentuk-matriks-teoritis",
    "title": "Modul 6 Praktikum Metode Numerik: Metode Iteratif untuk SPL",
    "section": "6. (Pengayaan) Metode Jacobi, dalam bentuk matriks (teoritis)",
    "text": "6. (Pengayaan) Metode Jacobi, dalam bentuk matriks (teoritis)\nSecara konsep, metode iteratif untuk SPL bisa dianggap sebagai semacam perumuman dari metode fixed-point, yang tadinya hanya satu variabel/persamaan menjadi banyak variabel/persamaan. Bentuk sumasi untuk masing-masing metode memang terlihat agak berbeda satu sama lain (seperti tidak bisa disamakan atau dibuat bentuk umumnya), terutama antara metode Jacobi dan metode Gauss-Seidel. Namun, mengingat asal-usulnya sebagai perumuman metode fixed-point, dan berhubung sistem persamaan yang ingin diselesaikan bersifat linier (membentuk SPL), metode iteratif untuk SPL bisa dituliskan dalam suatu bentuk umum menggunakan matriks (bentuk matriks), yakni\n\\[\\textbf{x}^{(k)} = T\\textbf{x}^{(k-1)} + \\textbf{c}\\]\ndi mana isi matriks \\(T\\) dan vektor konstanta \\(\\textbf{c}\\) ditentukan tergantung metode iteratif yang digunakan: apakah metode Jacobi, metode Gauss-Seidel, atau metode SOR.\nSekilas, bentuk umum tersebut memang terlihat lebih sederhana, seperti betapa sederhananya metode fixed-point. Namun, secara perhitungan, perkalian matriks bisa memakan waktu yang relatif lama, sehingga versi praktis yang telah dibahas sebelumnya lah yang lebih cocok untuk dibuat program maupun untuk perhitungan manual.\nMeskipun demikian, bentuk umum di atas masih ada kegunaannya, khususnya untuk mempermudah pembahasan teoritis seperti analisis error. Berikut ini, kita tetap akan membahas bentuk matriks untuk ketiga metode tersebut sebagai materi pengayaan.\nSebelumnya, dari SPL \\(A\\textbf{x}=\\textbf{b}\\), kita bisa “memecah” matriks koefisien \\(A\\) menjadi tiga bagian, yaitu \\(A = (-L_{neg}) + D + (-U_{neg})\\) atau sama saja \\(A = D - L_{neg} - U_{neg}\\): * Matriks \\((-L_{neg})\\) adalah matriks segitiga bawah menggunakan elemen matriks \\(A\\) yang berada di bawah diagonal, sedangkan sisanya nol. * Matriks \\(D\\) adalah matriks diagonal yang menggunakan elemen diagonal matriks \\(A\\), sedangkan sisanya nol. * Matriks \\((-U_{neg})\\) adalah matriks segitiga atas yang menggunakan elemen \\(A\\) yang berada di atas diagonal, sedangkan sisanya nol.\nPerhatikan bahwa matriks \\((-L_{neg})\\) dan \\((-U_{neg})\\) dituliskan dengan tanda minus. Sebenarnya, nilai elemen segitiga bawah/atas yang disimpan ke matriks \\(L_{neg}\\) dan \\(U_{neg}\\) ini adalah negatif dari nilai aslinya di matriks \\(A\\). Sehinga, matriks segitiga bawah/atas yang memuat nilai aslinya bisa ditulis dengan minus: \\((-L_{neg})\\) dan \\((-U_{neg})\\). Keterangan “neg” maksudnya negatif, sehingga minus negatif menjadi kembali positif atau menjadi nilai aslinya. Hati-hati, pembahasan di buku Burden tidak melibatkan keterangan “neg”, sehingga langsung ditulis misalnya \\(A=D-L-U\\).\n\\[A = \\begin{bmatrix}\na_{11} & a_{12} & \\dots & a_{1n} \\\\\na_{21} & a_{22} & \\dots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{n1} & a_{n2} & \\dots & a_{nn}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\na_{11} & 0 & \\dots & 0 \\\\\n0 & a_{22} & \\dots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\dots & a_{nn}\n\\end{bmatrix}\n-\n\\begin{bmatrix}\n0 & 0 & \\dots & 0 \\\\\n-a_{21} & 0 & \\dots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n-a_{n1} & -a_{n2} & \\dots & 0\n\\end{bmatrix}\n-\n\\begin{bmatrix}\n0 & -a_{12} & \\dots & -a_{1n} \\\\\n0 & 0 & \\dots & -a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\dots & 0\n\\end{bmatrix}\n\\\\\nA = D - L_{neg} - U_{neg}\n\\]\nDengan demikian, kita bisa menyusun fungsi untuk memisahkan matriks koefisien \\(A\\) menjadi \\(D - L_{neg} - U_{neg}\\).\n\ndef PisahDLnegUneg(matriks_A):\n    # memperoleh ukuran n x n dari matriks A, ambil banyaknya baris aja\n    n = np.shape(matriks_A)[0]\n\n    # buat dulu matriks D, Lneg dan Uneg, ukuran n x n, sementara nol semua\n    D = np.zeros((n,n))\n    Lneg = np.zeros((n,n))\n    Uneg = np.zeros((n,n))\n\n    # double for loop melihat tiap elemen di matriks A...\n    for i in range(n): # baris ke-i\n        for j in range(n): # kolom ke-j\n            if i == j: # jika elemen diagonal...\n                # ... maka simpan ke matriks D\n                D[i, j] = matriks_A[i, j]\n            elif i &gt; j: # jika lebih ke bawah daripada ke kanan...\n                # ... maka simpan ke matriks Lneg (karena segitiga bawah)\n                Lneg[i, j] = -matriks_A[i, j] # (jangan lupa dibuat negatif)\n            else: # selain itu (berarti segitiga atas)\n                # simpan ke matriks Uneg, jangan lupa dibuat negatif\n                Uneg[i, j] = -matriks_A[i, j]\n    \n    # return tiga matriks sekaligus sebagai satu kesatuan\n    return (D, Lneg, Uneg)\n\n\n# Contoh\nmatriks_koef = np.array([\n    [1, 2, 3],\n    [4, 5, 6],\n    [7, 8, 9]\n])\n\nD, Lneg, Uneg = PisahDLnegUneg(matriks_koef)\nprint(D)\nprint(Lneg)\nprint(Uneg)\n\n[[1. 0. 0.]\n [0. 5. 0.]\n [0. 0. 9.]]\n[[ 0.  0.  0.]\n [-4.  0.  0.]\n [-7. -8.  0.]]\n[[ 0. -2. -3.]\n [ 0.  0. -6.]\n [ 0.  0.  0.]]\n\n\nSelanjutnya, kita bisa menuliskan matriks \\(T_j\\) dan vektor konstanta \\(\\textbf{c}_j\\) untuk metode Jacobi sebagai berikut:\n\\[T_j = D^{-1}\\left(L_{neg}+U_{neg}\\right), \\hspace{0.5cm} \\textbf{c}_j = D^{-1}\\textbf{b}\\]\nsehingga rumus iterasi metode Jacobi menjadi\n\\[\\textbf{x}^{(k)} = T_j\\textbf{x}^{(k-1)} + \\textbf{c}_j\\]\n\ndef JacobiTeoritis(matriks_koefisien, vektor_b, tebakan_awal, tol):\n    # pisahkan dulu\n    D, Lneg, Uneg = PisahDLnegUneg(matriks_koefisien)\n\n    # susun matriks T_j dan vektor konstanta c_j\n    D_invers = np.linalg.inv(D)\n    Tj = np.matmul( D_invers, Lneg+Uneg )\n    cj = np.matmul( D_invers, vektor_b )\n\n    # iterasi pertama\n\n    # x^(k-1), salin dari tebakan awal\n    xk_1 = tebakan_awal.copy()\n\n    # x^(k), rumus metode Jacobi bentuk matriks\n    xk = np.matmul( Tj, xk_1 ) + cj\n\n    # iterasi kedua dan seterusnya dalam while loop\n\n    while np.linalg.norm(xk_1 - xk, np.inf) &gt; tol: # kriteria pemberhentian\n        # yang sebelumnya menjadi x^(k) itu sekarang menjadi x^(k-1)\n        xk_1 = xk\n\n        # lakukan iterasi untuk memperoleh x^(k) yang baru\n        xk = np.matmul( Tj, xk_1 ) + cj\n\n    # jika sudah keluar while loop, toleransi sudah terpenuhi\n    return xk\n\n\nmatriks_koef = np.array(eval(input(\"Masukkan matriks koefisien A: \"))).astype(float)\nvektor_b = np.array(eval(input(\"Masukkan vektor b: \"))).astype(float)\ntebakan_awal = np.array(eval(input(\"Masukkan tebakan awal: \")), dtype=float)\n\ntoleransi = eval(input(\"Masukkan toleransi: \"))\n\nhasil = JacobiTeoritis(matriks_koef, vektor_b, tebakan_awal, toleransi)\nprint(\"Hasil metode Jacobi (teoritis) adalah:\")\nprint(hasil)\n\nMasukkan matriks koefisien A: [ [10, -1, 2, 0], [-1, 11, -1, 3], [2, -1, 10, -1], [0, 3, -1, 8] ]\nMasukkan vektor b: [6, 25, -11, 15]\nMasukkan tebakan awal: [0, 0, 0, 0]\nMasukkan toleransi: 10**-4\nHasil metode Jacobi (teoritis) adalah:\n[ 0.99998973  2.00001582 -1.00001257  1.00001924]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#pengayaan-metode-gauss-seidel-dalam-bentuk-matriks-teoritis",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#pengayaan-metode-gauss-seidel-dalam-bentuk-matriks-teoritis",
    "title": "Modul 6 Praktikum Metode Numerik: Metode Iteratif untuk SPL",
    "section": "7. (Pengayaan) Metode Gauss-Seidel, dalam bentuk matriks (teoritis)",
    "text": "7. (Pengayaan) Metode Gauss-Seidel, dalam bentuk matriks (teoritis)\nUntuk metode Gauss-Seidel, kita definisikan matriks \\(T_g\\) dan vektor konstanta \\(\\textbf{c}_g\\) sebagai berikut:\n\\[T_g = \\left( D - L_{neg} \\right)^{-1} U_{neg}, \\hspace{0.5cm} \\textbf{c}_g = \\left( D - L_{neg} \\right)^{-1} \\textbf{b}\\]\nSehingga, rumus iterasi untuk metode Gauss-Seidel bentuk matriks bisa ditulis:\n\\[\\textbf{x}^{(k)} = T_g \\textbf{x}^{(k-1)} + \\textbf{c}_g\\]\n\ndef GaussSeidelTeoritis(matriks_koefisien, vektor_b, tebakan_awal, tol):\n    # pisahkan dulu\n    D, Lneg, Uneg = PisahDLnegUneg(matriks_koefisien)\n\n    # susun matriks T_g dan vektor konstanta c_g\n    DminusLneg_invers = np.linalg.inv(D - Lneg)\n    Tg = np.matmul( DminusLneg_invers, Uneg )\n    cg = np.matmul( DminusLneg_invers, vektor_b )\n\n    # iterasi pertama\n\n    # x^(k-1), salin dari tebakan awal\n    xk_1 = tebakan_awal.copy()\n\n    # x^(k), rumus metode Gauss-Seidel bentuk matriks\n    xk = np.matmul( Tg, xk_1 ) + cg\n\n    # iterasi kedua dan seterusnya dalam while loop\n\n    while np.linalg.norm(xk_1 - xk, np.inf) &gt; tol: # kriteria pemberhentian\n        # yang sebelumnya menjadi x^(k) itu sekarang menjadi x^(k-1)\n        xk_1 = xk\n\n        # lakukan iterasi untuk memperoleh x^(k) yang baru\n        xk = np.matmul( Tg, xk_1 ) + cg\n\n    # jika sudah keluar while loop, toleransi sudah terpenuhi\n    return xk\n\n\nmatriks_koef = np.array(eval(input(\"Masukkan matriks koefisien A: \"))).astype(float)\nvektor_b = np.array(eval(input(\"Masukkan vektor b: \"))).astype(float)\ntebakan_awal = np.array(eval(input(\"Masukkan tebakan awal: \")), dtype=float)\n\ntoleransi = eval(input(\"Masukkan toleransi: \"))\n\nhasil = GaussSeidelTeoritis(matriks_koef, vektor_b, tebakan_awal, toleransi)\nprint(\"Hasil metode Gauss-Seidel (teoritis) adalah:\")\nprint(hasil)\n\nMasukkan matriks koefisien A: [ [10, -1, 2, 0], [-1, 11, -1, 3], [2, -1, 10, -1], [0, 3, -1, 8] ]\nMasukkan vektor b: [6, 25, -11, 15]\nMasukkan tebakan awal: [0, 0, 0, 0]\nMasukkan toleransi: 10**-4\nHasil metode Gauss-Seidel (teoritis) adalah:\n[ 1.00000836  2.00000117 -1.00000275  0.99999922]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#pengayaan-metode-sor-dalam-bentuk-matriks-teoritis",
    "href": "semuahalaman/modulprak/2024/genap/metnum/modul6.html#pengayaan-metode-sor-dalam-bentuk-matriks-teoritis",
    "title": "Modul 6 Praktikum Metode Numerik: Metode Iteratif untuk SPL",
    "section": "8. (Pengayaan) Metode SOR, dalam bentuk matriks (teoritis)",
    "text": "8. (Pengayaan) Metode SOR, dalam bentuk matriks (teoritis)\nUntuk metode SOR, diberikan suatu nilai omega, kita definisikan matriks \\(T_{\\omega}\\) dan vektor konstanta \\(\\textbf{c}_{\\omega}\\) sebagai berikut:\n\\[T_{\\omega} = \\left( D-\\omega L \\right)^{-1}\\left[ (1-\\omega)D + \\omega U \\right], \\hspace{0.5cm} \\textbf{c}_{\\omega} = \\omega \\left( D-\\omega L\\right)^{-1} \\textbf{b}\\]\nSehingga, rumus iterasi untuk metode SOR bentuk matriks bisa ditulis:\n\\[\\textbf{x}^{(k)} = T_{\\omega} \\textbf{x}^{(k-1)} + \\textbf{c}_{\\omega}\\]\n\ndef SORTeoritis(matriks_koefisien, vektor_b, tebakan_awal, omega, tol):\n    # pisahkan dulu\n    D, Lneg, Uneg = PisahDLnegUneg(matriks_koefisien)\n\n    # susun matriks T_omega dan vektor konstanta c_omega\n    DminusomegaLneg_invers = np.linalg.inv( D - omega * Lneg)\n    T_omega = np.matmul ( DminusomegaLneg_invers, (1-omega)*D + omega*Uneg )\n    c_omega = omega * np.matmul( DminusomegaLneg_invers, vektor_b )\n\n    # iterasi pertama\n\n    # x^(k-1), salin dari tebakan awal\n    xk_1 = tebakan_awal.copy()\n\n    # x^(k), rumus metode SOR bentuk matriks\n    xk = np.matmul( T_omega, xk_1 ) + c_omega\n\n    # iterasi kedua dan seterusnya dalam while loop\n\n    while np.linalg.norm(xk_1 - xk, np.inf) &gt; tol: # kriteria pemberhentian\n        # yang sebelumnya menjadi x^(k) itu sekarang menjadi x^(k-1)\n        xk_1 = xk\n\n        # lakukan iterasi untuk memperoleh x^(k) yang baru\n        xk = np.matmul( T_omega, xk_1 ) + c_omega\n\n    # jika sudah keluar while loop, toleransi sudah terpenuhi\n    return xk\n\n\nmatriks_koef = np.array(eval(input(\"Masukkan matriks koefisien A: \"))).astype(float)\nvektor_b = np.array(eval(input(\"Masukkan vektor b: \"))).astype(float)\ntebakan_awal = np.array(eval(input(\"Masukkan tebakan awal: \")), dtype=float)\nomega = eval(input(\"Masukkan faktor relaksasi (omega): \"))\ntoleransi = eval(input(\"Masukkan toleransi: \"))\n\nhasil = SORTeoritis(matriks_koef, vektor_b, tebakan_awal, omega, toleransi)\nprint(\"Hasil metode SOR (teoritis) adalah:\")\nprint(hasil)\n\nMasukkan matriks koefisien A: [ [4, 3, 0], [3, 4, -1], [0, -1, 4] ]\nMasukkan vektor b: [24, 30, -24]\nMasukkan tebakan awal: [0, 0, 0]\nMasukkan faktor relaksasi (omega): 1.25\nMasukkan toleransi: 10**-4\nHasil metode SOR (teoritis) adalah:\n[ 2.99998919  4.00000321 -4.9999937 ]"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul6.html",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul6.html",
    "title": "Pertemuan 6 : Interactive Data Visualization (plotly)",
    "section": "",
    "text": "Kembali ke EDA"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul6.html#line-chart",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul6.html#line-chart",
    "title": "Pertemuan 6 : Interactive Data Visualization (plotly)",
    "section": "Line Chart",
    "text": "Line Chart\n\n# using the iris dataset\ndf = px.data.iris()\n \n# plotting the line chart\nfig = px.line(df, y=\"sepal_width\")\n \n# showing the plot\nfig.show()\n\n                                                \n\n\nApa bedanya dengan line plot biasa?\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# plotting the line chart\nsns.lineplot(df, y=\"sepal_width\", x=df.index)\n\n# showing the plot\nplt.show()\n\n\n\n\n\n\n\n\n\nGrouping\n\n# plotting the line chart\nfig = px.line(df, y=\"sepal_width\", line_group='species')\n \n# showing the plot\nfig.show()\n\n                                                \n\n\n\n# plotting the line chart\nfig = px.line(df, y=\"sepal_width\", line_dash='species',\n              color='species')\n \n# showing the plot\nfig.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul6.html#bar-chart",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul6.html#bar-chart",
    "title": "Pertemuan 6 : Interactive Data Visualization (plotly)",
    "section": "Bar Chart",
    "text": "Bar Chart\n\n# Loading the data\ndf = px.data.tips()\n \n# Creating the bar chart\nfig = px.bar(df, x='day', y=\"total_bill\")\n \nfig.show()\n\n                                                \n\n\n\nGrouping\n\n# Creating the bar chart\nfig = px.bar(df, x='day', y=\"total_bill\", color='sex',\n             facet_row='time', facet_col='sex')\n \nfig.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul6.html#scatter-plot",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul6.html#scatter-plot",
    "title": "Pertemuan 6 : Interactive Data Visualization (plotly)",
    "section": "Scatter Plot",
    "text": "Scatter Plot\n\n# plotting the scatter chart\nfig = px.scatter(df, x='total_bill', y=\"tip\")\n \n# showing the plot\nfig.show()\n\n                                                \n\n\n\nGrouping\n\n# plotting the scatter chart\nfig = px.scatter(df, x='total_bill', y=\"tip\", color='time',\n                 symbol='sex', size='size', facet_row='day',\n                 facet_col='time')\n \n# showing the plot\nfig.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul6.html#histogram",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul6.html#histogram",
    "title": "Pertemuan 6 : Interactive Data Visualization (plotly)",
    "section": "Histogram",
    "text": "Histogram\n\n# plotting the histogram\nfig = px.histogram(df, x=\"total_bill\")\n \n# showing the plot\nfig.show()\n\n                                                \n\n\n\nGrouping\n\n# plotting the histogram\nfig = px.histogram(df, x=\"total_bill\", color='sex',\n                   nbins=50, histnorm='percent',\n                   barmode='overlay')\n \n# showing the plot\nfig.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul6.html#pie-chart",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul6.html#pie-chart",
    "title": "Pertemuan 6 : Interactive Data Visualization (plotly)",
    "section": "Pie Chart",
    "text": "Pie Chart\n\n# plotting the pie chart\nfig = px.pie(df, values=\"total_bill\", names=\"day\")\n \n# showing the plot\nfig.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul6.html#donut-chart",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul6.html#donut-chart",
    "title": "Pertemuan 6 : Interactive Data Visualization (plotly)",
    "section": "Donut Chart",
    "text": "Donut Chart\n\n# plotting the donut chart\nfig = px.pie(df, values=\"total_bill\", names=\"day\",\n             color_discrete_sequence=px.colors.sequential.RdBu,\n             opacity=0.7, hole=0.5)\n \n# showing the plot\nfig.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul6.html#box-plot",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul6.html#box-plot",
    "title": "Pertemuan 6 : Interactive Data Visualization (plotly)",
    "section": "Box Plot",
    "text": "Box Plot\n\n# plotting the boxplot\nfig = px.box(df, x=\"day\", y=\"tip\")\n \n# showing the plot\nfig.show()\n\n                                                \n\n\n\nGrouping\n\n# plotting the boxplot\nfig = px.box(df, x=\"day\", y=\"tip\", color='sex',\n             facet_row='time', boxmode='group',\n             notched=True)\n \n# showing the plot\nfig.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul6.html#violin-plot",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul6.html#violin-plot",
    "title": "Pertemuan 6 : Interactive Data Visualization (plotly)",
    "section": "Violin Plot",
    "text": "Violin Plot\n\n# plotting the violin plot\nfig = px.violin(df, x=\"day\", y=\"tip\")\n \n# showing the plot\nfig.show()\n\n                                                \n\n\n\nGrouping\n\n# plotting the violin plot\nfig = px.violin(df, x=\"day\", y=\"tip\", color='sex',\n                facet_row='time', box=True)\n \n# showing the plot\nfig.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul6.html#d-plot",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul6.html#d-plot",
    "title": "Pertemuan 6 : Interactive Data Visualization (plotly)",
    "section": "3D Plot",
    "text": "3D Plot\n\n# plotting the figure\nfig = px.scatter_3d(df, x=\"total_bill\", y=\"sex\", z=\"tip\")\n \nfig.show()\n\n                                                \n\n\n\nGrouping\n\n# plotting the figure\nfig = px.scatter_3d(df, x=\"total_bill\", y=\"sex\", z=\"tip\", color='day', \n                    size='total_bill', symbol='time')\n \nfig.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul6.html#dropdown-menu",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul6.html#dropdown-menu",
    "title": "Pertemuan 6 : Interactive Data Visualization (plotly)",
    "section": "Dropdown Menu",
    "text": "Dropdown Menu\n\nimport plotly.graph_objects as go\n\nplot = go.Figure(data=[go.Scatter(\n    x=df['day'],\n    y=df['tip'],\n    mode='markers',)\n])\n \n# Add dropdown\nplot.update_layout(\n    updatemenus=[\n        dict(buttons=list([\n            dict(\n                args=[\"type\", \"scatter\"],\n                label=\"Scatter Plot\",\n                method=\"restyle\"\n            ),\n            dict(\n                args=[\"type\", \"bar\"],\n                label=\"Bar Chart\",\n                method=\"restyle\"\n            )\n        ]),\n            direction=\"down\",\n        ),\n    ]\n)\n \nplot.show()\n\n                                                \n\n\n\n\n\n\n\n\nplotly.graph_objects\n\n\n\nPada saat kita menggunakan plotly.express (px), secara tidak langsung kita menggunakan plotly.graph_objects untuk menghasilkan suatu plot karena plotly.express dibangun di atas plotly.graph_objects, sehingga kedua library ini pada dasarnya memiliki fungsi yang sama. Hanya saja penggunaan pada plotly.express jauh lebih simple dan bersih.\nLebih lanjut silakan baca dokumentasi berikut : Dokumentasi plotly.express"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul6.html#buttons",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul6.html#buttons",
    "title": "Pertemuan 6 : Interactive Data Visualization (plotly)",
    "section": "Buttons",
    "text": "Buttons\n\nplot = go.Figure(data=[go.Scatter(\n    x=df['day'],\n    y=df['tip'],\n    mode='markers',)\n])\n \n# Add dropdown\nplot.update_layout(\n    updatemenus=[\n        dict(\n            type=\"buttons\",\n            direction=\"left\",\n            buttons=list([\n                dict(\n                    args=[\"type\", \"scatter\"],\n                    label=\"Scatter Plot\",\n                    method=\"restyle\"\n                ),\n                dict(\n                    args=[\"type\", \"bar\"],\n                    label=\"Bar Chart\",\n                    method=\"restyle\"\n                )\n            ]),\n        ),\n    ]\n)\n \nplot.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/eda/modul6.html#sliders-and-selectors",
    "href": "semuahalaman/modulprak/2024/genap/eda/modul6.html#sliders-and-selectors",
    "title": "Pertemuan 6 : Interactive Data Visualization (plotly)",
    "section": "Sliders and Selectors",
    "text": "Sliders and Selectors\n\nx = df['total_bill']\ny = df['tip']\n \nplot = go.Figure(data=[go.Scatter(\n    x=x,\n    y=y,\n    mode='markers',)\n])\n \nplot.update_layout(\n    xaxis=dict(\n        rangeselector=dict(\n            buttons=list([\n                dict(count=1,\n                    step=\"day\",\n                    stepmode=\"backward\"),\n            ])\n        ),\n        rangeslider=dict(\n            visible=True\n        ),\n    )\n)\n \nplot.show()\n\n                                                \n\n\nLebih lanjut silakan buka dokumentasi library plotly pada link berikut : Dokumentasi Plotly\n\nUntuk memperbaiki dan meningkatkan kualitas praktikum kedepannya, silakan berikan feedback anda melalui link berikut : Feedback Praktikum EDA 2023/2024"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul9.html",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul9.html",
    "title": "Modul 9 Persamaan Diferensial Numerik: PDP orde 1, persamaan transport/adveksi",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\nIni adalah pertemuan terakhir praktikum Persamaan Diferensial Numerik tahun ini.\nDi pertemuan kali ini, kita akan membahas penyelesaian secara numerik untuk PDP orde 1, lebih tepatnya “persamaan transport” atau juga disebut persamaan adveksi. (Selain itu, semua PDP orde 1 tergolong hiperbolik.)\nPersamaan transport adalah salah satu bentuk PDP paling sederhana. Persamaan transport bisa dituliskan sebagai berikut:\n\\[u_t + du_x = 0, \\quad (x,t) \\in [0, L] \\times [0, T],\\] \\[u(x,0) = f(x), \\quad 0 \\le x \\le L.\\]\nUntuk kebutuhan praktikum, bentuk umum persamaan transport bisa ditulis:\n\\[u_t + du_x = 0, \\quad \\text{xb} &lt; x &lt; \\text{xu}, \\quad \\text{tb} &lt; t &lt; \\text{tu}\\]\n\\[u(x,\\text{tb}) = f(x), \\quad \\text{xb} \\le x \\le \\text{xu}\\]\n\\[u(\\text{xb},t) = \\text{lb}(t), \\quad \\text{tb} &lt; t &lt; \\text{tu}\\]\n\\[u(\\text{xu},t) = \\text{rb}(t), \\quad \\text{tb} &lt; t &lt; \\text{tu}\\]\nSolusi eksak dari persamaan transport bisa ditulis \\(u(x,t) = f(x-dt)\\) (catatan: \\(dt\\) di sini adalah nilai \\(d\\) dikali variabel \\(t\\), bukan diferensial). Interval \\(x\\) dan \\(t\\) dipartisi dengan step size \\(h = \\Delta x\\) dan \\(k = \\Delta t\\) berturut-turut sehingga diperoleh \\[x_j = (j-1) \\Delta x, \\quad j = 1, 2, \\dots, N_x = m\\] \\[t_n = (n-1) \\Delta t, \\quad n = 1, 2, \\dots, N_t = N\\] Dari sini diperoleh suau grid dengan titik-titik \\((x_j, t_n)\\). Untuk nilai hampiran di titik-titik grid tersebut, bisa digunakan notasi \\(u_j^n \\equiv u(x_j, t_n)\\) ataupun \\(w_{j,n} \\equiv u(x_j, t_n)\\).\nBerikut beberapa metode untuk mengaproksimasi persamaan transport:"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul9.html#metode-courant-isaacson-rees",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul9.html#metode-courant-isaacson-rees",
    "title": "Modul 9 Persamaan Diferensial Numerik: PDP orde 1, persamaan transport/adveksi",
    "section": "Metode Courant-Isaacson-Rees",
    "text": "Metode Courant-Isaacson-Rees\nMetode ini adalah metode FTBS (Forward Time Backward Space) yang juga dikenal dengan metode upwind dengan akurasi \\(O(\\Delta t, \\Delta x)\\). Metode ini memiliki persamaan beda hingga \\[\\frac{u_{j}^{n+1} - u_j^n}{\\Delta t} + d\\frac{u_j^n - u_{j-1}^n}{\\Delta x} = 0\\]\nJika dituliskan dalam term \\(u_j^{n+1}\\), yaitu dalam bentuk \\(u_j^{n+1} = \\dots\\) maka bentuknya menjadi \\[u_j^{n+1} = (1-C)u_j^n + Cu_{j-1}^n, \\quad C \\equiv \\frac{d\\Delta t}{\\Delta x}\\] Metode ini membutuhkan syarat batas kiri.\n\nFunction file\nBerikut kode algoritma metode Courant-Isaacson-Rees menggunakan Octave.\n\nFunction file courant_i_r.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x, t, u] = courant_i_r(d, f, lb, xb, xu, tb, tu, dx, dt)\n  x = xb : dx : xu;\n  t = tb : dt : tu;\n  nx = length(x);\n  nt = length(t);\n  u = zeros(nx, nt);\n\n  for j = 1 : nx\n    u(j, 1) = f(x(j));\n  endfor\n\n  for n = 1 : nt\n    u(1, n) = lb(t(n));\n  endfor\n\n  C = d * dt / dx;\n  for n = 1 : (nt - 1)\n    for j = 2 : nx\n      u(j, n+1) = (1-C) * u(j, n) + C * u(j-1, n);\n    endfor\n  endfor\nendfunction\n\n\n\n\n\n\nContoh penggunaan\nMisal diberikan soal berikut:\n\\[u_t + u_x = 0, \\quad 0 \\le x \\le 1, \\quad 0 \\le t \\le 1\\] \\[u(x,0) = \\sin(8 \\pi x), \\quad 0 \\le x \\le 1\\] \\[u(0,t) = \\sin(-8 \\pi t), \\quad u(1,t) = \\sin(-8 \\pi (1-t)), \\quad 0 \\le t \\le 1\\] \\[\\Delta x = 0.025, \\quad \\Delta t = 0.02\\]\nPerhatikan bahwa \\(d=1\\).\nDalam membandingkan dengan solusi eksak, sulit jika kita menumpuk plot seperti biasa. Kita akan menggunakan syntax figure(n) pada Octave untuk membuat lebih dari satu jendela plot untuk kebutuhannya masing-masing. Variabel sol akan digunakan untuk menyimpan solusi eksak dari persamaan transport.\n\nScript file coba_courant_i_r.m - nama file bebas\n\n\n\nd = 1;\nf = @(x) sin(8*pi*x);\nlb = @(t) sin(-8*pi*t);\nxb = 0;\nxu = 1;\ntb = 0;\ntu = 1;\ndx = 0.025;\ndt = 0.02;\n\n[x, t, u] = courant_i_r(d, f, lb, xb, xu, tb, tu, dx, dt);\n\nsln = @(x,t) sin(8*pi*(x-t));\n\nfor j = 1 : length(x)\n  for n = 1 : length(t)\n    y(j, n) = sln(x(j), t(n));\n  endfor\nendfor\n\nfigure(1);\nhold on;\nmesh(x, t, u');\nxlabel('x');\nylabel('t');\nzlabel('u');\ntitle(\"Solusi Metode Courant-Isaacson-Rees\");\n\nfigure(2);\nhold on;\nmesh(x, t, y');\nxlabel('x');\nylabel('t');\nzlabel('u');\ntitle(\"Solusi Eksak\")\n\n% solusi eksak pada t=1\nu1 = @(x) sln(x, 1);\n\nfigure(3);\nhold on;\nfplot(u1, [0, 1], 'k');\nscatter(x, u(:, length(t)), 'r');\nlegend(\"Eksak\", \"Metode Courant\");\ntitle(\"Penampang pada t=1\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoba putar-putar grafiknya :)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul9.html#metode-richardson-ftcs",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul9.html#metode-richardson-ftcs",
    "title": "Modul 9 Persamaan Diferensial Numerik: PDP orde 1, persamaan transport/adveksi",
    "section": "Metode Richardson (FTCS)",
    "text": "Metode Richardson (FTCS)\nMetode ini adalah metode FTCS (Forward Time Center Space) dengan akurasi \\(O(\\Delta t, \\Delta x^2)\\). Metode ini memiliki persamaan beda hingga\n\\[\\frac{u_j^{n+1} - u_j^n}{\\Delta t} + d\\frac{u_{j+1}^n - u_{j-1}^n}{2 \\Delta x} = 0\\]\nJika dituliskan dalam term \\(u_j^{n+1}\\) menjadi\n\\[u_j^{n+1} = u_j^n + C(u_{j+1}^n - u_{j-1}^n), \\quad C \\equiv \\frac{d \\Delta t}{2\\Delta x}\\]\nMetode ini membutuhkan syarat batas kiri dan kanan.\nPerlu dicatat, metode ini tidak stabil; hasilnya kemungkinan akan jelek.\n\nFunction file\nBerikut kode algoritma metode Richardson menggunakan Octave.\n\nFunction file richardson.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x, t, u] = richardson(d, f, lb, rb, xb, xu, tb, tu, dx, dt)\n  x = xb : dx : xu;\n  t = tb : dt : tu;\n  nx = length(x);\n  nt = length(t);\n  u = zeros(nx, nt);\n\n  for j = 1 : nx\n    u(j, 1) = f(x(j));\n  endfor\n\n  for n = 1 : nt\n    u(1, n) = lb(t(n));\n    u(nx, n) = rb(t(n));\n  endfor\n\n  C = (d * dt) / (2 * dx);\n  for n = 1 : (nt - 1)\n    for j = 2 : (nx - 1)\n      u(j, n+1) = u(j, n) - C * (u(j+1, n) - u(j-1, n));\n    endfor\n  endfor\nendfunction\n\n\n\n\n\n\nContoh penggunaan\nDengan soal yang sama,\n\\[u_t + u_x = 0, \\quad 0 \\le x \\le 1, \\quad 0 \\le t \\le 1\\] \\[u(x,0) = \\sin(8 \\pi x), \\quad 0 \\le x \\le 1\\] \\[u(0,t) = \\sin(-8 \\pi t), \\quad u(1,t) = \\sin(-8 \\pi (1-t)), \\quad 0 \\le t \\le 1\\] \\[\\Delta x = 0.025, \\quad \\Delta t = 0.02\\]\n\nScript file coba_richardson.m - nama file bebas\n\n\n\nd = 1;\nf = @(x) sin(8*pi*x);\nlb = @(t) sin(-8*pi*t);\nrb = @(t) sin(-8*pi*(1-t));\nxb = 0;\nxu = 1;\ntb = 0;\ntu = 1;\ndx = 0.025;\ndt = 0.02;\n\n[x, t, u] = richardson(d, f, lb, rb, xb, xu, tb, tu, dx, dt);\n\nsln = @(x,t) sin(8*pi*(x-t));\n\nfor j = 1 : length(x)\n  for n = 1 : length(t)\n    y(j, n) = sln(x(j), t(n));\n  endfor\nendfor\n\nfigure(1);\nhold on;\nmesh(x, t, u');\nxlabel('x');\nylabel('t');\nzlabel('u');\ntitle(\"Solusi Metode Richardson\");\n\nfigure(2);\nhold on;\nmesh(x, t, y');\nxlabel('x');\nylabel('t');\nzlabel('u');\ntitle(\"Solusi Eksak\")\n\n% solusi eksak pada t=1\nu1 = @(x) sln(x, 1);\n\nfigure(3);\nhold on;\nfplot(u1, [0, 1], 'k');\nscatter(x, u(:, length(t)), 'r');\nlegend(\"Eksak\", \"Metode Richardson\");\ntitle(\"Penampang pada t=1\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJika diperhatikan, terlihat bahwa nilai u(x, 0) di figure 1 adalah 0, sehingga kalian mungkin akan mengira bahwa metodenya salah atau typo. Namun perhatikan sumbu u pada figure 1 dan 3. Nilainya mempunyai range yang berkisar [−10000, 10000]. Hal ini menunjukkan bahwa solusi metode Richardson akan tidak stabil. Pada faktanya, untuk persamaan transport, metode ini selalu tidak stabil. Kita dapat membatasi range dengan menambahkan zlim([-1, 1]); dan ylim([-1, 1]); berturut-turut pada figure(1); dan figure(3);."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul9.html#metode-lax",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul9.html#metode-lax",
    "title": "Modul 9 Persamaan Diferensial Numerik: PDP orde 1, persamaan transport/adveksi",
    "section": "Metode Lax",
    "text": "Metode Lax\nMetode ini adalah perbaikan dari metode Richardson, mengganti \\(u_j^n\\) dengan \\(\\frac{1}{2} (u_{j+1}^n + u_{j-1}^n)\\), sehingga persamaan bedanya menjadi\n\\[u_j^{n+1} = \\frac{1}{2} (u_{j+1}^n + u_{j-1}^n) + C(u_{j+1}^n - u_{j-1}^n), \\quad C \\equiv \\frac{d \\Delta t}{2 \\Delta x}\\]\nMetode ini membutuhkan syarat batas kiri dan kanan.\n\nFunction file\nBerikut kode algoritma metode Lax menggunakan Octave.\n\nFunction file lax.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x, t, u] = lax(d, f, lb, rb, xb, xu, tb, tu, dx, dt)\n  x = xb : dx : xu;\n  t = tb : dt : tu;\n  nx = length(x);\n  nt = length(t);\n  u = zeros(nx, nt);\n\n  for j = 1 : nx\n    u(j, 1) = f(x(j));\n  endfor\n\n  for n = 1 : nt\n    u(1, n) = lb(t(n));\n    u(nx, n) = rb(t(n));\n  endfor\n  \n  C = (d * dt) / (2 * dx);\n  for n = 1 : (nt - 1)\n    for j = 2 : (nx - 1)\n      u(j, n+1) = (u(j+1, n) + u(j-1, n)) / 2 - C * (u(j+1, n) - u(j-1, n));\n    endfor\n  endfor\nendfunction\n\n\n\n\n\n\nContoh penggunaan\nDengan soal yang sama,\n\\[u_t + u_x = 0, \\quad 0 \\le x \\le 1, \\quad 0 \\le t \\le 1\\] \\[u(x,0) = \\sin(8 \\pi x), \\quad 0 \\le x \\le 1\\] \\[u(0,t) = \\sin(-8 \\pi t), \\quad u(1,t) = \\sin(-8 \\pi (1-t)), \\quad 0 \\le t \\le 1\\] \\[\\Delta x = 0.025, \\quad \\Delta t = 0.02\\]\n\nScript file coba_lax.m - nama file bebas\n\n\n\nd = 1;\nf = @(x) sin(8*pi*x);\nlb = @(t) sin(-8*pi*t);\nrb = @(t) sin(-8*pi*(1-t));\nxb = 0;\nxu = 1;\ntb = 0;\ntu = 1;\ndx = 0.025;\ndt = 0.02;\n\n[x, t, u] = lax(d, f, lb, rb, xb, xu, tb, tu, dx, dt);\n\nsln = @(x,t) sin(8*pi*(x-t));\n\nfor j = 1 : length(x)\n  for n = 1 : length(t)\n    y(j, n) = sln(x(j), t(n));\n  endfor\nendfor\n\nfigure(1);\nhold on;\nmesh(x, t, u');\nxlabel('x');\nylabel('t');\nzlabel('u');\ntitle(\"Solusi Metode Lax\");\n\nfigure(2);\nhold on;\nmesh(x, t, y');\nxlabel('x');\nylabel('t');\nzlabel('u');\ntitle(\"Solusi Eksak\");\n\n% solusi eksak pada t=1\nu1 = @(x) sln(x, 1);\n\nfigure(3);\nhold on;\nfplot(u1, [0, 1], 'k');\nscatter(x, u(:, length(t)), 'r');\nlegend(\"Eksak\", \"Metode Lax\");\ntitle(\"Penampang pada t=1\");"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul8.html",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul8.html",
    "title": "Modul 8 Kalkulin 2024 Genap: Integral Lipat, Pemrograman dengan Wolfram Mathematica",
    "section": "",
    "text": "Kembali ke Kalkulin\nIni adalah pertemuan terakhir praktikum Kalkulin tahun ini."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul8.html#integral-lipat",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul8.html#integral-lipat",
    "title": "Modul 8 Kalkulin 2024 Genap: Integral Lipat, Pemrograman dengan Wolfram Mathematica",
    "section": "Integral Lipat",
    "text": "Integral Lipat"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul8.html#programming-with-mathematica",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul8.html#programming-with-mathematica",
    "title": "Modul 8 Kalkulin 2024 Genap: Integral Lipat, Pemrograman dengan Wolfram Mathematica",
    "section": "Programming with Mathematica",
    "text": "Programming with Mathematica"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul8.html#contoh-module",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul8.html#contoh-module",
    "title": "Modul 8 Kalkulin 2024 Genap: Integral Lipat, Pemrograman dengan Wolfram Mathematica",
    "section": "Contoh Module",
    "text": "Contoh Module"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/modul8.html#tambahan-menyusun-matriks-secara-pemrograman",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/modul8.html#tambahan-menyusun-matriks-secara-pemrograman",
    "title": "Modul 8 Kalkulin 2024 Genap: Integral Lipat, Pemrograman dengan Wolfram Mathematica",
    "section": "Tambahan: menyusun matriks secara pemrograman",
    "text": "Tambahan: menyusun matriks secara pemrograman"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/tugas3.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/tugas3.html",
    "title": "Tugas 3 Praktikum Sains Data 2024 Genap: Klasifikasi Gambar dengan Neural Network",
    "section": "",
    "text": "Kembali ke Sains Data\n\n\n\nKerjakan secara individu.\nKerjakan tugas ini menggunakan bahasa pemrograman Python dengan file format berupa interactive Python notebook (yaitu file berbentuk .ipynb BUKAN .py), yang bisa dibuat misalnya menggunakan Jupyter Notebook atau Google Colaboratory.\nHarap sertakan penjelasan untuk setiap proses secara singkat di samping potongan kode (bisa dengan teks / text box maupun dengan comment, ‘#’).\nFormat nama file untuk Tugas 3 adalah:\nNama Lengkap_NPM_Kelas SIAK_Tugas3PrakSaindat.ipynb\nContoh penamaan yang benar:\nYann André LeCun_2201234567_Kelas C_Tugas3PrakSaindat.ipynb\nUntuk mengumpulkan lebih dari satu file, gunakan .zip dengan format nama yang sama (dan file .ipynb yang di dalamnya juga masih menggunakan format nama yang sama).\nApabila ada yang ingin direvisi setelah pengumpulan, lakukan pengumpulan ulang di Google Forms yang sama, tambahkan keterangan bahwa ada revisi, dan tambahkan kata “revisi” pada bagian akhir nama file, contohnya menjadi\nYann André LeCun_2201234567_Kelas C_Tugas3PrakSaindat_revisi.ipynb\nYann André LeCun_2201234567_Kelas C_Tugas3PrakSaindat_revisi2.ipynb\nYann André LeCun_2201234567_Kelas C_Tugas3PrakSaindat_revisi3.ipynb\n(tentunya gunakan .zip kalau ada lebih dari satu file yang ingin dikumpulkan)\n(Revisi boleh dilakukan berkali-kali selama masa pengerjaan.)\nPengumpulan tugas dilakukan ke Google Forms berikut ini, sesuai dengan kelas Anda di SIAK NG (link akan selalu sama untuk semua tugas praktikum Sains Data):\n\nKelas A: https://forms.gle/TdxprAuySMAWt5NR7\nKelas B: https://forms.gle/bk2LBnowfZhmw5qY9\n\nDengan durasi pengerjaan sekitar 3 (tiga) minggu, tenggat waktu (deadline) pengumpulan Tugas 3 ini (termasuk revisi) adalah:\nSabtu, 8 Juni 2024, pukul 23.59 WIB.\nMohon manfaatkan waktu Anda dengan baik (seperti mencicil pengerjaan, bahkan sudah selesai dari jauh-jauh hari) agar mengumpulkan tugas sebelum deadline. Keterlambatan pengumpulan bisa dikenakan pengurangan nilai atau bahkan dianggap tidak mengumpulkan, tergantung kesepakatan dari dosen. Meskipun demikian, lebih baik terlambat mengumpulkan daripada tidak mengumpulkan sama sekali.\nSesuai standar Universitas Indonesia, plagiarisme dilarang keras dan bisa menyebabkan nilai tugas praktikum menjadi nol untuk semua pihak yang terlibat, tanpa peringatan apapun. Namun, Anda boleh memanfaatkan kode apapun yang ada di modul praktikum.\nNarahubung untuk Tugas 3 Praktikum Sains Data adalah:\n\nRifki - LINE: rifkyprakasya_\nBisma - LINE: bisma_joyosumarto\n\n\n\n\n\nTugas 3 ini terdiri dari soal a-e.\nDi beberapa praktikum terakhir, kalian sudah mempelajari tentang neural network, baik menggunakan TensorFlow & Keras maupun menggunakan PyTorch. Untuk melatih apa yang telah kalian pelajari, mari kita coba contoh kasus yang sempat mengguncang dunia: klasifikasi gambar bilangan/digit 0-9 (dengan dataset MNIST) menggunakan neural network.\nUntuk tugas ini, kalian dibebaskan memilih antara menggunakan TensorFlow & Keras atau menggunakan PyTorch. Pilihlah salah satu.\nKemudian, lakukan end-to-end machine learning, atau lebih tepatnya end-to-end classification, yang meliputi:\n\nPerolehan data\nApabila kalian menggunakan TensorFlow & Keras, kalian bisa memperoleh dataset MNIST dengan kode seperti berikut:\nmnist = keras.datasets.mnist\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nNamun, jika kalian menggunakan PyTorch, kalian bisa memperoleh objek Dataset untuk dataset MNIST dengan kode seperti berikut:\nmnist_train = torchvision.datasets.MNIST(\n    root = \"./mnist_data\", # folder tempat download\n    train = True, # data training\n    download = True, # karena belum ada\n    # agar file gambar otomatis diubah menjadi tensor\n    transform = torchvision.transforms.ToTensor()\n)\n\nmnist_test = torchvision.datasets.MNIST(\n    root = \"./mnist_data\", # folder yang sama untuk tempat download\n    train = False, # bukan data training\n    download = True,\n    transform = torchvision.transforms.ToTensor()\n)\nSetelah memperolehnya, terlepas apakah kalian menggunakan TensorFlow & Keras atau PyTorch, kalian bisa mempertimbangkan bagaimana cara memperoleh data validation: apakah dari data training atau dari data testing, atau bahkan data testing langsung dianggap data validation.\nUntuk PyTorch, jangan lupa mengubahnya menjadi DataLoader juga.\nLangkah preprocessing yang sekiranya diperlukan, kalau ada.\nTraining: buatlah model neural network menggunakan framework yang telah Anda pilih (yaitu antara Tensorflow & Keras atau PyTorch) untuk menyelesaikan masalah klasifikasi gambar tersebut.\nAnda dibebaskan untuk memilih hyperparameter seperti\n\n\nsusunan arsitektur (berkreasilah!): banyaknya hidden layer, banyaknya neuron di tiap layer, dan fungsi aktivasi di tiap layer;\noptimizer;\nlearning rate;\nbanyaknya epoch; dan\nbatch size.\nLakukan training, simpanlah history dari training loss serta validation loss ke dalam file mymodel_loss_hist.csv, lalu tampilkan plot training loss dan validation loss terhadap epoch.\nTidak ada larangan apabila Anda ingin melakukan hyperparameter tuning, yaitu mencoba beberapa pilihan hyperparameter (misalnya mencoba beberapa arsitektur) kemudian memilih model dengan performa terbaik.\nSimpan juga weights dari model Anda, yaitu ke dalam file mymodel.weights.h5 untuk TensorFlow & Keras, atau ke dalam file mymodel.pth untuk PyTorch.\n\n\nMencoba prediksi: menggunakan model tersebut, lakukan prediksi kelas untuk beberapa gambar yang ada di data testing, dan bandingkan dengan kelas aslinya. (Anda boleh juga menampilkan hasil prediksi kelas dari gambar menggunakan slider seperti yang ada di modul praktikum).\nEvaluasi model: untuk model neural network yang telah Anda buat, tampilkan/hitunglah metrik evaluasi untuk klasifikasi, misalnya menampilkan confusion matrix atau menghitung Jaccard score."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/tugas3.html#petunjuk-umum",
    "href": "semuahalaman/modulprak/2024/genap/saindat/tugas3.html#petunjuk-umum",
    "title": "Tugas 3 Praktikum Sains Data 2024 Genap: Klasifikasi Gambar dengan Neural Network",
    "section": "",
    "text": "Kerjakan secara individu.\nKerjakan tugas ini menggunakan bahasa pemrograman Python dengan file format berupa interactive Python notebook (yaitu file berbentuk .ipynb BUKAN .py), yang bisa dibuat misalnya menggunakan Jupyter Notebook atau Google Colaboratory.\nHarap sertakan penjelasan untuk setiap proses secara singkat di samping potongan kode (bisa dengan teks / text box maupun dengan comment, ‘#’).\nFormat nama file untuk Tugas 3 adalah:\nNama Lengkap_NPM_Kelas SIAK_Tugas3PrakSaindat.ipynb\nContoh penamaan yang benar:\nYann André LeCun_2201234567_Kelas C_Tugas3PrakSaindat.ipynb\nUntuk mengumpulkan lebih dari satu file, gunakan .zip dengan format nama yang sama (dan file .ipynb yang di dalamnya juga masih menggunakan format nama yang sama).\nApabila ada yang ingin direvisi setelah pengumpulan, lakukan pengumpulan ulang di Google Forms yang sama, tambahkan keterangan bahwa ada revisi, dan tambahkan kata “revisi” pada bagian akhir nama file, contohnya menjadi\nYann André LeCun_2201234567_Kelas C_Tugas3PrakSaindat_revisi.ipynb\nYann André LeCun_2201234567_Kelas C_Tugas3PrakSaindat_revisi2.ipynb\nYann André LeCun_2201234567_Kelas C_Tugas3PrakSaindat_revisi3.ipynb\n(tentunya gunakan .zip kalau ada lebih dari satu file yang ingin dikumpulkan)\n(Revisi boleh dilakukan berkali-kali selama masa pengerjaan.)\nPengumpulan tugas dilakukan ke Google Forms berikut ini, sesuai dengan kelas Anda di SIAK NG (link akan selalu sama untuk semua tugas praktikum Sains Data):\n\nKelas A: https://forms.gle/TdxprAuySMAWt5NR7\nKelas B: https://forms.gle/bk2LBnowfZhmw5qY9\n\nDengan durasi pengerjaan sekitar 3 (tiga) minggu, tenggat waktu (deadline) pengumpulan Tugas 3 ini (termasuk revisi) adalah:\nSabtu, 8 Juni 2024, pukul 23.59 WIB.\nMohon manfaatkan waktu Anda dengan baik (seperti mencicil pengerjaan, bahkan sudah selesai dari jauh-jauh hari) agar mengumpulkan tugas sebelum deadline. Keterlambatan pengumpulan bisa dikenakan pengurangan nilai atau bahkan dianggap tidak mengumpulkan, tergantung kesepakatan dari dosen. Meskipun demikian, lebih baik terlambat mengumpulkan daripada tidak mengumpulkan sama sekali.\nSesuai standar Universitas Indonesia, plagiarisme dilarang keras dan bisa menyebabkan nilai tugas praktikum menjadi nol untuk semua pihak yang terlibat, tanpa peringatan apapun. Namun, Anda boleh memanfaatkan kode apapun yang ada di modul praktikum.\nNarahubung untuk Tugas 3 Praktikum Sains Data adalah:\n\nRifki - LINE: rifkyprakasya_\nBisma - LINE: bisma_joyosumarto"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/tugas3.html#soal",
    "href": "semuahalaman/modulprak/2024/genap/saindat/tugas3.html#soal",
    "title": "Tugas 3 Praktikum Sains Data 2024 Genap: Klasifikasi Gambar dengan Neural Network",
    "section": "",
    "text": "Tugas 3 ini terdiri dari soal a-e.\nDi beberapa praktikum terakhir, kalian sudah mempelajari tentang neural network, baik menggunakan TensorFlow & Keras maupun menggunakan PyTorch. Untuk melatih apa yang telah kalian pelajari, mari kita coba contoh kasus yang sempat mengguncang dunia: klasifikasi gambar bilangan/digit 0-9 (dengan dataset MNIST) menggunakan neural network.\nUntuk tugas ini, kalian dibebaskan memilih antara menggunakan TensorFlow & Keras atau menggunakan PyTorch. Pilihlah salah satu.\nKemudian, lakukan end-to-end machine learning, atau lebih tepatnya end-to-end classification, yang meliputi:\n\nPerolehan data\nApabila kalian menggunakan TensorFlow & Keras, kalian bisa memperoleh dataset MNIST dengan kode seperti berikut:\nmnist = keras.datasets.mnist\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nNamun, jika kalian menggunakan PyTorch, kalian bisa memperoleh objek Dataset untuk dataset MNIST dengan kode seperti berikut:\nmnist_train = torchvision.datasets.MNIST(\n    root = \"./mnist_data\", # folder tempat download\n    train = True, # data training\n    download = True, # karena belum ada\n    # agar file gambar otomatis diubah menjadi tensor\n    transform = torchvision.transforms.ToTensor()\n)\n\nmnist_test = torchvision.datasets.MNIST(\n    root = \"./mnist_data\", # folder yang sama untuk tempat download\n    train = False, # bukan data training\n    download = True,\n    transform = torchvision.transforms.ToTensor()\n)\nSetelah memperolehnya, terlepas apakah kalian menggunakan TensorFlow & Keras atau PyTorch, kalian bisa mempertimbangkan bagaimana cara memperoleh data validation: apakah dari data training atau dari data testing, atau bahkan data testing langsung dianggap data validation.\nUntuk PyTorch, jangan lupa mengubahnya menjadi DataLoader juga.\nLangkah preprocessing yang sekiranya diperlukan, kalau ada.\nTraining: buatlah model neural network menggunakan framework yang telah Anda pilih (yaitu antara Tensorflow & Keras atau PyTorch) untuk menyelesaikan masalah klasifikasi gambar tersebut.\nAnda dibebaskan untuk memilih hyperparameter seperti\n\n\nsusunan arsitektur (berkreasilah!): banyaknya hidden layer, banyaknya neuron di tiap layer, dan fungsi aktivasi di tiap layer;\noptimizer;\nlearning rate;\nbanyaknya epoch; dan\nbatch size.\nLakukan training, simpanlah history dari training loss serta validation loss ke dalam file mymodel_loss_hist.csv, lalu tampilkan plot training loss dan validation loss terhadap epoch.\nTidak ada larangan apabila Anda ingin melakukan hyperparameter tuning, yaitu mencoba beberapa pilihan hyperparameter (misalnya mencoba beberapa arsitektur) kemudian memilih model dengan performa terbaik.\nSimpan juga weights dari model Anda, yaitu ke dalam file mymodel.weights.h5 untuk TensorFlow & Keras, atau ke dalam file mymodel.pth untuk PyTorch.\n\n\nMencoba prediksi: menggunakan model tersebut, lakukan prediksi kelas untuk beberapa gambar yang ada di data testing, dan bandingkan dengan kelas aslinya. (Anda boleh juga menampilkan hasil prediksi kelas dari gambar menggunakan slider seperti yang ada di modul praktikum).\nEvaluasi model: untuk model neural network yang telah Anda buat, tampilkan/hitunglah metrik evaluasi untuk klasifikasi, misalnya menampilkan confusion matrix atau menghitung Jaccard score."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/tugas3.html",
    "href": "semuahalaman/modulprak/2024/genap/metnum/tugas3.html",
    "title": "Tugas 3 Praktikum Metode Numerik",
    "section": "",
    "text": "Semester Genap Tahun Ajaran 2023/2024\nKembali ke Metode Numerik"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/tugas3.html#petunjuk-umum",
    "href": "semuahalaman/modulprak/2024/genap/metnum/tugas3.html#petunjuk-umum",
    "title": "Tugas 3 Praktikum Metode Numerik",
    "section": "Petunjuk Umum:",
    "text": "Petunjuk Umum:\n\nKerjakan secara individu.\nKerjakan tugas ini menggunakan bahasa pemrograman Python dengan file format berupa interactive Python notebook (yaitu file berbentuk .ipynb BUKAN .py), yang bisa dibuat misalnya menggunakan Jupyter Notebook atau Google Colaboratory.\nHarap sertakan penjelasan untuk setiap variabel yang digunakan dan setiap proses secara singkat di samping potongan kode (dengan comment, ‘#’). Selain itu, sertakan juga penjelasan program (yang bisa mencakupi idenya apa, bagaimana cara eksekusi program, atau tentang algoritma program yang digunakan) pada cell di sebelah (atas/bawah) program.\nFormat nama file untuk Tugas 3 adalah:\nNama Lengkap_NPM_Kelas SIAK_Tugas3PrakMetnum.ipynb\nContoh penamaan yang benar:\nLuthfi Athallah Herdita Wiryaman_2206826980_Kelas G_Tugas3PrakMetnum.ipynb\nApabila ada yang ingin direvisi setelah pengumpulan, lakukan pengumpulan ulang di Google Forms yang sama, tambahkan keterangan bahwa ada revisi, dan tambahkan kata “revisi” pada bagian akhir nama file, contohnya menjadi\nLuthfi Athallah Herdita Wiryaman_2206826980_Kelas G_Tugas3PrakMetnum_revisi.ipynb\nLuthfi Athallah Herdita Wiryaman_2206826980_Kelas G_Tugas3PrakMetnum_revisi2.ipynb\nLuthfi Athallah Herdita Wiryaman_2206826980_Kelas G_Tugas3PrakMetnum_revisi3.ipynb\n(Revisi boleh dilakukan berkali-kali.)\nPengumpulan tugas dilakukan ke Google Forms berikut ini, sesuai dengan kelas Anda di SIAK NG (link akan selalu sama untuk semua tugas praktikum metode numerik):\n\nKelas A: https://forms.gle/AaWvGqEmY1nyx2d48\nKelas B: https://forms.gle/f433d9oJozgkdKZv5\nKelas C: https://forms.gle/iQbibikmgEacst8Z8\nKelas D: https://forms.gle/8F5D9hha2yEstd6z8\nKelas E: https://forms.gle/xz9fpedj9JLXHJH37\nKelas F: https://forms.gle/Ho7kbabuJUopkAP78\n\nDurasi pengerjaan Tugas 3 ini adalah 2 (dua) minggu, dan tenggat waktu (deadline) pengumpulan Tugas 3 ini adalah:\nMinggu, 9 Juni 2024, pukul 23.59 WIB.\nMohon manfaatkan waktu Anda dengan baik (seperti mencicil pengerjaan, bahkan sudah selesai dari jauh-jauh hari) agar mengumpulkan tugas sebelum deadline. Keterlambatan pengumpulan bisa dikenakan pengurangan nilai atau bahkan dianggap tidak mengumpulkan, tergantung kesepakatan dari dosen. Meskipun demikian, lebih baik terlambat mengumpulkan daripada tidak mengumpulkan sama sekali.\nSesuai standar Universitas Indonesia, plagiarisme dilarang keras dan bisa menyebabkan nilai tugas praktikum menjadi nol untuk semua pihak yang terlibat, tanpa peringatan apapun.\nModule atau package Python yang boleh digunakan (di-import) untuk Tugas 3 ini hanyalah NumPy, Tabulate, dan matplotlib. Apabila Anda berniat ingin menggunakan module lain, harap konfirmasikan ke narahubung terlebih dahulu (bisa saja diperbolehkan).\nNarahubung untuk Tugas 3 Praktikum Metode Numerik adalah:\n\nZaki - LINE: linenyazaki\nPandu - LINE: pandyadaffa\nDahut - LINE: narendrahutapea\nDani - LINE: 123_dani"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/tugas3.html#soal-tugas-3-praktikum-metode-numerik",
    "href": "semuahalaman/modulprak/2024/genap/metnum/tugas3.html#soal-tugas-3-praktikum-metode-numerik",
    "title": "Tugas 3 Praktikum Metode Numerik",
    "section": "Soal Tugas 3 Praktikum Metode Numerik",
    "text": "Soal Tugas 3 Praktikum Metode Numerik\n\nKetentuan Soal\nDiberikan suatu fungsi \\(f:[1+k, 3+k]→\\mathbb{R}\\) dengan \\[\\begin{equation}\nf(x) = x\\ln x\n\\end{equation}\\] dan \\(k = \\text{(NPM)} \\mod 5\\). Kita bisa mengaproksimasi fungsi tersebut dalam bentuk polinomial berderajat \\(n=2\\), misalkan \\(P_2(x)=a_2x^2+a_1x+a_0\\), dengan menyelesaikan Sistem Persamaan Linier berikut \\[\\begin{align}\na_0\\int_a^bx^0dx+a_1\\int_a^bx^1dx+a_2\\int_a^bx^2dx&=\\int_a^bx^0f(x)dx\\\\\na_0\\int_a^bx^1dx+a_1\\int_a^bx^2dx+a_2\\int_a^bx^3dx&=\\int_a^bx^1f(x)dx\\\\\na_0\\int_a^bx^2dx+a_1\\int_a^bx^3dx+a_2\\int_a^bx^4dx&=\\int_a^bx^2f(x)dx\n\\end{align}\\] Sistem persamaan tersebut disebut sebagai Persamaan Normal (normal equations) dengan \\(n=2\\). Rumus umum dari Persamaan Normal (untuk sembarang \\(n\\)) adalah SPL berikut: \\[\\begin{align}\n\\sum_{k=0}^na_k\\int_a^bx^{j+k}dx=\\int_a^bx^jf(x)dx, \\text{ untuk setiap } j = 0,1,..., n\n\\end{align}\\] Solusi dari SPL tersebut merupakan koefisien-koefisien dari polinomial \\(P_n\\). Dalam kasus polinomial berderajat dua di atas, solusi dari SPL tersebut secara berturut-turut menjadi nilai-nilai \\(a_0, a_1, a_2\\).\n(Kalau tertarik, kalian boleh saja baca lebih lanjut di subbab 8.2 buku Burden, atau bahkan mempelajari lebih lanjut di mata kuliah Matematika Numerik).\nBuatlah program untuk menyelesaikan Persamaan Normal dari fungsi \\(f\\) yang diberikan, dalam rangka menentukan aproksimasi polinomial berderajat dua \\(P_2\\) dari \\(f\\).\n\n\nTugas Integrasi Numerik\n[40] Gunakan salah satu dari metode berikut untuk mengaproksimasi hasil integral pada koefisien persamaan normal - Integrasi Numerik Komposit dengan banyaknya subinterval besar N = k + 10 (boleh menggunakan rumus khusus atau rumus umum dengan memilih salah satu metode Newton-Cotes) - Kuadratur Adaptif dengan metode Simpson (metode Simpson adaptif), dengan toleransi \\(10^{-5}\\) dan faktor/pengkali toleransi = 10\n\n\nTugas SPL Iteratif\n\n[20] Setelah didapatkan nilai koefisien dan konstanta dari persamaan normal tersebut pada langkah sebelumnya, selesaikan SPL tersebut secara iteratif menggunakan metode Gauss-Seidel dengan nilai awalnya adalah vektor nol \\((0,0,...,0)\\), toleransi = \\(10^{-5}\\), dan maksimal banyaknya iterasi adalah \\(200\\). Gunakan error absolut dan norm infinity untuk menghitung error pada tiap iterasi.\n[20] Tampilkan hasil \\(a_0, a_1, a_2\\) pada tiap iterasi Gauss-Seidel dan nilai error pada iterasi tersebut dalam bentuk tabel.\n\n\n\nKerapian Program\n\n[10] Keseluruhan program dikemas di dalam satu subprogram atau fungsi (function) yang bisa menerima sembarang fungsi \\(f\\), interval \\([a, b]\\), NPM, toleransi dan faktor pengali (jika menggunakan metode kuadratur adaptif), serta toleransi dan maksimal banyaknya iterasi untuk metode Gauss-Seidel.\n[10] Program Anda bisa berjalan berulang kali (dengan beberapa kali input dan output) sesuai permintaan user, tanpa harus berhenti dan di-run ulang secara manual terlebih dahulu.\n\n\n\nBonus\nKetentuan berikut tidak wajib kalian buat, namun apabila dikerjakan akan menjadi nilai tambah apabila terdapat kekurangan pada program yang telah kalian buat.\n\nProgram dapat menampilkan hasil fungsi \\(P_2\\) kemudian buat plot perbandingan fungsi \\(f\\) dan \\(P_2\\).\nProgram dapat menerima sembarang nilai \\(n\\) dan menghasilkan polinomial aproksimasi berderajat \\(n\\)."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/metnum/tugas3.html#contoh-output-program-disclaimer-contoh-input-kemungkinan-berbeda-dengan-soal-dalam-pengerjaan-tetap-pakai-input-soal",
    "href": "semuahalaman/modulprak/2024/genap/metnum/tugas3.html#contoh-output-program-disclaimer-contoh-input-kemungkinan-berbeda-dengan-soal-dalam-pengerjaan-tetap-pakai-input-soal",
    "title": "Tugas 3 Praktikum Metode Numerik",
    "section": "Contoh Output Program (disclaimer: contoh input kemungkinan berbeda dengan soal, dalam pengerjaan tetap pakai input soal)",
    "text": "Contoh Output Program (disclaimer: contoh input kemungkinan berbeda dengan soal, dalam pengerjaan tetap pakai input soal)\nMasukkan fungsi f yang ingin di aproksimasi: x*log(x)\nMasukkan derajat polinomial aproksimasinya (bonus, boleh langsung dibuat n = 2): 2\nMasukkan NPM anda: 2206026867\nNilai k yang digunakan adalah k = 2\n\nMetode yang digunakan untuk integrasi numerik adalah metode komposit boole's rule dengan banyaknya subinterval besar adalah N = 12\nMasukkan batas bawah interval: 1\nMasukkan batas atas interval: 3\n\nInterval yang digunakan adalah [3, 5]\n\nMatriks diperbesar yang didapat menggunakan metode komposit boole's rule adalah:\n[[  2.           8.          32.66666667  11.17421861]\n [  8.          32.66666667 136.          46.28351353]\n [ 32.66666667 136.         576.4        195.22777497]]\n\nAkan digunakan metode Gauss-Seidel untuk menyelesaikan SPL\nMasukkan besar toleransi error: 10**(-7)\nMasukkan banyaknya iterasi maksimal: 100\n\nTabel hasil iterasi Gauss Seidel dari matriks diperbesar tersebut adalah\n|   Iterasi |         x1 |        x2 |        x3 |        Error |\n|-----------+------------+-----------+-----------+--------------|\n|         0 |  0         | 0         | 0         | nan          |\n|         1 |  5.58711   | 0.0485706 | 0.0106002 |   5.58711    |\n|         2 |  5.21969   | 0.0944193 | 0.0206052 |   0.367418   |\n|         3 |  4.87288   | 0.137699  | 0.0300485 |   0.346811   |\n|         4 |  4.54552   | 0.178553  | 0.0389617 |   0.327359   |\n|         5 |  4.23652   | 0.217119  | 0.0473743 |   0.308999   |\n|         6 |  3.94485   | 0.253524  | 0.0553146 |   0.291669   |\n|         7 |  3.66954   | 0.28789   | 0.0628089 |   0.275311   |\n|         8 |  3.40967   | 0.32033   | 0.0698824 |   0.259871   |\n|         9 |  3.16437   | 0.350954  | 0.0765587 |   0.245297   |\n|        10 |  2.93283   | 0.379863  | 0.08286   |   0.231541   |\n|        11 |  2.71428   | 0.407153  | 0.0888073 |   0.218556   |\n|        12 |  2.50798   | 0.432915  | 0.0944206 |   0.206301   |\n|        13 |  2.31324   | 0.457235  | 0.0997186 |   0.194732   |\n|        14 |  2.12943   | 0.480194  | 0.104719  |   0.183813   |\n|        15 |  1.95592   | 0.501868  | 0.109438  |   0.173507   |\n|        16 |  1.79215   | 0.522329  | 0.113892  |   0.163778   |\n|        17 |  1.63755   | 0.541645  | 0.118096  |   0.154596   |\n|        18 |  1.49162   | 0.55988   | 0.122064  |   0.145928   |\n|        19 |  1.35388   | 0.577096  | 0.125809  |   0.137747   |\n|        20 |  1.22385   | 0.593349  | 0.129343  |   0.130025   |\n|        21 |  1.10111   | 0.608693  | 0.132678  |   0.122736   |\n|        22 |  0.985257  | 0.62318   | 0.135826  |   0.115856   |\n|        23 |  0.875895  | 0.636857  | 0.138797  |   0.109363   |\n|        24 |  0.772662  | 0.649769  | 0.141601  |   0.103233   |\n|        25 |  0.675214  | 0.661961  | 0.144247  |   0.0974474  |\n|        26 |  0.583228  | 0.673471  | 0.146745  |   0.0919863  |\n|        27 |  0.496396  | 0.684339  | 0.149101  |   0.0868317  |\n|        28 |  0.41443   | 0.694601  | 0.151326  |   0.0819662  |\n|        29 |  0.337056  | 0.70429   | 0.153425  |   0.0773738  |\n|        30 |  0.264017  | 0.713438  | 0.155405  |   0.0730389  |\n|        31 |  0.19507   | 0.722076  | 0.157275  |   0.0689473  |\n|        32 |  0.129985  | 0.730233  | 0.159039  |   0.0650853  |\n|        33 |  0.0685448 | 0.737936  | 0.160703  |   0.0614399  |\n|        34 |  0.0105457 | 0.745209  | 0.162274  |   0.0579991  |\n|        35 | -0.0442055 | 0.752077  | 0.163757  |   0.0547513  |\n|        36 | -0.0958912 | 0.758564  | 0.165155  |   0.0516857  |\n|        37 | -0.144683  | 0.764689  | 0.166475  |   0.0487921  |\n|        38 | -0.190744  | 0.770474  | 0.167721  |   0.0460608  |\n|        39 | -0.234227  | 0.775938  | 0.168896  |   0.0434828  |\n|        40 | -0.275276  | 0.781098  | 0.170005  |   0.0410495  |\n|        41 | -0.314029  | 0.785972  | 0.171051  |   0.0387526  |\n|        42 | -0.350614  | 0.790576  | 0.172038  |   0.0365846  |\n|        43 | -0.385152  | 0.794924  | 0.17297   |   0.0345383  |\n|        44 | -0.417759  | 0.799032  | 0.173848  |   0.0326067  |\n|        45 | -0.448542  | 0.802912  | 0.174677  |   0.0307836  |\n|        46 | -0.477605  | 0.806578  | 0.17546   |   0.0290627  |\n|        47 | -0.505043  | 0.810042  | 0.176197  |   0.0274384  |\n|        48 | -0.530948  | 0.813314  | 0.176893  |   0.0259052  |\n|        49 | -0.555406  | 0.816406  | 0.17755   |   0.024458   |\n|        50 | -0.578498  | 0.819327  | 0.17817   |   0.023092   |\n|        51 | -0.600301  | 0.822088  | 0.178754  |   0.0218026  |\n|        52 | -0.620887  | 0.824697  | 0.179305  |   0.0205856  |\n|        53 | -0.640324  | 0.827163  | 0.179825  |   0.0194369  |\n|        54 | -0.658676  | 0.829493  | 0.180315  |   0.0183526  |\n|        55 | -0.676005  | 0.831696  | 0.180777  |   0.0173292  |\n|        56 | -0.692368  | 0.833779  | 0.181213  |   0.0163631  |\n|        57 | -0.70782   | 0.835748  | 0.181624  |   0.0154513  |\n|        58 | -0.72241   | 0.837609  | 0.182012  |   0.0145906  |\n|        59 | -0.736189  | 0.839369  | 0.182377  |   0.0137782  |\n|        60 | -0.7492    | 0.841034  | 0.182722  |   0.0130114  |\n|        61 | -0.761488  | 0.842609  | 0.183047  |   0.0122877  |\n|        62 | -0.773092  | 0.844098  | 0.183353  |   0.0116045  |\n|        63 | -0.784052  | 0.845507  | 0.183642  |   0.0109596  |\n|        64 | -0.794403  | 0.84684   | 0.183914  |   0.010351   |\n|        65 | -0.804179  | 0.848101  | 0.184171  |   0.00977643 |\n|        66 | -0.813413  | 0.849295  | 0.184412  |   0.00923414 |\n|        67 | -0.822136  | 0.850425  | 0.18464   |   0.00872228 |\n|        68 | -0.830375  | 0.851494  | 0.184854  |   0.00823913 |\n|        69 | -0.838158  | 0.852507  | 0.185057  |   0.00778309 |\n|        70 | -0.845511  | 0.853466  | 0.185247  |   0.00735263 |\n|        71 | -0.852457  | 0.854375  | 0.185426  |   0.00694633 |\n|        72 | -0.85902   | 0.855236  | 0.185595  |   0.00656282 |\n|        73 | -0.86522   | 0.856051  | 0.185754  |   0.00620082 |\n|        74 | -0.87108   | 0.856824  | 0.185904  |   0.00585914 |\n|        75 | -0.876616  | 0.857557  | 0.186045  |   0.00553662 |\n|        76 | -0.881848  | 0.858252  | 0.186177  |   0.0052322  |\n|        77 | -0.886793  | 0.858911  | 0.186302  |   0.00494486 |\n|        78 | -0.891467  | 0.859536  | 0.186419  |   0.00467364 |\n|        79 | -0.895885  | 0.860129  | 0.18653   |   0.00441763 |\n|        80 | -0.900061  | 0.860692  | 0.186634  |   0.00417599 |\n|        81 | -0.904008  | 0.861227  | 0.186731  |   0.0039479  |\n|        82 | -0.907741  | 0.861734  | 0.186823  |   0.00373261 |\n|        83 | -0.91127   | 0.862217  | 0.186909  |   0.0035294  |\n|        84 | -0.914608  | 0.862675  | 0.18699   |   0.00333759 |\n|        85 | -0.917765  | 0.863111  | 0.187066  |   0.00315654 |\n|        86 | -0.92075   | 0.863526  | 0.187138  |   0.00298564 |\n|        87 | -0.923575  | 0.863921  | 0.187205  |   0.00282434 |\n|        88 | -0.926247  | 0.864296  | 0.187267  |   0.00267208 |\n|        89 | -0.928775  | 0.864654  | 0.187326  |   0.00252837 |\n|        90 | -0.931168  | 0.864994  | 0.187381  |   0.00239271 |\n|        91 | -0.933432  | 0.865319  | 0.187433  |   0.00226467 |\n|        92 | -0.935576  | 0.865629  | 0.187482  |   0.00214381 |\n|        93 | -0.937606  | 0.865924  | 0.187527  |   0.00202973 |\n|        94 | -0.939528  | 0.866206  | 0.187569  |   0.00192205 |\n|        95 | -0.941348  | 0.866476  | 0.187609  |   0.00182041 |\n|        96 | -0.943073  | 0.866733  | 0.187646  |   0.00172448 |\n|        97 | -0.944707  | 0.866979  | 0.18768   |   0.00163392 |\n|        98 | -0.946255  | 0.867215  | 0.187713  |   0.00154845 |\n|        99 | -0.947723  | 0.86744   | 0.187743  |   0.00146776 |\nDidapatkan nilai a_0 = -0.9477230349410641 a_1 = 0.8674398999199682 a_2 = 0.18774271522888558\nFungsi approksimasi berdasarkan data yang diberikan adalah (bonus): 0.18774271522888558 * x ** 2 + 0.8674398999199682 * x - 0.9477230349410641\n\n\n\n\n\nsatu.png\n\n\nApakah Anda ingin menggunakan program ini lagi? (y/n): y\n\nMasukkan fungsi f yang ingin di aproksimasi: x*log(x)\nMasukkan derajat polinomial aproksimasinya (bonus, boleh langsung dibuat n = 2): 3\nMasukkan NPM anda: 2206026867\nNilai k yang digunakan adalah k = 2\n\nMetode yang digunakan untuk integrasi numerik adalah metode komposit boole's rule dengan banyaknya subinterval besar adalah N = 12\nMasukkan batas bawah interval: 3\nMasukkan batas atas interval: 5\n\nInterval yang digunakan adalah [5, 7]\n\nMatriks diperbesar yang didapat menggunakan metode komposit boole's rule adalah:\n[[2.00000000e+00 1.20000000e+01 7.26666667e+01 4.44000000e+02 1.31200258e+02]\n [1.20000000e+01 7.26666667e+01 4.44000000e+02 2.73640000e+03 8.05557893e+02]\n [7.26666667e+01 4.44000000e+02 2.73640000e+03 1.70040000e+04 4.98780368e+03]\n [4.44000000e+02 2.73640000e+03 1.70040000e+04 1.06488286e+05 3.11304860e+04]]\n\nAkan digunakan metode Gauss-Seidel untuk menyelesaikan SPL\nMasukkan besar toleransi error: 10**(-7)\nMasukkan banyaknya iterasi maksimal: 100\n\nTabel hasil iterasi Gauss Seidel dari matriks diperbesar tersebut adalah\n|   Iterasi |         x1 |       x2 |        x3 |        x4 |       Error |\n|-----------+------------+----------+-----------+-----------+-------------|\n|         0 |   0        | 0        | 0         | 0         | nan         |\n|         1 |  65.6001   | 0.25261  | 0.0397245 | 0.0059848 |  65.6001    |\n|         2 |  61.3125   | 0.492567 | 0.0774602 | 0.0116702 |   4.28761   |\n|         3 |  57.2396   | 0.720503 | 0.113307  | 0.017071  |   4.07295   |\n|         4 |  53.3705   | 0.937021 | 0.147359  | 0.0222017 |   3.86904   |\n|         5 |  49.6952   | 1.14269  | 0.179706  | 0.0270757 |   3.67533   |\n|         6 |  46.2039   | 1.33806  | 0.210433  | 0.0317058 |   3.49132   |\n|         7 |  42.8874   | 1.52364  | 0.239623  | 0.0361043 |   3.31652   |\n|         8 |  39.7369   | 1.69992  | 0.26735   | 0.0402827 |   3.15047   |\n|         9 |  36.7441   | 1.86736  | 0.29369   | 0.0442521 |   2.99274   |\n|        10 |  33.9012   | 2.02642  | 0.318711  | 0.048023  |   2.84289   |\n|        11 |  31.2007   | 2.1775   | 0.342479  | 0.0516052 |   2.70055   |\n|        12 |  28.6354   | 2.32102  | 0.365057  | 0.0550082 |   2.56533   |\n|        13 |  26.1985   | 2.45734  | 0.386504  | 0.058241  |   2.43688   |\n|        14 |  23.8836   | 2.58682  | 0.406878  | 0.0613121 |   2.31487   |\n|        15 |  21.6847   | 2.70982  | 0.426232  | 0.0642296 |   2.19895   |\n|        16 |  19.5958   | 2.82665  | 0.444616  | 0.0670012 |   2.08884   |\n|        17 |  17.6116   | 2.93763  | 0.46208   | 0.0696342 |   1.98425   |\n|        18 |  15.7267   | 3.04304  | 0.478669  | 0.0721355 |   1.88488   |\n|        19 |  13.9362   | 3.14316  | 0.494428  | 0.0745117 |   1.79049   |\n|        20 |  12.2354   | 3.23826  | 0.509397  | 0.0767691 |   1.70083   |\n|        21 |  10.6197   | 3.3286   | 0.523617  | 0.0789136 |   1.61565   |\n|        22 |   9.08497  | 3.4144   | 0.537125  | 0.0809509 |   1.53474   |\n|        23 |   7.62709  | 3.4959   | 0.549957  | 0.0828863 |   1.45788   |\n|        24 |   6.24222  | 3.57331  | 0.562145  | 0.084725  |   1.38486   |\n|        25 |   4.92672  | 3.64683  | 0.573724  | 0.0864718 |   1.3155    |\n|        26 |   3.6771   | 3.71667  | 0.584722  | 0.0881312 |   1.24962   |\n|        27 |   2.49007  | 3.783    | 0.59517   | 0.0897077 |   1.18703   |\n|        28 |   1.36251  | 3.846    | 0.605094  | 0.0912055 |   1.12757   |\n|        29 |   0.291419 | 3.90584  | 0.614521  | 0.0926283 |   1.07109   |\n|        30 |  -0.726014 | 3.96268  | 0.623476  | 0.0939801 |   1.01743   |\n|        31 |  -1.69248  | 4.01666  | 0.631983  | 0.0952643 |   0.966465  |\n|        32 |  -2.61053  | 4.06793  | 0.640063  | 0.0964844 |   0.918048  |\n|        33 |  -3.48258  | 4.11662  | 0.647738  | 0.0976435 |   0.872054  |\n|        34 |  -4.31094  | 4.16287  | 0.655029  | 0.0987447 |   0.828363  |\n|        35 |  -5.0978   | 4.20679  | 0.661955  | 0.0997909 |   0.786858  |\n|        36 |  -5.84523  | 4.24851  | 0.668534  | 0.100785  |   0.747431  |\n|        37 |  -6.55521  | 4.28812  | 0.674783  | 0.101729  |   0.709978  |\n|        38 |  -7.22961  | 4.32575  | 0.680719  | 0.102626  |   0.674399  |\n|        39 |  -7.87021  | 4.36148  | 0.686357  | 0.103479  |   0.640602  |\n|        40 |  -8.47871  | 4.39542  | 0.691713  | 0.104289  |   0.608496  |\n|        41 |  -9.0567   | 4.42765  | 0.696801  | 0.105058  |   0.577997  |\n|        42 |  -9.60573  | 4.45825  | 0.701633  | 0.105789  |   0.549025  |\n|        43 | -10.1272   | 4.48731  | 0.706224  | 0.106484  |   0.521503  |\n|        44 | -10.6226   | 4.51491  | 0.710584  | 0.107144  |   0.495358  |\n|        45 | -11.0931   | 4.54112  | 0.714725  | 0.107771  |   0.470522  |\n|        46 | -11.54     | 4.56601  | 0.718659  | 0.108366  |   0.44693   |\n|        47 | -11.9646   | 4.58965  | 0.722396  | 0.108932  |   0.424518  |\n|        48 | -12.3678   | 4.61209  | 0.725946  | 0.10947   |   0.403228  |\n|        49 | -12.7508   | 4.63339  | 0.729317  | 0.109981  |   0.383004  |\n|        50 | -13.1146   | 4.65363  | 0.732519  | 0.110467  |   0.363792  |\n|        51 | -13.4601   | 4.67284  | 0.735561  | 0.110928  |   0.345542  |\n|        52 | -13.7883   | 4.69108  | 0.73845   | 0.111367  |   0.328205  |\n|        53 | -14.1001   | 4.7084   | 0.741194  | 0.111783  |   0.311737  |\n|        54 | -14.3962   | 4.72484  | 0.743801  | 0.112179  |   0.296092  |\n|        55 | -14.6774   | 4.74045  | 0.746276  | 0.112555  |   0.281231  |\n|        56 | -14.9445   | 4.75527  | 0.748628  | 0.112913  |   0.267113  |\n|        57 | -15.1982   | 4.76933  | 0.750861  | 0.113252  |   0.253702  |\n|        58 | -15.4392   | 4.78269  | 0.752983  | 0.113575  |   0.240963  |\n|        59 | -15.668    | 4.79536  | 0.754997  | 0.113882  |   0.228861  |\n|        60 | -15.8854   | 4.8074   | 0.756911  | 0.114173  |   0.217365  |\n|        61 | -16.0918   | 4.81882  | 0.758729  | 0.11445   |   0.206444  |\n|        62 | -16.2879   | 4.82966  | 0.760455  | 0.114714  |   0.19607   |\n|        63 | -16.4741   | 4.83995  | 0.762094  | 0.114964  |   0.186215  |\n|        64 | -16.651    | 4.84971  | 0.763651  | 0.115202  |   0.176854  |\n|        65 | -16.8189   | 4.85898  | 0.76513   | 0.115428  |   0.167961  |\n|        66 | -16.9785   | 4.86777  | 0.766535  | 0.115643  |   0.159513  |\n|        67 | -17.1299   | 4.87612  | 0.767868  | 0.115847  |   0.151488  |\n|        68 | -17.2738   | 4.88404  | 0.769135  | 0.116041  |   0.143865  |\n|        69 | -17.4104   | 4.89155  | 0.770338  | 0.116226  |   0.136623  |\n|        70 | -17.5402   | 4.89867  | 0.771481  | 0.116401  |   0.129744  |\n|        71 | -17.6634   | 4.90544  | 0.772566  | 0.116568  |   0.123209  |\n|        72 | -17.7804   | 4.91185  | 0.773596  | 0.116726  |   0.117002  |\n|        73 | -17.8915   | 4.91793  | 0.774574  | 0.116877  |   0.111105  |\n|        74 | -17.997    | 4.9237   | 0.775503  | 0.11702   |   0.105503  |\n|        75 | -18.0972   | 4.92917  | 0.776386  | 0.117156  |   0.100182  |\n|        76 | -18.1923   | 4.93436  | 0.777223  | 0.117286  |   0.0951267 |\n|        77 | -18.2826   | 4.93928  | 0.778019  | 0.117409  |   0.0903247 |\n|        78 | -18.3684   | 4.94394  | 0.778774  | 0.117526  |   0.0857631 |\n|        79 | -18.4498   | 4.94837  | 0.779492  | 0.117638  |   0.0814299 |\n|        80 | -18.5271   | 4.95256  | 0.780173  | 0.117743  |   0.0773135 |\n|        81 | -18.6005   | 4.95653  | 0.780819  | 0.117844  |   0.0734032 |\n|        82 | -18.6702   | 4.96029  | 0.781433  | 0.11794   |   0.0696886 |\n|        83 | -18.7364   | 4.96386  | 0.782016  | 0.118031  |   0.06616   |\n|        84 | -18.7992   | 4.96724  | 0.782569  | 0.118118  |   0.062808  |\n|        85 | -18.8588   | 4.97044  | 0.783095  | 0.1182    |   0.0596238 |\n|        86 | -18.9154   | 4.97347  | 0.783593  | 0.118279  |   0.0565989 |\n|        87 | -18.9691   | 4.97634  | 0.784067  | 0.118353  |   0.0537255 |\n|        88 | -19.0201   | 4.97906  | 0.784516  | 0.118424  |   0.0509959 |\n|        89 | -19.0685   | 4.98163  | 0.784943  | 0.118492  |   0.048403  |\n|        90 | -19.1145   | 4.98406  | 0.785348  | 0.118556  |   0.0459398 |\n|        91 | -19.1581   | 4.98637  | 0.785732  | 0.118618  |   0.0436    |\n|        92 | -19.1995   | 4.98855  | 0.786097  | 0.118676  |   0.0413773 |\n|        93 | -19.2387   | 4.99061  | 0.786443  | 0.118731  |   0.0392658 |\n|        94 | -19.276    | 4.99255  | 0.786771  | 0.118784  |   0.03726   |\n|        95 | -19.3113   | 4.9944   | 0.787083  | 0.118835  |   0.0353547 |\n|        96 | -19.3449   | 4.99614  | 0.787379  | 0.118883  |   0.0335447 |\n|        97 | -19.3767   | 4.99778  | 0.78766   | 0.118928  |   0.0318253 |\n|        98 | -19.4069   | 4.99933  | 0.787926  | 0.118972  |   0.030192  |\n|        99 | -19.4355   | 5.0008   | 0.788179  | 0.119013  |   0.0286404 |\nDidapatkan nilai a_0 = -19.435538369145267 a_1 = 5.000797855866304 a_2 = 0.788178630037227 a_3 = 0.11901301847757702\nFungsi approksimasi berdasarkan data yang diberikan adalah (bonus): 0.11901301847757702 * x ** 3 + 0.788178630037227 * x ** 2 + 5.000797855866304 * x - 19.435538369145267\n\n\n\ndua.png\n\n\nApakah Anda ingin menggunakan program ini lagi? (y/n) n\nTerima kasih telah menggunakan program ini."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/tugas_kalku2.html",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/tugas_kalku2.html",
    "title": "Tugas Praktikum Kalkulus 2, 2024 Genap",
    "section": "",
    "text": "Dibuat oleh Tim Aslab Kalkulin 2024 Genap\nKembali ke Kalkulin\nPetunjuk ini disalin dari https://bit.ly/TugasPraktikumKalkulus2Revisi"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/tugas_kalku2.html#ketentuan-pengerjaan-tugas",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/tugas_kalku2.html#ketentuan-pengerjaan-tugas",
    "title": "Tugas Praktikum Kalkulus 2, 2024 Genap",
    "section": "Ketentuan Pengerjaan Tugas",
    "text": "Ketentuan Pengerjaan Tugas\n\nTerdapat 2 soal yang perlu dikerjakan, soal pertama kalian diminta untuk mengerjakannya secara manual (tulis tangan) dengan bantuan wolfram mathematica.\nTugas dikumpulkan paling lambat Minggu, 26 Mei 2023 Pukul 23.59 WIB. Keterlambatan menyebabkan nilai maksimal hanya 70 saja.\nKerjakan semua soal menggunakan Wolfram Mathematica, tools yang digunakan bebas, tidak terbatas pada yang sudah diajarkan oleh kami. Pada setiap soal, kalian akan menggunakan beberapa syntax, jelaskan secara singkat saja kegunaannya pada pengerjaan soal yang diberikan.\nKalian dipersilahkan untuk berdiskusi dengan teman kalian. Akan tetapi, kalian tidak diizinkan untuk mengumpulkan hasil yang sama persis dengan teman kalian. Kami sarankan jika kalian berdiskusi dengan teman kalian, setiap orang harus menulis syntax pada Wolfram Mathematica, jangan langsung copy paste syntaxnya. Pelanggaran terhadap peraturan akan menyebabkan nilai tugas menjadi 0.\nSemua file dikumpulkan dalam bentuk file .zip dengan ketentuan penamaan: NPM_Nama Lengkap_Tugas Praktikum Kalkulus 2\nContoh: 2106706322_Peter Alexander_Tugas Praktikum Kalkulus 2.\nKumpulkan file .zip pada link berikut:\nhttps://bit.ly/PengumpulanTugasPraktikumKalkulus2\nhttps://bit.ly/PengumpulanTugasPraktikumKalkulus2\nhttps://bit.ly/PengumpulanTugasPraktikumKalkulus2\nJika ada yang ingin ditanyakan silahkan menghubungi:\n\nSoal 1: Peter Alexander (petlex/088289326995)\nSoal 2. Muhammad Fasya Syaifullah (ifasyai/087841154853)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/tugas_kalku2.html#soal",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/tugas_kalku2.html#soal",
    "title": "Tugas Praktikum Kalkulus 2, 2024 Genap",
    "section": "Soal",
    "text": "Soal\n\nAlleo seorang mahasiswa S1 Matematika UI angkatan 2023. Suatu hari kakaknya, Toby, melihat Alleo sedang sakit demam di ranjang. Toby memutuskan untuk mengambilkan obat demamnya, namun dia tidak segera memberikannya untuk Alleo. Toby mengatakan bahwa obatnya memiliki bentuk yang serupa dengan bangun ruang yang dibatasi pertidaksamaan : \\(\\frac{x^2}{28} + \\frac{y^2}{7} + \\frac{z^2}{5} \\le 1\\). Kemudian, Toby menyuruh Alleo untuk melakukan beberapa hal berikut sebelum dia akan memberikan obatnya pada Alleo :\n\nGambarkan bangun ruang yang dibatasi pertidaksamaan berikut (Gambar yang dihasilkan ada 2, 1 berupa gambar tulisan tangan di kertas, 1 lagi berupa hasil screenshot hasil output dari Wolfram Mathematica), sertakan pula 1 baris kode yang digunakan untuk mendapatkan output di Wolfram Mathematica (kode harus dapat berjalan saat di-”paste” di Wolfram Mathematica!\nHitung volume obat Alleo (Perhitungan yang dilampirkan ada 2, 1 perhitungan manual di kertas, dan 1 nya lagi hasil screenshot perhitungan dari Wolfram Mathematica), sertakan pula 1 baris kode yang digunakan untuk mendapatkan output di Wolfram Mathematica (kode harus dapat berjalan saat di-”paste” di Wolfram Mathematica!)\n\nBantulah Alleo agar bisa diberikan obat oleh kakaknya!\nDr. Vegapunk mendapatkan pesan dari Tuan Imu yang berisi 2 fungsi aneh. Fungsi aneh tersebut diberikan kepada Dr. Vegapunk untuk memecahkan pola-pola yang ada pada Poneglyph. Berikut adalah fungsi-fungsi tersebut.\n\n\\(r = \\left(10 \\cos \\left( n\\theta \\right) + 9 \\sin \\left( n \\frac{\\theta}{2} \\right) \\right)^n\\)\n\\(r = \\sin \\left( n\\theta \\right) \\frac{1}{\\theta}\\)\nUntuk \\(0.1 \\le \\theta \\le 2\\pi\\) dan untuk \\(n \\in N^+, \\hspace{0.2cm} n \\le 10\\)\n\nCari bentuk-bentuk fungsi pada poin a dan b untuk setiap n yang memenuhi! Carilah ekspansi untuk n = 7 dan n = 10 untuk bagian a!\n\nContoh lampiran screenshot Wolfram Mathematica (meliputi Input dan Outputnya) :"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul1.html#tambahan-mencari-nilai-di-array",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul1.html#tambahan-mencari-nilai-di-array",
    "title": "Modul 1 Persamaan Diferensial Numerik: Pengenalan GNU Octave",
    "section": "Tambahan: mencari nilai di array",
    "text": "Tambahan: mencari nilai di array\nMisalkan kita punya array\n\nx_arr = [9, 8, 7, 6]\n\nx_arr =\n\n   9   8   7   6\n\n\n\nApabila kita menerapkan kondisional tertentu pada array, kondisionalnya akan diterapkan per elemen. Misalnya, kita bisa memeriksa, elemen mana saja yang lebih besar dari 7.5\n\nx_arr &gt; 7.5\n\nans =\n\n  1  1  0  0\n\n\n\nNilai 9 dan 8 memenuhi, sehingga menjadi 1 (artinya true/benar). Sedangkan, nilai 7 dan 6 tidak memenuhi, sehingga menjadi 0 (artinya false/salah).\nAda fungsi find yang menerima suatu array/matriks dan memberikan output berupa indeks-indeks yang nilainya taknol.\n\nfind([1, 1, 0, 0])\n\nans =\n\n   1   2\n\n\n\nKalau digunakan seperti ini, mungkin kelihatannya agak aneh. Namun, kita bisa gabungkan dengan penggunaan kondisional…\n\nfind(x_arr &gt; 7.5)\n\nans =\n\n   1   2\n\n\n\nSehingga fungsi find seolah-olah mencari, indeks mana saja yang memenuhi kondisional.\nContoh lain, kondisional kesamaan:\n\nx_arr == 7\n\nans =\n\n  0  0  1  0\n\n\n\nHanya nilai 7 (yaitu di posisi ketiga) yang menjadi true, karena memang hanya itu yang sama dengan 7.\nApabila kita gunakan bersama fungsi find, maka sama saja seperti melakukan linear search\n\nfind(x_arr == 7)\n\nans = 3\n\n\nYaitu, nilai 7 di array berada pada indeks 3\n\nx_arr(3)\n\nans = 7\n\n\nApabila kita coba cari sesuatu yang tidak ada (misalnya nilai 5), hasilnya kosong:\n\nfind(x_arr == 5)\n\nans = [](1x0)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/tugas_alin1.html",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/tugas_alin1.html",
    "title": "Tugas Praktikum Aljabar Linier 1, 2024 Genap",
    "section": "",
    "text": "Dibuat oleh Tim Aslab Kalkulin 2024 Genap\nKembali ke Kalkulin\nPetunjuk ini disalin dari https://bit.ly/SoalTugasPraktikumAlin1"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/tugas_alin1.html#ketentuan-pengerjaan-tugas",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/tugas_alin1.html#ketentuan-pengerjaan-tugas",
    "title": "Tugas Praktikum Aljabar Linier 1, 2024 Genap",
    "section": "Ketentuan Pengerjaan Tugas",
    "text": "Ketentuan Pengerjaan Tugas\n\nTerdapat 3 soal yang perlu dikerjakan, perhatikan kalimat perintah dan kalimat pertanyaan pada setiap soal, dan perhatikan jawaban apa yang diminta setiap soal!\nTugas dikumpulkan paling lambat Minggu, 2 Juni 2023 Pukul 23.59 WIB. Keterlambatan menyebabkan nilai maksimal hanya 70 saja.\nKerjakan semua soal menggunakan Wolfram Mathematica, tools yang digunakan bebas, tidak terbatas pada yang sudah diajarkan oleh kami. Pada setiap soal, kalian akan menggunakan beberapa syntax, jelaskan secara singkat saja kegunaannya pada pengerjaan soal yang diberikan.\nKalian dipersilahkan untuk berdiskusi dengan teman kalian. Akan tetapi, kalian tidak diizinkan untuk mengumpulkan hasil yang sama persis dengan teman kalian. Kami sarankan jika kalian berdiskusi dengan teman kalian, setiap orang harus menulis syntax pada Wolfram Mathematica, jangan langsung copy paste syntaxnya. Pelanggaran terhadap peraturan akan menyebabkan nilai tugas menjadi 0.\nSemua file yang diperlukan (bagi Ms. Word, pdf, notebook Wolfram, dll) dikumpulkan dalam bentuk file .zip dengan ketentuan penamaan: NPM_Nama Lengkap_Tugas Praktikum Alin1.\nContoh: 2106706322_Peter Alexander_Tugas Praktikum Alin1.\nKumpulkan file .zip pada link berikut:\nhttps://bit.ly/PengumpulanTugasPraktikumAlin1\nhttps://bit.ly/PengumpulanTugasPraktikumAlin1\nhttps://bit.ly/PengumpulanTugasPraktikumAlin1\nJika ada yang ingin ditanyakan silahkan menghubungi:\nSoal 1: Peter Alexander (petlex/088289326995)\nSoal 2. Ahong / Citius Vienny (citiusaa2003/082184749305)\nSoal 3 : Samuel Christopher Khong (samuelck2004/089508814903)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/kalkulin/tugas_alin1.html#soal",
    "href": "semuahalaman/modulprak/2024/genap/kalkulin/tugas_alin1.html#soal",
    "title": "Tugas Praktikum Aljabar Linier 1, 2024 Genap",
    "section": "Soal",
    "text": "Soal\n\nSuatu hari, Aldrin dan Chrysalis sedang pergi makan berdua. Saat Chrysalis pergi ke toilet, Aldrin kepo untuk membuka HP milik Chrysalis. Namun, ternyata HP Chrysalis terdapat password yang unik. Passwordnya bukan berupa angka hasil, namun juga memerlukan proses pengerjaan agar HP tersebut terbuka. Berikut keterangan yang tertera pada HP Chrysalis :\n\nDiberikan matriks berikut, berikan argumen secara teori apakah matriks berikut dapat didiagonalisasi? Setelah itu, berikan dukungan berupa output Wolfram Mathematica yang membuktikan bahwa matriks tersebut dapat didiagonalisasi.\nLalu, lakukanlah proses diagonalisasi dengan metode yang diajarkan di kelas, lakukan juga di Wolfram Mathematica, lalu bandingkan hasilnya (lampirkan output Wolfram Mathematica dari setiap kode yang dipakai)\n\n\\[\\begin{pmatrix}\n     \\frac{77}{9} & \\frac{52}{9} & -\\frac{40}{9} \\\\\n     \\frac{52}{9} & \\frac{143}{9} & -\\frac{92}{9} \\\\\n     -\\frac{40}{9} & -\\frac{92}{9} & \\frac{149}{9}\n\\end{pmatrix}\\]\nPada akhirnya Aldrin pun berhasil membuka HP milik Chrysalis. Aldrin pun terkejut di dalam HP itu ternyata ada surat cinta untuk seseorang. Aldrin ingin membukanya tetapi ada 9 angka sebagai sandinya. Sandi untuk membuka suratnya adalah bilangan yang terurut dari terkecil ke terbesar dan angka yang ada pada sandi adalah angka yang ada pada solusi dari permasalahan berikut:\nMisalkan \\(T : R^3 \\rightarrow R^3\\) adalah sebuah transformasi linier dengan matrik standarnya diberikan oleh:\n\\[\\begin{pmatrix}\n     \\frac{77}{9} & \\frac{52}{9} & -\\frac{40}{9} \\\\\n     \\frac{52}{9} & \\frac{143}{9} & -\\frac{92}{9} \\\\\n     -\\frac{40}{9} & -\\frac{92}{9} & \\frac{149}{9}\n\\end{pmatrix}\\]\nTentukan suatu basis S di \\(R^3\\) sedemikian sehingga \\([T]_S\\) adalah diagonal.\nPetunjuk pengerjaan:\n\nPada soal no pertama, kalian telah mendiagonalisasi matrik tersebut (Matriksnya sama dengan no pertama). Pada tabel 1 subbab 8.5 buku Howard Anton, D (matriks diagonal hasil diagonalisasi) dan matriks di atas memiliki sifat yang sama. Dengan bantuan Wolfram Mathematica, buktikan seluruh sifat yang sama, kecuali sifat terakhir.\n\n\n\n\n\nTentukan basis S yang dicari tersebut.\nHint: perhatikan definisi dari \\([T]_S\\), eigenvector, eigenvalue, dan matriks diagonalisasinya.\nBuktikan bahwa \\([T]_S\\) adalah matriks diagonal secara manual pada selembar kertas, tuliskan langkah pembuktiannya saja, untuk perhitungan gunakan bantuan Wolfram Mathematica\n\nAda seseorang bernama Jono. Jono berencana untuk mengikuti Fun Run pada hari Minggu pagi, hari dimana dia tidak biasa bangun pagi. Maka dari itu, Jono memasang sebuah alarm di jam yang bernama Olam agar ia bisa bangun tepat waktu dan tidak telat mengikuti fun run. Keesokan harinya, ia dibangunkan pada jam empt pagi oleh Olam. Namun, Olam tidak berhenti berdering, dan jika ditinggal terus berdering akan membangunkan seisi rumah Jono. Maka dari itu, Jono perlu segera mematikan alarmnya. Namun, Jono perlu menyelesaikan beberapa pertanyaan untuk dapat mematikan Olam. Pertanyaannya adalah:\n\\[A = \\begin{pmatrix}\n     5 & 2 & 8 \\\\\n     3 & 9 & 4 \\\\\n     8 & 4 & 7\n\\end{pmatrix}\\]\n\nApakah matriks ini merupakan matriks hasil kali dalam? Verifikasi dengan menyamakan perhitungan manual dan Wolfram Mathematica!\n\nJika ya, pertanyaan selesai.\nJika tidak, jawab pertanyaan berikut, dan lanjut ke pertanyaan 2\n\nBerapa jumlah aksioma yang dilanggar?\nApa saja aksioma yang dilanggar?\n\n\nJika diberikan bahwa penyebab matriks ini bukan matriks hasil kali dalam adalah angka 2 pada baris 1, kolom 2, diantara angka-angka yang ada dalam jarum jam Olam, angka berapakah yang kamu pilih untuk menggantikan angka 2? Berikan verifikasinya dengan Wolfram Mathematica saja!\n\n\nContoh lampiran screenshot Wolfram Mathematica (meliputi Input dan Outputnya) :"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul5.html#contoh-lain-untuk-metode-taylor-orde-n",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul5.html#contoh-lain-untuk-metode-taylor-orde-n",
    "title": "Modul 5 Persamaan Diferensial Numerik: Sistem PDB orde 1 dan PDB orde tinggi",
    "section": "Contoh lain: untuk metode Taylor orde \\(n\\)",
    "text": "Contoh lain: untuk metode Taylor orde \\(n\\)\n\nFunction file taylor_sysm.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = taylor_sysm(cell_f, cell_fp, a, b, N, alphas)\n  m = length(cell_f);\n  \n  h = (b - a) / N;\n  n = length(cell_fp{1}) + 1;\n  t = zeros(N + 1, 1);\n  w = zeros(m, N + 1);\n  t(1) = a;\n  w(:, 1) = alphas;\n  for i = 1 : N\n    t(i + 1) = t(i) + h;\n    \n    for j = 1 : m\n      T = cell_f{j}(t(i), w(:, i));\n      for p = 2 : n\n        T += h^(p-1) * cell_fp{j}{p-1}(t(i), w(:, i)) / factorial(p);\n      endfor\n      w(j, i + 1) = w(j, i) + h * T;\n    endfor\n  endfor\nendfunction\n\n\n\n\nMencoba masalah yang sama,\n\\(u'_1 = -4u_1+3u_2+6, \\;u_1(0)=0\\)\n\\(u'_2 = -2.4u_1+1.6u_2+3.6, \\;u_2(0)=0\\)\nAkan diuji dengan \\(h=0.1\\) dan \\(0\\leq t \\leq 0.5\\)\nSolusi eksak:\n\\(u_1(t)=-3.375e^{-2t}+1.875e^{-0.4t}+1.5\\)\n\\(u_2(t) = -2.25e^{-2t}+2.25e^{-0.4t}\\)\nPerhatikan bahwa\n\\[u_1' = f_1(t, u_1, u_2) = -4u_1+3u_2+6\\]\n\\[u_2' = f_2(t, u_1, u_2) = -2.4u_1+1.6u_2+3.6\\]\n\nContoh \\(n=1\\) (metode Euler)\nApabila kita tidak menyediakan turunan (terhadap \\(t\\)) dari \\(f_1\\) maupun dari \\(f_2\\), maka \\(n=1\\), yaitu metode Taylor orde \\(n\\) menjadi metode Euler.\n\nScript file coba1_taylor_sysm.m - nama file bebas\n\n\n\nf1 = @(t, u) (-4*u(1) +3*u(2) + 6);\nturunan_f1 = {}; % tidak menyediakan turunan f1 terhadap t\n\nf2 = @(t, u) (-2.4*u(1) + 1.6*u(2) + 3.6);\nturunan_f2 = {}; % tidak menyediakan turunan f2 terhadap t\n\na = 0;\nb = 0.5;\nh = 0.1;\nN = (b - a) / h;\nalpha1 = 0;\nalpha2 = 0;\n\n[t, w] = taylor_sysm({f1, f2}, {turunan_f1, turunan_f2}, a, b, N, [alpha1, alpha2]);\n\nsln1 = @(t) (-3.375*exp(-2*t) + 1.875*exp(-0.4*t) + 1.5);\nsln2 = @(t) (-2.25*exp(-2*t) + 2.25*exp(-0.4*t));\n\nu1_eksak = sln1(t);\nu2_eksak = sln2(t);\n\n% menghitung error\nerr_w1 = abs(w(1, :)' - u1_eksak);\nerr_w2 = abs(w(2, :)' - u2_eksak);\nerr_w1_total = sum(err_w1); % norm L1 (taxicab/Manhattan)\nerr_w2_total = sum(err_w2); % norm L1 (taxicab/Manhattan)\n\n% menampilkan tabel, termasuk error\nformat long;\ndisp(\"Tabel aproksimasi w1,i, solusi eksak u1(t), dan error:\");\n[t, w(1, :)', u1_eksak, err_w1]\ndisp(\"Tabel aproksimasi w2,i, solusi eksak u2(t), dan error:\");\n[t, w(2, :)', u2_eksak, err_w2]\ndisp(\"Error total (norm L1) untuk w1,i:\");\ndisp(err_w1_total);\ndisp(\"Error total (norm L1) untuk w2,i:\");\ndisp(err_w2_total);\nformat;\n\nfigure;\nhold on;\nfplot(sln1, [a,b], 'r');\nscatter(t, w(1, :), 'r');\ntitle(\"u1\");\nlegend(\"u1 (eksak)\", \"w1,i (aproksimasi)\")\nlegend('location', 'northwest')\n\nfigure;\nhold on;\nfplot(sln2, [a,b], 'b');\nscatter(t, w(2, :), 'b');\ntitle(\"u2\");\nlegend(\"u2 (eksak)\", \"w2,i (aproksimasi)\")\nlegend('location', 'northwest')\n\nTabel aproksimasi w1,i, solusi eksak u1(t), dan error:\nans =\n\n                   0                   0                   0                   0\n   0.100000000000000   0.600000000000000   0.538263906772417   0.061736093227583\n   0.200000000000000   1.068000000000000   0.968512994104659   0.099487005895341\n   0.300000000000000   1.430880000000000   1.310736547027331   0.120143452972669\n   0.400000000000000   1.710124800000000   1.581284350416023   0.128840449583977\n   0.500000000000000   1.922903808000000   1.793527048067598   0.129376759932402\n\nTabel aproksimasi w2,i, solusi eksak u2(t), dan error:\nans =\n\n                   0                   0                   0                   0\n   0.100000000000000   0.360000000000000   0.319632043667268   0.040367956332732\n   0.200000000000000   0.633600000000000   0.568791675789742   0.064808324210258\n   0.300000000000000   0.838656000000000   0.760744801402045   0.077911198597955\n   0.400000000000000   0.989429760000000   0.906333355910227   0.083096404089773\n   0.500000000000000   1.097308569600000   1.014415451789714   0.082893117810286\n\nError total (norm L1) untuk w1,i:\n0.539583761611971\nError total (norm L1) untuk w2,i:\n0.349077001041004\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContoh \\(n=4\\) (metode Taylor orde 4)\nDengan contoh yang sama,\n\\[u_1' = f_1(t, u_1, u_2) = -4u_1+3u_2+6\\]\n\\[u_2' = f_2(t, u_1, u_2) = -2.4u_1+1.6u_2+3.6\\]\nApabila ingin menggunakan metode Taylor orde 4, kita perlu memiliki turunan (terhadap \\(t\\)) dari \\(f_1\\) maupun dari \\(f_2\\) hingga turunan ketiga (\\(n-1=4-1=3\\)).\nUntuk \\(f_1\\),\n$$\\[\\begin{align*}\n    f_1(t, u_1, u_2) &= -4u_1 + 3u_2 + 6 \\\\[1em]\n\n    f_1'(t, u_1, u_2) &= \\frac{d}{dt} f_1(t, u_1, u_2) \\\\\n    &= \\frac{d}{dt} \\left(-4u_1 + 3u_2 + 6\\right) \\\\\n    &= -4u'_1 + 3u'_2 \\\\\n    &= -4\\left(-4u_1 + 3u_2 + 6\\right)\n    + 3\\left(-2.4u_1 + 1.6u_2 + 3.6\\right) \\\\\n    &= 16u_1 - 12u_2 - 24 - 7.2u_1 + 4.8u_2 + 10.8 \\\\\n    &= 8.8u_1 - 7.2u_2 - 13.2 \\\\[1em]\n\n    f_1''(t, u_1, u_2) &= \\frac{d}{dt} f_1'(t, u_1, u_2) \\\\\n    &= \\frac{d}{dt} \\left(8.8u_1 - 7.2u_2 - 13.2\\right) \\\\\n    &= 8.8u_1' - 7.2u_2' \\\\\n    &= 8.8\\left(-4u_1 + 3u_2 + 6\\right)\n    - 7.2\\left(-2.4u_1 + 1.6u_2 + 3.6\\right) \\\\\n    &= -35.2u_1 + 26.4u_2 + 52.8 + 17.28u_1 - 11.52u_2 - 25.92 \\\\\n    &= -17.92u_1 + 14.88u_2 + 26.8 \\\\[1em]\n\n    f_1'''(t, u_1, u_2) &= \\frac{d}{dt} f_1''(t, u_1, u_2) \\\\\n    &= \\frac{d}{dt} \\left(-17.92u_1 + 14.88u_2 + 26.8\\right) \\\\\n    &= -17.92u_1' + 14.88u_2' \\\\\n    &= -17.92\\left(-4u_1 + 3u_2 + 6\\right)\n    + 14.88\\left(-2.4u_1 + 1.6u_2 + 3.6\\right) \\\\\n    &= 71.68u_1 - 53.76u_2 -107.52 - 35.712u_1 + 23.808u_2 + 53.568 \\\\\n    &= 35.968u_1 - 29.952u_2 - 53.952\n\\end{align*}\\]$$\nUntuk \\(f_2\\),\n$$\\[\\begin{align*}\n    f_2(t, u_1, u_2) &= -2.4u_1 + 1.6u_2 + 3.6 \\\\[1em]\n\n    f_2'(t, u_1, u_2) &= \\frac{d}{dt} f_2(t, u_1, u_2) \\\\\n    &= \\frac{d}{dt} \\left(-2.4u_1 + 1.6u_2 + 3.6\\right) \\\\\n    &= -2.4u_1' + 1.6u_2' \\\\\n    &= -2.4\\left(-4u_1 + 3u_2 + 6\\right)\n    + 1.6\\left(-2.4u_1 + 1.6u_2 + 3.6\\right) \\\\\n    &= 9.6u_1 - 7.2u_2 - 14.4 + -3.84u_1 + 2.56u_2 + 5.76 \\\\\n    &= 5.76u_1 - 4.64u_2 - 8.64 \\\\[1em]\n\n    f_2''(t, u_1, u_2) &= \\frac{d}{dt} f_2'(t, u_1, u_2) \\\\\n    &= \\frac{d}{dt} \\left(5.76u_1 - 4.64u_2 - 8.64\\right) \\\\\n    &= 5.76u_1' - 4.64u_2' \\\\\n    &= 5.76\\left(-4u_1 + 3u_2 + 6\\right)\n    -4.64\\left(-2.4u_1 + 1.6u_2 + 3.6\\right) \\\\\n    &= -23.04u_1 + 17.28u_2 + 34.56 + 11.136u_1 - 7.424u_2 - 16.704 \\\\\n    &= -11.904u_1 + 9.856u_2 + 17.856 \\\\[1em]\n\n    f_2'''(t, u_1, u_2) &= \\frac{d}{dt} f_2''(t, u_!, u_2) \\\\\n    &= \\frac{d}{dt} \\left(-11.904u_1 + 9.856u_2 + 17.856\\right) \\\\\n    &= -11.904u_1' + 9.856u_2' \\\\\n    &= -11.904\\left(-4u_1 + 3u_2 + 6\\right)\n    + 9.856\\left(-2.4u_1 + 1.6u_2 + 3.6\\right) \\\\\n    &= 47.616u_1 - 35.712u_2 - 71.424 - 23.6544u_1 + 15.7696u_2 + 35.4816 \\\\\n    &= 23.9616u_1 - 19.9424u_2 - 35.9424\n\\end{align*}\\]$$\nSehingga, untuk \\(f_1\\),\n$$\\[\\begin{align*}\n    f_1(t, u_1, u_2) &= -4u_1 + 3u_2 + 6 \\\\[1em]\n\n    f_1'(t, u_1, u_2) &= 8.8u_1 - 7.2u_2 - 13.2 \\\\[1em]\n\n    f_1''(t, u_1, u_2) &= -17.92u_1 + 14.88u_2 + 26.8 \\\\[1em]\n\n    f_1'''(t, u_1, u_2) &= 35.968u_1 - 29.952u_2 - 53.952\n\\end{align*}\\]$$\ndan untuk \\(f_2\\),\n$$\\[\\begin{align*}\n    f_2(t, u_1, u_2) &= -2.4u_1 + 1.6u_2 + 3.6 \\\\[1em]\n\n    f_2'(t, u_1, u_2) &= 5.76u_1 - 4.64u_2 - 8.64 \\\\[1em]\n\n    f_2''(t, u_1, u_2) &= -11.904u_1 + 9.856u_2 + 17.856 \\\\[1em]\n\n    f_2'''(t, u_1, u_2) &= 23.9616u_1 - 19.9424u_2 - 35.9424\n\\end{align*}\\]$$\nFungsi \\(f_1\\) dan \\(f_2\\) serta turunan-turunannya bisa kita gunakan sebagai berikut.\n\nScript file coba2_taylor_sysm.m - nama file bebas\n\n\n\nf1    = @(t, u) (-4*u(1) +3*u(2) + 6);\nf1p   = @(t, u) (8.8*u(1) - 7.2*u(2) - 13.2);\nf1pp  = @(t, u) (-17.92*u(1) + 14.88*u(2) + 26.8);\nf1ppp = @(t, u) (35.968*u(1) - 29.952*u(2) - 53.952);\nturunan_f1 = {f1p, f1pp, f1ppp};\n\nf2    = @(t, u) (-2.4*u(1) + 1.6*u(2) + 3.6);\nf2p   = @(t, u) (5.76*u(1) - 4.64*u(2) - 8.64);\nf2pp  = @(t, u) (-11.904*u(1) + 9.856*u(2) + 17.856);\nf2ppp = @(t, u) (23.9616*u(1) - 19.9424*u(2) - 35.9424);\nturunan_f2 = {f2p, f2pp, f2ppp};\n\na = 0;\nb = 0.5;\nh = 0.1;\nN = (b - a) / h;\nalpha1 = 0;\nalpha2 = 0;\n\n[t, w] = taylor_sysm({f1, f2}, {turunan_f1, turunan_f2}, a, b, N, [alpha1, alpha2]);\n\nsln1 = @(t) (-3.375*exp(-2*t) + 1.875*exp(-0.4*t) + 1.5);\nsln2 = @(t) (-2.25*exp(-2*t) + 2.25*exp(-0.4*t));\n\nu1_eksak = sln1(t);\nu2_eksak = sln2(t);\n\n% menghitung error\nerr_w1 = abs(w(1, :)' - u1_eksak);\nerr_w2 = abs(w(2, :)' - u2_eksak);\nerr_w1_total = sum(err_w1); % norm L1 (taxicab/Manhattan)\nerr_w2_total = sum(err_w2); % norm L1 (taxicab/Manhattan)\n\n% menampilkan tabel, termasuk error\nformat long;\ndisp(\"Tabel aproksimasi w1,i, solusi eksak u1(t), dan error:\");\n[t, w(1, :)', u1_eksak, err_w1]\ndisp(\"Tabel aproksimasi w2,i, solusi eksak u2(t), dan error:\");\n[t, w(2, :)', u2_eksak, err_w2]\ndisp(\"Error total (norm L1) untuk w1,i:\");\ndisp(err_w1_total);\ndisp(\"Error total (norm L1) untuk w2,i:\");\ndisp(err_w2_total);\nformat;\n\nfigure;\nhold on;\nfplot(sln1, [a,b], 'r');\nscatter(t, w(1, :), 'r');\ntitle(\"u1\");\nlegend(\"u1 (eksak)\", \"w1,i (aproksimasi)\")\nlegend('location', 'northwest')\n\nfigure;\nhold on;\nfplot(sln2, [a,b], 'b');\nscatter(t, w(2, :), 'b');\ntitle(\"u2\");\nlegend(\"u2 (eksak)\", \"w2,i (aproksimasi)\")\nlegend('location', 'northwest')\n\nTabel aproksimasi w1,i, solusi eksak u1(t), dan error:\nans =\n\n                   0                   0                   0                   0\n   0.100000000000000   0.538241866666667   0.538263906772417   0.000022040105751\n   0.200000000000000   0.968476855353088   0.968512994104659   0.000036138751571\n   0.300000000000000   1.310692432573591   1.310736547027331   0.000044114453740\n   0.400000000000000   1.581236949834047   1.581284350416023   0.000047400581977\n   0.500000000000000   1.793479923348867   1.793527048067598   0.000047124718731\n\nTabel aproksimasi w2,i, solusi eksak u2(t), dan error:\nans =\n\n                   0                   0                   0                   0\n   0.100000000000000   0.319626240000000   0.319632043667268   0.000005803667268\n   0.200000000000000   0.568785014157039   0.568791675789742   0.000006661632703\n   0.300000000000000   0.760741028831847   0.760744801402045   0.000003772570198\n   0.400000000000000   0.906335276984882   0.906333355910227   0.000001921074655\n   0.500000000000000   1.014425131989109   1.014415451789714   0.000009680199395\n\nError total (norm L1) untuk w1,i:\n1.968186117699000e-04\nError total (norm L1) untuk w2,i:\n2.783914421899958e-05"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul5.html#contoh-lain-untuk-metode-adams-predictor-corrector-orde-4",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul5.html#contoh-lain-untuk-metode-adams-predictor-corrector-orde-4",
    "title": "Modul 5 Persamaan Diferensial Numerik: Sistem PDB orde 1 dan PDB orde tinggi",
    "section": "Contoh lain: untuk metode Adams predictor-corrector orde 4",
    "text": "Contoh lain: untuk metode Adams predictor-corrector orde 4\n\nFunction file adams_pc_orde4_sysm.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [t, w] = adams_pc_orde4_sysm(cell_f, a, b, N, alphas)\n  m = length(cell_f);\n  \n  % Inisiasi variabel awal\n  h = (b - a) / N;\n  t = zeros(N + 1, 1);\n  w = zeros(m, N + 1);\n  t(1) = a;\n  w(:, 1) = alphas;\n  \n  % Hitung w(2), w(3), w(4) menggunakan metode Runge-Kutta orde 4\n  k1 = zeros(m, 1);\n  k2 = zeros(m, 1);\n  k3 = zeros(m, 1);\n  k4 = zeros(m, 1);\n  for i = 1 : 3\n      t(i + 1) = t(i) + h;\n      \n      for j = 1 : m\n        k1(j) = h * cell_f{j}(t(i), w(:,i));\n      endfor\n      \n      for j = 1 : m\n        k2(j) = h * cell_f{j}(t(i) + (h/2), w(:,i) + (k1/2));\n      endfor\n      \n      for j = 1 : m\n        k3(j) = h * cell_f{j}(t(i) + (h/2), w(:,i) + (k2/2));\n      endfor\n      \n      for j = 1 : m\n        k4(j) = h * cell_f{j}(t(i + 1), w(:,i) + k3);\n      endfor\n      \n      for j = 1 : m\n        w(j,i+1) = w(j,i) + (k1(j) + 2*k2(j) + 2*k3(j) + k4(j)) / 6;\n      endfor\n  endfor\n  \n  % Algoritma utama Adams Predictor-Corrector orde 4\n  m0 = zeros(m, 1);\n  m1 = zeros(m, 1);\n  m2 = zeros(m, 1);\n  m3 = zeros(m, 1);\n  m4 = zeros(m, 1);\n  for i = 4 : N\n    t(i + 1) = t(i) + h;\n    \n    for j = 1 : m\n      m1(j) = cell_f{j}(t(i), w(:,i));\n    endfor\n    \n    for j = 1 : m\n      m2(j) = cell_f{j}(t(i-1), w(:,i-1));\n    endfor \n    \n    for j = 1 : m\n      m3(j) = cell_f{j}(t(i-2), w(:,i-2));\n    endfor\n    \n    for j = 1 : m\n      m4(j) = cell_f{j}(t(i-3), w(:,i-3));\n    endfor\n    \n    % Adams-Bashforth orde 4 (four-step)\n    for j = 1 : m\n      w(j,i+1) = w(j,i) + (h/24) * (55*m1(j) - 59*m2(j) + 37*m3(j) - 9*m4(j));\n    endfor\n    % Adams-Moulton orde 4 (three-step)\n    for j = 1 : m\n      m0(j) = cell_f{j}(t(i+1), w(:,i+1));\n    endfor\n    for j = 1 : m\n      w(j,i+1) = w(j,i) + (h/24) * (9*m0(j) + 19*m1(j) - 5*m2(j) + m3(j));\n    endfor\n  endfor\nendfunction\n\n\n\n\nMencoba untuk masalah yang sama, yaitu\n\\(u'_1 = -4u_1+3u_2+6, \\;u_1(0)=0\\)\n\\(u'_2 = -2.4u_1+1.6u_2+3.6, \\;u_2(0)=0\\)\nAkan diuji dengan \\(h=0.1\\) dan \\(0\\leq t \\leq 0.5\\)\nSolusi eksak:\n\\(u_1(t)=-3.375e^{-2t}+1.875e^{-0.4t}+1.5\\)\n\\(u_2(t) = -2.25e^{-2t}+2.25e^{-0.4t}\\)\n\nScript file coba_adams_pc_orde4_sysm.m - nama file bebas\n\n\n\nf1 = @(t, u) (-4*u(1) +3*u(2) + 6);\nf2 = @(t, u) (-2.4*u(1) + 1.6*u(2) + 3.6);\n\na = 0;\nb = 0.5;\nh = 0.1;\nN = (b - a) / h;\nalpha1 = 0;\nalpha2 = 0;\n\n[t, w] = adams_pc_orde4_sysm({f1, f2}, a, b, N, [alpha1, alpha2]);\n\nsln1 = @(t) (-3.375*exp(-2*t) + 1.875*exp(-0.4*t) + 1.5);\nsln2 = @(t) (-2.25*exp(-2*t) + 2.25*exp(-0.4*t));\n\nu1_eksak = sln1(t);\nu2_eksak = sln2(t);\n\n% menghitung error\nerr_w1 = abs(w(1, :)' - u1_eksak);\nerr_w2 = abs(w(2, :)' - u2_eksak);\nerr_w1_total = sum(err_w1); % norm L1 (taxicab/Manhattan)\nerr_w2_total = sum(err_w2); % norm L1 (taxicab/Manhattan)\n\n% menampilkan tabel, termasuk error\nformat long;\ndisp(\"Tabel aproksimasi w1,i, solusi eksak u1(t), dan error:\");\n[t, w(1, :)', u1_eksak, err_w1]\ndisp(\"Tabel aproksimasi w2,i, solusi eksak u2(t), dan error:\");\n[t, w(2, :)', u2_eksak, err_w2]\ndisp(\"Error total (norm L1) untuk w1,i:\");\ndisp(err_w1_total);\ndisp(\"Error total (norm L1) untuk w2,i:\");\ndisp(err_w2_total);\nformat;\n\nfigure;\nhold on;\nfplot(sln1, [a,b], 'r');\nscatter(t, w(1, :), 'r');\ntitle(\"u1\");\nlegend(\"u1 (eksak)\", \"w1,i (aproksimasi)\")\nlegend('location', 'northwest')\n\nfigure;\nhold on;\nfplot(sln2, [a,b], 'b');\nscatter(t, w(2, :), 'b');\ntitle(\"u2\");\nlegend(\"u2 (eksak)\", \"w2,i (aproksimasi)\")\nlegend('location', 'northwest')\n\nTabel aproksimasi w1,i, solusi eksak u1(t), dan error:\nans =\n\n                   0                   0                   0                   0\n   0.100000000000000   0.538255200000000   0.538263906772417   0.000008706772417\n   0.200000000000000   0.968498737529088   0.968512994104659   0.000014256575571\n   0.300000000000000   1.310719039205257   1.310736547027331   0.000017507822074\n   0.400000000000000   1.581306013228106   1.581284350416023   0.000021662812083\n   0.500000000000000   1.793573533217050   1.793527048067598   0.000046485149452\n\nTabel aproksimasi w2,i, solusi eksak u2(t), dan error:\nans =\n\n                   0                   0                   0                   0\n   0.100000000000000   0.319626240000000   0.319632043667268   0.000005803667268\n   0.200000000000000   0.568782173034906   0.568791675789742   0.000009502754836\n   0.300000000000000   0.760733131868175   0.760744801402045   0.000011669533870\n   0.400000000000000   0.906347797116244   0.906333355910227   0.000014441206017\n   0.500000000000000   1.014446438459705   1.014415451789714   0.000030986669992\n\nError total (norm L1) untuk w1,i:\n1.086191315975427e-04\nError total (norm L1) untuk w2,i:\n7.240383198242606e-05"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul5.html#pdb-orde-tinggi",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul5.html#pdb-orde-tinggi",
    "title": "Modul 5 Persamaan Diferensial Numerik: Sistem PDB orde 1 dan PDB orde tinggi",
    "section": "PDB orde tinggi",
    "text": "PDB orde tinggi\n\n(penjelasan tanpa kode) Mengubah PDB orde tinggi menjadi sistem PDB orde 1\nMisalkan ada PDB orde \\(m\\) (tidak harus linier),\n\\[\\dots y^{\\left(m\\right)}\\left(t\\right) + \\dots y^{\\left(m-1\\right)}\\left(t\\right) + \\dots + \\dots y''\\left(t\\right) + \\dots y'\\left(t\\right) + \\dots y\\left(t\\right) + \\dots = 0\\]\nyang bisa dipindah ruas dsb, untuk memperoleh bentuk:\n\\[y^{\\left(m\\right)}\\left(t\\right) = \\left[\\text{sisanya}\\right]\\]\natau biasa ditulis\n\\[y^{\\left(m\\right)}\\left(t\\right) = f\\left(t, y, y', y'', \\dots, y^{\\left(m-1\\right)}\\right)\\]\nKita bisa mendefinisikan fungsi \\(u_1 \\left(t\\right), u_2 \\left(t\\right), \\dots, u_m \\left(t\\right)\\) sebagai berikut,\n\\[\\begin{align*}\n    u_1 \\left(t\\right) &= y\\left(t\\right) \\\\\n    u_2 \\left(t\\right) &= y'\\left(t\\right) \\\\\n    &\\vdots \\\\\n    u_j \\left(t\\right) &= y^{\\left(j-1\\right)}\\left(t\\right) \\\\\n    &\\vdots \\\\\n    u_{m-1} \\left(t\\right) &= y^{\\left(m-2\\right)}\\left(t\\right) \\\\\n    u_m \\left(t\\right) &= y^{\\left(m-1\\right)}\\left(t\\right)\n\\end{align*}\\]\nSehingga turunannya terhadap \\(t\\) adalah,\n\\[\\begin{align*}\n    \\frac{du_1}{dt} &= y'\\left(t\\right) \\\\\n    \\frac{du_2}{dt} &= y''\\left(t\\right) \\\\\n    &\\vdots \\\\\n    \\frac{du_j}{dt} &= y^{\\left(j\\right)}\\left(t\\right) \\\\\n    &\\vdots \\\\\n    \\frac{du_{m-1}}{dt} &= y^{\\left(m-1\\right)}\\left(t\\right) \\\\\n    \\frac{du_m}{dt} &= y^{\\left(m\\right)}\\left(t\\right)\n\\end{align*}\\]\nTernyata, \\(u_1'\\left(t\\right) = y'\\left(t\\right) = u_2\\left(t\\right)\\), lalu \\(u_2'\\left(t\\right) = y''\\left(t\\right) = u_3\\left(t\\right)\\), dan seterusnya. Untuk yang terakhir, sebelumnya kita sudah menuliskan\n\\[y^{\\left(m\\right)}\\left(t\\right) = f\\left(t, y, y', y'', \\dots, y^{\\left(m-1\\right)}\\right)\\]\nsedangkan \\(\\frac{du_m}{dt} = y^{\\left(m\\right)}\\left(t\\right)\\).\nSehingga, bisa ditulis:\n\\[\\begin{align*}\n    \\frac{du_1}{dt} &= u_2\\left(t\\right) \\\\\n    \\frac{du_2}{dt} &= u_3\\left(t\\right) \\\\\n    &\\vdots \\\\\n    \\frac{du_j}{dt} &= u_{j+1}\\left(t\\right) \\\\\n    &\\vdots \\\\\n    \\frac{du_{m-1}}{dt} &= u_m\\left(t\\right) \\\\\n    \\frac{du_m}{dt} &= f\\left(t, y, y', y'', \\dots, y^{\\left(m-1\\right)}\\right) \\\\\n\\end{align*}\\]\nyaitu sistem PDB orde 1 dalam \\(u_1 \\left(t\\right), u_2 \\left(t\\right), \\dots, u_m \\left(t\\right)\\).\nSolusi \\(y\\left(t\\right)\\) bisa diperoleh dari \\(u_1 \\left(t\\right)\\). Apabila ditanya \\(y'\\left(t\\right)\\), maka bisa diperoleh dari \\(u_2 \\left(t\\right)\\). Apabila ditanya \\(y''\\left(t\\right)\\), maka bisa diperoleh dari \\(u_3 \\left(t\\right)\\), dan seterusnya.\n\n\nContoh: mengubah PDB orde 3 menjadi sistem PDB\nMenggunakan soal Exercise Set 5.9 no. 3d dari buku,\n\\[t^3 y''' - t^2 y'' + 3ty' - 4y = 5t^3 \\ln{t} + 9t^3, \\quad 1 \\le t \\le 2\\]\n\\[y(1) = 0, \\quad y'(1) = 1, \\quad y''(1) = 3\\]\ndengan \\(h=0.1\\), dan diketahui solusi eksak\n\\[y(t) = -t^2 + t\\cos{\\left(\\ln{t}\\right)} + t\\sin{\\left(\\ln{t}\\right)} + t^3 \\ln{t}\\]\n\\[y'(t) = -2t + 2\\cos{\\left(\\ln{t}\\right)} + t^2 + 3t^2 \\ln{t}\\]\n\\[y''(t) = -2 - \\frac{2}{t}\\sin{\\left(\\ln{t}\\right)} + 5t + 6t \\ln{t}\\]\nPerhatikan bahwa turunan tertinggi adalah turunan ketiga, sehingga PDB yang diberikan adalah PDB orde 3, yaitu PDB orde \\(m\\) dengan \\(m=3\\).\nKita bisa melakukan pindah ruas agar memperoleh bentuk\n\\[y''' = \\left[\\text{sisanya}\\right]\\]\natau bisa ditulis\n\\[y''' = f\\left(t, y, y', y''\\right)\\]\nseperti berikut:\n\\[t^3 y''' - t^2 y'' + 3ty' - 4y = 5t^3 \\ln{t} + 9t^3\\]\n\\[t^3 y''' = t^2 y'' - 3ty' + 4y + 5t^3 \\ln{t} + 9t^3\\]\n\\[y''' = \\frac{1}{t^3}\\left(t^2 y'' - 3ty' + 4y + 5t^3 \\ln{t} + 9t^3\\right)\\]\n\\[y''' = \\frac{1}{t} y'' - \\frac{3}{t^2}y' + \\frac{4}{t^3}y + 5 \\ln{t} + 9\\]\nSehingga bisa ditulis\n\\[y''' = f\\left(t, y, y', y''\\right) = \\frac{1}{t} y'' - \\frac{3}{t^2}y' + \\frac{4}{t^3}y + 5 \\ln{t} + 9, \\quad 1 \\le t \\le 2\\]\n\\[y(1) = 0, \\quad y'(1) = 1, \\quad y''(1) = 3\\]\nPDB orde \\(m=3\\) bisa diubah menjadi sistem PDB orde 1 yang terdiri dari \\(m=3\\) persamaan, dengan permisalan\n\\[u_1(t) = y(t)\\]\n\\[u_2(t) = y'(t)\\]\n\\[u_3(t) = y''(t)\\]\nsehingga\n\\[\\begin{align*}\n    u_1'(t) &= y'(t) = u_2(t) \\\\\n    u_2'(t) &= y''(t) = u_3(t) \\\\\n    u_3'(t) &= y'''(t) = f\\left(t, y, y', y''\\right) = \\frac{1}{t} y'' - \\frac{3}{t^2}y' + \\frac{4}{t^3}y + 5 \\ln{t} + 9\n\\end{align*}\\]\natau bisa ditulis\n\\[\\begin{align*}\n    u_1'(t) &= u_2(t) \\\\\n    u_2'(t) &= u_3(t) \\\\\n    u_3'(t) &= f\\left(t, u_1, u_2, u_3\\right) = \\frac{1}{t} u_3(t) - \\frac{3}{t^2}u_2(t) + \\frac{4}{t^3}u_1(t) + 5 \\ln{t} + 9\n\\end{align*}\\]\nBerdasarkan permisalan, nilai-nilai awal\n\\[y(1) = 0, \\quad y'(1) = 1, \\quad y''(1) = 3\\]\nmenjadi\n\\[u_1(1) = 0, \\quad u_2(1) = 1, \\quad u_3(1) = 3\\]\nSehingga, diperoleh sistem PDB orde 3 sebagai berikut:\n\\[\\begin{align*}\n    u_1' &= u_2, \\quad u_1(1) = 0 \\\\\n    u_2' &= u_3, \\quad u_2(1) = 1 \\\\\n    u_3' &= \\frac{1}{t} u_3 - \\frac{3}{t^2}u_2 + \\frac{4}{t^3}u_1 + 5 \\ln{t} + 9,\n    \\quad u_3(1) = 3\n\\end{align*}\\]\nKita dapat memisalkan\n\\[\\begin{align*}\n    f_1\\left(t, u_1, u_2, u_3\\right) &= u_1' \\\\\n    f_2\\left(t, u_1, u_2, u_3\\right) &= u_2' \\\\\n    f_3\\left(t, u_1, u_2, u_3\\right) &= u_3'\n\\end{align*}\\]\nyaitu\n\\[\\begin{align*}\n    f_1\\left(t, u_1, u_2, u_3\\right) &= u_2 \\\\\n    f_2\\left(t, u_1, u_2, u_3\\right) &= u_3 \\\\\n    f_3\\left(t, u_1, u_2, u_3\\right) &= \\frac{1}{t} u_3 - \\frac{3}{t^2}u_2 + \\frac{4}{t^3}u_1 + 5 \\ln{t} + 9\n\\end{align*}\\]\nagar sistem PDB orde 3 di atas bisa ditulis dalam bentuk umum sistem PDB orde 1, yaitu\n\\[\\begin{align*}\n    u_1' &= f_1\\left(t, u_1, u_2, u_3\\right) \\\\\n    u_2' &= f_2\\left(t, u_1, u_2, u_3\\right) \\\\\n    u_3' &= f_3\\left(t, u_1, u_2, u_3\\right)\n\\end{align*}\\]\nmasih dengan nilai-nilai awal\n\\[u_1(1) = 0, \\quad u_2(1) = 1, \\quad u_3(1) = 3\\]\nSetelah bentuknya diubah menjadi sistem PDB orde 1, kita dapat menyelesaikannya menggunakan algoritma-algoritma sistem PDB orde 1 seperti biasa. Berdasarkan permisalan yang telah dilakukan,\n\nsolusi \\(u_1(t)\\) akan menjadi solusi \\(y(t)\\), biasanya ini yang diminta\nsolusi \\(u_2(t)\\) akan menjadi solusi \\(y'(t)\\)\nsolusi \\(u_3(t)\\) akan menjadi solusi \\(y''(t)\\)\n\nWalaupun mungkin kita hanya memerlukan solusi \\(y(t)\\), algoritma yang tersedia mengharuskan semua nilai dihitung di tiap iterasi. Tidak ada salahnya juga; siapa tahu, misalnya solusi \\(y'(t)\\) atau solusi \\(y''(t)\\) diperlukan nantinya.\n(Apabila diperlukan, nilai \\(y^{\\left(m\\right)}(t)\\), yaitu nilai \\(y'''(t)\\), bisa dihitung menggunakan \\(f\\left(t, y, y', y'', \\dots, y^{\\left(m-1\\right)}\\right)\\), yaitu menggunakan \\(f\\left(t, y, y', y''\\right) = \\frac{1}{t} y'' - \\frac{3}{t^2}y' + \\frac{4}{t^3}y + 5 \\ln{t} + 9\\).)\n\n\nContoh metode Runge-Kutta orde 4\nSistem kita adalah\n\\[\\begin{align*}\n    u_1' &= f_1\\left(t, u_1, u_2, u_3\\right) = u_2 \\\\\n    u_2' &= f_2\\left(t, u_1, u_2, u_3\\right) = u_3 \\\\\n    u_3' &= f_3\\left(t, u_1, u_2, u_3\\right) = \\frac{1}{t} u_3 - \\frac{3}{t^2}u_2 + \\frac{4}{t^3}u_1 + 5 \\ln{t} + 9\n\\end{align*}\\]\n\\[1 \\le t \\le 2\\]\n\\[u_1(1) = 0, \\quad u_2(1) = 1, \\quad u_3(1) = 3\\]\ndengan \\(h=0.1\\), dan diketahui solusi eksak\n\\[y(t) = -t^2 + t\\cos{\\left(\\ln{t}\\right)} + t\\sin{\\left(\\ln{t}\\right)} + t^3 \\ln{t}\\]\n\\[y'(t) = -2t + 2\\cos{\\left(\\ln{t}\\right)} + t^2 + 3t^2 \\ln{t}\\]\n\\[y''(t) = -2 - \\frac{2}{t}\\sin{\\left(\\ln{t}\\right)} + 5t + 6t \\ln{t}\\]\n(yang bisa dianggap solusi eksak untuk \\(u_1\\), \\(u_2\\), dan \\(u_3\\), sesuai permisalan)\nKita bisa menggunakan metode Runge-Kutta orde 4 untuk sistem, seperti berikut.\n\nScript file pdb3_coba_rko4_sysm.m - nama file bebas\n\n\n\nf1 = @(t, u) u(2);\nf2 = @(t, u) u(3);\nf3 = @(t, u) (1/t .* u(3) - 3/(t.^2) .* u(2) + 4/(t.^3) .* u(1) + 5*log(t) + 9);\n\na = 1;\nb = 2;\nh = 0.1;\nN = (b - a) / h;\nalpha1 = 0;\nalpha2 = 1;\nalpha3 = 3;\n\n[t, w] = rko4_sysm({f1, f2, f3}, a, b, N, [alpha1, alpha2, alpha3]);\n\n% solusi eksak\nsln1 = @(t) (-t.^2 + t .* cos(log(t)) + t .* sin(log(t)) + t.^3 .* log(t));\nsln2 = @(t) (-2*t + 2 * cos(log(t)) + t.^2 + 3 * t.^2 .* log(t));\nsln3 = @(t) (-2 - 2./t .* sin(log(t)) + 5*t + 6 * t .* log(t));\n\nu1_eksak = sln1(t);\nu2_eksak = sln2(t);\nu3_eksak = sln3(t);\n\n[t, w', u1_eksak, u2_eksak, u3_eksak]\n\nfigure;\nhold on;\nfplot(sln1, [a, b], 'r');\nscatter(t, w(1, :), 'r'); % ambil baris pertama yaitu solusi u1\ntitle(\"Solusi u1(t) atau y(t)\");\nlegend(\"Solusi eksak\", \"w1,i (aproksimasi)\");\nlegend('location', 'northwest');\n\nfigure;\nhold on;\nfplot(sln2, [a, b], 'g');\nscatter(t, w(2, :), 'g'); % ambil baris kedua yaitu solusi u2\ntitle(\"Solusi u2(t) atau y'(t)\");\nlegend(\"Solusi eksak\", \"w2,i (aproksimasi)\");\nlegend('location', 'northwest');\n\nfigure;\nhold on;\nfplot(sln3, [a, b], 'b');\nscatter(t, w(3, :), 'b'); % ambil baris ketiga yaitu solusi u3\ntitle(\"Solusi u3(t) atau y''(t)\");\nlegend(\"Solusi eksak\", \"w3,i (aproksimasi)\");\nlegend('location', 'northwest');\n\nans =\n\n    1.0000         0    1.0000    3.0000         0    1.0000    3.0000\n    1.1000    0.1165    1.3469    3.9560    0.1165    1.3469    3.9560\n    1.2000    0.2727    1.7945    5.0105    0.2727    1.7945    5.0105\n    1.3000    0.4791    2.3517    6.1474    0.4791    2.3517    6.1474\n    1.4000    0.7470    3.0263    7.3547    0.7470    3.0263    7.3547\n    1.5000    1.0885    3.8247    8.6232    1.0885    3.8247    8.6233\n    1.6000    1.5163    4.7527    9.9459    1.5163    4.7528    9.9459\n    1.7000    2.0435    5.8155   11.3170    2.0435    5.8155   11.3170\n    1.8000    2.6840    7.0176   12.7319    2.6840    7.0176   12.7320\n    1.9000    3.4518    8.3632   14.1869    3.4518    8.3633   14.1869\n    2.0000    4.3616    9.8562   15.6788    4.3616    9.8562   15.6788\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApabila perlu dihitung errornya, kodenya bisa menjadi seperti berikut:\n\nScript file pdb3_coba2_rko4_sysm.m - nama file bebas\n\n\n\nf1 = @(t, u) u(2);\nf2 = @(t, u) u(3);\nf3 = @(t, u) (1/t .* u(3) - 3/(t.^2) .* u(2) + 4/(t.^3) .* u(1) + 5*log(t) + 9);\n\na = 1;\nb = 2;\nh = 0.1;\nN = (b - a) / h;\nalpha1 = 0;\nalpha2 = 1;\nalpha3 = 3;\n\n[t, w] = rko4_sysm({f1, f2, f3}, a, b, N, [alpha1, alpha2, alpha3]);\n\n% solusi eksak\nsln1 = @(t) (-t.^2 + t .* cos(log(t)) + t .* sin(log(t)) + t.^3 .* log(t));\nsln2 = @(t) (-2*t + 2 * cos(log(t)) + t.^2 + 3 * t.^2 .* log(t));\nsln3 = @(t) (-2 - 2./t .* sin(log(t)) + 5*t + 6 * t .* log(t));\n\nu1_eksak = sln1(t);\nu2_eksak = sln2(t);\nu3_eksak = sln3(t);\n\n% menghitung error\nerr_w1 = abs(w(1, :)' - u1_eksak);\nerr_w2 = abs(w(2, :)' - u2_eksak);\nerr_w3 = abs(w(3, :)' - u3_eksak);\nerr_w1_total = sum(err_w1); % norm L1 (taxicab/Manhattan)\nerr_w2_total = sum(err_w2); % norm L1 (taxicab/Manhattan)\nerr_w3_total = sum(err_w3); % norm L1 (taxicab/Manhattan)\n\n% menampilkan tabel, termasuk error\nformat long;\ndisp(\"Tabel aproksimasi w1,i, solusi eksak u1(t), dan error:\");\n[t, w(1, :)', u1_eksak, err_w1]\ndisp(\"Tabel aproksimasi w2,i, solusi eksak u2(t), dan error:\");\n[t, w(2, :)', u2_eksak, err_w2]\ndisp(\"Tabel aproksimasi w3,i, solusi eksak u3(t), dan error:\");\n[t, w(3, :)', u3_eksak, err_w3]\ndisp(\"Error total (norm L1) untuk w1,i:\");\ndisp(err_w1_total);\ndisp(\"Error total (norm L1) untuk w2,i:\");\ndisp(err_w2_total);\ndisp(\"Error total (norm L1) untuk w3,i:\");\ndisp(err_w3_total);\nformat;\n\nfigure;\nhold on;\nfplot(sln1, [a, b], 'r');\nscatter(t, w(1, :), 'r'); % ambil baris pertama yaitu solusi u1\ntitle(\"Solusi u1(t) atau y(t)\");\nlegend(\"Solusi eksak\", \"w1,i (aproksimasi)\");\nlegend('location', 'northwest');\n\nfigure;\nhold on;\nfplot(sln2, [a, b], 'g');\nscatter(t, w(2, :), 'g'); % ambil baris kedua yaitu solusi u2\ntitle(\"Solusi u2(t) atau y'(t)\");\nlegend(\"Solusi eksak\", \"w2,i (aproksimasi)\");\nlegend('location', 'northwest');\n\nfigure;\nhold on;\nfplot(sln3, [a, b], 'b');\nscatter(t, w(3, :), 'b'); % ambil baris ketiga yaitu solusi u3\ntitle(\"Solusi u3(t) atau y''(t)\");\nlegend(\"Solusi eksak\", \"w3,i (aproksimasi)\");\nlegend('location', 'northwest');\n\nTabel aproksimasi w1,i, solusi eksak u1(t), dan error:\nans =\n\n   1.000000000000000                   0                   0                   0\n   1.100000000000000   0.116547765077132   0.116547953377741   0.000000188300609\n   1.200000000000000   0.272737593417178   0.272737913137213   0.000000319720036\n   1.300000000000000   0.479101055922200   0.479101624357037   0.000000568434836\n   1.400000000000000   0.746997034090164   0.746998073629463   0.000001039539299\n   1.500000000000000   1.088490794798314   1.088492594095847   0.000001799297533\n   1.600000000000001   1.516261839314915   1.516264730431065   0.000002891116151\n   1.700000000000001   2.043532071845456   2.043536416215900   0.000004344370444\n   1.800000000000001   2.684008671952472   2.684014851438298   0.000006179485825\n   1.900000000000001   3.451837841224076   3.451846252199066   0.000008410974990\n   2.000000000000001   4.361566750517713   4.361577799834785   0.000011049317072\n\nTabel aproksimasi w2,i, solusi eksak u2(t), dan error:\nans =\n\n   1.000000000000000   1.000000000000000   1.000000000000000                   0\n   1.100000000000000   1.346897244698541   1.346898796867440   0.000001552168898\n   1.200000000000000   1.794476400848503   1.794479954480695   0.000003553632192\n   1.300000000000000   2.351739790653634   2.351745763551004   0.000005972897370\n   1.400000000000000   3.026298521404629   3.026307271933378   0.000008750528749\n   1.500000000000000   3.824715727217527   3.824727552609112   0.000011825391586\n   1.600000000000001   4.752746018651163   4.752761161714929   0.000015143063766\n   1.700000000000001   5.815506875823461   5.815525533513762   0.000018657690301\n   1.800000000000001   7.017604163612482   7.017626495142349   0.000022331529867\n   1.900000000000001   8.363225949009005   8.363252082824820   0.000026133815815\n   2.000000000000001   9.856213929909213   9.856243969447302   0.000030039538089\n\nTabel aproksimasi w3,i, solusi eksak u3(t), dan error:\nans =\n\n Columns 1 through 3:\n\n   1.000000000000000e+00   3.000000000000000e+00   3.000000000000000e+00\n   1.100000000000000e+00   3.956010469157951e+00   3.956018195368995e+00\n   1.200000000000000e+00   5.010512494112985e+00   5.010526645695958e+00\n   1.300000000000000e+00   6.147399365577646e+00   6.147418750933507e+00\n   1.400000000000000e+00   7.354687155068509e+00   7.354710775454516e+00\n   1.500000000000000e+00   8.623230661511867e+00   8.623257706687671e+00\n   1.600000000000001e+00   9.945893119295571e+00   9.945922939388453e+00\n   1.700000000000001e+00   1.131699337911594e+01   1.131702545393904e+01\n   1.800000000000001e+00   1.273192816711290e+01   1.273196207929798e+01\n   1.900000000000001e+00   1.418690793287085e+01   1.418694334605300e+01\n   2.000000000000001e+00   1.567876824876296e+01   1.567880489040572e+01\n\n Column 4:\n\n                       0\n   7.726211044278841e-06\n   1.415158297302099e-05\n   1.938535586099022e-05\n   2.362038600622896e-05\n   2.704517580376375e-05\n   2.982009288210463e-05\n   3.207482310685350e-05\n   3.391218507609040e-05\n   3.541318215205536e-05\n   3.664164275640758e-05\n\nError total (norm L1) untuk w1,i:\n3.679055679502163e-05\nError total (norm L1) untuk w2,i:\n1.439602566337683e-04\nError total (norm L1) untuk w3,i:\n2.597906376617942e-04\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContoh metode Adams Predictor-Corrector orde 4\nKita bisa menggunakan kode di atas, tinggal menukar fungsi rko4_sysm dengan adams_pc_orde4_sysm\n\nScript file pdb3_coba_adams_pc_orde4_sysm.m - nama file bebas\n\n\n\nf1 = @(t, u) u(2);\nf2 = @(t, u) u(3);\nf3 = @(t, u) (1/t .* u(3) - 3/(t.^2) .* u(2) + 4/(t.^3) .* u(1) + 5*log(t) + 9);\n\na = 1;\nb = 2;\nh = 0.1;\nN = (b - a) / h;\nalpha1 = 0;\nalpha2 = 1;\nalpha3 = 3;\n\n[t, w] = adams_pc_orde4_sysm({f1, f2, f3}, a, b, N, [alpha1, alpha2, alpha3]);\n\n% solusi eksak\nsln1 = @(t) (-t.^2 + t .* cos(log(t)) + t .* sin(log(t)) + t.^3 .* log(t));\nsln2 = @(t) (-2*t + 2 * cos(log(t)) + t.^2 + 3 * t.^2 .* log(t));\nsln3 = @(t) (-2 - 2./t .* sin(log(t)) + 5*t + 6 * t .* log(t));\n\nu1_eksak = sln1(t);\nu2_eksak = sln2(t);\nu3_eksak = sln3(t);\n\n[t, w', u1_eksak, u2_eksak, u3_eksak]\n\nfigure;\nhold on;\nfplot(sln1, [a, b], 'r');\nscatter(t, w(1, :), 'r'); % ambil baris pertama yaitu solusi u1\ntitle(\"Solusi u1(t) atau y(t)\");\nlegend(\"Solusi eksak\", \"w1,i (aproksimasi)\");\nlegend('location', 'northwest');\n\nfigure;\nhold on;\nfplot(sln2, [a, b], 'g');\nscatter(t, w(2, :), 'g'); % ambil baris kedua yaitu solusi u2\ntitle(\"Solusi u2(t) atau y'(t)\");\nlegend(\"Solusi eksak\", \"w2,i (aproksimasi)\");\nlegend('location', 'northwest');\n\nfigure;\nhold on;\nfplot(sln3, [a, b], 'b');\nscatter(t, w(3, :), 'b'); % ambil baris ketiga yaitu solusi u3\ntitle(\"Solusi u3(t) atau y''(t)\");\nlegend(\"Solusi eksak\", \"w3,i (aproksimasi)\");\nlegend('location', 'northwest');\n\nans =\n\n    1.0000         0    1.0000    3.0000         0    1.0000    3.0000\n    1.1000    0.1165    1.3469    3.9560    0.1165    1.3469    3.9560\n    1.2000    0.2727    1.7945    5.0105    0.2727    1.7945    5.0105\n    1.3000    0.4791    2.3517    6.1474    0.4791    2.3517    6.1474\n    1.4000    0.7470    3.0263    7.3547    0.7470    3.0263    7.3547\n    1.5000    1.0885    3.8248    8.6232    1.0885    3.8247    8.6233\n    1.6000    1.5163    4.7528    9.9459    1.5163    4.7528    9.9459\n    1.7000    2.0435    5.8156   11.3170    2.0435    5.8155   11.3170\n    1.8000    2.6840    7.0177   12.7319    2.6840    7.0176   12.7320\n    1.9000    3.4518    8.3633   14.1869    3.4518    8.3633   14.1869\n    2.0000    4.3616    9.8563   15.6787    4.3616    9.8562   15.6788\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApabila perlu dihitung errornya:\n\nScript file pdb3_coba2_adams_pc_orde4_sysm.m - nama file bebas\n\n\n\nf1 = @(t, u) u(2);\nf2 = @(t, u) u(3);\nf3 = @(t, u) (1/t .* u(3) - 3/(t.^2) .* u(2) + 4/(t.^3) .* u(1) + 5*log(t) + 9);\n\na = 1;\nb = 2;\nh = 0.1;\nN = (b - a) / h;\nalpha1 = 0;\nalpha2 = 1;\nalpha3 = 3;\n\n[t, w] = adams_pc_orde4_sysm({f1, f2, f3}, a, b, N, [alpha1, alpha2, alpha3]);\n\n% solusi eksak\nsln1 = @(t) (-t.^2 + t .* cos(log(t)) + t .* sin(log(t)) + t.^3 .* log(t));\nsln2 = @(t) (-2*t + 2 * cos(log(t)) + t.^2 + 3 * t.^2 .* log(t));\nsln3 = @(t) (-2 - 2./t .* sin(log(t)) + 5*t + 6 * t .* log(t));\n\nu1_eksak = sln1(t);\nu2_eksak = sln2(t);\nu3_eksak = sln3(t);\n\n% menghitung error\nerr_w1 = abs(w(1, :)' - u1_eksak);\nerr_w2 = abs(w(2, :)' - u2_eksak);\nerr_w3 = abs(w(3, :)' - u3_eksak);\nerr_w1_total = sum(err_w1); % norm L1 (taxicab/Manhattan)\nerr_w2_total = sum(err_w2); % norm L1 (taxicab/Manhattan)\nerr_w3_total = sum(err_w3); % norm L1 (taxicab/Manhattan)\n\n% menampilkan tabel, termasuk error\nformat long;\ndisp(\"Tabel aproksimasi w1,i, solusi eksak u1(t), dan error:\");\n[t, w(1, :)', u1_eksak, err_w1]\ndisp(\"Tabel aproksimasi w2,i, solusi eksak u2(t), dan error:\");\n[t, w(2, :)', u2_eksak, err_w2]\ndisp(\"Tabel aproksimasi w3,i, solusi eksak u3(t), dan error:\");\n[t, w(3, :)', u3_eksak, err_w3]\ndisp(\"Error total (norm L1) untuk w1,i:\");\ndisp(err_w1_total);\ndisp(\"Error total (norm L1) untuk w2,i:\");\ndisp(err_w2_total);\ndisp(\"Error total (norm L1) untuk w3,i:\");\ndisp(err_w3_total);\nformat;\n\nfigure;\nhold on;\nfplot(sln1, [a, b], 'r');\nscatter(t, w(1, :), 'r'); % ambil baris pertama yaitu solusi u1\ntitle(\"Solusi u1(t) atau y(t)\");\nlegend(\"Solusi eksak\", \"w1,i (aproksimasi)\");\nlegend('location', 'northwest');\n\nfigure;\nhold on;\nfplot(sln2, [a, b], 'g');\nscatter(t, w(2, :), 'g'); % ambil baris kedua yaitu solusi u2\ntitle(\"Solusi u2(t) atau y'(t)\");\nlegend(\"Solusi eksak\", \"w2,i (aproksimasi)\");\nlegend('location', 'northwest');\n\nfigure;\nhold on;\nfplot(sln3, [a, b], 'b');\nscatter(t, w(3, :), 'b'); % ambil baris ketiga yaitu solusi u3\ntitle(\"Solusi u3(t) atau y''(t)\");\nlegend(\"Solusi eksak\", \"w3,i (aproksimasi)\");\nlegend('location', 'northwest');\n\nTabel aproksimasi w1,i, solusi eksak u1(t), dan error:\nans =\n\n   1.000000000000000                   0                   0                   0\n   1.100000000000000   0.116547765077132   0.116547953377741   0.000000188300609\n   1.200000000000000   0.272737593417178   0.272737913137213   0.000000319720036\n   1.300000000000000   0.479101055922200   0.479101624357037   0.000000568434836\n   1.400000000000000   0.746988331768006   0.746998073629463   0.000009741861457\n   1.500000000000000   1.088479331032411   1.088492594095847   0.000013263063436\n   1.600000000000001   1.516250804091531   1.516264730431065   0.000013926339534\n   1.700000000000001   2.043523756922286   2.043536416215900   0.000012659293614\n   1.800000000000001   2.684004508018369   2.684014851438298   0.000010343419929\n   1.900000000000001   3.451838703918476   3.451846252199066   0.000007548280589\n   2.000000000000001   4.361573101909957   4.361577799834785   0.000004697924828\n\nTabel aproksimasi w2,i, solusi eksak u2(t), dan error:\nans =\n\n   1.000000000000000   1.000000000000000   1.000000000000000                   0\n   1.100000000000000   1.346897244698541   1.346898796867440   0.000001552168898\n   1.200000000000000   1.794476400848503   1.794479954480695   0.000003553632192\n   1.300000000000000   2.351739790653634   2.351745763551004   0.000005972897370\n   1.400000000000000   3.026328879302920   3.026307271933378   0.000021607369542\n   1.500000000000000   3.824765611199535   3.824727552609112   0.000038058590423\n   1.600000000000001   4.752808495899515   4.752761161714929   0.000047334184586\n   1.700000000000001   5.815576770936465   5.815525533513762   0.000051237422703\n   1.800000000000001   7.017677812981450   7.017626495142349   0.000051317839101\n   1.900000000000001   8.363300595016490   8.363252082824820   0.000048512191670\n   2.000000000000001   9.856287435428921   9.856243969447302   0.000043465981619\n\nTabel aproksimasi w3,i, solusi eksak u3(t), dan error:\nans =\n\n Columns 1 through 3:\n\n   1.000000000000000e+00   3.000000000000000e+00   3.000000000000000e+00\n   1.100000000000000e+00   3.956010469157951e+00   3.956018195368995e+00\n   1.200000000000000e+00   5.010512494112985e+00   5.010526645695958e+00\n   1.300000000000000e+00   6.147399365577646e+00   6.147418750933507e+00\n   1.400000000000000e+00   7.354687175512593e+00   7.354710775454516e+00\n   1.500000000000000e+00   8.623223151179934e+00   8.623257706687671e+00\n   1.600000000000001e+00   9.945876374658745e+00   9.945922939388453e+00\n   1.700000000000001e+00   1.131696670232371e+01   1.131702545393904e+01\n   1.800000000000001e+00   1.273189177401384e+01   1.273196207929798e+01\n   1.900000000000001e+00   1.418686238954817e+01   1.418694334605300e+01\n   2.000000000000001e+00   1.567871426475001e+01   1.567880489040572e+01\n\n Column 4:\n\n                       0\n   7.726211044278841e-06\n   1.415158297302099e-05\n   1.938535586099022e-05\n   2.359994192246972e-05\n   3.455550773701077e-05\n   4.656472970765435e-05\n   5.875161532742368e-05\n   7.030528413842774e-05\n   8.095650483497252e-05\n   9.062565571049674e-05\n\nError total (norm L1) untuk w1,i:\n7.325663886766087e-05\nError total (norm L1) untuk w2,i:\n3.126122781038632e-04\nError total (norm L1) untuk w3,i:\n4.466223892567456e-04"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul7.html#plot-tiga-dimensi-dan-grid",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul7.html#plot-tiga-dimensi-dan-grid",
    "title": "Modul 7 Persamaan Diferensial Numerik: Nonlinear Finite Difference, PDP Eliptik & Hiperbolik",
    "section": "Plot tiga dimensi dan grid",
    "text": "Plot tiga dimensi dan grid\nMisalnya kita ingin membuat plot fungsi \\(u(x,y) = 4x + y\\), setidaknya di titik-titik \\(x = 0,1,2,3\\) dan \\(y = 0, 1, 2\\). (Materi ini bisa dianggap perumuman dari materi plotting dua dimensi di Modul 2; kalau lupa, mungkin bisa baca itu dulu.)\nPertama-tama, kita bisa membuat array untuk nilai-nilai \\(x\\) dan untuk nilai-nilai \\(y\\) yang kita ingin gunakan untuk plotting\n\nx_arr = [0, 1, 2, 3]\ny_arr = [0, 1, 2]\n\nx_arr =\n\n   0   1   2   3\n\ny_arr =\n\n   0   1   2\n\n\n\nApabila fungsi \\(u(x,y) = 4x + y\\) dihitung di semua titik tersebut, bentuknya akan berupa grid, agar semua kemungkinan nilai \\(x\\) dicoba dengan semua kemungkinan nilai \\(y\\).\nCaranya, kita susun terlebih dahulu dua grid, yaitu satu grid untuk nilai \\(x\\) yang berisi nilai \\(x\\) di posisi yang sesuai, dan satu grid untuk nilai \\(y\\) yang berisi nilai \\(y\\) di posisi yang sesuai. Ada fungsi Octave untuk melakukan ini, yaitu meshgrid yang bisa digunakan sebagai berikut.\n\n[x_grid, y_grid] = meshgrid(x_arr, y_arr)\n\nx_grid =\n\n   0   1   2   3\n   0   1   2   3\n   0   1   2   3\n\ny_grid =\n\n   0   0   0   0\n   1   1   1   1\n   2   2   2   2\n\n\n\nPerhatikan,\n\nuntuk posisi pertama \\(x\\), yaitu dengan \\(x=0\\), satu kolom itu semuanya diisi \\(x=0\\). Untuk posisi kedua, satu kolom itu semuanya diisi \\(x=1\\). Begitu juga untuk \\(x=2\\) dan \\(x=3\\). Arahnya dari kiri ke kanan.\nuntuk grid \\(y\\), mirip dengan grid \\(x\\), tetapi arahnya dari atas ke bawah (bukan bawah ke atas).\n\nSetelah itu, barulah kita buat grid untuk hasilnya yaitu grid untuk \\(u\\), dengan menerapkan fungsi \\(u\\) menggunakan grid \\(x\\) dan grid \\(y\\) tersebut.\n\n% contoh fungsi yang ingin kita coba\nu = @(x, y) (4 * x + y);\n\n\n% menggunakan fungsinya untuk memperoleh grid u dari grid x dan grid y\nu_grid = u(x_grid, y_grid)\n\nu_grid =\n\n    0    4    8   12\n    1    5    9   13\n    2    6   10   14\n\n\n\nTerakhir, kita tinggal menggambarnya menggunakan fungsi mesh seperti berikut:\n\nmesh(x_arr, y_arr, u_grid);\ntitle(\"Plot u(x,y)=4x+y\");\nxlabel(\"x\");\nylabel(\"y\");\nzlabel(\"u\");\n\n\n\n\n\n\n\n\nPerhatikan,\n\nwalaupun tadi arah di grid \\(y\\) adalah dari atas ke bawah, gambarnya masih dari bawah ke atas seperti biasanya (perhatikan sumbunya).\nwalaupun tadi kita libatkan x_grid dan y_grid dalam perhitungan untuk memperoleh u_grid, pada akhirnya, yang digunakan untuk plot adalah x_arr dan y_arr\n\nKetika nilai-nilai u_grid ditampilkan, ia ditampilkan sebagai matriks (nilai \\(y\\) dari atas ke bawah), sehingga mungkin arahnya kurang sesuai dengan gambar (nilai \\(y\\) dari bawah ke atas), seperti terbalik.\nAda fungsi Octave untuk mem-flip atau membalik arah atas-bawah ini, yaitu flipud (flip up-down)\n\nflipud(u_grid)\n\nans =\n\n    2    6   10   14\n    1    5    9   13\n    0    4    8   12\n\n\n\nKetika ditampilkan seperti ini, nilai-nilai u_grid terlihat cocok dengan gambar.\nNamun, misalkan kita memerlukan nilai \\(u(2, 1)\\). Bagaimana cara membacanya dari grid?\n\\(x=2\\) ada di indeks 3 di x_arr\n\nfind(x_arr == 2)\n\nans = 3\n\n\n\\(y = 1\\) ada di indeks 2 di y_arr\n\nfind(y_arr == 1)\n\nans = 2\n\n\nSehingga nilai \\(u(2,1)\\) seharusnya ada di indeks (3,2) dari u_grid…\n\nu_grid(3, 2)\n\nans = 6\n\n\nHmm, kok aneh? Harusnya kan \\(u(2,1) = 4(2)+1 = 9\\)?\nKarena satu dan lain hal, kita perlu mentranspos matriks grid nya terlebih dahulu:\n\nu_grid'(3, 2)\n\nans = 9\n\n\nSelama berurusan dengan PDP secara numerik, seringkali akan seperti itu; matriks untuk menyimpan/mengakses hasil perhitungan adalah transpos dari matriks yang diberikan ke fungsi mesh.\nKali ini, matriks u_grid menyimpan nilai-nilai untuk mesh, sehingga perlu ditranspos untuk keperluan mengakses hasil perhitungan. Nanti bisa juga sebaliknya, yaitu dimiliki matriks yang menyimpan hasil perhitungan, sehingga perlu ditranspos ketika ingin menggunakan mesh.\n(Terlebih lagi, orientasi matriks untuk menampilkan nilai-nilai di grid dengan flipud akan sama dengan orientasi matriks untuk fungsi mesh. Jadi, kalau nantinya perlu ditranspos ketika ingin menggunakan mesh, kita juga perlu mentranspos ketika ingin menggunakan flipud untuk menampilkan nilai-nilai di grid.)\nMengapa harus berurusan dengan transpos? Mari kita lihat lagi bentuk matriks u_grid\n\nu_grid\n\nu_grid =\n\n    0    4    8   12\n    1    5    9   13\n    2    6   10   14\n\n\n\nNilai 9 ada di mana? Harusnya di indeks (3,2). Kalau kita bayangkan itu adalah grid yang terbalik secara atas-bawah. Berarti, dari ujung kiri-atas yaitu indeks (1,1), kita ke kanan dua langkah, lalu ke bawah satu langkah.\nPerhatikan: ke kanan dua langkah adalah perpindahan kolom, dan ke bawah satu langkah adalah perpinahan baris. Sedangkan, urutan indeks dalam mengakses nilai pada matriks aalah baris dulu, baru kolom. Karena dimensinya terbalik seperti itu, kita perlu mentranspos sebelum mengakses nilainya.\nKalau kita transpos dulu,\n\nu_grid'\n\nans =\n\n    0    1    2\n    4    5    6\n    8    9   10\n   12   13   14\n\n\n\nbarulah kita bisa menggunakan indeks (3,2), yaitu di baris ke-3, kolom ke-2.\n\nu_grid'(3,2)\n\nans = 9\n\n\nSedikit tambahan: alternatif dari fungsi mesh adalah fungsi surf\n\nsurf(x_arr, y_arr, u_grid);\ntitle(\"Plot u(x,y)=4x+y\");\nxlabel(\"x\");\nylabel(\"y\");\nzlabel(\"u\");\n\n\n\n\n\n\n\n\nBedanya, fungsi surf memberi warna seperti itu. Walaupun terlihat bagus, mungkin plotnya malah menjadi lebih sulit dibaca, sehingga kita akan tetap menggunakan mesh"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/modul7.html#pdp-eliptiklaplacepoisson",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/modul7.html#pdp-eliptiklaplacepoisson",
    "title": "Modul 7 Persamaan Diferensial Numerik: Nonlinear Finite Difference, PDP Eliptik & Hiperbolik",
    "section": "PDP Eliptik/Laplace/Poisson",
    "text": "PDP Eliptik/Laplace/Poisson\n\nBentuk umum persamaan Laplace\nDi mata kuliah Persamaan Diferensial Numerik, PDP orde 2 eliptik yang dibahas adalah persamaan Laplace, atau juga disebut persamaan Poisson.\nBentuk umum dari persamaan Laplace bisa ditulis \\[\\frac{\\partial^2 u}{\\partial x^2}\\left(x,y\\right) + \\frac{\\partial^2 u}{\\partial y^2}\\left(x,y\\right) = f\\left(x,y\\right), \\quad a &lt; x &lt; b, \\quad c &lt; y &lt; d\\] \\[u\\left(x, c\\right) = g\\left(x, c\\right), \\quad u\\left(x, d\\right) = g\\left(x, d\\right), \\quad a \\le x \\le b\\] \\[u\\left(a, y\\right) = g\\left(a, y\\right), \\quad u\\left(b, y\\right) = g\\left(b, y\\right), \\quad c \\le y \\le d\\] yang disertai nilai step size \\(h\\) (yaitu \\(\\Delta x\\)) dan nilai step size \\(k\\) (yaitu \\(\\Delta y\\)).\nPerhatikan bahwa ada source function \\(f\\left(x,y\\right)\\) (yang bisa saja bernilai nol) dan ada syarat batas semua sisi (karena PDP ini dalam variabel \\(x,y\\)).\nSelain itu, semua syarat batas seolah-olah diberikan oleh satu fungsi \\(g\\). Namun, biasanya, syarat batas bawah, atas, kiri, dan kanan yang diketahui tampak seperti fungsi yang berbeda-beda (walaupun sebenarnya digunakan satu fungsi yang sama).\nOleh karena itu, untuk kebutuhan praktikum, kita bisa menuliskan bentuk umum persamaan Laplace sebagai berikut:\n\\[\\frac{\\partial^2 u}{\\partial x^2}\\left(x,y\\right) + \\frac{\\partial^2 u}{\\partial y^2}\\left(x,y\\right) = f\\left(x,y\\right), \\quad a &lt; x &lt; b, \\quad c &lt; y &lt; d\\] \\[u\\left(x, c\\right) = \\text{db}\\left(x, c\\right), \\quad u\\left(x, d\\right) = \\text{ub}\\left(x, d\\right), \\quad a \\le x \\le b\\] \\[u\\left(a, y\\right) = \\text{lb}\\left(a, y\\right), \\quad u\\left(b, y\\right) = \\text{rb}\\left(b, y\\right), \\quad c \\le y \\le d\\]\nKeterangan:\n\ndb bisa diingat down boundary condition, maksudnya syarat batas bawah\nub bisa diingat upper boundary condition, maksudnya syarat batas atas\nlb bisa diingat left boundary condition, maksudnya syarat batas kiri\nrb bisa diingat right boundary condition, maksudnya syarat batas kanan\n\nKita memberi nama yang berbeda-beda untuk fungsi-fungsi syarat batas ini agar lebih mudah nantinya ketika ingin menginput syarat batas.\nLebih lanjut, batasan interval bisa kita tulis\n\\[\\text{xb} &lt; x &lt; \\text{xu}, \\quad \\text{yb} &lt; y &lt; \\text{yu}\\]\n\nxb bisa diingat “\\(x\\) (below)”\nxu bisa diingat “\\(x\\) (upper)”\nyb bisa diingat “\\(y\\) (below)”\nyu bisa diingat “\\(y\\) (upper)”\n\n\n\nIde utama\nMetode yang umum digunakan dalam penyelesaian PDP secara numerik adalah metode finite difference, melibatkan yang namanaya diskretisasi, yaitu memecah tiap interval menjadi titik-titik.\nUntuk PDP dalam variabel \\(x\\) dan \\(y\\), diskretisasi dilakukan sebagai berikut:\n\ninterval \\(a \\le x \\le b\\) dipecah menjadi titik-titik \\(x_i = a + ih\\) dengan \\(i=0,\\dots,m\\), yaitu menjadi sebanyak \\((m+1)\\) titik\ninterval \\(c \\le y \\le d\\) dipecah menjadi titik-titik \\(y_j = c + jk\\) dengan \\(j=0,\\dots,N\\), yaitu menjadi sebanyak \\((N+1)\\) titik\n\nKemudian, hasil aproksimasi solusi PDP pada titik \\(\\left(x_i, y_j\\right)\\) ditulis \\(w_{i,j}\\)\n(atau terkadang ditulis \\(u_i^j\\), atau bahkan \\(u_j^n\\) untuk titik \\(\\left(x_j, y_n\\right)\\))\nDiskretisasi untuk penylesaian PDP secara numerik bisa dipandang sebagai perumuman dari proses diskretisasi untuk penyelesaian PDB secara numerik, yaitu perumuman dari \\(t_i = a + ih\\) atau terkadang ditulis \\(x_i = a + ih\\).\nUntuk persamaan Laplace, hanya ada satu metode finite difference, yang diawali dengan permisalan nilai lambda berikut:\n\\[\\lambda = \\left(\\frac{h^2}{k^2}\\right) = \\frac{h^2}{k^2}\\]\nIde utama dari metode finite difference untuk persamaan Laplace adalah menuliskan rumus finite difference berikut untuk tiap \\(i=1,\\dots,(m-1)\\) dan juga untuk tiap \\(j=1,\\dots,(N-1)\\):\n\\[2\\left(\\lambda+1\\right) w_{i,j} - \\left(w_{i+1,j} + w_{i-1,j}\\right) - \\lambda\\left(w_{i,j+1} + w_{i,j-1}\\right) = -h^2 f\\left(x_i, y_j\\right)\\]\nSetelah menuliskan rumus tersebut sebanyak \\((m-1)\\times(N-1)\\) kali, perhatikan bahwa ada beberapa nilai syarat batas yang sudah diketahui dan berupa konstana, misalnya batas bawah \\(w_{0,0}, w_{1,0}, w_{2,0}, \\dots\\) dan batas kiri \\(w_{0,0}, w_{0,1}, w_{0,2}, \\dots\\)\nNilai-nilai yang sudah diketahui tersebut bisa langsung dimasukkan ke dalam persamaan-persamaannya.\nDengan demikian, diperoleh SPL yang terdiri dari \\((m-1)\\times(N-1)\\) buah variabel, yaitu variabel-variabel \\(w_{i,j}\\) untuk tiap \\(i=1,\\dots,(m-1)\\) dan tiap \\(j=1,\\dots,(N-1)\\).\nSPL ini dapat diselesaikan untuk memperoleh semua nilai \\(w_{i,j}\\) sekaligus.\n(Dalam penggunaan Octave, indeks \\(0,\\dots,m\\) dan \\(0,\\dots,N\\) digeser menjadi \\(1,\\dots,(m+1)\\) dan \\(1,\\dots,(N+1)\\) karena indeks array yang dimulai dari 1.)\n\n\nPenggunaan metode Gauss-Seidel\nSayangnya, tidak ada cara cepat untuk menyusun SPL tersebut. Apabila penyelesaian dilakukan secara manual, tidak masalah; kita tinggal susun SPLnya secara manual, hingga bisa disusun dalam bentuk matriks, baru menyelesaikan SPL dalam bentuk matriks tersebut (yang bisa dilakukan dengan metode langsung seperti OBE, invers, ataupun metode iteratif, atau dengan bantuan komputer).\nApabila PDP eliptik ingin diselesaikan secara program, daripada harus menyusun bentuk SPL secara rapi terlebih dahulu, kita bisa menggunakan metode penyelesaian SPL yang iteratif. Contohnya, metode Gauss-Seidel bisa langsung menggunakan bentuk umumnya, yaitu\n\\[2\\left(\\lambda+1\\right) w_{i,j} - \\left(w_{i+1,j} + w_{i-1,j}\\right) - \\lambda\\left(w_{i,j+1} + w_{i,j-1}\\right) = -h^2 f\\left(x_i, y_j\\right)\\]\nyang dipindahruaskan agar diperoleh\n\\[2\\left(\\lambda+1\\right) w_{i,j} = \\left(w_{i+1,j} + w_{i-1,j}\\right) + \\lambda\\left(w_{i,j+1} + w_{i,j-1}\\right) -h^2 f\\left(x_i, y_j\\right)\\]\n\\[w_{i,j} = \\frac{1}{2\\left(\\lambda+1\\right)}\\left(w_{i+1,j} + w_{i-1,j} + \\lambda\\left(w_{i,j+1} + w_{i,j-1}\\right) -h^2 f\\left(x_i, y_j\\right)\\right)\\]\nMengingat dari mata kuliah Metode Numerik, metode Gauss-Seidel memang memanfaatkan bentuk persamaan yang seperti ini.\nMenggunakan metode Gauss-Seidel, kita tinggal memasang tebakan awal untuk tiap variabel \\(w_{i,j}\\) (yang bisa dipasang nol semua menurut buku Burden), kemudian mengulang-ulang perhitungan menggunakan rumus tersebut hingga konvergen.\n\n\nFunction file\n\nFunction file eliptik_iteratif.m - nama file harus sama dengan nama fungsi\n\n\n\nfunction [x, y, w] = eliptik_iteratif(f, db, ub, lb, rb, xb, xu, yb, yu, h, k, tol, M)\n  x = xb : h : xu;\n  y = yb : k : yu;\n  m_plus_1 = length(x);\n  N_plus_1 = length(y);\n  \n  % susun matriks solusi w_{i,j}\n  % awalnya berisi nol semua agar sekaligus mengisi tebakan awal\n  w = zeros(m_plus_1, N_plus_1);\n\n  % isi syarat batas (saat ini masih nol semua)\n  for i = 1 : m_plus_1 % digeser dari i=0,...,m jadi i=1,...,(m+1)\n    w(i, 1)         = db(x(i), yb);\n    w(i, N_plus_1)  = ub(x(i), yu);\n  endfor\n  for j = 2 : (N_plus_1 - 1) % digeser dari j=1,...,(N-1) jadi j=2,...,N\n    w(1, j)         = lb(xb, y(j));\n    w(m_plus_1, j)  = rb(xu, y(j));\n  endfor\n  \n  % lakukan iterasi metode Gauss-Seidel untuk semua nilai w_{i,j} lainnya\n  lambd = (h/k)^2;\n  err = tol + 1; % errornya sembarang dulu, yang penting masuk loop\n  k = 1;\n  while (!(err &lt;= tol) && (k != M+1))\n    old_values = w(2 : m_plus_1 - 1,  2 : N_plus_1 - 1); % selain syarat batas\n    for i = 2 : (m_plus_1 - 1) % digeser dari i=1,...,(m-1) jadi i=2,...,m\n      for j = 2 : (N_plus_1 - 1) % digeser dari j=1,...,(N-1) jadi j=2,...,N\n        w(i, j) = w(i+1, j) + w(i-1, j) + lambd * (w(i, j+1) + w(i, j-1));\n        w(i, j) += - h^2 * f(x(i), y(j));\n        w(i, j) /= 2 * (lambd + 1);\n      endfor\n    endfor\n    new_values = w(2 : m_plus_1 - 1,  2 : N_plus_1 - 1); % selain syarat batas\n    err = max(max(abs(old_values - new_values))); % norm infinity\n    k += 1; % lanjut ke iterasi selanjutnya\n  endwhile\nendfunction\n\n\n\n\n\n\nContoh 1\nSelesaikan PDP eliptik\n\\[\\frac{\\partial^2 u}{\\partial x^2} \\left(x,y\\right) + \\frac{\\partial^2 u}{\\partial y^2} \\left(x,y\\right) = 0, \\quad 0 &lt; x &lt; 0.5, \\quad 0 &lt; y &lt; 0.5\\]\ndengan syarat batas\n\\[u(x,0) = 0, \\quad u(x, 0.5) = 200x, \\quad 0 \\le x \\le 0.5\\]\n\\[u(0,y) = 0, \\quad u(0.5, y) = 200y, \\quad 0 \\le y \\le 0.5\\]\nsecara numerik dengan step size \\(h = k = 0.125\\), toleransi \\(10^{-8}\\), dan maksimum iterasi \\(M=50\\).\n\nScript file coba1_eliptik.m - nama file bebas\n\n\n\nf = @(x,y) 0;\ndb = @(x,y) 0;\nub = @(x,y) 200*x;\nlb = @(x,y) 0;\nrb = @(x,y) 200*y;\nxb = 0;\nxu = 0.5;\nyb = 0;\nyu = 0.5;\nh = 0.125;\nk = 0.125;\ntol = 10^(-8);\nM = 50;\n\n[x_arr, y_arr, w] = eliptik_iteratif(f, db, ub, lb, rb, xb, xu, yb, yu, h, k, tol, M);\n\n% menampilkan nilai aproksimasi dalam bentuk seperi grid\ndisp(\"Grid nilai aproksimasi:\");\ndisp(flipud(w'));\n\n% gambar mesh hasil aproksimasi\nfigure;\nmesh(x_arr, y_arr, w');\ntitle(\"Hasil aproksimasi\");\nxlabel(\"x\");\nylabel(\"y\");\nzlabel(\"u\");\n\nGrid nilai aproksimasi:\n          0    25.0000    50.0000    75.0000   100.0000\n          0    18.7500    37.5000    56.2500    75.0000\n          0    12.5000    25.0000    37.5000    50.0000\n          0     6.2500    12.5000    18.7500    25.0000\n          0          0          0          0          0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContoh 2\nSelesaikan PDP eliptik\n\\[\\frac{\\partial^2 u}{\\partial x^2} \\left(x,y\\right) + \\frac{\\partial^2 u}{\\partial y^2} \\left(x,y\\right) = xe^y, \\quad 0 &lt; x &lt; 2, \\quad 0 &lt; y &lt; 1\\]\ndengan syarat batas\n\\[u(x, 0) = x, \\quad u(x, 1) = ex, \\quad 0 \\le x \\le 2\\]\n\\[u(0, y) = 0, \\quad u(2, y) = 2e^y, \\quad 0 \\le y \\le 1\\]\nsecara numerik dengan \\(m = 6\\) dan \\(N = 5\\), menggunakan metode Gauss-Seidel dengan toleransi \\(10^{-10}\\) dan maksimum iterasi \\(M=100\\).\nLalu, bandingkan hasilnya dengan solusi eksak \\(u(x,y) = xe^y\\)\nHint: perhatikan bahwa ruas kanan di PDP eliptik yang diberikan adalah \\(f(x,y) = xe^y\\)\n\nScript file coba2_eliptik.m - nama file bebas\n\n\n\nf = @(x,y) x .* exp(y);\ndb = @(x,y) x;\nub = @(x,y) e * x;\nlb = @(x,y) 0;\nrb = @(x,y) 2 * exp(y);\nxb = 0;\nxu = 2;\nyb = 0;\nyu = 1;\nm = 6;\nN = 5;\nh = (xu - xb)/m; % rumus step size: h = (b-a)/m untuk interval a &lt; x &lt; b\nk = (yu - yb)/N; % rumus step size: k = (d-c)/N untuk interval c &lt; y &lt; d\ntol = 10^(-10);\nM = 100;\n\n[x_arr, y_arr, w] = eliptik_iteratif(f, db, ub, lb, rb, xb, xu, yb, yu, h, k, tol, M);\n\n% solusi eksak\nsln = @(x, y) x .* exp(y);\n[x_grid, y_grid] = meshgrid(x_arr, y_arr);\nu = sln(x_grid, y_grid);\n\n% menampilkan nilai aproksimasi dalam bentuk seperi grid\ndisp(\"Grid nilai aproksimasi:\");\ndisp(flipud(w'));\n\n% menampilkan grid solusi eksak\ndisp(\"Grid solusi eksak:\");\ndisp(flipud(u));\n\n% perhitungan error\nerr_grid = abs(w' - u); % absolute error\nerr_total = sum(sum(err_grid)); % norm L1 (taxicab/Manhattan)\ndisp(\"Grid nilai error:\");\ndisp(flipud(err_grid));\ndisp(\"Error total (norm L1):\");\ndisp(err_total);\n\n% gambar mesh hasil aproksimasi\nfigure 1;\nmesh(x_arr, y_arr, w');\ntitle(\"Hasil aproksimasi\");\nxlabel(\"x\");\nylabel(\"y\");\nzlabel(\"u\");\n\n% gambar mesh solusi eksak\nfigure 2;\nmesh(x_arr, y_arr, u);\ntitle(\"Solusi eksak\");\nxlabel(\"x\");\nylabel(\"y\");\nzlabel(\"u\");\n\nGrid nilai aproksimasi:\n        0   0.9061   1.8122   2.7183   3.6244   4.5305   5.4366\n        0   0.7420   1.4840   2.2260   2.9679   3.7097   4.4511\n        0   0.6076   1.2152   1.8227   2.4302   3.0375   3.6442\n        0   0.4975   0.9950   1.4924   1.9898   2.4870   2.9836\n        0   0.4073   0.8145   1.2218   1.6290   2.0360   2.4428\n        0   0.3333   0.6667   1.0000   1.3333   1.6667   2.0000\nGrid solusi eksak:\n        0   0.9061   1.8122   2.7183   3.6244   4.5305   5.4366\n        0   0.7418   1.4837   2.2255   2.9674   3.7092   4.4511\n        0   0.6074   1.2147   1.8221   2.4295   3.0369   3.6442\n        0   0.4973   0.9945   1.4918   1.9891   2.4864   2.9836\n        0   0.4071   0.8143   1.2214   1.6285   2.0357   2.4428\n        0   0.3333   0.6667   1.0000   1.3333   1.6667   2.0000\nGrid nilai error:\n Columns 1 through 6:\n\n            0            0            0            0            0            0\n            0   1.6009e-04   3.1459e-04   4.5177e-04   5.4035e-04   4.8919e-04\n            0   2.2315e-04   4.3731e-04   6.2391e-04   7.3483e-04   6.4084e-04\n            0   2.0835e-04   4.0778e-04   5.8003e-04   6.7871e-04   5.8389e-04\n            0   1.3036e-04   2.5524e-04   3.6345e-04   4.2668e-04   3.7106e-04\n            0            0            0            0            0            0\n\n Column 7:\n\n            0\n            0\n            0\n            0\n            0\n            0\nError total (norm L1):\n8.6216e-03"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/tugas2.html",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/tugas2.html",
    "title": "Tugas 2 Praktikum Persamaan Diferensial Numerik 2024 Genap: Masalah Nilai Batas PDB Numerik",
    "section": "",
    "text": "Semester Genap Tahun Ajaran 2023/2024\nKembali ke Persamaan Diferensial Numerik"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/tugas2.html#petunjuk-umum",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/tugas2.html#petunjuk-umum",
    "title": "Tugas 2 Praktikum Persamaan Diferensial Numerik 2024 Genap: Masalah Nilai Batas PDB Numerik",
    "section": "Petunjuk Umum",
    "text": "Petunjuk Umum\n\nTugas ini dikerjakan secara individu.\nTerdapat dua (2) soal yang harus dijawab.\nFile-file yang harus diunggah terdiri dari:\n\nBeberapa function file sesuai kebutuhan. Penamaan untuk function file dibebaskan (tentunya nama fungsinya harus menyesuaikan), selama masih relevan dengan isi fungsinya (misalnya, dilarang menamakan function file adamsorde5.m jika isinya adalah metode Runge-Kutta).\nSejumlah script file sesuai ketentuan soal.\nSatu file .pdf (format penamaan: “penjelasan.pdf”) yang berisi penjelasan terkait jawaban kalian, sesuai permintaan soal. Pembuatannya bebas apakah menggunakan Word, LaTeX, atau yang lainnya. Jangan lupa tuliskan nama lengkap, NPM, kelas, dan judul “Tugas 2 Persamaan Diferensial Numerik 2024 Genap”.\n\nSemua file disatukan dalam satu file .zip dengan format penamaan:\n[Nama Lengkap]_[NPM]_[Kelas SIAK]_Tugas 2_Prak PDNum.zip\nContoh: Sung Jinwoo_2201234567_C_Tugas 2_Prak PDNum.zip\nBatas pengumpulan tugas ini adalah Jumat, 14 Juni 2024, pukul 23.59 WIB. Tugas dikumpulkan sesuai dengan kelas SIAK (link akan selalu sama untuk semua tugas praktikum PDNum):\nKelas A: https://forms.gle/sdSZAfFZJkNu9rK68\nKelas B: https://forms.gle/wdvZJ4c1UvifV5gEA\nKeterlambatan akan dikenakan pengurangan nilai.\nDilarang dengan keras melakukan plagiarisme, baik mencontek ataupun dicontek. Jika terdapat mahasiswa yang terindikasi melakukan plagiarisme, maka mahasiswa tersebut memperoleh nilai 0 untuk tugas ini. Namun, Anda sangat dianjurkan memanfaatkan apapun yang ada di modul praktikum.\nApabila ada pertanyaan, harap hubungi CP:\nBisma (LINE: bisma_joyosumarto)\nKarina (LINE: karinac12)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/tugas2.html#soal",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/tugas2.html#soal",
    "title": "Tugas 2 Praktikum Persamaan Diferensial Numerik 2024 Genap: Masalah Nilai Batas PDB Numerik",
    "section": "Soal",
    "text": "Soal\nTugas ini terdiri dari soal 1a-1d dan 2a-2e.\n\nDiberikan masalah nilai batas (MNB) linier / Linear Boundary Value Problem (BVP)\n\\[y'' = -4x^{(-1)}y' - 2x^{(-2)}y + 2x^{(-2)}\\ln{(x)}, \\quad 1 \\le x \\le 2,\\]\n\\[y(1) = -\\frac{1}{2}, \\quad y(2) = \\ln{2}\\]\ndan diketahui solusi eksaknya adalah\n\\[y(x) = \\ln{(x)} + \\frac{5}{x} - \\frac{4}{x^2} - \\frac{3}{2}\\]\nDengan \\(h = 0.1\\),\n\nDi file penjelasan, cocokkan PDB di atas dengan bentuk umum masalah nilai batas linier\n\\[y'' = p(x)y' + q(x)y + r(x), \\quad a \\le x \\le b,\\]\n\\[y(a) = \\alpha, \\quad y(b) = \\beta\\]\nyaitu tentukan fungsi \\(p(x)\\), fungsi \\(q(x)\\), fungsi \\(r(x)\\), nilai \\(a\\), nilai \\(b\\), nilai \\(\\alpha\\), dan nilai \\(\\beta\\).\nBuatlah script file soal_1b.m berisi penggunaan metode linear shooting untuk mengaproksimasi solusi dari MNB tersebut. Bandingkan dengan solusi analitik (cukup \\(y(x)\\) saja), sertakan perhitungan error. Lampirkan tabel dan gambar grafiknya di file penjelasan, serta perhitungan nilai \\(N\\).\nHint: untuk metode shooting (linier maupun nonlinier),\n\\[h = \\frac{b-a}{N}\\]\nBuatlah script file soal_1c.m berisi penggunaan metode linear finite difference untuk mengaproksimasi solusi dari MNB tersebut. Bandingkan dengan solusi analitik, sertakan perhitungan error. Lampirkan tabel dan gambar grafiknya di file penjelasan, serta perhitungan nilai \\(N\\).\nHint: untuk metode finite difference untuk masalah nilai batas (linier maupun nonlinier),\n\\[h = \\frac{b-a}{N+1}\\]\nDi file penjelasan, berikan argumen Anda: di antara kedua metode tersebut, apakah ada metode yang jelas lebih baik untuk masalah ini, ataukah sama-sama cukup baik?\n\nDiberikan masalah nilai batas nonlinier\n\\[y'' = \\frac{1}{2} \\left(1 - \\left(y'\\right)^2 - y \\sin{x}\\right), \\quad 0 \\le x \\le \\pi\\]\n\\[y(0) = 2, \\quad y(\\pi) = 2\\]\ndan diketahui solusi eksaknya adalah\n\\[y(x) = 2 + \\sin{x}\\]\nDengan toleransi \\(10^{-4}\\) dan \\(h = \\frac{\\pi}{20}\\),\n\nDi file penjelasan, cocokkan PDB di atas dengan bentuk umum masalah nilai batas\n\\[y'' = f(x, y, y'), \\quad a \\le x \\le b,\\]\n\\[y(a) = \\alpha, \\quad y(b) = \\beta\\]\nyaitu tentukan fungsi \\(f(x, y, y')\\), nilai \\(a\\), nilai \\(b\\), nilai \\(\\alpha\\), dan nilai \\(\\beta\\).\nDi file penjelasan, uraikan perhitungan \\(f_y(x,y,y')\\) (yaitu \\(\\frac{\\partial f}{\\partial y}(x,y,y')\\)) dan \\(f_{y'}(x,y,y')\\) (yaitu \\(\\frac{\\partial f}{\\partial y'}(x,y,y')\\)) secara analitik (turunan parsial).\nBuatlah script file soal_2c.m berisi penggunaan metode nonlinear shooting untuk mengaproksimasi solusi dari MNB tersebut. Bandingkan dengan solusi analitik (cukup \\(y(x)\\) saja), sertakan perhitungan error. Lampirkan tabel dan gambar grafiknya di file penjelasan, serta perhitungan nilai \\(N\\).\nBuatlah script file soal_2d.m berisi penggunaan metode nonlinear finite difference untuk mengaproksimasi solusi dari MNB tersebut. Bandingkan dengan solusi analitik, sertakan perhitungan error. Lampirkan tabel dan gambar grafiknya di file penjelasan, serta perhitungan nilai \\(N\\).\nDi file penjelasan, berikan argumen Anda: di antara kedua metode tersebut, apakah ada metode yang jelas lebih baik untuk masalah ini, ataukah sama-sama cukup baik?"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/tugas1.html",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/tugas1.html",
    "title": "Tugas 1 Praktikum Persamaan Diferensial Numerik 2024 Genap: Masalah Nilai Awal PDB Numerik",
    "section": "",
    "text": "Semester Genap Tahun Ajaran 2023/2024\nKembali ke Persamaan Diferensial Numerik"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/tugas1.html#petunjuk-umum",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/tugas1.html#petunjuk-umum",
    "title": "Tugas 1 Praktikum Persamaan Diferensial Numerik 2024 Genap: Masalah Nilai Awal PDB Numerik",
    "section": "Petunjuk Umum",
    "text": "Petunjuk Umum\n\nTugas ini dikerjakan secara individu.\nTerdapat dua (2) soal yang harus dijawab.\nFile-file yang harus diunggah terdiri dari:\n\nBeberapa function file sesuai kebutuhan. Penamaan untuk function file dibebaskan (tentunya nama fungsinya harus menyesuaikan), selama masih relevan dengan isi fungsinya (misalnya, dilarang menamakan function file adamsorde5.m jika isinya adalah metode Runge-Kutta).\nSejumlah script file sesuai ketentuan soal.\nSatu file .pdf (format penamaan: “penjelasan.pdf”) yang berisi penjelasan terkait jawaban kalian, sesuai permintaan soal. Pembuatannya bebas apakah menggunakan Word, LaTeX, atau yang lainnya. Jangan lupa tuliskan nama lengkap, NPM, kelas, dan judul “Tugas 1 Persamaan Diferensial Numerik 2024 Genap”.\n\nSemua file disatukan dalam satu file .zip dengan format penamaan:\n[Nama Lengkap]_[NPM]_[Kelas SIAK]_Tugas 1_Prak PDNum.zip\nContoh: Satoru Gojo_2201234567_C_Tugas 1_Prak PDNum.zip\nBatas pengumpulan tugas ini adalah Jumat, 14 Juni 2024, pukul 23.59 WIB. Tugas dikumpulkan sesuai dengan kelas SIAK (link akan selalu sama untuk semua tugas praktikum PDNum):\nKelas A: https://forms.gle/sdSZAfFZJkNu9rK68\nKelas B: https://forms.gle/wdvZJ4c1UvifV5gEA\nKeterlambatan akan dikenakan pengurangan nilai.\nDilarang dengan keras melakukan plagiarisme, baik mencontek ataupun dicontek. Jika terdapat mahasiswa yang terindikasi melakukan plagiarisme, maka mahasiswa tersebut memperoleh nilai 0 untuk tugas ini. Namun, Anda sangat dianjurkan memanfaatkan apapun yang ada di modul praktikum.\nApabila ada pertanyaan, harap hubungi CP:\nBisma (LINE: bisma_joyosumarto)\nKarina (LINE: karinac12)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/tugas1.html#soal",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/tugas1.html#soal",
    "title": "Tugas 1 Praktikum Persamaan Diferensial Numerik 2024 Genap: Masalah Nilai Awal PDB Numerik",
    "section": "Soal",
    "text": "Soal\nTugas ini terdiri dari soal 1a-1d dan 2a-2e.\n\nDiberikan suatu masalah nilai awal (MNA) / initial value problem (IVP):\n\\[\n\\begin{aligned}\n& y^{\\prime}=\\frac{y^{2}}{1+t}, \\quad 1 \\leq t \\leq 2 \\\\\n& y(1)=-(\\ln 2)^{-1}\n\\end{aligned}\n\\]\nDiketahui solusi eksak dari MNA tersebut adalah:\n\\[\ny(t)=-\\frac{1}{\\ln (t+1)}\n\\]\nDengan \\(h=0.05\\),\n\nDi file penjelasan, cocokkan MNA di atas dengan bentuk umum MNA PDB orde 1\n\\[y' = f(t,y), \\quad a \\le t \\le b\\] \\[y(a) = \\alpha\\]\nyaitu tentukan fungsi \\(f(t,y)\\), nilai \\(a\\), nilai \\(b\\), dan nilai \\(\\alpha\\). Hitung juga nilai \\(N\\).\nBuatlah script file soal_1b.m berisi penggunaan satu metode one-step pilihan Anda untuk mengaproksimasi solusi dari MNA tersebut. (Tentunya, perolehlah terlebih dahulu function file yang sesuai dari modul praktikum.) Bandingkan dengan solusi analitik, sertakan perhitungan error. Lampirkan tabel dan gambar grafiknya di file penjelasan.\nBuatlah script file soal_1c.m berisi penggunaan satu metode multistep pilihan Anda untuk mengaproksimasi solusi dari MNA tersebut. Bandingkan dengan solusi analitik, sertakan perhitungan error. Lampirkan tabel dan gambar grafiknya di file penjelasan.\nDi file penjelasan, berikan argumen Anda: di antara kedua metode tersebut, apakah ada metode yang jelas lebih baik untuk masalah ini, ataukah sama-sama cukup baik?\n\nDiberikan MNA PDB orde 2\n\\[y^{\\prime \\prime}-2 y^{\\prime}+y=t e^t-t, \\quad 0 \\leq t \\leq 1, \\quad y(0)=y^{\\prime}(0)=0\\]\ndan diketahui solusi analitiknya:\n\\[y(t)=\\frac{1}{6} t^3 e^t-t e^t+2 e^t-t-2\\]\nDengan \\(h=0.05\\),\n\nDi file penjelasan, tentukan rumus \\(y'(t)\\) dari solusi analitik yang diberikan.\nDi file penjelasan, berikan uraian mengubah MNA PDB orde 2 tersebut menjadi sistem MNA PDB orde 1. Hitung juga nilai \\(N\\).\nBuatlah script file soal_2c.m berisi penggunaan satu metode one-step pilihan Anda untuk mengaproksimasi solusi dari sistem tersebut. Bandingkan dengan solusi analitik (baik \\(y(t)\\) maupun \\(y'(t)\\)), sertakan perhitungan error. Lampirkan tabel dan gambar grafiknya di file penjelasan.\nBuatlah script file soal_2d.m berisi penggunaan satu metode multistep pilihan Anda untuk mengaproksimasi solusi dari sistem tersebut. Bandingkan dengan solusi analitik (baik \\(y(t)\\) maupun \\(y'(t)\\)), sertakan perhitungan error. Lampirkan tabel dan gambar grafiknya di file penjelasan.\nDi file penjelasan, berikan argumen Anda: di antara kedua metode tersebut, apakah ada metode yang jelas lebih baik untuk masalah ini, ataukah sama-sama cukup baik?"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/tugas3.html",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/tugas3.html",
    "title": "Tugas 3 Praktikum Persamaan Diferensial Numerik 2024 Genap: PDP Numerik",
    "section": "",
    "text": "Semester Genap Tahun Ajaran 2023/2024\nKembali ke Persamaan Diferensial Numerik"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/tugas3.html#petunjuk-umum",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/tugas3.html#petunjuk-umum",
    "title": "Tugas 3 Praktikum Persamaan Diferensial Numerik 2024 Genap: PDP Numerik",
    "section": "Petunjuk Umum",
    "text": "Petunjuk Umum\n\nTugas ini dikerjakan secara individu.\nTerdapat tiga (3) soal yang harus dijawab.\nFile-file yang harus diunggah terdiri dari:\n\nBeberapa function file sesuai kebutuhan. Penamaan untuk function file dibebaskan (tentunya nama fungsinya harus menyesuaikan), selama masih relevan dengan isi fungsinya (misalnya, dilarang menamakan function file adamsorde5.m jika isinya adalah metode Runge-Kutta).\nSejumlah script file sesuai ketentuan soal.\nSatu file .pdf (format penamaan: “penjelasan.pdf”) yang berisi penjelasan terkait jawaban kalian, sesuai permintaan soal. Pembuatannya bebas apakah menggunakan Word, LaTeX, atau yang lainnya. Jangan lupa tuliskan nama lengkap, NPM, kelas, dan judul “Tugas 3 Persamaan Diferensial Numerik 2024 Genap”.\n\nSemua file disatukan dalam satu file .zip dengan format penamaan:\n[Nama Lengkap]_[NPM]_[Kelas SIAK]_Tugas 3_Prak PDNum.zip\nContoh: Kibutsuji Muzan_2201234567_C_Tugas 3_Prak PDNum.zip\nBatas pengumpulan tugas ini adalah Jumat, 14 Juni 2024, pukul 23.59 WIB. Tugas dikumpulkan sesuai dengan kelas SIAK (link akan selalu sama untuk semua tugas praktikum PDNum):\nKelas A: https://forms.gle/sdSZAfFZJkNu9rK68\nKelas B: https://forms.gle/wdvZJ4c1UvifV5gEA\nKeterlambatan akan dikenakan pengurangan nilai.\nDilarang dengan keras melakukan plagiarisme, baik mencontek ataupun dicontek. Jika terdapat mahasiswa yang terindikasi melakukan plagiarisme, maka mahasiswa tersebut memperoleh nilai 0 untuk tugas ini. Namun, Anda sangat dianjurkan memanfaatkan apapun yang ada di modul praktikum.\nApabila ada pertanyaan, harap hubungi CP:\nBisma (LINE: bisma_joyosumarto)\nKarina (LINE: karinac12)"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/pdnum/tugas3.html#soal",
    "href": "semuahalaman/modulprak/2024/genap/pdnum/tugas3.html#soal",
    "title": "Tugas 3 Praktikum Persamaan Diferensial Numerik 2024 Genap: PDP Numerik",
    "section": "Soal",
    "text": "Soal\nTugas ini terdiri dari soal 1a-1d, 2a-2f, dan 3a-3e.\n\nDiberikan masalah persamaan transport (adveksi):\n\\[u_t + 2u_x = 0, \\quad 0 &lt; x &lt; 2, \\quad 0 &lt; t &lt; 3\\]\n\\[u(x,0) = e^{-x^2}, \\quad 0 \\le x \\le 2\\]\n\\[u(0,t) = e^{-4t^2}, \\quad 0 &lt; t &lt; 3\\]\n\\[u(2,t) = e^{-4\\left(1-t\\right)^2}, \\quad 0 &lt; t &lt; 3\\]\nyang memiliki solusi eksak \\(u(x,t) = e^{-\\left(x-2t\\right)^2}\\).\nDengan \\(\\Delta x = \\Delta t = 0.1\\),\n\nDi file penjelasan, cocokkan PDP di atas dengan bentuk umum persamaan transport\n\\[u_t + du_x = 0, \\quad \\text{xb} &lt; x &lt; \\text{xu}, \\quad \\text{tb} &lt; t &lt; \\text{tu}\\]\n\\[u(x,\\text{tb}) = f(x), \\quad \\text{xb} \\le x \\le \\text{xu}\\]\n\\[u(\\text{xb},t) = \\text{lb}(t), \\quad \\text{tb} &lt; t &lt; \\text{tu}\\]\n\\[u(\\text{xu},t) = \\text{rb}(t), \\quad \\text{tb} &lt; t &lt; \\text{tu}\\]\nyaitu tentukan nilai \\(d\\), nilai \\(\\text{xb}\\), nilai \\(\\text{xu}\\), nilai \\(\\text{tb}\\), nilai \\(\\text{tu}\\), fungsi \\(f(x)\\), fungsi \\(\\text{lb}(t)\\), dan fungsi \\(\\text{rb}(t)\\).\nBuatlah script file soal_1b.m berisi penggunaan metode Courant-Isaacson-Rees untuk mengaproksimasi solusi dari PDP tersebut. Lampirkan gambar grafiknya (termasuk grafik solusi analitik) di file penjelasan (putar dulu grafiknya agar lebih terlihat). Seberapa mirip hasilnya dengan solusi analitik?\nBuatlah script file soal_1c.m berisi penggunaan metode Richardson untuk mengaproksimasi solusi dari PDP tersebut. Lampirkan gambar grafiknya di file penjelasan (putar dulu grafiknya agar lebih terlihat). Apakah solusi numeriknya stabil?\nBuatlah script file soal_1d.m berisi penggunaan metode Lax untuk mengaproksimasi solusi dari PDP tersebut. Lampirkan gambar grafiknya di file penjelasan (putar dulu grafiknya agar lebih terlihat). Seberapa mirip hasilnya dengan solusi analitik?\n\nDiberikan masalah nilai awal-batas\n\\[\\begin{aligned}\n     u_t &= 3u_{xx}, \\quad 0 \\le x \\le \\pi, \\quad 0 &lt; t \\le T, \\\\\n     u(0,t) &= u(\\pi, t) = 0, \\quad 0 &lt; t \\le T, \\\\\n     u(x,0) &= 3\\sin{(2x)} - 6\\sin{(5x)}, \\quad 0 \\le x \\le \\pi\n\\end{aligned}\\]\ndan setelah menggunakan metode pemisahan variabel di UAS PDP tahun ini diketahui solusi eksaknya adalah\n\\[u(x,t) = 3e^{-12t} \\sin{(2x)} - 6e^{-75t} \\sin{(5x)}\\]\nDengan \\(T=2\\),\n\nDi file penjelasan, uraikan pemeriksaan diskriminan dari PDP tersebut untuk memastikan bahwa PDP di atas tergolong parabolik.\nDi file penjelasan, cocokkan PDP parabolik di atas dengan bentuk umum persamaan panas\n\\[\\frac{\\partial u}{\\partial t} (x,t) = \\alpha^2 \\frac{\\partial^2 u}{\\partial x^2}(x,t), \\quad \\text{xb} \\le x \\le \\text{xu}, \\quad \\text{tb} &lt; t \\le \\text{tu},\\]\n\\[u(x,\\text{tb}) = f(x), \\quad \\text{xb} \\le x \\le \\text{xu}\\]\n\\[u(\\text{xb},t) = \\text{lb}(t), \\quad \\text{tb} &lt; t \\le \\text{tu}\\]\n\\[u(\\text{xu},t) = \\text{rb}(t), \\quad \\text{tb} &lt; t \\le \\text{tu}\\]\nyaitu tentukan nilai \\(\\alpha^2\\), nilai \\(\\text{xb}\\), nilai \\(\\text{xu}\\), nilai \\(\\text{tb}\\), nilai \\(\\text{tu}\\), fungsi \\(f(x)\\), fungsi \\(\\text{lb}(t)\\), dan fungsi \\(\\text{rb}(t)\\).\nDengan \\(h = \\Delta x = \\frac{\\pi}{10}\\) dan \\(k = \\Delta t = 0.1\\), uraikan perhitungan nilai \\(\\lambda\\) di file penjelasan. Apakah \\(\\lambda \\le \\frac{1}{2}\\)?\nBuatlah script file soal_2d.m berisi penggunaan metode forward-difference untuk mengaproksimasi solusi dari PDP tersebut. Lampirkan gambar grafiknya (termasuk grafik solusi analitik) di file penjelasan. Apakah solusi numeriknya stabil?\nBuatlah script file soal_2e.m berisi penggunaan metode backward-difference untuk mengaproksimasi solusi dari PDP tersebut. Lampirkan gambar grafiknya di file penjelasan. Seberapa mirip hasilnya dengan solusi analitik?\nBuatlah script file soal_2f.m berisi penggunaan metode Crank-Nicolson untuk mengaproksimasi solusi dari PDP tersebut. Lampirkan gambar grafiknya di file penjelasan. Seberapa mirip hasilnya dengan solusi analitik?\n\nDiberikan persamaan gelombang\n\\[\\frac{\\partial^2 u}{\\partial t^2} - \\frac{1}{16\\pi^2} \\frac{\\partial^2 u}{\\partial x^2} = 0, \\quad 0 &lt; x &lt; 0.5, \\quad 0 &lt; t &lt; 0.5\\]\n\\[u(x,0) = 0, \\quad 0 \\le x \\le 0.5\\]\n\\[\\frac{\\partial u}{\\partial t}(x,0) = \\sin{4\\pi x}, \\quad 0 \\le x \\le 0.5\\]\n\\[u(0,t) = u(0.5, t) = 0, \\quad t &gt; 0\\]\nyang diketahui solusi eksaknya adalah\n\\[u(x,t) = \\sin{(t)} \\sin{(4\\pi x)}\\]\n\nDi file penjelasan, uraikan pemeriksaan diskriminan dari PDP tersebut untuk memastikan bahwa PDP di atas tergolong hiperbolik.\nDi file penjelasan, cocokkan persamaan gelombang di atas dengan bentuk umum\n\\[\\frac{\\partial^2 u}{\\partial t^2}\\left(x,t\\right) - \\alpha^2 \\frac{\\partial^2 u}{\\partial  x^2}\\left(x,t\\right) = 0, \\quad \\text{xb} &lt; x &lt; \\text{xu}, \\quad \\text{tb} &lt; t &lt; \\text{tu}\\]\n\\[u\\left(x,\\text{tb}\\right) = f\\left(x\\right), \\quad \\frac{\\partial u}{\\partial t}\\left(x,\\text{tb}\\right) = g\\left(x\\right), \\quad \\text{xb} \\le x \\le \\text{xu}\\]\n\\[u\\left(\\text{xb},t\\right) = \\text{lb}\\left(t\\right), \\quad \\text{tb} &lt; t \\le \\text{tu}\\]\n\\[u\\left(\\text{xu},t\\right) = \\text{rb}\\left(t\\right), \\quad \\text{tb} &lt; t \\le \\text{tu}\\]\nyaitu tentukan nilai \\(\\alpha^2\\), nilai \\(\\text{xb}\\), nilai \\(\\text{xu}\\), nilai \\(\\text{tb}\\), nilai \\(\\text{tu}\\), fungsi \\(f(x)\\), fungsi \\(g(x)\\), fungsi \\(\\text{lb}(t)\\), dan fungsi \\(\\text{rb}(t)\\).\nBuatlah script file soal_3c.m untuk mengaproksimasi solusi dari persamaan gelombang tersebut dengan \\(m=4\\) dan \\(N=4\\). Lampirkan hasil output grid-grid, error totalnya, dan gambar grafiknya di file penjelasan.\nDi file penjelsan, tulis ulang output grid aproksimasi dengan rapi (misalnya menggunakan fitur tabel di Word atau LaTeX) disertai nilai \\(x\\) di tiap kolom (sebelah bawah) dan nilai \\(t\\) di tiap baris (sebelah kiri).\nContohnya, hasil output berikut dengan \\(x_0=0\\), \\(t_0=0\\), \\(\\Delta x = 0.25\\) dan \\(\\Delta t = 0.25\\),\n    0  -0.7071  -1.0000  -0.7071        0\n    0  -0.5000  -0.7071  -0.5000        0\n    0        0        0  -0.0000        0\n    0   0.5000   0.7071   0.5000        0\n    0   0.7071   1.0000   0.7071   0.0000\nditulis dengan rapi menjadi\n\n\n\n\n\n\n\n\n\n\n\n\\(t_4 = 1\\)\n0\n-0.7071\n-1.0000\n-0.7071\n0\n\n\n\\(t_3 = 0.75\\)\n0\n-0.5000\n-0.7071\n-0.5000\n0\n\n\n\\(t_2 = 0.5\\)\n0\n0\n0\n-0.0000\n0\n\n\n\\(t_1 = 0.25\\)\n0\n0.5000\n0.7071\n0.5000\n0\n\n\n\\(t_0 = 0\\)\n0\n0.7071\n1.0000\n0.7071\n0.0000\n\n\n\n\\(x_0=0\\)\n\\(x_1=0.25\\)\n\\(x_2=0.5\\)\n\\(x_3=0.75\\)\n\\(x_4=1\\)\n\n\n\n\\(\\)\nDi file penjelsan, tulis ulang output grid solusi eksak dengan rapi (misalnya menggunakan fitur tabel di Word atau LaTeX) disertai nilai \\(x\\) di tiap kolom (sebelah bawah) dan nilai \\(t\\) di tiap baris (sebelah kiri)."
  }
]